<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 86]
- [cs.CL](#cs.CL) [Total: 49]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.LG](#cs.LG) [Total: 71]
- [cs.NE](#cs.NE) [Total: 3]
- [eess.IV](#eess.IV) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [An Memory-Efficient Framework for Deformable Transformer with Neural Architecture Search](https://arxiv.org/abs/2507.11549)
*Wendong Mao,Mingfan Zhao,Jianfeng Guan,Qiwei Dong,Zhongfeng Wang*

Main category: cs.CV

TL;DR: 提出一种硬件友好的优化框架，通过NAS自动优化切片策略以改进变形注意力Transformer模型的硬件性能，同时仅微小降低模型准确率。


<details>
  <summary>Details</summary>
Motivation: 变形注意力Transformer的采样机制导致不规则内存访问，难以高效部署在硬件上，目前加速方法存在硬件开销高或模型准确率下降的问题。

Method: 通过神经架构搜索(NAS)结合新的切片策略，在推理过程中将输入特征划分为统一块，避免内存冲突；并设计了FPGA验证系统评估性能。

Result: 在ImageNet-1K数据集上验证，该方法的准确性仅比基础DAT下降0.2%。硬件实验显示相比现有方法，DRAM访问次数降低至18%。

Conclusion: 优化框架在维持较高模型准确率同时显著提升硬件性能，证明了其在边缘硬件上的实用性。

Abstract: Deformable Attention Transformers (DAT) have shown remarkable performance in
computer vision tasks by adaptively focusing on informative image regions.
However, their data-dependent sampling mechanism introduces irregular memory
access patterns, posing significant challenges for efficient hardware
deployment. Existing acceleration methods either incur high hardware overhead
or compromise model accuracy. To address these issues, this paper proposes a
hardware-friendly optimization framework for DAT. First, a neural architecture
search (NAS)-based method with a new slicing strategy is proposed to
automatically divide the input feature into uniform patches during the
inference process, avoiding memory conflicts without modifying model
architecture. The method explores the optimal slice configuration by jointly
optimizing hardware cost and inference accuracy. Secondly, an FPGA-based
verification system is designed to test the performance of this framework on
edge-side hardware. Algorithm experiments on the ImageNet-1K dataset
demonstrate that our hardware-friendly framework can maintain have only 0.2%
accuracy drop compared to the baseline DAT. Hardware experiments on Xilinx FPGA
show the proposed method reduces DRAM access times to 18% compared with
existing DAT acceleration methods.

</details>


### [2] [Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction](https://arxiv.org/abs/2507.11550)
*Hyeonseok Jin,Geonmin Kim,Kyungbaek Kim*

Main category: cs.CV

TL;DR: 提出了一种名为Deformable Dynamic Convolution Network (DDCN)的新型网络，用于进行高效且准确的交通预测，解决了传统方法的异质性和可扩展性的限制问题。


<details>
  <summary>Details</summary>
Motivation: 目前的交通预测方法在捕捉区域和时间段的异质性方面存在困难，同时主流的GNN方法对大型数据集扩展能力有限。

Method: 提出基于偏移的可变形过滤器并结合Transformer风格的卷积神经网络，将其分解为编码器-解码器结构，编码器中引入了空间和时空注意力模块，解码器中采用前馈模块进行补充。

Result: 在四个真实世界的数据集上进行了综合实验，DDCN取得了具有竞争力的性能，证明了其有效性。

Conclusion: CNN方法依旧在时空交通预测中具有发展潜力，DDCN的一系列创新证明了其在准确性和效率上的应用优势。

Abstract: Spatio-temporal traffic prediction plays a key role in intelligent
transportation systems by enabling accurate prediction in complex urban areas.
Although not only accuracy but also efficiency for scalability is important,
some previous methods struggle to capture heterogeneity such as varying traffic
patterns across regions and time periods. Moreover, Graph Neural Networks
(GNNs), which are the mainstream of traffic prediction, not only require
predefined adjacency matrix, but also limit scalability to large-scale data
containing many nodes due to their inherent complexity. To overcome these
limitations, we propose Deformable Dynamic Convolution Network (DDCN) for
accurate yet efficient traffic prediction. Traditional Convolutional Neural
Networks (CNNs) are limited in modeling non-Euclidean spatial structures and
spatio-temporal heterogeneity, DDCN overcomes these challenges by dynamically
applying deformable filters based on offset. Specifically, DDCN decomposes
transformer-style CNN to encoder-decoder structure, and applies proposed
approaches to the spatial and spatio-temporal attention blocks of the encoder
to emphasize important features. The decoder, composed of feed-forward module,
complements the output of the encoder. This novel structure make DDCN can
perform accurate yet efficient traffic prediction. In comprehensive experiments
on four real-world datasets, DDCN achieves competitive performance, emphasizing
the potential and effectiveness of CNN-based approaches for spatio-temporal
traffic prediction.

</details>


### [3] [Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models](https://arxiv.org/abs/2507.11554)
*Zejian Li,Yize Li,Chenye Meng,Zhongni Liu,Yang Ling,Shengyuan Zhang,Guang Yang,Changyuan Yang,Zhiyuan Yang,Lingyun Sun*

Main category: cs.CV

TL;DR: 提出了Inversion-DPO，通过避免奖励建模简化了对扩散模型的人类偏好对齐，提高生成精度及训练效率，并在文本到图像生成和组合性图像生成任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型对齐方法因需要训练基础模型和奖励模型，计算开销大且可能降低模型精度和效率。

Method: 通过重新构建直接偏好优化(DPO)并使用DDIM反演规避奖励建模，进行不可行的后验采样并得到高效的后训练范式。

Result: 在文本到图像和组合性图像生成任务中显著提升生成模型性能，并展示了生成高保真、组合一致图像的能力。

Conclusion: Inversion-DPO方法为扩散模型的高效、精确对齐开辟了新途径，优化了复杂真实生成任务中的应用。

Abstract: Recent advancements in diffusion models (DMs) have been propelled by
alignment methods that post-train models to better conform to human
preferences. However, these approaches typically require computation-intensive
training of a base model and a reward model, which not only incurs substantial
computational overhead but may also compromise model accuracy and training
efficiency. To address these limitations, we propose Inversion-DPO, a novel
alignment framework that circumvents reward modeling by reformulating Direct
Preference Optimization (DPO) with DDIM inversion for DMs. Our method conducts
intractable posterior sampling in Diffusion-DPO with the deterministic
inversion from winning and losing samples to noise and thus derive a new
post-training paradigm. This paradigm eliminates the need for auxiliary reward
models or inaccurate appromixation, significantly enhancing both precision and
efficiency of training. We apply Inversion-DPO to a basic task of text-to-image
generation and a challenging task of compositional image generation. Extensive
experiments show substantial performance improvements achieved by Inversion-DPO
compared to existing post-training methods and highlight the ability of the
trained generative models to generate high-fidelity compositionally coherent
images. For the post-training of compostitional image geneation, we curate a
paired dataset consisting of 11,140 images with complex structural annotations
and comprehensive scores, designed to enhance the compositional capabilities of
generative models. Inversion-DPO explores a new avenue for efficient,
high-precision alignment in diffusion models, advancing their applicability to
complex realistic generation tasks. Our code is available at
https://github.com/MIGHTYEZ/Inversion-DPO

</details>


### [4] [Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2507.11558)
*Changlu Chen,Yanbin Liu,Chaoxi Niu,Ling Chen,Tianqing Zhu*

Main category: cs.CV

TL;DR: ST-VFM系统性地重新编程视觉基础模型（VFMs），用于时空预测任务，通过dual-branch架构和两阶段重编程克服关键限制，显示出卓越表现。


<details>
  <summary>Details</summary>
Motivation: 解决VFMs在时空预测任务中缺乏时间建模能力以及视觉和时空数据之间模式差异的问题。

Method: 提出ST-VFM框架，引入dual-branch架构整合原始时空输入与辅助流输入，通过前置和后置阶段重编程机制有效嵌入时间上下文及动态交互，充分利用VFMs的空间建模能力。

Result: 在10个时空数据集上实验，显示ST-VFM相较于现有方法表现更强，在多种VFMs（如DINO, CLIP, DEIT）中验证其稳健性。

Conclusion: ST-VFM在基础视觉模型的基础上提出了一种通用时空预测的创新方法，为ST预测任务提供了高效解决方案。

Abstract: Foundation models have achieved remarkable success in natural language
processing and computer vision, demonstrating strong capabilities in modeling
complex patterns. While recent efforts have explored adapting large language
models (LLMs) for time-series forecasting, LLMs primarily capture
one-dimensional sequential dependencies and struggle to model the richer
spatio-temporal (ST) correlations essential for accurate ST forecasting. In
this paper, we present \textbf{ST-VFM}, a novel framework that systematically
reprograms Vision Foundation Models (VFMs) for general-purpose spatio-temporal
forecasting. While VFMs offer powerful spatial priors, two key challenges arise
when applying them to ST tasks: (1) the lack of inherent temporal modeling
capacity and (2) the modality gap between visual and ST data. To address these,
ST-VFM adopts a \emph{dual-branch architecture} that integrates raw ST inputs
with auxiliary ST flow inputs, where the flow encodes lightweight temporal
difference signals interpretable as dynamic spatial cues. To effectively
process these dual-branch inputs, ST-VFM introduces two dedicated reprogramming
stages. The \emph{pre-VFM reprogramming} stage applies a Temporal-Aware Token
Adapter to embed temporal context and align both branches into VFM-compatible
feature spaces. The \emph{post-VFM reprogramming} stage introduces a Bilateral
Cross-Prompt Coordination module, enabling dynamic interaction between branches
through prompt-based conditioning, thus enriching joint representation learning
without modifying the frozen VFM backbone. Extensive experiments on ten
spatio-temporal datasets show that ST-VFM outperforms state-of-the-art
baselines, demonstrating effectiveness and robustness across VFM backbones
(e.g., DINO, CLIP, DEIT) and ablation studies, establishing it as a strong
general framework for spatio-temporal forecasting.

</details>


### [5] [Expert Operational GANS: Towards Real-Color Underwater Image Restoration](https://arxiv.org/abs/2507.11562)
*Ozer Can Devecioglu,Serkan Kiranyaz,Mehmet Yamac,Moncef Gabbouj*

Main category: cs.CV

TL;DR: 利用多生成器的xOp-GAN模型解决水下图像修复问题，比传统方法在性能上有更大提升。


<details>
  <summary>Details</summary>
Motivation: 解决由于复杂光传播、散射和深度衰减产生的水下图像恢复难题，传统GAN方法效果有限。

Method: 提出xOp-GAN，一个采用多个专家生成器的GAN模型，每个生成器针对特定图像质量子集进行训练，由判别器根据感知置信评分选择最佳恢复图像。

Result: 在LSUI数据集上进行测试，xOp-GAN的PSNR值高达25.16 dB，大幅优于单一回归模型，同时降低了模型复杂度。

Conclusion: xOp-GAN证明了多生成器结合判别器的创新设计在水下图像修复中的有效性，为解决异质领域修复问题提供了新方向。

Abstract: The wide range of deformation artifacts that arise from complex light
propagation, scattering, and depth-dependent attenuation makes the underwater
image restoration to remain a challenging problem. Like other single deep
regressor networks, conventional GAN-based restoration methods struggle to
perform well across this heterogeneous domain, since a single generator network
is typically insufficient to capture the full range of visual degradations. In
order to overcome this limitation, we propose xOp-GAN, a novel GAN model with
several expert generator networks, each trained solely on a particular subset
with a certain image quality. Thus, each generator can learn to maximize its
restoration performance for a particular quality range. Once a xOp-GAN is
trained, each generator can restore the input image and the best restored image
can then be selected by the discriminator based on its perceptual confidence
score. As a result, xOP-GAN is the first GAN model with multiple generators
where the discriminator is being used during the inference of the regression
task. Experimental results on benchmark Large Scale Underwater Image (LSUI)
dataset demonstrates that xOp-GAN achieves PSNR levels up to 25.16 dB,
surpassing all single-regressor models by a large margin even, with reduced
complexity.

</details>


### [6] [Data-Driven Meta-Analysis and Public-Dataset Evaluation for Sensor-Based Gait Age Estimation](https://arxiv.org/abs/2507.11571)
*Varun Velankar*

Main category: cs.CV

TL;DR: 本文研究如何从步态估计年龄，综述了59项研究并进行大规模实验，证明深度网络的准确性和效率，提出将误差降至3年的实际指导方案。


<details>
  <summary>Details</summary>
Motivation: 步态年龄估计在医疗、安防和人机交互等领域有重要应用价值，探索如何提高估计精度。

Method: 结合元分析和大规模实验，使用多种传感器数据及深度学习模型（ResNet34等），并进行可视化分析（Grad-CAM）。

Result: 多传感器融合平均误差低至3.4年，深度网络可达96%的准确性，处理时间小于0.1秒。

Conclusion: 本文提供了步态年龄估计的基准并提出优化模型误差的指南，为实际应用提供了方法论支持。

Abstract: Estimating a person's age from their gait has important applications in
healthcare, security and human-computer interaction. In this work, we review
fifty-nine studies involving over seventy-five thousand subjects recorded with
video, wearable and radar sensors. We observe that convolutional neural
networks produce an average error of about 4.2 years, inertial-sensor models
about 4.5 years and multi-sensor fusion as low as 3.4 years, with notable
differences between lab and real-world data. We then analyse sixty-three
thousand eight hundred forty-six gait cycles from the OU-ISIR Large-Population
dataset to quantify correlations between age and five key metrics: stride
length, walking speed, step cadence, step-time variability and joint-angle
entropy, with correlation coefficients of at least 0.27. Next, we fine-tune a
ResNet34 model and apply Grad-CAM to reveal that the network attends to the
knee and pelvic regions, consistent with known age-related gait changes.
Finally, on a one hundred thousand sample subset of the VersatileGait database,
we compare support vector machines, decision trees, random forests, multilayer
perceptrons and convolutional neural networks, finding that deep networks
achieve up to 96 percent accuracy while processing each sample in under 0.1
seconds. By combining a broad meta-analysis with new large-scale experiments
and interpretable visualizations, we establish solid performance baselines and
practical guidelines for reducing gait-age error below three years in
real-world scenarios.

</details>


### [7] [What cat is that? A re-id model for feral cats](https://arxiv.org/abs/2507.11575)
*Victor Caquilpan*

Main category: cs.CV

TL;DR: 本研究开发了PPGNet-Cat模型，通过调整现有的PPGNet模型，用于野生猫个体的重新识别任务，取得很高的准确率和性能。


<details>
  <summary>Details</summary>
Motivation: 野猫对澳大利亚野生动物有显著危害，因此需要有效的监控手段，以减少其影响。

Method: 使用计算机视觉方法，通过修改原用于阿穆尔虎再识别的PPGNet模型开发PPGNet-Cat，并进行了对比学习实验如ArcFace loss。

Result: PPGNet-Cat在识别野猫方面表现突出，mAP达到0.86，rank-1准确率为0.95。

Conclusion: PPGNet-Cat证明了在野猫个体重新识别任务中的竞争力，为相关领域提供了参考模型。

Abstract: Feral cats exert a substantial and detrimental impact on Australian wildlife,
placing them among the most dangerous invasive species worldwide. Therefore,
closely monitoring these cats is essential labour in minimising their effects.
In this context, the potential application of Re-Identification (re-ID) emerges
to enhance monitoring activities for these animals, utilising images captured
by camera traps. This project explores different CV approaches to create a
re-ID model able to identify individual feral cats in the wild. The main
approach consists of modifying a part-pose guided network (PPGNet) model,
initially used in the re-ID of Amur tigers, to be applicable for feral cats.
This adaptation, resulting in PPGNet-Cat, which incorporates specific
modifications to suit the characteristics of feral cats images. Additionally,
various experiments were conducted, particularly exploring contrastive learning
approaches such as ArcFace loss. The main results indicate that PPGNet-Cat
excels in identifying feral cats, achieving high performance with a mean
Average Precision (mAP) of 0.86 and a rank-1 accuracy of 0.95. These outcomes
establish PPGNet-Cat as a competitive model within the realm of re-ID.

</details>


### [8] [SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation](https://arxiv.org/abs/2507.11579)
*Sathvik Chereddy,John Femiani*

Main category: cs.CV

TL;DR: 提出SketchDNN，一种生成模型，用于CAD草图的合成，联合模型连续参数和离散类别标签，通过高斯Softmax扩散过程实现。


<details>
  <summary>Details</summary>
Motivation: 解决CAD草图中原语参数表示的异质性和原语排列的不变性问题。

Method: 采用高斯Softmax扩散，将加高斯噪声的logits通过Softmax变换投影到概率单纯形上，从而实现离散变量混合标签。

Result: 在SketchGraphs数据集上，生成质量显著提高，FID从16.04降至7.80，NLL从84.8降至81.33，达到新一代SOTA水平。

Conclusion: SketchDNN通过统一处理连续和离散变量的扩散过程，改进了CAD草图生成质量。

Abstract: We present SketchDNN, a generative model for synthesizing CAD sketches that
jointly models both continuous parameters and discrete class labels through a
unified continuous-discrete diffusion process. Our core innovation is
Gaussian-Softmax diffusion, where logits perturbed with Gaussian noise are
projected onto the probability simplex via a softmax transformation,
facilitating blended class labels for discrete variables. This formulation
addresses 2 key challenges, namely, the heterogeneity of primitive
parameterizations and the permutation invariance of primitives in CAD sketches.
Our approach significantly improves generation quality, reducing Fr\'echet
Inception Distance (FID) from 16.04 to 7.80 and negative log-likelihood (NLL)
from 84.8 to 81.33, establishing a new state-of-the-art in CAD sketch
generation on the SketchGraphs dataset.

</details>


### [9] [Interpretable Prediction of Lymph Node Metastasis in Rectal Cancer MRI Using Variational Autoencoders](https://arxiv.org/abs/2507.11638)
*Benjamin Keel,Aaron Quyn,David Jayne,Maryam Mohsin,Samuel D. Relton*

Main category: cs.CV

TL;DR: 该研究提出一种基于变分自编码器（VAE）的模型，在MRI数据集上实现了对直肠癌淋巴结转移（LNM）的优异预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于传统放射学特征的模型在识别直肠癌淋巴结转移方面准确性有限，研究引入VAE以提取影像数据的潜在精细特征。

Method: 模型采用VAE作为特征编码器，利用其重构功能有效捕捉影像数据中的结构化特征模式，并结合MLP进行病理N分期预测。

Result: 提出的VAE-MLP模型在内部MRI数据集上的性能为AUC 0.86±0.05，灵敏度0.79±0.06，特异度0.85±0.05，达到当前最优结果。

Conclusion: 本研究展示了VAE在影像特征编码与解释性方面的潜力，为直肠癌淋巴结转移的精准诊断提供了新方法。

Abstract: Effective treatment for rectal cancer relies on accurate lymph node
metastasis (LNM) staging. However, radiological criteria based on lymph node
(LN) size, shape and texture morphology have limited diagnostic accuracy. In
this work, we investigate applying a Variational Autoencoder (VAE) as a feature
encoder model to replace the large pre-trained Convolutional Neural Network
(CNN) used in existing approaches. The motivation for using a VAE is that the
generative model aims to reconstruct the images, so it directly encodes visual
features and meaningful patterns across the data. This leads to a disentangled
and structured latent space which can be more interpretable than a CNN. Models
are deployed on an in-house MRI dataset with 168 patients who did not undergo
neo-adjuvant treatment. The post-operative pathological N stage was used as the
ground truth to evaluate model predictions. Our proposed model 'VAE-MLP'
achieved state-of-the-art performance on the MRI dataset, with cross-validated
metrics of AUC 0.86 +/- 0.05, Sensitivity 0.79 +/- 0.06, and Specificity 0.85
+/- 0.05. Code is available at:
https://github.com/benkeel/Lymph_Node_Classification_MIUA.

</details>


### [10] [Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment](https://arxiv.org/abs/2507.11642)
*Abhishek Jaiswal,Nisheeth Srivastava*

Main category: cs.CV

TL;DR: 该研究提出通过运动视频中的姿态来推断人类意图，尤其在板球运动中区分攻击性和防守性行为，并取得超过75% F1得分和80% AUC-ROC。


<details>
  <summary>Details</summary>
Motivation: 通过姿态推断心理状态具有重要意义，但由于人类数据的隐私问题，研究面临挑战，因此提出通过运动场景如板球积累多样化数据。

Method: 利用板球运动视频的动作分析，通过姿态信息推断球员的攻击性或防守意图，并结合弱监督学习验证结果。

Result: 模型在分类攻击性和防守性行为时取得了超过75%的F1得分和超过80%的AUC-ROC，表明即使数据中有噪声，姿态信息仍能有效传递意图。

Conclusion: 研究证明姿态分析可以为意图推断并应用于体育分析提供支持，同时可推广至其他领域的人类行为分析。

Abstract: Posture-based mental state inference has significant potential in diagnosing
fatigue, preventing injury, and enhancing performance across various domains.
Such tools must be research-validated with large datasets before being
translated into practice. Unfortunately, such vision diagnosis faces serious
challenges due to the sensitivity of human subject data. To address this, we
identify sports settings as a viable alternative for accumulating data from
human subjects experiencing diverse emotional states. We test our hypothesis in
the game of cricket and present a posture-based solution to identify human
intent from activity videos. Our method achieves over 75\% F1 score and over
80\% AUC-ROC in discriminating aggressive and defensive shot intent through
motion analysis. These findings indicate that posture leaks out strong signals
for intent inference, even with inherent noise in the data pipeline.
Furthermore, we utilize existing data statistics as weak supervision to
validate our findings, offering a potential solution for overcoming data
labelling limitations. This research contributes to generalizable techniques
for sports analytics and also opens possibilities for applying human behavior
analysis across various fields.

</details>


### [11] [VISTA: Monocular Segmentation-Based Mapping for Appearance and View-Invariant Global Localization](https://arxiv.org/abs/2507.11653)
*Hannah Shafferman,Annika Thomas,Jouko Kinnari,Michael Ricard,Jose Nino,Jonathan How*

Main category: cs.CV

TL;DR: 该论文提出一种名为VISTA的单目全局定位框架，用于在多样化视角和季节变化下保持一致定位。


<details>
  <summary>Details</summary>
Motivation: 解决自主导航中因参考帧差异和环境变化导致的定位挑战，特别在无预先知识的不规则环境中。

Method: 研发了VISTA框架，包括前端基于对象的分割与跟踪模块，以及基于几何一致性进行子地图对应搜索，以对齐车辆参考帧。

Result: VISTA在季节性和不同视角航拍数据集中相比基线方法提升了69%的召回率，同时地图大小更紧凑，仅为最节省内存基线的0.6%。

Conclusion: 该方法无需特定领域训练或微调，可支持资源受限平台的实时实施，为不规则环境提供了一种高效的定位解决方案。

Abstract: Global localization is critical for autonomous navigation, particularly in
scenarios where an agent must localize within a map generated in a different
session or by another agent, as agents often have no prior knowledge about the
correlation between reference frames. However, this task remains challenging in
unstructured environments due to appearance changes induced by viewpoint
variation, seasonal changes, spatial aliasing, and occlusions -- known failure
modes for traditional place recognition methods. To address these challenges,
we propose VISTA (View-Invariant Segmentation-Based Tracking for Frame
Alignment), a novel open-set, monocular global localization framework that
combines: 1) a front-end, object-based, segmentation and tracking pipeline,
followed by 2) a submap correspondence search, which exploits geometric
consistencies between environment maps to align vehicle reference frames. VISTA
enables consistent localization across diverse camera viewpoints and seasonal
changes, without requiring any domain-specific training or finetuning. We
evaluate VISTA on seasonal and oblique-angle aerial datasets, achieving up to a
69% improvement in recall over baseline methods. Furthermore, we maintain a
compact object-based map that is only 0.6% the size of the most
memory-conservative baseline, making our approach capable of real-time
implementation on resource-constrained platforms.

</details>


### [12] [Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis](https://arxiv.org/abs/2507.11730)
*Maciej Szankin,Vidhyananth Venkatasamy,Lihang Ying*

Main category: cs.CV

TL;DR: 研究评估了多模态视觉语言模型(VLMs)与传统OCR方法在户外广告文本识别中的表现，包括在复杂场景和天气噪声下的表现对比。


<details>
  <summary>Details</summary>
Motivation: 解决传统OCR管道在复杂户外场景中识别性能下降的问题，引入多模态VLMs进行对比和验证。

Method: 比较多个VLMs模型（例如Qwen 2.5 VL 3B）与基于CNN的OCR方法（PaddleOCRv4），在ICDAR 2015和SVT数据集上进行测试，并加入合成天气噪声以模拟真实场景。

Result: VLMs在整体场景推理上表现优秀，而轻量级CNN管道在裁剪文本识别方面仍能以较低计算成本取得竞争性精度。

Conclusion: 尽管VLMs在复杂场景下显示出优势，但轻量化传统OCR在特定应用场景下仍具有较高潜力，该研究公开了天气增强基准和评估代码以促进未来研究。

Abstract: Outdoor advertisements remain a critical medium for modern marketing, yet
accurately verifying billboard text visibility under real-world conditions is
still challenging. Traditional Optical Character Recognition (OCR) pipelines
excel at cropped text recognition but often struggle with complex outdoor
scenes, varying fonts, and weather-induced visual noise. Recently, multimodal
Vision-Language Models (VLMs) have emerged as promising alternatives, offering
end-to-end scene understanding with no explicit detection step. This work
systematically benchmarks representative VLMs - including Qwen 2.5 VL 3B,
InternVL3, and SmolVLM2 - against a compact CNN-based OCR baseline
(PaddleOCRv4) across two public datasets (ICDAR 2015 and SVT), augmented with
synthetic weather distortions to simulate realistic degradation. Our results
reveal that while selected VLMs excel at holistic scene reasoning, lightweight
CNN pipelines still achieve competitive accuracy for cropped text at a fraction
of the computational cost-an important consideration for edge deployment. To
foster future research, we release our weather-augmented benchmark and
evaluation code publicly.

</details>


### [13] [Beyond Task-Specific Reasoning: A Unified Conditional Generative Framework for Abstract Visual Reasoning](https://arxiv.org/abs/2507.11761)
*Fan Shi,Bin Li,Xiangyang Xue*

Main category: cs.CV

TL;DR: 该论文提出了一种统一条件生成解算器 (UCGS)，用以解决多个抽象视觉推理 (AVR) 任务，并展示了其跨多任务泛化和零样本推理的能力。


<details>
  <summary>Details</summary>
Motivation: 针对当前深度AVR求解器通常需要基于任务的特定设计或重新训练的问题，研究者希望开发一种能够统一解决多种AVR任务的框架，以降低成本并增强模型泛化能力。

Method: 提出一种统一条件生成解算器 (UCGS)，通过将部分知名AVR任务重新定义为目标图片在面板中可预测性的估计问题，并训练一个条件生成模型来在统一框架中解决多个AVR任务。

Result: 实验表明，UCGS可以通过一次多任务训练展示其在多个AVR任务上的抽象推理能力，并在测试阶段对未见的任务表现出零样本推理能力。

Conclusion: 与基于任务的特定方法相比，UCGS展示了跨任务统一建模的潜力，为实现高效和通用AVR解算提供了新的思路。

Abstract: Abstract visual reasoning (AVR) enables humans to quickly discover and
generalize abstract rules to new scenarios. Designing intelligent systems with
human-like AVR abilities has been a long-standing topic in the artificial
intelligence community. Deep AVR solvers have recently achieved remarkable
success in various AVR tasks. However, they usually use task-specific designs
or parameters in different tasks. In such a paradigm, solving new tasks often
means retraining the model, and sometimes retuning the model architectures,
which increases the cost of solving AVR problems. In contrast to task-specific
approaches, this paper proposes a novel Unified Conditional Generative Solver
(UCGS), aiming to address multiple AVR tasks in a unified framework. First, we
prove that some well-known AVR tasks can be reformulated as the problem of
estimating the predictability of target images in problem panels. Then, we
illustrate that, under the proposed framework, training one conditional
generative model can solve various AVR tasks. The experiments show that with a
single round of multi-task training, UCGS demonstrates abstract reasoning
ability across various AVR tasks. Especially, UCGS exhibits the ability of
zero-shot reasoning, enabling it to perform abstract reasoning on problems from
unseen AVR tasks in the testing phase.

</details>


### [14] [CorrMoE: Mixture of Experts with De-stylization Learning for Cross-Scene and Cross-Domain Correspondence Pruning](https://arxiv.org/abs/2507.11834)
*Peiwen Xia,Tangfei Liao,Wei Zhu,Danhuai Zhao,Jianjun Ke,Kaihao Zhang,Tong Lu,Tao Wang*

Main category: cs.CV

TL;DR: 作者提出一种新方法（CorrMoE）以增强图像配对中对应关系筛选的可靠性，尤其是应对跨领域和场景多样性的影响。


<details>
  <summary>Details</summary>
Motivation: 当前的配对筛选方法在处理具有显著差异的场景和领域时表现有限，需要一种更加鲁棒的方法来应对图像对的多样性和域转移问题。

Method: 作者提出了一个名为CorrMoE的框架，包括去风格化双分支模块，用于减轻域特定表示的影响，以及一种Bi-Fusion专家混合模块，用于适应性地融合多视角特征。

Result: CorrMoE在多个基准数据集上表现出更高的准确性和广泛适应性。

Conclusion: CorrMoE方法不仅提升了承担跨域和跨场景任务的能力，还在多个数据集上取得了超越现有技术的优异表现。

Abstract: Establishing reliable correspondences between image pairs is a fundamental
task in computer vision, underpinning applications such as 3D reconstruction
and visual localization. Although recent methods have made progress in pruning
outliers from dense correspondence sets, they often hypothesize consistent
visual domains and overlook the challenges posed by diverse scene structures.
In this paper, we propose CorrMoE, a novel correspondence pruning framework
that enhances robustness under cross-domain and cross-scene variations. To
address domain shift, we introduce a De-stylization Dual Branch, performing
style mixing on both implicit and explicit graph features to mitigate the
adverse influence of domain-specific representations. For scene diversity, we
design a Bi-Fusion Mixture of Experts module that adaptively integrates
multi-perspective features through linear-complexity attention and dynamic
expert routing. Extensive experiments on benchmark datasets demonstrate that
CorrMoE achieves superior accuracy and generalization compared to
state-of-the-art methods. The code and pre-trained models are available at
https://github.com/peiwenxia/CorrMoE.

</details>


### [15] [ProtoConNet: Prototypical Augmentation and Alignment for Open-Set Few-Shot Image Classification](https://arxiv.org/abs/2507.11845)
*Kexuan Shi,Zhuang Qi,Jingjing Zhu,Lei Meng,Yaochen Zhang,Haibei Huang,Xiangxu Meng*

Main category: cs.CV

TL;DR: 这篇论文研究了开放集少样本图像分类问题，通过一种新方法增强模型在未知环境中的泛化能力，提出了ProtoConNet方法，显著提升特征学习效果和开放集中样本识别能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法忽视丰富上下文信息的问题，从而提高少样本分类场景的模型泛化能力。

Method: 提出了一种名为ProtoConNet的方法，由三个主要模块组成：1.基于聚类的数据选择（CDS）模块，用于挖掘多样数据模式并保留核心特征；2.上下文增强的语义优化（CSR）模块，构建上下文字典并融入图像表示；3.原型对齐（PA）模块，缩小图像表示与类别原型之间的差距，同时扩大已知与未知类的特征间距。

Result: 实验结果表明，提出的ProtoConNet方法在两个数据集上效果显著，增强了少样本场景中的表示学习能力，并更好地识别开放集样本。

Conclusion: ProtoConNet方法通过整合丰富的上下文信息，克服了现有方法的不足，大幅提升了开放集少样本分类的表现，展示了较强的优势。

Abstract: Open-set few-shot image classification aims to train models using a small
amount of labeled data, enabling them to achieve good generalization when
confronted with unknown environments. Existing methods mainly use visual
information from a single image to learn class representations to distinguish
known from unknown categories. However, these methods often overlook the
benefits of integrating rich contextual information. To address this issue,
this paper proposes a prototypical augmentation and alignment method, termed
ProtoConNet, which incorporates background information from different samples
to enhance the diversity of the feature space, breaking the spurious
associations between context and image subjects in few-shot scenarios.
Specifically, it consists of three main modules: the clustering-based data
selection (CDS) module mines diverse data patterns while preserving core
features; the contextual-enhanced semantic refinement (CSR) module builds a
context dictionary to integrate into image representations, which boosts the
model's robustness in various scenarios; and the prototypical alignment (PA)
module reduces the gap between image representations and class prototypes,
amplifying feature distances for known and unknown classes. Experimental
results from two datasets verified that ProtoConNet enhances the effectiveness
of representation learning in few-shot scenarios and identifies open-set
samples, making it superior to existing methods.

</details>


### [16] [From Coarse to Nuanced: Cross-Modal Alignment of Fine-Grained Linguistic Cues and Visual Salient Regions for Dynamic Emotion Recognition](https://arxiv.org/abs/2507.11892)
*Yu Liu,Leyuan Qu,Hanlei Shi,Di Gao,Yuhua Zheng,Taihao Li*

Main category: cs.CV

TL;DR: 本研究提出了一种用于动态面部表情识别（DFER）的方法，名为GRACE，通过多模态对齐和细粒度动态建模，显著提高了识别性能并取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 当前研究中，现有方法未能充分利用生成文本中的细微情感线索，也未能有效过滤与情感表达无关的面部动态。

Method: 提出GRACE方法，包括动态运动建模、情感文本增强（CATE模块）和基于熵正则化的最优传输的跨模态对齐，同时引入运动差分加权机制以突显表情相关的运动特征。

Result: 在三个基准数据集上的实验表明，GRACE在应对情感类别模糊或不平衡的情况下，显著提高了识别性能并取得了新的SOTA结果。

Conclusion: 该研究通过整合语义文本优化与视觉动态信息，有效提升了动态面部表情识别的准确性，展示了其在情感计算中的潜力。

Abstract: Dynamic Facial Expression Recognition (DFER) aims to identify human emotions
from temporally evolving facial movements and plays a critical role in
affective computing. While recent vision-language approaches have introduced
semantic textual descriptions to guide expression recognition, existing methods
still face two key limitations: they often underutilize the subtle emotional
cues embedded in generated text, and they have yet to incorporate sufficiently
effective mechanisms for filtering out facial dynamics that are irrelevant to
emotional expression. To address these gaps, We propose GRACE, Granular
Representation Alignment for Cross-modal Emotion recognition that integrates
dynamic motion modeling, semantic text refinement, and token-level cross-modal
alignment to facilitate the precise localization of emotionally salient
spatiotemporal features. Our method constructs emotion-aware textual
descriptions via a Coarse-to-fine Affective Text Enhancement (CATE) module and
highlights expression-relevant facial motion through a motion-difference
weighting mechanism. These refined semantic and visual signals are aligned at
the token level using entropy-regularized optimal transport. Experiments on
three benchmark datasets demonstrate that our method significantly improves
recognition performance, particularly in challenging settings with ambiguous or
imbalanced emotion classes, establishing new state-of-the-art (SOTA) results in
terms of both UAR and WAR.

</details>


### [17] [Spatial Frequency Modulation for Semantic Segmentation](https://arxiv.org/abs/2507.11893)
*Linwei Chen,Ying Fu,Lin Gu,Dezhi Zheng,Jifeng Dai*

Main category: cs.CV

TL;DR: 提出了空间频率调制(SFM)技术，通过对高频信息进行调整和还原，有效缓解下采样中的混叠问题，并提升图像分割和其他任务的性能。


<details>
  <summary>Details</summary>
Motivation: 高频信息对于语义分割至关重要，但在经典下采样操作中容易因混叠造成失真，影响精度。

Method: 通过自适应重采样(ARS)调制高频特征至低频，在上采样过程中通过多尺度自适应上采样(MSAU)还原高频信息；该方法可嵌入到多种网络架构中。

Result: 特征可视化和分析表明该方法在缓解混叠的同时还能成功还原细节，并在多种任务（包括图像分类、实例分割等）中验证其广泛适用性和有效性。

Conclusion: SFM是一种能够有效保留高频信息并提升模型表现的通用方法，适用于多种计算机视觉任务。

Abstract: High spatial frequency information, including fine details like textures,
significantly contributes to the accuracy of semantic segmentation. However,
according to the Nyquist-Shannon Sampling Theorem, high-frequency components
are vulnerable to aliasing or distortion when propagating through downsampling
layers such as strided-convolution. Here, we propose a novel Spatial Frequency
Modulation (SFM) that modulates high-frequency features to a lower frequency
before downsampling and then demodulates them back during upsampling.
Specifically, we implement modulation through adaptive resampling (ARS) and
design a lightweight add-on that can densely sample the high-frequency areas to
scale up the signal, thereby lowering its frequency in accordance with the
Frequency Scaling Property. We also propose Multi-Scale Adaptive Upsampling
(MSAU) to demodulate the modulated feature and recover high-frequency
information through non-uniform upsampling This module further improves
segmentation by explicitly exploiting information interaction between densely
and sparsely resampled areas at multiple scales. Both modules can seamlessly
integrate with various architectures, extending from convolutional neural
networks to transformers. Feature visualization and analysis confirm that our
method effectively alleviates aliasing while successfully retaining details
after demodulation. Finally, we validate the broad applicability and
effectiveness of SFM by extending it to image classification, adversarial
robustness, instance segmentation, and panoptic segmentation tasks. The code is
available at
\href{https://github.com/Linwei-Chen/SFM}{https://github.com/Linwei-Chen/SFM}.

</details>


### [18] [SEPose: A Synthetic Event-based Human Pose Estimation Dataset for Pedestrian Monitoring](https://arxiv.org/abs/2507.11910)
*Kaustav Chanda,Aayush Atul Verma,Arpitsinh Vaghela,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: 本文提出了一个名为SEPose的合成事件驱动的人体姿势估计数据集，旨在弥补事件传感器领域数据的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的行人和交通监控系统在低延迟与宽动态范围条件下仍然缺乏足够的数据覆盖，尤其对于分散注意力的行走或异常行为的场景。

Method: 利用动态视觉传感器和CARLA模拟器，生成包含约35万名带有人体姿势关键点标注的行人数据集，覆盖不同人群密度、交通流量及多种光照与天气条件下的城市、郊区与农村环境。

Result: 通过训练和评估现有先进模型（如RVT和YOLOv8），验证该数据集在真实事件数据上的模拟到实际推广能力。

Conclusion: SEPose为事件驱动的多人人体姿势估计提供了一个全面的合成数据来源，填补了该领域的空白。

Abstract: Event-based sensors have emerged as a promising solution for addressing
challenging conditions in pedestrian and traffic monitoring systems. Their
low-latency and high dynamic range allow for improved response time in
safety-critical situations caused by distracted walking or other unusual
movements. However, the availability of data covering such scenarios remains
limited. To address this gap, we present SEPose -- a comprehensive synthetic
event-based human pose estimation dataset for fixed pedestrian perception
generated using dynamic vision sensors in the CARLA simulator. With nearly 350K
annotated pedestrians with body pose keypoints from the perspective of fixed
traffic cameras, SEPose is a comprehensive synthetic multi-person pose
estimation dataset that spans busy and light crowds and traffic across diverse
lighting and weather conditions in 4-way intersections in urban, suburban, and
rural environments. We train existing state-of-the-art models such as RVT and
YOLOv8 on our dataset and evaluate them on real event-based data to demonstrate
the sim-to-real generalization capabilities of the proposed dataset.

</details>


### [19] [Dark-EvGS: Event Camera as an Eye for Radiance Field in the Dark](https://arxiv.org/abs/2507.11931)
*Jingqian Wu,Peiqi Duan,Zongqiang Wang,Changwei Wang,Boxin Shi,Edmund Y. Lam*

Main category: cs.CV

TL;DR: 提出了一种名为Dark-EvGS的框架，以在低光环境下通过事件相机和3D Gaussian Splatting技术重建任意视角的亮帧，克服了传统方法在低光条件下的不足。


<details>
  <summary>Details</summary>
Motivation: 传统相机在低光环境下捕捉清晰图像面临动态范围受限和运动模糊问题，事件相机具备高动态范围和高速特性，能够缓解这些问题。研究旨在改善低光条件下的3D辐射场重建和亮帧合成。

Method: 提出Dark-EvGS框架，结合事件相机和3D Gaussian Splatting技术，采用三重监督学习以捕获全局与细节信息，并添加色调匹配模块以确保生成帧的色彩一致性。此外，构建了一套首个真实场景的数据集用于事件引导亮帧合成任务。

Result: 实验表明，新方法在低光环境下实现了优于现有方法的辐射场重建表现，解决了低光条件下的成像挑战。

Conclusion: Dark-EvGS框架通过创新的设计和方法，成功提升了低光条件下亮帧合成和任意视角图像重建效果，提供了一个实际验证且更优的解决方案。

Abstract: In low-light environments, conventional cameras often struggle to capture
clear multi-view images of objects due to dynamic range limitations and motion
blur caused by long exposure. Event cameras, with their high-dynamic range and
high-speed properties, have the potential to mitigate these issues.
Additionally, 3D Gaussian Splatting (GS) enables radiance field reconstruction,
facilitating bright frame synthesis from multiple viewpoints in low-light
conditions. However, naively using an event-assisted 3D GS approach still faced
challenges because, in low light, events are noisy, frames lack quality, and
the color tone may be inconsistent. To address these issues, we propose
Dark-EvGS, the first event-assisted 3D GS framework that enables the
reconstruction of bright frames from arbitrary viewpoints along the camera
trajectory. Triplet-level supervision is proposed to gain holistic knowledge,
granular details, and sharp scene rendering. The color tone matching block is
proposed to guarantee the color consistency of the rendered frames.
Furthermore, we introduce the first real-captured dataset for the event-guided
bright frame synthesis task via 3D GS-based radiance field reconstruction.
Experiments demonstrate that our method achieves better results than existing
methods, conquering radiance field reconstruction under challenging low-light
conditions. The code and sample data are included in the supplementary
material.

</details>


### [20] [Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs](https://arxiv.org/abs/2507.11932)
*Mohammad Shahab Sepehri,Berk Tinaz,Zalan Fabian,Mahdi Soltanolkotabi*

Main category: cs.CV

TL;DR: 本文讨论了当前多模态大语言模型（MLLMs）在心理视觉化能力方面的不足，并提出了新的基准Hyperphantasia来评估这种能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型评测主要集中于被动视觉感知，缺乏对主动构建视觉模式能力的评估，而这种心理视觉化能力在人类认知中尤为重要。

Method: 提出一个名为Hyperphantasia的合成基准，通过四种程序生成的谜题对MLLMs的心理视觉化能力进行评估，并设置了三个难度级别以研究模型在复杂性增加时的表现。

Result: 评估结果显示，当前MLLMs的表现与人类在心理视觉化能力上存在显著差距，但某些模型表现出部分能力。同时，还探讨了利用强化学习改进视觉模拟能力的可能性。

Conclusion: 心理视觉化能力仍是当前MLLMs的一个未解挑战，需进一步研究以填补性能差距。

Abstract: Mental visualization, the ability to construct and manipulate visual
representations internally, is a core component of human cognition and plays a
vital role in tasks involving reasoning, prediction, and abstraction. Despite
the rapid progress of Multimodal Large Language Models (MLLMs), current
benchmarks primarily assess passive visual perception, offering limited insight
into the more active capability of internally constructing visual patterns to
support problem solving. Yet mental visualization is a critical cognitive skill
in humans, supporting abilities such as spatial navigation, predicting physical
trajectories, and solving complex visual problems through imaginative
simulation. To bridge this gap, we introduce Hyperphantasia, a synthetic
benchmark designed to evaluate the mental visualization abilities of MLLMs
through four carefully constructed puzzles. Each task is procedurally generated
and presented at three difficulty levels, enabling controlled analysis of model
performance across increasing complexity. Our comprehensive evaluation of
state-of-the-art models reveals a substantial gap between the performance of
humans and MLLMs. Additionally, we explore the potential of reinforcement
learning to improve visual simulation capabilities. Our findings suggest that
while some models exhibit partial competence in recognizing visual patterns,
robust mental visualization remains an open challenge for current MLLMs.

</details>


### [21] [RaDL: Relation-aware Disentangled Learning for Multi-Instance Text-to-Image Generation](https://arxiv.org/abs/2507.11947)
*Geon Park,Seon Bin Kim,Gunho Jung,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 介绍了RaDL框架，可以在文本生成图像时更好地处理图像中多实例的关系与属性问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本生成图像方法存在多实例关系不准确及属性泄露的问题。

Method: 提出名为Relation-Aware Disentangled Learning (RaDL)的框架，通过学习参数增强实例属性，并结合Relation Attention和动作动词信息生成关系感知的图像特征。

Result: 在COCO-Position, COCO-MIG与DrawBench评价中，RaDL在位置准确性、多属性考虑和实例关系方面优于现有方法。

Conclusion: RaDL框架能够在多实例场景下生成更准确反映实例关系和属性的图像，为该领域提供了有效解决方案。

Abstract: With recent advancements in text-to-image (T2I) models, effectively
generating multiple instances within a single image prompt has become a crucial
challenge. Existing methods, while successful in generating positions of
individual instances, often struggle to account for relationship discrepancy
and multiple attributes leakage. To address these limitations, this paper
proposes the relation-aware disentangled learning (RaDL) framework. RaDL
enhances instance-specific attributes through learnable parameters and
generates relation-aware image features via Relation Attention, utilizing
action verbs extracted from the global prompt. Through extensive evaluations on
benchmarks such as COCO-Position, COCO-MIG, and DrawBench, we demonstrate that
RaDL outperforms existing methods, showing significant improvements in
positional accuracy, multiple attributes consideration, and the relationships
between instances. Our results present RaDL as the solution for generating
images that consider both the relationships and multiple attributes of each
instance within the multi-instance image.

</details>


### [22] [Prototypical Progressive Alignment and Reweighting for Generalizable Semantic Segmentation](https://arxiv.org/abs/2507.11955)
*Yuhang Zhang,Zhengyu Zhang,Muxin Liao,Shishun Tian,Wenbin Zou,Lu Zhang,Chen Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为PPAR的新框架，通过引入两种基于CLIP的原型并采用渐进对齐和重加权机制，解决了泛化语义分割领域中的三个主要挑战，从而实现了跨多个基准的最新性能。


<details>
  <summary>Details</summary>
Motivation: 鉴于现实应用对高泛化性的需求，如何在未见域中实现稳健的语义分割成为一个重要挑战；为此，研究动机是克服现有方法在原型对齐策略粗糙、原型构建方法容易过拟合以及忽视样本间差异性所带来的局限性。

Method: 方法上，该论文设计了PPAR框架，引入了两种基于CLIP模型的原型（原始文本原型OTP和视觉文本原型VTP），并通过渐进对齐策略逐步降低域间差距，同时采用重加权机制评估数据的可靠性以削弱负转移效应。此外，理论分析揭示了该方法与领域泛化理论的一致性。

Result: 实验表明，PPAR在多个基准数据集上达到了最新的性能，验证了其实用性和有效性。

Conclusion: 本文的结论是，通过结合CLIP原型、渐进对齐和重加权的PPAR框架，可以有效提高语义分割模型在未见域中的泛化能力，解决了一些关键局限性问题。

Abstract: Generalizable semantic segmentation aims to perform well on unseen target
domains, a critical challenge due to real-world applications requiring high
generalizability. Class-wise prototypes, representing class centroids, serve as
domain-invariant cues that benefit generalization due to their stability and
semantic consistency. However, this approach faces three challenges. First,
existing methods often adopt coarse prototypical alignment strategies, which
may hinder performance. Second, naive prototypes computed by averaging source
batch features are prone to overfitting and may be negatively affected by
unrelated source data. Third, most methods treat all source samples equally,
ignoring the fact that different features have varying adaptation difficulties.
To address these limitations, we propose a novel framework for generalizable
semantic segmentation: Prototypical Progressive Alignment and Reweighting
(PPAR), leveraging the strong generalization ability of the CLIP model.
Specifically, we define two prototypes: the Original Text Prototype (OTP) and
Visual Text Prototype (VTP), generated via CLIP to serve as a solid base for
alignment. We then introduce a progressive alignment strategy that aligns
features in an easy-to-difficult manner, reducing domain gaps gradually.
Furthermore, we propose a prototypical reweighting mechanism that estimates the
reliability of source data and adjusts its contribution, mitigating the effect
of irrelevant or harmful features (i.e., reducing negative transfer). We also
provide a theoretical analysis showing the alignment between our method and
domain generalization theory. Extensive experiments across multiple benchmarks
demonstrate that PPAR achieves state-of-the-art performance, validating its
effectiveness.

</details>


### [23] [Language-Guided Contrastive Audio-Visual Masked Autoencoder with Automatically Generated Audio-Visual-Text Triplets from Videos](https://arxiv.org/abs/2507.11967)
*Yuchi Ishikawa,Shota Nakada,Hokuto Munakata,Kazuhiro Saito,Tatsuya Komatsu,Yoshimitsu Aoki*

Main category: cs.CV

TL;DR: 本文提出了LG-CAV-MAE方法，通过结合多模态的对比学习和遮掩自编码器，显著提升了音视频表示的学习效果。


<details>
  <summary>Details</summary>
Motivation: 当前音视频表示学习缺乏对文本的有效利用，为进一步提升多模态表示学习性能，需要引入文本信息并结合无监督的方法生成多模态数据对。

Method: 将预训练文本编码器集成到音视频对比遮掩自编码器中，并通过自动化方法生成音视频文本三元组数据，利用CLAP筛选保证音频与文本的高度相关性。

Result: 在音视频检索及分类任务中，LG-CAV-MAE方法显著优于现有方法，在检索任务的Recall@10上提升5.6%，分类任务上提升3.2%。

Conclusion: LG-CAV-MAE在无需人工标注的情况下，成功利用文本信息来增强音视频表示学习，为多模态学习提供了新的思路。

Abstract: In this paper, we propose Language-Guided Contrastive Audio-Visual Masked
Autoencoders (LG-CAV-MAE) to improve audio-visual representation learning.
LG-CAV-MAE integrates a pretrained text encoder into contrastive audio-visual
masked autoencoders, enabling the model to learn across audio, visual and text
modalities. To train LG-CAV-MAE, we introduce an automatic method to generate
audio-visual-text triplets from unlabeled videos. We first generate frame-level
captions using an image captioning model and then apply CLAP-based filtering to
ensure strong alignment between audio and captions. This approach yields
high-quality audio-visual-text triplets without requiring manual annotations.
We evaluate LG-CAV-MAE on audio-visual retrieval tasks, as well as an
audio-visual classification task. Our method significantly outperforms existing
approaches, achieving up to a 5.6% improvement in recall@10 for retrieval tasks
and a 3.2% improvement for the classification task.

</details>


### [24] [Watch, Listen, Understand, Mislead: Tri-modal Adversarial Attacks on Short Videos for Content Appropriateness Evaluation](https://arxiv.org/abs/2507.11968)
*Sahid Hossain Mustakim,S M Jishanul Islam,Ummay Maria Muna,Montasir Chowdhury,Mohammed Jawwadul Islam,Sadia Ahmmed,Tashfia Sikder,Syed Tasdid Azam Dhrubo,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: 本文研究了多模态大语言模型（MLLMs）在短视频内容审核中的安全性。提出了一个综合评估框架，包括新数据集SVMA和新的三模态攻击策略ChimeraBreak，揭示了现有模型的显著漏洞。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大模型主要用于内容审核，但其在短视频场景下的鲁棒性和安全性研究不足，单模态评估方法无法充分检测联合攻击漏洞。

Method: 提出了一个综合性框架，包括一个由人类引导生成的短视频多模态对抗数据集（SVMA）和新型的三模态攻击策略（ChimeraBreak），用于同时测试视觉、听觉和语义推理能力。

Result: 通过广泛实验发现，当前先进的MLLMs对新提出的攻击策略有较高的攻击成功率（ASR），暴露了模型在内容误分类和法政策内容识别中的偏差。

Conclusion: 研究揭示了多模态大模型的安全性缺陷，并为开发更鲁棒和安全的MLLMs提供了重要参考。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly used for content
moderation, yet their robustness in short-form video contexts remains
underexplored. Current safety evaluations often rely on unimodal attacks,
failing to address combined attack vulnerabilities. In this paper, we introduce
a comprehensive framework for evaluating the tri-modal safety of MLLMs. First,
we present the Short-Video Multimodal Adversarial (SVMA) dataset, comprising
diverse short-form videos with human-guided synthetic adversarial attacks.
Second, we propose ChimeraBreak, a novel tri-modal attack strategy that
simultaneously challenges visual, auditory, and semantic reasoning pathways.
Extensive experiments on state-of-the-art MLLMs reveal significant
vulnerabilities with high Attack Success Rates (ASR). Our findings uncover
distinct failure modes, showing model biases toward misclassifying benign or
policy-violating content. We assess results using LLM-as-a-judge, demonstrating
attack reasoning efficacy. Our dataset and findings provide crucial insights
for developing more robust and safe MLLMs.

</details>


### [25] [GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2507.11969)
*Zhaohong Huang,Yuxin Zhang,Jingjing Xie,Fei Chao,Rongrong Ji*

Main category: cs.CV

TL;DR: 本文提出了Global-Spatial Bias Learner (GS-Bias)，作为一种高效且性能优越的测试时适配（TTA）方法，提升了视觉语言模型（VLMs）的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于多视图增强提高VLM泛化性能的方法，要么需要调整文本提示的高成本开销，要么是手动视觉特征增强带来的不稳定性能提升，亟需一种在性能和效率之间取得平衡的解决方案。

Method: GS-Bias引入了两种在TTA过程中可学习的偏置：全局偏置用于增强测试图像的全局语义特征一致性，空间偏置则学习图像空间视觉表示中区域之间的语义关联性。这些偏置直接加到预训练VLM的logits上，无需全梯度回传，从而显著提升效率。

Result: 在15个基准数据集上，GS-Bias取得了领先的性能：在跨数据集泛化提升2.23%，在领域泛化提升2.72%，同时对比TPT在ImageNet上仅需6.5%的内存使用。

Conclusion: GS-Bias以高效的方式实现了卓越的TTA性能，显著提升了VLM的零样本泛化能力，为平衡效率与效果提供了有力的解决方法。

Abstract: Recent advances in test-time adaptation (TTA) for Vision-Language Models
(VLMs) have garnered increasing attention, particularly through the use of
multiple augmented views of a single image to boost zero-shot generalization.
Unfortunately, existing methods fail to strike a satisfactory balance between
performance and efficiency, either due to excessive overhead of tuning text
prompts or unstable benefits from handcrafted, training-free visual feature
enhancement. In this paper, we present Global-Spatial Bias Learner (GS-Bias),
an efficient and effective TTA paradigm that incorporates two learnable biases
during TTA, unfolded as the global bias and spatial bias. Particularly, the
global bias captures the global semantic features of a test image by learning
consistency across augmented views, while spatial bias learns the semantic
coherence between regions in the image's spatial visual representation. It is
worth highlighting that these two sets of biases are directly added to the
logits outputed by the pretrained VLMs, which circumvent the full
backpropagation through VLM that hinders the efficiency of existing TTA
methods. This endows GS-Bias with extremely high efficiency while achieving
state-of-the-art performance on 15 benchmark datasets. For example, it achieves
a 2.23% improvement over TPT in cross-dataset generalization and a 2.72%
improvement in domain generalization, while requiring only 6.5% of TPT's memory
usage on ImageNet.

</details>


### [26] [EC-Diff: Fast and High-Quality Edge-Cloud Collaborative Inference for Diffusion Models](https://arxiv.org/abs/2507.11980)
*Jiajian Xie,Shengyu Zhang,Zhou Zhao,Fan Wu,Fei Wu*

Main category: cs.CV

TL;DR: 本文提出了一种名为EC-Diff的方法加速云端推理、优化边缘设备生成输出，显著提高生成质量并加快推理速度。


<details>
  <summary>Details</summary>
Motivation: 在边缘-云协同框架中，推理时间过长以及语义不一致性是影响用户体验的主要问题。

Method: 设计了K步噪声近似策略用以降低云推理频率，并通过两阶段贪心搜索算法找到噪声近似和边缘模型切换的最优参数。

Result: 大规模实验表明，该方法在保持生成质量的同时，相较于云端推理实现了平均2倍推理加速。

Conclusion: EC-Diff提供了一种高效的边缘-云协同生成方法，成功在生成质量与推理速度间达到了平衡。

Abstract: Diffusion Models have shown remarkable proficiency in image and video
synthesis. As model size and latency increase limit user experience, hybrid
edge-cloud collaborative framework was recently proposed to realize fast
inference and high-quality generation, where the cloud model initiates
high-quality semantic planning and the edge model expedites later-stage
refinement. However, excessive cloud denoising prolongs inference time, while
insufficient steps cause semantic ambiguity, leading to inconsistency in edge
model output. To address these challenges, we propose EC-Diff that accelerates
cloud inference through gradient-based noise estimation while identifying the
optimal point for cloud-edge handoff to maintain generation quality.
Specifically, we design a K-step noise approximation strategy to reduce cloud
inference frequency by using noise gradients between steps and applying cloud
inference periodically to adjust errors. Then we design a two-stage greedy
search algorithm to efficiently find the optimal parameters for noise
approximation and edge model switching. Extensive experiments demonstrate that
our method significantly enhances generation quality compared to edge
inference, while achieving up to an average $2\times$ speedup in inference
compared to cloud inference. Video samples and source code are available at
https://ec-diff.github.io/.

</details>


### [27] [Unsupervised Part Discovery via Descriptor-Based Masked Image Restoration with Optimized Constraints](https://arxiv.org/abs/2507.11985)
*Jiahao Xia,Yike Wu,Wenjian Huang,Jianguo Zhang,Jian Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的无监督部分发现方法，称为Masked Part Autoencoder (MPAE)，通过编码部分特征并通过遮挡恢复图像来发现复杂场景中的有意义部分。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督部分发现方法在处理跨类别和场景时可靠性不强，本文旨在解决这一限制并消除对精细标注的依赖。

Method: MPAE先从输入图像学习部分描述符和特征图，并对原图像进行遮挡生成patch特征。然后基于局部特征和描述符的相似性，用学习到的部分描述符填补遮挡区域，通过恢复遮挡的patch强化与部分形状的一致性。

Result: 实验表明，MPAE能够在多种类别和场景下鲁棒地发现有意义的部分，并明显提升应用能力。

Conclusion: MPAE无需精细标注即可在复杂场景中发现符合实际形状的部分特征，为处理遮挡和跨类别部分相似性提供了基础，具有更广泛的适用性。

Abstract: Part-level features are crucial for image understanding, but few studies
focus on them because of the lack of fine-grained labels. Although unsupervised
part discovery can eliminate the reliance on labels, most of them cannot
maintain robustness across various categories and scenarios, which restricts
their application range. To overcome this limitation, we present a more
effective paradigm for unsupervised part discovery, named Masked Part
Autoencoder (MPAE). It first learns part descriptors as well as a feature map
from the inputs and produces patch features from a masked version of the
original images. Then, the masked regions are filled with the learned part
descriptors based on the similarity between the local features and descriptors.
By restoring these masked patches using the part descriptors, they become
better aligned with their part shapes, guided by appearance features from
unmasked patches. Finally, MPAE robustly discovers meaningful parts that
closely match the actual object shapes, even in complex scenarios. Moreover,
several looser yet more effective constraints are proposed to enable MPAE to
identify the presence of parts across various scenarios and categories in an
unsupervised manner. This provides the foundation for addressing challenges
posed by occlusion and for exploring part similarity across multiple
categories. Extensive experiments demonstrate that our method robustly
discovers meaningful parts across various categories and scenarios. The code is
available at the project https://github.com/Jiahao-UTS/MPAE.

</details>


### [28] [Style Composition within Distinct LoRA modules for Traditional Art](https://arxiv.org/abs/2507.11986)
*Jaehyun Lee,Wonhark Park,Wonsik Shin,Hyunho Lee,Hyoung Min Na,Nojun Kwak*

Main category: cs.CV

TL;DR: 提出一种无须训练的扩散管道，实现通过风格专精模型自然混合多种艺术风格。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在控制多种绘画风格上表现出的风格交织和无法光滑插值的问题。

Method: 通过使用风格专精模型，在噪声较低的潜变量中通过空间掩码进行风格融合，并且引入深度地图条件以确保结构一致性。

Result: 实验表明该方法成功地通过掩码实现区域特定的风格混合。

Conclusion: 新方法既保留了单一风格的真实性，又可通过用户操作实现混合风格的自由控制。

Abstract: Diffusion-based text-to-image models have achieved remarkable results in
synthesizing diverse images from text prompts and can capture specific artistic
styles via style personalization. However, their entangled latent space and
lack of smooth interpolation make it difficult to apply distinct painting
techniques in a controlled, regional manner, often causing one style to
dominate. To overcome this, we propose a zero-shot diffusion pipeline that
naturally blends multiple styles by performing style composition on the
denoised latents predicted during the flow-matching denoising process of
separately trained, style-specialized models. We leverage the fact that
lower-noise latents carry stronger stylistic information and fuse them across
heterogeneous diffusion pipelines using spatial masks, enabling precise,
region-specific style control. This mechanism preserves the fidelity of each
individual style while allowing user-guided mixing. Furthermore, to ensure
structural coherence across different models, we incorporate depth-map
conditioning via ControlNet into the diffusion framework. Qualitative and
quantitative experiments demonstrate that our method successfully achieves
region-specific style mixing according to the given masks.

</details>


### [29] [ID-EA: Identity-driven Text Enhancement and Adaptation with Textual Inversion for Personalized Text-to-Image Generation](https://arxiv.org/abs/2507.11990)
*Hyun-Jun Jin,Young-Eun Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 提出了ID-EA框架，用于改进文本到图像生成模型中的身份一致性问题。


<details>
  <summary>Details</summary>
Motivation: 当前的文本反演方法在生成个性化头像时难以保持面部身份一致性。

Method: ID-EA框架包括两个关键组件：ID-Enhancer和ID-Adapter，分别通过整合身份嵌入和调整跨注意力模块实现文本视觉一致性对齐。

Result: ID-EA在身份一致性指标上显著优于现有方法，同时计算效率更高，生成速度快15倍。

Conclusion: ID-EA框架有效解决了个性化图像生成中的身份一致性问题，具备创新性和实际应用潜力。

Abstract: Recently, personalized portrait generation with a text-to-image diffusion
model has significantly advanced with Textual Inversion, emerging as a
promising approach for creating high-fidelity personalized images. Despite its
potential, current Textual Inversion methods struggle to maintain consistent
facial identity due to semantic misalignments between textual and visual
embedding spaces regarding identity. We introduce ID-EA, a novel framework that
guides text embeddings to align with visual identity embeddings, thereby
improving identity preservation in a personalized generation. ID-EA comprises
two key components: the ID-driven Enhancer (ID-Enhancer) and the ID-conditioned
Adapter (ID-Adapter). First, the ID-Enhancer integrates identity embeddings
with a textual ID anchor, refining visual identity embeddings derived from a
face recognition model using representative text embeddings. Then, the
ID-Adapter leverages the identity-enhanced embedding to adapt the text
condition, ensuring identity preservation by adjusting the cross-attention
module in the pre-trained UNet model. This process encourages the text features
to find the most related visual clues across the foreground snippets. Extensive
quantitative and qualitative evaluations demonstrate that ID-EA substantially
outperforms state-of-the-art methods in identity preservation metrics while
achieving remarkable computational efficiency, generating personalized
portraits approximately 15 times faster than existing approaches.

</details>


### [30] [SAMST: A Transformer framework based on SAM pseudo label filtering for remote sensing semi-supervised semantic segmentation](https://arxiv.org/abs/2507.11994)
*Jun Yin,Fei Wu,Yupeng Ren,Jisheng Huang,Qiankun Li,Heng jin,Jianhai Fu,Chanjie Cui*

Main category: cs.CV

TL;DR: 本文提出了SAMST，一种结合SAM模型的半监督遥感影像语义分割方法，通过改进伪标签提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 应对公共遥感数据集在分辨率差异和地物类别定义不一致方面的局限性，利用大量未标注的遥感数据提升语义分割性能。

Method: 利用SAM模型的零样本泛化能力，提出伪标签自训练框架，包括监督模型自训练（结合已标注和伪标签数据）和基于SAM的伪标签优化模块进行改进。优化模块包含三部分：阈值过滤模块、生成区域提示的模块及标签优化模块。

Result: 在Potsdam数据集上的实验验证了SAMST方法的有效性，显著改善了模型依赖有限标注数据的性能。

Conclusion: SAMST通过结合大模型的泛化能力与小模型的高效训练，成功解决了遥感语义分割中有限标注数据带来的挑战。

Abstract: Public remote sensing datasets often face limitations in universality due to
resolution variability and inconsistent land cover category definitions. To
harness the vast pool of unlabeled remote sensing data, we propose SAMST, a
semi-supervised semantic segmentation method. SAMST leverages the strengths of
the Segment Anything Model (SAM) in zero-shot generalization and boundary
detection. SAMST iteratively refines pseudo-labels through two main components:
supervised model self-training using both labeled and pseudo-labeled data, and
a SAM-based Pseudo-label Refiner. The Pseudo-label Refiner comprises three
modules: a Threshold Filter Module for preprocessing, a Prompt Generation
Module for extracting connected regions and generating prompts for SAM, and a
Label Refinement Module for final label stitching. By integrating the
generalization power of large models with the training efficiency of small
models, SAMST improves pseudo-label accuracy, thereby enhancing overall model
performance. Experiments on the Potsdam dataset validate the effectiveness and
feasibility of SAMST, demonstrating its potential to address the challenges
posed by limited labeled data in remote sensing semantic segmentation.

</details>


### [31] [AU-Blendshape for Fine-grained Stylized 3D Facial Expression Manipulation](https://arxiv.org/abs/2507.12001)
*Hao Li,Ju Dai,Feng Zhou,Kaida Ning,Lei Li,Junjun Pan*

Main category: cs.CV

TL;DR: 本文提出了一个新的数据集AUBlendSet和网络AUBlendNet，用于基于面部动作单元（AUs）实现精细的3D面部表情操控。


<details>
  <summary>Details</summary>
Motivation: 目前精细的3D面部表情操控面临挑战，主要是因为缺乏适合的数据集。

Method: 构建了AUBlendSet数据集，包含基于32个标准AUs的500个身份的blendshape数据，并提出AUBlendNet网络，用来学习不同角色风格的AU-Blendshape基向量并实现表情操控。

Result: 通过多个实验任务验证了AUBlendSet和AUBlendNet的有效性，如具有风格化的表情操控、语音驱动的表情动画以及情感识别数据增强。

Conclusion: AUBlendSet是第一个基于面部AUs实现连续3D表情操控的数据集，AUBlendNet是第一个支持任何身份的相应网络，这两者对3D面部动画任务有重要意义。

Abstract: While 3D facial animation has made impressive progress, challenges still
exist in realizing fine-grained stylized 3D facial expression manipulation due
to the lack of appropriate datasets. In this paper, we introduce the
AUBlendSet, a 3D facial dataset based on AU-Blendshape representation for
fine-grained facial expression manipulation across identities. AUBlendSet is a
blendshape data collection based on 32 standard facial action units (AUs)
across 500 identities, along with an additional set of facial postures
annotated with detailed AUs. Based on AUBlendSet, we propose AUBlendNet to
learn AU-Blendshape basis vectors for different character styles. AUBlendNet
predicts, in parallel, the AU-Blendshape basis vectors of the corresponding
style for a given identity mesh, thereby achieving stylized 3D emotional facial
manipulation. We comprehensively validate the effectiveness of AUBlendSet and
AUBlendNet through tasks such as stylized facial expression manipulation,
speech-driven emotional facial animation, and emotion recognition data
augmentation. Through a series of qualitative and quantitative experiments, we
demonstrate the potential and importance of AUBlendSet and AUBlendNet in 3D
facial animation tasks. To the best of our knowledge, AUBlendSet is the first
dataset, and AUBlendNet is the first network for continuous 3D facial
expression manipulation for any identity through facial AUs. Our source code is
available at https://github.com/wslh852/AUBlendNet.git.

</details>


### [32] [Frequency-Dynamic Attention Modulation for Dense Prediction](https://arxiv.org/abs/2507.12006)
*Linwei Chen,Lin Gu,Ying Fu*

Main category: cs.CV

TL;DR: 提出了一种基于电路理论的新方法FDAM（频率动态注意力调制），通过AttInv和FreqScale技术改善ViTs的频率表现，从而提升各种视觉任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有ViTs中注意力机制导致了频率消失问题，影响了细节和纹理的保留，因此需要一种方法来解决这个问题。

Method: 引入了FDAM方法，其中包括Attention Inversion（AttInv）和Frequency Dynamic Scaling（FreqScale）两项技术，分别进行高频滤波和频率组件的动态加权调节。

Result: 在各种ViTs（如SegFormer、DeiT和MaskDINO）中取得了性能提升，包括语义分割、目标检测和实例分割任务；在遥感检测任务中也达到了单尺度下的最新技术水平。

Conclusion: FDAM方法有效解决了表示塌陷问题，并能简单地集成到现有ViTs中，大幅提高模型性能。

Abstract: Vision Transformers (ViTs) have significantly advanced computer vision,
demonstrating strong performance across various tasks. However, the attention
mechanism in ViTs makes each layer function as a low-pass filter, and the
stacked-layer architecture in existing transformers suffers from frequency
vanishing. This leads to the loss of critical details and textures. We propose
a novel, circuit-theory-inspired strategy called Frequency-Dynamic Attention
Modulation (FDAM), which can be easily plugged into ViTs. FDAM directly
modulates the overall frequency response of ViTs and consists of two
techniques: Attention Inversion (AttInv) and Frequency Dynamic Scaling
(FreqScale). Since circuit theory uses low-pass filters as fundamental
elements, we introduce AttInv, a method that generates complementary high-pass
filtering by inverting the low-pass filter in the attention matrix, and
dynamically combining the two. We further design FreqScale to weight different
frequency components for fine-grained adjustments to the target response
function. Through feature similarity analysis and effective rank evaluation, we
demonstrate that our approach avoids representation collapse, leading to
consistent performance improvements across various models, including SegFormer,
DeiT, and MaskDINO. These improvements are evident in tasks such as semantic
segmentation, object detection, and instance segmentation. Additionally, we
apply our method to remote sensing detection, achieving state-of-the-art
results in single-scale settings. The code is available at
\href{https://github.com/Linwei-Chen/FDAM}{https://github.com/Linwei-Chen/FDAM}.

</details>


### [33] [Dual form Complementary Masking for Domain-Adaptive Image Segmentation](https://arxiv.org/abs/2507.12008)
*Jiawen Wang,Yinda Chen,Xiaoyu Liu,Che Liu,Dong Liu,Jianqing Gao,Zhiwei Xiong*

Main category: cs.CV

TL;DR: Paper将掩码重建重新定义为稀疏信号重建问题，提出了MaskTwins框架来加强跨域一致性学习并提升无监督领域适应的效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅将掩码视为输入图像的一种变形形式，缺乏理论分析，导致对掩码重建理解浅显和能力不足。

Method: 将掩码重建理论化为稀疏信号重建问题，并基于此提出MaskTwins框架，通过互补掩码方式提取领域无关的图像特征，并直接将其整合至主训练流程，进行端到端的跨域一致性训练。

Result: 在自然和生物图像分割任务中，MaskTwins优于基线方法，证明其在无需预训练情况下提取领域无关特征的能力。

Conclusion: MaskTwins提供了一种新的领域自适应分割范式，展现了显著的特征提取和领域泛化能力。

Abstract: Recent works have correlated Masked Image Modeling (MIM) with consistency
regularization in Unsupervised Domain Adaptation (UDA). However, they merely
treat masking as a special form of deformation on the input images and neglect
the theoretical analysis, which leads to a superficial understanding of masked
reconstruction and insufficient exploitation of its potential in enhancing
feature extraction and representation learning. In this paper, we reframe
masked reconstruction as a sparse signal reconstruction problem and
theoretically prove that the dual form of complementary masks possesses
superior capabilities in extracting domain-agnostic image features. Based on
this compelling insight, we propose MaskTwins, a simple yet effective UDA
framework that integrates masked reconstruction directly into the main training
pipeline. MaskTwins uncovers intrinsic structural patterns that persist across
disparate domains by enforcing consistency between predictions of images masked
in complementary ways, enabling domain generalization in an end-to-end manner.
Extensive experiments verify the superiority of MaskTwins over baseline methods
in natural and biological image segmentation. These results demonstrate the
significant advantages of MaskTwins in extracting domain-invariant features
without the need for separate pre-training, offering a new paradigm for
domain-adaptive segmentation.

</details>


### [34] [Deep Neural Encoder-Decoder Model to Relate fMRI Brain Activity with Naturalistic Stimuli](https://arxiv.org/abs/2507.12009)
*Florian David,Michael Chan,Elenor Morgenroth,Patrik Vuilleumier,Dimitri Van De Ville*

Main category: cs.CV

TL;DR: 提出了一种基于深度神经网络的端到端编码器-解码器模型，用于解码自然刺激下的大脑活动。


<details>
  <summary>Details</summary>
Motivation: 研究如何使用fMRI数据解码大脑活动，探索深度学习在视觉处理的潜力。

Method: 使用时间卷积层处理连续影片帧的时间相关性，预测视觉皮层周围体素活动并重建视觉输入，同时通过显著性图研究与视觉解码相关的大脑区域。

Result: 发现中枢视觉区域（如中枕区、梭状区和高距）对视觉解码贡献最大，模型可重构边缘、面部和对比等视觉特征。

Conclusion: 深度学习模型能够作为探讨视觉处理的工具，有助于理解大脑在观影中的视觉加工过程。

Abstract: We propose an end-to-end deep neural encoder-decoder model to encode and
decode brain activity in response to naturalistic stimuli using functional
magnetic resonance imaging (fMRI) data. Leveraging temporally correlated input
from consecutive film frames, we employ temporal convolutional layers in our
architecture, which effectively allows to bridge the temporal resolution gap
between natural movie stimuli and fMRI acquisitions. Our model predicts
activity of voxels in and around the visual cortex and performs reconstruction
of corresponding visual inputs from neural activity. Finally, we investigate
brain regions contributing to visual decoding through saliency maps. We find
that the most contributing regions are the middle occipital area, the fusiform
area, and the calcarine, respectively employed in shape perception, complex
recognition (in particular face perception), and basic visual features such as
edges and contrasts. These functions being strongly solicited are in line with
the decoder's capability to reconstruct edges, faces, and contrasts. All in
all, this suggests the possibility to probe our understanding of visual
processing in films using as a proxy the behaviour of deep learning models such
as the one proposed in this paper.

</details>


### [35] [SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection](https://arxiv.org/abs/2507.12017)
*Xiwei Zhang,Chunjin Yang,Yiming Xiao,Runtong Zhang,Fanman Meng*

Main category: cs.CV

TL;DR: 現有的無監督域適應物體檢測方法不考慮RGB域內的多個子域（如日間、夜間和霧天場景）的特性，本文提出了一種基於解耦-耦合策略的新框架SS-DC，有效提升了RGB-紅外域適應的效果。


<details>
  <summary>Details</summary>
Motivation: 現有方法忽視了RGB域中的多個子域，且缺乏對域不變與域特異特徵進行解耦的能力，導致RGB到紅外域的適應困難。

Method: 提出一種基於光譜適應等冪解耦（SAID）的新解耦模塊，利用濾波器組光譜處理及自蒸餾驅動的解耦損失實現特徵分離；通過空間和光譜域的特徵金字塔進行新的空間-光譜耦合方法。

Result: 提出的SS-DC框架顯著提升了基線性能，並在多個RGB-紅外數據集，包括基於FLIR-ADAS的新實驗協議上超越現有的UDAOD方法。

Conclusion: 提出的SS-DC框架被證明能夠更精確地解耦和耦合域不變與域特異特徵，提升了無監督域適應物體檢測的性能。

Abstract: Unsupervised domain adaptive object detection (UDAOD) from the visible domain
to the infrared (RGB-IR) domain is challenging. Existing methods regard the RGB
domain as a unified domain and neglect the multiple subdomains within it, such
as daytime, nighttime, and foggy scenes. We argue that decoupling the
domain-invariant (DI) and domain-specific (DS) features across these multiple
subdomains is beneficial for RGB-IR domain adaptation. To this end, this paper
proposes a new SS-DC framework based on a decoupling-coupling strategy. In
terms of decoupling, we design a Spectral Adaptive Idempotent Decoupling (SAID)
module in the aspect of spectral decomposition. Due to the style and content
information being highly embedded in different frequency bands, this module can
decouple DI and DS components more accurately and interpretably. A novel filter
bank-based spectral processing paradigm and a self-distillation-driven
decoupling loss are proposed to improve the spectral domain decoupling. In
terms of coupling, a new spatial-spectral coupling method is proposed, which
realizes joint coupling through spatial and spectral DI feature pyramids.
Meanwhile, this paper introduces DS from decoupling to reduce the domain bias.
Extensive experiments demonstrate that our method can significantly improve the
baseline performance and outperform existing UDAOD methods on multiple RGB-IR
datasets, including a new experimental protocol proposed in this paper based on
the FLIR-ADAS dataset.

</details>


### [36] [Dataset Ownership Verification for Pre-trained Masked Models](https://arxiv.org/abs/2507.12022)
*Yuechen Xie,Jie Song,Yicheng Shan,Xiaoyan Zhang,Yuanyu Wan,Shengxuming Zhang,Jiarui Duan,Mingli Song*

Main category: cs.CV

TL;DR: 论文提出方法DOV4MM（用于掩码建模的数据集所有权验证）解决当前掩码模型上数据集所有权验证的不足问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习的快速发展使得高质量的开源数据集面临潜在滥用的风险，因此保护数据集至关重要。而现有验证方法主要聚焦于监督模型和对比预训练模型，对日益普及的掩码模型不适用。

Method: 提出DOV4MM方法，通过观察模型在目标数据集上预训练时，嵌入空间内掩码信息重构难度的显著对比，来验证模型是否使用了指定数据集。

Result: 在ImageNet-1K的10个掩码图像模型和WikiText-103的4个掩码文本模型上验证了DOV4MM的有效性。结果显示，该方法显著优于之前技术，$p$值远低于0.05。

Conclusion: DOV4MM提供了一种适用于掩码模型的数据所有权验证方法，有助于增强数据所有者的权益保护。

Abstract: High-quality open-source datasets have emerged as a pivotal catalyst driving
the swift advancement of deep learning, while facing the looming threat of
potential exploitation. Protecting these datasets is of paramount importance
for the interests of their owners. The verification of dataset ownership has
evolved into a crucial approach in this domain; however, existing verification
techniques are predominantly tailored to supervised models and contrastive
pre-trained models, rendering them ill-suited for direct application to the
increasingly prevalent masked models. In this work, we introduce the inaugural
methodology addressing this critical, yet unresolved challenge, termed Dataset
Ownership Verification for Masked Modeling (DOV4MM). The central objective is
to ascertain whether a suspicious black-box model has been pre-trained on a
particular unlabeled dataset, thereby assisting dataset owners in safeguarding
their rights. DOV4MM is grounded in our empirical observation that when a model
is pre-trained on the target dataset, the difficulty of reconstructing masked
information within the embedding space exhibits a marked contrast to models not
pre-trained on that dataset. We validated the efficacy of DOV4MM through ten
masked image models on ImageNet-1K and four masked language models on
WikiText-103. The results demonstrate that DOV4MM rejects the null hypothesis,
with a $p$-value considerably below 0.05, surpassing all prior approaches. Code
is available at https://github.com/xieyc99/DOV4MM.

</details>


### [37] [MVAR: MultiVariate AutoRegressive Air Pollutants Forecasting Model](https://arxiv.org/abs/2507.12023)
*Xu Fan,Zhihao Wang,Yuetan Lin,Yan Zhang,Yang Xiang,Hao Li*

Main category: cs.CV

TL;DR: 本文提出了多变量自回归空气污染物预测模型（MVAR），通过新的训练范式和空间变换模块，实现了多污染物的长时间精确预测，并验证了性能优越性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中于单一污染物预测，未充分考虑不同污染物间相互作用和空间响应差异，且数据利用效率低下。

Method: 提出了MVAR模型及其训练范式，结合气象数据和空间变换模块，学习污染物相互作用和空间响应特点，并使用覆盖北中国75个城市的多污染物数据集进行实验。

Result: 实验证明，MVAR在长时间多污染物预测上优于最先进的方法，验证了模型架构的有效性。

Conclusion: MVAR模型提高了多污染物预测的精准度和数据利用效率，为污染预警和政策制定提供了工具支持。

Abstract: Air pollutants pose a significant threat to the environment and human health,
thus forecasting accurate pollutant concentrations is essential for pollution
warnings and policy-making. Existing studies predominantly focus on
single-pollutant forecasting, neglecting the interactions among different
pollutants and their diverse spatial responses. To address the practical needs
of forecasting multivariate air pollutants, we propose MultiVariate
AutoRegressive air pollutants forecasting model (MVAR), which reduces the
dependency on long-time-window inputs and boosts the data utilization
efficiency. We also design the Multivariate Autoregressive Training Paradigm,
enabling MVAR to achieve 120-hour long-term sequential forecasting.
Additionally, MVAR develops Meteorological Coupled Spatial Transformer block,
enabling the flexible coupling of AI-based meteorological forecasts while
learning the interactions among pollutants and their diverse spatial responses.
As for the lack of standardized datasets in air pollutants forecasting, we
construct a comprehensive dataset covering 6 major pollutants across 75 cities
in North China from 2018 to 2023, including ERA5 reanalysis data and FuXi-2.0
forecast data. Experimental results demonstrate that the proposed model
outperforms state-of-the-art methods and validate the effectiveness of the
proposed architecture.

</details>


### [38] [3D-MoRe: Unified Modal-Contextual Reasoning for Embodied Question Answering](https://arxiv.org/abs/2507.12026)
*Rongtao Xu,Han Gao,Mingming Yu,Dong An,Shunpeng Chen,Changwei Wang,Li Guo,Xiaodan Liang,Shibiao Xu*

Main category: cs.CV

TL;DR: 该论文提出了3D-MoRe，一个用于生成大规模3D语言数据集的新范式。


<details>
  <summary>Details</summary>
Motivation: 满足室内场景任务对多样化和可扩展数据日益增长的需求。

Method: 整合多模态嵌入、跨模态交互以及语言模型解码器处理自然语言指令与3D场景数据，同时使用数据增强和语义过滤确保数据质量。

Result: 3D-MoRe生成62,000个问答对和73,000个对象描述，并在ScanQA和ScanRefer任务中显著超越现有技术水平，CIDEr分别提高2.15%和1.84%。

Conclusion: 3D-MoRe有效提升了复杂3D环境中的推理与响应生成能力，其代码和生成数据集均已公开。

Abstract: With the growing need for diverse and scalable data in indoor scene tasks,
such as question answering and dense captioning, we propose 3D-MoRe, a novel
paradigm designed to generate large-scale 3D-language datasets by leveraging
the strengths of foundational models. The framework integrates key components,
including multi-modal embedding, cross-modal interaction, and a language model
decoder, to process natural language instructions and 3D scene data. This
approach facilitates enhanced reasoning and response generation in complex 3D
environments. Using the ScanNet 3D scene dataset, along with text annotations
from ScanQA and ScanRefer, 3D-MoRe generates 62,000 question-answer (QA) pairs
and 73,000 object descriptions across 1,513 scenes. We also employ various data
augmentation techniques and implement semantic filtering to ensure high-quality
data. Experiments on ScanQA demonstrate that 3D-MoRe significantly outperforms
state-of-the-art baselines, with the CIDEr score improving by 2.15\%.
Similarly, on ScanRefer, our approach achieves a notable increase in CIDEr@0.5
by 1.84\%, highlighting its effectiveness in both tasks. Our code and generated
datasets will be publicly released to benefit the community, and both can be
accessed on the https://3D-MoRe.github.io.

</details>


### [39] [SGLoc: Semantic Localization System for Camera Pose Estimation from 3D Gaussian Splatting Representation](https://arxiv.org/abs/2507.12027)
*Beining Xu,Siting Zhu,Hesheng Wang*

Main category: cs.CV

TL;DR: SGLoc是一种全新的定位系统，通过利用语义信息直接从3D高斯散射(3DGS)表示中回归相机位置，进行全局定位且无需初始位姿先验。


<details>
  <summary>Details</summary>
Motivation: 为了实现无初始位姿先验的相机全局定位，探讨如何利用2D图像与3D场景表示之间的语义关系，克服传统方法的局限性。

Method: 提出了一种多层次位姿回归策略，利用语义驱动的全局检索算法，通过2D图像与3DGS的语义匹配得到粗略位姿，然后通过迭代优化进一步细化。

Result: 在12scenes和7scenes数据集上的表现优于现有基线方法，展现了无需初始位姿先验的卓越定位能力。

Conclusion: SGLoc是一种高性能的全局定位方法，突破了无需初始位姿先验的技术瓶颈，具有实际应用潜力。

Abstract: We propose SGLoc, a novel localization system that directly regresses camera
poses from 3D Gaussian Splatting (3DGS) representation by leveraging semantic
information. Our method utilizes the semantic relationship between 2D image and
3D scene representation to estimate the 6DoF pose without prior pose
information. In this system, we introduce a multi-level pose regression
strategy that progressively estimates and refines the pose of query image from
the global 3DGS map, without requiring initial pose priors. Moreover, we
introduce a semantic-based global retrieval algorithm that establishes
correspondences between 2D (image) and 3D (3DGS map). By matching the extracted
scene semantic descriptors of 2D query image and 3DGS semantic representation,
we align the image with the local region of the global 3DGS map, thereby
obtaining a coarse pose estimation. Subsequently, we refine the coarse pose by
iteratively optimizing the difference between the query image and the rendered
image from 3DGS. Our SGLoc demonstrates superior performance over baselines on
12scenes and 7scenes datasets, showing excellent capabilities in global
localization without initial pose prior. Code will be available at
https://github.com/IRMVLab/SGLoc.

</details>


### [40] [Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery](https://arxiv.org/abs/2507.12029)
*Xinhang Wan,Jiyuan Liu,Qian Qu,Suyuan Liu,Chuyu Zhang,Fangdi Wang,Xinwang Liu,En Zhu,Kunlun He*

Main category: cs.CV

TL;DR: 提出了一种新的框架IICMVNCD，用于解决在多视角环境下的新类别发现问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的新类别发现方法主要针对单一视角数据，忽略了多视角数据，且依赖伪标签造成性能不稳定。

Method: 在单视角层面，利用矩阵分解提取数据的分布一致性和样本间的关系；在多视角层面，通过已知类的视角关系指导新类聚类，并通过动态调整视角权重提升学习效果。

Result: 实验结果证明，所提框架在多视角新类别发现任务中性能出色。

Conclusion: 该方法首次探索了多视角环境下的新类别发现问题，并提供了一种有效且稳健的解决方案。

Abstract: In this paper, we address the problem of novel class discovery (NCD), which
aims to cluster novel classes by leveraging knowledge from disjoint known
classes. While recent advances have made significant progress in this area,
existing NCD methods face two major limitations. First, they primarily focus on
single-view data (e.g., images), overlooking the increasingly common multi-view
data, such as multi-omics datasets used in disease diagnosis. Second, their
reliance on pseudo-labels to supervise novel class clustering often results in
unstable performance, as pseudo-label quality is highly sensitive to factors
such as data noise and feature dimensionality. To address these challenges, we
propose a novel framework named Intra-view and Inter-view Correlation Guided
Multi-view Novel Class Discovery (IICMVNCD), which is the first attempt to
explore NCD in multi-view setting so far. Specifically, at the intra-view
level, leveraging the distributional similarity between known and novel
classes, we employ matrix factorization to decompose features into
view-specific shared base matrices and factor matrices. The base matrices
capture distributional consistency among the two datasets, while the factor
matrices model pairwise relationships between samples. At the inter-view level,
we utilize view relationships among known classes to guide the clustering of
novel classes. This includes generating predicted labels through the weighted
fusion of factor matrices and dynamically adjusting view weights of known
classes based on the supervision loss, which are then transferred to novel
class learning. Experimental results validate the effectiveness of our proposed
approach.

</details>


### [41] [MoViAD: Modular Visual Anomaly Detection](https://arxiv.org/abs/2507.12049)
*Manuel Barusco,Francesco Borsatti,Arianna Stropeni,Davide Dalle Pezze,Gian Antonio Susto*

Main category: cs.CV

TL;DR: 本文介绍了MoViAD，一个面向视觉异常检测（VAD）的高度模块化库，提供了最先进的模型、训练工具、数据集及相关工具，旨在解决异常数据稀缺和需要无监督训练的问题。


<details>
  <summary>Details</summary>
Motivation: 对于VAD领域，由于异常数据稀缺及需要无监督训练等问题，提出了一种综合方法以加速研究与部署。

Method: 开发了一个名为MoViAD的模块化库，支持多种应用场景（如持续学习、半监督、少样本等），并通过边缘设备和物联网等设置，实现高效的设备端执行和分布式推断。

Result: MoViAD集成了多种工具，包括不同的模型骨干、评估指标及效率分析工具，并支持快速部署和灵活扩展。

Conclusion: MoViAD能够有效简化VAD研究和应用流程，既满足工程部署的需求，又为研究者提供了开发和实验新方法的平台。

Abstract: VAD is a critical field in machine learning focused on identifying deviations
from normal patterns in images, often challenged by the scarcity of anomalous
data and the need for unsupervised training. To accelerate research and
deployment in this domain, we introduce MoViAD, a comprehensive and highly
modular library designed to provide fast and easy access to state-of-the-art
VAD models, trainers, datasets, and VAD utilities. MoViAD supports a wide array
of scenarios, including continual, semi-supervised, few-shots, noisy, and many
more. In addition, it addresses practical deployment challenges through
dedicated Edge and IoT settings, offering optimized models and backbones, along
with quantization and compression utilities for efficient on-device execution
and distributed inference. MoViAD integrates a selection of backbones, robust
evaluation VAD metrics (pixel-level and image-level) and useful profiling tools
for efficiency analysis. The library is designed for fast, effortless
deployment, enabling machine learning engineers to easily use it for their
specific setup with custom models, datasets, and backbones. At the same time,
it offers the flexibility and extensibility researchers need to develop and
experiment with new methods.

</details>


### [42] [InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing](https://arxiv.org/abs/2507.12060)
*Kun-Hsiang Lin,Yu-Wen Tseng,Kang-Yang Huang,Jhih-Ciang Wu,Wen-Huang Cheng*

Main category: cs.CV

TL;DR: 本文提出了一个名为InstructFLIP的新框架，通过整合视觉语言模型（VLMs）和引入指令调优，大幅提升面部防伪系统的跨领域通用性。


<details>
  <summary>Details</summary>
Motivation: 当前面部防伪系统在跨领域的泛化能力上仍然存在两大挑战：对攻击类型的语义理解有限，以及跨领域的训练冗余持续存在。

Method: 提出InstructFLIP框架，通过结合视觉语言模型（VLMs）以增强视觉输入的感知，并采用元领域策略学习，在单一领域数据训练下实现跨多个领域的统一模型。在方法上，框架将指令分为内容和风格两部分，引导模型分别关注伪造的语义本质以及环境和摄像头特征的差异。

Result: 实验结果表明，InstructFLIP在准确性方面超越了现有的最先进模型，同时显著减少了跨领域训练的冗余。

Conclusion: InstructFLIP在提升跨领域面部防伪系统的语义理解能力和泛化能力上表现出色，是一个高效解决此领域两大挑战的创新框架。

Abstract: Face anti-spoofing (FAS) aims to construct a robust system that can withstand
diverse attacks. While recent efforts have concentrated mainly on cross-domain
generalization, two significant challenges persist: limited semantic
understanding of attack types and training redundancy across domains. We
address the first by integrating vision-language models (VLMs) to enhance the
perception of visual input. For the second challenge, we employ a meta-domain
strategy to learn a unified model that generalizes well across multiple
domains. Our proposed InstructFLIP is a novel instruction-tuned framework that
leverages VLMs to enhance generalization via textual guidance trained solely on
a single domain. At its core, InstructFLIP explicitly decouples instructions
into content and style components, where content-based instructions focus on
the essential semantics of spoofing, and style-based instructions consider
variations related to the environment and camera characteristics. Extensive
experiments demonstrate the effectiveness of InstructFLIP by outperforming SOTA
models in accuracy and substantially reducing training redundancy across
diverse domains in FAS. Project website is available at
https://kunkunlin1221.github.io/InstructFLIP.

</details>


### [43] [MS-DETR: Towards Effective Video Moment Retrieval and Highlight Detection by Joint Motion-Semantic Learning](https://arxiv.org/abs/2507.12062)
*Hongxu Ma,Guanshuo Wang,Fufu Yu,Qiong Jia,Shouhong Ding*

Main category: cs.CV

TL;DR: 提出了MS-DETR框架，利用运动-语义特征增强MR和HD任务性能，在四个基准测试上超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有MR/HD框架未充分利用视频内容中的时空关系，存在改进空间。

Method: 通过编码器显式模型提取运动和语义间的关系，解码器结合任务相关性进行精确定位，并提出对抗稀疏性问题的生成策略及对比去噪学习。

Result: 在四个MR/HD基准测试中取得了优于当前最先进模型的表现，证实了方法的有效性。

Conclusion: MS-DETR框架有效融合了时空运动和语义特征，显著提升了MR和HD任务表现，展现出对视频内容建模的潜力。

Abstract: Video Moment Retrieval (MR) and Highlight Detection (HD) aim to pinpoint
specific moments and assess clip-wise relevance based on the text query. While
DETR-based joint frameworks have made significant strides, there remains
untapped potential in harnessing the intricate relationships between temporal
motion and spatial semantics within video content. In this paper, we propose
the Motion-Semantics DETR (MS-DETR), a framework that captures rich
motion-semantics features through unified learning for MR/HD tasks. The encoder
first explicitly models disentangled intra-modal correlations within motion and
semantics dimensions, guided by the given text queries. Subsequently, the
decoder utilizes the task-wise correlation across temporal motion and spatial
semantics dimensions to enable precise query-guided localization for MR and
refined highlight boundary delineation for HD. Furthermore, we observe the
inherent sparsity dilemma within the motion and semantics dimensions of MR/HD
datasets. To address this issue, we enrich the corpus from both dimensions by
generation strategies and propose contrastive denoising learning to ensure the
above components learn robustly and effectively. Extensive experiments on four
MR/HD benchmarks demonstrate that our method outperforms existing
state-of-the-art models by a margin. Our code is available at
https://github.com/snailma0229/MS-DETR.git.

</details>


### [44] [Foresight in Motion: Reinforcing Trajectory Prediction with Reward Heuristics](https://arxiv.org/abs/2507.12083)
*Muleilan Pei,Shaoshuai Shi,Xuesong Chen,Xu Liu,Shaojie Shen*

Main category: cs.CV

TL;DR: 本文提出了一种基于规划视角的运动预测方法，将行为意图作为轨迹预测的空间指导，采用基于逆强化学习的“先推理，后预测”策略。


<details>
  <summary>Details</summary>
Motivation: 目前大多数数据驱动方法直接预测未来轨迹，存在解释性和预测精度上的局限，作者希望通过引入行为意图推理改善这些问题。

Method: 首先将交通代理和场景元素编码为统一的向量表示，通过基于查询的逆强化学习推导奖励分布，以指导策略展开推理多种可能的行为意图，最终通过分层DETR样式解码器生成高精度轨迹预测。

Result: 在Argoverse和nuScenes等大规模数据集上，方法显著提高了轨迹预测的置信度，且性能在同类方法中竞争力较强。

Conclusion: 基于意图推理的运动预测方法显著提升了轨迹预测的质量，并为自动驾驶系统的安全性提供了保障。

Abstract: Motion forecasting for on-road traffic agents presents both a significant
challenge and a critical necessity for ensuring safety in autonomous driving
systems. In contrast to most existing data-driven approaches that directly
predict future trajectories, we rethink this task from a planning perspective,
advocating a "First Reasoning, Then Forecasting" strategy that explicitly
incorporates behavior intentions as spatial guidance for trajectory prediction.
To achieve this, we introduce an interpretable, reward-driven intention
reasoner grounded in a novel query-centric Inverse Reinforcement Learning (IRL)
scheme. Our method first encodes traffic agents and scene elements into a
unified vectorized representation, then aggregates contextual features through
a query-centric paradigm. This enables the derivation of a reward distribution,
a compact yet informative representation of the target agent's behavior within
the given scene context via IRL. Guided by this reward heuristic, we perform
policy rollouts to reason about multiple plausible intentions, providing
valuable priors for subsequent trajectory generation. Finally, we develop a
hierarchical DETR-like decoder integrated with bidirectional selective state
space models to produce accurate future trajectories along with their
associated probabilities. Extensive experiments on the large-scale Argoverse
and nuScenes motion forecasting datasets demonstrate that our approach
significantly enhances trajectory prediction confidence, achieving highly
competitive performance relative to state-of-the-art methods.

</details>


### [45] [YOLOv8-SMOT: An Efficient and Robust Framework for Real-Time Small Object Tracking via Slice-Assisted Training and Adaptive Association](https://arxiv.org/abs/2507.12087)
*Xiang Yu,Xinyao Liu,Guang Liang*

Main category: cs.CV

TL;DR: 此论文介绍了从无人机视角跟踪小型、多对象（如鸟类）的解决方案，在检测与关联两方面采取创新措施，最终在“Finding Birds”挑战赛中获胜。


<details>
  <summary>Details</summary>
Motivation: 研究基于无人机视角的多物体跟踪，以解决目标特征稀缺、复杂动态交织及遮挡问题，从而优化小物体检测与跟踪的性能。

Method: 提出了SliceTrain训练框架用于检测，通过分块切割与随机增强解决小物体学习不足的问题；同时设计基于OC-SORT框架的增强跟踪器，结合EMA运动方向维护和自适应相似度度量技术应对不规则运动与身份问题。

Result: 在SMOT4SB公共测试集上取得SO-HOTA分数55.205的突出表现，验证了方法的有效性与先进性。

Conclusion: 新的方法有效提升了复杂条件下的小型多目标跟踪性能，并在实际挑战中表现出色，展示了其技术优势。

Abstract: Tracking small, agile multi-objects (SMOT), such as birds, from an Unmanned
Aerial Vehicle (UAV) perspective is a highly challenging computer vision task.
The difficulty stems from three main sources: the extreme scarcity of target
appearance features, the complex motion entanglement caused by the combined
dynamics of the camera and the targets themselves, and the frequent occlusions
and identity ambiguity arising from dense flocking behavior. This paper details
our championship-winning solution in the MVA 2025 "Finding Birds" Small
Multi-Object Tracking Challenge (SMOT4SB), which adopts the
tracking-by-detection paradigm with targeted innovations at both the detection
and association levels. On the detection side, we propose a systematic training
enhancement framework named \textbf{SliceTrain}. This framework, through the
synergy of 'deterministic full-coverage slicing' and 'slice-level stochastic
augmentation, effectively addresses the problem of insufficient learning for
small objects in high-resolution image training. On the tracking side, we
designed a robust tracker that is completely independent of appearance
information. By integrating a \textbf{motion direction maintenance (EMA)}
mechanism and an \textbf{adaptive similarity metric} combining \textbf{bounding
box expansion and distance penalty} into the OC-SORT framework, our tracker can
stably handle irregular motion and maintain target identities. Our method
achieves state-of-the-art performance on the SMOT4SB public test set, reaching
an SO-HOTA score of \textbf{55.205}, which fully validates the effectiveness
and advancement of our framework in solving complex real-world SMOT problems.
The source code will be made available at
https://github.com/Salvatore-Love/YOLOv8-SMOT.

</details>


### [46] [BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images](https://arxiv.org/abs/2507.12095)
*Davide Di Nucci,Matteo Tomei,Guido Borghi,Luca Ciuffreda,Roberto Vezzani,Rita Cucchiara*

Main category: cs.CV

TL;DR: 本文提出了基于稀疏视角输入进行车辆3D重建的方法，优化了高斯点散射技术并引入了选择性光度损失，同时改进了相机姿态估计流程。


<details>
  <summary>Details</summary>
Motivation: 现有方法在需要密集输入视角的情况下限制了实际应用，本研究旨在解决稀疏视角输入下的3D车辆重建问题。

Method: 结合深度图和先进的姿态估计架构合成新视角数据，改进了高斯点散射算法并从DUSt3R架构中替代传统的运动结构恢复，使用选择性光度损失提升性能。

Result: 通过实验验证了在多个基准上的性能优势，证明了在受约束输入条件下也能实现高质量重建。

Conclusion: 该方法在稀疏视角输入条件下实现了更高效、更准确的3D车辆重建，为相关技术的实际应用奠定了基础。

Abstract: Accurate 3D reconstruction of vehicles is vital for applications such as
vehicle inspection, predictive maintenance, and urban planning. Existing
methods like Neural Radiance Fields and Gaussian Splatting have shown
impressive results but remain limited by their reliance on dense input views,
which hinders real-world applicability. This paper addresses the challenge of
reconstructing vehicles from sparse-view inputs, leveraging depth maps and a
robust pose estimation architecture to synthesize novel views and augment
training data. Specifically, we enhance Gaussian Splatting by integrating a
selective photometric loss, applied only to high-confidence pixels, and
replacing standard Structure-from-Motion pipelines with the DUSt3R architecture
to improve camera pose estimation. Furthermore, we present a novel dataset
featuring both synthetic and real-world public transportation vehicles,
enabling extensive evaluation of our approach. Experimental results demonstrate
state-of-the-art performance across multiple benchmarks, showcasing the
method's ability to achieve high-quality reconstructions even under constrained
input conditions.

</details>


### [47] [DeepShade: Enable Shade Simulation by Text-conditioned Image Generation](https://arxiv.org/abs/2507.12103)
*Longchao Da,Xiangrui Liu,Mithun Shivakoti,Thirulogasankar Pranav Kutralingam,Yezhou Yang,Hua Wei*

Main category: cs.CV

TL;DR: 本文探讨现有路由系统中未能整合阴影信息的问题，提出了结合3D模拟和扩散模型的创新方法，以生成和学习阴影变化，提升路由系统在极端炎热天气下的实用性。


<details>
  <summary>Details</summary>
Motivation: 全球变暖加剧导致的热浪对公共健康构成严重威胁，但当前的路由系统未能将阴影信息纳入，这主要由于卫星图像的噪声以及生成模型缺乏训练数据。

Method: 1. 创建了涵盖多样地理区域、多种建筑密度和城市布局的大型数据集，通过Blender模拟生成建筑阴影，并与卫星图像对齐。2. 提出了基于扩散模型的DeepShade，结合RGB和Canny边缘层，并使用对比学习捕捉阴影的时序变化，以文本描述为条件生成阴影图像。

Result: 利用生成的阴影预测计算Tempe, Arizona的遮阴比例并用于实际路线规划，显著提高了热浪条件下的实用性。

Conclusion: 该研究为极端高温天气下的城市规划提供了参考，同时展示了环境应用的潜力，助力未来的公共健康与规划设计。

Abstract: Heatwaves pose a significant threat to public health, especially as global
warming intensifies. However, current routing systems (e.g., online maps) fail
to incorporate shade information due to the difficulty of estimating shades
directly from noisy satellite imagery and the limited availability of training
data for generative models. In this paper, we address these challenges through
two main contributions. First, we build an extensive dataset covering diverse
longitude-latitude regions, varying levels of building density, and different
urban layouts. Leveraging Blender-based 3D simulations alongside building
outlines, we capture building shadows under various solar zenith angles
throughout the year and at different times of day. These simulated shadows are
aligned with satellite images, providing a rich resource for learning shade
patterns. Second, we propose the DeepShade, a diffusion-based model designed to
learn and synthesize shade variations over time. It emphasizes the nuance of
edge features by jointly considering RGB with the Canny edge layer, and
incorporates contrastive learning to capture the temporal change rules of
shade. Then, by conditioning on textual descriptions of known conditions (e.g.,
time of day, solar angles), our framework provides improved performance in
generating shade images. We demonstrate the utility of our approach by using
our shade predictions to calculate shade ratios for real-world route planning
in Tempe, Arizona. We believe this work will benefit society by providing a
reference for urban planning in extreme heat weather and its potential
practical applications in the environment.

</details>


### [48] [Out-of-distribution data supervision towards biomedical semantic segmentation](https://arxiv.org/abs/2507.12105)
*Yiquan Gao,Duohui Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Med-OoD的数据驱动框架，通过引入分布外（OoD）数据监督来改进生物医学分割网络，对现有网络无需架构修改，显著提高分类精度。


<details>
  <summary>Details</summary>
Motivation: 当前生物医学分割网络在面对有限且不完美的医疗数据集时，易发生前景和背景目标的错误分类。提出方法旨在有效利用分布外数据来提升模型可靠性和性能。

Method: 提出了无需外部数据源、特征正则化目标和额外注释的Med-OoD框架，将分布外数据监督无缝整合入分割网络。并探索仅利用无前景类标签的分布外数据训练网络的可能性。

Result: 实验表明，Med-OoD能够有效减少像素误分类，显著提升Lizard数据集上的分割性能。同时，完全利用无前景标签的分布外数据训练模型仍能达到76.1%的mIoU。

Conclusion: 该框架为生物医学分割网络提供了一种新的数据驱动策略，展示了分布外数据的强大作用，可能对相关领域 OoD 数据的使用引发新的思考。

Abstract: Biomedical segmentation networks easily suffer from the unexpected
misclassification between foreground and background objects when learning on
limited and imperfect medical datasets. Inspired by the strong power of
Out-of-Distribution (OoD) data on other visual tasks, we propose a data-centric
framework, Med-OoD to address this issue by introducing OoD data supervision
into fully-supervised biomedical segmentation with none of the following needs:
(i) external data sources, (ii) feature regularization objectives, (iii)
additional annotations. Our method can be seamlessly integrated into
segmentation networks without any modification on the architectures. Extensive
experiments show that Med-OoD largely prevents various segmentation networks
from the pixel misclassification on medical images and achieves considerable
performance improvements on Lizard dataset. We also present an emerging
learning paradigm of training a medical segmentation network completely using
OoD data devoid of foreground class labels, surprisingly turning out 76.1% mIoU
as test result. We hope this learning paradigm will attract people to rethink
the roles of OoD data. Code is made available at
https://github.com/StudioYG/Med-OoD.

</details>


### [49] [Non-Adaptive Adversarial Face Generation](https://arxiv.org/abs/2507.12107)
*Sunpill Kim,Seunghun Paik,Chanwoo Hwang,Minsu Kim,Jae Hong Seo*

Main category: cs.CV

TL;DR: 提出了一种生成对抗性面部图像的新方法，能以非常有限的查询次数成功攻击面部识别系统，同时保留较高的伪装特性。


<details>
  <summary>Details</summary>
Motivation: 面部识别系统（FRS）受到对抗攻击时，可能导致严重的安全和隐私问题，尤其在身份验证场景中。因此需要探索生成有效对抗性面图的方法。

Method: 方法利用FRS特征空间的结构特点，识别具有相同属性的个体（如性别或种族）形成的属性子球，生成具有目标身份特征的对抗性面部图像，同时仅需一次包含100张图像的非自适应查询。

Result: 提出的方案在仅需一次非自适应查询的情况下，在AWS CompareFaces API默认阈值下达到93%以上的成功率。

Conclusion: 通过高效的对抗性生成方法，不仅实现了良好的攻击效果，还能在生成过程中保留高层属性，并减少对开源替代模型或可传递性的依赖。

Abstract: Adversarial attacks on face recognition systems (FRSs) pose serious security
and privacy threats, especially when these systems are used for identity
verification. In this paper, we propose a novel method for generating
adversarial faces-synthetic facial images that are visually distinct yet
recognized as a target identity by the FRS. Unlike iterative optimization-based
approaches (e.g., gradient descent or other iterative solvers), our method
leverages the structural characteristics of the FRS feature space. We figure
out that individuals sharing the same attribute (e.g., gender or race) form an
attributed subsphere. By utilizing such subspheres, our method achieves both
non-adaptiveness and a remarkably small number of queries. This eliminates the
need for relying on transferability and open-source surrogate models, which
have been a typical strategy when repeated adaptive queries to commercial FRSs
are impossible. Despite requiring only a single non-adaptive query consisting
of 100 face images, our method achieves a high success rate of over 93% against
AWS's CompareFaces API at its default threshold. Furthermore, unlike many
existing attacks that perturb a given image, our method can deliberately
produce adversarial faces that impersonate the target identity while exhibiting
high-level attributes chosen by the adversary.

</details>


### [50] [LidarPainter: One-Step Away From Any Lidar View To Novel Guidance](https://arxiv.org/abs/2507.12114)
*Yuzhou Ji,Ke Ma,Hong Cai,Anchun Zhang,Lizhuang Ma,Xin Tan*

Main category: cs.CV

TL;DR: LidarPainter通过扩散模型提升动态驾驶场景重建质量，尤其是在轨迹偏移时表现出色，支持实时的视图恢复和风格化生成。


<details>
  <summary>Details</summary>
Motivation: 为了解决动态驾驶场景重建时因轨迹偏移导致的质量下降问题，如背景和模型损坏，且现有方法在一致性、变形和时间消耗上有局限性。

Method: 提出了LidarPainter，这是一种基于扩散模型的单步方法，在稀疏LiDAR数据和受损渲染图基础上实现一致的驾驶视图恢复，支持实时高保真车道偏移场景重建，同时支持文本提示的风格化生成。

Result: 实验显示LidarPainter在速度、质量和资源效率上均优于现有方法，比StreetCrafter快7倍，显存需求仅为其1/5。

Conclusion: LidarPainter是一种高效且多样化的工具，可显著提升驾驶场景重建质量，并通过文本提示扩展场景生成的可能性。

Abstract: Dynamic driving scene reconstruction is of great importance in fields like
digital twin system and autonomous driving simulation. However, unacceptable
degradation occurs when the view deviates from the input trajectory, leading to
corrupted background and vehicle models. To improve reconstruction quality on
novel trajectory, existing methods are subject to various limitations including
inconsistency, deformation, and time consumption. This paper proposes
LidarPainter, a one-step diffusion model that recovers consistent driving views
from sparse LiDAR condition and artifact-corrupted renderings in real-time,
enabling high-fidelity lane shifts in driving scene reconstruction. Extensive
experiments show that LidarPainter outperforms state-of-the-art methods in
speed, quality and resource efficiency, specifically 7 x faster than
StreetCrafter with only one fifth of GPU memory required. LidarPainter also
supports stylized generation using text prompts such as "foggy" and "night",
allowing for a diverse expansion of the existing asset library.

</details>


### [51] [Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph](https://arxiv.org/abs/2507.12123)
*Sergey Linok,Gleb Naumov*

Main category: cs.CV

TL;DR: 该论文提出了一种名为OVIGo-3DHSG的新方法，通过3D分层场景图实现开放词汇的室内物体定位。


<details>
  <summary>Details</summary>
Motivation: 当前室内环境物体理解面临复杂的空间推理挑战，需引入高效方法辅助解决。

Method: 使用RGB-D帧序列与开放词汇基础模型生成分层场景图，并结合大语言模型进行多步推理。

Result: 在Habitat Matterport 3D语义场景测试中，展现了较高的语义和几何准确性以及优于现有方法的场景理解与物体定位能力。

Conclusion: OVIGo-3DHSG在需要空间推理与室内场景理解的应用中表现出强大潜力。

Abstract: We propose OVIGo-3DHSG method - Open-Vocabulary Indoor Grounding of objects
using 3D Hierarchical Scene Graph. OVIGo-3DHSG represents an extensive indoor
environment over a Hierarchical Scene Graph derived from sequences of RGB-D
frames utilizing a set of open-vocabulary foundation models and sensor data
processing. The hierarchical representation explicitly models spatial relations
across floors, rooms, locations, and objects. To effectively address complex
queries involving spatial reference to other objects, we integrate the
hierarchical scene graph with a Large Language Model for multistep reasoning.
This integration leverages inter-layer (e.g., room-to-object) and intra-layer
(e.g., object-to-object) connections, enhancing spatial contextual
understanding. We investigate the semantic and geometry accuracy of
hierarchical representation on Habitat Matterport 3D Semantic multi-floor
scenes. Our approach demonstrates efficient scene comprehension and robust
object grounding compared to existing methods. Overall OVIGo-3DHSG demonstrates
strong potential for applications requiring spatial reasoning and understanding
of indoor environments. Related materials can be found at
https://github.com/linukc/OVIGo-3DHSG.

</details>


### [52] [Block-based Symmetric Pruning and Fusion for Efficient Vision Transformers](https://arxiv.org/abs/2507.12125)
*Yi-Kuan Hsieh,Jun-Wei Hsieh,Xin Li,Yu-Ming Chang,Yu-Chee Tseng*

Main category: cs.CV

TL;DR: 提出了一种新的块对称剪枝与融合方法（BSPF-ViT），专注于高效Vision Transformer（ViT）剪枝，提高准确性并降低计算量。


<details>
  <summary>Details</summary>
Motivation: 现有ViT剪枝方法往往独立处理Q和K，忽略了token之间的交互，导致性能下降。论文提出优化剪枝的需求以提升模型效果和速度。

Method: 引入块对称剪枝与融合（BSPF-ViT）方法，联合剪枝Q与K tokens，利用token及其邻居的信息，通过相似性融合压缩保留tokens，减少计算量并保留关键信息，同时对称的注意矩阵也实现了计算加速。

Result: 相比现有方法，BSPF-ViT在所有剪枝水平上均表现更优：ImageNet分类任务中DeiT-T和DeiT-S准确率分别提高1.3%和2.0%，计算开销下降50%，在各种ViT模型中实现40%的速度提升。

Conclusion: BSPF-ViT成功在不降低甚至提升准确率的情况下实现ViT的高效化，为有效加速和优化ViT的剪枝开辟了新的路径。

Abstract: Vision Transformer (ViT) has achieved impressive results across various
vision tasks, yet its high computational cost limits practical applications.
Recent methods have aimed to reduce ViT's $O(n^2)$ complexity by pruning
unimportant tokens. However, these techniques often sacrifice accuracy by
independently pruning query (Q) and key (K) tokens, leading to performance
degradation due to overlooked token interactions. To address this limitation,
we introduce a novel {\bf Block-based Symmetric Pruning and Fusion} for
efficient ViT (BSPF-ViT) that optimizes the pruning of Q/K tokens jointly.
Unlike previous methods that consider only a single direction, our approach
evaluates each token and its neighbors to decide which tokens to retain by
taking token interaction into account. The retained tokens are compressed
through a similarity fusion step, preserving key information while reducing
computational costs. The shared weights of Q/K tokens create a symmetric
attention matrix, allowing pruning only the upper triangular part for speed up.
BSPF-ViT consistently outperforms state-of-the-art ViT methods at all pruning
levels, increasing ImageNet classification accuracy by 1.3% on DeiT-T and 2.0%
on DeiT-S, while reducing computational overhead by 50%. It achieves 40%
speedup with improved accuracy across various ViTs.

</details>


### [53] [Learning Pixel-adaptive Multi-layer Perceptrons for Real-time Image Enhancement](https://arxiv.org/abs/2507.12135)
*Junyu Lou,Xiaorui Zhao,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: 提出了一种基于双边网格的像素自适应多层感知机(BPAM)框架，通过结合双边网格的空间建模能力与多层感知机(MLP)的非线性映射能力，实现了优于现有技术的实时图像增强处理。


<details>
  <summary>Details</summary>
Motivation: 解决传统双边网格处理方法受限于线性仿射变换、难以建模复杂颜色关系，以及传统MLP全局参数共享难以处理局部变化的问题。

Method: 将MLP参数嵌入双边网格中，根据像素的空间坐标和强度值动态检索特定颜色映射的MLP参数。此外，引入了一种新的网格分解策略，通过多通道引导图从对应子网格中获取具体的类别参数，确保颜色信息的有效利用与精确参数生成。

Result: 在公共数据集上的实验表明，在保持实时处理能力的同时，与现有最先进方法相比，本方法取得了更好的性能。

Conclusion: 新方法突破了现有局限性，成功结合双边网格与MLP的优势，提供了一种高效且性能优异的实时图像增强解决方案。

Abstract: Deep learning-based bilateral grid processing has emerged as a promising
solution for image enhancement, inherently encoding spatial and intensity
information while enabling efficient full-resolution processing through slicing
operations. However, existing approaches are limited to linear affine
transformations, hindering their ability to model complex color relationships.
Meanwhile, while multi-layer perceptrons (MLPs) excel at non-linear mappings,
traditional MLP-based methods employ globally shared parameters, which is hard
to deal with localized variations. To overcome these dual challenges, we
propose a Bilateral Grid-based Pixel-Adaptive Multi-layer Perceptron (BPAM)
framework. Our approach synergizes the spatial modeling of bilateral grids with
the non-linear capabilities of MLPs. Specifically, we generate bilateral grids
containing MLP parameters, where each pixel dynamically retrieves its unique
transformation parameters and obtain a distinct MLP for color mapping based on
spatial coordinates and intensity values. In addition, we propose a novel grid
decomposition strategy that categorizes MLP parameters into distinct types
stored in separate subgrids. Multi-channel guidance maps are used to extract
category-specific parameters from corresponding subgrids, ensuring effective
utilization of color information during slicing while guiding precise parameter
generation. Extensive experiments on public datasets demonstrate that our
method outperforms state-of-the-art methods in performance while maintaining
real-time processing capabilities.

</details>


### [54] [AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving](https://arxiv.org/abs/2507.12137)
*Jiawei Xu,Kai Deng,Zexin Fan,Shenlong Wang,Jin Xie,Jian Yang*

Main category: cs.CV

TL;DR: 研究提出了一种名为AD-GS的新型自监督框架，用于从单个日志中渲染高质量的驾驶场景，具有精确的动态物体建模和场景分解能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵的手动标注或无法准确捕捉动态物体运动和分解场景。研发无需标注的高质量渲染机制是目标。

Method: 提出一种结合局部B样条曲线和全局三角函数的运动模型，同时使用伪2D分割自动分解场景为物体与背景，并通过动态高斯和时间可见性掩码进行表示。

Result: 实验表明，该模型在无标注场景下明显优于其他方法，并与依赖标注的方法表现相当。

Conclusion: AD-GS在无需标注的条件下实现了高质量动态驾驶场景渲染，为自监督方法提供了新的可能性。

Abstract: Modeling and rendering dynamic urban driving scenes is crucial for
self-driving simulation. Current high-quality methods typically rely on costly
manual object tracklet annotations, while self-supervised approaches fail to
capture dynamic object motions accurately and decompose scenes properly,
resulting in rendering artifacts. We introduce AD-GS, a novel self-supervised
framework for high-quality free-viewpoint rendering of driving scenes from a
single log. At its core is a novel learnable motion model that integrates
locality-aware B-spline curves with global-aware trigonometric functions,
enabling flexible yet precise dynamic object modeling. Rather than requiring
comprehensive semantic labeling, AD-GS automatically segments scenes into
objects and background with the simplified pseudo 2D segmentation, representing
objects using dynamic Gaussians and bidirectional temporal visibility masks.
Further, our model incorporates visibility reasoning and physically rigid
regularization to enhance robustness. Extensive evaluations demonstrate that
our annotation-free model significantly outperforms current state-of-the-art
annotation-free methods and is competitive with annotation-dependent
approaches.

</details>


### [55] [Neural Human Pose Prior](https://arxiv.org/abs/2507.12138)
*Michal Heker,Sefy Kararlitsky,David Tolpin*

Main category: cs.CV

TL;DR: 通过引入基于normalizing flows的方法，本文在6D旋转格式下建模了人体姿态的神经先验。


<details>
  <summary>Details</summary>
Motivation: 现有的人体姿态先验建模方法缺乏灵活性或表达能力，难以满足复杂任务需求。

Method: 采用RealNVP来学习灵活的姿态分布，并通过逆向的Gram-Schmidt过程确保训练的稳定性和与现有框架的兼容性。

Result: 提出的方法在定性和定量评估中均表现出色，且通过消融实验分析了模型的影响。

Conclusion: 本文为人体运动捕捉和重建领域的姿态先验引入了坚实的概率基础，具有较高的框架通用性和可复现性。

Abstract: We introduce a principled, data-driven approach for modeling a neural prior
over human body poses using normalizing flows. Unlike heuristic or
low-expressivity alternatives, our method leverages RealNVP to learn a flexible
density over poses represented in the 6D rotation format. We address the
challenge of modeling distributions on the manifold of valid 6D rotations by
inverting the Gram-Schmidt process during training, enabling stable learning
while preserving downstream compatibility with rotation-based frameworks. Our
architecture and training pipeline are framework-agnostic and easily
reproducible. We demonstrate the effectiveness of the learned prior through
both qualitative and quantitative evaluations, and we analyze its impact via
ablation studies. This work provides a sound probabilistic foundation for
integrating pose priors into human motion capture and reconstruction pipelines.

</details>


### [56] [Wavelet-based Decoupling Framework for low-light Stereo Image Enhancement](https://arxiv.org/abs/2507.12188)
*Shuangli Du,Siming Yan,Zhenghao Shi,Zhenzhen You,Lu Sun*

Main category: cs.CV

TL;DR: 本文提出了一种基于小波变换的低光双目图像增强方法，通过特征空间解耦实现亮度调整与纹理增强。


<details>
  <summary>Details</summary>
Motivation: 现有的低光图像增强方法通常将所有退化因素编码到单一潜在空间中，导致特征高度纠缠和模型易于捷径学习。

Method: 通过小波变换将特征空间分解为低频分支用于亮度调整和多个高频分支用于纹理增强。同时提出了高频引导跨视图交互模块（HF-CIM）和基于交叉注意力机制的细节与纹理增强模块（DTEM）。

Result: 实验表明，该方法在光照调整和高频信息恢复方面具有显著优势，对真实和合成图像都取得了良好效果。

Conclusion: 基于小波的特征解耦方法可以有效解决低光图像的复杂退化问题，在光照和纹理增强方面性能卓越。

Abstract: Low-light images suffer from complex degradation, and existing enhancement
methods often encode all degradation factors within a single latent space. This
leads to highly entangled features and strong black-box characteristics, making
the model prone to shortcut learning. To mitigate the above issues, this paper
proposes a wavelet-based low-light stereo image enhancement method with feature
space decoupling. Our insight comes from the following findings: (1) Wavelet
transform enables the independent processing of low-frequency and
high-frequency information. (2) Illumination adjustment can be achieved by
adjusting the low-frequency component of a low-light image, extracted through
multi-level wavelet decomposition. Thus, by using wavelet transform the feature
space is decomposed into a low-frequency branch for illumination adjustment and
multiple high-frequency branches for texture enhancement. Additionally, stereo
low-light image enhancement can extract useful cues from another view to
improve enhancement. To this end, we propose a novel high-frequency guided
cross-view interaction module (HF-CIM) that operates within high-frequency
branches rather than across the entire feature space, effectively extracting
valuable image details from the other view. Furthermore, to enhance the
high-frequency information, a detail and texture enhancement module (DTEM) is
proposed based on cross-attention mechanism. The model is trained on a dataset
consisting of images with uniform illumination and images with non-uniform
illumination. Experimental results on both real and synthetic images indicate
that our algorithm offers significant advantages in light adjustment while
effectively recovering high-frequency information. The code and dataset are
publicly available at: https://github.com/Cherisherr/WDCI-Net.git.

</details>


### [57] [Fine-Grained Image Recognition from Scratch with Teacher-Guided Data Augmentation](https://arxiv.org/abs/2507.12157)
*Edwin Arkel Rios,Fernando Mikael,Oswin Gosal,Femiloye Oyerinde,Hao-Chun Liang,Bo-Cheng Lai,Min-Chun Hu*

Main category: cs.CV

TL;DR: 该研究提出了一种新框架(TGDA)，可从零开始训练高性能的细粒度图像识别(FGIR)系统，无需依赖预训练模型。


<details>
  <summary>Details</summary>
Motivation: 现有细粒度图像识别方法严重依赖于预训练模型，限制了在资源受限和特定任务环境中的适应能力。

Method: 引入TGDA框架，结合数据感知增强与通过知识蒸馏实现的弱监督训练；设计了低分辨率FGIR的LRNets及针对高效推理优化的ViTFS视觉Transformer架构。

Result: 在多个FGIR基准测试中，TGDA方法在低分辨率环境上提升准确率高达23%，同时显著减少参数量及训练数据需求；ViTFS在高效性能方面大幅优于ViT B-16。

Conclusion: TGDA框架作为预训练的替代方案，展现出高效和强适应性的潜力，可推动细粒度视觉系统的进一步发展。

Abstract: Fine-grained image recognition (FGIR) aims to distinguish visually similar
sub-categories within a broader class, such as identifying bird species. While
most existing FGIR methods rely on backbones pretrained on large-scale datasets
like ImageNet, this dependence limits adaptability to resource-constrained
environments and hinders the development of task-specific architectures
tailored to the unique challenges of FGIR.
  In this work, we challenge the conventional reliance on pretrained models by
demonstrating that high-performance FGIR systems can be trained entirely from
scratch. We introduce a novel training framework, TGDA, that integrates
data-aware augmentation with weak supervision via a fine-grained-aware teacher
model, implemented through knowledge distillation. This framework unlocks the
design of task-specific and hardware-aware architectures, including LRNets for
low-resolution FGIR and ViTFS, a family of Vision Transformers optimized for
efficient inference.
  Extensive experiments across three FGIR benchmarks over diverse settings
involving low-resolution and high-resolution inputs show that our method
consistently matches or surpasses state-of-the-art pretrained counterparts. In
particular, in the low-resolution setting, LRNets trained with TGDA improve
accuracy by up to 23\% over prior methods while requiring up to 20.6x less
parameters, lower FLOPs, and significantly less training data. Similarly,
ViTFS-T can match the performance of a ViT B-16 pretrained on ImageNet-21k
while using 15.3x fewer trainable parameters and requiring orders of magnitudes
less data. These results highlight TGDA's potential as an adaptable alternative
to pretraining, paving the way for more efficient fine-grained vision systems.

</details>


### [58] [Revealing the Ancient Beauty: Digital Reconstruction of Temple Tiles using Computer Vision](https://arxiv.org/abs/2507.12195)
*Arkaprabha Basu*

Main category: cs.CV

TL;DR: 本文提出了三种用于印度文化遗产保护的先进方法，包括分形卷积法、敏感瓷砖填充法和超分辨率策略。


<details>
  <summary>Details</summary>
Motivation: 旨在通过现代计算技术提升文化遗产的数字化保护和修复能力，尤其是针对印度特有建筑和艺术特点提供创新的解决方案。

Method: 引入了分形卷积方法用于建筑图案提取，敏感瓷砖填充方法结合数据增强技术处理特定遗迹，以及超分辨率方法用于高质量图像放大。

Result: 在合理成本下实现了自动化的无缝区域填充，并保留了高度细节化的瓷砖图案，同时保持真实性。

Conclusion: 该研究通过有效的数字方法彰显了传统与创新的平衡，为文化遗产保护领域带来了高效性和美学质量的提升。

Abstract: Modern digitised approaches have dramatically changed the preservation and
restoration of cultural treasures, integrating computer scientists into
multidisciplinary projects with ease. Machine learning, deep learning, and
computer vision techniques have revolutionised developing sectors like 3D
reconstruction, picture inpainting,IoT-based methods, genetic algorithms, and
image processing with the integration of computer scientists into
multidisciplinary initiatives. We suggest three cutting-edge techniques in
recognition of the special qualities of Indian monuments, which are famous for
their architectural skill and aesthetic appeal. First is the Fractal
Convolution methodology, a segmentation method based on image processing that
successfully reveals subtle architectural patterns within these irreplaceable
cultural buildings. The second is a revolutionary Self-Sensitive Tile Filling
(SSTF) method created especially for West Bengal's mesmerising Bankura
Terracotta Temples with a brand-new data augmentation method called MosaicSlice
on the third. Furthermore, we delve deeper into the Super Resolution strategy
to upscale the images without losing significant amount of quality. Our methods
allow for the development of seamless region-filling and highly detailed tiles
while maintaining authenticity using a novel data augmentation strategy within
affordable costs introducing automation. By providing effective solutions that
preserve the delicate balance between tradition and innovation, this study
improves the subject and eventually ensures unrivalled efficiency and aesthetic
excellence in cultural heritage protection. The suggested approaches advance
the field into an era of unmatched efficiency and aesthetic quality while
carefully upholding the delicate equilibrium between tradition and innovation.

</details>


### [59] [Hybrid Ensemble Approaches: Optimal Deep Feature Fusion and Hyperparameter-Tuned Classifier Ensembling for Enhanced Brain Tumor Classification](https://arxiv.org/abs/2507.12177)
*Zahid Ullah,Dragan Pamucar,Jihie Kim*

Main category: cs.CV

TL;DR: 本文提出了一种双重集成框架，结合深度学习特征提取和机器学习分类模型，提升脑肿瘤分类精度。


<details>
  <summary>Details</summary>
Motivation: MRI图像诊断脑肿瘤准确性受到专家主观判断、疲劳及图像细节不足等问题影响。本研究旨在解决这些挑战，提高诊断准确性。

Method: 采用双重集成框架，包括预训练深度学习模型提取特征及优化超参数的机器学习模型进行分类。模型训练使用公开MRI脑肿瘤数据集，并结合广泛的预处理、数据增强及迁移学习技术。

Result: 研究结果表明，该方法显著优于现有技术，尤其在特征与分类器融合及超参数微调部分表现突出。

Conclusion: 双重集成框架提供了更高效的脑肿瘤分类方案，为医学影像分析领域做出了重要贡献。

Abstract: Magnetic Resonance Imaging (MRI) is widely recognized as the most reliable
tool for detecting tumors due to its capability to produce detailed images that
reveal their presence. However, the accuracy of diagnosis can be compromised
when human specialists evaluate these images. Factors such as fatigue, limited
expertise, and insufficient image detail can lead to errors. For example, small
tumors might go unnoticed, or overlap with healthy brain regions could result
in misidentification. To address these challenges and enhance diagnostic
precision, this study proposes a novel double ensembling framework, consisting
of ensembled pre-trained deep learning (DL) models for feature extraction and
ensembled fine-tuned hyperparameter machine learning (ML) models to efficiently
classify brain tumors. Specifically, our method includes extensive
preprocessing and augmentation, transfer learning concepts by utilizing various
pre-trained deep convolutional neural networks and vision transformer networks
to extract deep features from brain MRI, and fine-tune hyperparameters of ML
classifiers. Our experiments utilized three different publicly available Kaggle
MRI brain tumor datasets to evaluate the pre-trained DL feature extractor
models, ML classifiers, and the effectiveness of an ensemble of deep features
along with an ensemble of ML classifiers for brain tumor classification. Our
results indicate that the proposed feature fusion and classifier fusion improve
upon the state of the art, with hyperparameter fine-tuning providing a
significant enhancement over the ensemble method. Additionally, we present an
ablation study to illustrate how each component contributes to accurate brain
tumor classification.

</details>


### [60] [RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models](https://arxiv.org/abs/2507.12201)
*Yiqi Tian,Pengfei Jin,Mingze Yuan,Na Li,Bo Zeng,Quanzheng Li*

Main category: cs.CV

TL;DR: 提出了RODS，利用几何视角修正扩散模型采样中的幻觉问题，提高采样质量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在生成建模中表现领先，但其采样过程易受幻觉影响，主要源于信号逼近误差。

Method: 将扩散采样方法重解释为优化问题，引入RODS，通过利用损失景观的几何线索，探测并修正高风险采样步骤，实现更平滑的采样轨迹和自适应扰动调整。

Result: 在多个数据集上实验表明，RODS检测出超过70%的幻觉样本并修正了25%以上，同时避免新伪影的引入。

Conclusion: RODS无需重新训练即可降低幻觉发生，提高采样的准确性和鲁棒性，且附加推理成本极小。

Abstract: Diffusion models have achieved state-of-the-art performance in generative
modeling, yet their sampling procedures remain vulnerable to hallucinations,
often stemming from inaccuracies in score approximation. In this work, we
reinterpret diffusion sampling through the lens of optimization and introduce
RODS (Robust Optimization-inspired Diffusion Sampler), a novel method that
detects and corrects high-risk sampling steps using geometric cues from the
loss landscape. RODS enforces smoother sampling trajectories and adaptively
adjusts perturbations, reducing hallucinations without retraining and at
minimal additional inference cost. Experiments on AFHQv2, FFHQ, and 11k-hands
demonstrate that RODS improves both sampling fidelity and robustness, detecting
over 70% of hallucinated samples and correcting more than 25%, all while
avoiding the introduction of new artifacts.

</details>


### [61] [MGFFD-VLM: Multi-Granularity Prompt Learning for Face Forgery Detection with VLM](https://arxiv.org/abs/2507.12232)
*Tao Chen,Jingyi Zhang,Decheng Liu,Chunlei Peng*

Main category: cs.CV

TL;DR: 本文提出了一个名为MGFFD-VLM的新型框架，通过扩展VQA数据集和引入多种创新方法，解决现有深度伪造检测的局限性，并提高伪造检测能力与可解释性。


<details>
  <summary>Details</summary>
Motivation: 作者注意到以往研究虽能检测伪造人脸及解释原因，但未充分利用伪造脸质量相关属性，且缺乏有效的训练策略。

Method: 作者扩展了VQA数据集为DD-VQA+，并提出MGFFD-VLM框架，引入了属性驱动的LoRA策略、多粒度提示学习及伪造感知训练策略，同时设计了多种辅助损失以加强伪造检测能力。

Result: 实验表明，该方法在文本伪造判别和分析的准确性上均优于已有方法。

Conclusion: MGFFD-VLM框架在伪造检测分类和解读上表现出显著优越性，解决了当前方法的局限性，并为深入研究提供了新的可能性。

Abstract: Recent studies have utilized visual large language models (VLMs) to answer
not only "Is this face a forgery?" but also "Why is the face a forgery?" These
studies introduced forgery-related attributes, such as forgery location and
type, to construct deepfake VQA datasets and train VLMs, achieving high
accuracy while providing human-understandable explanatory text descriptions.
However, these methods still have limitations. For example, they do not fully
leverage face quality-related attributes, which are often abnormal in forged
faces, and they lack effective training strategies for forgery-aware VLMs. In
this paper, we extend the VQA dataset to create DD-VQA+, which features a
richer set of attributes and a more diverse range of samples. Furthermore, we
introduce a novel forgery detection framework, MGFFD-VLM, which integrates an
Attribute-Driven Hybrid LoRA Strategy to enhance the capabilities of Visual
Large Language Models (VLMs). Additionally, our framework incorporates
Multi-Granularity Prompt Learning and a Forgery-Aware Training Strategy. By
transforming classification and forgery segmentation results into prompts, our
method not only improves forgery classification but also enhances
interpretability. To further boost detection performance, we design multiple
forgery-related auxiliary losses. Experimental results demonstrate that our
approach surpasses existing methods in both text-based forgery judgment and
analysis, achieving superior accuracy.

</details>


### [62] [Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants](https://arxiv.org/abs/2507.12269)
*Sybelle Goedicke-Fritz,Michelle Bous,Annika Engel,Matthias Flotho,Pascal Hirsch,Hannah Wittig,Dino Milanovic,Dominik Mohr,Mathias Kaspar,Sogand Nemat,Dorothea Kerner,Arno Bücker,Andreas Keller,Sascha Meyer,Michael Zemlin,Philipp Flotho*

Main category: cs.CV

TL;DR: 文章探讨了一种基于深度学习的早产儿支气管肺发育不良（BPD）预测方法，使用入院24小时内的胸部X光片，通过领域特定的预训练和进阶训练方法提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 支气管肺发育不良（BPD）严重影响极低出生体重婴儿的生命质量，但传统干预措施可能带来神经发育损伤和系统性并发症，因此需要一种非侵入性工具提前预测风险。

Method: 利用深度学习方法，基于ResNet-50模型对163名早产儿的入院胸部X光图像进行分析，采用领域特定预训练、逐步冻结层和线性探测技术，并运用了CutMix数据增强技术来优化模型性能。

Result: 模型在中重度BPD预测中的AUROC达到0.78，平衡准确率为0.69，F1分数为0.67。领域内预训练显著优于ImageNet初始化，证实了领域特定预训练的重要性，而常规IRDS评分预后效果有限（AUROC仅为0.57）。

Conclusion: 领域特定预训练结合优化策略可准确预测早产儿的BPD风险，建议进一步推广至实际应用及联邦学习环境中。

Abstract: Bronchopulmonary dysplasia (BPD) is a chronic lung disease affecting 35% of
extremely low birth weight infants. Defined by oxygen dependence at 36 weeks
postmenstrual age, it causes lifelong respiratory complications. However,
preventive interventions carry severe risks, including neurodevelopmental
impairment, ventilator-induced lung injury, and systemic complications.
Therefore, early BPD prognosis and prediction of BPD outcome is crucial to
avoid unnecessary toxicity in low risk infants. Admission radiographs of
extremely preterm infants are routinely acquired within 24h of life and could
serve as a non-invasive prognostic tool. In this work, we developed and
investigated a deep learning approach using chest X-rays from 163 extremely
low-birth-weight infants ($\leq$32 weeks gestation, 401-999g) obtained within
24 hours of birth. We fine-tuned a ResNet-50 pretrained specifically on adult
chest radiographs, employing progressive layer freezing with discriminative
learning rates to prevent overfitting and evaluated a CutMix augmentation and
linear probing. For moderate/severe BPD outcome prediction, our best performing
model with progressive freezing, linear probing and CutMix achieved an AUROC of
0.78 $\pm$ 0.10, balanced accuracy of 0.69 $\pm$ 0.10, and an F1-score of 0.67
$\pm$ 0.11. In-domain pre-training significantly outperformed ImageNet
initialization (p = 0.031) which confirms domain-specific pretraining to be
important for BPD outcome prediction. Routine IRDS grades showed limited
prognostic value (AUROC 0.57 $\pm$ 0.11), confirming the need of learned
markers. Our approach demonstrates that domain-specific pretraining enables
accurate BPD prediction from routine day-1 radiographs. Through progressive
freezing and linear probing, the method remains computationally feasible for
site-level implementation and future federated learning deployments.

</details>


### [63] [Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models](https://arxiv.org/abs/2507.12236)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.CV

TL;DR: 本文探讨了在医学影像中利用生成式文本到图像扩散模型进行短语定位，提出了一种新后处理技术BBM，从而实现了更高的定位精度。


<details>
  <summary>Details</summary>
Motivation: 探索生成式模型在短语定位任务中的潜力，以改进当前基于判别模型的不足，特别是在医学影像中的应用。

Method: 利用生成式扩散模型与冻结的领域特定语言模型（如CXR-BERT）进行微调，并提出一种新后处理技术BBM来提高定位精度。

Result: 生成式扩散模型显著超越现有判别模型，其mIoU分数是后者的两倍。BBM进一步提高了文字和图像偏差的对齐，使定位精度更高。

Conclusion: 生成式方法被确立为医学影像领域短语定位任务的更有效范式，推动了临床应用的可解释性与稳健性发展。

Abstract: Phrase grounding, i.e., mapping natural language phrases to specific image
regions, holds significant potential for disease localization in medical
imaging through clinical reports. While current state-of-the-art methods rely
on discriminative, self-supervised contrastive models, we demonstrate that
generative text-to-image diffusion models, leveraging cross-attention maps, can
achieve superior zero-shot phrase grounding performance. Contrary to prior
assumptions, we show that fine-tuning diffusion models with a frozen,
domain-specific language model, such as CXR-BERT, substantially outperforms
domain-agnostic counterparts. This setup achieves remarkable improvements, with
mIoU scores doubling those of current discriminative methods. These findings
highlight the underexplored potential of generative models for phrase grounding
tasks. To further enhance performance, we introduce Bimodal Bias Merging (BBM),
a novel post-processing technique that aligns text and image biases to identify
regions of high certainty. BBM refines cross-attention maps, achieving even
greater localization accuracy. Our results establish generative approaches as a
more effective paradigm for phrase grounding in the medical imaging domain,
paving the way for more robust and interpretable applications in clinical
practice. The source code and model weights are available at
https://github.com/Felix-012/generate_to_ground.

</details>


### [64] [Calisthenics Skills Temporal Video Segmentation](https://arxiv.org/abs/2507.12245)
*Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 本文探讨如何通过视频分析实现对静态健身技能的时间段分割，这有助于运动员训练及比赛评分，并提出了一个基准数据集和方法。


<details>
  <summary>Details</summary>
Motivation: 为实现对健身技能的自动化评估，研究提供一个数据集及方法来识别和分割视频中的静态健身技能时间段。

Method: 创建了一个含有运动员表演的静态健身技能视频数据集，并提供了时间段注释；同时提出了一个基准算法以处理视频分割问题。

Result: 验证了提出的问题具有可行性，尽管当前方法还有改进空间。

Conclusion: 本文为静态健身技能的自动化时间段分割提供了初步研究，未来发展潜力明显。

Abstract: Calisthenics is a fast-growing bodyweight discipline that consists of
different categories, one of which is focused on skills. Skills in calisthenics
encompass both static and dynamic elements performed by athletes. The
evaluation of static skills is based on their difficulty level and the duration
of the hold. Automated tools able to recognize isometric skills from a video by
segmenting them to estimate their duration would be desirable to assist
athletes in their training and judges during competitions. Although the video
understanding literature on action recognition through body pose analysis is
rich, no previous work has specifically addressed the problem of calisthenics
skill temporal video segmentation. This study aims to provide an initial step
towards the implementation of automated tools within the field of Calisthenics.
To advance knowledge in this context, we propose a dataset of video footage of
static calisthenics skills performed by athletes. Each video is annotated with
a temporal segmentation which determines the extent of each skill. We hence
report the results of a baseline approach to address the problem of skill
temporal segmentation on the proposed dataset. The results highlight the
feasibility of the proposed problem, while there is still room for improvement.

</details>


### [65] [Comparative Analysis of CNN Performance in Keras, PyTorch and JAX on PathMNIST](https://arxiv.org/abs/2507.12248)
*Anida Nezović,Jalal Romano,Nada Marić,Medina Kapo,Amila Akagić*

Main category: cs.CV

TL;DR: 本文通过PathMNIST数据集，比较Keras, PyTorch和JAX在医疗图像分类中的性能。


<details>
  <summary>Details</summary>
Motivation: 探索不同深度学习框架在医疗成像领域的表现，弥补其比较研究的不足。

Method: 使用卷积神经网络（CNN）在PathMNIST数据集上的模型开发，评估训练效率、分类精度与推理速度。

Result: 研究发现这些框架在计算速度和模型精度之间存在权衡，为实际应用提供参考。

Conclusion: 为医学图像分析领域的研究人员与实践者提供了深度学习框架选择的有价值洞见。

Abstract: Deep learning has significantly advanced the field of medical image
classification, particularly with the adoption of Convolutional Neural Networks
(CNNs). Various deep learning frameworks such as Keras, PyTorch and JAX offer
unique advantages in model development and deployment. However, their
comparative performance in medical imaging tasks remains underexplored. This
study presents a comprehensive analysis of CNN implementations across these
frameworks, using the PathMNIST dataset as a benchmark. We evaluate training
efficiency, classification accuracy and inference speed to assess their
suitability for real-world applications. Our findings highlight the trade-offs
between computational speed and model accuracy, offering valuable insights for
researchers and practitioners in medical image analysis.

</details>


### [66] [FADE: Adversarial Concept Erasure in Flow Models](https://arxiv.org/abs/2507.12283)
*Zixuan Fu,Yan Ren,Finn Carter,Chenyue Wang,Ze Niu,Dacheng Yu,Emily Davis,Bo Zhang*

Main category: cs.CV

TL;DR: 提出一种名为FADE的新方法，用于从文本到图像的扩散模型中擦除特定概念，同时保持模型的生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在隐私和公平性方面的风险问题，例如记住敏感概念或延续偏见。

Method: FADE将轨迹感知微调策略与对抗目标结合，实现可靠擦除特定概念，同时保留整体模型性能，并通过理论证明其可以最小化模型输出与被擦除概念之间的互信息。

Result: 在Stable Diffusion和FLUX上的实验中，FADE在概念移除性能和图像质量上超越了现有的最新基线方法，如ESD、UCE、MACE和ANT，并且在概念移除与保真度的调和平均值指标上提升了5-10%。

Conclusion: FADE设立了安全和公平生成建模的新标准，通过不从头重新训练的方法去除特定概念。

Abstract: Diffusion models have demonstrated remarkable image generation capabilities,
but also pose risks in privacy and fairness by memorizing sensitive concepts or
perpetuating biases. We propose a novel \textbf{concept erasure} method for
text-to-image diffusion models, designed to remove specified concepts (e.g., a
private individual or a harmful stereotype) from the model's generative
repertoire. Our method, termed \textbf{FADE} (Fair Adversarial Diffusion
Erasure), combines a trajectory-aware fine-tuning strategy with an adversarial
objective to ensure the concept is reliably removed while preserving overall
model fidelity. Theoretically, we prove a formal guarantee that our approach
minimizes the mutual information between the erased concept and the model's
outputs, ensuring privacy and fairness. Empirically, we evaluate FADE on Stable
Diffusion and FLUX, using benchmarks from prior work (e.g., object, celebrity,
explicit content, and style erasure tasks from MACE). FADE achieves
state-of-the-art concept removal performance, surpassing recent baselines like
ESD, UCE, MACE, and ANT in terms of removal efficacy and image quality.
Notably, FADE improves the harmonic mean of concept removal and fidelity by
5--10\% over the best prior method. We also conduct an ablation study to
validate each component of FADE, confirming that our adversarial and
trajectory-preserving objectives each contribute to its superior performance.
Our work sets a new standard for safe and fair generative modeling by
unlearning specified concepts without retraining from scratch.

</details>


### [67] [Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models](https://arxiv.org/abs/2507.12318)
*Samuel Lavoie,Michael Noukhovitch,Aaron Courville*

Main category: cs.CV

TL;DR: 该研究发现扩散模型成功的关键在于其输入条件，提出了一种名为DLC的新表示法，采用离散的图像标记以提高生成效果。


<details>
  <summary>Details</summary>
Motivation: 探索扩散模型条件表示对于生成高保真图片的重要性，并试图开发一种更具组合性和生成性的方法。

Method: 引入了基于Simplicial Embeddings的DLC，采用自监督学习目标训练，将其与扩散模型结合用于图像生成。

Result: 使用DLC的扩散模型在ImageNet数据集上实现了无条件图片生成的最新状态，并证明可以生成超出训练分布以外的图片。

Conclusion: DLC不仅提高了生成的保真度，还通过其组合性使生成模型能够超越训练数据分布，同时支持更高效的文本生成图像任务。

Abstract: We argue that diffusion models' success in modeling complex distributions is,
for the most part, coming from their input conditioning. This paper
investigates the representation used to condition diffusion models from the
perspective that ideal representations should improve sample fidelity, be easy
to generate, and be compositional to allow out-of-training samples generation.
We introduce Discrete Latent Code (DLC), an image representation derived from
Simplicial Embeddings trained with a self-supervised learning objective. DLCs
are sequences of discrete tokens, as opposed to the standard continuous image
embeddings. They are easy to generate and their compositionality enables
sampling of novel images beyond the training distribution. Diffusion models
trained with DLCs have improved generation fidelity, establishing a new
state-of-the-art for unconditional image generation on ImageNet. Additionally,
we show that composing DLCs allows the image generator to produce
out-of-distribution samples that coherently combine the semantics of images in
diverse ways. Finally, we showcase how DLCs can enable text-to-image generation
by leveraging large-scale pretrained language models. We efficiently finetune a
text diffusion language model to generate DLCs that produce novel samples
outside of the image generator training distribution.

</details>


### [68] [Efficient Calisthenics Skills Classification through Foreground Instance Selection and Depth Estimation](https://arxiv.org/abs/2507.12292)
*Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 提出一种基于计算机视觉的体操技能分类方法，直接利用深度估计和运动员区域提取绕过人体姿态估计模块，提升效率并缩短推理时间。


<details>
  <summary>Details</summary>
Motivation: 现有体操技能识别方法依赖于姿态估计算法，但计算成本高、推理时间长，不适合实时或移动设备应用。

Method: 通过结合Depth Anything V2进行深度估计及YOLOv10进行运动员定位，将主体从背景中分割出来，避免了高成本的人体姿态估计模块。

Result: 与基于骨架的方法相比，新方法推理速度提高了38.3倍，深度图分类准确率也有所提升（0.837 vs. 0.815）。

Conclusion: 该方法在效率、准确性及模块化设计上表现优异，为未来增强和实际应用提供了灵活性。

Abstract: Calisthenics skill classification is the computer vision task of inferring
the skill performed by an athlete from images, enabling automatic performance
assessment and personalized analytics. Traditional methods for calisthenics
skill recognition are based on pose estimation methods to determine the
position of skeletal data from images, which is later fed to a classification
algorithm to infer the performed skill. Despite the progress in human pose
estimation algorithms, they still involve high computational costs, long
inference times, and complex setups, which limit the applicability of such
approaches in real-time applications or mobile devices. This work proposes a
direct approach to calisthenics skill recognition, which leverages depth
estimation and athlete patch retrieval to avoid the computationally expensive
human pose estimation module. Using Depth Anything V2 for depth estimation and
YOLOv10 for athlete localization, we segment the subject from the background
rather than relying on traditional pose estimation techniques. This strategy
increases efficiency, reduces inference time, and improves classification
accuracy. Our approach significantly outperforms skeleton-based methods,
achieving 38.3x faster inference with RGB image patches and improved
classification accuracy with depth patches (0.837 vs. 0.815). Beyond these
performance gains, the modular design of our pipeline allows for flexible
replacement of components, enabling future enhancements and adaptation to
real-world applications.

</details>


### [69] [Cluster Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/2507.12359)
*Nikolaos Giakoumoglou,Tania Stathaki*

Main category: cs.CV

TL;DR: 本文介绍了一种新的无监督视觉表示学习方法Cluster Contrast (CueCo)，结合了对比学习和聚类的优势。


<details>
  <summary>Details</summary>
Motivation: 受近期进展的启发，旨在设计一种方法能够同时在特征空间中分散和对齐特征表示，提升视觉表示学习的效果。

Method: 采用两层神经网络作为查询网络和键网络，使用对比损失增强类间分离，结合聚类目标以增加类内紧凑性。键网络通过查询网络输出的慢速移动平均进行更新。

Result: 在CIFAR-10、CIFAR-100和ImageNet-100上，使用ResNet-18骨干网络进行线性评估分别达到了91.40%、68.56%和78.65%的top-1分类精度。

Conclusion: 通过结合对比学习和聚类，CueCo为无监督视觉表示学习开辟了新的研究方向。

Abstract: We introduce Cluster Contrast (CueCo), a novel approach to unsupervised
visual representation learning that effectively combines the strengths of
contrastive learning and clustering methods. Inspired by recent advancements,
CueCo is designed to simultaneously scatter and align feature representations
within the feature space. This method utilizes two neural networks, a query and
a key, where the key network is updated through a slow-moving average of the
query outputs. CueCo employs a contrastive loss to push dissimilar features
apart, enhancing inter-class separation, and a clustering objective to pull
together features of the same cluster, promoting intra-class compactness. Our
method achieves 91.40% top-1 classification accuracy on CIFAR-10, 68.56% on
CIFAR-100, and 78.65% on ImageNet-100 using linear evaluation with a ResNet-18
backbone. By integrating contrastive learning with clustering, CueCo sets a new
direction for advancing unsupervised visual representation learning.

</details>


### [70] [Unsupervised Monocular 3D Keypoint Discovery from Multi-View Diffusion Priors](https://arxiv.org/abs/2507.12336)
*Subin Jeon,In Cho,Junyoung Hong,Seon Joo Kim*

Main category: cs.CV

TL;DR: 本文提出KeyDiff3D框架，无监督实现单目3D关键点估计，通过单幅图像准确预测3D关键点。


<details>
  <summary>Details</summary>
Motivation: 解决以往方法需要昂贵的人工注释或多视角图像的问题，通过单视图图像实现单目3D关键点估计。

Method: 利用预训练的多视角扩散模型嵌入的几何先验，生成多视角图像作为监督信号，并通过扩散模型的2D特征构建3D特征体。

Result: 在多个数据集（如Human3.6M, Stanford Dogs等）上验证，表明方法在精度、泛化性及实现单图像生成3D对象操控方面效果显著。

Conclusion: KeyDiff3D在无需昂贵数据的情况下有效实现高精度3D关键点估计与单图像生成的3D对象操控，展现出广泛的潜力。

Abstract: This paper introduces KeyDiff3D, a framework for unsupervised monocular 3D
keypoints estimation that accurately predicts 3D keypoints from a single image.
While previous methods rely on manual annotations or calibrated multi-view
images, both of which are expensive to collect, our method enables monocular 3D
keypoints estimation using only a collection of single-view images. To achieve
this, we leverage powerful geometric priors embedded in a pretrained multi-view
diffusion model. In our framework, this model generates multi-view images from
a single image, serving as a supervision signal to provide 3D geometric cues to
our model. We also use the diffusion model as a powerful 2D multi-view feature
extractor and construct 3D feature volumes from its intermediate
representations. This transforms implicit 3D priors learned by the diffusion
model into explicit 3D features. Beyond accurate keypoints estimation, we
further introduce a pipeline that enables manipulation of 3D objects generated
by the diffusion model. Experimental results on diverse aspects and datasets,
including Human3.6M, Stanford Dogs, and several in-the-wild and out-of-domain
datasets, highlight the effectiveness of our method in terms of accuracy,
generalization, and its ability to enable manipulation of 3D objects generated
by the diffusion model from a single image.

</details>


### [71] [Improving Lightweight Weed Detection via Knowledge Distillation](https://arxiv.org/abs/2507.12344)
*Ahmet Oğuz Saltık,Max Voigt,Sourav Modak,Mike Beckworth,Anthony Stein*

Main category: cs.CV

TL;DR: 本文探讨了在精细农业中提升轻量级模型性能以实现实时智能喷洒的技术，提出通过通道知识蒸馏（CWD）和掩码生成蒸馏（MGD）方法实现改进。


<details>
  <summary>Details</summary>
Motivation: 提升轻量级模型在资源受限平台上的性能，从而实现精准农业中的实时杂草检测和分类，同时降低环境影响。

Method: 利用YOLO11x作为教师模型，YOLO11n作为参考和学生模型，采用CWD与MGD两种知识蒸馏方法进行模型优化，评估其对糖用甜菜农作物及四种杂草类型的检测性能提升。

Result: 实验表明，CWD和MGD均显著提高了学生模型的mAP50表现，CWD提升2.5%，MGD提升1.9%。此外，验证了学生模型在嵌入式设备上的部署性能，其具有较好的实时性和性能稳定性。

Conclusion: CWD和MGD是提高深度学习杂草检测精度的有效、实用方法，特别是在资源受限场景中的精细农业和植物表型应用中具备显著优势。

Abstract: Weed detection is a critical component of precision agriculture, facilitating
targeted herbicide application and reducing environmental impact. However,
deploying accurate object detection models on resource-limited platforms
remains challenging, particularly when differentiating visually similar weed
species commonly encountered in plant phenotyping applications. In this work,
we investigate Channel-wise Knowledge Distillation (CWD) and Masked Generative
Distillation (MGD) to enhance the performance of lightweight models for
real-time smart spraying systems. Utilizing YOLO11x as the teacher model and
YOLO11n as both reference and student, both CWD and MGD effectively transfer
knowledge from the teacher to the student model. Our experiments, conducted on
a real-world dataset comprising sugar beet crops and four weed types (Cirsium,
Convolvulus, Fallopia, and Echinochloa), consistently show increased AP50
across all classes. The distilled CWD student model achieves a notable
improvement of 2.5% and MGD achieves 1.9% in mAP50 over the baseline without
increasing model complexity. Additionally, we validate real-time deployment
feasibility by evaluating the student YOLO11n model on Jetson Orin Nano and
Raspberry Pi 5 embedded devices, performing five independent runs to evaluate
performance stability across random seeds. These findings confirm CWD and MGD
as an effective, efficient, and practical approach for improving deep
learning-based weed detection accuracy in precision agriculture and plant
phenotyping scenarios.

</details>


### [72] [AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models](https://arxiv.org/abs/2507.12414)
*Santosh Vasa,Aditi Ramadwar,Jnana Rama Krishna Darabattula,Md Zafar Anwar,Stanislaw Antol,Andrei Vatavu,Thomas Monninger,Sihao Ding*

Main category: cs.CV

TL;DR: 本文提出了AutoVDC框架，利用视觉语言模型（VLMs）自动识别视觉数据集中的错误标注，以提高数据质量，并通过实验验证了其在自动驾驶数据集中的错误检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统数据集的人工标注存在不完善之处，人工复核大数据集工作量大且成本高，亟需一种高效的自动化方法来提高数据质量。

Method: 提出了AutoVDC框架，结合视觉语言模型（VLMs）自动检测数据集中的错误标注。通过在公开数据集KITTI和nuImages中注入人为错误测试其检测率，并比较不同VLMs的效果与微调影响。

Result: 实验显示AutoVDC在错误检测和数据清理任务中表现优异，具有显著提升大规模生产数据集可靠性和准确性的潜力。

Conclusion: AutoVDC框架有效提升了视觉数据集的清理效率与质量，尤其适用于自动驾驶领域的大规模数据处理。

Abstract: Training of autonomous driving systems requires extensive datasets with
precise annotations to attain robust performance. Human annotations suffer from
imperfections, and multiple iterations are often needed to produce high-quality
datasets. However, manually reviewing large datasets is laborious and
expensive. In this paper, we introduce AutoVDC (Automated Vision Data Cleaning)
framework and investigate the utilization of Vision-Language Models (VLMs) to
automatically identify erroneous annotations in vision datasets, thereby
enabling users to eliminate these errors and enhance data quality. We validate
our approach using the KITTI and nuImages datasets, which contain object
detection benchmarks for autonomous driving. To test the effectiveness of
AutoVDC, we create dataset variants with intentionally injected erroneous
annotations and observe the error detection rate of our approach. Additionally,
we compare the detection rates using different VLMs and explore the impact of
VLM fine-tuning on our pipeline. The results demonstrate our method's high
performance in error detection and data cleaning experiments, indicating its
potential to significantly improve the reliability and accuracy of large-scale
production datasets in autonomous driving.

</details>


### [73] [QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval](https://arxiv.org/abs/2507.12416)
*Jaehyun Kwak,Ramahdani Muhammad Izaaz Inhar,Se-Young Yun,Sung-Ju Lee*

Main category: cs.CV

TL;DR: 提出了Query-Relevant Retrieval through Hard Negative Sampling (QuRe)方法来优化复合图像检索（CIR）性能，特别是在用户满意度方面。


<details>
  <summary>Details</summary>
Motivation: 现有的CIR方法主要关注目标图像的检索，但忽略了其他图像的相关性，这可能因为对比学习中过多的假负例影响模型表现。

Method: 提出了QuRe模型，该模型通过优化奖励目标减少假负例，结合一种硬负采样策略，以提高检索的相关性。

Result: QuRe在FashionIQ和CIRR数据集上实现了最先进的性能，并在人类偏好对齐的数据集HP-FashionIQ上表现出最佳表现。

Conclusion: 通过减少假负例并引入新的硬负采样策略，QuRe显著提升了CIR任务的性能，同时更好地对齐用户偏好。

Abstract: Composed Image Retrieval (CIR) retrieves relevant images based on a reference
image and accompanying text describing desired modifications. However, existing
CIR methods only focus on retrieving the target image and disregard the
relevance of other images. This limitation arises because most methods
employing contrastive learning-which treats the target image as positive and
all other images in the batch as negatives-can inadvertently include false
negatives. This may result in retrieving irrelevant images, reducing user
satisfaction even when the target image is retrieved. To address this issue, we
propose Query-Relevant Retrieval through Hard Negative Sampling (QuRe), which
optimizes a reward model objective to reduce false negatives. Additionally, we
introduce a hard negative sampling strategy that selects images positioned
between two steep drops in relevance scores following the target image, to
effectively filter false negatives. In order to evaluate CIR models on their
alignment with human satisfaction, we create Human-Preference FashionIQ
(HP-FashionIQ), a new dataset that explicitly captures user preferences beyond
target retrieval. Extensive experiments demonstrate that QuRe achieves
state-of-the-art performance on FashionIQ and CIRR datasets while exhibiting
the strongest alignment with human preferences on the HP-FashionIQ dataset. The
source code is available at https://github.com/jackwaky/QuRe.

</details>


### [74] [Text-driven Multiplanar Visual Interaction for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2507.12382)
*Kaiwen Huang,Yi Zhou,Huazhu Fu,Yizhe Zhang,Chen Gong,Tao Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的基于文本驱动的多平面视觉交互框架，用于半监督医学图像分割，显著提升了视觉特征并优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 探索使用文本数据增强3D医学图像任务的视觉语义嵌入，以降低数据标注成本。

Method: 提出Text-SemiSeg框架，包括文本增强多平面表示（TMR）、类别感知语义对齐（CSA）和动态认知增强（DCA）三大模块，加强文本和视觉特征的交互与对齐，同时改进有监督和半监督数据的分布一致性。

Result: 在三个公共数据集上进行实验，证明该模型利用文本信息显著提升了视觉特征，并在效果上优于现有方法。

Conclusion: 该研究验证了文本信息在增强视觉语义理解中的潜力，为半监督医学图像分割提供了新的思路和解决方案。

Abstract: Semi-supervised medical image segmentation is a crucial technique for
alleviating the high cost of data annotation. When labeled data is limited,
textual information can provide additional context to enhance visual semantic
understanding. However, research exploring the use of textual data to enhance
visual semantic embeddings in 3D medical imaging tasks remains scarce. In this
paper, we propose a novel text-driven multiplanar visual interaction framework
for semi-supervised medical image segmentation (termed Text-SemiSeg), which
consists of three main modules: Text-enhanced Multiplanar Representation (TMR),
Category-aware Semantic Alignment (CSA), and Dynamic Cognitive Augmentation
(DCA). Specifically, TMR facilitates text-visual interaction through planar
mapping, thereby enhancing the category awareness of visual features. CSA
performs cross-modal semantic alignment between the text features with
introduced learnable variables and the intermediate layer of visual features.
DCA reduces the distribution discrepancy between labeled and unlabeled data
through their interaction, thus improving the model's robustness. Finally,
experiments on three public datasets demonstrate that our model effectively
enhances visual features with textual information and outperforms other
methods. Our code is available at https://github.com/taozh2017/Text-SemiSeg.

</details>


### [75] [OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments](https://arxiv.org/abs/2507.12396)
*Hayat Ullah,Abbas Khan,Arslan Munir,Hari Kalva*

Main category: cs.CV

TL;DR: 本文引入了两个用于监控图像视觉分析的基准数据集OD-VIRAT Large和OD-VIRAT Tiny，并评测了多个先进目标检测架构在复杂背景下的性能。


<details>
  <summary>Details</summary>
Motivation: 传统监控数据集欠缺真实和多样性，难以全面评估目标检测模型在复杂环境中的性能，影响安全监控系统的开发。

Method: 提出两个基准数据集OD-VIRAT Large和OD-VIRAT Tiny，分别包含599,996张图片中的870万标注实例及19,860张图片中的28.89万标注实例，并评估了多个目标检测模型在不同复杂情况下的表现。

Result: OD-VIRAT数据集涵盖10种人类监控场景，评测了RETMDET、YOLOX等最新检测架构在复杂背景和小目标下的检测能力，为模型性能研究提供基准。

Conclusion: 这一研究提出的基准数据集和分析框架将促进更高效和健壮的目标检测架构的发展，为解决监控图像中复杂问题提供了重要参考。

Abstract: Realistic human surveillance datasets are crucial for training and evaluating
computer vision models under real-world conditions, facilitating the
development of robust algorithms for human and human-interacting object
detection in complex environments. These datasets need to offer diverse and
challenging data to enable a comprehensive assessment of model performance and
the creation of more reliable surveillance systems for public safety. To this
end, we present two visual object detection benchmarks named OD-VIRAT Large and
OD-VIRAT Tiny, aiming at advancing visual understanding tasks in surveillance
imagery. The video sequences in both benchmarks cover 10 different scenes of
human surveillance recorded from significant height and distance. The proposed
benchmarks offer rich annotations of bounding boxes and categories, where
OD-VIRAT Large has 8.7 million annotated instances in 599,996 images and
OD-VIRAT Tiny has 288,901 annotated instances in 19,860 images. This work also
focuses on benchmarking state-of-the-art object detection architectures,
including RETMDET, YOLOX, RetinaNet, DETR, and Deformable-DETR on this object
detection-specific variant of VIRAT dataset. To the best of our knowledge, it
is the first work to examine the performance of these recently published
state-of-the-art object detection architectures on realistic surveillance
imagery under challenging conditions such as complex backgrounds, occluded
objects, and small-scale objects. The proposed benchmarking and experimental
settings will help in providing insights concerning the performance of selected
object detection models and set the base for developing more efficient and
robust object detection architectures.

</details>


### [76] [InterpIoU: Rethinking Bounding Box Regression with Interpolation-Based IoU Optimization](https://arxiv.org/abs/2507.12420)
*Haoyuan Liu,Hiroshi Watanabe*

Main category: cs.CV

TL;DR: 提出了一种新的回归损失函数InterpIoU，通过对插值框和目标框的IoU进行计算，取代了传统的几何惩罚。实验结果表明，该方法在小物体检测任务上表现显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有IoU损失函数通过人工设计的几何惩罚克服非重叠情况下IoU不可导的问题，但这些方法对检测框的形状和分布过于敏感，且在小目标检测上表现欠佳，甚至可能导致目标框异常放大。

Method: 提出了InterpIoU，通过对预测框和目标框之间的插值框的IoU计算取代人工设计的几何惩罚，并进一步提出Dynamic InterpIoU，动态调整插值系数以增强适应性。

Result: 在COCO、VisDrone和PASCAL VOC数据集上，InterpIoU及其改进方法在多种检测框架中均表现出优越的性能，尤其在小目标检测中提升明显。

Conclusion: 设计的IoU本身是理想的回归目标，现有的几何惩罚既是多余的也是不优的，提出的InterpIoU和Dynamic InterpIoU有效提高了目标检测的性能，尤其是小目标检测。

Abstract: Bounding box regression (BBR) is fundamental to object detection, where the
regression loss is crucial for accurate localization. Existing IoU-based losses
often incorporate handcrafted geometric penalties to address IoU's
non-differentiability in non-overlapping cases and enhance BBR performance.
However, these penalties are sensitive to box shape, size, and distribution,
often leading to suboptimal optimization for small objects and undesired
behaviors such as bounding box enlargement due to misalignment with the IoU
objective. To address these limitations, we propose InterpIoU, a novel loss
function that replaces handcrafted geometric penalties with a term based on the
IoU between interpolated boxes and the target. By using interpolated boxes to
bridge the gap between predictions and ground truth, InterpIoU provides
meaningful gradients in non-overlapping cases and inherently avoids the box
enlargement issue caused by misaligned penalties. Simulation results further
show that IoU itself serves as an ideal regression target, while existing
geometric penalties are both unnecessary and suboptimal. Building on InterpIoU,
we introduce Dynamic InterpIoU, which dynamically adjusts interpolation
coefficients based on IoU values, enhancing adaptability to scenarios with
diverse object distributions. Experiments on COCO, VisDrone, and PASCAL VOC
show that our methods consistently outperform state-of-the-art IoU-based losses
across various detection frameworks, with particularly notable improvements in
small object detection, confirming their effectiveness.

</details>


### [77] [Interpreting Radiologist's Intention from Eye Movements in Chest X-ray Diagnosis](https://arxiv.org/abs/2507.12461)
*Trong-Thang Pham,Anh Nguyen,Zhigang Deng,Carol C. Wu,Hien Van Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: 本文提出了一种深度学习模型RadGazeIntent，用于捕捉放射科医生在观察医学影像时的意图，通过变换注视数据的时空特征来预测他们的诊断行为。


<details>
  <summary>Details</summary>
Motivation: 现有模型无法捕捉放射科医生注视的意图，但医生在解读影像时有特定的目标并按照心中清单系统性搜索，这种行为解析对建模有巨大意义。

Method: 提出RadGazeIntent模型，使用基于Transformer的架构，将注视数据的时空特征转化为诊断意图的表征，同时创建了基于意图标签划分的三个子数据集，用于学习意图驱动的行为模式。

Result: 实验结果表明，RadGazeIntent模型在所有意图标签数据集上均优于基线方法，并能够准确预测放射科医生在特定时间的诊断目标。

Conclusion: RadGazeIntent成功捕捉了医生注视行为背后的诊断意图，对理解医疗图像解读过程及增强诊断支持系统具有重要价值。

Abstract: Radiologists rely on eye movements to navigate and interpret medical images.
A trained radiologist possesses knowledge about the potential diseases that may
be present in the images and, when searching, follows a mental checklist to
locate them using their gaze. This is a key observation, yet existing models
fail to capture the underlying intent behind each fixation. In this paper, we
introduce a deep learning-based approach, RadGazeIntent, designed to model this
behavior: having an intention to find something and actively searching for it.
Our transformer-based architecture processes both the temporal and spatial
dimensions of gaze data, transforming fine-grained fixation features into
coarse, meaningful representations of diagnostic intent to interpret
radiologists' goals. To capture the nuances of radiologists' varied
intention-driven behaviors, we process existing medical eye-tracking datasets
to create three intention-labeled subsets: RadSeq (Systematic Sequential
Search), RadExplore (Uncertainty-driven Exploration), and RadHybrid (Hybrid
Pattern). Experimental results demonstrate RadGazeIntent's ability to predict
which findings radiologists are examining at specific moments, outperforming
baseline methods across all intention-labeled datasets.

</details>


### [78] [DVFL-Net: A Lightweight Distilled Video Focal Modulation Network for Spatio-Temporal Action Recognition](https://arxiv.org/abs/2507.12426)
*Hayat Ullah,Muhammad Ali Shafique,Abbas Khan,Arslan Munir*

Main category: cs.CV

TL;DR: 提出了一种高效的视频识别模型DVFL-Net，通过知识蒸馏和空间-时间特征调制，实现了性能与效率的平衡，适合实时应用。


<details>
  <summary>Details</summary>
Motivation: Transformer在视频识别中虽然表现出色，但计算成本高，无法满足实时和设备端应用需求，因此需要一种轻量化解决方案。

Method: DVFL-Net利用从预训练教师模型到紧凑学生模型的知识蒸馏，以及时空焦点调制，有效转移信息。特别是使用前向KL散度量化知识迁移效果。

Result: DVFL-Net在多个基准数据集上表现优越，低内存占用、减少计算量(GFLOPs)、同时维持精确性。

Conclusion: DVFL-Net是一种适合实时应用的视频识别模型，能够高效利用资源并保持高性能。

Abstract: The landscape of video recognition has evolved significantly, shifting from
traditional Convolutional Neural Networks (CNNs) to Transformer-based
architectures for improved accuracy. While 3D CNNs have been effective at
capturing spatiotemporal dynamics, recent Transformer models leverage
self-attention to model long-range spatial and temporal dependencies. Despite
achieving state-of-the-art performance on major benchmarks, Transformers remain
computationally expensive, particularly with dense video data. To address this,
we propose a lightweight Video Focal Modulation Network, DVFL-Net, which
distills spatiotemporal knowledge from a large pre-trained teacher into a
compact nano student model, enabling efficient on-device deployment. DVFL-Net
utilizes knowledge distillation and spatial-temporal feature modulation to
significantly reduce computation while preserving high recognition performance.
We employ forward Kullback-Leibler (KL) divergence alongside spatio-temporal
focal modulation to effectively transfer both local and global context from the
Video-FocalNet Base (teacher) to the proposed VFL-Net (student). We evaluate
DVFL-Net on UCF50, UCF101, HMDB51, SSV2, and Kinetics-400, benchmarking it
against recent state-of-the-art methods in Human Action Recognition (HAR).
Additionally, we conduct a detailed ablation study analyzing the impact of
forward KL divergence. The results confirm the superiority of DVFL-Net in
achieving an optimal balance between performance and efficiency, demonstrating
lower memory usage, reduced GFLOPs, and strong accuracy, making it a practical
solution for real-time HAR applications.

</details>


### [79] [Traffic-Aware Pedestrian Intention Prediction](https://arxiv.org/abs/2507.12433)
*Fahimeh Orvati Nia,Hai Lin*

Main category: cs.CV

TL;DR: 提出了TA-STGCN模型，将动态交通信号和场景语境整合到行人意图预测中，比基线模型在PIE数据集上提高了4.75%的预测准确率。


<details>
  <summary>Details</summary>
Motivation: 目前模型未充分考虑动态交通信号与场景语境信息，限制了真实场景中的应用效果。

Method: 提出了交通感知时空图卷积网络（TA-STGCN），结合动态交通信号状态和边界框大小，捕获复杂城市环境中的时空依赖。

Result: 在PIE数据集上，TA-STGCN模型提高了行人意图预测准确率4.75%。

Conclusion: TA-STGCN在整合交通信号及场景信息方面有效提升了准确性，为自动驾驶安全导航提供支持。

Abstract: Accurate pedestrian intention estimation is crucial for the safe navigation
of autonomous vehicles (AVs) and hence attracts a lot of research attention.
However, current models often fail to adequately consider dynamic traffic
signals and contextual scene information, which are critical for real-world
applications. This paper presents a Traffic-Aware Spatio-Temporal Graph
Convolutional Network (TA-STGCN) that integrates traffic signs and their states
(Red, Yellow, Green) into pedestrian intention prediction. Our approach
introduces the integration of dynamic traffic signal states and bounding box
size as key features, allowing the model to capture both spatial and temporal
dependencies in complex urban environments. The model surpasses existing
methods in accuracy. Specifically, TA-STGCN achieves a 4.75% higher accuracy
compared to the baseline model on the PIE dataset, demonstrating its
effectiveness in improving pedestrian intention prediction.

</details>


### [80] [Describe Anything Model for Visual Question Answering on Text-rich Images](https://arxiv.org/abs/2507.12441)
*Yen-Linh Vu,Dinh-Thang Duong,Truong-Binh Duong,Anh-Khoi Nguyen,Thanh-Huy Nguyen,Le Thien Phuc Nguyen,Jianhua Xing,Xingjian Li,Tianyang Wang,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: 提出DAM-QA框架，利用Describe Anything Model (DAM) 的区域描述能力提升视觉问答（VQA）任务的表现，在文本密集的图像场景中表现出众。


<details>
  <summary>Details</summary>
Motivation: 作者认为DAM的区域描述能力能有效提升VQA任务中特别是处理文本密集图像场景的表现，因此设计了一个利用DAM改进VQA的框架。

Method: 引入DAM-QA框架，结合专门的评估协议，利用DAM的区域感知能力，设计机制从多区域视角聚合答案，加强基于文本信息的推理能力。

Result: 在六个VQA基准上，DAM-QA均明显优于基础DAM模型，在DocVQA数据集上得分提高了7+。此外，DAM-QA在参数更少的情况下性能超过其他区域感知模型，与强大的通用视觉语言模型的差距显著缩小。

Conclusion: DAM-QA框架展示了DAM模型在处理文本密集图像和广泛VQA任务中的潜力，结合有效的整合策略能进一步提升表现。

Abstract: Recent progress has been made in region-aware vision-language modeling,
particularly with the emergence of the Describe Anything Model (DAM). DAM is
capable of generating detailed descriptions of any specific image areas or
objects without the need for additional localized image-text alignment
supervision. We hypothesize that such region-level descriptive capability is
beneficial for the task of Visual Question Answering (VQA), especially in
challenging scenarios involving images with dense text. In such settings, the
fine-grained extraction of textual information is crucial to producing correct
answers. Motivated by this, we introduce DAM-QA, a framework with a tailored
evaluation protocol, developed to investigate and harness the region-aware
capabilities from DAM for the text-rich VQA problem that requires reasoning
over text-based information within images. DAM-QA incorporates a mechanism that
aggregates answers from multiple regional views of image content, enabling more
effective identification of evidence that may be tied to text-related elements.
Experiments on six VQA benchmarks show that our approach consistently
outperforms the baseline DAM, with a notable 7+ point gain on DocVQA. DAM-QA
also achieves the best overall performance among region-aware models with fewer
parameters, significantly narrowing the gap with strong generalist VLMs. These
results highlight the potential of DAM-like models for text-rich and broader
VQA tasks when paired with efficient usage and integration strategies. Our code
is publicly available at https://github.com/Linvyl/DAM-QA.git.

</details>


### [81] [Vision-based Perception for Autonomous Vehicles in Obstacle Avoidance Scenarios](https://arxiv.org/abs/2507.12449)
*Van-Hoang-Anh Phan,Chi-Tam Nguyen,Doan-Trung Au,Thanh-Danh Phan,Minh-Thien Duong,My-Ha Le*

Main category: cs.CV

TL;DR: 本文提出了一种仅使用相机的高效障碍物规避系统，结合YOLOv11和深度估计模型以实现障碍检测和处理，并通过大学校园点测试其有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在改进基于相机的感知和路径规划系统，提升无人驾驶车辆在复杂环境中的安全性与导航能力。

Method: 论文中使用YOLOv11进行对象检测，并结合Depth Anything V2等深度估计模型了解目标距离，同时基于Frenet-Pure Pursuit方法进行路径规划。

Result: 通过大学校园内的多种场景测试，验证了此系统快速识别障碍、规划路径的有效性和鲁棒性。

Conclusion: 通过采取先进的视觉感知与规划技术，该系统展示了高效处理障碍物及改善自主导航能力的潜力。

Abstract: Obstacle avoidance is essential for ensuring the safety of autonomous
vehicles. Accurate perception and motion planning are crucial to enabling
vehicles to navigate complex environments while avoiding collisions. In this
paper, we propose an efficient obstacle avoidance pipeline that leverages a
camera-only perception module and a Frenet-Pure Pursuit-based planning
strategy. By integrating advancements in computer vision, the system utilizes
YOLOv11 for object detection and state-of-the-art monocular depth estimation
models, such as Depth Anything V2, to estimate object distances. A comparative
analysis of these models provides valuable insights into their accuracy,
efficiency, and robustness in real-world conditions. The system is evaluated in
diverse scenarios on a university campus, demonstrating its effectiveness in
handling various obstacles and enhancing autonomous navigation. The video
presenting the results of the obstacle avoidance experiments is available at:
https://www.youtube.com/watch?v=FoXiO5S_tA8

</details>


### [82] [Mitigating Object Hallucinations via Sentence-Level Early Intervention](https://arxiv.org/abs/2507.12455)
*Shangpin Peng,Senqiao Yang,Li Jiang,Zhuotao Tian*

Main category: cs.CV

TL;DR: 提出了一种名为SENTINEL的新框架，通过句子级的早期干预显著减少跨模态大模型的幻想问题，效果显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决跨模态大语言模型中存在的幻想问题，现有方法往往成本高或与数据分布存在不匹配，为此本文提出无需依赖人工注释的新方法。

Method: 设计SENTINEL框架，首先通过模型输出迭代采样及开放词汇检测器交叉验证获取高质量偏好对，然后构建上下文感知的偏好数据，并用偏好损失函数强化训练模型，以句子级别减轻幻想问题。

Result: SENTINEL在幻想问题上显著改进，将幻想减少90%以上，并在相关基准测试中优于目前最先进的方法，同时展现出较好的泛化能力。

Conclusion: SENTINEL展示出减少幻想问题的高效性和优越性，为跨模态模型的进一步发展提供了有力支持。

Abstract: Multimodal large language models (MLLMs) have revolutionized cross-modal
understanding but continue to struggle with hallucinations - fabricated content
contradicting visual inputs. Existing hallucination mitigation methods either
incur prohibitive computational costs or introduce distribution mismatches
between training data and model outputs. We identify a critical insight:
hallucinations predominantly emerge at the early stages of text generation and
propagate through subsequent outputs. To address this, we propose **SENTINEL**
(**S**entence-level **E**arly i**N**tervention **T**hrough **IN**-domain
pr**E**ference **L**earning), a framework that eliminates dependency on human
annotations. Specifically, we first bootstrap high-quality in-domain preference
pairs by iteratively sampling model outputs, validating object existence
through cross-checking with two open-vocabulary detectors, and classifying
sentences into hallucinated/non-hallucinated categories. Subsequently, we use
context-coherent positive samples and hallucinated negative samples to build
context-aware preference data iteratively. Finally, we train models using a
context-aware preference loss (C-DPO) that emphasizes discriminative learning
at the sentence level where hallucinations initially manifest. Experimental
results show that SENTINEL can reduce hallucinations by over 90\% compared to
the original model and outperforms the previous state-of-the-art method on both
hallucination benchmarks and general capabilities benchmarks, demonstrating its
superiority and generalization ability. The models, datasets, and code are
available at https://github.com/pspdada/SENTINEL.

</details>


### [83] [SpatialTrackerV2: 3D Point Tracking Made Easy](https://arxiv.org/abs/2507.12462)
*Yuxi Xiao,Jianyuan Wang,Nan Xue,Nikita Karaev,Yuri Makarov,Bingyi Kang,Xing Zhu,Hujun Bao,Yujun Shen,Xiaowei Zhou*

Main category: cs.CV

TL;DR: SpatialTrackerV2是一种针对单目视频的前馈式3D点跟踪方法，能够高效准确地完成3D点跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有3D点跟踪方法依赖模块化管道，本研究希望设计一种高性能的端到端解决方案，整合点跟踪、单目深度和相机姿态估计。

Method: 提出的SpatialTrackerV2方法通过场景几何、相机自运动和像素级物体运动的分解，构建一个完全可微的端到端架构。其训练数据涵盖广泛数据集（包括合成序列、RGB-D视频和未标注片段）。

Result: SpatialTrackerV2相比现有3D跟踪方法性能提升30%，并在动态3D重建中匹敌当前领先方法，速度提升50倍。

Conclusion: 该方法有效地整合了几何与运动学习，提供了一个高效、可扩展的3D点跟踪解决方案，适用于多种数据场景。

Abstract: We present SpatialTrackerV2, a feed-forward 3D point tracking method for
monocular videos. Going beyond modular pipelines built on off-the-shelf
components for 3D tracking, our approach unifies the intrinsic connections
between point tracking, monocular depth, and camera pose estimation into a
high-performing and feedforward 3D point tracker. It decomposes world-space 3D
motion into scene geometry, camera ego-motion, and pixel-wise object motion,
with a fully differentiable and end-to-end architecture, allowing scalable
training across a wide range of datasets, including synthetic sequences, posed
RGB-D videos, and unlabeled in-the-wild footage. By learning geometry and
motion jointly from such heterogeneous data, SpatialTrackerV2 outperforms
existing 3D tracking methods by 30%, and matches the accuracy of leading
dynamic 3D reconstruction approaches while running 50$\times$ faster.

</details>


### [84] [MMHU: A Massive-Scale Multimodal Benchmark for Human Behavior Understanding](https://arxiv.org/abs/2507.12463)
*Renjie Li,Ruijie Ye,Mingyang Wu,Hao Frank Yang,Zhiwen Fan,Hezhen Hu,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 提出了一个名为MMHU的大规模基准数据集用于自动驾驶中人类行为分析，涵盖丰富注释并提供广泛任务的评估套件。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏全面的评估基准来理解自动驾驶中人类行为的重要性。

Method: 设计了MMHU基准数据集，包括57k条人类运动片段和1.73M帧数据，结合人类参与的注释流程，涵盖运动、轨迹、意图等全面标签，完成多项任务基准测试。

Result: 该数据集通过丰富的注释和广泛的任务测试，为多任务行为理解提供了强大的评估能力。

Conclusion: MMHU数据集可推进自动驾驶情景下人类行为的深入研究，促进安全驾驶系统的开发。

Abstract: Humans are integral components of the transportation ecosystem, and
understanding their behaviors is crucial to facilitating the development of
safe driving systems. Although recent progress has explored various aspects of
human behavior$\unicode{x2014}$such as motion, trajectories, and
intention$\unicode{x2014}$a comprehensive benchmark for evaluating human
behavior understanding in autonomous driving remains unavailable. In this work,
we propose $\textbf{MMHU}$, a large-scale benchmark for human behavior analysis
featuring rich annotations, such as human motion and trajectories, text
description for human motions, human intention, and critical behavior labels
relevant to driving safety. Our dataset encompasses 57k human motion clips and
1.73M frames gathered from diverse sources, including established driving
datasets such as Waymo, in-the-wild videos from YouTube, and self-collected
data. A human-in-the-loop annotation pipeline is developed to generate rich
behavior captions. We provide a thorough dataset analysis and benchmark
multiple tasks$\unicode{x2014}$ranging from motion prediction to motion
generation and human behavior question answering$\unicode{x2014}$thereby
offering a broad evaluation suite. Project page :
https://MMHU-Benchmark.github.io.

</details>


### [85] [CytoSAE: Interpretable Cell Embeddings for Hematology](https://arxiv.org/abs/2507.12464)
*Muhammed Furkan Dasdelen,Hyesu Lim,Michele Buck,Katharina S. Götze,Carsten Marr,Steffen Schneider*

Main category: cs.CV

TL;DR: 本文提出了一个名为CytoSAE的稀疏自编码器(SAE)，并将其应用于血液学领域以解读医学成像模型，具有良好的可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏自编码器已在语言模型和视觉模型中展示出潜力，但在医学成像模型中缺乏相关的解释方法。本研究希望填补这一空白，并验证其在血液学中的适用性。

Method: 提出并设计了CytoSAE，一种稀疏自编码器，利用超过4万张血液单细胞图像进行训练，并测试其在多种数据集及领域中的泛化能力。

Result: CytoSAE验证了形态学相关的概念，通过医学专家确认了其有效性。此外，其成功生成了患者及疾病特定的概念，用于检测异常病理细胞，并在AML亚型分类任务中达到了领域内先进的性能水平。

Conclusion: CytoSAE不仅能提供精确的疾病分类性能，还能在亚细胞水平上实现可解释性，为医学图像分析和疾病检测提供了一个有前景的工具。

Abstract: Sparse autoencoders (SAEs) emerged as a promising tool for mechanistic
interpretability of transformer-based foundation models. Very recently, SAEs
were also adopted for the visual domain, enabling the discovery of visual
concepts and their patch-wise attribution to tokens in the transformer model.
While a growing number of foundation models emerged for medical imaging, tools
for explaining their inferences are still lacking. In this work, we show the
applicability of SAEs for hematology. We propose CytoSAE, a sparse autoencoder
which is trained on over 40,000 peripheral blood single-cell images. CytoSAE
generalizes to diverse and out-of-domain datasets, including bone marrow
cytology, where it identifies morphologically relevant concepts which we
validated with medical experts. Furthermore, we demonstrate scenarios in which
CytoSAE can generate patient-specific and disease-specific concepts, enabling
the detection of pathognomonic cells and localized cellular abnormalities at
the patch level. We quantified the effect of concepts on a patient-level AML
subtype classification task and show that CytoSAE concepts reach performance
comparable to the state-of-the-art, while offering explainability on the
sub-cellular level. Source code and model weights are available at
https://github.com/dynamical-inference/cytosae.

</details>


### [86] [PhysX: Physical-Grounded 3D Asset Generation](https://arxiv.org/abs/2507.12465)
*Ziang Cao,Zhaoxi Chen,Linag Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: PhysX提出了一个物理基础的3D生成范式，融合物理属性以提升逼真性和应用性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D生成多集中于几何和纹理，忽视物理属性，限制了其在物理域应用中的潜力。

Method: 引入物理标注的3D数据集PhysXNet，并提出物理感知的图像到3D生成框架PhysXGen，采用双分支结构结合物理知识和3D结构。

Result: 实验验证了提出框架在生成物理感知的3D资产方面的优越性和通用性。

Conclusion: PhysX为生成物理感知的3D资产提供了一种端到端的解决方案，有助于未来生成物理AI研究。

Abstract: 3D modeling is moving from virtual to physical. Existing 3D generation
primarily emphasizes geometries and textures while neglecting physical-grounded
modeling. Consequently, despite the rapid development of 3D generative models,
the synthesized 3D assets often overlook rich and important physical
properties, hampering their real-world application in physical domains like
simulation and embodied AI. As an initial attempt to address this challenge, we
propose \textbf{PhysX}, an end-to-end paradigm for physical-grounded 3D asset
generation. 1) To bridge the critical gap in physics-annotated 3D datasets, we
present PhysXNet - the first physics-grounded 3D dataset systematically
annotated across five foundational dimensions: absolute scale, material,
affordance, kinematics, and function description. In particular, we devise a
scalable human-in-the-loop annotation pipeline based on vision-language models,
which enables efficient creation of physics-first assets from raw 3D assets.2)
Furthermore, we propose \textbf{PhysXGen}, a feed-forward framework for
physics-grounded image-to-3D asset generation, injecting physical knowledge
into the pre-trained 3D structural space. Specifically, PhysXGen employs a
dual-branch architecture to explicitly model the latent correlations between 3D
structures and physical properties, thereby producing 3D assets with plausible
physical predictions while preserving the native geometry quality. Extensive
experiments validate the superior performance and promising generalization
capability of our framework. All the code, data, and models will be released to
facilitate future research in generative physical AI.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [87] [Subjective Evaluation Profile Analysis of Science Fiction Short Stories and its Critical-Theoretical Significance](https://arxiv.org/abs/2507.11582)
*Kazuyoshi Otsuka*

Main category: cs.CL

TL;DR: 本研究借助大型语言模型（LLMs）分析文学评估中的美学偏好和模式，发现模型之间和故事之间的评价显著差异。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在文学评估中的主观性及其评价模式。

Method: 对10篇日本科幻短篇小说翻译评估，采用主成分分析和聚类技术分析不同LLMs的评价一致性和模式，并采取7次会话设计以减少外部偏差。

Result: 发现LLMs存在显著评价一致性差异（α从1到0.35），以及五种不同的评估模式，各LLMs使用独特的评价词汇表。

Conclusion: LLMs在文学评估中可能具有类似于人类批评流派的个性化评价特征，而非中立评估工具。

Abstract: This study positions large language models (LLMs) as "subjective literary
critics" to explore aesthetic preferences and evaluation patterns in literary
assessment. Ten Japanese science fiction short stories were translated into
English and evaluated by six state-of-the-art LLMs across seven independent
sessions. Principal component analysis and clustering techniques revealed
significant variations in evaluation consistency ({\alpha} ranging from 1.00 to
0.35) and five distinct evaluation patterns. Additionally, evaluation variance
across stories differed by up to 4.5-fold, with TF-IDF analysis confirming
distinctive evaluation vocabularies for each model. Our seven-session
within-day protocol using an original Science Fiction corpus strategically
minimizes external biases, allowing us to observe implicit value systems shaped
by RLHF and their influence on literary judgment. These findings suggest that
LLMs may possess individual evaluation characteristics similar to human
critical schools, rather than functioning as neutral benchmarkers.

</details>


### [88] [MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering](https://arxiv.org/abs/2507.11625)
*Varun Srivastava,Fan Lei,Srija Mukhopadhyay,Vivek Gupta,Ross Maciejewski*

Main category: cs.CL

TL;DR: 构建了一个名为MapIQ的数据集研究三种类型地图的问答问题，并测试了多模态大模型（MLLMs）的表现及其对地图设计变化的敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有关于Map-VQA的研究主要集中在有限的地图类别（如等值线图），不能全面覆盖更多种类的地图类型和视觉分析任务。

Method: 引入包含14,706个问答数据对的MapIQ数据集，涵盖三种地图类型和六个主题；通过六个视觉分析任务评估多种MLLM性能，并研究地图设计变化对性能的影响。

Result: 实验表明：各种MLLM之间存在性能差异，人类基准依然优于MLLM，地图设计变化显著影响模型性能，加强地图设计可提高模型表现。

Conclusion: MLLMs在Map-VQA任务上存在潜在改进空间，改进的地图设计和内部地理知识的增强能提升模型效果。

Abstract: Recent advancements in multimodal large language models (MLLMs) have driven
researchers to explore how well these models read data visualizations, e.g.,
bar charts, scatter plots. More recently, attention has shifted to visual
question answering with maps (Map-VQA). However, Map-VQA research has primarily
focused on choropleth maps, which cover only a limited range of thematic
categories and visual analytical tasks. To address these gaps, we introduce
MapIQ, a benchmark dataset comprising 14,706 question-answer pairs across three
map types: choropleth maps, cartograms, and proportional symbol maps spanning
topics from six distinct themes (e.g., housing, crime). We evaluate multiple
MLLMs using six visual analytical tasks, comparing their performance against
one another and a human baseline. An additional experiment examining the impact
of map design changes (e.g., altered color schemes, modified legend designs,
and removal of map elements) provides insights into the robustness and
sensitivity of MLLMs, their reliance on internal geographic knowledge, and
potential avenues for improving Map-VQA performance.

</details>


### [89] [Cross-lingual Few-shot Learning for Persian Sentiment Analysis with Incremental Adaptation](https://arxiv.org/abs/2507.11634)
*Farideh Majidi,Ziaeddin Beheshtifard*

Main category: cs.CL

TL;DR: 本研究探讨了通过少样本学习和增量学习在波斯语中的跨语言情感分析，取得了96%的准确率。


<details>
  <summary>Details</summary>
Motivation: 开发一种能在有限波斯语数据基础上，借助高资源语言知识进行情感分析的模型。

Method: 采用三种多语言预训练模型（XLM-RoBERTa、mDeBERTa 和 DistilBERT），通过少样本学习和增量学习对多种来源的小规模波斯语数据进行微调。

Result: mDeBERTa 和 XLM-RoBERTa 在波斯语情感分析中表现优异，达到了96%的精度。

Conclusion: 结合少样本学习、增量学习与多语言预训练模型的方法能够有效提高波斯语情感分析的性能。

Abstract: This research examines cross-lingual sentiment analysis using few-shot
learning and incremental learning methods in Persian. The main objective is to
develop a model capable of performing sentiment analysis in Persian using
limited data, while getting prior knowledge from high-resource languages. To
achieve this, three pre-trained multilingual models (XLM-RoBERTa, mDeBERTa, and
DistilBERT) were employed, which were fine-tuned using few-shot and incremental
learning approaches on small samples of Persian data from diverse sources,
including X, Instagram, Digikala, Snappfood, and Taaghche. This variety enabled
the models to learn from a broad range of contexts. Experimental results show
that the mDeBERTa and XLM-RoBERTa achieved high performances, reaching 96%
accuracy on Persian sentiment analysis. These findings highlight the
effectiveness of combining few-shot learning and incremental learning with
multilingual pre-trained models.

</details>


### [90] [Partitioner Guided Modal Learning Framework](https://arxiv.org/abs/2507.11661)
*Guimin Hu,Yi Xin,Lijie Hu,Zhihong Zhu,Hasti Seifi*

Main category: cs.CL

TL;DR: 本文提出了PgM框架，通过划分和学习单模态和配对模态特征，实现了多模态领域的更高效学习与应用。


<details>
  <summary>Details</summary>
Motivation: 在多模态学习中，如何有效区分和利用单模态与配对模态特征是一个关键挑战。本文提出PgM框架，旨在更全面和灵活地学习与应用这些特征。

Method: 提出一个框架即PgM，包括模态划分器、单模态学习器、配对模态学习器以及单-配对模态解码器，以区分并专注于单模态和配对模态的学习和重建。

Result: 在四个多模态任务上验证了PgM的有效性，并展现了其在其他现有模型上的迁移能力。此外，论文还可视化了相关特征分布，分析了它们对任务的贡献。

Conclusion: PgM提供了对单模态和配对模态特征的全面学习、灵活调整及不同学习速率的支持，在多模态任务和模型迁移中均表现出色。

Abstract: Multimodal learning benefits from multiple modal information, and each
learned modal representations can be divided into uni-modal that can be learned
from uni-modal training and paired-modal features that can be learned from
cross-modal interaction. Building on this perspective, we propose a
partitioner-guided modal learning framework, PgM, which consists of the modal
partitioner, uni-modal learner, paired-modal learner, and uni-paired modal
decoder. Modal partitioner segments the learned modal representation into
uni-modal and paired-modal features. Modal learner incorporates two dedicated
components for uni-modal and paired-modal learning. Uni-paired modal decoder
reconstructs modal representation based on uni-modal and paired-modal features.
PgM offers three key benefits: 1) thorough learning of uni-modal and
paired-modal features, 2) flexible distribution adjustment for uni-modal and
paired-modal representations to suit diverse downstream tasks, and 3) different
learning rates across modalities and partitions. Extensive experiments
demonstrate the effectiveness of PgM across four multimodal tasks and further
highlight its transferability to existing models. Additionally, we visualize
the distribution of uni-modal and paired-modal features across modalities and
tasks, offering insights into their respective contributions.

</details>


### [91] [ExpliCIT-QA: Explainable Code-Based Image Table Question Answering](https://arxiv.org/abs/2507.11694)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Pedro Alonso Doval,Jorge Alcalde Vesteiro,Héctor Cerezo-Costas*

Main category: cs.CL

TL;DR: 提出了一种名为ExpliCIT-QA的系统，扩展自MRT方法，用于处理表格问答，包括复杂的表格图像并提供可解释的答案。


<details>
  <summary>Details</summary>
Motivation: 解决表格问答中复杂表格图像理解与可解释性问题，加强透明度和可审计性以适用于敏感领域。

Method: 开发了一个多模块系统，包括：多模态表格理解、基于语言的推理、自动代码生成与执行、以及自然语言解释，提供逐步推理和结果解读。

Result: 在TableVQA-Bench基准上测试，证明其在可解释性和透明性上优于现有方法。

Conclusion: ExpliCIT-QA在提高解释能力和保证审计透明度上表现良好，为在敏感领域的应用提供了可能性。

Abstract: We present ExpliCIT-QA, a system that extends our previous MRT approach for
tabular question answering into a multimodal pipeline capable of handling
complex table images and providing explainable answers. ExpliCIT-QA follows a
modular design, consisting of: (1) Multimodal Table Understanding, which uses a
Chain-of-Thought approach to extract and transform content from table images;
(2) Language-based Reasoning, where a step-by-step explanation in natural
language is generated to solve the problem; (3) Automatic Code Generation,
where Python/Pandas scripts are created based on the reasoning steps, with
feedback for handling errors; (4) Code Execution to compute the final answer;
and (5) Natural Language Explanation that describes how the answer was
computed. The system is built for transparency and auditability: all
intermediate outputs, parsed tables, reasoning steps, generated code, and final
answers are available for inspection. This strategy works towards closing the
explainability gap in end-to-end TableVQA systems. We evaluated ExpliCIT-QA on
the TableVQA-Bench benchmark, comparing it with existing baselines. We
demonstrated improvements in interpretability and transparency, which open the
door for applications in sensitive domains like finance and healthcare where
auditing results are critical.

</details>


### [92] [CRABS: A syntactic-semantic pincer strategy for bounding LLM interpretation of Python notebooks](https://arxiv.org/abs/2507.11742)
*Meng Li,Timothy M. McPhillips,Dingmin Wang,Shin-Rong Tsai,Bertram Ludäscher*

Main category: cs.CL

TL;DR: 本文提出一种名为CRABS的新方法，通过LLM结合浅层语法分析解决Python笔记本的数据流和依赖性解析问题，并在50个Kaggle笔记本数据集上取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 当前，大型语言模型（LLMs）虽然在理解代码时表现出色，但依然难以全面理解现实中的笔记本代码，尤其是在面对上下文较长或出错情况时。因此，本文试图解决这些问题，促进对笔记本信息流和操作的精确解析。

Method: 提出一种名为Capture and Resolve Assisted Bounding Strategy (CRABS)的方法，通过浅层语法分析与抽象语法树解析协助LLM理解笔记本，从而在单元格级别上实现数据输入输出集的精确识别。

Result: 在50个包含共3454个单元格输入输出的Kaggle笔记本数据集上，模型在解决语法分析后的不确定性方面达到了98%的正确率。同时，CRABS平均在单元格信息流识别中的F1分数为98%，在传递性单元依赖性识别中的F1分数为99%。

Conclusion: CRABS方法有效结合了浅层语法分析与LLM的优势，为对Python笔记本的解析、复用及适配提供了一种可行且精确的新途径。

Abstract: Recognizing the information flows and operations comprising data science and
machine learning Python notebooks is critical for evaluating, reusing, and
adapting notebooks for new tasks. Investigating a notebook via re-execution
often is impractical due to the challenges of resolving data and software
dependencies. While Large Language Models (LLMs) pre-trained on large codebases
have demonstrated effectiveness in understanding code without running it, we
observe that they fail to understand some realistic notebooks due to
hallucinations and long-context challenges. To address these issues, we propose
a notebook understanding task yielding an information flow graph and
corresponding cell execution dependency graph for a notebook, and demonstrate
the effectiveness of a pincer strategy that uses limited syntactic analysis to
assist full comprehension of the notebook using an LLM. Our Capture and Resolve
Assisted Bounding Strategy (CRABS) employs shallow syntactic parsing and
analysis of the abstract syntax tree (AST) to capture the correct
interpretation of a notebook between lower and upper estimates of the
inter-cell I/O sets, then uses an LLM to resolve remaining ambiguities via
cell-by-cell zero-shot learning, thereby identifying the true data inputs and
outputs of each cell. We evaluate and demonstrate the effectiveness of our
approach using an annotated dataset of 50 representative, highly up-voted
Kaggle notebooks that together represent 3454 actual cell inputs and outputs.
The LLM correctly resolves 1397 of 1425 (98%) ambiguities left by analyzing the
syntactic structure of these notebooks. Across 50 notebooks, CRABS achieves
average F1 scores of 98% identifying cell-to-cell information flows and 99%
identifying transitive cell execution dependencies.

</details>


### [93] [AI Wizards at CheckThat! 2025: Enhancing Transformer-Based Embeddings with Sentiment for Subjectivity Detection in News Articles](https://arxiv.org/abs/2507.11764)
*Matteo Fasulo,Luca Babboni,Luca Tedeschini*

Main category: cs.CL

TL;DR: 本论文介绍AI Wizards团队参与CLEF 2025 CheckThat！检测实验室任务1，探讨新闻文章的主观性检测，包括单语、多语言和无监督环境下的分类方法。


<details>
  <summary>Details</summary>
Motivation: 研究不同语言环境下检测主观/客观分类模型的表现，并提升模型的准确性与普适性，特别是针对未见语言的泛化能力。

Method: 提出一种增强Transformer分类器的方法，将辅助模型生成的情感分数整合入句子表示中，并结合mDeBERTaV3-base、ModernBERT-base (英文)、Llama3.2-1B等模型，同时通过针对开发集优化的决策阈值校准来应对类别不平衡问题。

Result: 通过情感特征的整合显著提升了性能，尤其在主观性F1分数上表现突出。例如，在希腊语上取得了排名第一的成绩（宏平均F1=0.51）。

Conclusion: 情感特征整合和优化的决策阈值对于不同语言的主观性检测模型有效，特别在任务中展示了强大的泛化能力。

Abstract: This paper presents AI Wizards' participation in the CLEF 2025 CheckThat! Lab
Task 1: Subjectivity Detection in News Articles, classifying sentences as
subjective/objective in monolingual, multilingual, and zero-shot settings.
Training/development datasets were provided for Arabic, German, English,
Italian, and Bulgarian; final evaluation included additional unseen languages
(e.g., Greek, Romanian, Polish, Ukrainian) to assess generalization. Our
primary strategy enhanced transformer-based classifiers by integrating
sentiment scores, derived from an auxiliary model, with sentence
representations, aiming to improve upon standard fine-tuning. We explored this
sentiment-augmented architecture with mDeBERTaV3-base, ModernBERT-base
(English), and Llama3.2-1B. To address class imbalance, prevalent across
languages, we employed decision threshold calibration optimized on the
development set. Our experiments show sentiment feature integration
significantly boosts performance, especially subjective F1 score. This
framework led to high rankings, notably 1st for Greek (Macro F1 = 0.51).

</details>


### [94] [Tracing Facts or just Copies? A critical investigation of the Competitions of Mechanisms in Large Language Models](https://arxiv.org/abs/2507.11809)
*Dante Campregher,Yanxu Chen,Sander Hoffman,Maria Heuss*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型如何处理事实与反事实信息之间的竞争，聚焦于注意力头的作用，并复现了三项相关研究的发现。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLMs）在面对矛盾性事实与反事实信息时注意力机制的作用，并验证和整合已有研究的成果。

Method: 通过机制可解释性工具，研究注意力头的强度与事实输出比例的关系，评估注意力头的抑制机制假设，并分析注意力模式的领域特异性。

Result: 发现关注事实输出的注意力头使用的是通用的复制抑制机制，而非选择性地抑制反事实。此外，注意力头的行为表现出领域依赖性，大型模型具有更专业化和类别敏感的模式。

Conclusion: 研究深化了对LLMs中注意力头的机制理解，为模型的解释性和性能提升提供了方向。

Abstract: This paper presents a reproducibility study examining how Large Language
Models (LLMs) manage competing factual and counterfactual information, focusing
on the role of attention heads in this process. We attempt to reproduce and
reconcile findings from three recent studies by Ortu et al., Yu, Merullo, and
Pavlick and McDougall et al. that investigate the competition between
model-learned facts and contradictory context information through Mechanistic
Interpretability tools. Our study specifically examines the relationship
between attention head strength and factual output ratios, evaluates competing
hypotheses about attention heads' suppression mechanisms, and investigates the
domain specificity of these attention patterns. Our findings suggest that
attention heads promoting factual output do so via general copy suppression
rather than selective counterfactual suppression, as strengthening them can
also inhibit correct facts. Additionally, we show that attention head behavior
is domain-dependent, with larger models exhibiting more specialized and
category-sensitive patterns.

</details>


### [95] [ILID: Native Script Language Identification for Indian Languages](https://arxiv.org/abs/2507.11832)
*Yash Ingle,Pruthwik Mishra*

Main category: cs.CL

TL;DR: 开发了一个230K句子的用于语言识别的数据集，包括英语和22种印度语，并构建了高性能的基线模型。


<details>
  <summary>Details</summary>
Motivation: 语言识别是自然语言处理的重要前置步骤，但在处理噪音短文本和代码混合等复杂环境中表现困难，尤其是处理具有相似性但同时存在差异的印度语言。

Method: 创建了一个多语言数据集，并使用机器学习和深度学习方法开发了一系列基线模型。

Result: 所开发的数据集是新的，基线模型在语言识别任务中达到与最先进模型相当的性能。

Conclusion: 本文的数据集和模型提供了对语言识别领域的有力支持，为进一步研究奠定了基础。

Abstract: The language identification task is a crucial fundamental step in NLP. Often
it serves as a pre-processing step for widely used NLP applications such as
multilingual machine translation, information retrieval, question and
answering, and text summarization. The core challenge of language
identification lies in distinguishing languages in noisy, short, and code-mixed
environments. This becomes even harder in case of diverse Indian languages that
exhibit lexical and phonetic similarities, but have distinct differences. Many
Indian languages share the same script making the task even more challenging.
In this paper, we release a dataset of 230K sentences consisting of English and
all 22 official Indian languages labeled with their language identifiers where
data in most languages are newly created. We also develop and release robust
baseline models using state-of-the-art approaches in machine learning and deep
learning that can aid the research in this field. Our baseline models are
comparable to the state-of-the-art models for the language identification task.

</details>


### [96] [Your LLM Knows the Future: Uncovering Its Multi-Token Prediction Potential](https://arxiv.org/abs/2507.11851)
*Mohammad Samragh,Arnav Kundu,David Harrison,Kumari Nishu,Devang Naik,Minsik Cho,Mehrdad Farajtabar*

Main category: cs.CL

TL;DR: 本论文提出了一种新框架，在保留传统自回归语言模型质量的前提下，通过预测多个后续token显著提高生成速度和并行度。


<details>
  <summary>Details</summary>
Motivation: 传统自回归语言模型因序列生成限制存在推理速度慢、并行性差的问题，尤其是在后期生成阶段。

Method: 本方法包括：(1)基于公共前缀的masked输入预测多token；(2)基于门控LoRA的模型改进以支持多token预测；(3)轻量可学习采样器，生成连贯序列；(4)多种辅助训练损失以保证生成一致性和准确性；(5)采用推测生成策略以高保真度快速扩展token。

Result: 在保证质量的基础上，该方法在代码和数学生成中速度提升近5倍，在普通对话与知识任务中提升约2.5倍。

Conclusion: 该框架通过高效的技术创新实现了自回归语言模型的速度提升和并行性改进，未来生成更高效。

Abstract: Autoregressive language models are constrained by their inherently sequential
nature, generating one token at a time. This paradigm limits inference speed
and parallelism, especially during later stages of generation when the
direction and semantics of text are relatively certain. In this work, we
propose a novel framework that leverages the inherent knowledge of vanilla
autoregressive language models about future tokens, combining techniques to
realize this potential and enable simultaneous prediction of multiple
subsequent tokens. Our approach introduces several key innovations: (1) a
masked-input formulation where multiple future tokens are jointly predicted
from a common prefix; (2) a gated LoRA formulation that preserves the original
LLM's functionality, while equipping it for multi-token prediction; (3) a
lightweight, learnable sampler module that generates coherent sequences from
the predicted future tokens; (4) a set of auxiliary training losses, including
a consistency loss, to enhance the coherence and accuracy of jointly generated
tokens; and (5) a speculative generation strategy that expands tokens
quadratically in the future while maintaining high fidelity. Our method
achieves significant speedups through supervised fine-tuning on pretrained
models. For example, it generates code and math nearly 5x faster, and improves
general chat and knowledge tasks by almost 2.5x. These gains come without any
loss in quality.

</details>


### [97] [Cross-Domain Transfer and Few-Shot Learning for Personal Identifiable Information Recognition](https://arxiv.org/abs/2507.11862)
*Junhong Ye,Xu Yuan,Xinying Qiu*

Main category: cs.CL

TL;DR: 本研究探讨了跨领域模型迁移、多领域数据融合及样本高效学习在PII识别中的效果，证明领域间迁移及数据融合的影响很大且领域依赖性高。


<details>
  <summary>Details</summary>
Motivation: PII识别是文本匿名化中的核心问题。本研究旨在探索如何通过先进的迁移学习和数据融合方法提高识别准确性。

Method: 基于医疗、法律和传记文本数据集进行实验，评估领域内表现、跨领域迁移、数据融合及少样本学习对PII识别的影响。

Result: 实验显示，法律领域数据对传记领域迁移效果好，而医疗领域不容易迁移。融合效益具领域特异性，仅10%的低专业领域数据即可实现高质量识别。

Conclusion: 跨领域迁移与数据融合的效果依赖于特定领域，少样本学习显现潜力，为PII识别提供有效解决途径。

Abstract: Accurate recognition of personally identifiable information (PII) is central
to automated text anonymization. This paper investigates the effectiveness of
cross-domain model transfer, multi-domain data fusion, and sample-efficient
learning for PII recognition. Using annotated corpora from healthcare (I2B2),
legal (TAB), and biography (Wikipedia), we evaluate models across four
dimensions: in-domain performance, cross-domain transferability, fusion, and
few-shot learning. Results show legal-domain data transfers well to
biographical texts, while medical domains resist incoming transfer. Fusion
benefits are domain-specific, and high-quality recognition is achievable with
only 10% of training data in low-specialization domains.

</details>


### [98] [COLA-GEC: A Bidirectional Framework for Enhancing Grammatical Acceptability and Error Correction](https://arxiv.org/abs/2507.11867)
*Xiangyu Yang,Xinying Qiu*

Main category: cs.CL

TL;DR: 引入COLA-GEC双向框架，通过相互知识传递增强语法错误校正和语法可接受性判断。在多语言基准测试中达成当前最佳结果，同时分析指出标点符号错误校正的挑战。


<details>
  <summary>Details</summary>
Motivation: 语法错误校正（GEC）和语法可接受性判断（COLA）共享语法知识，但独立发展。本研究旨在整合两者的优势，增强彼此效果。

Method: 通过引入COLA-GEC双向框架：1. 利用GEC数据集改进语法可接受性模型；2. 在GEC模型训练中加入动态损失函数，增强校正的语法正确性。

Result: 提出的框架在多语言基准测试中取得了当前最佳表现，同时分析出标点符号错误校正的挑战。

Conclusion: COLA-GEC框架通过互相知识转移提升了语法相关任务的性能，为未来的语法建模改进提供了有价值的分析和方向。

Abstract: Grammatical Error Correction (GEC) and grammatical acceptability judgment
(COLA) are core tasks in natural language processing, sharing foundational
grammatical knowledge yet typically evolving independently. This paper
introduces COLA-GEC, a novel bidirectional framework that enhances both tasks
through mutual knowledge transfer. First, we augment grammatical acceptability
models using GEC datasets, significantly improving their performance across
multiple languages. Second, we integrate grammatical acceptability signals into
GEC model training via a dynamic loss function, effectively guiding corrections
toward grammatically acceptable outputs. Our approach achieves state-of-the-art
results on several multilingual benchmarks. Comprehensive error analysis
highlights remaining challenges, particularly in punctuation error correction,
providing insights for future improvements in grammatical modeling.

</details>


### [99] [DualReward: A Dynamic Reinforcement Learning Framework for Cloze Tests Distractor Generation](https://arxiv.org/abs/2507.11875)
*Tianyou Huang,Xinglu Chen,Jingshen Zhang,Xinying Qiu,Ruiying Niu*

Main category: cs.CL

TL;DR: 论文提出了一种名为DualReward的新型强化学习框架，用于生成完形填空测试中的干扰项，通过双重奖励结构和自适应奖励伸缩机制实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖监督学习或静态生成模型，难以有效处理多样性和高质量干扰项生成的问题。

Method: 采用强化学习框架引入双重奖励机制，区分人类创造的金标准干扰项与模型生成的候选干扰项，并根据模型表现动态调整奖励信号强度。

Result: 在CLOTH-F和MCQ数据集上均表现出超越当前最先进方法的性能，特别是在多样性更高的跨域数据(MCQ)上有显著提升。

Conclusion: DualReward框架提供了一种平衡学习可靠人类示例与探索高质量新干扰项的灵活方法，并适用于不同类型和领域的测试生成。

Abstract: This paper introduces DualReward, a novel reinforcement learning framework
for automatic distractor generation in cloze tests. Unlike conventional
approaches that rely primarily on supervised learning or static generative
models, our method employs a dual reward structure with adaptive scaling that
differentiates between human-created gold standard distractors and
model-generated candidates. The framework dynamically adjusts reward signal
intensity based on model performance and confidence. We evaluate our approach
on both passage-level (CLOTH-F) and sentence-level (MCQ) cloze test datasets,
demonstrating consistent improvements over state-of-the-art baselines.
Experimental results show that our adaptive reward scaling mechanism provides
modest but consistent benefits on homogeneous datasets (CLOTH-F) and more
substantial improvements (3.48-3.86% in P@1) on diverse, cross-domain data
(MCQ), suggesting its particular effectiveness for handling varied question
types and domains. Our work offers a flexible framework that effectively
balances learning from reliable human examples while exploring novel,
high-quality distractors for automated test generation.

</details>


### [100] [LLMs Encode Harmfulness and Refusal Separately](https://arxiv.org/abs/2507.11878)
*Jiachen Zhao,Jing Huang,Zhengxuan Wu,David Bau,Weiyan Shi*

Main category: cs.CL

TL;DR: 該論文探討大型語言模型（LLMs）內部對「有害性」的理解與拒絕行為的關係，並提出了一種新方法「Latent Guard」來提高模型安全性。


<details>
  <summary>Details</summary>
Motivation: 分析LLMs內部對於有害性概念的理解，以揭示其拒絕行為背後的機制，並探索更穩健的安全機制。

Method: 通過發現和操控模型中的有害性方向，並驗證其與拒絕方向的區別，提出一種內在的安全機制「Latent Guard」，用來檢測不安全輸入並減少過度拒絕。

Result: 實驗表明LLMs的內部有害性表示在面對多種輸入指令時比拒絕決策更穩健，並且Latent Guard的性能與專門微調的安全模型相當甚至更好。

Conclusion: LLMs對有害性內部表示的理解提供了一種新的AI安全研究途徑，且利用這些內在表示可以有效改進現有的安全機制。

Abstract: LLMs are trained to refuse harmful instructions, but do they truly understand
harmfulness beyond just refusing? Prior work has shown that LLMs' refusal
behaviors can be mediated by a one-dimensional subspace, i.e., a refusal
direction. In this work, we identify a new dimension to analyze safety
mechanisms in LLMs, i.e., harmfulness, which is encoded internally as a
separate concept from refusal. There exists a harmfulness direction that is
distinct from the refusal direction. As causal evidence, steering along the
harmfulness direction can lead LLMs to interpret harmless instructions as
harmful, but steering along the refusal direction tends to elicit refusal
responses directly without reversing the model's judgment on harmfulness.
Furthermore, using our identified harmfulness concept, we find that certain
jailbreak methods work by reducing the refusal signals without reversing the
model's internal belief of harmfulness. We also find that adversarially
finetuning models to accept harmful instructions has minimal impact on the
model's internal belief of harmfulness. These insights lead to a practical
safety application: The model's latent harmfulness representation can serve as
an intrinsic safeguard (Latent Guard) for detecting unsafe inputs and reducing
over-refusals that is robust to finetuning attacks. For instance, our Latent
Guard achieves performance comparable to or better than Llama Guard 3 8B, a
dedicated finetuned safeguard model, across different jailbreak methods. Our
findings suggest that LLMs' internal understanding of harmfulness is more
robust than their refusal decision to diverse input instructions, offering a
new perspective to study AI safety

</details>


### [101] [Marco-Bench-MIF: On Multilingual Instruction-Following Capability of Large Language Models](https://arxiv.org/abs/2507.11882)
*Bo Zeng,Chenyang Lyu,Sinuo Liu,Mingyan Zeng,Minghao Wu,Xuanfan Ni,Tianqi Shi,Yu Zhao,Yefeng Liu,Chenyu Zhu,Ruizhe Li,Jiahui Geng,Qing Li,Yu Tong,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: 本文提出了一个面向多语言情境的指令跟随能力评测数据集Marco-Bench-MIF，填补了现有数据集在多语言和本地化场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有指令跟随评测数据集主要以英语为主或通过机器翻译扩展，这限制了其在多语言场景中的应用。

Method: 通过混合管道结合翻译与验证，生成一个覆盖30种语言的多语言指令跟随评测数据集，处理语言约束和文化背景问题。

Result: 对20+ LLMs进行了评估，发现高/低资源语言间的准确率差距为25-35%，模型规模影响性能且仍有语言脚本相关挑战，并且机器翻译数据的准确率较本地化数据低7-22%。

Conclusion: Marco-Bench-MIF揭示了多语言指令跟随中存在的挑战，并为后续研究提供了重要的基准。

Abstract: Instruction-following capability has become a major ability to be evaluated
for Large Language Models (LLMs). However, existing datasets, such as IFEval,
are either predominantly monolingual and centered on English or simply machine
translated to other languages, limiting their applicability in multilingual
contexts. In this paper, we present an carefully-curated extension of IFEval to
a localized multilingual version named Marco-Bench-MIF, covering 30 languages
with varying levels of localization. Our benchmark addresses linguistic
constraints (e.g., modifying capitalization requirements for Chinese) and
cultural references (e.g., substituting region-specific company names in
prompts) via a hybrid pipeline combining translation with verification. Through
comprehensive evaluation of 20+ LLMs on our Marco-Bench-MIF, we found that: (1)
25-35% accuracy gap between high/low-resource languages, (2) model scales
largely impact performance by 45-60% yet persists script-specific challenges,
and (3) machine-translated data underestimates accuracy by7-22% versus
localized data. Our analysis identifies challenges in multilingual instruction
following, including keyword consistency preservation and compositional
constraint adherence across languages. Our Marco-Bench-MIF is available at
https://github.com/AIDC-AI/Marco-Bench-MIF.

</details>


### [102] [A Survey of Deep Learning for Geometry Problem Solving](https://arxiv.org/abs/2507.11936)
*Jianzhe Ma,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: 该论文综述深度学习在几何问题求解中的应用，包括任务总结、方法回顾、评估分析及挑战与未来方向，并提供相关论文清单。


<details>
  <summary>Details</summary>
Motivation: 填补深度学习在几何问题求解领域应用综述的空白，推动该领域进一步发展。

Method: 通过全面文献综述，对几何问题求解相关任务、深度学习方法、评估标准及未来研究方向进行分析和总结。

Result: 总结了深度学习在几何问题求解中的方法、评价指标及其挑战，同时针对未来研究提出建议，并提供了相关研究论文的持续更新列表。

Conclusion: 论文为深度学习在几何问题求解领域提供了综合性和实用性的参考，促进了该领域的研究进展。

Abstract: Geometry problem solving is a key area of mathematical reasoning, which is
widely involved in many important fields such as education, mathematical
ability assessment of artificial intelligence, and multimodal ability
assessment. In recent years, the rapid development of deep learning technology,
especially the rise of multimodal large language models, has triggered a
widespread research boom. This paper provides a survey of the applications of
deep learning in geometry problem solving, including (i) a comprehensive
summary of the relevant tasks in geometry problem solving; (ii) a thorough
review of related deep learning methods; (iii) a detailed analysis of
evaluation metrics and methods; and (iv) a critical discussion of the current
challenges and future directions that can be explored. Our goal is to provide a
comprehensive and practical reference of deep learning for geometry problem
solving to promote further developments in this field. We create a continuously
updated list of papers on GitHub: https://github.com/majianz/dl4gps.

</details>


### [103] [POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering](https://arxiv.org/abs/2507.11939)
*Yichen Xu,Liangyu Chen,Liang Zhang,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: 此研究提出PolyChartQA，这是首个大规模多语言图表问答基准，包括22,606个图表和26,151个问答，覆盖10种语言。


<details>
  <summary>Details</summary>
Motivation: 现有图表理解基准过于以英语为中心，无法满足全球化需求。

Method: 采用分离式流水线，将图表数据与渲染代码分开，通过LLM翻译和严格质控生成多语言图表。

Result: 实现对多语言图表理解的系统性评估，并揭示不同语言间的性能差距，尤其是低资源语言表现较弱。

Conclusion: 此基准为开发全球化包容的视觉-语言模型奠定了基础。

Abstract: Charts are a universally adopted medium for interpreting and communicating
data. However, existing chart understanding benchmarks are predominantly
English-centric, limiting their accessibility and applicability to global
audiences. In this paper, we present PolyChartQA, the first large-scale
multilingual chart question answering benchmark covering 22,606 charts and
26,151 question-answering pairs across 10 diverse languages. PolyChartQA is
built using a decoupled pipeline that separates chart data from rendering code,
allowing multilingual charts to be flexibly generated by simply translating the
data and reusing the code. We leverage state-of-the-art LLM-based translation
and enforce rigorous quality control in the pipeline to ensure the linguistic
and semantic consistency of the generated multilingual charts. PolyChartQA
facilitates systematic evaluation of multilingual chart understanding.
Experiments on both open- and closed-source large vision-language models reveal
a significant performance gap between English and other languages, especially
low-resource ones with non-Latin scripts. This benchmark lays a foundation for
advancing globally inclusive vision-language models.

</details>


### [104] [BlockBPE: Parallel BPE Tokenization](https://arxiv.org/abs/2507.11941)
*Amos You*

Main category: cs.CL

TL;DR: 提出了BlockBPE，一个高效的GPU并行字节对编码实现，相比现有方法极大提升了高批量推理的吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有的字节对编码实现主要依赖CPU，性能在高批量推理中特别受限，因此需要一种优化的GPU实现方案。

Method: 通过取消正则表达式预处理，BlockBPE在GPU中实现了线程块内的高并行化Token合并，从而降低复杂度。

Result: 在高批量推理任务中，BlockBPE的吞吐量比OpenAI tiktoken高出2倍，比HuggingFace Tokenizers高出2.5倍。

Conclusion: BlockBPE通过优化预处理和并行化实现，为高批量推理任务提供了显著的速度提升，同时保持生成质量。

Abstract: Tokenization is a critical preprocessing step in large language model
pipelines, yet widely-used implementations remain CPU-bound and suboptimal for
batch inference workflows on GPU. We present BlockBPE, a parallel GPU
implementation of byte-pair encoding (BPE) that achieves near linear-time
complexity under realistic assumptions and is optimized for high-throughput,
batch inference. Unlike existing Rust-based tokenizers such as HuggingFace
Tokenizers or OpenAI's tiktoken-whose runtimes are dominated by Regex
pre-tokenization and exhibit $O(n \log n)$ runtime-BlockBPE eliminates the
Regex pre-tokenization which leads to small loss in generation quality, but
enables highly parallelized token merges within thread blocks, reducing overall
complexity to $O(nd)$ where $d \ll n$. On high-batch inference workloads,
BlockBPE achieves up to 2x higher throughput than tiktoken and 2.5x over
HuggingFace Tokenizers.

</details>


### [105] [DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression](https://arxiv.org/abs/2507.11942)
*Yi Zhao,Zuchao Li,Hai Zhao,Baoyuan Qi,Guoming Liu*

Main category: cs.CL

TL;DR: 本文提出了一种动态注意感知任务无关的提示压缩方法（DAC），用于在提示压缩过程中动态感知信息熵的变化，从而实现高效的提示压缩效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于信息熵的提示压缩方法忽视了注意力关键词和信息熵变化的动态特性，可能导致信息损失和压缩效果的不足。

Method: 通过结合信息熵和注意力信息，提出了一个能够动态感知信息熵变化的注意感知提示压缩算法，用于实现精细化的提示压缩。

Result: 在包括LongBench、GSM8K和BBH等多个领域的测试中，DAC在各种任务和LLM模型中都表现出了稳健且显著的改进效果。

Conclusion: 动态注意感知的提示压缩方法（DAC）在各类任务和模型表现上表现出色，验证了其有效性并提供了一种提高提示压缩效率的新方法。

Abstract: Task-agnostic prompt compression leverages the redundancy in natural language
to reduce computational overhead and enhance information density within
prompts, especially in long-context scenarios. Existing methods predominantly
rely on information entropy as the metric to compress lexical units, aiming to
achieve minimal information loss. However, these approaches overlook two
critical aspects: (i) the importance of attention-critical tokens at the
algorithmic level, and (ii) shifts in information entropy during the
compression process. Motivated by these challenges, we propose a dynamic
attention-aware approach for task-agnostic prompt compression (DAC). This
approach effectively integrates entropy and attention information, dynamically
sensing entropy shifts during compression to achieve fine-grained prompt
compression. Extensive experiments across various domains, including LongBench,
GSM8K, and BBH, show that DAC consistently yields robust and substantial
improvements across a diverse range of tasks and LLMs, offering compelling
evidence of its efficacy.

</details>


### [106] [IAM: Efficient Inference through Attention Mapping between Different-scale LLMs](https://arxiv.org/abs/2507.11953)
*Yi Zhao,Zuchao Li,Hai Zhao*

Main category: cs.CL

TL;DR: 提出了IAM框架，通过在小型和大型LLM之间执行注意力映射，实现了计算加速和KV缓存减少。


<details>
  <summary>Details</summary>
Motivation: 解决当前LLM在处理长上下文时的高资源消耗问题，以及现有效率优化方法未利用外部信息的局限性。

Method: 通过分析不同尺度LLM的注意力矩阵相似性，引入IAM框架进行注意力计算映射，从而优化性能。

Result: 实验表明IAM可将预填加速15%，KV缓存使用量减少22.1%，且不显著影响性能，并具有模型通用性和方法正交性。

Conclusion: IAM框架不仅提升了LLM的计算效率，还降低了存储开销，是现有优化工具的有益补充。

Abstract: LLMs encounter significant challenges in resource consumption nowadays,
especially with long contexts. Despite extensive efforts dedicate to enhancing
inference efficiency, these methods primarily exploit internal sparsity within
the models, without leveraging external information for optimization. We
identify the high similarity of attention matrices across different-scale LLMs,
which offers a novel perspective for optimization. We first conduct a
comprehensive analysis of how to measure similarity, how to select mapping
Layers and whether mapping is consistency. Based on these insights, we
introduce the IAM framework, which achieves dual benefits of accelerated
attention computation and reduced KV cache usage by performing attention
mapping between small and large LLMs. Our experimental results demonstrate that
IAM can accelerate prefill by 15% and reduce KV cache usage by 22.1% without
appreciably sacrificing performance. Experiments on different series of models
show the generalizability of IAM. Importantly, it is also orthogonal to many
existing KV cache optimization methods, making it a versatile addition to the
current toolkit for enhancing LLM efficiency.

</details>


### [107] [The benefits of query-based KGQA systems for complex and temporal questions in LLM era](https://arxiv.org/abs/2507.11954)
*Artem Alekseev,Mikhail Chaichuk,Miron Butko,Alexander Panchenko,Elena Tutubalina,Oleg Somov*

Main category: cs.CL

TL;DR: 本论文探讨了大型语言模型在多跳推理和时间问题方面的局限性，提出了一种基于查询的多阶段知识图谱问答（KGQA）框架，以提升复杂问答任务的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在处理多跳推理和时间类问题方面表现薄弱，而基于知识图谱的问答能够通过可执行查询模块化解决这些问题。本研究旨在弥补此不足。

Method: 研究提出了一种基于知识图谱的多阶段框架，通过一种新的实体链接和谓词匹配方法（结合链式推理），改善多跳和时间问答任务的能力。

Result: 实验结果表明，该方法在多跳和时间问答任务上性能优异，即使使用小型语言模型，也能显著提升鲁棒性。

Conclusion: 基于查询的多阶段知识图谱问答框架在提升多跳推理与时间问题方面具有巨大潜力，并为改进问答系统提供了新的思路。

Abstract: Large language models excel in question-answering (QA) yet still struggle
with multi-hop reasoning and temporal questions. Query-based knowledge graph QA
(KGQA) offers a modular alternative by generating executable queries instead of
direct answers. We explore multi-stage query-based framework for WikiData QA,
proposing multi-stage approach that enhances performance on challenging
multi-hop and temporal benchmarks. Through generalization and rejection
studies, we evaluate robustness across multi-hop and temporal QA datasets.
Additionally, we introduce a novel entity linking and predicate matching method
using CoT reasoning. Our results demonstrate the potential of query-based
multi-stage KGQA framework for improving multi-hop and temporal QA with small
language models. Code and data: https://github.com/ar2max/NLDB-KGQA-System

</details>


### [108] [PoTPTQ: A Two-step Power-of-Two Post-training for LLMs](https://arxiv.org/abs/2507.11959)
*Xinyu Wang,Vahid Partovi Nia,Peng Lu,Jerry Huang,Xiao-Wen Chang,Boxing Chen,Yufei Cui*

Main category: cs.CL

TL;DR: 本研究提出了一种新的基于PoT量化的框架，用于LLM权重，能够在极低精度数值格式下实现更高精度并加速计算。


<details>
  <summary>Details</summary>
Motivation: 解决当前PoT量化在GPU上效率较低的问题，同时在低精度下维持模型准确性，降低大语言模型的计算资源需求。

Method: 引入两步后训练算法：首先初始化量化比例，然后使用小规模校准数据集进行优化；提出一种改进的PoT量化框架，提升GPU去量化效率。

Result: 实验结果表明，该方法在2-和3-bit低精度格式下性能优于现有的整数量化技术，并在推理速度上显著加速，与现有方法相比，在NVIDIA V100和RTX 4090上的速度分别提高了3.67倍和1.63倍。

Conclusion: 该研究不仅提升了低精度量化的模型准确性，还显著提高了GPU上的推理速度，为大语言模型的高效部署提供了一种有效的方法。

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across
various natural language processing (NLP) tasks. However, their deployment is
challenging due to the substantial computational resources required.
Power-of-two (PoT) quantization is a general tool to counteract this
difficulty. Albeit previous works on PoT quantization can be efficiently
dequantized on CPUs using fixed-point addition, it showed less effectiveness on
GPUs. The reason is entanglement of the sign bit and sequential bit
manipulations needed for dequantization. We propose a novel POT quantization
framework for LLM weights that (i) outperforms state-of-the-art accuracy in
extremely low-precision number formats, and (ii) enables faster inference
through more efficient dequantization. To maintain the accuracy of the
quantized model, we introduce a two-step post-training algorithm: (i)
initialize the quantization scales with a robust starting point, and (ii)
refine these scales using a minimal calibration set. The performance of our PoT
post-training algorithm surpasses the current state-of-the-art in integer
quantization, particularly at low precisions such as 2- and 3-bit formats. Our
PoT quantization accelerates the dequantization step required for the floating
point inference and leads to $3.67\times$ speed up on a NVIDIA V100, and
$1.63\times$ on a NVIDIA RTX 4090, compared to uniform integer dequantization.

</details>


### [109] [Toxicity-Aware Few-Shot Prompting for Low-Resource Singlish Translation](https://arxiv.org/abs/2507.11966)
*Ziyu Ge,Gabriel Chua,Leanne Tan,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: 本文研究了低资源语言对的有毒内容翻译问题，通过两阶段框架提高翻译质量，同时保持文化敏感性和有毒性内容的保留。


<details>
  <summary>Details</summary>
Motivation: 随着在线交流中使用的不常见语言和方言增多，标准翻译系统经常无法准确翻译包括俚语和文化背景相关的有害语言表达。因此，本文研究这一问题以提高翻译系统在此类语言上的表现。

Method: 本文提出了一个两阶段框架：第一阶段利用人工确认的少量提示工程来捕捉俚语、语气及毒性；第二阶段通过多种大语言模型的基准测试优化模型和提示，采用语义相似性评估翻译性能。

Result: 通过定量的人工评估，验证了框架的有效性和效率，提升了翻译质量并保留了文化敏感性内容。

Conclusion: 本文框架不仅改善了翻译效果，还能支持多文化语言模型的安全性及文化敏感的内容审查，为低资源语言环境中的内容管理提供了新的可能性，以此强调了在现实应用中的社会语言学细微差别的重要性。

Abstract: As online communication increasingly incorporates under-represented languages
and colloquial dialects, standard translation systems often fail to preserve
local slang, code-mixing, and culturally embedded markers of harmful speech.
Translating toxic content between low-resource language pairs poses additional
challenges due to scarce parallel data and safety filters that sanitize
offensive expressions. In this work, we propose a reproducible, two-stage
framework for toxicity-preserving translation, demonstrated on a code-mixed
Singlish safety corpus. First, we perform human-verified few-shot prompt
engineering: we iteratively curate and rank annotator-selected Singlish-target
examples to capture nuanced slang, tone, and toxicity. Second, we optimize
model-prompt pairs by benchmarking several large language models using semantic
similarity via direct and back-translation. Quantitative human evaluation
confirms the effectiveness and efficiency of our pipeline. Beyond improving
translation quality, our framework contributes to the safety of multicultural
LLMs by supporting culturally sensitive moderation and benchmarking in
low-resource contexts. By positioning Singlish as a testbed for inclusive NLP,
we underscore the importance of preserving sociolinguistic nuance in real-world
applications such as content moderation and regional platform governance.

</details>


### [110] [Graph Representations for Reading Comprehension Analysis using Large Language Model and Eye-Tracking Biomarker](https://arxiv.org/abs/2507.11972)
*Yuhong Zhang,Jialu Li,Shilai Yang,Yuchen Xu,Gert Cauwenberghs,Tzyy-Ping Jung*

Main category: cs.CL

TL;DR: 研究探讨了人类与大型语言模型（LLMs）在阅读理解和完成功能性任务（如推理、情感解读和信息检索）中的表现对比。利用图结构进行语义分析，并通过注视点分布验证了LLM在图拓扑结构上的高一致性。


<details>
  <summary>Details</summary>
Motivation: 探究人类与LLMs在阅读理解过程中的异同，特别是在功能性任务中的语言理解表现。本研究弥补了以往仅分析单词局限性的问题，试图获得更深层次的洞察。

Method: 利用LLM构建基于语义和问题导向的文本图表达结构，通过分析重要节点和边上的眼动分布模式，比较人类与LLMs的理解一致性。

Result: 研究显示，LLMs在语言理解层面与人类在图拓扑结构上的一致性较高，验证了模型的有效性和潜在意义。

Conclusion: 本研究扩展了以往的发现，为人机协同学习提供了新的视角，同时也揭示了LLMs在更高层次语义分析中的潜力。

Abstract: Reading comprehension is a fundamental skill in human cognitive development.
With the advancement of Large Language Models (LLMs), there is a growing need
to compare how humans and LLMs understand language across different contexts
and apply this understanding to functional tasks such as inference, emotion
interpretation, and information retrieval. Our previous work used LLMs and
human biomarkers to study the reading comprehension process. The results showed
that the biomarkers corresponding to words with high and low relevance to the
inference target, as labeled by the LLMs, exhibited distinct patterns,
particularly when validated using eye-tracking data. However, focusing solely
on individual words limited the depth of understanding, which made the
conclusions somewhat simplistic despite their potential significance. This
study used an LLM-based AI agent to group words from a reading passage into
nodes and edges, forming a graph-based text representation based on semantic
meaning and question-oriented prompts. We then compare the distribution of eye
fixations on important nodes and edges. Our findings indicate that LLMs exhibit
high consistency in language understanding at the level of graph topological
structure. These results build on our previous findings and offer insights into
effective human-AI co-learning strategies.

</details>


### [111] [Value-Based Large Language Model Agent Simulation for Mutual Evaluation of Trust and Interpersonal Closeness](https://arxiv.org/abs/2507.11979)
*Yuki Sakamoto,Takahisa Uchida,Hiroshi Ishiguro*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型（LLM）代理中的价值相似性对关系建立的影响，并通过实验验证了相似价值的代理更易建立信任和亲密关系。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在模拟复杂社会现象方面展示了强大潜力，而价值相似性在现实人类社会中构建信任和亲密关系上非常重要，但其在LLM代理社会中的表现尚未深入研究。

Method: 通过预实验评估了控制LLM代理价值的最有效模型和提示设计；随后通过主实验，生成具有特定价值的LLM代理对，分析它们在对话后的信任和亲密关系评价，实验分别用英语和日语进行以研究语言依赖性。

Result: 实验结果证实，高价值相似性的代理对表现出更高的相互信任和亲密关系。

Conclusion: 研究表明，LLM代理可作为验证社会科学理论的有效测试平台，有助于阐明价值对关系建立的影响机制，并为社会科学新理论和洞察提供基础。

Abstract: Large language models (LLMs) have emerged as powerful tools for simulating
complex social phenomena using human-like agents with specific traits. In human
societies, value similarity is important for building trust and close
relationships; however, it remains unexplored whether this principle holds true
in artificial societies comprising LLM agents. Therefore, this study
investigates the influence of value similarity on relationship-building among
LLM agents through two experiments. First, in a preliminary experiment, we
evaluated the controllability of values in LLMs to identify the most effective
model and prompt design for controlling the values. Subsequently, in the main
experiment, we generated pairs of LLM agents imbued with specific values and
analyzed their mutual evaluations of trust and interpersonal closeness
following a dialogue. The experiments were conducted in English and Japanese to
investigate language dependence. The results confirmed that pairs of agents
with higher value similarity exhibited greater mutual trust and interpersonal
closeness. Our findings demonstrate that the LLM agent simulation serves as a
valid testbed for social science theories, contributes to elucidating the
mechanisms by which values influence relationship building, and provides a
foundation for inspiring new theories and insights into the social sciences.

</details>


### [112] [Simplifications are Absolutists: How Simplified Language Reduces Word Sense Awareness in LLM-Generated Definitions](https://arxiv.org/abs/2507.11981)
*Lukas Ellinger,Miriam Anschütz,Georg Groh*

Main category: cs.CL

TL;DR: 研究LLMs（大型语言模型）在不同目标群体中定义单词的表现，特别是对多义词的影响，发现简化定义会降低多义词的完整性，同时精调模型能显著提升定义质量。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs对多义词定义在不同目标群体中（普通用户、简单模式、ELI5模式）的适应性；关注在教育领域，过度简化是否会导致信息缺失或误导。

Method: 利用两个跨语言的新评估数据集，测试多个模型（DeepSeek v3、Llama 4 Maverick等）；采用LLM-as-Judge和人工注释进行质量评估；通过直接偏好优化对Llama 3.1 8B进行微调。

Result: 简化定义显著降低多义词定义的完整性并增加误解风险；经过直接偏好优化微调的Llama 3.1 8B在所有提示模式下表现出显著提升。

Conclusion: 在教育性NLP应用中，需在定义的简单性与完整性之间实现平衡，以确保针对所有学习者提供可靠、具上下文意识的定义。

Abstract: Large Language Models (LLMs) can provide accurate word definitions and
explanations for any context. However, the scope of the definition changes for
different target groups, like children or language learners. This is especially
relevant for homonyms, words with multiple meanings, where oversimplification
might risk information loss by omitting key senses, potentially misleading
users who trust LLM outputs. We investigate how simplification impacts homonym
definition quality across three target groups: Normal, Simple, and ELI5. Using
two novel evaluation datasets spanning multiple languages, we test DeepSeek v3,
Llama 4 Maverick, Qwen3-30B A3B, GPT-4o mini, and Llama 3.1 8B via LLM-as-Judge
and human annotations. Our results show that simplification drastically
degrades definition completeness by neglecting polysemy, increasing the risk of
misunderstanding. Fine-tuning Llama 3.1 8B with Direct Preference Optimization
substantially improves homonym response quality across all prompt types. These
findings highlight the need to balance simplicity and completeness in
educational NLP to ensure reliable, context-aware definitions for all learners.

</details>


### [113] [Improving Data and Parameter Efficiency of Neural Language Models Using Representation Analysis](https://arxiv.org/abs/2507.12004)
*Josip Jukić*

Main category: cs.CL

TL;DR: 研究了语言模型中的数据和参数效率问题，重点在表示分析和优化技术。提出基于平滑性的正则化、主动学习结合参数高效微调，以及利用上下文学习增强的弱监督方法。


<details>
  <summary>Details</summary>
Motivation: 解决神经语言模型中数据和参数效率低的问题，增强模型的鲁棒性、泛化能力和稳定性，特别是在低资源和动态环境下。

Method: 通过表示平滑性分析引入正则化措施、结合主动学习与参数高效微调的方法以及上下文学习增强的弱监督技术。

Result: 实验表明，这些方法在性能、稳定性和效率上明显优于传统方法，特别适用于低资源环境。

Conclusion: 提出的多种创新方法显著提高了神经语言模型的效率和适用性，降低了标注依赖和计算成本，为低资源设置中的自然语言处理任务提供了新思路。

Abstract: This thesis addresses challenges related to data and parameter efficiency in
neural language models, with a focus on representation analysis and the
introduction of new optimization techniques. The first part examines the
properties and dynamics of language representations within neural models,
emphasizing their significance in enhancing robustness and generalization. It
proposes innovative approaches based on representation smoothness, including
regularization strategies that utilize Jacobian and Hessian matrices to
stabilize training and mitigate sensitivity to input perturbations. The second
part focuses on methods to significantly enhance data and parameter efficiency
by integrating active learning strategies with parameter-efficient fine-tuning,
guided by insights from representation smoothness analysis. It presents
smoothness-informed early-stopping techniques designed to eliminate the need
for labeled validation sets and proposes innovative combinations of active
learning and parameter-efficient fine-tuning to reduce labeling efforts and
computational resources. Extensive experimental evaluations across various NLP
tasks demonstrate that these combined approaches substantially outperform
traditional methods in terms of performance, stability, and efficiency. The
third part explores weak supervision techniques enhanced by in-context learning
to effectively utilize unlabeled data, further reducing dependence on extensive
labeling. It shows that using in-context learning as a mechanism for weak
supervision enables models to better generalize from limited labeled data by
leveraging unlabeled examples more effectively during training. Comprehensive
empirical evaluations confirm significant gains in model accuracy,
adaptability, and robustness, especially in low-resource settings and dynamic
data environments.

</details>


### [114] [A Comparative Approach to Assessing Linguistic Creativity of Large Language Models and Humans](https://arxiv.org/abs/2507.12039)
*Anca Dinu,Andra-Maria Florescu,Alina Resceanu*

Main category: cs.CL

TL;DR: 本研究设计了一项语言创造力测试，用于评价人类和大型语言模型(LLMs)的表现。结果表明，LLMs整体表现优于人类。


<details>
  <summary>Details</summary>
Motivation: 研究目的是通过设计测试对比人类与LLMs在语言创造力上的表现，从而探索二者在语言创新上的能力差异。

Method: 测试包括生成新词语及隐喻语言应用两部分，分别针对派生、复合及隐喻等语言现象。使用OCSAI工具对答案的原创性、精细化和灵活性三个指标进行自动评价，同时分析个体答案的独特性，并手动分析了部分数据集。

Result: LLMs在所有指标上均优于人类，在八项测试任务中的六项上表现更佳，人类更倾向于E(扩展型)创造力，而LLMs偏向F(固定型)创造力。

Conclusion: LLMs表现出色，展示出其在语言创造力方面的潜力，但形式化与扩展性之间依然存在差异。

Abstract: The following paper introduces a general linguistic creativity test for
humans and Large Language Models (LLMs). The test consists of various tasks
aimed at assessing their ability to generate new original words and phrases
based on word formation processes (derivation and compounding) and on
metaphorical language use. We administered the test to 24 humans and to an
equal number of LLMs, and we automatically evaluated their answers using OCSAI
tool for three criteria: Originality, Elaboration, and Flexibility. The results
show that LLMs not only outperformed humans in all the assessed criteria, but
did better in six out of the eight test tasks. We then computed the uniqueness
of the individual answers, which showed some minor differences between humans
and LLMs. Finally, we performed a short manual analysis of the dataset, which
revealed that humans are more inclined towards E(extending)-creativity, while
LLMs favor F(ixed)-creativity.

</details>


### [115] [Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited](https://arxiv.org/abs/2507.12059)
*Anthony G Cohn,Robert E Blackwell*

Main category: cs.CL

TL;DR: 研究了28种大型语言模型（LLMs）在推理方位能力上的表现，发现即使是较新的推理模型仍然无法对所有问题给出正确答案。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在给定场景下准确推理出正确方位的能力及其局限性。

Method: 利用由多种模板生成的基准，测试LLMs在涉及不同变量（如移动方式、叙述视角等）下推理方位的能力。

Result: 即使是最新的推理模型也无法可靠地在所有问题中确定正确的方位。

Conclusion: 说明了当前大型语言模型在理解和推理空间方位上的能力不足，需要进一步研究。

Abstract: We investigate the abilities of 28 Large language Models (LLMs) to reason
about cardinal directions (CDs) using a benchmark generated from a set of
templates, extensively testing an LLM's ability to determine the correct CD
given a particular scenario. The templates allow for a number of degrees of
variation such as means of locomotion of the agent involved, and whether set in
the first, second or third person. Even the newer Large Reasoning Models are
unable to reliably determine the correct CD for all questions. This paper
summarises and extends earlier work presented at COSIT-24.

</details>


### [116] [StylOch at PAN: Gradient-Boosted Trees with Frequency-Based Stylometric Features](https://arxiv.org/abs/2507.12064)
*Jeremi K. Ochab,Mateusz Matias,Tymoteusz Boba,Tomasz Walkowiak*

Main category: cs.CL

TL;DR: 本论文提出一种模块化的文体分析管道，用于二元AI检测任务。


<details>
  <summary>Details</summary>
Motivation: 开发一种高效、可解释的方法来检测由机器生成的文本。

Method: 使用spaCy模型进行文本预处理并提取数千个特征，结合light-gradient提升机器作为分类器，使用超过50万个机器生成文本进行训练。

Result: 通过探索多种参数设置提升了分类器的能力，利用大规模训练集实现了这一目标。

Conclusion: 提出的方法计算成本低、可解释性强，基于非神经网络的方法取得有效成果。

Abstract: This submission to the binary AI detection task is based on a modular
stylometric pipeline, where: public spaCy models are used for text
preprocessing (including tokenisation, named entity recognition, dependency
parsing, part-of-speech tagging, and morphology annotation) and extracting
several thousand features (frequencies of n-grams of the above linguistic
annotations); light-gradient boosting machines are used as the classifier. We
collect a large corpus of more than 500 000 machine-generated texts for the
classifier's training. We explore several parameter options to increase the
classifier's capacity and take advantage of that training set. Our approach
follows the non-neural, computationally inexpensive but explainable approach
found effective previously.

</details>


### [117] [BOOKCOREF: Coreference Resolution at Book Scale](https://arxiv.org/abs/2507.12075)
*Giuliano Martinelli,Tommaso Bonomo,Pere-Lluís Huguet Cabot,Roberto Navigli*

Main category: cs.CL

TL;DR: 提出了一种针对长篇文本进行共指消解标注的自动化流程，并创建了首个书籍级别的共指基准BOOKCOREF，测试表明其资源显著提升现有系统性能，同时揭示了当前模型在超长文本中表现的不佳。


<details>
  <summary>Details</summary>
Motivation: 现有共指消解系统评测基准主要针对短至中篇幅文本，无法有效评估长篇文本（如书籍）中的共指能力。

Method: 提出了一种新颖的自动化流程，为完整的叙事文本生成高质量的共指消解标注，并基于此流程创建了首个平均长度超过20万标记的书籍级别共指基准BOOKCOREF。

Result: 实验表明，自动流程具备鲁棒性，且BOOKCOREF资源帮助现有长文档共指系统在完整书籍评估中性能提升达+20 CoNLL-F1分。

Conclusion: 通过BOOKCOREF的创建和试验，展示了开发能够处理书籍级别长文本的共指消解系统的必要性，同时公开资料和代码以推动研究。

Abstract: Coreference Resolution systems are typically evaluated on benchmarks
containing small- to medium-scale documents. When it comes to evaluating long
texts, however, existing benchmarks, such as LitBank, remain limited in length
and do not adequately assess system capabilities at the book scale, i.e., when
co-referring mentions span hundreds of thousands of tokens. To fill this gap,
we first put forward a novel automatic pipeline that produces high-quality
Coreference Resolution annotations on full narrative texts. Then, we adopt this
pipeline to create the first book-scale coreference benchmark, BOOKCOREF, with
an average document length of more than 200,000 tokens. We carry out a series
of experiments showing the robustness of our automatic procedure and
demonstrating the value of our resource, which enables current long-document
coreference systems to gain up to +20 CoNLL-F1 points when evaluated on full
books. Moreover, we report on the new challenges introduced by this
unprecedented book-scale setting, highlighting that current models fail to
deliver the same performance they achieve on smaller documents. We release our
data and code to encourage research and development of new book-scale
Coreference Resolution systems at https://github.com/sapienzanlp/bookcoref.

</details>


### [118] [Findings of MEGA: Maths Explanation with LLMs using the Socratic Method for Active Learning](https://arxiv.org/abs/2507.12079)
*Tosin Adewumi,Foteini Simistira Liwicki,Marcus Liwicki,Viktor Gardelli,Lama Alkhaled,Hamam Mokayed*

Main category: cs.CL

TL;DR: 本文研究结合苏格拉底方法、思维链推理(CoT)、简化游戏化和形成性反馈对大学生数学学习效果的影响，提出了MEGA方法，通过实验表明其优于传统的CoT方法。


<details>
  <summary>Details</summary>
Motivation: 由于许多学生在数学学习中遇到困难导致规避相关学科，而问题的根源常为教学方法不佳，因此需要改进学习方法。

Method: 采用“游戏化+AI+诱导式推理”的MEGA方法，与传统CoT方法进行对比研究，选用GSM8K和MATH数据集，通过学生评估验证两种方法对数学学习的效果。

Result: 实验表明，MEGA方法在两个数据集上的学生评价优于CoT方法，尤其在较难的MATH数据集上表现出色（47.5%优于26.67%）。

Conclusion: MEGA方法显著改善了学生的数学学习和问题理解能力，展示了AI驱动的多方法论教学的潜力。

Abstract: This paper presents an intervention study on the effects of the combined
methods of (1) the Socratic method, (2) Chain of Thought (CoT) reasoning, (3)
simplified gamification and (4) formative feedback on university students'
Maths learning driven by large language models (LLMs). We call our approach
Mathematics Explanations through Games by AI LLMs (MEGA). Some students
struggle with Maths and as a result avoid Math-related discipline or subjects
despite the importance of Maths across many fields, including signal
processing. Oftentimes, students' Maths difficulties stem from suboptimal
pedagogy. We compared the MEGA method to the traditional step-by-step (CoT)
method to ascertain which is better by using a within-group design after
randomly assigning questions for the participants, who are university students.
Samples (n=60) were randomly drawn from each of the two test sets of the Grade
School Math 8K (GSM8K) and Mathematics Aptitude Test of Heuristics (MATH)
datasets, based on the error margin of 11%, the confidence level of 90%, and a
manageable number of samples for the student evaluators. These samples were
used to evaluate two capable LLMs at length (Generative Pretrained Transformer
4o (GPT4o) and Claude 3.5 Sonnet) out of the initial six that were tested for
capability. The results showed that students agree in more instances that the
MEGA method is experienced as better for learning for both datasets. It is even
much better than the CoT (47.5% compared to 26.67%) in the more difficult MATH
dataset, indicating that MEGA is better at explaining difficult Maths problems.

</details>


### [119] [Iterative Augmentation with Summarization Refinement (IASR) Evaluation for Unstructured Survey data Modeling and Analysis](https://arxiv.org/abs/2507.12126)
*Payal Bhattad,Sai Manoj Pudukotai Dinakarrao,Anju Gupta*

Main category: cs.CL

TL;DR: 开发了一种评估框架和方法以确保大语言模型（LLM）文本增强的语义一致性和多样性。


<details>
  <summary>Details</summary>
Motivation: 为了解决低资源设置中数据稀疏的问题，开发一种有助于保持语义一致的文本增强方法。

Method: 引入评估框架，包括扩展性分析和迭代增强与摘要优化（IASR），结合使用BERTopic进行真实场景测试。

Result: 评估表明，GPT-3.5 Turbo在语义一致性、多样性和生成效率间表现最佳，增强的主题模型实现了400%的主题粒度提升且完全消除主题重叠。

Conclusion: 该框架有效提升文本增强的语义保真度和实用性，可广泛应用于自然语言处理的实践中。

Abstract: Text data augmentation is a widely used strategy for mitigating data sparsity
in natural language processing (NLP), particularly in low-resource settings
where limited samples hinder effective semantic modeling. While augmentation
can improve input diversity and downstream interpretability, existing
techniques often lack mechanisms to ensure semantic preservation during
large-scale or iterative generation, leading to redundancy and instability.
This work introduces a principled evaluation framework for large language model
(LLM) based text augmentation, comprising two components: (1) Scalability
Analysis, which measures semantic consistency as augmentation volume increases,
and (2) Iterative Augmentation with Summarization Refinement (IASR), which
evaluates semantic drift across recursive paraphrasing cycles. Empirical
evaluations across state-of-the-art LLMs show that GPT-3.5 Turbo achieved the
best balance of semantic fidelity, diversity, and generation efficiency.
Applied to a real-world topic modeling task using BERTopic with GPT-enhanced
few-shot labeling, the proposed approach results in a 400% increase in topic
granularity and complete elimination of topic overlaps. These findings
validated the utility of the proposed frameworks for structured evaluation of
LLM-based augmentation in practical NLP pipelines.

</details>


### [120] [Overview of the Sensemaking Task at the ELOQUENT 2025 Lab: LLMs as Teachers, Students and Evaluators](https://arxiv.org/abs/2507.12143)
*Pavel Šindelář,Ondřej Bojar*

Main category: cs.CL

TL;DR: ELOQUENT 是一个评估生成语言模型的共享任务集，Sensemaking 是其中一个任务，旨在通过教师、学生和评估者系统三个步骤测试生成模型对文本的理解能力。


<details>
  <summary>Details</summary>
Motivation: 研究目标是通过任务设置，测试生成语言模型在生成问题、回答问题和评估答案三方面的能力，验证其对文本进行合理解读的效果。

Method: Sensemaking 包括三个任务：(1) 教师系统生成问题；(2) 学生系统回答问题；(3) 评估者系统对答案评分，同时采用自动化和人工评分方法对结果进行对比验证。

Result: 2025 年 Sensemaking 包括多个语言和来源的数据集，共有 4 个团队参与，分别提交了教师、学生和评估者系统的方案。结果显示，尽管 LLM 在回答准确性方面表现尚可，但在限定输入范围内回答仍有困难。此外，评估系统存在判断错误的情况。

Conclusion: 当前的评价策略在问题生成和答案评估方面仍需改进，尤其是如何提高教师系统的问题质量评判以及评估者系统对无意义答案的分辨能力。

Abstract: ELOQUENT is a set of shared tasks that aims to create easily testable
high-level criteria for evaluating generative language models. Sensemaking is
one such shared task.
  In Sensemaking, we try to assess how well generative models ``make sense out
of a given text'' in three steps inspired by exams in a classroom setting: (1)
Teacher systems should prepare a set of questions, (2) Student systems should
answer these questions, and (3) Evaluator systems should score these answers,
all adhering rather strictly to a given set of input materials.
  We report on the 2025 edition of Sensemaking, where we had 7 sources of test
materials (fact-checking analyses of statements, textbooks, transcribed
recordings of a lecture, and educational videos) spanning English, German,
Ukrainian, and Czech languages.
  This year, 4 teams participated, providing us with 2 Teacher submissions, 2
Student submissions, and 2 Evaluator submissions. We added baselines for
Teacher and Student using commercial large language model systems. We devised a
fully automatic evaluation procedure, which we compare to a minimalistic manual
evaluation.
  We were able to make some interesting observations. For the first task, the
creation of questions, better evaluation strategies will still have to be
devised because it is difficult to discern the quality of the various candidate
question sets. In the second task, question answering, the LLMs examined
overall perform acceptably, but restricting their answers to the given input
texts remains problematic. In the third task, evaluation of question answers,
our adversarial tests reveal that systems using the LLM-as-a-Judge paradigm
erroneously rate both garbled question-answer pairs and answers to mixed-up
questions as acceptable.

</details>


### [121] [Toward a Behavioural Translation Style Space: Simulating the Temporal Dynamics of Affect, Behaviour, and Cognition in Human Translation Production](https://arxiv.org/abs/2507.12208)
*Michael Carl,Takanori Mizowaki,Aishvarya Ray,Masaru Yamada,Devi Sri Bandaru,Xinyue Ren*

Main category: cs.CL

TL;DR: 本文提出了一种称为行为翻译风格空间(BTSS)的模型，描述了可能的行为翻译模式，并通过分层结构体现了翻译的认知和情感状态。


<details>
  <summary>Details</summary>
Motivation: 探索人类翻译过程中行为、情感和认知的动态关系，使其可视化并以层次结构表示。

Method: 利用按键记录和凝视数据，分析隐藏的心理处理结构，并组织为多层嵌套的BTSS。

Result: BTSS可以用于理解和模拟人类翻译中情感、自动化行为及认知的时间动态变化。

Conclusion: BTSS不仅有助于揭示翻译行为的多层次结构，还为开发模拟人类翻译过程的计算机翻译代理提供基础。

Abstract: The paper introduces a Behavioural Translation Style Space (BTSS) that
describes possible behavioural translation patterns. The suggested BTSS is
organized as a hierarchical structure that entails various embedded processing
layers. We posit that observable translation behaviour - i.e., eye and finger
movements - is fundamental when executing the physical act of translation but
it is caused and shaped by higher-order cognitive processes and affective
translation states. We analyse records of keystrokes and gaze data as
indicators of the hidden mental processing structure and organize the
behavioural patterns as a multi-layered embedded BTSS. The BTSS serves as the
basis for a computational translation agent to simulate the temporal dynamics
of affect, automatized behaviour and cognition during human translation
production.

</details>


### [122] [Towards few-shot isolated word reading assessment](https://arxiv.org/abs/2507.12217)
*Reuben Smit,Retief Louw,Herman Kamper*

Main category: cs.CL

TL;DR: 提出了一种基于少样本学习的、无需自动语音识别（ASR）的孤立单词阅读评估方法，利用自监督学习（SSL）模型的中间特征层进行编码，在低资源环境中的效果有限。


<details>
  <summary>Details</summary>
Motivation: 为了解决低资源环境中儿童孤立单词阅读数据评估的难题，提出一种不依赖ASR系统的替代方法。

Method: 通过比较儿童语音数据与少量成人参考模板，使用SSL模型的中间层特征进行特征编码，并探索特征离散化及模板重心均值的方法。

Result: 理想条件下，成人语音数据的系统表现良好，但应用于儿童语音时性能显著下降，即使使用儿童模板也未能显著改善。

Conclusion: 尽管SSL表示在低资源语音任务中显示出成功，但在少样本分类系统中处理儿童语音数据时仍存在局限性。

Abstract: We explore an ASR-free method for isolated word reading assessment in
low-resource settings. Our few-shot approach compares input child speech to a
small set of adult-provided reference templates. Inputs and templates are
encoded using intermediate layers from large self-supervised learned (SSL)
models. Using an Afrikaans child speech benchmark, we investigate design
options such as discretising SSL features and barycentre averaging of the
templates. Idealised experiments show reasonable performance for adults, but a
substantial drop for child speech input, even with child templates. Despite the
success of employing SSL representations in low-resource speech tasks, our work
highlights the limitations of SSL representations for processing child data
when used in a few-shot classification system.

</details>


### [123] [Improving Contextual ASR via Multi-grained Fusion with Large Language Models](https://arxiv.org/abs/2507.12252)
*Shilin Zhou,Zhenghua Li*

Main category: cs.CL

TL;DR: 提出了一种多粒度融合方法，结合了基于Token和短语的语言模型，显著提升自动语音识别系统的关键词识别能力


<details>
  <summary>Details</summary>
Motivation: 现有的端到端自动语音识别系统对通用语音转录表现优异，但在识别特定上下文中的关键词（如专有名词或特定用户实体）方面存在不足

Method: 提出了一种结合Token级和短语级融合的多粒度方法，采用后融合策略，将语音识别的声学信息与大语言模型的上下文信息结合起来

Result: 中英文数据集实验表明，此方法在关键词相关指标上达到了当前最优性能，同时保证了非关键词文本的高准确性

Conclusion: Token级与短语级融合在此框架中协同发挥作用，代码和模型将公开发布

Abstract: While end-to-end Automatic Speech Recognition (ASR) models have shown
impressive performance in transcribing general speech, they often struggle to
accurately recognize contextually relevant keywords, such as proper nouns or
user-specific entities.
  Previous approaches have explored leveraging keyword dictionaries in the
textual modality to improve keyword recognition, either through token-level
fusion that guides token-by-token generation or phrase-level fusion that
enables direct copying of keyword phrases.
  However, these methods operate at different granularities and have their own
limitations.
  In this paper, we propose a novel multi-grained fusion approach that jointly
leverages the strengths of both token-level and phrase-level fusion with Large
Language Models (LLMs).
  Our approach incorporates a late-fusion strategy that elegantly combines
ASR's acoustic information with LLM's rich contextual knowledge, balancing
fine-grained token precision with holistic phrase-level understanding.
  Experiments on Chinese and English datasets demonstrate that our approach
achieves state-of-the-art performance on keyword-related metrics while
preserving high accuracy on non-keyword text.
  Ablation studies further confirm that the token-level and phrase-level
components both contribute significantly to the performance gains,
complementing each other in our joint multi-grained framework.
  The code and models will be publicly available at https://github.com/.

</details>


### [124] [Translationese-index: Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese](https://arxiv.org/abs/2507.12260)
*Yikang Liu,Wanyang Zhang,Yiming Wang,Jialong Tang,Pei Zhang,Baosong Yang,Fei Huang,Rui Wang,Hai Hu*

Main category: cs.CL

TL;DR: 提出了一种量化翻译腔的新指标T-index，通过对比微调的语言模型计算得出，用于评估翻译腔的强弱。


<details>
  <summary>Details</summary>
Motivation: 在机器翻译中，翻译腔对翻译质量的影响需要被量化和评估，但缺乏一种有效的测量工具。

Method: 通过合成数据集与真实翻译数据集，利用对比微调的0.5B语言模型计算T-index，进行跨领域结果评估及与人工评价对比验证。

Result: T-index证明具有很高的稳定性和效率，能够深入捕捉翻译腔特性，与人工评价高度相关（Pearson's $r=0.568$）。

Conclusion: T-index是一种独立且有用的指标，可以作为现有机器翻译质量评估（QE）指标的补充工具。

Abstract: In this paper, we propose the first quantitative measure for translationese
-- the translationese-index (T-index) for graded and generalizable measurement
of translationese, computed from the likelihood ratios of two contrastively
fine-tuned language models (LMs). We use a synthesized dataset and a dataset
with translations in the wild to evaluate T-index's generalizability in
cross-domain settings and its validity against human judgments. Our results
show that T-index is both robust and efficient. T-index scored by two 0.5B LMs
fine-tuned on only 1-5k pairs of synthetic data can well capture translationese
in the wild. We find that the relative differences in T-indices between
translations can well predict pairwise translationese annotations obtained from
human annotators; and the absolute values of T-indices correlate well with
human ratings of degrees of translationese (Pearson's $r = 0.568$).
Additionally, the correlation between T-index and existing machine translation
(MT) quality estimation (QE) metrics such as BLEU and COMET is low, suggesting
that T-index is not covered by these metrics and can serve as a complementary
metric in MT QE.

</details>


### [125] [Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes](https://arxiv.org/abs/2507.12261)
*Johann Frei,Nils Feldhus,Lisa Raithel,Roland Roller,Alexander Meyer,Frank Kramer*

Main category: cs.CL

TL;DR: 该论文介绍了一个名为Infherno的框架，用于将非结构化临床文本转换为符合HL7 FHIR标准的结构化数据，重点解决通用性和结构不一致性问题。


<details>
  <summary>Details</summary>
Motivation: 以往方法在处理译自自由形式临床笔记到FHIR资源时，存在通用性与结构一致性挑战，为此提出一种新的方法以解决问题。

Method: 通过结合LLM代理、代码执行与医疗术语数据库工具，设计了一种端到端的框架方法。

Result: Infherno能够准确预测并生成符合FHIR文件模式的资源，性能媲美人工基准。

Conclusion: 该框架有效支持临床数据集成与机构间互操作性，其前端支持自定义及合成数据应用。

Abstract: For clinical data integration and healthcare services, the HL7 FHIR standard
has established itself as a desirable format for interoperability between
complex health data. Previous attempts at automating the translation from
free-form clinical notes into structured FHIR resources rely on modular,
rule-based systems or LLMs with instruction tuning and constrained decoding.
Since they frequently suffer from limited generalizability and structural
inconformity, we propose an end-to-end framework powered by LLM agents, code
execution, and healthcare terminology database tools to address these issues.
Our solution, called Infherno, is designed to adhere to the FHIR document
schema and competes well with a human baseline in predicting FHIR resources
from unstructured text. The implementation features a front end for custom and
synthetic data and both local and proprietary models, supporting clinical data
integration processes and interoperability across institutions.

</details>


### [126] [Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding](https://arxiv.org/abs/2507.12295)
*Feng Xiao,Jicong Fan*

Main category: cs.CL

TL;DR: 研究提出了一种用于文本异常检测的标准化基准工具包，通过对多种语言模型的嵌入在不同领域数据集中的表现进行系统化评估。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理领域文本异常检测应用广泛，但缺乏标准化和全面的基准 hinder 创新模型的比较和发展。

Method: 系统评估了基于嵌入的文本异常检测算法，使用来自早期语言模型和多个大语言模型的嵌入，在多领域数据集上，采用全面的评估指标如AUROC和AUPRC，进行实验和分析。

Result: 研究发现：嵌入质量显著影响文本异常检测效果；深度学习方法在使用LLM嵌入时没有明显优于传统浅层算法的性能；跨模型的性能矩阵表现出显著的低秩特性，提供高效模型评估及选择的新策略。

Conclusion: 此研究通过开源的基准工具包与代码，为文本异常检测系统的后续研究提供了一个坚实的基础。

Abstract: Text anomaly detection is a critical task in natural language processing
(NLP), with applications spanning fraud detection, misinformation
identification, spam detection and content moderation, etc. Despite significant
advances in large language models (LLMs) and anomaly detection algorithms, the
absence of standardized and comprehensive benchmarks for evaluating the
existing anomaly detection methods on text data limits rigorous comparison and
development of innovative approaches. This work performs a comprehensive
empirical study and introduces a benchmark for text anomaly detection,
leveraging embeddings from diverse pre-trained language models across a wide
array of text datasets. Our work systematically evaluates the effectiveness of
embedding-based text anomaly detection by incorporating (1) early language
models (GloVe, BERT); (2) multiple LLMs (LLaMa-2, LLama-3, Mistral, OpenAI
(small, ada, large)); (3) multi-domain text datasets (news, social media,
scientific publications); (4) comprehensive evaluation metrics (AUROC, AUPRC).
Our experiments reveal a critical empirical insight: embedding quality
significantly governs anomaly detection efficacy, and deep learning-based
approaches demonstrate no performance advantage over conventional shallow
algorithms (e.g., KNN, Isolation Forest) when leveraging LLM-derived
embeddings.In addition, we observe strongly low-rank characteristics in
cross-model performance matrices, which enables an efficient strategy for rapid
model evaluation (or embedding evaluation) and selection in practical
applications. Furthermore, by open-sourcing our benchmark toolkit that includes
all embeddings from different models and code at
https://github.com/jicongfan/Text-Anomaly-Detection-Benchmark, this work
provides a foundation for future research in robust and scalable text anomaly
detection systems.

</details>


### [127] [Chain-of-Descriptions: Improving Code LLMs for VHDL Code Generation and Summarization](https://arxiv.org/abs/2507.12308)
*Prashanth Vijayaraghavan,Apoorva Nitsure,Charles Mackin,Luyao Shi,Stefano Ambrogio,Arvind Haran,Viresh Paruthi,Ali Elzein,Dan Coops,David Beymer,Tyler Baldwin,Ehsan Degan*

Main category: cs.CL

TL;DR: 这篇文章探讨了LLMs在硬件描述语言（HDL）尤其是VHDL代码生成和总结中的应用，提出并验证了一种改进方法——Chain-of-Descriptions（CoDes）。


<details>
  <summary>Details</summary>
Motivation: LLMs已广泛应用于多个领域，但针对硬件描述语言（如VHDL）的研究稀缺，现有模型在该领域表现不足。因此，有必要评估并优化LLMs在EDA任务中的表现。

Method: 提出了CoDes方法，通过生成一系列中间描述步骤，并将其与原始输入结合，作为输入提供给LLMs，从而改进VHDL代码生成和总结效果。

Result: 实验表明，CoDes方法在多个指标和两个数据集（VHDL-Eval和VHDL-Xform）上的表现显著优于标准提示策略。

Conclusion: CoDes方法有效提高了LLMs在VHDL任务中的表现，为未来改进此类模型的研究提供了框架。

Abstract: Large Language Models (LLMs) have become widely used across diverse NLP tasks
and domains, demonstrating their adaptability and effectiveness. In the realm
of Electronic Design Automation (EDA), LLMs show promise for tasks like
Register-Transfer Level (RTL) code generation and summarization. However,
despite the proliferation of LLMs for general code-related tasks, there's a
dearth of research focused on evaluating and refining these models for hardware
description languages (HDLs), notably VHDL. In this study, we evaluate the
performance of existing code LLMs for VHDL code generation and summarization
using various metrics and two datasets -- VHDL-Eval and VHDL-Xform. The latter,
an in-house dataset, aims to gauge LLMs' understanding of functionally
equivalent code. Our findings reveal consistent underperformance of these
models across different metrics, underscoring a significant gap in their
suitability for this domain. To address this challenge, we propose
Chain-of-Descriptions (CoDes), a novel approach to enhance the performance of
LLMs for VHDL code generation and summarization tasks. CoDes involves
generating a series of intermediate descriptive steps based on: (i) the problem
statement for code generation, and (ii) the VHDL code for summarization. These
steps are then integrated with the original input prompt (problem statement or
code) and provided as input to the LLMs to generate the final output. Our
experiments demonstrate that the CoDes approach significantly surpasses the
standard prompting strategy across various metrics on both datasets. This
method not only improves the quality of VHDL code generation and summarization
but also serves as a framework for future research aimed at enhancing code LLMs
for VHDL.

</details>


### [128] [Exploring Gender Bias in Alzheimer's Disease Detection: Insights from Mandarin and Greek Speech Perception](https://arxiv.org/abs/2507.12356)
*Liu He,Yuanchao Li,Rui Feng,XinRan Han,Yin-Long Liu,Yuwei Yang,Zude Zhu,Jiahong Yuan*

Main category: cs.CL

TL;DR: 研究显示，在阿尔茨海默症（AD）语音感知中存在性别偏差，男性语音更易被识别为AD，尤其是在中文语音中。


<details>
  <summary>Details</summary>
Motivation: 探索阿尔茨海默症语音感知中的性别偏差以及相关的声学特性对感知的影响。

Method: 通过感知实验，16名中文听众评估了中文和希腊语语音，并结合声学分析，探索不同性别与语言的影响。

Result: 结果显示，男性语音更易被感知为AD，尤其是中文语音，并发现声学特性振幅颤动（shimmer）与AD感知显著相关。

Conclusion: 性别偏差在AD语音感知中扮演重要角色，未来模型开发需考虑这一偏差，并在不同语言背景验证性能。

Abstract: Gender bias has been widely observed in speech perception tasks, influenced
by the fundamental voicing differences between genders. This study reveals a
gender bias in the perception of Alzheimer's Disease (AD) speech. In a
perception experiment involving 16 Chinese listeners evaluating both Chinese
and Greek speech, we identified that male speech was more frequently identified
as AD, with this bias being particularly pronounced in Chinese speech. Acoustic
analysis showed that shimmer values in male speech were significantly
associated with AD perception, while speech portion exhibited a significant
negative correlation with AD identification. Although language did not have a
significant impact on AD perception, our findings underscore the critical role
of gender bias in AD speech perception. This work highlights the necessity of
addressing gender bias when developing AD detection models and calls for
further research to validate model performance across different linguistic
contexts.

</details>


### [129] [Beyond Single Models: Enhancing LLM Detection of Ambiguity in Requests through Debate](https://arxiv.org/abs/2507.12370)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.CL

TL;DR: 本文提出一种多智能体辩论框架，通过让多个大语言模型（LLMs）进行辩论，提升对用户请求中模糊性信息的检测和解决能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在处理用户请求时，常因信息模糊性而表现不足，需要解决这一问题以提升互动系统的自然性和适应性。

Method: 引入一个包括三种LLM架构（Llama3-8B、Gemma2-9B、Mistral-7B）的辩论框架，并使用包含多样化模糊性的定制数据集进行模型训练与评估。

Result: 该辩论框架显著提升了部分模型在处理模糊性请求时的性能，其中Mistral-7B带头的辩论成功率达到76.7%，尤其善于处理复杂模糊性问题并快速达成共识。

Conclusion: 通过结构化的辩论框架，不仅提高了LLM的澄清和互动性能，还为更健壮、适应性强的语言理解系统开发提供了重要启示。

Abstract: Large Language Models (LLMs) have demonstrated significant capabilities in
understanding and generating human language, contributing to more natural
interactions with complex systems. However, they face challenges such as
ambiguity in user requests processed by LLMs. To address these challenges, this
paper introduces and evaluates a multi-agent debate framework designed to
enhance detection and resolution capabilities beyond single models. The
framework consists of three LLM architectures (Llama3-8B, Gemma2-9B, and
Mistral-7B variants) and a dataset with diverse ambiguities. The debate
framework markedly enhanced the performance of Llama3-8B and Mistral-7B
variants over their individual baselines, with Mistral-7B-led debates achieving
a notable 76.7% success rate and proving particularly effective for complex
ambiguities and efficient consensus. While acknowledging varying model
responses to collaborative strategies, these findings underscore the debate
framework's value as a targeted method for augmenting LLM capabilities. This
work offers important insights for developing more robust and adaptive language
understanding systems by showing how structured debates can lead to improved
clarity in interactive systems.

</details>


### [130] [Web-Browsing LLMs Can Access Social Media Profiles and Infer User Demographics](https://arxiv.org/abs/2507.12372)
*Meysam Alizadeh,Fabrizio Gilardi,Zeynab Samei,Mohsen Mosleh*

Main category: cs.CL

TL;DR: 研究探讨LLMs是否能通过用户名推断社交媒体用户的人口属性，并发现其具有一定准确性，但存在偏见风险。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs具备实时信息检索能力，研究其解析社交媒体数据的可能性尚未探索。

Method: 使用包含48个Twitter账号的合成数据集和1384名国际参与者的调查数据集，评估模型访问社交媒体内容和推断人口学特征的能力。

Result: 模型能够访问社交媒体内容并以合理准确性预测用户的人口特征，但对活跃度较低账户可能存在偏见。

Conclusion: LLMs在后API时代的计算社会科学中有潜力，但需防止滥用，建议在公共应用程序中限制该功能，仅对验证研究提供受控访问。

Abstract: Large language models (LLMs) have traditionally relied on static training
data, limiting their knowledge to fixed snapshots. Recent advancements,
however, have equipped LLMs with web browsing capabilities, enabling real time
information retrieval and multi step reasoning over live web content. While
prior studies have demonstrated LLMs ability to access and analyze websites,
their capacity to directly retrieve and analyze social media data remains
unexplored. Here, we evaluate whether web browsing LLMs can infer demographic
attributes of social media users given only their usernames. Using a synthetic
dataset of 48 X (Twitter) accounts and a survey dataset of 1,384 international
participants, we show that these models can access social media content and
predict user demographics with reasonable accuracy. Analysis of the synthetic
dataset further reveals how LLMs parse and interpret social media profiles,
which may introduce gender and political biases against accounts with minimal
activity. While this capability holds promise for computational social science
in the post API era, it also raises risks of misuse particularly in information
operations and targeted advertising underscoring the need for safeguards. We
recommend that LLM providers restrict this capability in public facing
applications, while preserving controlled access for verified research
purposes.

</details>


### [131] [Probing for Arithmetic Errors in Language Models](https://arxiv.org/abs/2507.12379)
*Yucheng Sun,Alessandro Stolfo,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 研究表明，通过分析语言模型内部激活状态，可以检测和纠正算术错误。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型内部激活是否能够用来检测和纠正算术错误，旨在提高模型的自我修正能力。

Method: 在实验中使用3位数加法开始，结合轻量探针解码模型的预测输出与正确答案，扩展到更复杂任务并利用探针指导错误处的重新提示。

Result: 轻量探针能以90%以上的准确率预测模型的正确性，同时改进任务准确性并最大限度减少对正确输出的干扰。

Conclusion: 算术错误可通过内部激活提前被发现，简单探针为模型轻量级自我修正提供了可行途径。

Abstract: We investigate whether internal activations in language models can be used to
detect arithmetic errors. Starting with a controlled setting of 3-digit
addition, we show that simple probes can accurately decode both the model's
predicted output and the correct answer from hidden states, regardless of
whether the model's output is correct. Building on this, we train lightweight
error detectors that predict model correctness with over 90% accuracy. We then
extend our analysis to structured chain-of-thought traces on addition-only
GSM8K problems and find that probes trained on simple arithmetic generalize
well to this more complex setting, revealing consistent internal
representations. Finally, we demonstrate that these probes can guide selective
re-prompting of erroneous reasoning steps, improving task accuracy with minimal
disruption to correct outputs. Our findings suggest that arithmetic errors can
be anticipated from internal activations alone, and that simple probes offer a
viable path toward lightweight model self-correction.

</details>


### [132] [Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data](https://arxiv.org/abs/2507.12425)
*Chandana Cheerla*

Main category: cs.CL

TL;DR: 论文提出了一种改进的RAG（检索增强生成）框架，结合密集嵌入和BM25的混合检索策略，应用于企业数据的处理，取得了显著的实验改进。


<details>
  <summary>Details</summary>
Motivation: 当前的大语言模型在企业数据处理上存在预训练静态化、上下文窗口短、异构数据难处理等限制，传统的RAG框架对于结构化和半结构化数据效果不足。

Method: 提出了混合检索策略的先进RAG框架，结合密集嵌入(all-mpnet-base-v2)和BM25，并利用元数据过滤（SpaCy NER）及交叉编码排序器；采用语义分块保证文本连贯性，保留表格数据结构完整性，量化索引优化检索效率，并融入人机反馈回路和对话记忆。

Result: 在企业数据集上取得显著实验改进，Precision@5提升15%，Recall@5提升13%，MRR提升16%；定性评估中忠实度、完整性和相关性指标均显著高于对比方法。

Conclusion: 框架在企业任务中展示了提供准确、全面以及上下文相关响应的能力，未来工作计划扩展至多模态数据和基于智能代理的检索。

Abstract: Organizations increasingly rely on proprietary enterprise data, including HR
records, structured reports, and tabular documents, for critical
decision-making. While Large Language Models (LLMs) have strong generative
capabilities, they are limited by static pretraining, short context windows,
and challenges in processing heterogeneous data formats. Conventional
Retrieval-Augmented Generation (RAG) frameworks address some of these gaps but
often struggle with structured and semi-structured data.
  This work proposes an advanced RAG framework that combines hybrid retrieval
strategies using dense embeddings (all-mpnet-base-v2) and BM25, enhanced by
metadata-aware filtering with SpaCy NER and cross-encoder reranking. The
framework applies semantic chunking to maintain textual coherence and retains
tabular data structures to preserve row-column integrity. Quantized indexing
optimizes retrieval efficiency, while human-in-the-loop feedback and
conversation memory improve adaptability.
  Experiments on enterprise datasets show notable improvements: Precision@5
increased by 15 percent (90 versus 75), Recall@5 by 13 percent (87 versus 74),
and Mean Reciprocal Rank by 16 percent (0.85 versus 0.69). Qualitative
evaluations show higher scores in Faithfulness (4.6 versus 3.0), Completeness
(4.2 versus 2.5), and Relevance (4.5 versus 3.2) on a 5-point Likert scale.
These results demonstrate the framework's effectiveness in delivering accurate,
comprehensive, and contextually relevant responses for enterprise tasks. Future
work includes extending to multimodal data and integrating agent-based
retrieval. The source code will be released at
https://github.com/CheerlaChandana/Enterprise-Chatbot

</details>


### [133] [Can We Predict Alignment Before Models Finish Thinking? Towards Monitoring Misaligned Reasoning Models](https://arxiv.org/abs/2507.12428)
*Yik Siu Chan,Zheng-Xin Yong,Stephen H. Bach*

Main category: cs.CL

TL;DR: 研究利用推理过程中的CoT（思维链）预测最终输出是否对齐，并提出使用CoT激活进行实时安全监控的可能性。


<details>
  <summary>Details</summary>
Motivation: 优化大语言模型的推理安全性，识别产生有害内容的风险。

Method: 评估了通过人类、强大语言模型和文本分类器对CoT文本或其激活进行监控，提出了使用线性探针预测是否安全的方法。

Result: CoT激活的线性探针显著优于基于文本的方法，并能在推理完成前准确预测模型输出的安全性。

Conclusion: 轻量级探针可用于实时安全监控，并在生成早期实施干预，具有推广性。

Abstract: Open-weights reasoning language models generate long chains-of-thought (CoTs)
before producing a final response, which improves performance but introduces
additional alignment risks, with harmful content often appearing in both the
CoTs and the final outputs. In this work, we investigate if we can use CoTs to
predict final response misalignment. We evaluate a range of monitoring
approaches, including humans, highly-capable large language models, and text
classifiers, using either CoT text or activations. First, we find that a simple
linear probe trained on CoT activations can significantly outperform all
text-based methods in predicting whether a final response will be safe or
unsafe. CoT texts are often unfaithful and can mislead humans and classifiers,
while model latents (i.e., CoT activations) offer a more reliable predictive
signal. Second, the probe makes accurate predictions before reasoning
completes, achieving strong performance even when applied to early CoT
segments. These findings generalize across model sizes, families, and safety
benchmarks, suggesting that lightweight probes could enable real-time safety
monitoring and early intervention during generation.

</details>


### [134] [S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling](https://arxiv.org/abs/2507.12451)
*Suman Adhya,Debarshi Kumar Sanyal*

Main category: cs.CL

TL;DR: 提出了一种新的球面切片Wasserstein自动编码器（S2WTM），用于处理主题建模中的后验坍缩问题，并优化潜在表征的超球面结构。


<details>
  <summary>Details</summary>
Motivation: 解决变分自动编码器(VAE)中后验坍缩对高维文本数据主题建模的不良影响，同时优化超球面潜在空间的建模。

Method: S2WTM引入了单位超球面上的先验分布，并利用球面切片Wasserstein距离对齐预测分布和先验分布，从而增强潜在表征的方向相似性。

Result: 实验表明，S2WTM较现有先进的主题模型表现更优，生成更连贯和多样化的主题，并在下游任务中表现更佳。

Conclusion: S2WTM有效缓解了后验坍缩问题，同时改进了超球面结构的潜在表征，显示其在主题建模中的优越性能。

Abstract: Modeling latent representations in a hyperspherical space has proven
effective for capturing directional similarities in high-dimensional text data,
benefiting topic modeling. Variational autoencoder-based neural topic models
(VAE-NTMs) commonly adopt the von Mises-Fisher prior to encode hyperspherical
structure. However, VAE-NTMs often suffer from posterior collapse, where the KL
divergence term in the objective function highly diminishes, leading to
ineffective latent representations. To mitigate this issue while modeling
hyperspherical structure in the latent space, we propose the Spherical Sliced
Wasserstein Autoencoder for Topic Modeling (S2WTM). S2WTM employs a prior
distribution supported on the unit hypersphere and leverages the Spherical
Sliced-Wasserstein distance to align the aggregated posterior distribution with
the prior. Experimental results demonstrate that S2WTM outperforms
state-of-the-art topic models, generating more coherent and diverse topics
while improving performance on downstream tasks.

</details>


### [135] [Language Models Improve When Pretraining Data Matches Target Tasks](https://arxiv.org/abs/2507.12466)
*David Mizrahi,Anders Boesen Lindbo Larsen,Jesse Allardice,Suzie Petryk,Yuri Gorokhov,Jeffrey Li,Alex Fang,Josh Gardner,Tom Gunter,Afshin Dehghan*

Main category: cs.CL

TL;DR: 本文提出了基于基准目标的排名方法（BETR），通过与基准训练样本的相似性选择预训练文档，从而优化数据选择策略并提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 探讨显式优化数据选择目标的影响，并通过针对基准目标的数据选择提高模型性能。

Method: 提出了一种称为BETR的方法，通过将基准样本和预训练文档嵌入共享空间，根据相似性进行评分，并训练轻量级分类器预测分数来选择数据。

Result: 通过BETR方法，在各个规模模型上的9个任务中表现优于基线方法（DCLM-Baseline和未过滤数据），并展现出良好的泛化能力。此外，分析发现大规模模型需求较少的过滤强度。

Conclusion: 直接匹配预训练数据与目标任务能显著影响模型能力，最佳选择策略需根据模型规模调整。

Abstract: Every data selection method inherently has a target. In practice, these
targets often emerge implicitly through benchmark-driven iteration: researchers
develop selection strategies, train models, measure benchmark performance, then
refine accordingly. This raises a natural question: what happens when we make
this optimization explicit? To explore this, we propose benchmark-targeted
ranking (BETR), a simple method that selects pretraining documents based on
similarity to benchmark training examples. BETR embeds benchmark examples and a
sample of pretraining documents in a shared space, scores this sample by
similarity to benchmarks, then trains a lightweight classifier to predict these
scores for the full corpus. We compare data selection methods by training over
500 models spanning $10^{19}$ to $10^{22}$ FLOPs and fitting scaling laws to
them. From this, we find that simply aligning pretraining data to evaluation
benchmarks using BETR achieves a 2.1x compute multiplier over DCLM-Baseline
(4.7x over unfiltered data) and improves performance on 9 out of 10 tasks
across all scales. BETR also generalizes well: when targeting a diverse set of
benchmarks disjoint from our evaluation suite, it still matches or outperforms
baselines. Our scaling analysis further reveals a clear trend: larger models
require less aggressive filtering. Overall, our findings show that directly
matching pretraining data to target tasks precisely shapes model capabilities
and highlight that optimal selection strategies must adapt to model scale.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [136] [A Study on the Application of Artificial Intelligence in Ecological Design](https://arxiv.org/abs/2507.11595)
*Hengyue Zhao*

Main category: cs.AI

TL;DR: 论文探讨了人工智能（AI）能否协助实现人与自然从主导关系向真正相互依存关系的转变，并通过案例研究分析AI在生态设计中的新角色及其潜力。


<details>
  <summary>Details</summary>
Motivation: 探究人工智能在改变人与自然关系及推动生态设计新范式的潜力。

Method: 通过案例研究分析AI在数据分析、图像识别和生态修复中的应用；并基于作者的AI辅助水修复原型，提出结合强化学习与植物修复的设计路径。

Result: 研究表明，AI能够连接科学见解、艺术实践和环境管理，推动技术驱动的可持续生态系统设计。

Conclusion: AI在生态设计中不仅拓宽了创造性方法，还重新定义了生态设计的理论与实践，揭示了其在未来可持续发展和技术生态系统中的应用前景。

Abstract: This paper asks whether our relationship with nature can move from human
dominance to genuine interdependence, and whether artificial intelligence (AI)
can mediate that shift. We examine a new ecological-design paradigm in which AI
interacts with non-human life forms. Through case studies we show how artists
and designers apply AI for data analysis, image recognition, and ecological
restoration, producing results that differ from conventional media. We argue
that AI not only expands creative methods but also reframes the theory and
practice of ecological design. Building on the author's prototype for
AI-assisted water remediation, the study proposes design pathways that couple
reinforcement learning with plant-based phytoremediation. The findings
highlight AI's potential to link scientific insight, artistic practice, and
environmental stewardship, offering a roadmap for future research on
sustainable, technology-enabled ecosystems.

</details>


### [137] [General Modular Harness for LLM Agents in Multi-Turn Gaming Environments](https://arxiv.org/abs/2507.11633)
*Yuxuan Zhang,Haoyang Yu,Lanxiang Hu,Haojian Jin,Hao Zhang*

Main category: cs.AI

TL;DR: 提出了一种模块化设计的LLM代理结构，结合感知、记忆和推理模块，支持单一模型在各种多轮游戏环境中无需特定领域优化下运行。


<details>
  <summary>Details</summary>
Motivation: 利用游戏这一低门槛、高多样性测试环境，研究一个通用框架通过模块化设计提升代理在动态交互场景中的能力。

Method: 设计了一个模块化的“感知-记忆-推理”系统，让一个LLM或VLM模型可以在广泛的多轮游戏环境中适用，并分析不同模块对性能的具体影响。

Result: 实验表明，与非模块化模型相比，该框架一致提升了游戏表现，并且显示了模块在不同情况下的特定贡献，例如，长时序谜题中记忆起主要作用，而嘈杂视觉环境下感知更为关键。

Conclusion: 模块化设计显著增强了通用型代理的潜力，并凸显了各模块在动态环境下的具体价值。

Abstract: We introduce a modular harness design for LLM agents that composes of
perception, memory, and reasoning components, enabling a single LLM or VLM
backbone to tackle a wide spectrum of multi turn gaming environments without
domain-specific engineering. Using classic and modern game suites as
low-barrier, high-diversity testbeds, our framework provides a unified workflow
for analyzing how each module affects performance across dynamic interactive
settings. Extensive experiments demonstrate that the harness lifts gameplay
performance consistently over un-harnessed baselines and reveals distinct
contribution patterns, for example, memory dominates in long-horizon puzzles
while perception is critical in vision noisy arcades. These findings highlight
the effectiveness of our modular harness design in advancing general-purpose
agent, given the familiarity and ubiquity of games in everyday human
experience.

</details>


### [138] [Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification](https://arxiv.org/abs/2507.11662)
*Moises Andrade,Joonhyuk Cha,Brandon Ho,Vriksha Srihari,Karmesh Yadav,Zsolt Kira*

Main category: cs.AI

TL;DR: 该论文提出了使用多模态大语言模型(MLLMs)作为代理行为验证器的潜力。然而，研究发现MLLMs存在显著的偏好，即倾向于支持上下文窗口中的信息，可能导致评估失误。为解决此问题，作者提出了一种名为自我基础验证(SGV)的方法，显著提升了模型验证准确性与失败检测率，设置了新的基准性能。


<details>
  <summary>Details</summary>
Motivation: 当前AI领域中，验证器在数学、棋类等明确标准领域有重要作用，但在无明确成功标准的领域(如计算机操作)应用受限，需要新的方法支持更复杂的代理行为验证。

Method: 提出了一种名为自我基础验证(SGV)的方法，通过无条件与有条件生成提升MLLMs的知识与推理能力。具体步骤包括：首先不依赖评估数据，抽取任务完成的广泛先验；其次基于生成的先验推理与评估候选行为。

Result: 使用SGV后，MLLM验证器的准确性与失败检测率最高提升20点。在不同场景中实现实时监督的性能提升，并在多项基准测试中超过先前最佳性能48%。

Conclusion: MLLMs可用于代理行为验证，但需解决偏好问题，通过自我基础验证(SGV)方法可显著增强其评估能力，开创了新的研究与应用潜力。

Abstract: Verifiers -- functions assigning rewards to agent behavior -- have been key
for AI progress in domains like math and board games. However, extending these
gains to domains without clear-cut success criteria (e.g.,computer use) remains
a challenge: while humans can recognize suitable outcomes, translating this
intuition into scalable rules is non-trivial. Multimodal Large Language
Models(MLLMs) emerge as a promising solution, given their world knowledge,
human-preference alignment, and reasoning skills. We evaluate MLLMs as
verifiers of agent trajectories across web navigation, computer use, and
robotic manipulation, and identify a critical limitation: agreement bias, a
strong tendency for MLLMs to favor information in their context window, often
generating chains of thought to rationalize flawed behavior. This bias is
pervasive across models, resilient to test-time scaling, and can impact several
methods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs
despite MLLMs showing strong, human-aligned priors on desired behavior. To
address this, we propose Self-Grounded Verification (SGV), a lightweight method
that enables more effective use of MLLMs' knowledge and reasoning by harnessing
their own sampling mechanisms via unconditional and conditional generation. SGV
operates in two steps: first, the MLLM is elicited to retrieve broad priors
about task completion, independent of the data under evaluation. Then,
conditioned on self-generated priors, it reasons over and evaluates a candidate
trajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in
accuracy and failure detection rates, and can perform real-time supervision of
heterogeneous agents, boosting task completion of a GUI specialist in OSWorld,
a diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting
a new state of the art on the benchmark, surpassing the previous best by 48%.

</details>


### [139] [ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making](https://arxiv.org/abs/2507.11733)
*Srikanth Vemula*

Main category: cs.AI

TL;DR: 介绍了通过结合案例推理（CBR）和本体驱动方法的全新方法ClarifAI，以提升AI透明性及可解释性。


<details>
  <summary>Details</summary>
Motivation: 希望解决AI在高风险决策中的透明性和可解释性问题，满足不同用户对解释机制的需求。

Method: 利用案例推理（CBR）与本体驱动方法相结合，设计ClarifAI理论和架构，以提供详尽的解释机制。

Result: ClarifAI展现了在不同领域提升AI可解释性及在高风险场景应用的潜力。

Conclusion: ClarifAI在推动AI系统可解释性方面具有重要意义，为关键决策过程的高效部署提供了可能性。

Abstract: This Study introduces Clarity and Reasoning Interface for Artificial
Intelligence(ClarifAI), a novel approach designed to augment the transparency
and interpretability of artificial intelligence (AI) in the realm of improved
decision making. Leveraging the Case-Based Reasoning (CBR) methodology and
integrating an ontology-driven approach, ClarifAI aims to meet the intricate
explanatory demands of various stakeholders involved in AI-powered
applications. The paper elaborates on ClarifAI's theoretical foundations,
combining CBR and ontologies to furnish exhaustive explanation mechanisms. It
further elaborates on the design principles and architectural blueprint,
highlighting ClarifAI's potential to enhance AI interpretability across
different sectors and its applicability in high-stake environments. This
research delineates the significant role of ClariAI in advancing the
interpretability of AI systems, paving the way for its deployment in critical
decision-making processes.

</details>


### [140] [Auto-Formulating Dynamic Programming Problems with Large Language Models](https://arxiv.org/abs/2507.11737)
*Chenyu Zhou,Jingyuan Yang,Linwei Xin,Yitian Chen,Ziyan He,Dongdong Ge*

Main category: cs.AI

TL;DR: 本文提出了一种名为DPLM的动态规划语言模型，借助DP-Bench基准和创新的数据生成方法DualReflect，在动态规划问题上超越了现有主流模型。


<details>
  <summary>Details</summary>
Motivation: 动态规划模型的构建需要专业知识，为了简化和自动化这一过程，作者探讨了使用大语言模型的可能性。本文致力于解决动态规划问题中随机性和数据稀缺性对现有模型表现的限制。

Method: 提出了DP-Bench基准和DPLM模型，并设计了DualReflect数据生成管道，通过前向生成增加多样性，后向生成提供正确性保障，结合两者优化模型性能。

Result: DPLM的表现可与OpenAI和DeepSeek的领先模型媲美，并在复杂问题上超越了这些模型。同时，DualReflect中的前向生成和后向生成各具优势，为训练数据提供了互补性。

Conclusion: 在训练数据有限的情况下，后向生成保证了模型的高准确性；而在大规模数据集上，前向生成的多样性带来了显著的性能提升，强调了两者结合的重要性。

Abstract: Dynamic programming (DP) is a fundamental method in operations research, but
formulating DP models has traditionally required expert knowledge of both the
problem context and DP techniques. Large Language Models (LLMs) offer the
potential to automate this process. However, DP problems pose unique challenges
due to their inherently stochastic transitions and the limited availability of
training data. These factors make it difficult to directly apply existing
LLM-based models or frameworks developed for other optimization problems, such
as linear or integer programming. We introduce DP-Bench, the first benchmark
covering a wide range of textbook-level DP problems to enable systematic
evaluation. We present Dynamic Programming Language Model (DPLM), a
7B-parameter specialized model that achieves performance comparable to
state-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on
hard problems. Central to DPLM's effectiveness is DualReflect, our novel
synthetic data generation pipeline, designed to scale up training data from a
limited set of initial examples. DualReflect combines forward generation for
diversity and backward generation for reliability. Our results reveal a key
insight: backward generation is favored in low-data regimes for its strong
correctness guarantees, while forward generation, though lacking such
guarantees, becomes increasingly valuable at scale for introducing diverse
formulations. This trade-off highlights the complementary strengths of both
approaches and the importance of combining them.

</details>


### [141] [Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity](https://arxiv.org/abs/2507.11787)
*Chandrashekar Muniyappa,Eunjin Kim*

Main category: cs.AI

TL;DR: 本文为一篇综述，主要讨论了群体智能在语义相似性文档检索中的应用，并展望未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用群体智能算法来提高语义相似性文档检索的效率和效果。

Method: 通过综述现有文献，总结目前在语义相似性检索中应用群体智能的方法及其技术发展。

Result: 分析了各种群体智能算法的最新研究进展，并评估其在语义相似性文档检索中的表现。

Conclusion: 群体智能算法在语义相似性检索领域具有广阔应用潜力，未来研究可关注新算法开发及其优化应用场景。

Abstract: Swarm Intelligence (SI) is gaining a lot of popularity in artificial
intelligence, where the natural behavior of animals and insects is observed and
translated into computer algorithms called swarm computing to solve real-world
problems. Due to their effectiveness, they are applied in solving various
computer optimization problems. This survey will review all the latest
developments in Searching for documents based on semantic similarity using
Swarm Intelligence algorithms and recommend future research directions.

</details>


### [142] [BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution](https://arxiv.org/abs/2507.12207)
*Subin Lin,Chuanbo Hua*

Main category: cs.AI

TL;DR: BuildEvo 利用大型语言模型（LLMs）自动设计并优化建筑能耗预测的启发式方法，展现出优异性能和透明的预测逻辑。


<details>
  <summary>Details</summary>
Motivation: 传统的启发式方法精度不足，而先进的模型难以解释且忽略物理原理，因此需要一种既精确又兼具物理意义和透明性的预测方法。

Method: 引入了一种名为 BuildEvo 的框架，利用大型语言模型在进化过程中自动构建和优化基于物理洞察的预测启发式规则。

Result: BuildEvo 在建筑能源预测基准测试中实现了最前沿的表现，同时提供了更强的泛化能力和可解释的预测逻辑。

Conclusion: BuildEvo 框架提升了建筑能耗预测的精确性和可信度，为复杂能耗系统模型的智能化设计提供了新方向。

Abstract: Accurate building energy forecasting is essential, yet traditional heuristics
often lack precision, while advanced models can be opaque and struggle with
generalization by neglecting physical principles. This paper introduces
BuildEvo, a novel framework that uses Large Language Models (LLMs) to
automatically design effective and interpretable energy prediction heuristics.
Within an evolutionary process, BuildEvo guides LLMs to construct and enhance
heuristics by systematically incorporating physical insights from building
characteristics and operational data (e.g., from the Building Data Genome
Project 2). Evaluations show BuildEvo achieves state-of-the-art performance on
benchmarks, offering improved generalization and transparent prediction logic.
This work advances the automated design of robust, physically grounded
heuristics, promoting trustworthy models for complex energy systems.

</details>


### [143] [A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS](https://arxiv.org/abs/2507.11916)
*Ehsan Futuhi,Nathan R. Sturtevant*

Main category: cs.AI

TL;DR: 本文提出一种在深度优先搜索中批量处理GPU计算的方法，并通过实验验证了其在3x3魔方和4x4滑块拼图问题上的效果。


<details>
  <summary>Details</summary>
Motivation: 鉴于GPU技术的高速发展及其强大的并行处理能力，研究如何在搜索算法中更高效地利用GPU尤其重要。

Method: 提出了一种基于代价约束的深度优先搜索方法（CB-DFS），结合CPU和GPU的并行能力，设计出Batch IDA*和Batch BTS等算法，并分析了相关超参数和硬件资源对性能的影响。

Result: 实验结果显示，GPU计算可以有效地在深度优先搜索中批量化处理，提升了在特定问题上的性能。

Conclusion: 结合GPU与CPU并行处理能力的策略在提升经典搜索算法性能方面具有显著潜力，同时保持了算法的最优性。

Abstract: The rapid advancement of GPU technology has unlocked powerful parallel
processing capabilities, creating new opportunities to enhance classic search
algorithms. A recent successful application of GPUs is in compressing large
pattern database (PDB) heuristics using neural networks while preserving
heuristic admissibility. However, very few algorithms have been designed to
exploit GPUs during search. Several variants of A* exist that batch GPU
computations. In this paper we introduce a method for batching GPU computations
in depth first search. In particular, we describe a new cost-bounded
depth-first search (CB-DFS) method that leverages the combined parallelism of
modern CPUs and GPUs. This is used to create algorithms like \emph{Batch IDA*},
an extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an
extensions of Budgeted Tree Search. Our approach builds on the general approach
used by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality
guarantees. We evaluate the approach on the 3x3 Rubik's Cube and 4x4 sliding
tile puzzle (STP), showing that GPU operations can be efficiently batched in
DFS. Additionally, we conduct extensive experiments to analyze the effects of
hyperparameters, neural network heuristic size, and hardware resources on
performance.

</details>


### [144] [Aime: Towards Fully-Autonomous Multi-Agent Framework](https://arxiv.org/abs/2507.11988)
*Yexuan Shi,Mingyu Wang,Yunxiang Cao,Hongjie Lai,Junjian Lan,Xin Han,Yu Wang,Jie Geng,Zhenan Li,Zihao Xia,Xiang Chen,Chen Li,Jian Xu,Wenbo Duan,Yuanshuo Zhu*

Main category: cs.AI

TL;DR: 研究引入Aime框架，通过动态规划和执行提升多智能体的适应性与鲁棒性，实验表明具有显著优越性。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统的“计划-执行”框架在执行刚性、代理能力静态性和通信低效性等方面存在局限性，限制了其在动态环境中的表现，亟需一种更灵活的架构。

Method: 提出了一种名为Aime的框架，包括动态规划器、演员工厂和集中进度管理模块，通过实时反馈动态调整策略、按需生成特定功能的智能体，并统一管理系统状态，实现了体系的灵活化与适应性。

Result: 通过在GAIA、SWE-bench Verified和WebVoyager等基准测试中，Aime展示出在通用推理、软件工程和实时网络导航上的显著优越性，超过了领域内的高水平专业代理。

Conclusion: Aime框架证明了在任务成功率与适应性上的优越性，为多智能体合作提供了更具弹性和高效的基础。

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are
emerging as a powerful paradigm for solving complex, multifaceted problems.
However, the potential of these systems is often constrained by the prevalent
plan-and-execute framework, which suffers from critical limitations: rigid plan
execution, static agent capabilities, and inefficient communication. These
weaknesses hinder their adaptability and robustness in dynamic environments.
This paper introduces Aime, a novel multi-agent framework designed to overcome
these challenges through dynamic, reactive planning and execution. Aime
replaces the conventional static workflow with a fluid and adaptive
architecture. Its core innovations include: (1) a Dynamic Planner that
continuously refines the overall strategy based on real-time execution
feedback; (2) an Actor Factory that implements Dynamic Actor instantiation,
assembling specialized agents on-demand with tailored tools and knowledge; and
(3) a centralized Progress Management Module that serves as a single source of
truth for coherent, system-wide state awareness. We empirically evaluated Aime
on a diverse suite of benchmarks spanning general reasoning (GAIA), software
engineering (SWE-bench Verified), and live web navigation (WebVoyager). The
results demonstrate that Aime consistently outperforms even highly specialized
state-of-the-art agents in their respective domains. Its superior adaptability
and task success rate establish Aime as a more resilient and effective
foundation for multi-agent collaboration.

</details>


### [145] [Understanding visual attention beehind bee-inspired UAV navigation](https://arxiv.org/abs/2507.11992)
*Pranav Rajbhandari,Abhi Veda,Matthew Garratt,Mandayam Srinivasan,Sridhar Ravi*

Main category: cs.AI

TL;DR: 本研究通过强化学习训练无人机使用光流进行导航，发现其注意力集中于光流的不连续区域和大光流幅值区域，实现了类似蜜蜂的导航能力。


<details>
  <summary>Details</summary>
Motivation: 蜜蜂利用有限的传感和计算能力导航障碍环境，启发研究如何将光流用于自主导航系统。

Method: 使用强化学习训练模拟蜜蜂导航能力的智能体，基于光流的感官输入在隧道中避障航行，并分析其注意模式。

Result: 训练的智能体主要关注光流中的不连续区域和大光流幅值区域，实现了障碍物规避与环境中心位置的保持。

Conclusion: 该策略类似飞行昆虫行为，可作为开发物理无人机控制方案的有效基础。

Abstract: Bio-inspired design is often used in autonomous UAV navigation due to the
capacity of biological systems for flight and obstacle avoidance despite
limited sensory and computational capabilities. In particular, honeybees mainly
use the sensory input of optic flow, the apparent motion of objects in their
visual field, to navigate cluttered environments. In our work, we train a
Reinforcement Learning agent to navigate a tunnel with obstacles using only
optic flow as sensory input. We inspect the attention patterns of trained
agents to determine the regions of optic flow on which they primarily base
their motor decisions. We find that agents trained in this way pay most
attention to regions of discontinuity in optic flow, as well as regions with
large optic flow magnitude. The trained agents appear to navigate a cluttered
tunnel by avoiding the obstacles that produce large optic flow, while
maintaining a centered position in their environment, which resembles the
behavior seen in flying insects. This pattern persists across independently
trained agents, which suggests that this could be a good strategy for
developing a simple explicit control law for physical UAVs.

</details>


### [146] [Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs](https://arxiv.org/abs/2507.12110)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: 提出了一种名为TPE-MARL的拓扑增强多智能体强化学习框架，用于优化混合交通中联网自动驾驶车辆的协作决策，显著提高了交通效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习中，探索与利用的平衡因维度爆炸问题而加剧。作者旨在解决混合交通中联网与自动驾驶车辆协作决策的优化问题。

Method: 设计一种支持动态交通流的游戏拓扑张量，用QMIX为基础算法，框架结合访问次数和智能体间互信息以增强探索与利用的平衡。

Result: 通过仿真实验，涵盖不同流量密度与自动化车辆渗透率，显示TPE-MARL具有比人类驾驶员更佳的交通效率、行驶安全以及决策平滑性。

Conclusion: 该方法成功压缩了高维交通状态信息，同时提高算法训练效率和决策合理性，在混合与全自动交通场景中都表现出优异性能。

Abstract: The exploration-exploitation trade-off constitutes one of the fundamental
challenges in reinforcement learning (RL), which is exacerbated in multi-agent
reinforcement learning (MARL) due to the exponential growth of joint
state-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL)
method for optimizing cooperative decision-making of connected and autonomous
vehicles (CAVs) in mixed traffic. This work presents two primary contributions:
First, we construct a game topology tensor for dynamic traffic flow,
effectively compressing high-dimensional traffic state information and decrease
the search space for MARL algorithms. Second, building upon the designed game
topology tensor and using QMIX as the backbone RL algorithm, we establish a
topology-enhanced MARL framework incorporating visit counts and agent mutual
information. Extensive simulations across varying traffic densities and CAV
penetration rates demonstrate the effectiveness of TPE-MARL. Evaluations
encompassing training dynamics, exploration patterns, macroscopic traffic
performance metrics, and microscopic vehicle behaviors reveal that TPE-MARL
successfully balances exploration and exploitation. Consequently, it exhibits
superior performance in terms of traffic efficiency, safety, decision
smoothness, and task completion. Furthermore, the algorithm demonstrates
decision-making rationality comparable to or exceeding that of human drivers in
both mixed-autonomy and fully autonomous traffic scenarios. Code of our work is
available at
\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.

</details>


### [147] [Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation](https://arxiv.org/abs/2507.12186)
*Edward Kim,Hanna Kurniawati*

Main category: cs.AI

TL;DR: 提出了一种新的在线POMDP求解器，能够深度采样未来历史并逐步更新策略，比现有方法效果更佳。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在线规划中的采样稀疏性问题，提高部分可观测马尔可夫决策过程（POMDP）的求解效率。

Method: 提出了一种名为部分可观测参考策略编程的算法，该算法优化采样未来历史并保证渐进策略更新，并提供理论性能保证，即性能损失由采样误差的平均值而非最大值决定。

Result: 通过两个动态变化的复杂环境问题进行验证，包括一个涉及约150步规划的直升机紧急场景，实验结果显示该算法显著优于当前基准。

Conclusion: 新算法在理论和实践中均表现优异，能够有效解决在线POMDP求解中的不足，展现出良好的应用前景。

Abstract: This paper proposes Partially Observable Reference Policy Programming, a
novel anytime online approximate POMDP solver which samples meaningful future
histories very deeply while simultaneously forcing a gradual policy update. We
provide theoretical guarantees for the algorithm's underlying scheme which say
that the performance loss is bounded by the average of the sampling
approximation errors rather than the usual maximum, a crucial requirement given
the sampling sparsity of online planning. Empirical evaluations on two
large-scale problems with dynamically evolving environments -- including a
helicopter emergency scenario in the Corsica region requiring approximately 150
planning steps -- corroborate the theoretical results and indicate that our
solver considerably outperforms current online benchmarks.

</details>


### [148] [Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning](https://arxiv.org/abs/2507.12215)
*Yuhao Chen,Shuochen Liu,Yuanjie Lyu,Chao Zhang,Jiayao Shi,Tong Xu*

Main category: cs.AI

TL;DR: 该论文通过中国象棋评估大型语言模型(LLMs)在空间战略推理上的表现，并提出了一个针对象棋的训练框架。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了探讨大型语言模型在复杂空间战略推理中的潜力，目前这方面的能力尚未充分挖掘。

Method: 提出了一个三阶段学习框架：(1)通过合法走子预测学习基本棋盘规则；(2)将战略注解纳入以提升决策能力；(3)通过使用多维奖励信号的强化学习进一步提升推理稳定性。

Result: 与通用LLMs相比，Xiangqi-R1在合法走子准确率提升18%，策略分析精度提升22%。

Conclusion: 结果表明，尽管当前LLMs在空间复杂任务中存在局限性，但通过定制化训练，可以显著提高其在具体棋类场景中的战略智能表现。

Abstract: Game playing has long served as a fundamental benchmark for evaluating
Artificial General Intelligence (AGI). While Large Language Models (LLMs) have
demonstrated impressive capabilities in general reasoning, their effectiveness
in spatial strategic reasoning, which is critical for complex and fully
observable board games, remains insufficiently explored. In this work, we adopt
Chinese Chess (Xiangqi) as a challenging and rich testbed due to its intricate
rules and spatial complexity. To advance LLMs' strategic competence in such
environments, we propose a training framework tailored to Xiangqi, built upon a
large-scale dataset of five million board-move pairs enhanced with expert
annotations and engine evaluations. Building on this foundation, we introduce
Xiangqi-R1, a 7B-parameter model trained in multi-stage manner: (1) fine-tuning
for legal move prediction to capture basic spatial rules, (2) incorporating
strategic annotations to improve decision-making, and (3) applying
reinforcement learning via Group Relative Policy Optimization (GRPO) with
multi-dimensional reward signals to enhance reasoning stability. Our
Experimental results indicate that, despite their size and power,
general-purpose LLMs struggle to achieve satisfactory performance in these
tasks. Compared to general-purpose LLMs, Xiangqi-R1 greatly advances with an
18% rise in move legality and a 22% boost in analysis accuracy. Our results
point to a promising path for creating general strategic intelligence in
spatially complex areas.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [149] [Recurrent U-Net-Based Graph Neural Network (RUGNN) for Accurate Deformation Predictions in Sheet Material Forming](https://arxiv.org/abs/2507.11547)
*Yingxue Zhao,Qianyi Chen,Haoran Li,Haosu Zhou,Hamid Reza Attar,Tobias Pfaff,Tailin Wu,Nan Li*

Main category: cs.LG

TL;DR: 本文介绍了一种新的基于图神经网络的代理模型RUGNN，用于预测板材成形过程中材料变形场。


<details>
  <summary>Details</summary>
Motivation: 传统的基于AI的代理模型无法很好地捕捉3D空间关系及处理置换不变性，因此需要一种新方法。

Method: 提出了一种结合U-Net和门控循环单元的RUGNN模型，并创新引入了“节点到表面”接触表示方法以提高计算效率。

Result: 通过冷成型和热成型案例研究，RUGNN模型在变形预测中表现优异，明显优于其他基准模型，并通过调参优化了模型效果。

Conclusion: RUGNN是一种可靠的方法，可支持板材成形设计，提供准确的可制造性预测。

Abstract: In recent years, various artificial intelligence-based surrogate models have
been proposed to provide rapid manufacturability predictions of material
forming processes. However, traditional AI-based surrogate models, typically
built with scalar or image-based neural networks, are limited in their ability
to capture complex 3D spatial relationships and to operate in a
permutation-invariant manner. To overcome these issues, emerging graph-based
surrogate models are developed using graph neural networks. This study
developed a new graph neural network surrogate model named Recurrent U
Net-based Graph Neural Network (RUGNN). The RUGNN model can achieve accurate
predictions of sheet material deformation fields across multiple forming
timesteps. The RUGNN model incorporates Gated Recurrent Units (GRUs) to model
temporal dynamics and a U-Net inspired graph-based downsample/upsample
mechanism to handle spatial long-range dependencies. A novel 'node-to-surface'
contact representation method was proposed, offering significant improvements
in computational efficiency for large-scale contact interactions. The RUGNN
model was validated using a cold forming case study and a more complex hot
forming case study using aluminium alloys. Results demonstrate that the RUGNN
model provides accurate deformation predictions closely matching ground truth
FE simulations and outperforming several baseline GNN architectures. Model
tuning was also performed to identify suitable hyperparameters, training
strategies, and input feature representations. These results demonstrate that
RUGNN is a reliable approach to support sheet material forming design by
enabling accurate manufacturability predictions.

</details>


### [150] [SurgeryLSTM: A Time-Aware Neural Model for Accurate and Explainable Length of Stay Prediction After Spine Surgery](https://arxiv.org/abs/2507.11570)
*Ha Na Cho,Sairam Sutari,Alexander Lopez,Hansen Bow,Kai Zheng*

Main category: cs.LG

TL;DR: 论文开发并评估了SurgeryLSTM，一种改进型模型，用于预测选择性脊柱手术的住院时间，结果显示其预测准确性和模型可解释性均优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 目前预测选择性脊柱手术住院时间的传统方法欠缺对时间序列数据的建模以及模型的可解释性，影响了临床中的有效应用。研究旨在通过整合时序建模和可解释性技术，提出更准确和可应用的解决方案。

Method: 采用包含注意力机制的双向长短期记忆网络（SurgeryLSTM），基于电子健康记录的围手术期结构化数据，与多种传统ML模型（如线性回归、随机森林、支持向量机、XGBoost）进行了对比分析，并引入可解释AI方法对关键预测因子进行识别。

Result: SurgeryLSTM实现了最高预测准确性（R2=0.86），优于XGBoost及其他基线模型；注意力机制提升了模型的解释性，使得临床医生能够更清晰追踪对预测结果贡献最大的时间段和特征。主要影响因子包括骨病、慢性肾病和腰椎融合手术。

Conclusion: SurgeryLSTM为选择性脊柱手术的住院时间预测提供了有效且可解释的AI解决方案，强调了将基于注意力机制的时序模型整合到医院规划流程中的潜力，以改进出院准备和个性化患者护理。

Abstract: Objective: To develop and evaluate machine learning (ML) models for
predicting length of stay (LOS) in elective spine surgery, with a focus on the
benefits of temporal modeling and model interpretability. Materials and
Methods: We compared traditional ML models (e.g., linear regression, random
forest, support vector machine (SVM), and XGBoost) with our developed model,
SurgeryLSTM, a masked bidirectional long short-term memory (BiLSTM) with an
attention, using structured perioperative electronic health records (EHR) data.
Performance was evaluated using the coefficient of determination (R2), and key
predictors were identified using explainable AI. Results: SurgeryLSTM achieved
the highest predictive accuracy (R2=0.86), outperforming XGBoost (R2 = 0.85)
and baseline models. The attention mechanism improved interpretability by
dynamically identifying influential temporal segments within preoperative
clinical sequences, allowing clinicians to trace which events or features most
contributed to each LOS prediction. Key predictors of LOS included bone
disorder, chronic kidney disease, and lumbar fusion identified as the most
impactful predictors of LOS. Discussion: Temporal modeling with attention
mechanisms significantly improves LOS prediction by capturing the sequential
nature of patient data. Unlike static models, SurgeryLSTM provides both higher
accuracy and greater interpretability, which are critical for clinical
adoption. These results highlight the potential of integrating attention-based
temporal models into hospital planning workflows. Conclusion: SurgeryLSTM
presents an effective and interpretable AI solution for LOS prediction in
elective spine surgery. Our findings support the integration of temporal,
explainable ML approaches into clinical decision support systems to enhance
discharge readiness and individualized patient care.

</details>


### [151] [Distribution-Free Uncertainty-Aware Virtual Sensing via Conformalized Neural Operators](https://arxiv.org/abs/2507.11574)
*Kazuma Kobayashi,Shailesh Garg,Farid Ahmed,Souvik Chakraborty,Syed Bahauddin Alam*

Main category: cs.LG

TL;DR: 提出了一种名为Conformalized Monte Carlo Operator (CMCO)的新方法，用于在神经算子学习中实现高效且可靠的不确定性量化（UQ）。该方法无须重新训练模型、集合学习或自定义损失函数，即可生成空间解析的不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 深度学习在复杂传感环境下的实用性受限于缺乏鲁棒的实时不确定性量化（UQ），特别是在高风险应用场景中。

Method: CMCO框架结合了Monte Carlo dropout与分裂保序预测（split conformal prediction），嵌入到单一的DeepONet架构中以实现分布无关的校准预测区间。

Result: 在湍流流动、弹塑性形变及全球宇宙射线剂量估计等三种应用中，CMCO方法在具有强空间梯度和基于代理传感的环境下，表现出接近理论预期的经验覆盖率。

Conclusion: CMCO提供了一种通用、易于整合且高效的不确定性量化解决方案，为数字孪生、传感器融合及安全监测领域的实时可信推断奠定了基础。

Abstract: Robust uncertainty quantification (UQ) remains a critical barrier to the safe
deployment of deep learning in real-time virtual sensing, particularly in
high-stakes domains where sparse, noisy, or non-collocated sensor data are the
norm. We introduce the Conformalized Monte Carlo Operator (CMCO), a framework
that transforms neural operator-based virtual sensing with calibrated,
distribution-free prediction intervals. By unifying Monte Carlo dropout with
split conformal prediction in a single DeepONet architecture, CMCO achieves
spatially resolved uncertainty estimates without retraining, ensembling, or
custom loss design. Our method addresses a longstanding challenge: how to endow
operator learning with efficient and reliable UQ across heterogeneous domains.
Through rigorous evaluation on three distinct applications: turbulent flow,
elastoplastic deformation, and global cosmic radiation dose estimation-CMCO
consistently attains near-nominal empirical coverage, even in settings with
strong spatial gradients and proxy-based sensing. This breakthrough offers a
general-purpose, plug-and-play UQ solution for neural operators, unlocking
real-time, trustworthy inference in digital twins, sensor fusion, and
safety-critical monitoring. By bridging theory and deployment with minimal
computational overhead, CMCO establishes a new foundation for scalable,
generalizable, and uncertainty-aware scientific machine learning.

</details>


### [152] [Einstein Fields: A Neural Perspective To Computational General Relativity](https://arxiv.org/abs/2507.11589)
*Sandeep Suresh Cranganore,Andrei Bodnar,Arturs Berzins,Johannes Brandstetter*

Main category: cs.LG

TL;DR: 本文提出了Einstein Fields，一种神经表示方法，将四维数值相对论模拟压缩到紧凑的隐式神经网络权重中，可以通过自动微分推导物理量。


<details>
  <summary>Details</summary>
Motivation: 现有数值相对论模拟通常计算量大、不高效，需要一种新的表示方法来提高存储效率和计算速度。

Method: 引入一种名为Einstein Fields的神经张量场，它能够将广义相对论的时空几何编码为神经场表示，并能产生动态行为，并在几个广义相对论测试中进行了验证。

Result: Einstein Fields展现出在四维时空的建模、跨网格的适应性、存储效率和导数准确性等方面的潜力，且易于使用。

Conclusion: 该研究为数值相对论提供了更可扩展、更高效的表示方法，并开源了基于JAX的库以促进领域发展。

Abstract: We introduce Einstein Fields, a neural representation that is designed to
compress computationally intensive four-dimensional numerical relativity
simulations into compact implicit neural network weights. By modeling the
\emph{metric}, which is the core tensor field of general relativity, Einstein
Fields enable the derivation of physical quantities via automatic
differentiation. However, unlike conventional neural fields (e.g., signed
distance, occupancy, or radiance fields), Einstein Fields are \emph{Neural
Tensor Fields} with the key difference that when encoding the spacetime
geometry of general relativity into neural field representations, dynamics
emerge naturally as a byproduct. Einstein Fields show remarkable potential,
including continuum modeling of 4D spacetime, mesh-agnosticity, storage
efficiency, derivative accuracy, and ease of use. We address these challenges
across several canonical test beds of general relativity and release an open
source JAX-based library, paving the way for more scalable and expressive
approaches to numerical relativity. Code is made available at
https://github.com/AndreiB137/EinFields

</details>


### [153] [Synthetic Tabular Data Generation: A Comparative Survey for Modern Techniques](https://arxiv.org/abs/2507.11590)
*Raju Challagundla,Mohsen Dorodchi,Pu Wang,Minwoo Lee*

Main category: cs.LG

TL;DR: 本文综述了关于合成表格数据生成的最新进展，并提出了一种基于实际生成目标的新型分类法，同时提出了一个基准框架以对齐技术创新与实际需求。


<details>
  <summary>Details</summary>
Motivation: 随着隐私法规的增强和真实数据访问的限制，合成数据生成成为解决隐私和数据获取问题的关键，尤其在金融、医疗和社会科学等领域。

Method: 引入了一种基于实际生成目标（比如应用、隐私保证、数据实用性）的新型分类法，并提出了一个评估合成数据技术的基准框架。

Result: 本综述构建了一个连接理论基础和实际部署的桥梁，为合成表格数据的开发和隐私敏感环境的应用提供指导。

Conclusion: 此研究为未来研究提供了方向，强调了根据实际需求开发更优的合成表格数据生成方法的重要性。

Abstract: As privacy regulations become more stringent and access to real-world data
becomes increasingly constrained, synthetic data generation has emerged as a
vital solution, especially for tabular datasets, which are central to domains
like finance, healthcare and the social sciences. This survey presents a
comprehensive and focused review of recent advances in synthetic tabular data
generation, emphasizing methods that preserve complex feature relationships,
maintain statistical fidelity, and satisfy privacy requirements. A key
contribution of this work is the introduction of a novel taxonomy based on
practical generation objectives, including intended downstream applications,
privacy guarantees, and data utility, directly informing methodological design
and evaluation strategies. Therefore, this review prioritizes the actionable
goals that drive synthetic data creation, including conditional generation and
risk-sensitive modeling. Additionally, the survey proposes a benchmark
framework to align technical innovation with real-world demands. By bridging
theoretical foundations with practical deployment, this work serves as both a
roadmap for future research and a guide for implementing synthetic tabular data
in privacy-critical environments.

</details>


### [154] [Learning Representations of Event Time Series with Sparse Autoencoders for Anomaly Detection, Similarity Search, and Unsupervised Classification](https://arxiv.org/abs/2507.11620)
*Steven Dillmann,Juan Rafael Martínez-Galarza*

Main category: cs.LG

TL;DR: 提出了一种新的事件时间序列表示方法，并使用稀疏自动编码器学习潜在物理意义表征，从而支持多种下游任务。


<details>
  <summary>Details</summary>
Motivation: 现有技术难以应对事件时间序列的非结构化和不规则特性，需要设计新的分析工具。

Method: 使用二维和三维张量表示事件时间序列，结合稀疏自动编码器以学习有意义的潜在特征表征。

Result: 在X射线天文学的真实数据集上验证了方法的有效性，能够捕捉时间和光谱特征，并区分类别。

Conclusion: 提供了一种灵活、可扩展且通用的框架，适用于科学和工业领域中复杂、非规则的事件时间序列分析。

Abstract: Event time series are sequences of discrete events occurring at irregular
time intervals, each associated with a domain-specific observational modality.
They are common in domains such as high-energy astrophysics, computational
social science, cybersecurity, finance, healthcare, neuroscience, and
seismology. Their unstructured and irregular structure poses significant
challenges for extracting meaningful patterns and identifying salient phenomena
using conventional techniques. We propose novel two- and three-dimensional
tensor representations for event time series, coupled with sparse autoencoders
that learn physically meaningful latent representations. These embeddings
support a variety of downstream tasks, including anomaly detection,
similarity-based retrieval, semantic clustering, and unsupervised
classification. We demonstrate our approach on a real-world dataset from X-ray
astronomy, showing that these representations successfully capture temporal and
spectral signatures and isolate diverse classes of X-ray transients. Our
framework offers a flexible, scalable, and generalizable solution for analyzing
complex, irregular event time series across scientific and industrial domains.

</details>


### [155] [Deep Generative Methods and Tire Architecture Design](https://arxiv.org/abs/2507.11639)
*Fouad Oubari,Raphael Meunier,Rodrigue Décatoire,Mathilde Mougeot*

Main category: cs.LG

TL;DR: 本研究评估了五种深度生成模型在工业轮胎架构生成中的表现，并提出了一种新的分类修补方法以增强离散扩散模型的条件生成能力。研究发现扩散模型综合性能最优，在特定任务中某些模型表现不同优势。


<details>
  <summary>Details</summary>
Motivation: 深度生成模型逐渐兴起，但如何选择最佳模型以满足复杂制造设计任务仍不明确。针对这一问题，本研究聚焦于五种代表性模型的整体优劣势分析。

Method: 研究测试了五种主流深度生成模型，并提出分类修补技术以改进扩散模型的条件生成能力。此外，通过特定几何意识指标，对各模型在工业轮胎架构生成中的表现进行了全面评估。

Result: 扩散模型表现综合最佳，但在特定条件生成案例中，掩膜训练的VAE 在大多数条件指标上优于MMVAE，而在扩散模型中，MDM在分布内表现更优，DDPM对分布外维度约束的适应性更强。

Conclusion: 扩散模型表现整体优异，提出的分类修补方法提升了离散扩散模型的条件生成能力，不同模型在具体场景中表现各异，为工业实践中的模型选择提供指导。

Abstract: As deep generative models proliferate across the AI landscape, industrial
practitioners still face critical yet unanswered questions about which deep
generative models best suit complex manufacturing design tasks. This work
addresses this question through a complete study of five representative models
(Variational Autoencoder, Generative Adversarial Network, multimodal
Variational Autoencoder, Denoising Diffusion Probabilistic Model, and
Multinomial Diffusion Model) on industrial tire architecture generation. Our
evaluation spans three key industrial scenarios: (i) unconditional generation
of complete multi-component designs, (ii) component-conditioned generation
(reconstructing architectures from partial observations), and (iii)
dimension-constrained generation (creating designs that satisfy specific
dimensional requirements). To enable discrete diffusion models to handle
conditional scenarios, we introduce categorical inpainting, a mask-aware
reverse diffusion process that preserves known labels without requiring
additional training. Our evaluation employs geometry-aware metrics specifically
calibrated for industrial requirements, quantifying spatial coherence,
component interaction, structural connectivity, and perceptual fidelity. Our
findings reveal that diffusion models achieve the strongest overall
performance; a masking-trained VAE nonetheless outperforms the multimodal
variant MMVAE\textsuperscript{+} on nearly all component-conditioned metrics,
and within the diffusion family MDM leads in-distribution whereas DDPM
generalises better to out-of-distribution dimensional constraints.

</details>


### [156] [Tracing the Path to Grokking: Embeddings, Dropout, and Network Activation](https://arxiv.org/abs/2507.11645)
*Ahmed Salah,David Yevick*

Main category: cs.LG

TL;DR: 本文提出多个实用指标来预测神经网络的"grokking"现象，即测试准确率滞后于训练准确率的显著提升，包括丢弃法下的方差、鲁棒性、嵌入相似性和稀疏性衡量等。


<details>
  <summary>Details</summary>
Motivation: 研究如何预测神经网络中的"grokking"现象并揭示其行为与成因。

Method: 通过测量丢弃法下的鲁棒曲线、测试准确率的方差、非活跃神经元百分比变化、嵌入分布特性等指标来追踪和预测"grokking"行为。

Result: 发现模型在"grokking"期间，丢弃法下的方差存在局部最大值，非活跃神经元百分比减少，嵌入趋向双峰分布，与余弦相似性模式和数据集对称性相关联。

Conclusion: 提出的指标不仅能够监测和预测"grokking"现象，还为其起源和行为提供了新的洞察。

Abstract: Grokking refers to delayed generalization in which the increase in test
accuracy of a neural network occurs appreciably after the improvement in
training accuracy This paper introduces several practical metrics including
variance under dropout, robustness, embedding similarity, and sparsity
measures, that can forecast grokking behavior. Specifically, the resilience of
neural networks to noise during inference is estimated from a Dropout
Robustness Curve (DRC) obtained from the variation of the accuracy with the
dropout rate as the model transitions from memorization to generalization. The
variance of the test accuracy under stochastic dropout across training
checkpoints further exhibits a local maximum during the grokking. Additionally,
the percentage of inactive neurons decreases during generalization, while the
embeddings tend to a bimodal distribution independent of initialization that
correlates with the observed cosine similarity patterns and dataset symmetries.
These metrics additionally provide valuable insight into the origin and
behaviour of grokking.

</details>


### [157] [ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs](https://arxiv.org/abs/2507.11649)
*Daniel Commey,Benjamin Appiah,Griffith S. Klogo,Garth V. Crosby*

Main category: cs.LG

TL;DR: 本文提出了一种结合零知识证明（ZKPs）的新协议用于联邦学习（FL）的隐私保护与可验证评估。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习的评估环节可能泄露敏感信息，需要一种方法实现数据的隐私保护。

Method: 利用零知识证明，客户端生成证明其本地损失低于特定阈值，而无需公开实际损失值，并在无第三方API依赖下实现。

Result: 在MNIST和HAR数据集上，验证了所提方法在计算开销、通信成本和可验证性上的有效性。

Conclusion: 提出的方案成功结合了隐私保护与高效验证，为联邦学习的评估设计提供了一种创新方向。

Abstract: Federated Learning (FL) enables collaborative model training on decentralized
data without exposing raw data. However, the evaluation phase in FL may leak
sensitive information through shared performance metrics. In this paper, we
propose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to
enable privacy-preserving and verifiable evaluation for FL. Instead of
revealing raw loss values, clients generate a succinct proof asserting that
their local loss is below a predefined threshold. Our approach is implemented
without reliance on external APIs, using self-contained modules for federated
learning simulation, ZKP circuit design, and experimental evaluation on both
the MNIST and Human Activity Recognition (HAR) datasets. We focus on a
threshold-based proof for a simple Convolutional Neural Network (CNN) model
(for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate
the approach in terms of computational overhead, communication cost, and
verifiability.

</details>


### [158] [STAGED: A Multi-Agent Neural Network for Learning Cellular Interaction Dynamics](https://arxiv.org/abs/2507.11660)
*Joao F. Rocha,Ke Xu,Xingzhi Sun,Ananya Krishna,Dhananjay Bhaskar,Blanche Mongeon,Morgan Craig,Mark Gerstein,Smita Krishnaswamy*

Main category: cs.LG

TL;DR: 本文介绍了一种名为STAGED的新方法，将空间时间代理建模与深度学习相结合，实现对细胞间通信和细胞内基因调控网络的建模。


<details>
  <summary>Details</summary>
Motivation: 当前的单细胞技术和空间转录组学方法无法通过数据驱动方式充分捕捉复杂的细胞动态交互，而传统基于规则的代理建模无法满足需求。

Method: 提出STAGED方法，结合代理建模和深度学习技术，使用图神经网络（GDEs）建模基因间的相互作用，动态学习交互权重，并通过注意力机制进行优化。

Result: 模型能够准确捕捉细胞内和细胞间的动态互动，并再现模拟轨迹和空间转录组数据中推断的轨迹。

Conclusion: 该方法为研究细胞动态提供了一种创新工具，能够更准确且适应性地表征复杂的细胞交互网络。

Abstract: The advent of single-cell technology has significantly improved our
understanding of cellular states and subpopulations in various tissues under
normal and diseased conditions by employing data-driven approaches such as
clustering and trajectory inference. However, these methods consider cells as
independent data points of population distributions. With spatial
transcriptomics, we can represent cellular organization, along with dynamic
cell-cell interactions that lead to changes in cell state. Still, key
computational advances are necessary to enable the data-driven learning of such
complex interactive cellular dynamics. While agent-based modeling (ABM)
provides a powerful framework, traditional approaches rely on handcrafted rules
derived from domain knowledge rather than data-driven approaches. To address
this, we introduce Spatio Temporal Agent-Based Graph Evolution Dynamics(STAGED)
integrating ABM with deep learning to model intercellular communication, and
its effect on the intracellular gene regulatory network. Using graph ODE
networks (GDEs) with shared weights per cell type, our approach represents
genes as vertices and interactions as directed edges, dynamically learning
their strengths through a designed attention mechanism. Trained to match
continuous trajectories of simulated as well as inferred trajectories from
spatial transcriptomics data, the model captures both intercellular and
intracellular interactions, enabling a more adaptive and accurate
representation of cellular dynamics.

</details>


### [159] [Composing Linear Layers from Irreducibles](https://arxiv.org/abs/2507.11688)
*Travis Pence,Daisuke Yamada,Vikas Singh*

Main category: cs.LG

TL;DR: 该论文探讨利用几何原语分解线性层，提出一种基于Clifford代数的方法，将其分解为旋量的乘积，并表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型模型中存在表现出组件化能力的低级原语，然而这些基本构建块的理解仍不清晰。作者希望通过研究线性层的组成结构，深入理解其基础原语。

Method: 利用Clifford代数，将线性层表达为双向量的组合，开发出一种可微分算法，将其分解为旋量的乘积，并显著减少参数需求，仅需O(log^2 d)个参数。

Result: 在LLM注意力层的键、查询和值投影中，基于旋量的线性层表现与强基线相当，例如Block-Hadamard和低秩近似。

Conclusion: 研究揭示了几何原语如何在深度学习模型中构成高级功能的代数视角，为模型设计提供了新启示。

Abstract: Contemporary large models often exhibit behaviors suggesting the presence of
low-level primitives that compose into modules with richer functionality, but
these fundamental building blocks remain poorly understood. We investigate this
compositional structure in linear layers by asking: can we identify/synthesize
linear transformations from a minimal set of geometric primitives? Using
Clifford algebra, we show that linear layers can be expressed as compositions
of bivectors -- geometric objects encoding oriented planes -- and introduce a
differentiable algorithm that decomposes them into products of rotors. This
construction uses only O(log^2 d) parameters, versus O(d^2) required by dense
matrices. Applied to the key, query, and value projections in LLM attention
layers, our rotor-based layers match the performance of strong baselines such
as block-Hadamard and low-rank approximations. Our findings provide an
algebraic perspective on how these geometric primitives can compose into
higher-level functions within deep models.

</details>


### [160] [The Impact of Coreset Selection on Spurious Correlations and Group Robustness](https://arxiv.org/abs/2507.11690)
*Amaya Dharmasiri,William Yang,Polina Kirichenko,Lydia Liu,Olga Russakovsky*

Main category: cs.LG

TL;DR: 该研究分析了数据集选择方法对偏见和模型鲁棒性的影响，特别是在存在虚假相关性时，提供了对常用抉择方法的全面评估。


<details>
  <summary>Details</summary>
Motivation: 数据集中存在的偏见可能导致模型学习虚假相关性。研究动机在于了解数据集缩减方法是否会加剧或减轻这种偏见并对模型的下游鲁棒性产生影响。

Method: 通过在十种虚假相关性基准下，使用五种衡量样本重要性/难度的指标以及五种数据选择策略，对不同大小的核心集进行了全面的实验分析。

Result: 揭示了样本难度与偏见取向间的复杂相互作用，以及数据集偏见对模型鲁棒性的影响。例如，通过基于嵌入的样本特征选择核心集比基于学习动态的选择方法风险更低。

Conclusion: 尽管某些核心集选择方法可以通过优先困难样本降低偏见，但它们并不能可靠地保证下游鲁棒性。

Abstract: Coreset selection methods have shown promise in reducing the training data
size while maintaining model performance for data-efficient machine learning.
However, as many datasets suffer from biases that cause models to learn
spurious correlations instead of causal features, it is important to understand
whether and how dataset reduction methods may perpetuate, amplify, or mitigate
these biases. In this work, we conduct the first comprehensive analysis of the
implications of data selection on the spurious bias levels of the selected
coresets and the robustness of downstream models trained on them. We use an
extensive experimental setting spanning ten different spurious correlations
benchmarks, five score metrics to characterize sample importance/ difficulty,
and five data selection policies across a broad range of coreset sizes.
Thereby, we unravel a series of nontrivial nuances in interactions between
sample difficulty and bias alignment, as well as dataset bias and resultant
model robustness. For example, we find that selecting coresets using
embedding-based sample characterization scores runs a comparatively lower risk
of inadvertently exacerbating bias than selecting using characterizations based
on learning dynamics. Most importantly, our analysis reveals that although some
coreset selection methods could achieve lower bias levels by prioritizing
difficult samples, they do not reliably guarantee downstream robustness.

</details>


### [161] [Time series classification of satellite data using LSTM networks: an approach for predicting leaf-fall to minimize railroad traffic disruption](https://arxiv.org/abs/2507.11702)
*Hein de Wilde,Ali Mohammed Mansoor Alsahag,Pierre Blanchet*

Main category: cs.LG

TL;DR: 该研究通过使用LSTM网络结合多光谱卫星数据和气象数据，开发了一个可预测落叶时间的系统，显著提高了预测的可靠性和可扩展性，为铁路行业的落叶缓解措施优化提供了可能性。


<details>
  <summary>Details</summary>
Motivation: 英国铁路行业因落叶导致的交通中断每年损失超过3亿英镑，当前的落叶预测方法在可扩展性和可靠性方面存有不足，因此亟需开发改进的预测系统。

Method: 本文采用LSTM网络，结合实地落叶数据与多光谱卫星及气象数据，开发了一个可缩放且可靠的落叶时间预测系统。

Result: 模型在预测落叶开始时间上的均方根误差为6.32天，结束时间的误差为9.31天，比以往研究更加精确。

Conclusion: 研究成果为铁路行业的落叶缓解措施优化提供了可能性，并有助于提升对复杂生态系统的理解。

Abstract: Railroad traffic disruption as a result of leaf-fall cost the UK rail
industry over 300 million per year and measures to mitigate such disruptions
are employed on a large scale, with 1.67 million kilometers of track being
treated in the UK in 2021 alone. Therefore, the ability to anticipate the
timing of leaf-fall would offer substantial benefits for rail network
operators, enabling the efficient scheduling of such mitigation measures.
However, current methodologies for predicting leaf-fall exhibit considerable
limitations in terms of scalability and reliability. This study endeavors to
devise a prediction system that leverages specialized prediction methods and
the latest satellite data sources to generate both scalable and reliable
insights into leaf-fall timings. An LSTM network trained on ground-truth
leaf-falling data combined with multispectral and meteorological satellite data
demonstrated a root-mean-square error of 6.32 days for predicting the start of
leaf-fall and 9.31 days for predicting the end of leaf-fall. The model, which
improves upon previous work on the topic, offers promising opportunities for
the optimization of leaf mitigation measures in the railway industry and the
improvement of our understanding of complex ecological systems.

</details>


### [162] [Reinforcement Learning from Adversarial Preferences in Tabular MDPs](https://arxiv.org/abs/2507.11706)
*Taira Tsuchiya,Shinji Ito,Haipeng Luo*

Main category: cs.LG

TL;DR: 本文提出了一种新框架---基于偏好的马尔可夫决策过程（PbMDPs），并研究了奖励函数由Borda分数决定的情形，分析了遗憾下界并设计了达到理论上限的算法。


<details>
  <summary>Details</summary>
Motivation: 当前马尔可夫决策过程（MDPs）的研究大多基于直接观察的数值损失值，而现实中的许多场景，偏好选择比直接的数值观察更为自然。本文旨在填补这类偏好驱动MDPs的研究空白。

Method: 作者首先提出了PbMDPs框架并针对Borda评分设定导出了遗憾下界；随后设计了两类遗憾最小化算法，包括基于全局占用测度优化的方法和基于策略优化的方法，并分别分析了已知与未知转移的情况。

Result: 本文得出PbMDPs框架下Borda评分的遗憾下界是 $\Omega( (H^2 S K)^{1/3} T^{2/3} )$，并提出两种策略达到此界限。基于全局优化方法的遗憾界为$\tilde{O}((H^2 S^2 K)^{1/3} T^{2/3} )$，而基于策略优化的方法遗憾接近为$\tilde{O}( (H^6 S K^5)^{1/3} T^{2/3} )$，且适用于未知转移设定。

Conclusion: 本文首次从理论和算法两个层面对PbMDPs进行研究，为偏好驱动的决策过程分析提供了重要的理论依据和解决方案，同时指出了针对状态数量的优化仍有改进空间。

Abstract: We introduce a new framework of episodic tabular Markov decision processes
(MDPs) with adversarial preferences, which we refer to as preference-based MDPs
(PbMDPs). Unlike standard episodic MDPs with adversarial losses, where the
numerical value of the loss is directly observed, in PbMDPs the learner instead
observes preferences between two candidate arms, which represent the choices
being compared. In this work, we focus specifically on the setting where the
reward functions are determined by Borda scores. We begin by establishing a
regret lower bound for PbMDPs with Borda scores. As a preliminary step, we
present a simple instance to prove a lower bound of $\Omega(\sqrt{HSAT})$ for
episodic MDPs with adversarial losses, where $H$ is the number of steps per
episode, $S$ is the number of states, $A$ is the number of actions, and $T$ is
the number of episodes. Leveraging this construction, we then derive a regret
lower bound of $\Omega( (H^2 S K)^{1/3} T^{2/3} )$ for PbMDPs with Borda
scores, where $K$ is the number of arms. Next, we develop algorithms that
achieve a regret bound of order $T^{2/3}$. We first propose a global
optimization approach based on online linear optimization over the set of all
occupancy measures, achieving a regret bound of $\tilde{O}((H^2 S^2 K)^{1/3}
T^{2/3} )$ under known transitions. However, this approach suffers from
suboptimal dependence on the potentially large number of states $S$ and
computational inefficiency. To address this, we propose a policy optimization
algorithm whose regret is roughly bounded by $\tilde{O}( (H^6 S K^5)^{1/3}
T^{2/3} )$ under known transitions, and further extend the result to the
unknown-transition setting.

</details>


### [163] [Subgraph Generation for Generalizing on Out-of-Distribution Links](https://arxiv.org/abs/2507.11710)
*Jay Revolinsky,Harry Shomer,Jiliang Tang*

Main category: cs.LG

TL;DR: 本文提出了一个名为FLEX的图生成模型框架，旨在增强图神经网络在超出分布场景中的表现，尤其是链接预测任务。


<details>
  <summary>Details</summary>
Motivation: 图神经网络（GNNs）在链接预测任务中表现出色，但对数据分布一致性依赖较高；图生成模型虽有生成能力，但应用场景受限，需要提出方法进行改进。

Method: 提出了FLEX框架，利用（1）结构条件图生成和（2）自编码器与GNN的对抗共训机制，确保样本间分布对齐，以增强分布外场景下的表现。

Result: 在合成和真实世界的分布外场景中进行了多项实验，验证了FLEX的性能提升能力，并探讨了图数据增强对链接结构的影响。

Conclusion: FLEX框架在不需要领域专家知识的情况下，能够有效增强分布外链接预测任务的性能，其代码已开源以供研究者使用。

Abstract: Graphs Neural Networks (GNNs) demonstrate high-performance on the link
prediction (LP) task. However, these models often rely on all dataset samples
being drawn from the same distribution. In addition, graph generative models
(GGMs) show a pronounced ability to generate novel output graphs. Despite this,
GGM applications remain largely limited to domain-specific tasks. To bridge
this gap, we propose FLEX as a GGM framework which leverages two mechanism: (1)
structurally-conditioned graph generation, and (2) adversarial co-training
between an auto-encoder and GNN. As such, FLEX ensures structural-alignment
between sample distributions to enhance link-prediction performance in
out-of-distribution (OOD) scenarios. Notably, FLEX does not require expert
knowledge to function in different OOD scenarios. Numerous experiments are
conducted in synthetic and real-world OOD settings to demonstrate FLEX's
performance-enhancing ability, with further analysis for understanding the
effects of graph data augmentation on link structures. The source code is
available here: https://github.com/revolins/FlexOOD.

</details>


### [164] [Globalization for Scalable Short-term Load Forecasting](https://arxiv.org/abs/2507.11729)
*Amirhossein Ahmadi,Hamidreza Zareipour,Henry Leung*

Main category: cs.LG

TL;DR: 本研究比较了电力传输网络负载预测中的局部预测模型（LFMs）与全球预测模型（GFMs），并提出新的时间序列聚类方法以应对数据异质性和漂移问题。


<details>
  <summary>Details</summary>
Motivation: 电力传输网络负载预测需要提高对数据漂移和异质性的适应能力，同时解决局部模型中的过拟合、扩展性差等问题。

Method: 本文提出时间序列聚类方法，分别针对特征变换模型引入基于模型的聚类方法，以及针对目标变换模型的加权实例聚类方法，并进行真实数据集实验验证。

Result: 通过在阿尔伯塔电力负载数据集上的实验，全球目标变换模型在加入全球特征与聚类技术后表现优于局部模型，而全球特征变换模型在局部与全球动态平衡方面存在挑战。

Conclusion: 全球化预测模型在应对数据漂移和提升精准性方面潜力巨大，但需要根据模型性质采取适当的聚类或特征变换策略以优化性能。

Abstract: Forecasting load in power transmission networks is essential across various
hierarchical levels, from the system level down to individual points of
delivery (PoD). While intuitive and locally accurate, traditional local
forecasting models (LFMs) face significant limitations, particularly in
handling generalizability, overfitting, data drift, and the cold start problem.
These methods also struggle with scalability, becoming computationally
expensive and less efficient as the network's size and data volume grow. In
contrast, global forecasting models (GFMs) offer a new approach to enhance
prediction generalizability, scalability, accuracy, and robustness through
globalization and cross-learning. This paper investigates global load
forecasting in the presence of data drifts, highlighting the impact of
different modeling techniques and data heterogeneity. We explore
feature-transforming and target-transforming models, demonstrating how
globalization, data heterogeneity, and data drift affect each differently. In
addition, we examine the role of globalization in peak load forecasting and its
potential for hierarchical forecasting. To address data heterogeneity and the
balance between globality and locality, we propose separate time series
clustering (TSC) methods, introducing model-based TSC for feature-transforming
models and new weighted instance-based TSC for target-transforming models.
Through extensive experiments on a real-world dataset of Alberta's electricity
load, we demonstrate that global target-transforming models consistently
outperform their local counterparts, especially when enriched with global
features and clustering techniques. In contrast, global feature-transforming
models face challenges in balancing local and global dynamics, often requiring
TSC to manage data heterogeneity effectively.

</details>


### [165] [Graph Neural Networks Powered by Encoder Embedding for Improved Node Learning](https://arxiv.org/abs/2507.11732)
*Shiyu Chen,Cencheng Shen,Youngser Park,Carey E. Priebe*

Main category: cs.LG

TL;DR: 提出了使用一种称为GEE的统计方法为GNN生成高质量初始节点特征的框架，显著提升了节点聚类和分类的性能。


<details>
  <summary>Details</summary>
Motivation: 传统GNN依赖随机或简单的初始特征表示，导致收敛慢和性能受限，因此需要优化初始特征以提升性能。

Method: 利用One-hot图编码技术（GEE）生成高质量初始节点特征，并将其与GNN整合形成GEE驱动的GNN（GG），同时提出了用于分类任务的增强版本GG-C。

Result: 在节点聚类任务中，GG在所有实际数据集上均达到最新性能，并且收敛速度更快；在分类任务中，GG-C性能优于其他基线方法。

Conclusion: 结构感知的特征初始化对发挥GNN的潜力至关重要，GEE框架显著提升了GNN的整体性能。

Abstract: Graph neural networks (GNNs) have emerged as a powerful framework for a wide
range of node-level graph learning tasks. However, their performance is often
constrained by reliance on random or minimally informed initial feature
representations, which can lead to slow convergence and suboptimal solutions.
In this paper, we leverage a statistically grounded method, one-hot graph
encoder embedding (GEE), to generate high-quality initial node features that
enhance the end-to-end training of GNNs. We refer to this integrated framework
as the GEE-powered GNN (GG), and demonstrate its effectiveness through
extensive simulations and real-world experiments across both unsupervised and
supervised settings. In node clustering, GG consistently achieves
state-of-the-art performance, ranking first across all evaluated real-world
datasets, while exhibiting faster convergence compared to the standard GNN. For
node classification, we further propose an enhanced variant, GG-C, which
concatenates the outputs of GG and GEE and outperforms competing baselines.
These results confirm the importance of principled, structure-aware feature
initialization in realizing the full potential of GNNs.

</details>


### [166] [Sparse Identification of Nonlinear Dynamics with Conformal Prediction](https://arxiv.org/abs/2507.11739)
*Urban Fasel*

Main category: cs.LG

TL;DR: 本文探讨了将符合预测方法与SINDy模型集成，用于时间序列预测、不确定性量化及模型选择的提升。


<details>
  <summary>Details</summary>
Motivation: SINDy是一种从数据中发现非线性动力学系统模型的工具，但其模型可靠性评估尤为重要。虽然已有诸多SINDy的不确定性量化方法，但需要更通用的解决方案。

Method: 通过将符合预测方法（Conformal Prediction）与E-SINDy集成，应用于时间序列预测的不确定性量化、基于特征重要性的模型选择及模型系数的不确定性量化。

Result: 验证过程中，方法在预测间隔覆盖目标、特征重要性量化及鲁棒的系数不确定性区间生成方面都显现出优越表现，甚至在非高斯噪声情况下也表现优异。

Conclusion: 符合预测方法结合E-SINDy提供了一种通用且有效的不确定性量化框架，在复杂系统模型的分析和预测中具有显著应用价值。

Abstract: The Sparse Identification of Nonlinear Dynamics (SINDy) is a method for
discovering nonlinear dynamical system models from data. Quantifying
uncertainty in SINDy models is essential for assessing their reliability,
particularly in safety-critical applications. While various uncertainty
quantification methods exist for SINDy, including Bayesian and ensemble
approaches, this work explores the integration of Conformal Prediction, a
framework that can provide valid prediction intervals with coverage guarantees
based on minimal assumptions like data exchangeability. We introduce three
applications of conformal prediction with Ensemble-SINDy (E-SINDy): (1)
quantifying uncertainty in time series prediction, (2) model selection based on
library feature importance, and (3) quantifying the uncertainty of identified
model coefficients using feature conformal prediction. We demonstrate the three
applications on stochastic predator-prey dynamics and several chaotic dynamical
systems. We show that conformal prediction methods integrated with E-SINDy can
reliably achieve desired target coverage for time series forecasting,
effectively quantify feature importance, and produce more robust uncertainty
intervals for model coefficients, even under non-Gaussian noise, compared to
standard E-SINDy coefficient estimates.

</details>


### [167] [A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction](https://arxiv.org/abs/2507.11757)
*Yuehua Song,Yong Gao*

Main category: cs.LG

TL;DR: 本文介绍了一种名为Graph-in-Graph (GiG)的框架，结合转导学习和归纳学习来准确预测药物-靶点相互作用（DTIs），并表现出显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前基于图神经网络（GNN）的DTI预测方法虽有所进展，但在有效整合药物、靶点及其相互作用的多样特性方面存在不足。

Method: 提出Graph-in-Graph (GiG)模型，将药物和靶点分子的分子结构图表征为药物-靶点相互作用图中的元节点，通过结合转导学习和归纳学习方法，全面挖掘分子层面和相互作用网络层面的特性。

Result: 实验结果表明，GiG模型在所有评估指标上均显著优于现有方法，验证了整合不同学习范式和相互作用数据的优势。

Conclusion: GiG模型成功提升了DTI预测的准确性，显示出整合多样特性和学习方法的潜力，为药物发现与靶点验证提供了新的有效工具。

Abstract: Accurately predicting drug-target interactions (DTIs) is pivotal for
advancing drug discovery and target validation techniques. While machine
learning approaches including those that are based on Graph Neural Networks
(GNN) have achieved notable success in DTI prediction, many of them have
difficulties in effectively integrating the diverse features of drugs, targets
and their interactions. To address this limitation, we introduce a novel
framework to take advantage of the power of both transductive learning and
inductive learning so that features at molecular level and drug-target
interaction network level can be exploited. Within this framework is a
GNN-based model called Graph-in-Graph (GiG) that represents graphs of drug and
target molecular structures as meta-nodes in a drug-target interaction graph,
enabling a detailed exploration of their intricate relationships. To evaluate
the proposed model, we have compiled a special benchmark comprising drug
SMILES, protein sequences, and their interaction data, which is interesting in
its own right. Our experimental results demonstrate that the GiG model
significantly outperforms existing approaches across all evaluation metrics,
highlighting the benefits of integrating different learning paradigms and
interaction data.

</details>


### [168] [Torsional-GFN: a conditional conformation generator for small molecules](https://arxiv.org/abs/2507.11759)
*Alexandra Volokhova,Léna Néhale Ezzine,Piotr Gaiński,Luca Scimeca,Emmanuel Bengio,Prudencio Tossou,Yoshua Bengio,Alex Hernandez-Garcia*

Main category: cs.LG

TL;DR: 研究提出了一种新方法（Torsional-GFN）用于高效生成分子构象，目标是近似采样玻尔兹曼分布。


<details>
  <summary>Details</summary>
Motivation: 探讨如何通过生成式机器学习方法更高效地从玻尔兹曼分布中采样分子构象，以支持药物发现过程中的应用（如估算分子与目标的结合亲和力）。

Method: 提出了一种条件生成流网络（GFlowNet），称为Torsional-GFN，它使用奖励函数作为训练信号，基于分子图与局部结构的条件，采样分子扭转角度的旋转。

Result: 实验结果表明，Torsional-GFN能在多个分子上实现近似玻尔兹曼分布的采样，并且能够对未见过的结合键长度和角度进行零样本泛化。

Conclusion: 提出的方法为扩展到更大分子体系、实现对未知分子的零样本泛化，以及将局部结构生成纳入GFlowNet模型中提供了新的可能性。

Abstract: Generating stable molecular conformations is crucial in several drug
discovery applications, such as estimating the binding affinity of a molecule
to a target. Recently, generative machine learning methods have emerged as a
promising, more efficient method than molecular dynamics for sampling of
conformations from the Boltzmann distribution. In this paper, we introduce
Torsional-GFN, a conditional GFlowNet specifically designed to sample
conformations of molecules proportionally to their Boltzmann distribution,
using only a reward function as training signal. Conditioned on a molecular
graph and its local structure (bond lengths and angles), Torsional-GFN samples
rotations of its torsion angles. Our results demonstrate that Torsional-GFN is
able to sample conformations approximately proportional to the Boltzmann
distribution for multiple molecules with a single model, and allows for
zero-shot generalization to unseen bond lengths and angles coming from the MD
simulations for such molecules. Our work presents a promising avenue for
scaling the proposed approach to larger molecular systems, achieving zero-shot
generalization to unseen molecules, and including the generation of the local
structure into the GFlowNet model.

</details>


### [169] [Scaling laws for activation steering with Llama 2 models and refusal mechanisms](https://arxiv.org/abs/2507.11771)
*Sheikh Abdur Raheem Ali,Justin Xu,Ivory Yang,Jasmine Xinze Li,Ayse Arslan,Clark Benham*

Main category: cs.LG

TL;DR: 本文研究对抗差异加权(CAA)在Llama 2模型中如何受规模影响，同时分析其调控语言模型输出的效果。


<details>
  <summary>Details</summary>
Motivation: 研究在模型复杂度增加的情况下，现有对齐技术的有效性，以及如何更好地控制LLMs输出特性。

Method: 基于对抗差异加权(CAA)，通过模型残差流的方向操控进行研究，使用Llama 2家族模型（7B, 13B, 70B）验证方法。

Result: 发现1) CAA在模型早中期层效果最优；2) CAA的效果随模型规模扩大而减弱；3) 负向引导比正向引导在各模型规模下更加显著。

Conclusion: 研究表明，CAA是一种有效的输出控制技术，但其适用性受层次和模型规模制约，同时为负向引导提供更强表现。

Abstract: As large language models (LLMs) evolve in complexity and capability, the
efficacy of less widely deployed alignment techniques are uncertain. Building
on previous work on activation steering and contrastive activation addition
(CAA), this paper explores the effectiveness of CAA with model scale using the
family of Llama 2 models (7B, 13B, and 70B). CAA works by finding desirable
'directions' in the model's residual stream vector space using contrastive
pairs (for example, hate to love) and adding this direction to the residual
stream during the forward pass. It directly manipulates the residual stream and
aims to extract features from language models to better control their outputs.
Using answer matching questions centered around the refusal behavior, we found
that 1) CAA is most effective when applied at early-mid layers. 2) The
effectiveness of CAA diminishes with model size. 3) Negative steering has more
pronounced effects than positive steering across all model sizes.

</details>


### [170] [Predicting Delayed Trajectories Using Network Features: A Study on the Dutch Railway Network](https://arxiv.org/abs/2507.11776)
*Merel Kampere,Ali Mohammed Mansoor Alsahag*

Main category: cs.LG

TL;DR: 研究使用XGBoost分类器结合拓扑特性预测荷兰铁路系统延误，但结果表明模型性能有限，需进一步改进。


<details>
  <summary>Details</summary>
Motivation: 解决荷兰铁路网络延误预测研究的不足，尤其关注全网络范围的延误传播模式，而不仅局限于短期预测。

Method: 使用XGBoost分类器并结合拓扑特性（如结点中心性度量），并与RandomForest、DecisionTree等多种分类器比较，以预测延误轨迹。

Result: 模型在非同时测试场景中表现有限，表明需要更多针对性的改进以提高预测性能。

Conclusion: 尽管结果受限，研究拓展了对交通网络评估的理解，并为开发更强预测模型指出了未来的发展方向。

Abstract: The Dutch railway network is one of the busiest in the world, with delays
being a prominent concern for the principal passenger railway operator NS. This
research addresses a gap in delay prediction studies within the Dutch railway
network by employing an XGBoost Classifier with a focus on topological
features. Current research predominantly emphasizes short-term predictions and
neglects the broader network-wide patterns essential for mitigating ripple
effects. This research implements and improves an existing methodology,
originally designed to forecast the evolution of the fast-changing US air
network, to predict delays in the Dutch Railways. By integrating Node
Centrality Measures and comparing multiple classifiers like RandomForest,
DecisionTree, GradientBoosting, AdaBoost, and LogisticRegression, the goal is
to predict delayed trajectories. However, the results reveal limited
performance, especially in non-simultaneous testing scenarios, suggesting the
necessity for more context-specific adaptations. Regardless, this research
contributes to the understanding of transportation network evaluation and
proposes future directions for developing more robust predictive models for
delays.

</details>


### [171] [Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation](https://arxiv.org/abs/2507.11789)
*Alessandro Palma,Sergei Rybakov,Leon Hetzel,Stephan Günnemann,Fabian J. Theis*

Main category: cs.LG

TL;DR: FlatVI通过正则化潜在空间为欧几里得几何结构，改进单细胞RNA测序数据的轨迹重建与流形插值。


<details>
  <summary>Details</summary>
Motivation: 现有方法的潜在空间插值假设线性转变及欧几里得几何，但这种假设在未强制执行下可能偏离数据流形的测地路径。为了解决这个问题，引入FlatVI框架。

Method: 提出FlatVI框架，通过正则化潜在流形，使其趋于欧几里得几何，并鼓励潜在空间中的直线近似解码后单细胞流形上的测地插值。

Result: 在合成数据上验证方法的理论正确性，在单细胞RNA时序数据上表现为改进的轨迹重建与流形插值效果。

Conclusion: FlatVI优化了现有方法在潜在空间几何方面的不足，证明其在处理单细胞RNA测序数据方面更为高效与符合理论预期。

Abstract: Latent space interpolations are a powerful tool for navigating deep
generative models in applied settings. An example is single-cell RNA
sequencing, where existing methods model cellular state transitions as latent
space interpolations with variational autoencoders, often assuming linear
shifts and Euclidean geometry. However, unless explicitly enforced, linear
interpolations in the latent space may not correspond to geodesic paths on the
data manifold, limiting methods that assume Euclidean geometry in the data
representations. We introduce FlatVI, a novel training framework that
regularises the latent manifold of discrete-likelihood variational autoencoders
towards Euclidean geometry, specifically tailored for modelling single-cell
count data. By encouraging straight lines in the latent space to approximate
geodesic interpolations on the decoded single-cell manifold, FlatVI enhances
compatibility with downstream approaches that assume Euclidean latent geometry.
Experiments on synthetic data support the theoretical soundness of our
approach, while applications to time-resolved single-cell RNA sequencing data
demonstrate improved trajectory reconstruction and manifold interpolation.

</details>


### [172] [CLID-MU: Cross-Layer Information Divergence Based Meta Update Strategy for Learning with Noisy Labels](https://arxiv.org/abs/2507.11807)
*Ruofan Hu,Dongyu Zhang,Huayi Zhang,Elke Rundensteiner*

Main category: cs.LG

TL;DR: 提出了一种名为CLID-MU的方法，用于无需干净标注数据集的带标签噪声学习，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的元学习方法需要依赖干净标注数据集，而这在实际中很难获取，因此需要一种无需干净标注数据集的带噪声标签学习方法。

Method: 设计了基于跨层信息分歧的元学习更新策略（CLID-MU），通过分析噪声对跨层数据结构一致性的影响，引导模型训练。

Result: 在多种合成和真实噪声的基准数据集上实验表明，CLID-MU优于最先进的方法。

Conclusion: 提出的CLID-MU方法在无需依赖干净标注数据集的情况下，能够有效处理有噪声的标签数据，提升了模型性能。

Abstract: Learning with noisy labels (LNL) is essential for training deep neural
networks with imperfect data. Meta-learning approaches have achieved success by
using a clean unbiased labeled set to train a robust model. However, this
approach heavily depends on the availability of a clean labeled meta-dataset,
which is difficult to obtain in practice. In this work, we thus tackle the
challenge of meta-learning for noisy label scenarios without relying on a clean
labeled dataset. Our approach leverages the data itself while bypassing the
need for labels. Building on the insight that clean samples effectively
preserve the consistency of related data structures across the last hidden and
the final layer, whereas noisy samples disrupt this consistency, we design the
Cross-layer Information Divergence-based Meta Update Strategy (CLID-MU).
CLID-MU leverages the alignment of data structures across these diverse feature
spaces to evaluate model performance and use this alignment to guide training.
Experiments on benchmark datasets with varying amounts of labels under both
synthetic and real-world noise demonstrate that CLID-MU outperforms
state-of-the-art methods. The code is released at
https://github.com/ruofanhu/CLID-MU.

</details>


### [173] [SynCoGen: Synthesizable 3D Molecule Generation via Joint Reaction and Coordinate Modeling](https://arxiv.org/abs/2507.11818)
*Andrei Rekesh,Miruna Cretu,Dmytro Shevchuk,Vignesh Ram Somnath,Pietro Liò,Robert A. Batey,Mike Tyers,Michał Koziarski,Cheng-Hao Liu*

Main category: cs.LG

TL;DR: 本研究提出了一种名为SynCoGen的框架，用于同时生成可合成3D分子，通过结合掩码图扩散和流匹配生成分子。


<details>
  <summary>Details</summary>
Motivation: 当前生成小分子设计中合成可达性问题仍然是一个主要难题，尤其是在几何条件生成方面的限制。

Method: 提出SynCoGen框架，结合掩码图扩散与流匹配，从分子构建块、化学反应和原子坐标的联合分布中采样，并使用SynSpace数据集进行训练。

Result: SynCoGen在小分子图和构象生成上达到了最先进性能，并在蛋白配体生成中的零样本分子连接器设计上表现出色。

Conclusion: SynCoGen框架为未来多种适用场景（如分子扩展、优化和直接结构条件生成）奠定了基础。

Abstract: Ensuring synthesizability in generative small molecule design remains a major
challenge. While recent developments in synthesizable molecule generation have
demonstrated promising results, these efforts have been largely confined to 2D
molecular graph representations, limiting the ability to perform geometry-based
conditional generation. In this work, we present SynCoGen (Synthesizable
Co-Generation), a single framework that combines simultaneous masked graph
diffusion and flow matching for synthesizable 3D molecule generation. SynCoGen
samples from the joint distribution of molecular building blocks, chemical
reactions, and atomic coordinates. To train the model, we curated SynSpace, a
dataset containing over 600K synthesis-aware building block graphs and 3.3M
conformers. SynCoGen achieves state-of-the-art performance in unconditional
small molecule graph and conformer generation, and the model delivers
competitive performance in zero-shot molecular linker design for protein ligand
generation in drug discovery. Overall, this multimodal formulation represents a
foundation for future applications enabled by non-autoregressive molecular
generation, including analog expansion, lead optimization, and direct structure
conditioning.

</details>


### [174] [MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory](https://arxiv.org/abs/2507.11821)
*Pouya Shaeri,Arash Karimi,Ariane Middel*

Main category: cs.LG

TL;DR: 提出了一种名为MNIST-Gen的自动化框架，用于生成用户指定类别的MNIST风格数据集。


<details>
  <summary>Details</summary>
Motivation: 标准数据集如MNIST对于领域特定任务（如分类树、食物等）不可用，而创建定制数据集又受限于时间和法律问题。

Method: 利用基于CLIP的语义理解、强化学习和人工反馈，结合分层语义分类，生成MNIST风格的数据集；每个数据变换阶段以可组合的态射建模。

Result: 以Tree-MNIST和Food-MNIST为例，自动分类准确度达到85%，相比人工方式节省80%的时间。

Conclusion: MNIST-Gen框架提供快速、高效的方法生成领域特定数据集，同时维护高分类准确性，适合领域任务评估使用。

Abstract: Neural networks are often benchmarked using standard datasets such as MNIST,
FashionMNIST, or other variants of MNIST, which, while accessible, are limited
to generic classes such as digits or clothing items. For researchers working on
domain-specific tasks, such as classifying trees, food items, or other
real-world objects, these data sets are insufficient and irrelevant.
Additionally, creating and publishing a custom dataset can be time consuming,
legally constrained, or beyond the scope of individual projects. We present
MNIST-Gen, an automated, modular, and adaptive framework for generating
MNIST-style image datasets tailored to user-specified categories using
hierarchical semantic categorization. The system combines CLIP-based semantic
understanding with reinforcement learning and human feedback to achieve
intelligent categorization with minimal manual intervention. Our hierarchical
approach supports complex category structures with semantic characteristics,
enabling fine-grained subcategorization and multiple processing modes:
individual review for maximum control, smart batch processing for large
datasets, and fast batch processing for rapid creation. Inspired by category
theory, MNIST-Gen models each data transformation stage as a composable
morphism, enhancing clarity, modularity, and extensibility. As proof of
concept, we generate and benchmark two novel datasets-\textit{Tree-MNIST} and
\textit{Food-MNIST}-demonstrating MNIST-Gen's utility for producing
task-specific evaluation data while achieving 85\% automatic categorization
accuracy and 80\% time savings compared to manual approaches.

</details>


### [175] [HyperEvent:Learning Cohesive Events for Large-scale Dynamic Link Prediction](https://arxiv.org/abs/2507.11836)
*Jian Gao,Jianshe Wu,JingYi Ding*

Main category: cs.LG

TL;DR: 该研究提出了HyperEvent框架，通过重新定义动态链接预测为超事件识别任务，实现了对复合超事件的结构凝聚力的捕获，在多项数据集中超过现有方法，尤其在大规模数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前方法未能有效捕获复杂系统中复合超事件的结构凝聚力，希望通过新的框架提升对动态链接的预测能力。

Method: 提出HyperEvent框架，通过动态构建事件关联序列和事件相关性向量来量化历史事件之间的依赖性，以预测查询事件是否形成有效的超事件，并引入并行训练算法以提高效率。

Result: HyperEvent在多个数据集上取得了显著优势，特别是在Flight数据集上实现了6.95%的Mean Reciprocal Rank提升，同时训练时间仅为现有方法的10.17%。

Conclusion: HyperEvent框架不仅显著提升动态链接预测的准确性，同时通过并行算法大幅提高了效率，为动态图研究提供了新的思路。

Abstract: Dynamic link prediction in continuous-time dynamic graphs is a fundamental
task for modeling evolving complex systems. Existing node-centric and
event-centric methods focus on individual interactions or atomic states,
failing to capture the structural cohesion of composite hyper-events, groups of
causally related events. To address this, we propose HyperEvent, a framework
reframing dynamic link prediction as hyper-event recognition. Central to
HyperEvent is the dynamic construction of an association sequence using event
correlation vectors. These vectors quantify pairwise dependencies between the
query event and relevant historical events, thereby characterizing the
structural cohesion of a potential hyper-event. The framework predicts the
occurrence of the query event by evaluating whether it collectively forms a
valid hyper-event with these historical events. Notably, HyperEvent outperforms
state-of-the-art methods on 4 out of 5 datasets in the official leaderboard.
For scalability, we further introduce an efficient parallel training algorithm
that segments large event streams to enable concurrent training. Experiments
validate HyperEvent's superior accuracy and efficiency on large-scale graphs.
Among which HyperEvent achieves a 6.95% improvement in Mean Reciprocal Rank
over state-of-the-art baseline on the large-scale Flight dataset while
utilizing only 10.17% of the training time.

</details>


### [176] [Protenix-Mini: Efficient Structure Predictor via Compact Architecture, Few-Step Diffusion and Switchable pLM](https://arxiv.org/abs/2507.11839)
*Chengyue Gong,Xinshi Chen,Yuxuan Zhang,Yuxuan Song,Hao Zhou,Wenzhi Xiao*

Main category: cs.LG

TL;DR: Protenix-Mini通过优化采样策略和简化模型设计，显著降低了生物分子结构预测中的推理复杂性，同时仅带来1%到5%的性能下降。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在解决生物分子结构预测中模型效率与预测精度之间的平衡问题，推动实际应用中的高效推理和大规模应用。

Method: 提出了Protenix-Mini，通过将多步采样改为两步常微分方程（ODE）采样策略，同时去除冗余的Transformer组件并替换MSA模块为ESM模块，从而优化模型结构。

Result: Protenix-Mini在简化了模型设计后，能够在精度仅下降1%到5%的情况下，实现高效的蛋白质结构预测。

Conclusion: 这项研究展示了一种适合有限计算资源环境下的高效蛋白质结构预测模型，具有重要的实际应用价值。

Abstract: Lightweight inference is critical for biomolecular structure prediction and
other downstream tasks, enabling efficient real-world deployment and
inference-time scaling for large-scale applications. In this work, we address
the challenge of balancing model efficiency and prediction accuracy by making
several key modifications, 1) Multi-step AF3 sampler is replaced by a few-step
ODE sampler, significantly reducing computational overhead for the diffusion
module part during inference; 2) In the open-source Protenix framework, a
subset of pairformer or diffusion transformer blocks doesn't make contributions
to the final structure prediction, presenting opportunities for architectural
pruning and lightweight redesign; 3) A model incorporating an ESM module is
trained to substitute the conventional MSA module, reducing MSA preprocessing
time. Building on these key insights, we present Protenix-Mini, a compact and
optimized model designed for efficient protein structure prediction. This
streamlined version incorporates a more efficient architectural design with a
two-step Ordinary Differential Equation (ODE) sampling strategy. By eliminating
redundant Transformer components and refining the sampling process,
Protenix-Mini significantly reduces model complexity with slight accuracy drop.
Evaluations on benchmark datasets demonstrate that it achieves high-fidelity
predictions, with only a negligible 1 to 5 percent decrease in performance on
benchmark datasets compared to its full-scale counterpart. This makes
Protenix-Mini an ideal choice for applications where computational resources
are limited but accurate structure prediction remains crucial.

</details>


### [177] [Generalized Linear Bandits: Almost Optimal Regret with One-Pass Update](https://arxiv.org/abs/2507.11847)
*Yu-Jie Zhang,Sheng-An Xu,Peng Zhao,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 研究了一种广义线性bandit问题，提出了既能实现最优遗憾界限，又具备高效计算和存储的算法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时兼顾计算效率和统计效率，希望提出既有最优遗憾界限又满足低时间和空间复杂度的算法。

Method: 通过对在线镜像下降(OMD)估计器进行新的分析，利用混合损失的概念构建紧密置信集，实现了统计高效的单次更新方法，并设计出优化的遗憾界限算法。

Result: 提出的算法在每一轮中仅需$O(1)$时间复杂度和存储空间，且达到了接近最优的遗憾界限。

Conclusion: 所提算法在广义线性bandit问题中实现了统计效率和计算效率的兼顾，为该领域提供了新的方案。

Abstract: We study the generalized linear bandit (GLB) problem, a contextual
multi-armed bandit framework that extends the classical linear model by
incorporating a non-linear link function, thereby modeling a broad class of
reward distributions such as Bernoulli and Poisson. While GLBs are widely
applicable to real-world scenarios, their non-linear nature introduces
significant challenges in achieving both computational and statistical
efficiency. Existing methods typically trade off between two objectives, either
incurring high per-round costs for optimal regret guarantees or compromising
statistical efficiency to enable constant-time updates. In this paper, we
propose a jointly efficient algorithm that attains a nearly optimal regret
bound with $\mathcal{O}(1)$ time and space complexities per round. The core of
our method is a tight confidence set for the online mirror descent (OMD)
estimator, which is derived through a novel analysis that leverages the notion
of mix loss from online prediction. The analysis shows that our OMD estimator,
even with its one-pass updates, achieves statistical efficiency comparable to
maximum likelihood estimation, thereby leading to a jointly efficient
optimistic method.

</details>


### [178] [OrdShap: Feature Position Importance for Sequential Black-Box Models](https://arxiv.org/abs/2507.11855)
*Davin Hill,Brian L. Hill,Aria Masoomi,Vijay S. Nori,Robert E. Tillman,Jennifer Dy*

Main category: cs.LG

TL;DR: OrdShap是一种能够区分特征值和特征位置影响的归因方法，通过量化模型预测对特征位置置换的响应变化来实现。


<details>
  <summary>Details</summary>
Motivation: 现有的特征归因方法难以单独评估特征值和特征位置的影响，尤其是在具有时序依赖性的模型中。

Method: 引入OrdShap方法，利用博弈论中的Sanchez-Bergantiños值，计算特征位置敏感的归因，从而将特征值与位置影响分离。

Result: OrdShap在健康、自然语言和合成数据集上的实验结果显示其在区分特征值与特征位置归因方面的有效性，并揭示了模型的内在行为模式。

Conclusion: OrdShap方法为时序深度学习模型分析提供了一种理论上有依据且实际有效的归因工具，将进一步推动模型可解释性研究。

Abstract: Sequential deep learning models excel in domains with temporal or sequential
dependencies, but their complexity necessitates post-hoc feature attribution
methods for understanding their predictions. While existing techniques quantify
feature importance, they inherently assume fixed feature ordering - conflating
the effects of (1) feature values and (2) their positions within input
sequences. To address this gap, we introduce OrdShap, a novel attribution
method that disentangles these effects by quantifying how a model's predictions
change in response to permuting feature position. We establish a game-theoretic
connection between OrdShap and Sanchez-Berganti\~nos values, providing a
theoretically grounded approach to position-sensitive attribution. Empirical
results from health, natural language, and synthetic datasets highlight
OrdShap's effectiveness in capturing feature value and feature position
attributions, and provide deeper insight into model behavior.

</details>


### [179] [A Policy-Improved Deep Deterministic Policy Gradient Framework for the Discount Order Acceptance Strategy of Ride-hailing Drivers](https://arxiv.org/abs/2507.11865)
*Hanwen Dai,Chang Gao,Fang He,Congyuan Ji,Yanni Yang*

Main category: cs.LG

TL;DR: 本文研究通过折扣快车服务管理司机接受行为比例的问题，从而提高个体平台的需求池和匹配效率，并提出了基于pi-DDPG的解决方案。


<details>
  <summary>Details</summary>
Motivation: 平台整合虽然能减少市场碎片化，但个体平台需要在扩大需求池和保持利润之间找到平衡，特别是在司机参与折扣快车服务的管理上。

Method: 提出pi-DDPG框架，包括早期性能提高的refiner模块、捕捉复杂时空模式的卷积LSTM网络，以及增强学习效率的优先经验回放机制。

Result: 数值实验表明，pi-DDPG显著提高了学习效率，减少了早期训练损失。

Conclusion: pi-DDPG框架在解决司机参与管理问题上表现良好，能够在不依赖大量历史数据的情况下实现高效学习。

Abstract: The rapid expansion of platform integration has emerged as an effective
solution to mitigate market fragmentation by consolidating multiple
ride-hailing platforms into a single application. To address heterogeneous
passenger preferences, third-party integrators provide Discount Express service
delivered by express drivers at lower trip fares. For the individual platform,
encouraging broader participation of drivers in Discount Express services has
the potential to expand the accessible demand pool and improve matching
efficiency, but often at the cost of reduced profit margins. This study aims to
dynamically manage drivers' acceptance of Discount Express from the perspective
of individual platforms. The lack of historical data under the new business
model necessitates online learning. However, early-stage exploration through
trial and error can be costly in practice, highlighting the need for reliable
early-stage performance in real-world deployment. To address these challenges,
this study formulates the decision regarding the proportion of drivers'
acceptance behavior as a continuous control task. In response to the high
stochasticity, the opaque matching mechanisms employed by third-party
integrator, and the limited availability of historical data, we propose a
policy-improved deep deterministic policy gradient (pi-DDPG) framework. The
proposed framework incorporates a refiner module to boost policy performance
during the early training phase, leverages a convolutional long short-term
memory network to effectively capture complex spatiotemporal patterns, and
adopts a prioritized experience replay mechanism to enhance learning
efficiency. A simulator based on a real-world dataset is developed to validate
the effectiveness of the proposed pi-DDPG. Numerical experiments demonstrate
that pi-DDPG achieves superior learning efficiency and significantly reduces
early-stage training losses.

</details>


### [180] [Imbalanced Regression Pipeline Recommendation](https://arxiv.org/abs/2507.11901)
*Juscimara G. Avelino,George D. C. Cavalcanti,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: 提出了Meta-learning for Imbalanced Regression (Meta-IR) 框架，用元分类器在零样本情况下推荐最佳的再采样和学习模型组合。


<details>
  <summary>Details</summary>
Motivation: 解决不平衡回归问题，其中目标值稀少性带来了挑战。现有方法需测试多种再采样和学习模型组合，耗时且复杂。

Method: 提出Meta-IR框架，使用元特征训练元分类器，预测每个任务最佳的再采样策略和学习算法组合。包括独立和链式两种方法，前者独立预测，后者通过输出作为输入实现关联建模。

Result: 链式方法表现优于独立方法，推测学习算法和再采样策略之间具有关联性。与自动机器学习框架及42种组合进行了比较，Meta-IR均表现更佳。

Conclusion: Meta-IR框架显著提升了不平衡回归问题的解决效果，证明链式方法可有效建模策略间的内在关联性。

Abstract: Imbalanced problems are prevalent in various real-world scenarios and are
extensively explored in classification tasks. However, they also present
challenges for regression tasks due to the rarity of certain target values. A
common alternative is to employ balancing algorithms in preprocessing to
address dataset imbalance. However, due to the variety of resampling methods
and learning models, determining the optimal solution requires testing many
combinations. Furthermore, the learning model, dataset, and evaluation metric
affect the best strategies. This work proposes the Meta-learning for Imbalanced
Regression (Meta-IR) framework, which diverges from existing literature by
training meta-classifiers to recommend the best pipeline composed of the
resampling strategy and learning model per task in a zero-shot fashion. The
meta-classifiers are trained using a set of meta-features to learn how to map
the meta-features to the classes indicating the best pipeline. We propose two
formulations: Independent and Chained. Independent trains the meta-classifiers
to separately indicate the best learning algorithm and resampling strategy.
Chained involves a sequential procedure where the output of one meta-classifier
is used as input for another to model intrinsic relationship factors. The
Chained scenario showed superior performance, suggesting a relationship between
the learning algorithm and the resampling strategy per task. Compared with
AutoML frameworks, Meta-IR obtained better results. Moreover, compared with
baselines of six learning algorithms and six resampling algorithms plus no
resampling, totaling 42 (6 X 7) configurations, Meta-IR outperformed all of
them. The code, data, and further information of the experiments can be found
on GitHub: https://github.com/JusciAvelino/Meta-IR.

</details>


### [181] [Resampling strategies for imbalanced regression: a survey and empirical analysis](https://arxiv.org/abs/2507.11902)
*Juscimara G. Avelino,George D. C. Cavalcanti,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: 研究讨论了数据不平衡问题在回归任务中的应用，提出和评估了几种平衡策略及模型，且给出了相关的实验代码和数据。


<details>
  <summary>Details</summary>
Motivation: 解决现实问题中不平衡数据的问题，扩展相关研究从分类任务到回归任务。

Method: 实验对比各种平衡和预测模型，基于三项标准（回归模型、学习过程、评估指标）提出了分类法，并使用相关数据和代码进行验证。

Result: 结果表明平衡策略可以优化模型学习，并指出了未来研究方向。

Conclusion: 此研究为不平衡回归问题提供了新的方法和见解，进一步促进了相关领域的发展。

Abstract: Imbalanced problems can arise in different real-world situations, and to
address this, certain strategies in the form of resampling or balancing
algorithms are proposed. This issue has largely been studied in the context of
classification, and yet, the same problem features in regression tasks, where
target values are continuous. This work presents an extensive experimental
study comprising various balancing and predictive models, and wich uses metrics
to capture important elements for the user and to evaluate the predictive model
in an imbalanced regression data context. It also proposes a taxonomy for
imbalanced regression approaches based on three crucial criteria: regression
model, learning process, and evaluation metrics. The study offers new insights
into the use of such strategies, highlighting the advantages they bring to each
model's learning process, and indicating directions for further studies. The
code, data and further information related to the experiments performed herein
can be found on GitHub: https://github.com/JusciAvelino/imbalancedRegression.

</details>


### [182] [From Generative to Episodic: Sample-Efficient Replicable Reinforcement Learning](https://arxiv.org/abs/2507.11926)
*Max Hopkins,Sihan Liu,Christopher Ye,Yuichi Yoshida*

Main category: cs.LG

TL;DR: 该研究解决了在低视界表格MDP中，探索是否是可复现学习的重大障碍问题。作者提出了一种基于$\tilde{O}(S^2A)$样本的可复现RL算法，缩小了生成模型与情景设置之间的差距，并证明了在生成模型下的下界为$\tilde{\Omega}(S^2A)$，在情景设置下的下界为$\tilde{\Omega}(S^2)$。


<details>
  <summary>Details</summary>
Motivation: 当前在可复现性研究中，探索是否比批量学习需要更多样本仍是一个未解决的问题，尤其在强化学习中，复杂环境交互进一步加剧了这一难题。

Method: 在研究低视界表格MDP中，提出了一种新颖的基于$\tilde{O}(S^2A)$样本的可复现RL算法，同时对生成模型和情景探索进行了理论下界的分析。

Result: 成功提出了一种几乎最优的可复现强化学习算法，同时缩小了生成模型和情景设置在样本效率上的差距。

Conclusion: 实验表明，探索并非可复现学习的重大障碍，研究算法在状态空间$S$维度上几乎达到了最优性能。

Abstract: The epidemic failure of replicability across empirical science and machine
learning has recently motivated the formal study of replicable learning
algorithms [Impagliazzo et al. (2022)]. In batch settings where data comes from
a fixed i.i.d. source (e.g., hypothesis testing, supervised learning), the
design of data-efficient replicable algorithms is now more or less understood.
In contrast, there remain significant gaps in our knowledge for control
settings like reinforcement learning where an agent must interact directly with
a shifting environment. Karbasi et. al show that with access to a generative
model of an environment with $S$ states and $A$ actions (the RL 'batch
setting'), replicably learning a near-optimal policy costs only
$\tilde{O}(S^2A^2)$ samples. On the other hand, the best upper bound without a
generative model jumps to $\tilde{O}(S^7 A^7)$ [Eaton et al. (2024)] due to the
substantial difficulty of environment exploration. This gap raises a key
question in the broader theory of replicability: Is replicable exploration
inherently more expensive than batch learning? Is sample-efficient replicable
RL even possible?
  In this work, we (nearly) resolve this problem (for low-horizon tabular
MDPs): exploration is not a significant barrier to replicable learning! Our
main result is a replicable RL algorithm on $\tilde{O}(S^2A)$ samples, bridging
the gap between the generative and episodic settings. We complement this with a
matching $\tilde{\Omega}(S^2A)$ lower bound in the generative setting (under
the common parallel sampling assumption) and an unconditional lower bound in
the episodic setting of $\tilde{\Omega}(S^2)$ showcasing the near-optimality of
our algorithm with respect to the state space $S$.

</details>


### [183] [Accelerating RF Power Amplifier Design via Intelligent Sampling and ML-Based Parameter Tuning](https://arxiv.org/abs/2507.11928)
*Abhishek Sriram,Neal Tuffy*

Main category: cs.LG

TL;DR: 本文提出了一种机器学习加速的优化框架，用于RF功率放大器设计，可减少65%的仿真需求，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 针对RF功率放大器设计中的仿真需求高、计算成本高问题，本研究提出以减少仿真时间和资源为目标的新方法。

Method: 结合最大最小拉丁超立方采样与CatBoost梯度增强算法，智能探索多维参数空间，仅仿真关键数据点以训练预测模型。

Result: 在15种功率放大器操作模式中验证，平均$R^2$达0.901，仿真时间减少58.24%至77.78%。

Conclusion: 这一框架在保证高精度的前提下，大幅优化了设计过程，适用于生产级RF电路快速设计迭代。

Abstract: This paper presents a machine learning-accelerated optimization framework for
RF power amplifier design that reduces simulation requirements by 65% while
maintaining $\pm0.3$ to $\pm0.4$ dBm accuracy. The proposed method combines
MaxMin Latin Hypercube Sampling with CatBoost gradient boosting to
intelligently explore multidimensional parameter spaces. Instead of
exhaustively simulating all parameter combinations to achieve target P2dB
compression specifications, our approach strategically selects approximately
35% of critical simulation points. The framework processes ADS netlists,
executes harmonic balance simulations on the reduced dataset, and trains a
CatBoost model to predict P2dB performance across the entire design space.
Validation across 15 PA operating modes yields an average $R^2$ of 0.901, with
the system ranking parameter combinations by their likelihood of meeting target
specifications. The integrated solution delivers 58.24% to 77.78% reduction in
simulation time through automated GUI-based workflows, enabling rapid design
iterations without compromising accuracy standards required for production RF
circuits.

</details>


### [184] [Kevin: Multi-Turn RL for Generating CUDA Kernels](https://arxiv.org/abs/2507.11948)
*Carlo Baronio,Pietro Marsella,Ben Pan,Simon Guo,Silas Alberti*

Main category: cs.LG

TL;DR: 本文提出Kevin，这是一个通过多轮强化学习优化CUDA内核生成和性能的模型，显著提高了生成的正确性和运行效率。


<details>
  <summary>Details</summary>
Motivation: 书写GPU内核代码复杂且需多次改进优化，论文旨在利用强化学习的奖励机制来改进这一迭代优化过程。

Method: 设计了一个多轮强化学习方法，从长轨迹中学习并进行有效的奖励归因，并用于训练Kevin模型以改善CUDA内核的生成和优化。

Result: Kevin模型显著提高了生成内核的正确性（从56%到82%）和性能加速（从0.53x到1.10x），并超越了一些前沿模型。

Conclusion: 研究展现了基于强化学习的多轮优化在GPU内核代码生成中的潜力，并验证了其在多个测试维度上的有效性。

Abstract: Writing GPU kernels is a challenging task and critical for AI systems'
efficiency. It is also highly iterative: domain experts write code and improve
performance through execution feedback. Moreover, it presents verifiable
rewards like correctness and speedup, making it a natural environment to apply
Reinforcement Learning (RL). To explicitly incorporate the iterative nature of
this process into training, we develop a flexible multi-turn RL recipe that
addresses unique challenges encountered in real-world settings, such as
learning from long trajectories and effective reward attribution across turns.
We present Kevin - K(ernel D)evin, the first model trained with multi-turn RL
for CUDA kernel generation and optimization. In our evaluation setup, Kevin
shows significant gains over its base model (QwQ-32B), improving correctness of
generated kernels (in pure CUDA) from 56% to 82% and mean speedup from 0.53x to
1.10x of baseline (PyTorch Eager), and surpassing frontier models like o4-mini
(0.78x). Finally, we study its behavior across test-time scaling axes: we found
scaling serial refinement more beneficial than parallel sampling. In
particular, when given more refinement turns, Kevin shows a higher rate of
improvement.

</details>


### [185] [Online Training and Pruning of Deep Reinforcement Learning Networks](https://arxiv.org/abs/2507.11975)
*Valentin Frank Ingmar Guenter,Athanasios Sideris*

Main category: cs.LG

TL;DR: 本文提出了一种在强化学习（RL）算法中同时进行训练和剪枝的网络方法，以解决深度网络计算和内存复杂性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习算法在特征提取网络中扩展深度神经网络虽然提升性能，但会带来计算和内存复杂性的问题。剪枝技术已在监督学习中取得成功，但其在RL中的应用仍然不够充分探索。

Method: 提出一种方法将剪枝与训练同时进行，特别应用于增强型RL算法（如使用OFENet的算法），通过变分参数引入正则化，裁剪对性能贡献小的网络单元，并利用基于DenseNet架构的成本感知正则化策略自动选择超参数。

Result: 在连续控制基准（MuJoCo）和Soft Actor-Critic RL环境中，该方法实现了OFENet的大量剪枝，同时性能损失很小。此外，实验还表明，在训练中对大网络进行剪枝比直接训练小网络效果更好且效率更高。

Conclusion: 该研究展示了剪枝技术在RL算法中的潜力，通过避免直接使用小网络，在保证性能的同时提高了计算和内存的效率。

Abstract: Scaling deep neural networks (NN) of reinforcement learning (RL) algorithms
has been shown to enhance performance when feature extraction networks are used
but the gained performance comes at the significant expense of increased
computational and memory complexity. Neural network pruning methods have
successfully addressed this challenge in supervised learning. However, their
application to RL is underexplored. We propose an approach to integrate
simultaneous training and pruning within advanced RL methods, in particular to
RL algorithms enhanced by the Online Feature Extractor Network (OFENet). Our
networks (XiNet) are trained to solve stochastic optimization problems over the
RL networks' weights and the parameters of variational Bernoulli distributions
for 0/1 Random Variables $\xi$ scaling each unit in the networks. The
stochastic problem formulation induces regularization terms that promote
convergence of the variational parameters to 0 when a unit contributes little
to the performance. In this case, the corresponding structure is rendered
permanently inactive and pruned from its network. We propose a cost-aware,
sparsity-promoting regularization scheme, tailored to the DenseNet architecture
of OFENets expressing the parameter complexity of involved networks in terms of
the parameters of the RVs in these networks. Then, when matching this cost with
the regularization terms, the many hyperparameters associated with them are
automatically selected, effectively combining the RL objectives and network
compression. We evaluate our method on continuous control benchmarks (MuJoCo)
and the Soft Actor-Critic RL agent, demonstrating that OFENets can be pruned
considerably with minimal loss in performance. Furthermore, our results confirm
that pruning large networks during training produces more efficient and higher
performing RL agents rather than training smaller networks from scratch.

</details>


### [186] [Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection](https://arxiv.org/abs/2507.11997)
*Tairan Huang,Yili Wang*

Main category: cs.LG

TL;DR: 本文提出了一种名为MLED的多级别大型语言模型（LLM）增强图欺诈检测框架，有效结合了文本和图结构信息，在4个真实数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有图欺诈检测方法未充分利用原始文本信息中的丰富语义线索，因此需探索如何有效融合文本嵌入与图结构信息。

Method: 提出MLED框架，利用LLM提取文本中的外部知识，并设计类型级和关系级增强器来提升图欺诈检测性能。

Result: 在四个真实世界数据集上的实验表明，MLED作为通用框架，达到了图欺诈检测的最新性能。

Conclusion: MLED有效地将LLM与图结构信息融合，为图欺诈检测提供了一种先进的通用方法。

Abstract: Graph fraud detection has garnered significant attention as Graph Neural
Networks (GNNs) have proven effective in modeling complex relationships within
multimodal data. However, existing graph fraud detection methods typically use
preprocessed node embeddings and predefined graph structures to reveal
fraudsters, which ignore the rich semantic cues contained in raw textual
information. Although Large Language Models (LLMs) exhibit powerful
capabilities in processing textual information, it remains a significant
challenge to perform multimodal fusion of processed textual embeddings with
graph structures. In this paper, we propose a \textbf{M}ulti-level \textbf{L}LM
\textbf{E}nhanced Graph Fraud \textbf{D}etection framework called MLED. In
MLED, we utilize LLMs to extract external knowledge from textual information to
enhance graph fraud detection methods. To integrate LLMs with graph structure
information and enhance the ability to distinguish fraudsters, we design a
multi-level LLM enhanced framework including type-level enhancer and
relation-level enhancer. One is to enhance the difference between the
fraudsters and the benign entities, the other is to enhance the importance of
the fraudsters in different relations. The experiments on four real-world
datasets show that MLED achieves state-of-the-art performance in graph fraud
detection as a generalized framework that can be applied to existing methods.

</details>


### [187] [Detecting In-Person Conversations in Noisy Real-World Environments with Smartwatch Audio and Motion Sensing](https://arxiv.org/abs/2507.12002)
*Alice Zhang,Callihan Bertley,Dawei Liang,Edison Thomaz*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的方法，通过利用音频和惯性数据检测面对面语言交流，实现场景中的社会互动识别。


<details>
  <summary>Details</summary>
Motivation: 研究人类社会互动及其对行为和社会的影响，尤其是面对面交流中的语言和非语言交流。

Method: 通过智能手表采集音频和惯性数据，结合机器学习和深度学习模型，比较三种数据融合方法，分析多模态感知的效果。

Result: 在实验室环境中，框架达到了82.0%±3.0%的宏F1得分，在半自然场景中也有77.2%±1.8%的表现。

Conclusion: 将音频与惯性数据融合，在多模态感知和特定情境下展示了显著性能，证明其在社会互动检测中的优势。

Abstract: Social interactions play a crucial role in shaping human behavior,
relationships, and societies. It encompasses various forms of communication,
such as verbal conversation, non-verbal gestures, facial expressions, and body
language. In this work, we develop a novel computational approach to detect a
foundational aspect of human social interactions, in-person verbal
conversations, by leveraging audio and inertial data captured with a commodity
smartwatch in acoustically-challenging scenarios. To evaluate our approach, we
conducted a lab study with 11 participants and a semi-naturalistic study with
24 participants. We analyzed machine learning and deep learning models with 3
different fusion methods, showing the advantages of fusing audio and inertial
data to consider not only verbal cues but also non-verbal gestures in
conversations. Furthermore, we perform a comprehensive set of evaluations
across activities and sampling rates to demonstrate the benefits of multimodal
sensing in specific contexts. Overall, our framework achieved 82.0$\pm$3.0%
macro F1-score when detecting conversations in the lab and 77.2$\pm$1.8% in the
semi-naturalistic setting.

</details>


### [188] [DUSE: A Data Expansion Framework for Low-resource Automatic Modulation Recognition based on Active Learning](https://arxiv.org/abs/2507.12011)
*Yao Lu,Hongyu Gao,Zhuangzhi Chen,Dongwei Xu,Yun Lin,Qi Xuan,Guan Gui*

Main category: cs.LG

TL;DR: 本文提出了一种名为DUSE的动态不确定性驱动样本扩展框架，有效解决了AMR数据稀缺的问题，并在实验中表现出优异性能。


<details>
  <summary>Details</summary>
Motivation: 针对AMR领域中由于目标域数据稀缺而导致模型训练不足的问题，设计一种可以扩展有用数据的新方法。

Method: 提出DUSE框架，通过不确定性评分函数从相关数据集中筛选有用样本，并通过主动学习策略不断优化评分器。

Result: DUSE在数据类别平衡和不平衡设置下均优于8种对比基准方法，并在跨模型的泛化性上表现出色。

Conclusion: DUSE框架有效缓解了AMR任务中的数据匮乏问题，同时展示了强大的性能与模型适配能力。

Abstract: Although deep neural networks have made remarkable achievements in the field
of automatic modulation recognition (AMR), these models often require a large
amount of labeled data for training. However, in many practical scenarios, the
available target domain data is scarce and difficult to meet the needs of model
training. The most direct way is to collect data manually and perform expert
annotation, but the high time and labor costs are unbearable. Another common
method is data augmentation. Although it can enrich training samples to a
certain extent, it does not introduce new data and therefore cannot
fundamentally solve the problem of data scarcity. To address these challenges,
we introduce a data expansion framework called Dynamic Uncertainty-driven
Sample Expansion (DUSE). Specifically, DUSE uses an uncertainty scoring
function to filter out useful samples from relevant AMR datasets and employs an
active learning strategy to continuously refine the scorer. Extensive
experiments demonstrate that DUSE consistently outperforms 8 coreset selection
baselines in both class-balance and class-imbalance settings. Besides, DUSE
exhibits strong cross-architecture generalization for unseen models.

</details>


### [189] [Granular feedback merits sophisticated aggregation](https://arxiv.org/abs/2507.12041)
*Anmol Kagrecha,Henrik Marklund,Potsawee Manakul,Richard Zeckhauser,Benjamin Van Roy*

Main category: cs.LG

TL;DR: 该研究探讨了如何在有限样本反馈下预测人口反馈分布，并发现更复杂算法在高反馈粒度下表现更优。


<details>
  <summary>Details</summary>
Motivation: 目前的挑战在于从少量个体的反馈中有效预测整个群体的反馈分布，传统的正则化平均方法可能存在优化空间。

Method: 通过将个体反馈结合更复杂的方法，与正则化平均进行比较，分析其在不同反馈粒度下的效果。

Result: 在二元反馈下，复杂方法与传统方法性能差异小，但在五点反馈下，复杂方法能显著减少所需样本量至传统方法的一半。

Conclusion: 使用复杂算法，在高反馈粒度场景下能够更高效地预测群体反馈分布。

Abstract: Human feedback is increasingly used across diverse applications like training
AI models, developing recommender systems, and measuring public opinion -- with
granular feedback often being preferred over binary feedback for its greater
informativeness. While it is easy to accurately estimate a population's
distribution of feedback given feedback from a large number of individuals,
cost constraints typically necessitate using smaller groups. A simple method to
approximate the population distribution is regularized averaging: compute the
empirical distribution and regularize it toward a prior. Can we do better? As
we will discuss, the answer to this question depends on feedback granularity.
  Suppose one wants to predict a population's distribution of feedback using
feedback from a limited number of individuals. We show that, as feedback
granularity increases, one can substantially improve upon predictions of
regularized averaging by combining individuals' feedback in ways more
sophisticated than regularized averaging.
  Our empirical analysis using questions on social attitudes confirms this
pattern. In particular, with binary feedback, sophistication barely reduces the
number of individuals required to attain a fixed level of performance. By
contrast, with five-point feedback, sophisticated methods match the performance
of regularized averaging with about half as many individuals.

</details>


### [190] [Information-Theoretic Generalization Bounds of Replay-based Continual Learning](https://arxiv.org/abs/2507.12043)
*Wen Wen,Tieliang Gong,Yunjiao Zhang,Zeyu Gao,Weizhan Zhang,Yong-Jin Liu*

Main category: cs.LG

TL;DR: 本文针对基于回放的持续学习方法，提出了信息论框架并推导出一系列界定泛化行为的信息理论界限，通过理论与实验揭示了基于回放的持续学习的泛化动态。


<details>
  <summary>Details</summary>
Motivation: 持续学习希望从连续任务中获取知识，同时避免遗忘问题。目前已有许多高效经验方法，但对这些方法特别是基于回放方法的泛化行为的理论认识却较少。

Method: 作者建立了统一的理论框架，推导了基于假设和预测的泛化界限，揭示了有选择性地回放比全面回放能够更好地泛化并缓解遗忘。同时通过低维变量降低计算复杂度。

Result: 理论分析表明，有限回放的策略可以提升泛化效果并缓减遗忘效应。同时在实验验证中，所提框架能有效捕捉基于回放的持续学习中的泛化动态。

Conclusion: 本文为理解基于回放的持续学习提出了一个通用框架，并通过信息理论分析和实验验证，证明了框架的有效性及其对泛化行为的解释力。

Abstract: Continual learning (CL) has emerged as a dominant paradigm for acquiring
knowledge from sequential tasks while avoiding catastrophic forgetting.
Although many CL methods have been proposed to show impressive empirical
performance, the theoretical understanding of their generalization behavior
remains limited, particularly for replay-based approaches. In this paper, we
establish a unified theoretical framework for replay-based CL, deriving a
series of information-theoretic bounds that explicitly characterize how the
memory buffer interacts with the current task to affect generalization.
Specifically, our hypothesis-based bounds reveal that utilizing the limited
exemplars of previous tasks alongside the current task data, rather than
exhaustive replay, facilitates improved generalization while effectively
mitigating catastrophic forgetting. Furthermore, our prediction-based bounds
yield tighter and computationally tractable upper bounds of the generalization
gap through the use of low-dimensional variables. Our analysis is general and
broadly applicable to a wide range of learning algorithms, exemplified by
stochastic gradient Langevin dynamics (SGLD) as a representative method.
Comprehensive experimental evaluations demonstrate the effectiveness of our
derived bounds in capturing the generalization dynamics in replay-based CL
settings.

</details>


### [191] [FloGAN: Scenario-Based Urban Mobility Flow Generation via Conditional GANs and Dynamic Region Decoupling](https://arxiv.org/abs/2507.12053)
*Seanglidet Yean,Jiazu Zhou,Bu-Sung Lee,Markus Schläpfer*

Main category: cs.LG

TL;DR: 提出一种新型数据驱动方法利用条件生成对抗网络（cGANs）生成适应性强的城市出行流量。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型过分依赖历史数据，且无法动态适应人口密度和土地使用变化；机制性方法假设静态场景，无法预测未来场景。

Method: 采用条件生成对抗网络（cGANs），结合动态区域大小和土地使用类型等适应性因素，生成基于城市模拟场景的出行流量。

Result: 方法通过应用于新加坡的手机数据并与现有方法比较，显示出显著优势和高效性能。

Conclusion: 该方法无需大量校准数据或复杂行为建模，可快速生成具有可调空间细化度的城市出行流量，适用于动态化和未来化场景需求。

Abstract: The mobility patterns of people in cities evolve alongside changes in land
use and population. This makes it crucial for urban planners to simulate and
analyze human mobility patterns for purposes such as transportation
optimization and sustainable urban development. Existing generative models
borrowed from machine learning rely heavily on historical trajectories and
often overlook evolving factors like changes in population density and land
use. Mechanistic approaches incorporate population density and facility
distribution but assume static scenarios, limiting their utility for future
projections where historical data for calibration is unavailable. This study
introduces a novel, data-driven approach for generating origin-destination
mobility flows tailored to simulated urban scenarios. Our method leverages
adaptive factors such as dynamic region sizes and land use archetypes, and it
utilizes conditional generative adversarial networks (cGANs) to blend
historical data with these adaptive parameters. The approach facilitates rapid
mobility flow generation with adjustable spatial granularity based on regions
of interest, without requiring extensive calibration data or complex behavior
modeling. The promising performance of our approach is demonstrated by its
application to mobile phone data from Singapore, and by its comparison with
existing methods.

</details>


### [192] [Emergence of Quantised Representations Isolated to Anisotropic Functions](https://arxiv.org/abs/2507.12070)
*George Bird*

Main category: cs.LG

TL;DR: 本文提出了一种新的方法用于确定表示对齐性，利用Spotlight Resonance方法扩展而来。发现网络基本单元的代数对称性是任务无关表示结构的强预测因子。


<details>
  <summary>Details</summary>
Motivation: 探讨功能形式选择如何带来不期望的归纳偏差，导致表示中的任务无关结构，尤其是离散化现象对于表示对齐和解释性的作用。

Method: 通过改变激活函数的代数对称性特征，使用Spotlight Resonance方法分析自动编码器模型中的表示如何形成和排列，并进行消融研究。

Result: 表示在离散代数对称性下趋于离散化，而在连续的正交对称性下保持连续。这种离散化与重建误差的可测增加相关。

Conclusion: 功能形式选择会施加额外的归纳偏差，这种现象支持一种通用的因果模型，用于解释离散表示的形成模式，并提供了对表征和解释性研究的新见解。

Abstract: This paper describes a novel methodology for determining representational
alignment, developed upon the existing Spotlight Resonance method. Using this,
it is found that algebraic symmetries of network primitives are a strong
predictor for task-agnostic structure in representations. Particularly, this
new tool is used to gain insight into how discrete representations can form and
arrange in autoencoder models, through an ablation study where only the
activation function is altered. Representations are found to tend to discretise
when the activation functions are defined through a discrete algebraic
permutation-equivariant symmetry. In contrast, they remain continuous under a
continuous algebraic orthogonal-equivariant definition. These findings
corroborate the hypothesis that functional form choices can carry unintended
inductive biases which produce task-independent artefactual structures in
representations, particularly that contemporary forms induce discretisation of
otherwise continuous structure -- a quantisation effect. Moreover, this
supports a general causal model for one mode in which discrete representations
may form, and could constitute a prerequisite for downstream interpretability
phenomena, including grandmother neurons, discrete coding schemes, general
linear features and possibly Superposition. Hence, this tool and proposed
mechanism for the influence of functional form on representations may provide
several insights into emergent interpretability research. Finally, preliminary
results indicate that quantisation of representations appears to correlate with
a measurable increase in reconstruction error, reinforcing previous conjectures
that this collapse can be detrimental.

</details>


### [193] [Measuring Informativeness Gap of (Mis)Calibrated Predictors](https://arxiv.org/abs/2507.12094)
*Yiding Feng,Wei Tang*

Main category: cs.LG

TL;DR: 本文提出了一种新的方法——信息差距，用于比较不同预测模型的下游决策任务性能，其框架推广了现有多个概念，并引入了一种新的信息性度量方法。


<details>
  <summary>Details</summary>
Motivation: 决策者需要在多个可能不校准的预测模型中选出在下游决策任务中更“有用”的模型。

Method: 引入新的度量指标——信息差距，通过定义最大正规化回报差异来比较预测器，并利用与地球搬运距离类似的知识框架进行度量。

Result: 新定义的度量方法具备完备性、合理性，并且在仅需预测访问的设定中具有高效的样本估计性能；同时在完美校准预测器上还获得了新的组合结构结果。

Conclusion: 通过信息差距度量，可以全面评估不同预测模型的潜在决策效用，为决策提供新的理论支持。

Abstract: In many applications, decision-makers must choose between multiple predictive
models that may all be miscalibrated. Which model (i.e., predictor) is more
"useful" in downstream decision tasks? To answer this, our first contribution
introduces the notion of the informativeness gap between any two predictors,
defined as the maximum normalized payoff advantage one predictor offers over
the other across all decision-making tasks. Our framework strictly generalizes
several existing notions: it subsumes U-Calibration [KLST-23] and Calibration
Decision Loss [HW-24], which compare a miscalibrated predictor to its
calibrated counterpart, and it recovers Blackwell informativeness [Bla-51,
Bla-53] as a special case when both predictors are perfectly calibrated. Our
second contribution is a dual characterization of the informativeness gap,
which gives rise to a natural informativeness measure that can be viewed as a
relaxed variant of the earth mover's distance (EMD) between two prediction
distributions. We show that this measure satisfies natural desiderata: it is
complete and sound, and it can be estimated sample-efficiently in the
prediction-only access setting. Along the way, we also obtain novel
combinatorial structural results when applying this measure to perfectly
calibrated predictors.

</details>


### [194] [Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks](https://arxiv.org/abs/2507.12127)
*Ngoc Duy Pham,Thusitha Dayaratne,Viet Vo,Shangqi Lai,Sharif Abuadbba,Hajime Suzuki,Xingliang Yuan,Carsten Rudolph*

Main category: cs.LG

TL;DR: 本文研究了6G无线设备增长导致的频谱稀缺问题，通过引入联邦学习（FL）的分布式机器学习方法，改进动态频谱分配（DSA）中的频谱感知，并提出解决数据标注稀缺及数据污染攻击的创新机制。


<details>
  <summary>Details</summary>
Motivation: 随着无线技术发展和设备数量急剧增加，频谱资源日益紧张，现有的DSA方法受限于隐私问题和技术瓶颈。

Method: 作者采用半监督联邦学习结合能量检测，提升模型在无标签数据上的训练能力，同时提出了一种类疫苗防御机制，从根本上缓解数据污染攻击问题。

Result: 实验表明，该方法在合成和真实数据集上均表现出高精度，且对目标型和非目标型数据污染攻击表现出强鲁棒性，即使部分参与者恶意也能保持准确性。

Conclusion: 联邦学习技术在频谱感知中具有巨大潜力，其方法不仅解决了数据标注稀缺问题，还在确保安全性与鲁棒性方面提出了创新性解决方案。

Abstract: Advancements in wireless and mobile technologies, including 5G advanced and
the envisioned 6G, are driving exponential growth in wireless devices. However,
this rapid expansion exacerbates spectrum scarcity, posing a critical
challenge. Dynamic spectrum allocation (DSA)--which relies on sensing and
dynamically sharing spectrum--has emerged as an essential solution to address
this issue. While machine learning (ML) models hold significant potential for
improving spectrum sensing, their adoption in centralized ML-based DSA systems
is limited by privacy concerns, bandwidth constraints, and regulatory
challenges. To overcome these limitations, distributed ML-based approaches such
as Federated Learning (FL) offer promising alternatives. This work addresses
two key challenges in FL-based spectrum sensing (FLSS). First, the scarcity of
labeled data for training FL models in practical spectrum sensing scenarios is
tackled with a semi-supervised FL approach, combined with energy detection,
enabling model training on unlabeled datasets. Second, we examine the security
vulnerabilities of FLSS, focusing on the impact of data poisoning attacks. Our
analysis highlights the shortcomings of existing majority-based defenses in
countering such attacks. To address these vulnerabilities, we propose a novel
defense mechanism inspired by vaccination, which effectively mitigates data
poisoning attacks without relying on majority-based assumptions. Extensive
experiments on both synthetic and real-world datasets validate our solutions,
demonstrating that FLSS can achieve near-perfect accuracy on unlabeled datasets
and maintain Byzantine robustness against both targeted and untargeted data
poisoning attacks, even when a significant proportion of participants are
malicious.

</details>


### [195] [HyDRA: A Hybrid Dual-Mode Network for Closed- and Open-Set RFFI with Optimized VMD](https://arxiv.org/abs/2507.12133)
*Hanwen Liu,Yuhe Huang,Yifeng Gong,Yanjie Zhai,Jiaxuan Lu*

Main category: cs.LG

TL;DR: 提出HyDRA架构，通过结合CNN、Transformer和Mamba部件处理无线通信中的设备识别问题，支持闭集和开放集分类任务，并提高性能。


<details>
  <summary>Details</summary>
Motivation: 提升无线通信系统中的设备识别性能并增强安全性，特别是对非授权设备的检测。

Method: 采用优化的变分模态分解进行高效预处理，结合Transformer动态序列编码器和Mamba线性流编码器，同时支持闭集和开放集分类任务。

Result: 在公开数据集上实现了SOTA级别的精度，在开放集方法中展现了良好的性能表现，并在NVIDIA Jetson Xavier NX平台上展现低耗时和低功耗的实时推断能力。

Conclusion: HyDRA是一种高效实用的无线认证方案，适用于实际环境中的实时设备识别任务。

Abstract: Device recognition is vital for security in wireless communication systems,
particularly for applications like access control. Radio Frequency Fingerprint
Identification (RFFI) offers a non-cryptographic solution by exploiting
hardware-induced signal distortions. This paper proposes HyDRA, a Hybrid
Dual-mode RF Architecture that integrates an optimized Variational Mode
Decomposition (VMD) with a novel architecture based on the fusion of
Convolutional Neural Networks (CNNs), Transformers, and Mamba components,
designed to support both closed-set and open-set classification tasks. The
optimized VMD enhances preprocessing efficiency and classification accuracy by
fixing center frequencies and using closed-form solutions. HyDRA employs the
Transformer Dynamic Sequence Encoder (TDSE) for global dependency modeling and
the Mamba Linear Flow Encoder (MLFE) for linear-complexity processing, adapting
to varying conditions. Evaluation on public datasets demonstrates
state-of-the-art (SOTA) accuracy in closed-set scenarios and robust performance
in our proposed open-set classification method, effectively identifying
unauthorized devices. Deployed on NVIDIA Jetson Xavier NX, HyDRA achieves
millisecond-level inference speed with low power consumption, providing a
practical solution for real-time wireless authentication in real-world
environments.

</details>


### [196] [RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization](https://arxiv.org/abs/2507.12142)
*Vladimir Bogachev,Vladimir Aletov,Alexander Molozhavenko,Denis Bobkov,Vera Soboleva,Aibek Alanov,Maxim Rakhuba*

Main category: cs.LG

TL;DR: 提出了一种称为RiemannLoRA的改进LoRA方法，改进了大语言模型的优化效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决LoRA初始化难题和低秩过参数化问题，改进大语言模型的微调效率。

Method: 通过将固定秩LoRA矩阵视为平滑流形，在流形上优化参数以减少过参数化问题，并结合数值线性代数与黎曼优化实现高效稳定的算法。

Result: 实验表明RiemannLoRA在大语言模型和扩散模型架构上的收敛速度和最终性能都优于标准LoRA及其最新改进。

Conclusion: RiemannLoRA通过统一框架在保持计算效率的同时显著提升了微调效果。

Abstract: Low-Rank Adaptation (LoRA) has become a widely adopted standard for
parameter-efficient fine-tuning of large language models (LLMs), significantly
reducing memory and computational demands. However, challenges remain,
including finding optimal initialization strategies or mitigating
overparametrization in low-rank matrix factorization. In this work, we propose
a novel approach that addresses both of the challenges simultaneously within a
unified framework. Our method treats a set of fixed-rank LoRA matrices as a
smooth manifold. Considering adapters as elements on this manifold removes
overparametrization, while determining the direction of the fastest loss
decrease along the manifold provides initialization. Special care is taken to
obtain numerically stable and computationally efficient implementation of our
method, using best practices from numerical linear algebra and Riemannian
optimization. Experimental results on LLM and diffusion model architectures
demonstrate that RiemannLoRA consistently improves both convergence speed and
final performance over standard LoRA and its state-of-the-art modifications.

</details>


### [197] [FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale](https://arxiv.org/abs/2507.12144)
*Boris Bonev,Thorsten Kurth,Ankur Mahesh,Mauro Bisson,Jean Kossaifi,Karthik Kashinath,Anima Anandkumar,William D. Collins,Michael S. Pritchard,Alexander Keller*

Main category: cs.LG

TL;DR: FourCastNet 3 使用几何机器学习实现了快速、高精度的全球天气建模和概率集合预测。


<details>
  <summary>Details</summary>
Motivation: 解决传统天气预报模型中在高精度、中长期预测和计算效率方面的局限性。

Method: 设计了适用于球面几何的全卷积神经网络，从而结合模型与数据并行训练增强训练效率。

Result: FourCastNet 3 准确度超越主流预测模型，与基于扩散的最佳预测方法相媲美，同时速度是后者的8-60倍。即使在60天的长期预测中仍保持良好的概率校准和频谱稳定性。

Conclusion: FourCastNet 3 在天气预测的计算效率、概率能力和长期稳定性方面表现出色，有望用于更高效的大规模集合预报和早期预警系统。

Abstract: FourCastNet 3 advances global weather modeling by implementing a scalable,
geometric machine learning (ML) approach to probabilistic ensemble forecasting.
The approach is designed to respect spherical geometry and to accurately model
the spatially correlated probabilistic nature of the problem, resulting in
stable spectra and realistic dynamics across multiple scales. FourCastNet 3
delivers forecasting accuracy that surpasses leading conventional ensemble
models and rivals the best diffusion-based methods, while producing forecasts 8
to 60 times faster than these approaches. In contrast to other ML approaches,
FourCastNet 3 demonstrates excellent probabilistic calibration and retains
realistic spectra, even at extended lead times of up to 60 days. All of these
advances are realized using a purely convolutional neural network architecture
tailored for spherical geometry. Scalable and efficient large-scale training on
1024 GPUs and more is enabled by a novel training paradigm for combined model-
and data-parallelism, inspired by domain decomposition methods in classical
numerical models. Additionally, FourCastNet 3 enables rapid inference on a
single GPU, producing a 90-day global forecast at 0.25{\deg}, 6-hourly
resolution in under 20 seconds. Its computational efficiency, medium-range
probabilistic skill, spectral fidelity, and rollout stability at subseasonal
timescales make it a strong candidate for improving meteorological forecasting
and early warning systems through large ensemble predictions.

</details>


### [198] [PRISM: Distributed Inference for Foundation Models at Edge](https://arxiv.org/abs/2507.12145)
*Muhammad Azlan Qazi,Alexandros Iosifidis,Qi Zhang*

Main category: cs.LG

TL;DR: PRISM是一种旨在高效部署基础模型到边缘环境的策略，显著减少通信开销和计算量，同时保证模型准确性仅略微下降。


<details>
  <summary>Details</summary>
Motivation: 当前基础模型虽然表现优异但在边缘设备上的部署具有挑战性，因此需要发展高效、实用的部署策略。

Method: 提出PRISM方法，通过Segment Means表示减少中间输出特征的跨设备通信；优化自注意力机制，减少冗余计算；设计针对自回归模型的分区因果屏蔽机制。

Result: 在ViT、BERT和GPT-2模型及多种数据集上评估，通信开销减少高达99.2%，计算量减少高达51.24%，准确性基本保持稳定。

Conclusion: PRISM为资源受限的分布式环境中部署基础模型提供了一种可扩展且实用的解决方案。

Abstract: Foundation models (FMs) have achieved remarkable success across a wide range
of applications, from image classification to natural langurage processing, but
pose significant challenges for deployment at edge. This has sparked growing
interest in developing practical and efficient strategies for bringing
foundation models to edge environments. In this work, we propose PRISM, a
communication-efficient and compute-aware strategy for distributed Transformer
inference on edge devices. Our method leverages a Segment Means representation
to approximate intermediate output features, drastically reducing inter-device
communication. Additionally, we restructure the self-attention mechanism to
eliminate redundant computations caused by per-device Key/Value calculation in
position-wise partitioning and design a partition-aware causal masking scheme
tailored for autoregressive models. We evaluate PRISM on ViT, BERT, and GPT-2
across diverse datasets, namely CIFAR-10, CIFAR-100, ImageNet-1k, GLUE, and
CBT. Our results demonstrate substantial reductions in communication overhead
(up to 99.2% for BERT at compression rate CR = 128) and per-device computation
(51.24% for BERT at the same setting), with only minor accuracy degradation.
This method offers a scalable and practical solution for deploying foundation
models in distributed resource-constrained environments.

</details>


### [199] [Multi-Component VAE with Gaussian Markov Random Field](https://arxiv.org/abs/2507.12165)
*Fouad Oubari,Mohamed El-Baha,Raphael Meunier,Rodrigue Décatoire,Mathilde Mougeot*

Main category: cs.LG

TL;DR: 本文提出了一种基于高斯马尔可夫随机场的多组件变分自编码器（GMRF MCVAE），用于更好地生成具有复杂依赖关系的数据。


<details>
  <summary>Details</summary>
Motivation: 目前的多组件变分自编码器通常采用简化的聚合策略，难以捕捉复杂的跨组件结构关联。这种限制降低了生成组件的整体结构一致性，因此需要一种新的方法来解决这一问题。

Method: 在自编码器的先验和后验分布中结合高斯马尔可夫随机场（GMRF），以显式建模组件间的关系，从而实现跨组件复杂交互的保真再现。

Result: 在合成Copula数据集上达到最新技术水平，在PolyMNIST基准数据集上表现出色，在真实世界的BIKED数据集上显著提升了结构一致性。

Conclusion: GMRF MCVAE适合用于需要强健和真实建模复杂组件一致性的实际应用。

Abstract: Multi-component datasets with intricate dependencies, like industrial
assemblies or multi-modal imaging, challenge current generative modeling
techniques. Existing Multi-component Variational AutoEncoders typically rely on
simplified aggregation strategies, neglecting critical nuances and consequently
compromising structural coherence across generated components. To explicitly
address this gap, we introduce the Gaussian Markov Random Field Multi-Component
Variational AutoEncoder , a novel generative framework embedding Gaussian
Markov Random Fields into both prior and posterior distributions. This design
choice explicitly models cross-component relationships, enabling richer
representation and faithful reproduction of complex interactions. Empirically,
our GMRF MCVAE achieves state-of-the-art performance on a synthetic Copula
dataset specifically constructed to evaluate intricate component relationships,
demonstrates competitive results on the PolyMNIST benchmark, and significantly
enhances structural coherence on the real-world BIKED dataset. Our results
indicate that the GMRF MCVAE is especially suited for practical applications
demanding robust and realistic modeling of multi-component coherence

</details>


### [200] [RadioDiff-3D: A 3D$\times$3D Radio Map Dataset and Generative Diffusion Based Benchmark for 6G Environment-Aware Communication](https://arxiv.org/abs/2507.12166)
*Xiucheng Wang,Qiming Zhang,Nan Cheng,Junting Chen,Zezhong Zhang,Zan Li,Shuguang Cui,Xuemin Shen*

Main category: cs.LG

TL;DR: 提出并构建了UrbanRadio3D，作为大规模高分辨率3D无线电图数据集，采用新的Benchmark方法测试并验证其优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有无线电图方法忽视了关键参数（如DoA、ToA）及垂直空间变化，且在静态模型框架下无法超出训练数据分布的泛化。

Method: 构建UrbanRadio3D数据集（基于光线追踪技术），数据体量和维度远超之前数据集；采用3D卷积神经网络和扩散模型框架RadioDiff-3D进行3D无线电图生成。

Result: RadioDiff-3D在UrbanRadio3D上的实验结果表明，其在多样环境动态下为生成高维无线电图提供了优越性能。

Conclusion: 本文提供了一个支持未来3D环境感知通信研究的基础数据集及基准测试，并验证了其高效构图能力。

Abstract: Radio maps (RMs) serve as a critical foundation for enabling
environment-aware wireless communication, as they provide the spatial
distribution of wireless channel characteristics. Despite recent progress in RM
construction using data-driven approaches, most existing methods focus solely
on pathloss prediction in a fixed 2D plane, neglecting key parameters such as
direction of arrival (DoA), time of arrival (ToA), and vertical spatial
variations. Such a limitation is primarily due to the reliance on static
learning paradigms, which hinder generalization beyond the training data
distribution. To address these challenges, we propose UrbanRadio3D, a
large-scale, high-resolution 3D RM dataset constructed via ray tracing in
realistic urban environments. UrbanRadio3D is over 37$\times$3 larger than
previous datasets across a 3D space with 3 metrics as pathloss, DoA, and ToA,
forming a novel 3D$\times$33D dataset with 7$\times$3 more height layers than
prior state-of-the-art (SOTA) dataset. To benchmark 3D RM construction, a UNet
with 3D convolutional operators is proposed. Moreover, we further introduce
RadioDiff-3D, a diffusion-model-based generative framework utilizing the 3D
convolutional architecture. RadioDiff-3D supports both radiation-aware
scenarios with known transmitter locations and radiation-unaware settings based
on sparse spatial observations. Extensive evaluations on UrbanRadio3D validate
that RadioDiff-3D achieves superior performance in constructing rich,
high-dimensional radio maps under diverse environmental dynamics. This work
provides a foundational dataset and benchmark for future research in 3D
environment-aware communication. The dataset is available at
https://github.com/UNIC-Lab/UrbanRadio3D.

</details>


### [201] [Explainable Evidential Clustering](https://arxiv.org/abs/2507.12192)
*Victor F. Lopes de Souza,Karima Bakhti,Sofiane Ramdani,Denis Mottet,Abdelhak Imoussaten*

Main category: cs.LG

TL;DR: 本文提出了基于Dempster-Shafer理论的无监督分类解释方法，包括IEMM算法，用于生成解释性强的决策树模型，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统方法无法有效处理现实数据中的不确定性和不精确性，尤其是在高风险领域（如医疗行业）中，需要对基于证据理论的聚类结果进行解释。

Method: 提出了一种结合代表性概念和效用函数的方法，定义了解释成本，开发了迭代证据错误最小化（IEMM）算法来生成决策树解释器，并在部分标记数据和实际场景中进行了验证。

Result: 算法性能在合成和实际数据上进行了验证，对于考虑决策者偏好的场景，算法生成的解释在93%的情况下是令人满意的。

Conclusion: 所提出的方法和算法能够有效应对证据聚类解释问题，提供高质量、可解释的决策树模型，适用于高风险领域实际应用。

Abstract: Unsupervised classification is a fundamental machine learning problem.
Real-world data often contain imperfections, characterized by uncertainty and
imprecision, which are not well handled by traditional methods. Evidential
clustering, based on Dempster-Shafer theory, addresses these challenges. This
paper explores the underexplored problem of explaining evidential clustering
results, which is crucial for high-stakes domains such as healthcare. Our
analysis shows that, in the general case, representativity is a necessary and
sufficient condition for decision trees to serve as abductive explainers.
Building on the concept of representativity, we generalize this idea to
accommodate partial labeling through utility functions. These functions enable
the representation of "tolerable" mistakes, leading to the definition of
evidential mistakeness as explanation cost and the construction of explainers
tailored to evidential classifiers. Finally, we propose the Iterative
Evidential Mistake Minimization (IEMM) algorithm, which provides interpretable
and cautious decision tree explanations for evidential clustering functions. We
validate the proposed algorithm on synthetic and real-world data. Taking into
account the decision-maker's preferences, we were able to provide an
explanation that was satisfactory up to 93% of the time.

</details>


### [202] [Nonlinear Concept Erasure: a Density Matching Approach](https://arxiv.org/abs/2507.12341)
*Antoine Saillenfest,Pirmin Lemberger*

Main category: cs.LG

TL;DR: 本文提出了通过概念抹除（concept erasure）来保护文本表示中的敏感信息不可推断，同时保持其他语义信息。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，确保神经网络无法从文本表示中推断敏感信息（如性别或种族）是实现公平性的一项重要挑战。

Method: 使用正交投影学习方法，对嵌入空间中的分布式表示进行信息处理，通过控制投影器的秩来调整擦除信息的程度，同时通过正交性保留嵌入的局部结构。

Result: 所提出的方法（$overline{\mathrm{L}}$EOPARD）在多个自然语言处理基准测试中的离散属性非线性抹除任务中达到了最先进的性能。

Conclusion: 方法不仅有效抹除了敏感信息，还能减轻深度非线性分类中的偏差，从而促进公平性。

Abstract: Ensuring that neural models used in real-world applications cannot infer
sensitive information, such as demographic attributes like gender or race, from
text representations is a critical challenge when fairness is a concern. We
address this issue through concept erasure, a process that removes information
related to a specific concept from distributed representations while preserving
as much of the remaining semantic information as possible. Our approach
involves learning an orthogonal projection in the embedding space, designed to
make the class-conditional feature distributions of the discrete concept to
erase indistinguishable after projection. By adjusting the rank of the
projector, we control the extent of information removal, while its
orthogonality ensures strict preservation of the local structure of the
embeddings. Our method, termed $\overline{\mathrm{L}}$EOPARD, achieves
state-of-the-art performance in nonlinear erasure of a discrete attribute on
classic natural language processing benchmarks. Furthermore, we demonstrate
that $\overline{\mathrm{L}}$EOPARD effectively mitigates bias in deep nonlinear
classifiers, thereby promoting fairness.

</details>


### [203] [Selective Quantization Tuning for ONNX Models](https://arxiv.org/abs/2507.12196)
*Nikolaos Louloudakis,Ajitha Rajan*

Main category: cs.LG

TL;DR: 本文提出了TuneQn，一种支持选择性量化和部署执行ONNX模型的工具，显著减少了精度损失和模型大小。


<details>
  <summary>Details</summary>
Motivation: 全量化模型的性能可能低于可接受水平，且在低端硬件上的部署面临挑战，因此需要进行选择性量化，但选择合适层具有挑战性。

Method: 提出TuneQn工具套件，结合剖析和多目标优化，支持ONNX模型的选择性量化、部署和性能评估，并通过帕累托优化识别最佳模型候选。

Result: 通过在四个ONNX模型、两种量化设置以及CPU/GPU设备上的实验，TuneQn可将精度损失减少至54.14%，并可将模型大小减少至72.9%。

Conclusion: TuneQn能够有效实现选择性量化和优化，显著提升模型的部署性能和资源效率。

Abstract: Quantization is a process that reduces the precision of deep neural network
models to lower model size and computational demands, often at the cost of
accuracy. However, fully quantized models may exhibit sub-optimal performance
below acceptable levels and face deployment challenges on low-end hardware
accelerators due to practical constraints. To address these issues,
quantization can be selectively applied to only a subset of layers, but
selecting which layers to exclude is non-trivial. To this direction, we propose
TuneQn, a suite enabling selective quantization, deployment and execution of
ONNX models across various CPU and GPU devices, combined with profiling and
multi-objective optimization. TuneQn generates selectively quantized ONNX
models, deploys them on different hardware, measures performance on metrics
like accuracy and size, performs Pareto Front minimization to identify the best
model candidate and visualizes the results. To demonstrate the effectiveness of
TuneQn, we evaluated TuneQn on four ONNX models with two quantization settings
across CPU and GPU devices. As a result, we demonstrated that our utility
effectively performs selective quantization and tuning, selecting ONNX model
candidates with up to a $54.14$% reduction in accuracy loss compared to the
fully quantized model, and up to a $72.9$% model size reduction compared to the
original model.

</details>


### [204] [Physics-Informed Linear Model (PILM): Analytical Representations and Application to Crustal Strain Rate Estimation](https://arxiv.org/abs/2507.12218)
*Tomohisa Okazaki*

Main category: cs.LG

TL;DR: 本文引入了一种称为物理信息线性模型（PILM）的新方法，用以通过线性组合基函数解决线性偏微分方程问题，并应用于逆问题及地壳应变估算。


<details>
  <summary>Details</summary>
Motivation: 偏微分方程（PDEs）在物理系统建模中十分重要，但从观测数据中求解这些方程或估计其中的系数、边界条件（BCs），对于理解相关现象至关重要。

Method: 提出并验证了一种物理信息线性模型（PILM），该模型通过线性组合基函数来表达求解方法，从而使得求解过程可解析。采用不同正则化方法进行比较分析，并用PILM估算地壳应变率。

Result: 结果表明，在从贝叶斯角度分析下，数学正则化方法比物理正则化方法性能更佳。PILM证明适用于线性正问题和逆问题，以及物理正则化处理的欠定系统。

Conclusion: PILM为线性偏微分方程提供了一种可解析框架，并在科学计算与数据处理领域展现了潜力。

Abstract: Many physical systems are described by partial differential equations (PDEs),
and solving these equations and estimating their coefficients or boundary
conditions (BCs) from observational data play a crucial role in understanding
the associated phenomena. Recently, a machine learning approach known as
physics-informed neural network, which solves PDEs using neural networks by
minimizing the sum of residuals from the PDEs, BCs, and data, has gained
significant attention in the scientific community. In this study, we
investigate a physics-informed linear model (PILM) that uses linear
combinations of basis functions to represent solutions, thereby enabling an
analytical representation of optimal solutions. The PILM was formulated and
verified for illustrative forward and inverse problems including cases with
uncertain BCs. Furthermore, the PILM was applied to estimate crustal strain
rates using geodetic data. Specifically, physical regularization that enforces
elastic equilibrium on the velocity fields was compared with mathematical
regularization that imposes smoothness constraints. From a Bayesian
perspective, mathematical regularization exhibited superior performance. The
PILM provides an analytically solvable framework applicable to linear forward
and inverse problems, underdetermined systems, and physical regularization.

</details>


### [205] [Optimizers Qualitatively Alter Solutions And We Should Leverage This](https://arxiv.org/abs/2507.12224)
*Razvan Pascanu,Clare Lyle,Ionut-Vlad Modoranu,Naima Elosegui Borras,Dan Alistarh,Petar Velickovic,Sarath Chandar,Soham De,James Martens*

Main category: cs.LG

TL;DR: 本文探讨了深度神经网络(DNN)优化中的新视角，强调了优化器不仅影响收敛速度，还能影响所学解的质性属性。


<details>
  <summary>Details</summary>
Motivation: 目前的优化研究更多专注于收敛效率，而较少关注优化器设计对最终学习结果的影响，这种局限性需要重新审视。

Method: 重新探索优化器的设计思路，提出关注优化器如何引入归纳偏差及影响模型表现的新角度。

Result: 优化器不仅决定学习过程的收敛速度，还影响最终模型的表现与性质。

Conclusion: 未来研究应着眼于优化器的设计如何作用于解决方案的性质，并将优化器设计视为与架构和数据并列的重要组成部分。

Abstract: Due to the nonlinear nature of Deep Neural Networks (DNNs), one can not
guarantee convergence to a unique global minimum of the loss when using
optimizers relying only on local information, such as SGD. Indeed, this was a
primary source of skepticism regarding the feasibility of DNNs in the early
days of the field. The past decades of progress in deep learning have revealed
this skepticism to be misplaced, and a large body of empirical evidence shows
that sufficiently large DNNs following standard training protocols exhibit
well-behaved optimization dynamics that converge to performant solutions. This
success has biased the community to use convex optimization as a mental model
for learning, leading to a focus on training efficiency, either in terms of
required iteration, FLOPs or wall-clock time, when improving optimizers. We
argue that, while this perspective has proven extremely fruitful, another
perspective specific to DNNs has received considerably less attention: the
optimizer not only influences the rate of convergence, but also the qualitative
properties of the learned solutions. Restated, the optimizer can and will
encode inductive biases and change the effective expressivity of a given class
of models. Furthermore, we believe the optimizer can be an effective way of
encoding desiderata in the learning process. We contend that the community
should aim at understanding the biases of already existing methods, as well as
aim to build new optimizers with the explicit intent of inducing certain
properties of the solution, rather than solely judging them based on their
convergence rates. We hope our arguments will inspire research to improve our
understanding of how the learning process can impact the type of solution we
converge to, and lead to a greater recognition of optimizers design as a
critical lever that complements the roles of architecture and data in shaping
model outcomes.

</details>


### [206] [Robust Causal Discovery in Real-World Time Series with Power-Laws](https://arxiv.org/abs/2507.12257)
*Matteo Tusoni,Giuseppe Masi,Andrea Coletta,Aldo Glielmo,Viviana Arrigoni,Novella Bartolini*

Main category: cs.LG

TL;DR: 本文提出了一种基于功率谱特征的因果发现方法，可以更稳健地处理噪声影响并改进因果推断结果。


<details>
  <summary>Details</summary>
Motivation: 因果关系发现在时间序列数据分析中十分重要，但现有方法对噪声敏感，难以在真实数据中得出准确因果结论。

Method: 通过研究真实世界时间序列的功率谱分布特点，利用功率谱特征增强真实因果信号，从而设计一种稳健的因果发现方法。

Result: 该方法在合成数据和真实数据集上表现优于当前最先进的方法，展现出更好的稳定性和实际应用价值。

Conclusion: 提出的方法有效缓解了噪声对因果发现结果的负面影响，可推广应用于多个领域的时间序列数据分析。

Abstract: Exploring causal relationships in stochastic time series is a challenging yet
crucial task with a vast range of applications, including finance, economics,
neuroscience, and climate science. Many algorithms for Causal Discovery (CD)
have been proposed, but they often exhibit a high sensitivity to noise,
resulting in misleading causal inferences when applied to real data. In this
paper, we observe that the frequency spectra of typical real-world time series
follow a power-law distribution, notably due to an inherent self-organizing
behavior. Leveraging this insight, we build a robust CD method based on the
extraction of power -law spectral features that amplify genuine causal signals.
Our method consistently outperforms state-of-the-art alternatives on both
synthetic benchmarks and real-world datasets with known causal structures,
demonstrating its robustness and practical relevance.

</details>


### [207] [A Framework for Nonstationary Gaussian Processes with Neural Network Parameters](https://arxiv.org/abs/2507.12262)
*Zachary James,Joseph Guinness*

Main category: cs.LG

TL;DR: 本文提出了一种结合神经网络的非平稳高斯过程模型，用于提高模型灵活性与适应性，在多个数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 高斯过程常因灵活性和不确定性量化而广受欢迎，但传统平稳核的使用限制了模型的表达能力，无法适应许多数据集的需求。

Method: 提出一种非平稳核的框架，其参数随着特征变化并由神经网络生成，神经网络与高斯过程联合训练，并支持大规模数据集的扩展。

Result: 在多个机器学习数据集上，该方法在准确性和对数得分方面优于传统平稳模型与变分推断的层次模型，并展示了在空间数据集中恢复非平稳参数的能力。

Conclusion: 结合神经网络的非平稳高斯过程模型具备灵活性与适应性，适合使用多种非平稳核且易于扩展，实验表明其优于传统方法。

Abstract: Gaussian processes have become a popular tool for nonparametric regression
because of their flexibility and uncertainty quantification. However, they
often use stationary kernels, which limit the expressiveness of the model and
may be unsuitable for many datasets. We propose a framework that uses
nonstationary kernels whose parameters vary across the feature space, modeling
these parameters as the output of a neural network that takes the features as
input. The neural network and Gaussian process are trained jointly using the
chain rule to calculate derivatives. Our method clearly describes the behavior
of the nonstationary parameters and is compatible with approximation methods
for scaling to large datasets. It is flexible and easily adapts to different
nonstationary kernels without needing to redesign the optimization procedure.
Our methods are implemented with the GPyTorch library and can be readily
modified. We test a nonstationary variance and noise variant of our method on
several machine learning datasets and find that it achieves better accuracy and
log-score than both a stationary model and a hierarchical model approximated
with variational inference. Similar results are observed for a model with only
nonstationary variance. We also demonstrate our approach's ability to recover
the nonstationary parameters of a spatial dataset.

</details>


### [208] [RegCL: Continual Adaptation of Segment Anything Model via Model Merging](https://arxiv.org/abs/2507.12297)
*Yuan-Chen Shu,Zhiwei Lin,Yongtao Wang*

Main category: cs.LG

TL;DR: 为解决SAM在特定领域中的表现限制，提出了一种名为RegCL的非重放型持续学习框架，用于多领域知识整合。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨领域任务中会造成灾难性遗忘，限制了模型的扩展性。

Method: RegCL利用模型合并算法，将多领域训练的参数模块合并，采用权重优化来减少合并模型与领域特定模型之间的预测差异。框架无需存储历史数据，且模型大小恒定。

Result: 实验表明，RegCL在多个下游数据集上实现了良好的持续学习性能。

Conclusion: RegCL在动态环境下有效整合多领域知识，同时保持参数高效性，是一种可扩展的CL框架。

Abstract: To address the performance limitations of the Segment Anything Model (SAM) in
specific domains, existing works primarily adopt adapter-based one-step
adaptation paradigms. However, some of these methods are specific developed for
specific domains. If used on other domains may lead to performance degradation.
This issue of catastrophic forgetting severely limits the model's scalability.
To address this issue, this paper proposes RegCL, a novel non-replay continual
learning (CL) framework designed for efficient multi-domain knowledge
integration through model merging. Specifically, RegCL incorporates the model
merging algorithm into the continual learning paradigm by merging the
parameters of SAM's adaptation modules (e.g., LoRA modules) trained on
different domains. The merging process is guided by weight optimization, which
minimizes prediction discrepancies between the merged model and each of the
domain-specific models. RegCL effectively consolidates multi-domain knowledge
while maintaining parameter efficiency, i.e., the model size remains constant
regardless of the number of tasks, and no historical data storage is required.
Experimental results demonstrate that RegCL achieves favorable continual
learning performance across multiple downstream datasets, validating its
effectiveness in dynamic scenarios.

</details>


### [209] [PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning](https://arxiv.org/abs/2507.12305)
*M. Anwar Ma'sum,Mahardhika Pratama,Savitha Ramasamy,Lin Liu,Habibullah Habibullah,Ryszard Kowalczyk*

Main category: cs.LG

TL;DR: 该研究提出了一种基于prompt的新方法，用于在线持续学习（OCL），解决了数据隐私和灾难性遗忘问题，并在多个数据集上超过现有方法表现。


<details>
  <summary>Details</summary>
Motivation: 当面临数据隐私约束时，在线持续学习因流数据的灾难性遗忘问题变得复杂。当前方法有基于记忆示例与参数增长的不足，难以解决数据流性能问题。

Method: 提出了一种四模块的轻量级prompt方法，包括通用知识生成器、特定知识调整器、预训练模型泛化保护机制以及软硬更新机制。

Result: 在CIFAR100、ImageNet-R、ImageNet-A和CUB数据集上显著优于现有方法。

Conclusion: 该方法提升了在线持续学习性能，同时减少了参数数量并获得了适中训练、推理时间和吞吐量特点。

Abstract: The data privacy constraint in online continual learning (OCL), where the
data can be seen only once, complicates the catastrophic forgetting problem in
streaming data. A common approach applied by the current SOTAs in OCL is with
the use of memory saving exemplars or features from previous classes to be
replayed in the current task. On the other hand, the prompt-based approach
performs excellently in continual learning but with the cost of a growing
number of trainable parameters. The first approach may not be applicable in
practice due to data openness policy, while the second approach has the issue
of throughput associated with the streaming data. In this study, we propose a
novel prompt-based method for online continual learning that includes 4 main
components: (1) single light-weight prompt generator as a general knowledge,
(2) trainable scaler-and-shifter as specific knowledge, (3) pre-trained model
(PTM) generalization preserving, and (4) hard-soft updates mechanism. Our
proposed method achieves significantly higher performance than the current
SOTAs in CIFAR100, ImageNet-R, ImageNet-A, and CUB dataset. Our complexity
analysis shows that our method requires a relatively smaller number of
parameters and achieves moderate training time, inference time, and throughput.
For further study, the source code of our method is available at
https://github.com/anwarmaxsum/PROL.

</details>


### [210] [Thought Purity: Defense Paradigm For Chain-of-Thought Attack](https://arxiv.org/abs/2507.12314)
*Zihao Xue,Zhen Bi,Long Ma,Zhenlin Hu,Yan Wang,Zhenfang Liu,Qing Sheng,Jie Xiao,Jungang Lou*

Main category: cs.LG

TL;DR: 本研究探讨强化学习训练的大型推理模型（LRM）在链式思维（CoT）生成中易受安全威胁的弱点，并提出了一种名为思想纯化（TP）的防御方法来解决此弱点。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是鉴于大型语言模型在推理能力上的进步，但依然存在安全方面的脆弱性，特别是在CoT生成过程中面对后门攻击等威胁。

Method: 提出一种由三部分组成的防御框架：安全优化的数据处理管道、强化学习增强的规则约束以及自适应监控指标，从而提升对恶意内容的抵抗力并保持模型性能。

Result: 实验结果表明，该方法显著提高了强化学习对齐模型对CoTA漏洞的防护能力，同时保持了推理系统的功能性。

Conclusion: 研究为应对CoTA攻击提供了第一个全面的防御机制，提升了新一代AI架构在安全性与功能性之间的平衡。

Abstract: While reinforcement learning-trained Large Reasoning Models (LRMs, e.g.,
Deepseek-R1) demonstrate advanced reasoning capabilities in the evolving Large
Language Models (LLMs) domain, their susceptibility to security threats remains
a critical vulnerability. This weakness is particularly evident in
Chain-of-Thought (CoT) generation processes, where adversarial methods like
backdoor prompt attacks can systematically subvert the model's core reasoning
mechanisms. The emerging Chain-of-Thought Attack (CoTA) reveals this
vulnerability through exploiting prompt controllability, simultaneously
degrading both CoT safety and task performance with low-cost interventions. To
address this compounded security-performance vulnerability, we propose Thought
Purity (TP): a defense paradigm that systematically strengthens resistance to
malicious content while preserving operational efficacy. Our solution achieves
this through three synergistic components: (1) a safety-optimized data
processing pipeline (2) reinforcement learning-enhanced rule constraints (3)
adaptive monitoring metrics. Our approach establishes the first comprehensive
defense mechanism against CoTA vulnerabilities in reinforcement
learning-aligned reasoning systems, significantly advancing the
security-functionality equilibrium for next-generation AI architectures.

</details>


### [211] [Heat Kernel Goes Topological](https://arxiv.org/abs/2507.12380)
*Maximilian Krahn,Vikas Garg*

Main category: cs.LG

TL;DR: 本文提出了一种基于组合复形的新拓扑学习框架，通过引入Laplacian算子和高效计算热核的方式，显著提升了计算效率和表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有的拓扑神经网络以图神经网络为基础，但其涉及的高阶信息传递计算成本高。作者希望提出一种既具高效性又有充分表达能力的新方法。

Method: 作者通过在组合复形上引入Laplacian算子，计算热核作为节点描述符，从而捕捉多尺度信息，并实现对称等变表示，使其易于集成到现代的Transformer架构中。

Result: 研究证明方法具有最大表达能力，可以区分任意非同构组合复形。在计算效率上优于现有拓扑方法，并在分子数据集及拓扑基准测试中展示了优异性能。

Conclusion: 该方法显著推动了拓扑深度学习的发展，提供了既具有表达能力又具备可扩展性的表示形式，为分子分类和属性预测任务提供了新的可能性。

Abstract: Topological neural networks have emerged as powerful successors of graph
neural networks. However, they typically involve higher-order message passing,
which incurs significant computational expense. We circumvent this issue with a
novel topological framework that introduces a Laplacian operator on
combinatorial complexes (CCs), enabling efficient computation of heat kernels
that serve as node descriptors. Our approach captures multiscale information
and enables permutation-equivariant representations, allowing easy integration
into modern transformer-based architectures.
  Theoretically, the proposed method is maximally expressive because it can
distinguish arbitrary non-isomorphic CCs. Empirically, it significantly
outperforms existing topological methods in terms of computational efficiency.
Besides demonstrating competitive performance with the state-of-the-art
descriptors on standard molecular datasets, it exhibits superior capability in
distinguishing complex topological structures and avoiding blind spots on
topological benchmarks. Overall, this work advances topological deep learning
by providing expressive yet scalable representations, thereby opening up
exciting avenues for molecular classification and property prediction tasks.

</details>


### [212] [Improving Reinforcement Learning Sample-Efficiency using Local Approximation](https://arxiv.org/abs/2507.12383)
*Mohit Prashant,Arvind Easwaran*

Main category: cs.LG

TL;DR: 本文提出了一种新的用于无限地平面马尔可夫决策过程(MDP)的PAC样本复杂度界定方法，其样本复杂度达到了 $O(SA \log A)$，在实验对比中显示出显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的PAC样本复杂度研究在无限地平面MDP场景中存在不足，本文旨在通过新的方法减少样本复杂度并提高效率。

Method: 通过将原始MDP分解为包含状态子集的小型MDP以简化样本复杂度分析，并设计出一种基于PAC-MDP的新算法来验证理论成果。

Result: 提出的PAC-MDP算法显著减少了样本复杂度，实现了对状态空间和动作空间的对数级缩减。

Conclusion: 通过实验比较表明，新算法在样本复杂度方面相比现有方法有重要改进，为无限地平面场景下的MDP学习提供了更优的解决方案。

Abstract: In this study, we derive Probably Approximately Correct (PAC) bounds on the
asymptotic sample-complexity for RL within the infinite-horizon Markov Decision
Process (MDP) setting that are sharper than those in existing literature. The
premise of our study is twofold: firstly, the further two states are from each
other, transition-wise, the less relevant the value of the first state is when
learning the $\epsilon$-optimal value of the second; secondly, the amount of
'effort', sample-complexity-wise, expended in learning the $\epsilon$-optimal
value of a state is independent of the number of samples required to learn the
$\epsilon$-optimal value of a second state that is a sufficient number of
transitions away from the first. Inversely, states within each other's vicinity
have values that are dependent on each other and will require a similar number
of samples to learn. By approximating the original MDP using smaller MDPs
constructed using subsets of the original's state-space, we are able to reduce
the sample-complexity by a logarithmic factor to $O(SA \log A)$ timesteps,
where $S$ and $A$ are the state and action space sizes. We are able to extend
these results to an infinite-horizon, model-free setting by constructing a
PAC-MDP algorithm with the aforementioned sample-complexity. We conclude with
showing how significant the improvement is by comparing our algorithm against
prior work in an experimental setting.

</details>


### [213] [Trustworthy Tree-based Machine Learning by $MoS_2$ Flash-based Analog CAM with Inherent Soft Boundaries](https://arxiv.org/abs/2507.12384)
*Bo Wen,Guoyun Gao,Zhicheng Xu,Ruibin Mao,Xiaojuan Qi,X. Sharon Hu,Xunzhao Yin,Can Li*

Main category: cs.LG

TL;DR: 本研究提出一种新型硬件-软件联合设计方法，利用基于$MoS_2$ Flash的类比内容寻址存储器（CAM）实现高效的软树模型推理，显著提高其在设备变化和对抗性攻击下的鲁棒性，并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 人工智能迅速发展引发了对其可信性的关注，尤其是在解释性和鲁棒性方面。树模型在解释性和精确性上表现突出，但因计算开销高而难以扩展。同时，使用类比内容寻址存储器加速这些模型的努力多因硬件性能和攻击漏洞问题受阻。

Method: 通过设计基于$MoS_2$ Flash的类比CAM与软边界的软树模型联合实现推理，用于攻克之前加速树模型方法中存在的硬件性能低下和对抗攻击问题。

Result: 实验表明，该方法在WDBC数据集上实现了96%的准确率，并保持了决策的可解释性。在MNIST数据集上，在设备阈值变化10%的情况下，其准确率仅下降0.6%，而传统决策树下降了45.3%。

Conclusion: 基于$MoS_2$ Flash的类比CAM结合软树模型证明了其在增强AI系统的可信性和效率方面具有巨大的潜力，并为研发专业化AI硬件提供了新方向。

Abstract: The rapid advancement of artificial intelligence has raised concerns
regarding its trustworthiness, especially in terms of interpretability and
robustness. Tree-based models like Random Forest and XGBoost excel in
interpretability and accuracy for tabular data, but scaling them remains
computationally expensive due to poor data locality and high data dependence.
Previous efforts to accelerate these models with analog content addressable
memory (CAM) have struggled, due to the fact that the difficult-to-implement
sharp decision boundaries are highly susceptible to device variations, which
leads to poor hardware performance and vulnerability to adversarial attacks.
This work presents a novel hardware-software co-design approach using $MoS_2$
Flash-based analog CAM with inherent soft boundaries, enabling efficient
inference with soft tree-based models. Our soft tree model inference
experiments on $MoS_2$ analog CAM arrays show this method achieves exceptional
robustness against device variation and adversarial attacks while achieving
state-of-the-art accuracy. Specifically, our fabricated analog CAM arrays
achieve $96\%$ accuracy on Wisconsin Diagnostic Breast Cancer (WDBC) database,
while maintaining decision explainability. Our experimentally calibrated model
validated only a $0.6\%$ accuracy drop on the MNIST dataset under $10\%$ device
threshold variation, compared to a $45.3\%$ drop for traditional decision
trees. This work paves the way for specialized hardware that enhances AI's
trustworthiness and efficiency.

</details>


### [214] [ROC-n-reroll: How verifier imperfection affects test-time scaling](https://arxiv.org/abs/2507.12399)
*Florian E. Dorner,Yatong Chen,André F. Cruz,Fanny Yang*

Main category: cs.LG

TL;DR: 本文探讨了测试时缩放如何通过使用额外的计算资源来改进语言模型性能，并提供了关于验证器对性能影响的理论研究。


<details>
  <summary>Details</summary>
Motivation: 现有工作强调了最佳取N（Best-of-N）和拒绝采样等技术对于测试时缩放的经验性方法，但缺乏对验证器不完善对性能影响的理论理解。

Method: 本文通过理论证明，实例级准确性如何由验证器的ROC曲线几何特性决定。拒绝采样依赖于ROC曲线的局部几何，而最佳取N依赖于其全局几何特性。

Result: 拒绝采样在固定计算资源中表现优于最佳取N，但在无穷计算资源下，二者准确性趋同，并由ROC曲线在原点附近的斜率决定。

Conclusion: 验证器的ROC曲线特性对不同缩放方法的性能有决定性影响，且拒绝采样与最佳取N各有优劣，需根据具体需求选择。

Abstract: Test-time scaling aims to improve language model performance by leveraging
additional compute during inference. While many works have empirically studied
techniques like Best-of-N (BoN) and rejection sampling that make use of a
verifier to enable test-time scaling, there is little theoretical understanding
of how verifier imperfection affects performance. In this work, we address this
gap. Specifically, we prove how instance-level accuracy of these methods is
precisely characterized by the geometry of the verifier's ROC curve.
Interestingly, while scaling is determined by the local geometry of the ROC
curve for rejection sampling, it depends on global properties of the ROC curve
for BoN. As a consequence when the ROC curve is unknown, it is impossible to
extrapolate the performance of rejection sampling based on the low-compute
regime. Furthermore, while rejection sampling outperforms BoN for fixed
compute, in the infinite-compute limit both methods converge to the same level
of accuracy, determined by the slope of the ROC curve near the origin. Our
theoretical results are confirmed by experiments on GSM8K using different
versions of Llama and Qwen to generate and verify solutions.

</details>


### [215] [NOCTA: Non-Greedy Objective Cost-Tradeoff Acquisition for Longitudinal Data](https://arxiv.org/abs/2507.12412)
*Dzung Dinh,Boqi Chen,Marc Niethammer,Junier Oliva*

Main category: cs.LG

TL;DR: 提出了一种名为NOCTA的方法，用于解决资源受限情况下的特征信息获取问题，尤其适用于复杂的时间序列预测任务。


<details>
  <summary>Details</summary>
Motivation: 面对资源受限的预测场景（如医疗领域），需要根据特征的重要性和获取成本决定获取何种信息，同时兼顾时间动态性。

Method: 提出NOCTA方法，通过非贪婪的方式进行特征获取，考虑时间动态和获取成本，并提出两种估计器：基于最近邻的NOCTA-NP和直接预测获取效用的NOCTA-P。

Result: 在合成和真实医疗数据集上的实验表明，两种NOCTA变体的表现均优于现有基线方法。

Conclusion: 该方法有效地在时间动态和获取成本之间平衡，实现了更优的预测性能。

Abstract: In many critical applications, resource constraints limit the amount of
information that can be gathered to make predictions. For example, in
healthcare, patient data often spans diverse features ranging from lab tests to
imaging studies. Each feature may carry different information and must be
acquired at a respective cost of time, money, or risk to the patient. Moreover,
temporal prediction tasks, where both instance features and labels evolve over
time, introduce additional complexity in deciding when or what information is
important. In this work, we propose NOCTA, a Non-Greedy Objective Cost-Tradeoff
Acquisition method that sequentially acquires the most informative features at
inference time while accounting for both temporal dynamics and acquisition
cost. We first introduce a cohesive estimation target for our NOCTA setting,
and then develop two complementary estimators: 1) a non-parametric method based
on nearest neighbors to guide the acquisition (NOCTA-NP), and 2) a parametric
method that directly predicts the utility of potential acquisitions (NOCTA-P).
Experiments on synthetic and real-world medical datasets demonstrate that both
NOCTA variants outperform existing baselines.

</details>


### [216] [Mixture of Raytraced Experts](https://arxiv.org/abs/2507.12419)
*Andrea Perin,Giacomo Lagomarsini,Claudio Gallicchio,Giuseppe Nuti*

Main category: cs.LG

TL;DR: 本文提出了一种堆叠专家混合结构（MoE），可动态调整计算图的宽度和深度，实现更高效的推断与训练。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE架构在计算中对每个样本的资源使用是固定的。本研究旨在解决这种限制，探索通过动态选择专家序列提高计算效率和预测精度。

Method: 方法通过从候选专家集中迭代采样，生成专家序列进行训练，类似于RNN的展开方式，同时不需要负载均衡机制。

Result: 初步实验显示，与传统方法相比，该方法可减少10%至40%的训练周期，同时保持或提高预测精度。

Conclusion: 此方法展示了改进MoE模型的潜力，为设计更高效、更强表达能力的模型提供了研究方向。

Abstract: We introduce a Mixture of Raytraced Experts, a stacked Mixture of Experts
(MoE) architecture which can dynamically select sequences of experts, producing
computational graphs of variable width and depth. Existing MoE architectures
generally require a fixed amount of computation for a given sample. Our
approach, in contrast, yields predictions with increasing accuracy as the
computation cycles through the experts' sequence. We train our model by
iteratively sampling from a set of candidate experts, unfolding the sequence
akin to how Recurrent Neural Networks are trained. Our method does not require
load-balancing mechanisms, and preliminary experiments show a reduction in
training epochs of 10\% to 40\% with a comparable/higher accuracy. These
results point to new research directions in the field of MoEs, allowing the
design of potentially faster and more expressive models. The code is available
at https://github.com/nutig/RayTracing

</details>


### [217] [Targeted Deep Architectures: A TMLE-Based Framework for Robust Causal Inference in Neural Networks](https://arxiv.org/abs/2507.12435)
*Yi Li,David Mccoy,Nolan Gunter,Kaitlyn Lee,Alejandro Schuler,Mark van der Laan*

Main category: cs.LG

TL;DR: 本文提出了目标深度架构（TDA），直接将TMLE嵌入神经网络参数空间，实现双稳健性和半参数效率，并在多维因果估计问题中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习工具在因果参数（如治疗效应、生存曲线）推断中的缺陷，以及TMLE框架在神经网络中的局限性促使了本研究。

Method: 提出了一种目标深度架构TDA，通过对模型参数分区，仅优化一个“小型目标子集”，并利用影响函数投影更新参数，从而去除一阶偏差并生成有效置信区间。

Result: 在IHDP数据集和模拟生存数据上，TDA相较于传统神经网络估计方法和已有的后处理方法减少了偏差，提高了覆盖率。

Conclusion: TDA实现了将深度学习与因果推断相结合，为多参数目标的因果推断开辟了直接且可扩展的路径。

Abstract: Modern deep neural networks are powerful predictive tools yet often lack
valid inference for causal parameters, such as treatment effects or entire
survival curves. While frameworks like Double Machine Learning (DML) and
Targeted Maximum Likelihood Estimation (TMLE) can debias machine-learning fits,
existing neural implementations either rely on "targeted losses" that do not
guarantee solving the efficient influence function equation or computationally
expensive post-hoc "fluctuations" for multi-parameter settings. We propose
Targeted Deep Architectures (TDA), a new framework that embeds TMLE directly
into the network's parameter space with no restrictions on the backbone
architecture. Specifically, TDA partitions model parameters - freezing all but
a small "targeting" subset - and iteratively updates them along a targeting
gradient, derived from projecting the influence functions onto the span of the
gradients of the loss with respect to weights. This procedure yields plug-in
estimates that remove first-order bias and produce asymptotically valid
confidence intervals. Crucially, TDA easily extends to multi-dimensional causal
estimands (e.g., entire survival curves) by merging separate targeting
gradients into a single universal targeting update. Theoretically, TDA inherits
classical TMLE properties, including double robustness and semiparametric
efficiency. Empirically, on the benchmark IHDP dataset (average treatment
effects) and simulated survival data with informative censoring, TDA reduces
bias and improves coverage relative to both standard neural-network estimators
and prior post-hoc approaches. In doing so, TDA establishes a direct, scalable
pathway toward rigorous causal inference within modern deep architectures for
complex multi-parameter targets.

</details>


### [218] [A Bayesian Incentive Mechanism for Poison-Resilient Federated Learning](https://arxiv.org/abs/2507.12439)
*Daniel Commey,Rebecca A. Sarpong,Griffith S. Klogo,Winful Bagyl-Bac,Garth V. Crosby*

Main category: cs.LG

TL;DR: 本文提出了一种基于经济激励的轻量级贝叶斯防御机制，通过验证模型更新的质量来防止联邦学习中的数据污染攻击，该方法在确保数据隐私的同时提升了全局模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习易受到恶意参与者提交有害模型更新（如数据污染攻击）的威胁，现有方法主要依赖统计聚合，对计算资源的要求较高且假设诚实多数，这些限制激发了研究者寻找新的解决方案。

Method: 通过将每轮训练建模为信息不完全的贝叶斯博弈，服务器使用私人验证数据集评估更新质量，并通过经济激励机制使恶意行为变得不经济。该设计满足个体理性（IR）和激励相容性（IC）。

Result: 在非独立同分布的MNIST及FashionMNIST实验中，面对50%标签污染攻击，模型准确率仍达到96.7%，仅比30%攻击情境下低0.3个百分点，且比标准FedAvg提高了51.7个百分点。

Conclusion: 该机制具有计算轻量性、预算可控性，并能无缝集成至现有联邦学习框架，为实现经济上鲁棒且可持续的联邦学习生态提供了现实可行的途径。

Abstract: Federated learning (FL) enables collaborative model training across
decentralized clients while preserving data privacy. However, its
open-participation nature exposes it to data-poisoning attacks, in which
malicious actors submit corrupted model updates to degrade the global model.
Existing defenses are often reactive, relying on statistical aggregation rules
that can be computationally expensive and that typically assume an honest
majority. This paper introduces a proactive, economic defense: a lightweight
Bayesian incentive mechanism that makes malicious behavior economically
irrational. Each training round is modeled as a Bayesian game of incomplete
information in which the server, acting as the principal, uses a small, private
validation dataset to verify update quality before issuing payments. The design
satisfies Individual Rationality (IR) for benevolent clients, ensuring their
participation is profitable, and Incentive Compatibility (IC), making poisoning
an economically dominated strategy. Extensive experiments on non-IID partitions
of MNIST and FashionMNIST demonstrate robustness: with 50% label-flipping
adversaries on MNIST, the mechanism maintains 96.7% accuracy, only 0.3
percentage points lower than in a scenario with 30% label-flipping adversaries.
This outcome is 51.7 percentage points better than standard FedAvg, which
collapses under the same 50% attack. The mechanism is computationally light,
budget-bounded, and readily integrates into existing FL frameworks, offering a
practical route to economically robust and sustainable FL ecosystems.

</details>


### [219] [Cost-aware Stopping for Bayesian Optimization](https://arxiv.org/abs/2507.12453)
*Qian Xie,Linda Cai,Alexander Terenin,Peter I. Frazier,Ziv Scully*

Main category: cs.LG

TL;DR: 本文提出了一种用于贝叶斯优化的成本感知终止规则，能够适应不同的评估成本，无需启发式调参，并提供了理论上的成本评估保证。


<details>
  <summary>Details</summary>
Motivation: 当前的贝叶斯优化在评估代价昂贵的黑盒函数时，缺乏可靠的成本感知终止规则，可能导致过高的评估成本。

Method: 设计了一种与状态最优成本感知获取函数相关联的终止规则，并提供了理论保证，确保在不牺牲问题质量的情况下减少评估成本。

Result: 实验表明，与PBGI获取函数结合使用时，该规则在解决方案质量与累计评估成本的权衡（成本调整简单遗憾）上优于其他组合。

Conclusion: 本文提出的成本感知终止规则在理论和实践中证明了其有效性和优越性，适合在贝叶斯优化中使用以减少评估成本。

Abstract: In automated machine learning, scientific discovery, and other applications
of Bayesian optimization, deciding when to stop evaluating expensive black-box
functions is an important practical consideration. While several adaptive
stopping rules have been proposed, in the cost-aware setting they lack
guarantees ensuring they stop before incurring excessive function evaluation
costs. We propose a cost-aware stopping rule for Bayesian optimization that
adapts to varying evaluation costs and is free of heuristic tuning. Our rule is
grounded in a theoretical connection to state-of-the-art cost-aware acquisition
functions, namely the Pandora's Box Gittins Index (PBGI) and log expected
improvement per cost. We prove a theoretical guarantee bounding the expected
cumulative evaluation cost incurred by our stopping rule when paired with these
two acquisition functions. In experiments on synthetic and empirical tasks,
including hyperparameter optimization and neural architecture size search, we
show that combining our stopping rule with the PBGI acquisition function
consistently matches or outperforms other acquisition-function--stopping-rule
pairs in terms of cost-adjusted simple regret, a metric capturing trade-offs
between solution quality and cumulative evaluation cost.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [220] [Emergent Heterogeneous Swarm Control Through Hebbian Learning](https://arxiv.org/abs/2507.11566)
*Fuda van Diggelen,Tugay Alperen Karagüzel,Andres Garcia Rincon,A. E. Eiben,Dario Floreano,Eliseo Ferrante*

Main category: cs.NE

TL;DR: 本文引入一种新的群体机器人异质性学习方法——赫布学习。


<details>
  <summary>Details</summary>
Motivation: 提出一种基于局部信息的神经适应学习方法以解决异质控制中的关键挑战。

Method: 采用统一的赫布学习规则，结合群体级行为的进化优化，进行异质性控制和性能提升。

Result: 赫布学习实现了自然的异质性出现，提升了群体行为切换能力及整体能力，与多智能体强化学习在标准任务中有竞争力。

Conclusion: 赫布学习为群体机器人领域提供了一种有效的异质性学习方法，并减少了参数复杂度和先验知识需求。

Abstract: In this paper, we introduce Hebbian learning as a novel method for swarm
robotics, enabling the automatic emergence of heterogeneity. Hebbian learning
presents a biologically inspired form of neural adaptation that solely relies
on local information. By doing so, we resolve several major challenges for
learning heterogeneous control: 1) Hebbian learning removes the complexity of
attributing emergent phenomena to single agents through local learning rules,
thus circumventing the micro-macro problem; 2) uniform Hebbian learning rules
across all swarm members limit the number of parameters needed, mitigating the
curse of dimensionality with scaling swarm sizes; and 3) evolving Hebbian
learning rules based on swarm-level behaviour minimises the need for extensive
prior knowledge typically required for optimising heterogeneous swarms. This
work demonstrates that with Hebbian learning heterogeneity naturally emerges,
resulting in swarm-level behavioural switching and in significantly improved
swarm capabilities. It also demonstrates how the evolution of Hebbian learning
rules can be a valid alternative to Multi Agent Reinforcement Learning in
standard benchmarking tasks.

</details>


### [221] [Survey of Genetic and Differential Evolutionary Algorithm Approaches to Search Documents Based On Semantic Similarity](https://arxiv.org/abs/2507.11751)
*Chandrashekar Muniyappa,Eunjin Kim*

Main category: cs.NE

TL;DR: 本文综述了基于语义文本相似性搜索文档的算法，重点关注遗传算法和差分进化算法的最新进展。


<details>
  <summary>Details</summary>
Motivation: 解决在大量数据中识别相似文档的挑战。

Method: 利用深度神经网络及遗传算法和差分进化算法等进化计算技术。

Result: 总结了深度学习与进化计算在语义相似性文档搜索中的最新成果。

Conclusion: 遗传算法和差分进化算法在语义相似性文档搜索中具有重要的应用潜力。

Abstract: Identifying similar documents within extensive volumes of data poses a
significant challenge. To tackle this issue, researchers have developed a
variety of effective distributed computing techniques. With the advancement of
computing power and the rise of big data, deep neural networks and evolutionary
computing algorithms such as genetic algorithms and differential evolution
algorithms have achieved greater success. This survey will explore the most
recent advancements in the search for documents based on their semantic text
similarity, focusing on genetic and differential evolutionary computing
algorithms.

</details>


### [222] [Simulated Language Acquisition in a Biologically Realistic Model of the Brain](https://arxiv.org/abs/2507.11788)
*Daniel Mitropolsky,Christos Papadimitriou*

Main category: cs.NE

TL;DR: 本文提出了一种数学公式化方法，基于六种神经科学基本原则，模拟了一个可以学习语言语义和句法角色的神经形态系统。


<details>
  <summary>Details</summary>
Motivation: 尽管神经科学取得了巨大进展，但我们仍无法精确解释神经放电如何导致高级认知，如计划和语言。本文旨在通过简化的神经科学原则解决这一问题。

Method: 根据六种广泛接受的神经科学原则（兴奋性神经元、脑区、随机突触、Hebbian可塑性、局部抑制、区域间抑制）构建数学模型，并在其基础上实现一个神经形态系统，用以语言学习。

Result: 该系统从零起步，通过接触有限的语句样本，成功学习了词语语义、句法角色以及词序，甚至能够生成新句子。

Conclusion: 所提出的模型展示了基于神经科学原理的语言学习潜力，并且对该领域未来的研究和扩展有重要启示。

Abstract: Despite tremendous progress in neuroscience, we do not have a compelling
narrative for the precise way whereby the spiking of neurons in our brain
results in high-level cognitive phenomena such as planning and language. We
introduce a simple mathematical formulation of six basic and broadly accepted
principles of neuroscience: excitatory neurons, brain areas, random synapses,
Hebbian plasticity, local inhibition, and inter-area inhibition. We implement a
simulated neuromorphic system based on this formalism, which is capable of
basic language acquisition: Starting from a tabula rasa, the system learns, in
any language, the semantics of words, their syntactic role (verb versus noun),
and the word order of the language, including the ability to generate novel
sentences, through the exposure to a modest number of grounded sentences in the
same language. We discuss several possible extensions and implications of this
result.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [223] [CompressedVQA-HDR: Generalized Full-reference and No-reference Quality Assessment Models for Compressed High Dynamic Range Videos](https://arxiv.org/abs/2507.11900)
*Wei Sun,Linhan Cao,Kang Fu,Dandan Zhu,Jun Jia,Menghan Hu,Xiongkuo Min,Guangtao Zhai*

Main category: eess.IV

TL;DR: 提出了一种名为CompressedVQA-HDR的评估HDR视频压缩质量的框架，采用Swin Transformer和SigLip 2作为核心模型，获得了最先进性能，并在ICME 2025竞赛中获奖。


<details>
  <summary>Details</summary>
Motivation: 目前压缩视频质量评估方法对HDR内容的扩展性不够，无法应对视频类型的多样化增长需求。

Method: 采用Swin Transformer 和 SigLip 2作为FR和NR模型的核心网络。通过在大规模SDR数据集上预训练并在HDRSDR-VQA数据集上微调模型，来克服HDR训练数据不足的问题。

Result: 解法在多个实验中表现优越，达到了现有FR和NR模型的最先进性能，并在IEEE ICME 2025竞赛中获得第一名。

Conclusion: 引入的CompressedVQA-HDR框架在HDR视频质量评估中展现了高效性和鲁棒性，对未来视频压缩领域具有指导意义。

Abstract: Video compression is a standard procedure applied to all videos to minimize
storage and transmission demands while preserving visual quality as much as
possible. Therefore, evaluating the visual quality of compressed videos is
crucial for guiding the practical usage and further development of video
compression algorithms. Although numerous compressed video quality assessment
(VQA) methods have been proposed, they often lack the generalization capability
needed to handle the increasing diversity of video types, particularly high
dynamic range (HDR) content. In this paper, we introduce CompressedVQA-HDR, an
effective VQA framework designed to address the challenges of HDR video quality
assessment. Specifically, we adopt the Swin Transformer and SigLip 2 as the
backbone networks for the proposed full-reference (FR) and no-reference (NR)
VQA models, respectively. For the FR model, we compute deep structural and
textural similarities between reference and distorted frames using
intermediate-layer features extracted from the Swin Transformer as its
quality-aware feature representation. For the NR model, we extract the global
mean of the final-layer feature maps from SigLip 2 as its quality-aware
representation. To mitigate the issue of limited HDR training data, we
pre-train the FR model on a large-scale standard dynamic range (SDR) VQA
dataset and fine-tune it on the HDRSDR-VQA dataset. For the NR model, we employ
an iterative mixed-dataset training strategy across multiple compressed VQA
datasets, followed by fine-tuning on the HDRSDR-VQA dataset. Experimental
results show that our models achieve state-of-the-art performance compared to
existing FR and NR VQA models. Moreover, CompressedVQA-HDR-FR won first place
in the FR track of the Generalizable HDR & SDR Video Quality Measurement Grand
Challenge at IEEE ICME 2025. The code is available at
https://github.com/sunwei925/CompressedVQA-HDR.

</details>


### [224] [Identifying Signatures of Image Phenotypes to Track Treatment Response in Liver Disease](https://arxiv.org/abs/2507.12012)
*Matthias Perkonigg,Nina Bastati,Ahmed Ba-Ssalamah,Peter Mesenbrink,Alexander Goehler,Miljen Martic,Xiaofei Zhou,Michael Trauner,Georg Langs*

Main category: eess.IV

TL;DR: 本研究通过无监督机器学习技术，在磁共振成像中提取肝组织的影像模式词汇，用于量化弥漫性肝病的治疗反应。


<details>
  <summary>Details</summary>
Motivation: 探索一种无监督机器学习方法以便从医学影像中提取能量化治疗效果和疾病进展的组织特征。

Method: 应用深度聚类网络，将医学图像划分为低维潜在空间，并建立组织学词汇库，通过分析组织类型与治疗反应的联系进行量化评估。

Result: 在一项非酒精性脂肪性肝炎患者的随机对照试验中，该方法成功识别治疗相关的肝组织变化路径，比传统非视觉测量更好地区分治疗组。同时，该词汇库还能通过无创影像预测活检特征，并在独立复制组中得到验证。

Conclusion: 研究表明该方法能够有效捕获和量化肝组织随治疗发生的差异性变化，具有广泛适用性，为弥漫性肝病的诊断和治疗提供了有力工具。

Abstract: Quantifiable image patterns associated with disease progression and treatment
response are critical tools for guiding individual treatment, and for
developing novel therapies. Here, we show that unsupervised machine learning
can identify a pattern vocabulary of liver tissue in magnetic resonance images
that quantifies treatment response in diffuse liver disease. Deep clustering
networks simultaneously encode and cluster patches of medical images into a
low-dimensional latent space to establish a tissue vocabulary. The resulting
tissue types capture differential tissue change and its location in the liver
associated with treatment response. We demonstrate the utility of the
vocabulary on a randomized controlled trial cohort of non-alcoholic
steatohepatitis patients. First, we use the vocabulary to compare longitudinal
liver change in a placebo and a treatment cohort. Results show that the method
identifies specific liver tissue change pathways associated with treatment, and
enables a better separation between treatment groups than established
non-imaging measures. Moreover, we show that the vocabulary can predict biopsy
derived features from non-invasive imaging data. We validate the method on a
separate replication cohort to demonstrate the applicability of the proposed
method.

</details>


### [225] [Benchmarking and Explaining Deep Learning Cortical Lesion MRI Segmentation in Multiple Sclerosis](https://arxiv.org/abs/2507.12092)
*Nataliia Molchanova,Alessandro Cagol,Mario Ocampo-Pineda,Po-Jui Lu,Matthias Weigel,Xinjie Chen,Erin Beck,Charidimos Tsagkas,Daniel Reich,Colin Vanden Bulcke,Anna Stolting,Serena Borrelli,Pietro Maggi,Adrien Depeursinge,Cristina Granziera,Henning Mueller,Pedro M. Gordaliza,Meritxell Bach Cuadra*

Main category: eess.IV

TL;DR: 该论文提出了基于MRI图像的皮层病变（CL）检测与分割多中心基准，利用nnU-Net框架优化了CL检测能力，达到了域内F1得分0.64，跨域F1得分0.5，并提供了复现代码以促进临床应用。


<details>
  <summary>Details</summary>
Motivation: 皮层病变是多发性硬化症的重要生物标志物，但因MRI图像特点难以检测，专家标注挑战大，且缺乏标准化自动方法，限制了临床应用。

Method: 使用来自四个机构的656个3T和7T MRI扫描数据，采用自配置nnU-Net框架，通过针对皮层病变的改进对其进行检测和分割，并对AI决策过程及误差进行分析。

Result: 域内实现F1得分0.64，跨域测试达F1得分0.5，展示了强大的病变检测能力，并分析了数据变异性、病变模糊性及协议差异对模型性能的影响。

Conclusion: 提供了优化的皮层病变检测与分割方法，并提出了解决阻碍临床接纳的建议，其实现和模型公开可用，为临床应用奠定了基础。

Abstract: Cortical lesions (CLs) have emerged as valuable biomarkers in multiple
sclerosis (MS), offering high diagnostic specificity and prognostic relevance.
However, their routine clinical integration remains limited due to subtle
magnetic resonance imaging (MRI) appearance, challenges in expert annotation,
and a lack of standardized automated methods. We propose a comprehensive
multi-centric benchmark of CL detection and segmentation in MRI. A total of 656
MRI scans, including clinical trial and research data from four institutions,
were acquired at 3T and 7T using MP2RAGE and MPRAGE sequences with
expert-consensus annotations. We rely on the self-configuring nnU-Net
framework, designed for medical imaging segmentation, and propose adaptations
tailored to the improved CL detection. We evaluated model generalization
through out-of-distribution testing, demonstrating strong lesion detection
capabilities with an F1-score of 0.64 and 0.5 in and out of the domain,
respectively. We also analyze internal model features and model errors for a
better understanding of AI decision-making. Our study examines how data
variability, lesion ambiguity, and protocol differences impact model
performance, offering future recommendations to address these barriers to
clinical adoption. To reinforce the reproducibility, the implementation and
models will be publicly accessible and ready to use at
https://github.com/Medical-Image-Analysis-Laboratory/ and
https://doi.org/10.5281/zenodo.15911797.

</details>
