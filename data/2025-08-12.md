<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 220]
- [cs.CL](#cs.CL) [Total: 96]
- [cs.AI](#cs.AI) [Total: 65]
- [cs.LG](#cs.LG) [Total: 144]
- [cs.NE](#cs.NE) [Total: 7]
- [eess.IV](#eess.IV) [Total: 15]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Med-GRIM: Enhanced Zero-Shot Medical VQA using prompt-embedded Multimodal Graph RAG](https://arxiv.org/abs/2508.06496)
*Rakesh Raj Madavan,Akshat Kaimal,Hashim Faisal,Chandrakala S*

Main category: cs.CV

TL;DR: 本文提出了BIND模型和Med-GRIM系统，专注于提高医疗视觉问答任务的效果，特别是在零样本多模态医疗应用中。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态视觉-语言模型在复杂领域（如医疗问答任务）中缺乏精确的响应能力。

Method: 提出BIND模型，通过对比学习优化联合嵌入空间引入密集编码，同时整合Med-GRIM系统结合图检索和提示工程，并运用小型语言模型以实现高效的模块化工作流程。

Result: Med-GRIM系统在无需高计算开销的情况下实现了接近大型语言模型的性能，并具有高准确性和稳健性。

Conclusion: 通过创新方法和数据集，展示了在医疗问答领域解决特定挑战的潜力，同时提供了可扩展的零样本多模态研究基础。

Abstract: An ensemble of trained multimodal encoders and vision-language models (VLMs)
has become a standard approach for visual question answering (VQA) tasks.
However, such models often fail to produce responses with the detailed
precision necessary for complex, domain-specific applications such as medical
VQA. Our representation model, BIND: BLIVA Integrated with Dense Encoding,
extends prior multimodal work by refining the joint embedding space through
dense, query-token-based encodings inspired by contrastive pretraining
techniques. This refined encoder powers Med-GRIM, a model designed for medical
VQA tasks that leverages graph-based retrieval and prompt engineering to
integrate domain-specific knowledge. Rather than relying on compute-heavy
fine-tuning of vision and language models on specific datasets, Med-GRIM
applies a low-compute, modular workflow with small language models (SLMs) for
efficiency. Med-GRIM employs prompt-based retrieval to dynamically inject
relevant knowledge, ensuring both accuracy and robustness in its responses. By
assigning distinct roles to each agent within the VQA system, Med-GRIM achieves
large language model performance at a fraction of the computational cost.
Additionally, to support scalable research in zero-shot multimodal medical
applications, we introduce DermaGraph, a novel Graph-RAG dataset comprising
diverse dermatological conditions. This dataset facilitates both multimodal and
unimodal querying. The code and dataset are available at:
https://github.com/Rakesh-123-cryp/Med-GRIM.git

</details>


### [2] [DiTalker: A Unified DiT-based Framework for High-Quality and Speaking Styles Controllable Portrait Animation](https://arxiv.org/abs/2508.06511)
*He Feng,Yongjia Ma,Donglin Di,Lei Fan,Tonghua Su,Xiangqian Wu*

Main category: cs.CV

TL;DR: DiTalker是一种基于扩散模型的统一框架，用于生成风格可控的肖像动画，实现精确的唇同步和动态头部动作等特征。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在生成肖像动画时，要么只关注唇同步，要么局限于静态情感转换，忽略动态风格如头部动作，并且通常使用双U-Net架构，增加计算开销。

Method: 提出DiTalker框架，引入风格-情感编码模块分别提取身份特定风格信息和与身份无关的情感特征；通过音频-风格融合模块，使用平行的交叉注意力层解耦音频和说话风格；采用优化约束强化唇同步和细粒度细节保留。

Result: 实验显示DiTalker在唇同步及说话风格可控性方面优于现有方法。

Conclusion: DiTalker有效克服现有方法的不足，实现精确的唇同步和自然的动态风格展现，是生成风格可控肖像动画的先进方法。

Abstract: Portrait animation aims to synthesize talking videos from a static reference
face, conditioned on audio and style frame cues (e.g., emotion and head poses),
while ensuring precise lip synchronization and faithful reproduction of
speaking styles. Existing diffusion-based portrait animation methods primarily
focus on lip synchronization or static emotion transformation, often
overlooking dynamic styles such as head movements. Moreover, most of these
methods rely on a dual U-Net architecture, which preserves identity consistency
but incurs additional computational overhead. To this end, we propose DiTalker,
a unified DiT-based framework for speaking style-controllable portrait
animation. We design a Style-Emotion Encoding Module that employs two separate
branches: a style branch extracting identity-specific style information (e.g.,
head poses and movements), and an emotion branch extracting identity-agnostic
emotion features. We further introduce an Audio-Style Fusion Module that
decouples audio and speaking styles via two parallel cross-attention layers,
using these features to guide the animation process. To enhance the quality of
results, we adopt and modify two optimization constraints: one to improve lip
synchronization and the other to preserve fine-grained identity and background
details. Extensive experiments demonstrate the superiority of DiTalker in terms
of lip synchronization and speaking style controllability. Project Page:
https://thenameishope.github.io/DiTalker/

</details>


### [3] [BigTokDetect: A Clinically-Informed Vision-Language Model Framework for Detecting Pro-Bigorexia Videos on TikTok](https://arxiv.org/abs/2508.06515)
*Minh Duc Chu,Kshitij Pawar,Zihao He,Roxanna Sharifi,Ross Sonnenblick,Magdalayna Curry,Laura D'Adamo,Lindsay Young,Stuart B Murray,Kristina Lerman*

Main category: cs.CV

TL;DR: 该研究提出了一种名为BigTokDetect的检测框架，专门针对社交媒体平台上的伤害性内容（如支持肌肉畸形症的内容）进行检测。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决社交媒体平台难以检测假借健身内容的有害信息（如支持肌肉畸形症的内容），这些内容会特别影响青少年男性。

Method: 研究者引入了BigTok，一个由临床心理学家和精神科医生标注的多模态数据集，并利用视觉语言模型进行领域特定微调，评估内容分类的准确性。

Result: 通过多模态融合，相较于仅文本方法，性能提升了5%-10%，最终在分类任务中准确度达到82.9%。

Conclusion: 该研究为检测多模态有害内容设立了新标准，并提供了适用于心理健康领域的内容监管工具和方法学框架。

Abstract: Social media platforms increasingly struggle to detect harmful content that
promotes muscle dysmorphic behaviors, particularly pro-bigorexia content that
disproportionately affects adolescent males. Unlike traditional eating disorder
detection focused on the "thin ideal," pro-bigorexia material masquerades as
legitimate fitness content through complex multimodal combinations of visual
displays, coded language, and motivational messaging that evade text-based
detection systems. We address this challenge by developing BigTokDetect, a
clinically-informed detection framework for identifying pro-bigorexia content
on TikTok. We introduce BigTok, the first expert-annotated multimodal dataset
of over 2,200 TikTok videos labeled by clinical psychologists and psychiatrists
across five primary categories spanning body image, nutrition, exercise,
supplements, and masculinity. Through a comprehensive evaluation of
state-of-the-art vision language models, we achieve 0.829% accuracy on primary
category classification and 0.690% on subcategory detection via domain-specific
finetuning. Our ablation studies demonstrate that multimodal fusion improves
performance by 5-10% over text-only approaches, with video features providing
the most discriminative signals. These findings establish new benchmarks for
multimodal harmful content detection and provide both the computational tools
and methodological framework needed for scalable content moderation in
specialized mental health domains.

</details>


### [4] [Frequency Prior Guided Matching: A Data Augmentation Approach for Generalizable Semi-Supervised Polyp Segmentation](https://arxiv.org/abs/2508.06517)
*Haoran Xi,Chen Liu,Xiaolin Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为频率先验引导匹配（FPGM）的新型数据增强框架，用于解决结直肠癌早期诊断中自动息肉分割的挑战。


<details>
  <summary>Details</summary>
Motivation: 息肉分割模型面临的挑战是标注数据有限且在领域迁移下性能显著下降，现有的半监督学习方法未能充分利用息肉的特定结构特性。

Method: 提出Frequency Prior Guided Matching (FPGM)框架，通过学习标注息肉边缘区域的域不变频率先验，并对未标注图像进行频谱扰动，使其幅度频谱与先验对齐，同时保留相位信息，来增强模型的泛化能力。

Result: 在六个公共数据集上的验证表明，FPGM在零样本泛化能力上显著优于十种竞争方法，在数据稀缺场景下，Dice评分提升超过10%。

Conclusion: 通过显著增强跨领域鲁棒性，FPGM为有限监督下自动息肉分割的临床部署提供了强有力的解决方案。

Abstract: Automated polyp segmentation is essential for early diagnosis of colorectal
cancer, yet developing robust models remains challenging due to limited
annotated data and significant performance degradation under domain shift.
Although semi-supervised learning (SSL) reduces annotation requirements,
existing methods rely on generic augmentations that ignore polyp-specific
structural properties, resulting in poor generalization to new imaging centers
and devices. To address this, we introduce Frequency Prior Guided Matching
(FPGM), a novel augmentation framework built on a key discovery: polyp edges
exhibit a remarkably consistent frequency signature across diverse datasets.
FPGM leverages this intrinsic regularity in a two-stage process. It first
learns a domain-invariant frequency prior from the edge regions of labeled
polyps. Then, it performs principled spectral perturbations on unlabeled
images, aligning their amplitude spectra with this learned prior while
preserving phase information to maintain structural integrity. This targeted
alignment normalizes domain-specific textural variations, thereby compelling
the model to learn the underlying, generalizable anatomical structure.
Validated on six public datasets, FPGM establishes a new state-of-the-art
against ten competing methods. It demonstrates exceptional zero-shot
generalization capabilities, achieving over 10% absolute gain in Dice score in
data-scarce scenarios. By significantly enhancing cross-domain robustness, FPGM
presents a powerful solution for clinically deployable polyp segmentation under
limited supervision.

</details>


### [5] [Large Language Models Facilitate Vision Reflection in Image Classification](https://arxiv.org/abs/2508.06525)
*Guoyuan An,JaeYoon Kim,SungEui Yoon*

Main category: cs.CV

TL;DR: 文章探讨了视觉反射在大型多模态模型（LMMs）中的可解释性，提出通过语言模型验证视觉模型预测增加识别精度，且发现模型主要依赖浓缩文本表示以增强性能，展示无需训练的连接器能改进细粒度识别任务。


<details>
  <summary>Details</summary>
Motivation: 理解视觉反射现象以及其在多模态模型中的作用，探索利用该现象提升视觉语言模型的性能及解释性潜力。

Method: 研究模型互动，利用视觉语言连接器将视觉特征映射为文本概念；分析替代大部分视觉特征为少量文本的效果；测试无训练连接器在细粒度任务中的表现。

Result: 发现视觉反射能提升预测精度，LMMs主要依赖浓缩文本表示；介绍了无需训练的连接器在特定任务上表现更好的潜力。

Conclusion: 视觉反射机制为增强视觉语言模型性能和解释性提供了新的可能性和方向，应进一步探索其在可解释性及鲁棒性领域的应用。

Abstract: This paper presents several novel findings on the explainability of vision
reflection in large multimodal models (LMMs). First, we show that prompting an
LMM to verify the prediction of a specialized vision model can improve
recognition accuracy, even on benchmarks like ImageNet, despite prior evidence
that LMMs typically underperform dedicated vision encoders. Second, we analyze
the internal behavior of vision reflection and find that the vision-language
connector maps visual features into explicit textual concepts, allowing the
language model to reason about prediction plausibility using commonsense
knowledge. We further observe that replacing a large number of vision tokens
with only a few text tokens still enables LLaVA to generate similar answers,
suggesting that LMMs may rely primarily on a compact set of distilled textual
representations rather than raw vision features. Third, we show that a
training-free connector can enhance LMM performance in fine-grained recognition
tasks, without extensive feature-alignment training. Together, these findings
offer new insights into the explainability of vision-language models and
suggest that vision reflection is a promising strategy for achieving robust and
interpretable visual recognition.

</details>


### [6] [A Framework Combining 3D CNN and Transformer for Video-Based Behavior Recognition](https://arxiv.org/abs/2508.06528)
*Xiuliang Zhang,Tadiwa Elisha Nyamasvisva,Chuntao Liu*

Main category: cs.CV

TL;DR: 提出了一种结合3D CNN和Transformer架构的混合框架，用于视频行为识别，兼具局部时空特征提取和全局上下文建模优点，并在基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统3D CNN无法很好地建模长距离依赖，而Transformers虽然擅长全局信息学习但计算成本高昂，旨在解决这两者的局限性。

Method: 提出结合3D CNN和Transformer的混合框架，3D CNN模块负责提取低级时空特征，而Transformer模块捕捉长距离时间依赖，并通过融合机制整合两种表示。

Result: 在基准数据集上表现优于传统3D CNN和单独的Transformer，提高了识别准确率且复杂度可控。

Conclusion: 混合框架验证了两种模块的互补优势，为视频行为识别提供了一种有效且可扩展的方案。

Abstract: Video-based behavior recognition is essential in fields such as public
safety, intelligent surveillance, and human-computer interaction. Traditional
3D Convolutional Neural Network (3D CNN) effectively capture local
spatiotemporal features but struggle with modeling long-range dependencies.
Conversely, Transformers excel at learning global contextual information but
face challenges with high computational costs. To address these limitations, we
propose a hybrid framework combining 3D CNN and Transformer architectures. The
3D CNN module extracts low-level spatiotemporal features, while the Transformer
module captures long-range temporal dependencies, with a fusion mechanism
integrating both representations. Evaluated on benchmark datasets, the proposed
model outperforms traditional 3D CNN and standalone Transformers, achieving
higher recognition accuracy with manageable complexity. Ablation studies
further validate the complementary strengths of the two modules. This hybrid
framework offers an effective and scalable solution for video-based behavior
recognition.

</details>


### [7] [RMT-PPAD: Real-time Multi-task Learning for Panoptic Perception in Autonomous Driving](https://arxiv.org/abs/2508.06529)
*Jiayuan Wang,Q. M. Jonathan Wu,Katsuya Suto,Ning Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为RMT-PPAD的实时、多任务Transformer模型，解决自动驾驶中目标检测、可驾驶区域分割和车道线分割的精度与实时性问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决多任务学习中任务间的负迁移以及手动设计不同分割任务结构的复杂性，同时解决车道线分割中训练和测试标签的不一致问题，提升自动驾驶系统的多任务表现。

Method: 提出一种轻量级的模块，结合门控控制与适配器实现特征的自适应融合，设计自适应分割解码器以自动学习多尺度特征权重，并改进车道线分割标签一致性问题，同时基于BDD100K数据集进行评价。

Result: RMT-PPAD在BDD100K数据集上实现了84.9%的mAP50和95.4%的目标检测召回率、92.6%的可驾驶区域分割mIoU、56.8%的车道线分割IoU及84.7%的车道线分割准确率，推理速度达32.6 FPS，在真实场景中表现稳定。

Conclusion: RMT-PPAD通过轻量化设计和任务优化，在多任务性能和实时性上达到了自动驾驶感知的新水准，且开源代码支持进一步研究。

Abstract: Autonomous driving systems rely on panoptic driving perception that requires
both precision and real-time performance. In this work, we propose RMT-PPAD, a
real-time, transformer-based multi-task model that jointly performs object
detection, drivable area segmentation, and lane line segmentation. We introduce
a lightweight module, a gate control with an adapter to adaptively fuse shared
and task-specific features, effectively alleviating negative transfer between
tasks. Additionally, we design an adaptive segmentation decoder to learn the
weights over multi-scale features automatically during the training stage. This
avoids the manual design of task-specific structures for different segmentation
tasks. We also identify and resolve the inconsistency between training and
testing labels in lane line segmentation. This allows fairer evaluation.
Experiments on the BDD100K dataset demonstrate that RMT-PPAD achieves
state-of-the-art results with mAP50 of 84.9% and Recall of 95.4% for object
detection, mIoU of 92.6% for drivable area segmentation, and IoU of 56.8% and
accuracy of 84.7% for lane line segmentation. The inference speed reaches 32.6
FPS. Moreover, we introduce real-world scenarios to evaluate RMT-PPAD
performance in practice. The results show that RMT-PPAD consistently delivers
stable performance. The source codes and pre-trained models are released at
https://github.com/JiayuanWang-JW/RMT-PPAD.

</details>


### [8] [What Makes "Good" Distractors for Object Hallucination Evaluation in Large Vision-Language Models?](https://arxiv.org/abs/2508.06530)
*Ming-Kun Xie,Jia-Hao Xiao,Gang Niu,Lei Feng,Zhiqiang Kou,Min-Ling Zhang,Masashi Sugiyama*

Main category: cs.CV

TL;DR: 提出了HOPE基准以替代传统的POPE基准，更有效评估大型视觉语言模型（LVLMs）的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有的POPE基准由于采样策略过于简单，无法有效评估LVLMs的幻觉问题。

Method: 引入基于CLIP的内容感知幻觉搜索以生成最具误导性的干扰项，并借助描述构造更高误导性的干扰项。

Result: HOPE基准使各种先进LVLMs的精确度下降至少9%，最高达23%，显著优于POPE在暴露幻觉漏洞上的表现。

Conclusion: HOPE基准通过更严格的伪造干扰项评估，为未来LVLMs的改进提供了有效工具。

Abstract: Large Vision-Language Models (LVLMs), empowered by the success of Large
Language Models (LLMs), have achieved impressive performance across domains.
Despite the great advances in LVLMs, they still suffer from the unavailable
object hallucination issue, which tends to generate objects inconsistent with
the image content. The most commonly used Polling-based Object Probing
Evaluation (POPE) benchmark evaluates this issue by sampling negative
categories according to category-level statistics, \textit{e.g.}, category
frequencies and co-occurrence. However, with the continuous advancement of
LVLMs, the POPE benchmark has shown diminishing effectiveness in assessing
object hallucination, as it employs a simplistic sampling strategy that
overlooks image-specific information and restricts distractors to negative
object categories only. In this paper, we introduce the Hallucination
searching-based Object Probing Evaluation (HOPE) benchmark, aiming to generate
the most misleading distractors (\textit{i.e.}, non-existent objects or
incorrect image descriptions) that can trigger hallucination in LVLMs, which
serves as a means to more rigorously assess their immunity to hallucination. To
explore the image-specific information, the content-aware hallucination
searching leverages Contrastive Language-Image Pre-Training (CLIP) to
approximate the predictive behavior of LVLMs by selecting negative objects with
the highest predicted likelihood as distractors. To expand the scope of
hallucination assessment, the description-based hallucination searching
constructs highly misleading distractors by pairing true objects with false
descriptions. Experimental results show that HOPE leads to a precision drop of
at least 9\% and up to 23\% across various state-of-the-art LVLMs,
significantly outperforming POPE in exposing hallucination vulnerabilities. The
code is available at https://github.com/xiemk/HOPE.

</details>


### [9] [Benchmarking Deep Learning-Based Object Detection Models on Feature Deficient Astrophotography Imagery Dataset](https://arxiv.org/abs/2508.06537)
*Shantanusinh Parmar*

Main category: cs.CV

TL;DR: 本文介绍了MobilTelesco，一个基于智能手机的天体摄影数据集，并在此数据集上对几个检测模型进行了基准测试，用以突显特征稀疏情况下的挑战。


<details>
  <summary>Details</summary>
Motivation: 目前的目标检测模型大多基于ImageNet、COCO和PASCAL VOC等数据集训练，这些数据集着重于日常物体，而缺乏在信号稀疏的非商业领域的适应性。从而提出解决此问题的新数据集。

Method: 通过提出MobilTelesco数据集，提供稀疏夜空图像，并对多种目标检测模型在此数据集上的性能进行基准测试分析。

Result: 发现并分析了多种检测模型在特征稀疏的夜空场景中所面临的挑战，展现了此新数据集的重要性。

Conclusion: MobilTelesco填补了信号稀疏领域的空缺，为目标检测模型在非商业领域的性能提升提供了新方向。同时揭示了在稀疏条件下基准测试的重要性。

Abstract: Object detection models are typically trained on datasets like ImageNet,
COCO, and PASCAL VOC, which focus on everyday objects. However, these lack
signal sparsity found in non-commercial domains. MobilTelesco, a
smartphone-based astrophotography dataset, addresses this by providing sparse
night-sky images. We benchmark several detection models on it, highlighting
challenges under feature-deficient conditions.

</details>


### [10] [MILD: Multi-Layer Diffusion Strategy for Complex and Precise Multi-IP Aware Human Erasing](https://arxiv.org/abs/2508.06543)
*Jinghan Yu,Zhiyuan Ma,Yue Ma,Kaiqi Liu,Yuhan Wang,Jianjun Li*

Main category: cs.CV

TL;DR: 本文提出了多层扩散（MILD）策略，解决复杂多主体场景下的人体擦除问题，并通过实验表明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在人体擦除任务中难以处理人际遮挡、人与物体交叠以及复杂背景干扰，主要由于数据集有限和缺乏前景空间解耦。

Method: 提出一个高质量多主体人体擦除数据集，并设计多层扩散（MILD）策略，将生成分解为前景实例和背景的语义化路径。同时引入人类形态引导和空间调制注意力机制。

Result: MILD方法在具有挑战性的人体擦除基准测试中表现优于最先进的方法。

Conclusion: 通过创新的方法和数据集，MILD有效提升了复杂情景下的人体擦除能力。

Abstract: Recent years have witnessed the success of diffusion models in
image-customized tasks. Prior works have achieved notable progress on
human-oriented erasing using explicit mask guidance and semantic-aware
inpainting. However, they struggle under complex multi-IP scenarios involving
human-human occlusions, human-object entanglements, and background
interferences. These challenges are mainly due to: 1) Dataset limitations, as
existing datasets rarely cover dense occlusions, camouflaged backgrounds, and
diverse interactions; 2) Lack of spatial decoupling, where foreground instances
cannot be effectively disentangled, limiting clean background restoration. In
this work, we introduce a high-quality multi-IP human erasing dataset with
diverse pose variations and complex backgrounds. We then propose Multi-Layer
Diffusion (MILD), a novel strategy that decomposes generation into semantically
separated pathways for each instance and the background. To enhance
human-centric understanding, we introduce Human Morphology Guidance,
integrating pose, parsing, and spatial relations. We further present
Spatially-Modulated Attention to better guide attention flow. Extensive
experiments show that MILD outperforms state-of-the-art methods on challenging
human erasing benchmarks.

</details>


### [11] [Statistical Confidence Rescoring for Robust 3D Scene Graph Generation from Multi-View Images](https://arxiv.org/abs/2508.06546)
*Qi Xun Yeo,Yanyan Li,Gim Hee Lee*

Main category: cs.CV

TL;DR: 提出了一种仅利用多视图RGB图像进行3D场景语义图估计的新方法，解决了深度信息预测中的噪声问题，并通过特征聚合及邻居节点信息改进了预测精度。


<details>
  <summary>Details</summary>
Motivation: 当前方法依赖于3D的地面真值注释，但在没有这些注释的情况下，仅利用多视图RGB图像进行3D场景语义图估计仍然是一个挑战。

Method: 通过语义掩码指导特征聚合、结合邻近节点信息、引入显式统计先验等方式增强特征的语义和空间信息，并减少背景噪声的干扰。

Result: 实验表明，该方法基于多视图图像输入的情况下，超越了现有方法的性能。

Conclusion: 在没有3D地面真值的条件下，该方法展示了多视图RGB图像驱动的3D场景语义图估计的潜力，并有效提升了预测的准确性与鲁棒性。

Abstract: Modern 3D semantic scene graph estimation methods utilize ground truth 3D
annotations to accurately predict target objects, predicates, and
relationships. In the absence of given 3D ground truth representations, we
explore leveraging only multi-view RGB images to tackle this task. To attain
robust features for accurate scene graph estimation, we must overcome the noisy
reconstructed pseudo point-based geometry from predicted depth maps and reduce
the amount of background noise present in multi-view image features. The key is
to enrich node and edge features with accurate semantic and spatial information
and through neighboring relations. We obtain semantic masks to guide feature
aggregation to filter background features and design a novel method to
incorporate neighboring node information to aid robustness of our scene graph
estimates. Furthermore, we leverage on explicit statistical priors calculated
from the training summary statistics to refine node and edge predictions based
on their one-hop neighborhood. Our experiments show that our method outperforms
current methods purely using multi-view images as the initial input. Our
project page is available at https://qixun1.github.io/projects/SCRSSG.

</details>


### [12] [Slice or the Whole Pie? Utility Control for AI Models](https://arxiv.org/abs/2508.06551)
*Ye Tao*

Main category: cs.CV

TL;DR: NNObfuscator 通过动态性能调节机制，减少深度神经网络多任务适配的资源成本与管理复杂性。


<details>
  <summary>Details</summary>
Motivation: 解决单个模型难以适配多种用户需求和性能要求的问题，同时减少模型训练的复杂性和资源浪费。

Method: 提出了NNObfuscator，通过动态调节机制，使单个模型在预设条件下调整性能水平，支持分层访问及实时适应多任务。

Result: 实验验证了NNObfuscator在多任务场景（如图像分类、语义分割、文本到图像生成）中的有效性，能够在无需多次调整的情况下，适应多种需求。

Conclusion: NNObfuscator提升了模型适应能力，优化了资源配置，支持了具有可持续性的AI业务模式，为多任务AI部署提供了创新解决方案。

Abstract: Training deep neural networks (DNNs) has become an increasingly
resource-intensive task, requiring large volumes of labeled data, substantial
computational power, and considerable fine-tuning efforts to achieve optimal
performance across diverse use cases. Although pre-trained models offer a
useful starting point, adapting them to meet specific user needs often demands
extensive customization, and infrastructure overhead. This challenge grows when
a single model must support diverse appli-cations with differing requirements
for performance. Traditional solutions often involve training multiple model
versions to meet varying requirements, which can be inefficient and difficult
to maintain. In order to overcome this challenge, we propose NNObfuscator, a
novel utility control mechanism that enables AI models to dynamically modify
their performance according to predefined conditions. It is different from
traditional methods that need separate models for each user. Instead,
NNObfuscator allows a single model to be adapted in real time, giving you
controlled access to multiple levels of performance. This mechanism enables
model owners set up tiered access, ensuring that free-tier users receive a
baseline level of performance while premium users benefit from enhanced
capabilities. The approach improves resource allocation, reduces unnecessary
computation, and supports sustainable business models in AI deployment. To
validate our approach, we conducted experiments on multiple tasks, including
image classification, semantic segmentation, and text to image generation,
using well-established models such as ResNet, DeepLab, VGG16, FCN and Stable
Diffusion. Experimental results show that NNObfuscator successfully makes model
more adaptable, so that a single trained model can handle a broad range of
tasks without requiring a lot of changes.

</details>


### [13] [Age-Diverse Deepfake Dataset: Bridging the Age Gap in Deepfake Detection](https://arxiv.org/abs/2508.06552)
*Unisha Joshi*

Main category: cs.CV

TL;DR: 本研究通过引入一个年龄多样化的深度伪造数据集，解决了深度伪造检测中存在的年龄偏差问题，并证明该数据集对检测模型的公平性和泛化能力有提升效果。


<details>
  <summary>Details</summary>
Motivation: 现有的深度伪造检测模型对数据集中的人口统计偏差，尤其是年龄偏差问题，研究较少。为了提高模型的公平性和性能，需要一个更具代表性的数据集。

Method: 提出通过使用Celeb-DF、FaceForensics++和UTKFace等数据集，以及生成合成数据的模块化流水线来填补年龄分布的空白，从而构建一个年龄多样化的深度伪造数据集。

Result: 用三个检测模型（XceptionNet、EfficientNet和LipForensics）进行评估后，结果表明，基于该数据集的模型在所有年龄组上表现更公平，准确率更高，跨数据集的泛化能力更强。

Conclusion: 本研究提供了一个可复制、关注公平性的深度伪造数据集及模型流程，为未来更公平的深度伪造检测研究奠定了基础。

Abstract: The challenges associated with deepfake detection are increasing
significantly with the latest advancements in technology and the growing
popularity of deepfake videos and images. Despite the presence of numerous
detection models, demographic bias in the deepfake dataset remains largely
unaddressed. This paper focuses on the mitigation of age-specific bias in the
deepfake dataset by introducing an age-diverse deepfake dataset that will
improve fairness across age groups. The dataset is constructed through a
modular pipeline incorporating the existing deepfake datasets Celeb-DF,
FaceForensics++, and UTKFace datasets, and the creation of synthetic data to
fill the age distribution gaps. The effectiveness and generalizability of this
dataset are evaluated using three deepfake detection models: XceptionNet,
EfficientNet, and LipForensics. Evaluation metrics, including AUC, pAUC, and
EER, revealed that models trained on the age-diverse dataset demonstrated
fairer performance across age groups, improved overall accuracy, and higher
generalization across datasets. This study contributes a reproducible,
fairness-aware deepfake dataset and model pipeline that can serve as a
foundation for future research in fairer deepfake detection. The complete
dataset and implementation code are available at
https://github.com/unishajoshi/age-diverse-deepfake-detection.

</details>


### [14] [Static and Plugged: Make Embodied Evaluation Simple](https://arxiv.org/abs/2508.06553)
*Jiahao Xiao,Jianbo Zhang,BoWen Yan,Shengyu Guo,Tongrui Ye,Kaiwei Zhang,Zicheng Zhang,Xiaohong Liu,Zhengxue Cheng,Lei Fan,Chuyi Li,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出了一个名为StaticEmbodiedBench的高效评测基准，旨在通过静态场景表示实现统一评估。


<details>
  <summary>Details</summary>
Motivation: 当前的评测方法如交互式仿真环境或现实环境存在成本高、分散且难以扩展的问题。

Method: 设计了StaticEmbodiedBench，这是一个支持多维度、静态场景表示的评测基准，允许通过简单的界面进行评价。

Result: 评估了19个视觉-语言模型（VLMs）和11个视觉-语言-动作模型（VLAs），首次建立了为体现智能的统一静态排行榜。

Conclusion: StaticEmbodiedBench为体现智能的发展提供了高效、统一的评测工具，并通过发布部分样本数据进一步加速领域的发展。

Abstract: Embodied intelligence is advancing rapidly, driving the need for efficient
evaluation. Current benchmarks typically rely on interactive simulated
environments or real-world setups, which are costly, fragmented, and hard to
scale. To address this, we introduce StaticEmbodiedBench, a plug-and-play
benchmark that enables unified evaluation using static scene representations.
Covering 42 diverse scenarios and 8 core dimensions, it supports scalable and
comprehensive assessment through a simple interface. Furthermore, we evaluate
19 Vision-Language Models (VLMs) and 11 Vision-Language-Action models (VLAs),
establishing the first unified static leaderboard for Embodied intelligence.
Moreover, we release a subset of 200 samples from our benchmark to accelerate
the development of embodied intelligence.

</details>


### [15] [StyleTailor: Towards Personalized Fashion Styling via Hierarchical Negative Feedback](https://arxiv.org/abs/2508.06555)
*Hongbo Ma,Fei Shen,Hongbin Xu,Xiaoce Wang,Gang Xu,Jinkai Zheng,Liangqiong Qu,Ming Li*

Main category: cs.CV

TL;DR: StyleTailor 是一框架结合个性化服装设计、购物推荐、虚拟试穿，并通过分层化语言模型反馈迭代优化，提升推荐质量。


<details>
  <summary>Details</summary>
Motivation: 当前，智能代理在众多领域表现优异，但个性化时尚造型领域仍是未充分探索的蓝海，具有极大潜力提升购物体验。

Method: 提出了StyleTailor框架，结合个性化服装设计代理和虚拟试穿代理，通过多层次视觉与语言反馈构建闭环机制，实现个性化推荐优化。

Result: 通过广泛实验发现，StyleTailor在个性化设计和推荐效果上领先于其他基线方法，成为智能时尚系统的新标杆。

Conclusion: StyleTailor展示了对个性化时尚系统的前沿探索，为智能化和用户优化提供了创新方向。

Abstract: The advancement of intelligent agents has revolutionized problem-solving
across diverse domains, yet solutions for personalized fashion styling remain
underexplored, which holds immense promise for promoting shopping experiences.
In this work, we present StyleTailor, the first collaborative agent framework
that seamlessly unifies personalized apparel design, shopping recommendation,
virtual try-on, and systematic evaluation into a cohesive workflow. To this
end, StyleTailor pioneers an iterative visual refinement paradigm driven by
multi-level negative feedback, enabling adaptive and precise user alignment.
Specifically, our framework features two core agents, i.e., Designer for
personalized garment selection and Consultant for virtual try-on, whose outputs
are progressively refined via hierarchical vision-language model feedback
spanning individual items, complete outfits, and try-on efficacy.
Counterexamples are aggregated into negative prompts, forming a closed-loop
mechanism that enhances recommendation quality.To assess the performance, we
introduce a comprehensive evaluation suite encompassing style consistency,
visual quality, face similarity, and artistic appraisal. Extensive experiments
demonstrate StyleTailor's superior performance in delivering personalized
designs and recommendations, outperforming strong baselines without negative
feedback and establishing a new benchmark for intelligent fashion systems.

</details>


### [16] [From Label Error Detection to Correction: A Modular Framework and Benchmark for Object Detection Datasets](https://arxiv.org/abs/2508.06556)
*Sarina Penquitt,Jonathan Klees,Rinor Cakaj,Daniel Kondermann,Matthias Rottmann,Lars Schmarje*

Main category: cs.CV

TL;DR: 本文提出了一种名为REC✔D（Rechecked）的半自动标注错误校正框架，利用现有检测器与众包微任务相结合，提升标注质量并验证效果。


<details>
  <summary>Details</summary>
Motivation: 当前物体检测数据集因标注错误影响训练与评估效果，解决此问题成为关键需求。

Method: 通过构建REC✔D框架，将检测器生成的错误标注候选与轻量化众包任务结合，聚合多名标注者的反馈以校正标注错误。

Result: 在KITTI数据集中的行人类别上应用时，发现至少24%的漏标或错误标注，生成高质量修正标注并对现有方法提供基准。

Conclusion: 现有方法结合REC✔D能显著提高数据集标注质量，但仍需进一步研究改进算法，以减少标注错误并提升自动化准确率。

Abstract: Object detection has advanced rapidly in recent years, driven by increasingly
large and diverse datasets. However, label errors, defined as missing labels,
incorrect classification or inaccurate localization, often compromise the
quality of these datasets. This can have a significant impact on the outcomes
of training and benchmark evaluations. Although several methods now exist for
detecting label errors in object detection datasets, they are typically
validated only on synthetic benchmarks or limited manual inspection. How to
correct such errors systemically and at scale therefore remains an open
problem. We introduce a semi-automated framework for label-error correction
called REC$\checkmark$D (Rechecked). Building on existing detectors, the
framework pairs their error proposals with lightweight, crowd-sourced
microtasks. These tasks enable multiple annotators to independently verify each
candidate bounding box, and their responses are aggregated to estimate
ambiguity and improve label quality. To demonstrate the effectiveness of
REC$\checkmark$D, we apply it to the class pedestrian in the KITTI dataset. Our
crowdsourced review yields high-quality corrected annotations, which indicate a
rate of at least 24% of missing and inaccurate annotations in original
annotations. This validated set will be released as a new real-world benchmark
for label error detection and correction. We show that current label error
detection methods, when combined with our correction framework, can recover
hundreds of errors in the time it would take a human to annotate bounding boxes
from scratch. However, even the best methods still miss up to 66% of the true
errors and with low quality labels introduce more errors than they find. This
highlights the urgent need for further research, now enabled by our released
benchmark.

</details>


### [17] [On the effectiveness of multimodal privileged knowledge distillation in two vision transformer based diagnostic applications](https://arxiv.org/abs/2508.06558)
*Simon Baur,Alexandra Benova,Emilio Dolgener Cantú,Jackie Ma*

Main category: cs.CV

TL;DR: 本研究提出了一种多模态特权知识蒸馏(MMPKD)的训练方法，该方法在训练时利用额外模态来指导单一视觉模型，结果提升了模型对输入图像中感兴趣区域(ROI)的注意力能力。


<details>
  <summary>Details</summary>
Motivation: 临床实际应用中，深度学习模型需要利用多种数据模态(如图像、文本和结构化数据)以实现可靠决策，但推理时并非所有模态都可用，因此需要一种能有效应对模态缺失的技术。

Method: 通过引入一种训练策略：多模态特权知识蒸馏(MMPKD)，在训练过程中使用仅在训练时可用的额外模态(如文本和元数据)指导一个视觉变换模型的学习。

Result: 在胸部放射图和乳腺密度数据集上进行测试，MMPKD在零样本情况下提升了模型定位感兴趣区域(ROI)的能力，但这一效果未能在不同领域中实现通用。

Conclusion: MMPKD作为一种创新性的方法，在特定情况下改进了视觉模型的注意力可用性，但其跨领域推广性仍需进一步研究。

Abstract: Deploying deep learning models in clinical practice often requires leveraging
multiple data modalities, such as images, text, and structured data, to achieve
robust and trustworthy decisions. However, not all modalities are always
available at inference time. In this work, we propose multimodal privileged
knowledge distillation (MMPKD), a training strategy that utilizes additional
modalities available solely during training to guide a unimodal vision model.
Specifically, we used a text-based teacher model for chest radiographs
(MIMIC-CXR) and a tabular metadata-based teacher model for mammography
(CBIS-DDSM) to distill knowledge into a vision transformer student model. We
show that MMPKD can improve the resulting attention maps' zero-shot
capabilities of localizing ROI in input images, while this effect does not
generalize across domains, as contrarily suggested by prior research.

</details>


### [18] [Grounding Emotion Recognition with Visual Prototypes: VEGA -- Revisiting CLIP in MERC](https://arxiv.org/abs/2508.06564)
*Guanyu Hu,Dimitrios Kollias,Xinyu Yang*

Main category: cs.CV

TL;DR: 引入了一种名为VEGA的机制，通过视觉情感导向的方式增强文本、声学和视觉信号在对话中的情感识别能力，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态情感识别模型在对多模态信号的对齐时缺乏心理学上的指导，作者期望通过引入心理学意义的先验来提高模型表现。

Method: 提出了一种VEGA机制，通过利用CLIP的图像编码器构建基于面部样例的情感特定视觉锚点，从而在表示空间中实现感知和心理学上的对齐。此外，使用随机锚点采样策略提高了语义稳定性和类内多样性，结合双分支架构和自蒸馏方法优化模型。

Result: 在IEMOCAP和MELD数据集上取得了SOTA的性能表现。

Conclusion: 通过引入心理学上的情感分类和多感知整合的认知理论，提出的VEGA机制成功改善了多模态情感识别的效果，并为现有的情感识别技术提供了更心理学导向的框架。

Abstract: Multimodal Emotion Recognition in Conversations remains a challenging task
due to the complex interplay of textual, acoustic and visual signals. While
recent models have improved performance via advanced fusion strategies, they
often lack psychologically meaningful priors to guide multimodal alignment. In
this paper, we revisit the use of CLIP and propose a novel Visual Emotion
Guided Anchoring (VEGA) mechanism that introduces class-level visual semantics
into the fusion and classification process. Distinct from prior work that
primarily utilizes CLIP's textual encoder, our approach leverages its image
encoder to construct emotion-specific visual anchors based on facial exemplars.
These anchors guide unimodal and multimodal features toward a perceptually
grounded and psychologically aligned representation space, drawing inspiration
from cognitive theories (prototypical emotion categories and multisensory
integration). A stochastic anchor sampling strategy further enhances robustness
by balancing semantic stability and intra-class diversity. Integrated into a
dual-branch architecture with self-distillation, our VEGA-augmented model
achieves sota performance on IEMOCAP and MELD. Code is available at:
https://github.com/dkollias/VEGA.

</details>


### [19] [Bridging Brain Connectomes and Clinical Reports for Early Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.06565)
*Jing Zhang,Xiaowei Yu,Minheng Chen,Lu Zhang,Tong Chen,Yan Zhuang,Chao Cao,Yanjun Lyu,Li Su,Tianming Liu,Dajiang Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种将脑影像数据与临床报告结合的新框架，利用多模态信息提高诊断效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 目前脑疾病研究中，如何将客观的影像数据与主观的文本报告（如医生笔记）有效联系起来是一个关键挑战。

Method: 通过将脑网络连接图（connectome）与临床报告在一个共同的跨模态潜在空间中对齐，同时把脑子网当作成像数据的“令牌”以对齐文本中的单词。这样能够更有效地发现影像数据和文本报告之间的系统关联。

Result: 在阿尔茨海默症神经影像数据指标（ADNI）数据集上验证了该方法，不仅预测性能达到最新水平，还能识别有临床意义的connectome-文本对。

Conclusion: 该方法为早期阿尔茨海默症机制研究和多模态生物标记开发提供了新见解，并展示了潜在的临床应用价值。

Abstract: Integrating brain imaging data with clinical reports offers a valuable
opportunity to leverage complementary multimodal information for more effective
and timely diagnosis in practical clinical settings. This approach has gained
significant attention in brain disorder research, yet a key challenge remains:
how to effectively link objective imaging data with subjective text-based
reports, such as doctors' notes. In this work, we propose a novel framework
that aligns brain connectomes with clinical reports in a shared cross-modal
latent space at both the subject and connectome levels, thereby enhancing
representation learning. The key innovation of our approach is that we treat
brain subnetworks as tokens of imaging data, rather than raw image patches, to
align with word tokens in clinical reports. This enables a more efficient
identification of system-level associations between neuroimaging findings and
clinical observations, which is critical since brain disorders often manifest
as network-level abnormalities rather than isolated regional alterations. We
applied our method to mild cognitive impairment (MCI) using the ADNI dataset.
Our approach not only achieves state-of-the-art predictive performance but also
identifies clinically meaningful connectome-text pairs, offering new insights
into the early mechanisms of Alzheimer's disease and supporting the development
of clinically useful multimodal biomarkers.

</details>


### [20] [Surformer v1: Transformer-Based Surface Classification Using Tactile and Vision Features](https://arxiv.org/abs/2508.06566)
*Manish Kansana,Elias Hossain,Shahram Rahimi,Noorbakhsh Amiri Golilarz*

Main category: cs.CV

TL;DR: 提出了一种名为Surformer v1的基于transformer的架构，用于通过触觉和视觉数据的多模态融合进行表面材料识别，取得了高准确率和低推理时间的优秀性能。


<details>
  <summary>Details</summary>
Motivation: 高效准确的表面材料识别对机器人感知和物理交互至关重要，尤其需整合视觉和触觉数据。

Method: 模型基于transformer架构，集成了模态特定编码器和跨模态注意力层；触觉特征经工程优化，视觉特征通过ResNet-50提取并降维；比较了基于特征和基于图像的多模态学习方法。

Result: Surformer v1在多模态学习中实现了99.4%的分类准确率，且推理时间仅为0.77毫秒，性能优于多数基线模型。

Conclusion: Surformer v1结合了准确性、效率和计算成本，适用于实时表面材料识别任务，尤其在多模态数据融合方面展现了强大优势。

Abstract: Surface material recognition is a key component in robotic perception and
physical interaction, particularly when leveraging both tactile and visual
sensory inputs. In this work, we propose Surformer v1, a transformer-based
architecture designed for surface classification using structured tactile
features and PCA-reduced visual embeddings extracted via ResNet-50. The model
integrates modality-specific encoders with cross-modal attention layers,
enabling rich interactions between vision and touch. Currently,
state-of-the-art deep learning models for vision tasks have achieved remarkable
performance. With this in mind, our first set of experiments focused
exclusively on tactile-only surface classification. Using feature engineering,
we trained and evaluated multiple machine learning models, assessing their
accuracy and inference time. We then implemented an encoder-only Transformer
model tailored for tactile features. This model not only achieved the highest
accuracy but also demonstrated significantly faster inference time compared to
other evaluated models, highlighting its potential for real-time applications.
To extend this investigation, we introduced a multimodal fusion setup by
combining vision and tactile inputs. We trained both Surformer v1 (using
structured features) and Multimodal CNN (using raw images) to examine the
impact of feature-based versus image-based multimodal learning on
classification accuracy and computational efficiency. The results showed that
Surformer v1 achieved 99.4% accuracy with an inference time of 0.77 ms, while
the Multimodal CNN achieved slightly higher accuracy but required significantly
more inference time. These findings suggest Surformer v1 offers a compelling
balance between accuracy, efficiency, and computational cost for surface
material recognition.

</details>


### [21] [ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos](https://arxiv.org/abs/2508.06570)
*Mohammad Zia Ur Rehman,Anukriti Bhatnagar,Omkar Kabde,Shubhi Bansal,Nagendra Kumar*

Main category: cs.CV

TL;DR: 提出一个名为ImpliHateVid的新视频数据集，用于隐性仇恨言论检测。同时设计了一种两阶段对比学习框架，结合多模态特征，提升仇恨言论检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究集中于文字和图像的仇恨言论检测，视频范畴的研究不足，因此需要专门数据集和方法。

Method: 构建ImpliHateVid视频数据集，并提出两阶段对比学习框架，第一阶段训练音频、文本和图像的模态编码器，第二阶段通过融合多模态特征进行交叉编码优化；加入情感、情绪和字幕特征以增强检测能力。

Result: 新方法在ImpliHateVid和HateMM数据集上验证了其多模态对比学习在视频仇恨内容检测中的有效性，并突出了数据集的重要性。

Conclusion: 研究推动了视频仇恨言论检测领域的发展，通过提出数据集和增强型框架，为相关任务提供了重要资源和方法支持。

Abstract: The existing research has primarily focused on text and image-based hate
speech detection, video-based approaches remain underexplored. In this work, we
introduce a novel dataset, ImpliHateVid, specifically curated for implicit hate
speech detection in videos. ImpliHateVid consists of 2,009 videos comprising
509 implicit hate videos, 500 explicit hate videos, and 1,000 non-hate videos,
making it one of the first large-scale video datasets dedicated to implicit
hate detection. We also propose a novel two-stage contrastive learning
framework for hate speech detection in videos. In the first stage, we train
modality-specific encoders for audio, text, and image using contrastive loss by
concatenating features from the three encoders. In the second stage, we train
cross-encoders using contrastive learning to refine multimodal representations.
Additionally, we incorporate sentiment, emotion, and caption-based features to
enhance implicit hate detection. We evaluate our method on two datasets,
ImpliHateVid for implicit hate speech detection and another dataset for general
hate speech detection in videos, HateMM dataset, demonstrating the
effectiveness of the proposed multimodal contrastive learning for hateful
content detection in videos and the significance of our dataset.

</details>


### [22] [ContextGuard-LVLM: Enhancing News Veracity through Fine-grained Cross-modal Contextual Consistency Verification](https://arxiv.org/abs/2508.06623)
*Sihan Ma,Qiming Wu,Ruotong Jiang,Frank Burns*

Main category: cs.CV

TL;DR: 研究提出了一种新的框架ContextGuard-LVLM，用于检测视觉与文本信息之间的细致上下文一致性，特别是复杂的逻辑推理和细微的上下文理解任务，实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着数字新闻媒体的激增，需要更有效的方法来验证视觉与文本信息之间的细粒度一致性，现有方法在捕捉更深层次的跨模态上下文一致性问题上表现不足。

Method: 提出了一个基于视觉-语言大模型（LVLMs）并结合多阶段上下文推理机制的新框架ContextGuard-LVLM，采用了强化和对抗学习策略，能够识别细微的上下文不一致问题。

Result: 通过对三个增强的数据集进行实验，ContextGuard-LVLM在几乎所有细粒度一致性任务中优于现有零样本LVLM基线方法（如InstructBLIP和LLaVA 1.5），展现出在复杂逻辑推理和细微上下文理解任务中的显著提升。

Conclusion: 该模型在处理上下文脱节问题上展现了更强的鲁棒性，并在人类专家评估中的一致率更高，验证了其在复杂上下文理解中的有效性。

Abstract: The proliferation of digital news media necessitates robust methods for
verifying content veracity, particularly regarding the consistency between
visual and textual information. Traditional approaches often fall short in
addressing the fine-grained cross-modal contextual consistency (FCCC) problem,
which encompasses deeper alignment of visual narrative, emotional tone, and
background information with text, beyond mere entity matching. To address this,
we propose ContextGuard-LVLM, a novel framework built upon advanced
Vision-Language Large Models (LVLMs) and integrating a multi-stage contextual
reasoning mechanism. Our model is uniquely enhanced through reinforced or
adversarial learning paradigms, enabling it to detect subtle contextual
misalignments that evade zero-shot baselines. We extend and augment three
established datasets (TamperedNews-Ent, News400-Ent, MMG-Ent) with new
fine-grained contextual annotations, including "contextual sentiment," "visual
narrative theme," and "scene-event logical coherence," and introduce a
comprehensive CTXT (Contextual Coherence) entity type. Extensive experiments
demonstrate that ContextGuard-LVLM consistently outperforms state-of-the-art
zero-shot LVLM baselines (InstructBLIP and LLaVA 1.5) across nearly all
fine-grained consistency tasks, showing significant improvements in complex
logical reasoning and nuanced contextual understanding. Furthermore, our model
exhibits superior robustness to subtle perturbations and a higher agreement
rate with human expert judgments on challenging samples, affirming its efficacy
in discerning sophisticated forms of context detachment.

</details>


### [23] [VL-MedGuide: A Visual-Linguistic Large Model for Intelligent and Explainable Skin Disease Auxiliary Diagnosis](https://arxiv.org/abs/2508.06624)
*Kexin Yu,Zihan Xu,Jialei Xie,Carter Adams*

Main category: cs.CV

TL;DR: 研究提出了VL-MedGuide框架，通过视觉-语言融合模型提升皮肤病诊断准确性，同时提供可解释性结果。


<details>
  <summary>Details</summary>
Motivation: 由于皮肤病诊断的视觉特征复杂且多样，现有模型在可解释性方面不足，难以满足临床需求。

Method: 研究设计了两阶段框架：多模态概念感知模块用于识别并描述皮肤病学视觉特征；可解释疾病推理模块结合视觉信息与语言描述进行诊断，并生成透明的诊断原因。

Result: 在Derm7pt数据集上的实验表现超过了现有基线（例如，疾病诊断达到83.55%的BACC，概念检测达到76.10%的BACC）；另外，人类评估验证了其结果的清晰性、完整性和可信度。

Conclusion: VL-MedGuide框架提供了新方法，将AI模型性能和临床实用性结合，为皮肤病诊断提供可操作且可解释的洞察。

Abstract: Accurate diagnosis of skin diseases remains a significant challenge due to
the complex and diverse visual features present in dermatoscopic images, often
compounded by a lack of interpretability in existing purely visual diagnostic
models. To address these limitations, this study introduces VL-MedGuide
(Visual-Linguistic Medical Guide), a novel framework leveraging the powerful
multi-modal understanding and reasoning capabilities of Visual-Language Large
Models (LVLMs) for intelligent and inherently interpretable auxiliary diagnosis
of skin conditions. VL-MedGuide operates in two interconnected stages: a
Multi-modal Concept Perception Module, which identifies and linguistically
describes dermatologically relevant visual features through sophisticated
prompt engineering, and an Explainable Disease Reasoning Module, which
integrates these concepts with raw visual information via Chain-of-Thought
prompting to provide precise disease diagnoses alongside transparent
rationales. Comprehensive experiments on the Derm7pt dataset demonstrate that
VL-MedGuide achieves state-of-the-art performance in both disease diagnosis
(83.55% BACC, 80.12% F1) and concept detection (76.10% BACC, 67.45% F1),
surpassing existing baselines. Furthermore, human evaluations confirm the high
clarity, completeness, and trustworthiness of its generated explanations,
bridging the gap between AI performance and clinical utility by offering
actionable, explainable insights for dermatological practice.

</details>


### [24] [CycleDiff: Cycle Diffusion Models for Unpaired Image-to-image Translation](https://arxiv.org/abs/2508.06625)
*Shilong Zou,Yuhang Huang,Renjiao Yi,Chenyang Zhu,Kai Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的跨域图像翻译方法，结合联合学习框架实现翻译优化和性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于GAN的方法在图像翻译中对数据分布的建模能力有限，且扩散过程与翻译过程难以有效对齐。

Method: 提出了联合学习框架，将扩散过程与翻译过程对齐；并设计时间依赖翻译网络，增强翻译的复杂映射能力。

Result: 在RGB$\leftrightarrow$RGB及多种跨模态任务上性能优于现有技术，显示出更高生成质量和结构一致性。

Conclusion: 通过联合学习提升了扩散与翻译过程的全局优化能力，改进了图像生成的保真度和一致性。

Abstract: We introduce a diffusion-based cross-domain image translator in the absence
of paired training data. Unlike GAN-based methods, our approach integrates
diffusion models to learn the image translation process, allowing for more
coverable modeling of the data distribution and performance improvement of the
cross-domain translation. However, incorporating the translation process within
the diffusion process is still challenging since the two processes are not
aligned exactly, i.e., the diffusion process is applied to the noisy signal
while the translation process is conducted on the clean signal. As a result,
recent diffusion-based studies employ separate training or shallow integration
to learn the two processes, yet this may cause the local minimal of the
translation optimization, constraining the effectiveness of diffusion models.
To address the problem, we propose a novel joint learning framework that aligns
the diffusion and the translation process, thereby improving the global
optimality. Specifically, we propose to extract the image components with
diffusion models to represent the clean signal and employ the translation
process with the image components, enabling an end-to-end joint learning
manner. On the other hand, we introduce a time-dependent translation network to
learn the complex translation mapping, resulting in effective translation
learning and significant performance improvement. Benefiting from the design of
joint learning, our method enables global optimization of both processes,
enhancing the optimality and achieving improved fidelity and structural
consistency. We have conducted extensive experiments on RGB$\leftrightarrow$RGB
and diverse cross-modality translation tasks including
RGB$\leftrightarrow$Edge, RGB$\leftrightarrow$Semantics and
RGB$\leftrightarrow$Depth, showcasing better generative performances than the
state of the arts.

</details>


### [25] [CoDe-NeRF: Neural Rendering via Dynamic Coefficient Decomposition](https://arxiv.org/abs/2508.06632)
*Wenpeng Xing,Jie Chen,Zaifeng Yang,Tiancheng Zhao,Gaolei Li,Changting Lin,Yike Guo,Meng Han*

Main category: cs.CV

TL;DR: 本文提出了一种基于动态系数分解的神经渲染框架，用于改进视角依赖外观的建模，主要解决NeRF在处理复杂镜面反射与高光时存在的模糊问题。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF方法在处理复杂镜面反射与高光中可能存在模糊问题，或者在使用物理基础反演渲染时遇到优化不稳定性，因此需要一种更灵活高效的方法来处理复杂外观建模。

Method: 通过动态系数分解，将复杂外观分解为一个静态神经基（编码固有材料属性）和由系数网络生成的一组动态系数，再由动态辐射积分器整合生成最终的辐射场。

Result: 实验结果表明，在多个具有挑战性的基准测试中，该方法相较于现有技术能够生成更加清晰且逼真的镜面高光效果。

Conclusion: 动态系数分解提供了一种灵活高效的复杂外观建模新方向，可提升神经场景表达的效果和精度。

Abstract: Neural Radiance Fields (NeRF) have shown impressive performance in novel view
synthesis, but challenges remain in rendering scenes with complex specular
reflections and highlights. Existing approaches may produce blurry reflections
due to entanglement between lighting and material properties, or encounter
optimization instability when relying on physically-based inverse rendering. In
this work, we present a neural rendering framework based on dynamic coefficient
decomposition, aiming to improve the modeling of view-dependent appearance. Our
approach decomposes complex appearance into a shared, static neural basis that
encodes intrinsic material properties, and a set of dynamic coefficients
generated by a Coefficient Network conditioned on view and illumination. A
Dynamic Radiance Integrator then combines these components to synthesize the
final radiance. Experimental results on several challenging benchmarks suggest
that our method can produce sharper and more realistic specular highlights
compared to existing techniques. We hope that this decomposition paradigm can
provide a flexible and effective direction for modeling complex appearance in
neural scene representations.

</details>


### [26] [Rethinking Key-frame-based Micro-expression Recognition: A Robust and Accurate Framework Against Key-frame Errors](https://arxiv.org/abs/2508.06640)
*Zheyuan Zhang,Weihao Tang,Hong Chen*

Main category: cs.CV

TL;DR: 这篇论文提出了一种名为CausalNet的新框架，用于改进在关键帧索引误差条件下的微表情识别，同时保持识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法虽然改进了基于关键帧索引的微表情识别，但在实际应用中难以获得准确的关键帧索引，而本研究旨在解决这一痛点。

Method: 该方法以整个微表情序列作为输入，并提出两个模块：Causal Motion Position Learning Module (CMPLM) 定位关键动作区域，Causal Attention Block (CAB) 学习肌肉收缩与放松的因果关系。

Result: 实验表明，CausalNet 在不同级别的关键帧误差下表现出了强鲁棒性，并在多个标准数据集上超过了最先进的方法。

Conclusion: CausalNet 在处理关键帧索引误差方面表现出色，同时具有高精度和实际应用潜力。代码已公开以供进一步研究。

Abstract: Micro-expression recognition (MER) is a highly challenging task in affective
computing. With the reduced-sized micro-expression (ME) input that contains key
information based on key-frame indexes, key-frame-based methods have
significantly improved the performance of MER. However, most of these methods
focus on improving the performance with relatively accurate key-frame indexes,
while ignoring the difficulty of obtaining accurate key-frame indexes and the
objective existence of key-frame index errors, which impedes them from moving
towards practical applications. In this paper, we propose CausalNet, a novel
framework to achieve robust MER facing key-frame index errors while maintaining
accurate recognition. To enhance robustness, CausalNet takes the representation
of the entire ME sequence as the input. To address the information redundancy
brought by the complete ME range input and maintain accurate recognition,
first, the Causal Motion Position Learning Module (CMPLM) is proposed to help
the model locate the muscle movement areas related to Action Units (AUs),
thereby reducing the attention to other redundant areas. Second, the Causal
Attention Block (CAB) is proposed to deeply learn the causal relationships
between the muscle contraction and relaxation movements in MEs. Empirical
experiments have demonstrated that on popular ME benchmarks, the CausalNet has
achieved robust MER under different levels of key-frame index noise. Meanwhile,
it has surpassed state-of-the-art (SOTA) methods on several standard MER
benchmarks when using the provided annotated key-frames. Code is available at
https://github.com/tony19980810/CausalNet.

</details>


### [27] [Towards Robust Red-Green Watermarking for Autoregressive Image Generators](https://arxiv.org/abs/2508.06656)
*Denis Lukovnikov,Andreas Müller,Erwin Quiring,Asja Fischer*

Main category: cs.CV

TL;DR: 本文探讨了在自动回归图像生成模型中应用生成内水印的可能性，提出了基于视觉标记聚类的新水印方法，增强了水印对图像干扰和再生成攻击的鲁棒性，同时保持了图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有研究已探索生成内水印用于隐扩散模型的应用，但尚未涉及自动回归图像生成模型。在此背景下，探讨是否可通过生成内水印提升自动回归图像模型的可追踪性具有重要意义。

Method: 本文提出两种基于视觉标记聚类的生成内水印方法：一种是无需训练的基于聚类查找表的方法；另一种是通过微调VAE编码器直接从受扰图像中预测标记聚类。此外，提出了标记聚类分类器以进一步增强水印的检测效果。

Result: 实验表明，所提方法在抗干扰和抗再生成攻击方面的表现优于现有方法，同时保持了高图像质量，并提供与轻量级方法相当的快速验证速度。

Conclusion: 基于视觉标记聚类的水印方法有效提升了生成内水印的鲁棒性和检测性能，为自动回归图像模型引入了一种高效且可扩展的水印解决方案。

Abstract: In-generation watermarking for detecting and attributing generated content
has recently been explored for latent diffusion models (LDMs), demonstrating
high robustness. However, the use of in-generation watermarks in autoregressive
(AR) image models has not been explored yet. AR models generate images by
autoregressively predicting a sequence of visual tokens that are then decoded
into pixels using a vector-quantized decoder. Inspired by red-green watermarks
for large language models, we examine token-level watermarking schemes that
bias the next-token prediction based on prior tokens. We find that a direct
transfer of these schemes works in principle, but the detectability of the
watermarks decreases considerably under common image perturbations. As a
remedy, we propose two novel watermarking methods that rely on visual token
clustering to assign similar tokens to the same set. Firstly, we investigate a
training-free approach that relies on a cluster lookup table, and secondly, we
finetune VAE encoders to predict token clusters directly from perturbed images.
Overall, our experiments show that cluster-level watermarks improve robustness
against perturbations and regeneration attacks while preserving image quality.
Cluster classification further boosts watermark detectability, outperforming a
set of baselines. Moreover, our methods offer fast verification runtime,
comparable to lightweight post-hoc watermarking methods.

</details>


### [28] [Learning More by Seeing Less: Line Drawing Pretraining for Efficient, Transferable, and Human-Aligned Vision](https://arxiv.org/abs/2508.06696)
*Tianqin Li,George Liu,Tai Sing Lee*

Main category: cs.CV

TL;DR: 该论文提出利用线条图像进行结构优先的预训练模式，以增强计算机视觉模型的高效性和通用性，并强调这种方法在人类视觉和计算机视觉中的可比性和优势。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉识别系统依赖于冗余的视觉输入，而人类能够通过简约的线条表示理解视觉内容，因此需要探索更高效的、基于结构的视觉学习方法。

Method: 提出利用线条图像进行预训练，以增强模型的形状偏差、注意力集中和数据效率，相比颜色监督的训练方法，传递模型的结构性知识变得更紧凑。

Result: 实验表明，使用线条图像预训练的模型在分类、检测和分割任务中表现更佳，并具有更低的本质维度。同时，与学生模型的知识蒸馏结合，效果较从传统方法训练的教师模型蒸馏显著更优。

Conclusion: 基于线条图像的预训练方法提供了一种高效、通用且对人类视觉偏好对齐的视觉学习策略，有助于开发更稳健和更适应性强的视觉系统。

Abstract: Despite remarkable progress in computer vision, modern recognition systems
remain limited by their dependence on rich, redundant visual inputs. In
contrast, humans can effortlessly understand sparse, minimal representations
like line drawings - suggesting that structure, rather than appearance,
underlies efficient visual understanding. In this work, we propose using line
drawings as a structure-first pretraining modality to induce more compact and
generalizable visual representations. We show that models pretrained on line
drawings develop stronger shape bias, more focused attention, and greater data
efficiency across classification, detection, and segmentation tasks. Notably,
these models also exhibit lower intrinsic dimensionality, requiring
significantly fewer principal components to capture representational variance -
echoing the similar observation in low dimensional efficient representation in
the brain. Beyond performance improvements, line drawing pretraining produces
more compressible representations, enabling better distillation into
lightweight student models. Students distilled from line-pretrained teachers
consistently outperform those trained from color-supervised teachers,
highlighting the benefits of structurally compact knowledge. Finally, we
demonstrate that the pretraining with line-drawing can also be extended to
unsupervised setting via our proposed method "learning to draw". Together, our
results support the view that structure-first visual learning fosters
efficiency, generalization, and human-aligned inductive biases - offering a
simple yet powerful strategy for building more robust and adaptable vision
systems.

</details>


### [29] [MMFformer: Multimodal Fusion Transformer Network for Depression Detection](https://arxiv.org/abs/2508.06701)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Hamdi Altaheri,Lobna Nassar,Fakhri Karray*

Main category: cs.CV

TL;DR: 研究提出了MMFformer模型，用于基于社交媒体内容进行抑郁症的多模态检测，性能优于当前方法。


<details>
  <summary>Details</summary>
Motivation: 抑郁症的早期发现对患者的健康和生活质量至关重要，但基于临床访谈的主观评估往往难以准确检测。利用社交媒体数据进行抑郁症早期诊断是近年来的研究重点。

Method: 提出MMFformer网络，该网络通过变换器捕获视频中的空间特征和音频中的时间动态信息，并结合晚期和中间特征融合策略以挖掘多模态信息间的最优相关性。

Result: 在两个大规模数据集上实验显示，MMFformer在D-Vlog数据集的F1-Score提高了13.92%，在LMVD数据集上提高了7.74%。

Conclusion: MMFformer有效解决了当前多模态抑郁症检测中的挑战，其性能显著优于其他先进方法，代码已公开发布。

Abstract: Depression is a serious mental health illness that significantly affects an
individual's well-being and quality of life, making early detection crucial for
adequate care and treatment. Detecting depression is often difficult, as it is
based primarily on subjective evaluations during clinical interviews. Hence,
the early diagnosis of depression, thanks to the content of social networks,
has become a prominent research area. The extensive and diverse nature of
user-generated information poses a significant challenge, limiting the accurate
extraction of relevant temporal information and the effective fusion of data
across multiple modalities. This paper introduces MMFformer, a multimodal
depression detection network designed to retrieve depressive spatio-temporal
high-level patterns from multimodal social media information. The transformer
network with residual connections captures spatial features from videos, and a
transformer encoder is exploited to design important temporal dynamics in
audio. Moreover, the fusion architecture fused the extracted features through
late and intermediate fusion strategies to find out the most relevant
intermodal correlations among them. Finally, the proposed network is assessed
on two large-scale depression detection datasets, and the results clearly
reveal that it surpasses existing state-of-the-art approaches, improving the
F1-Score by 13.92% for D-Vlog dataset and 7.74% for LMVD dataset. The code is
made available publicly at
https://github.com/rezwanh001/Large-Scale-Multimodal-Depression-Detection.

</details>


### [30] [Fourier Optics and Deep Learning Methods for Fast 3D Reconstruction in Digital Holography](https://arxiv.org/abs/2508.06703)
*Justin London*

Main category: cs.CV

TL;DR: 这篇论文探讨了利用计算机生成全息图（CGH）技术合成数字全息图，提出了一种高效快速的框架，并优化了生成算法和去除噪声的过程。


<details>
  <summary>Details</summary>
Motivation: 当前的CGH方法虽有潜力，但在生成效率、质量及去噪优化方面存在改进空间。研究目标为发展更高效的CGH合成框架。

Method: 使用点云和MRI数据重建体积目标，并采用非凸傅里叶光学优化算法生成全息图，包括交替投影、SGD和准牛顿方法，对比分析这些算法与基于深度学习的HoloNet性能，并引入2D中值滤波去除多余伪影和噪声。

Result: 算法在计算性能和重建质量（MSE、RMSE、PSNR）上有改进，通过2D中值滤波显著减少伪影和噪声。

Conclusion: 提出的框架通过结合传统优化方法和去噪处理，展示了更高效和高质量的CGH生成潜力。

Abstract: Computer-generated holography (CGH) is a promising method that modulates
user-defined waveforms with digital holograms. An efficient and fast pipeline
framework is proposed to synthesize CGH using initial point cloud and MRI data.
This input data is reconstructed into volumetric objects that are then input
into non-convex Fourier optics optimization algorithms for phase-only hologram
(POH) and complex-hologram (CH) generation using alternating projection, SGD,
and quasi-Netwton methods. Comparison of reconstruction performance of these
algorithms as measured by MSE, RMSE, and PSNR is analyzed as well as to HoloNet
deep learning CGH. Performance metrics are shown to be improved by using 2D
median filtering to remove artifacts and speckled noise during optimization.

</details>


### [31] [Restage4D: Reanimating Deformable 3D Reconstruction from a Single Video](https://arxiv.org/abs/2508.06715)
*Jixuan He,Chieh Hubert Lin,Lu Qi,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 该研究提出了Restage4D，一种基于视频条件的4D重演系统，能够重建和优化变形3D场景中的几何结构与运动质量。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型在捕捉4D场景中的物理真实感和动态性方面存在不足，而真实视频能够提供物理基础的几何和运动线索。

Method: 使用视频倒带训练策略在实际基础视频与合成驱动视频之间建立共享运动表示。同时设计了感知遮挡的刚性损失及消遮挡回溯机制来提升几何和结构一致性。

Result: 在DAVIS和PointOdyssey数据集上表现出了几何一致性、运动质量和3D跟踪性能的提升。

Conclusion: 该方法在保持变形结构的同时修复了生成模型中出现的错误，展示了真实视频运动先验在4D重演任务中的潜力。

Abstract: Creating deformable 3D content has gained increasing attention with the rise
of text-to-image and image-to-video generative models. While these models
provide rich semantic priors for appearance, they struggle to capture the
physical realism and motion dynamics needed for authentic 4D scene synthesis.
In contrast, real-world videos can provide physically grounded geometry and
articulation cues that are difficult to hallucinate. One question is raised:
\textit{Can we generate physically consistent 4D content by leveraging the
motion priors of the real-world video}? In this work, we explore the task of
reanimating deformable 3D scenes from a single video, using the original
sequence as a supervisory signal to correct artifacts from synthetic motion. We
introduce \textbf{Restage4D}, a geometry-preserving pipeline for
video-conditioned 4D restaging. Our approach uses a video-rewinding training
strategy to temporally bridge a real base video and a synthetic driving video
via a shared motion representation. We further incorporate an occlusion-aware
rigidity loss and a disocclusion backtracing mechanism to improve structural
and geometry consistency under challenging motion. We validate Restage4D on
DAVIS and PointOdyssey, demonstrating improved geometry consistency, motion
quality, and 3D tracking performance. Our method not only preserves deformable
structure under novel motion, but also automatically corrects errors introduced
by generative models, revealing the potential of video prior in 4D restaging
task. Source code and trained models will be released.

</details>


### [32] [FoundBioNet: A Foundation-Based Model for IDH Genotyping of Glioma from Multi-Parametric MRI](https://arxiv.org/abs/2508.06756)
*Somayeh Farahani,Marjaneh Hejazi,Antonio Di Ieva,Sidong Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为FoundBioNet的基础模型，基于SWIN-UNETR架构，用于通过多参数MRI无创预测IDH突变状态，表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前IDH突变的检测主要依赖侵入性组织采样，存在难以捕捉肿瘤空间异质性的局限性，而稀缺的标注数据限制了深度学习模型的性能。

Method: 提出了一种Foundation-based Biomarker Network (FoundBioNet)基础模型，采用SWIN-UNETR架构，同时结合两个关键模块：肿瘤感知特征编码（TAFE）和跨模态差异（CMD）。

Result: 模型在EGD、TCGA、Ivy GAP、RHUH和UPenn的独立测试集上分别达到了90.58%、88.08%、65.41%和80.31%的AUC，明显优于基线方法（p ≤ 0.05）。

Conclusion: FoundBioNet通过结合大规模预训练和任务特定的微调，提升了IDH突变预测的准确性和解释性，为个性化患者护理提供了潜力。

Abstract: Accurate, noninvasive detection of isocitrate dehydrogenase (IDH) mutation is
essential for effective glioma management. Traditional methods rely on invasive
tissue sampling, which may fail to capture a tumor's spatial heterogeneity.
While deep learning models have shown promise in molecular profiling, their
performance is often limited by scarce annotated data. In contrast, foundation
deep learning models offer a more generalizable approach for glioma imaging
biomarkers. We propose a Foundation-based Biomarker Network (FoundBioNet) that
utilizes a SWIN-UNETR-based architecture to noninvasively predict IDH mutation
status from multi-parametric MRI. Two key modules are incorporated: Tumor-Aware
Feature Encoding (TAFE) for extracting multi-scale, tumor-focused features, and
Cross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch
signals associated with IDH mutation. The model was trained and validated on a
diverse, multi-center cohort of 1705 glioma patients from six public datasets.
Our model achieved AUCs of 90.58%, 88.08%, 65.41%, and 80.31% on independent
test sets from EGD, TCGA, Ivy GAP, RHUH, and UPenn, consistently outperforming
baseline approaches (p <= 0.05). Ablation studies confirmed that both the TAFE
and CMD modules are essential for improving predictive accuracy. By integrating
large-scale pretraining and task-specific fine-tuning, FoundBioNet enables
generalizable glioma characterization. This approach enhances diagnostic
accuracy and interpretability, with the potential to enable more personalized
patient care.

</details>


### [33] [VOccl3D: A Video Benchmark Dataset for 3D Human Pose and Shape Estimation under real Occlusions](https://arxiv.org/abs/2508.06757)
*Yash Garg,Saketh Bachu,Arindam Dutta,Rohit Lal,Sarosij Bose,Calvin-Khang Ta,M. Salman Asif,Amit Roy-Chowdhury*

Main category: cs.CV

TL;DR: 论文提出了一个新的数据集VOccl3D，用于评估和改进在遮挡场景下的3D人体姿态和形状估计方法，提供了更现实的基准环境。


<details>
  <summary>Details</summary>
Motivation: 当前的HPS方法在复杂姿态或显著遮挡场景下表现有限，现有数据集的遮挡场景不够真实，需要一个更真实的遮挡数据集来弥补这一差距。

Method: 采用先进的计算机图形渲染技术构建VOccl3D数据集，并在此数据集上微调现有HPS方法CLIFF和BEDLAM-CLIFF，同时也微调YOLO11以提升遮挡下的检测性能。

Result: 在多个公开数据集以及VOccl3D测试集上，微调后的方法显著提升了定性和定量表现，也改善了遮挡场景下的人体检测结果。

Conclusion: VOccl3D数据集为遮挡场景处理方法提供了更真实的基准和研究基础，促进该领域技术的进一步发展。

Abstract: Human pose and shape (HPS) estimation methods have been extensively studied,
with many demonstrating high zero-shot performance on in-the-wild images and
videos. However, these methods often struggle in challenging scenarios
involving complex human poses or significant occlusions. Although some studies
address 3D human pose estimation under occlusion, they typically evaluate
performance on datasets that lack realistic or substantial occlusions, e.g.,
most existing datasets introduce occlusions with random patches over the human
or clipart-style overlays, which may not reflect real-world challenges. To
bridge this gap in realistic occlusion datasets, we introduce a novel benchmark
dataset, VOccl3D, a Video-based human Occlusion dataset with 3D body pose and
shape annotations. Inspired by works such as AGORA and BEDLAM, we constructed
this dataset using advanced computer graphics rendering techniques,
incorporating diverse real-world occlusion scenarios, clothing textures, and
human motions. Additionally, we fine-tuned recent HPS methods, CLIFF and
BEDLAM-CLIFF, on our dataset, demonstrating significant qualitative and
quantitative improvements across multiple public datasets, as well as on the
test split of our dataset, while comparing its performance with other
state-of-the-art methods. Furthermore, we leveraged our dataset to enhance
human detection performance under occlusion by fine-tuning an existing object
detector, YOLO11, thus leading to a robust end-to-end HPS estimation system
under occlusions. Overall, this dataset serves as a valuable resource for
future research aimed at benchmarking methods designed to handle occlusions,
offering a more realistic alternative to existing occlusion datasets. See the
Project page for code and dataset:https://yashgarg98.github.io/VOccl3D-dataset/

</details>


### [34] [SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding](https://arxiv.org/abs/2508.06763)
*Zihao Sheng,Zilin Huang,Yen-Jung Chen,Yansong Qu,Yuhao Luo,Yue Leng,Sikai Chen*

Main category: cs.CV

TL;DR: SafePLUG是一种新框架，增强了多模态大语言模型（MLLMs）在精细交通事故分析中的能力，包括像素级理解和时间定位。


<details>
  <summary>Details</summary>
Motivation: 目前的MLLMs在交通事故中主要侧重于图像或视频级理解，难以处理精细的视觉细节和局部场景组件，限制了其在复杂事故场景中的应用。

Method: 提出SafePLUG框架，支持任意形状的视觉提示进行区域感知式问答，以及基于语言指令的像素级分割，同时识别事故场景中的时序事件。此外，构建了一个包含多模态问答对的新数据集，提供像素级注释和时间事件边界。

Result: SafePLUG在区域问答、像素分割、时间事件定位和事故理解等任务上表现出色。

Conclusion: SafePLUG为复杂交通场景的精细理解奠定了基础，可提升驾驶安全性并加强智能交通系统中的情境感知。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress
across a range of vision-language tasks and demonstrate strong potential for
traffic accident understanding. However, existing MLLMs in this domain
primarily focus on coarse-grained image-level or video-level comprehension and
often struggle to handle fine-grained visual details or localized scene
components, limiting their applicability in complex accident scenarios. To
address these limitations, we propose SafePLUG, a novel framework that empowers
MLLMs with both Pixel-Level Understanding and temporal Grounding for
comprehensive traffic accident analysis. SafePLUG supports both
arbitrary-shaped visual prompts for region-aware question answering and
pixel-level segmentation based on language instructions, while also enabling
the recognition of temporally anchored events in traffic accident scenarios. To
advance the development of MLLMs for traffic accident understanding, we curate
a new dataset containing multimodal question-answer pairs centered on diverse
accident scenarios, with detailed pixel-level annotations and temporal event
boundaries. Experimental results show that SafePLUG achieves strong performance
on multiple tasks, including region-based question answering, pixel-level
segmentation, temporal event localization, and accident event understanding.
These capabilities lay a foundation for fine-grained understanding of complex
traffic scenes, with the potential to improve driving safety and enhance
situational awareness in smart transportation systems. The code, dataset, and
model checkpoints will be made publicly available at:
https://zihaosheng.github.io/SafePLUG

</details>


### [35] [DiffUS: Differentiable Ultrasound Rendering from Volumetric Imaging](https://arxiv.org/abs/2508.06768)
*Noe Bertramo,Gabriel Duguey,Vivek Gopalakrishnan*

Main category: cs.CV

TL;DR: 提出了一种名为DiffUS的基于物理的可微超声渲染器，用于从MRI/CT数据合成逼真的B超图像，解决术中超声成像与术前规划的对齐问题。


<details>
  <summary>Details</summary>
Motivation: 术中超声成像常用于实时手术指导，但因噪声、伪影及与术前高分辨率MRI/CT对齐困难，其解释具有挑战性。

Method: 提出了一个基于物理的可微渲染器DiffUS，运用机器学习将MRI转换为声阻抗数据，通过射线追踪和波传播仿真生成逼真的B超图像，并在PyTorch中实现了可用于梯度优化的张量操作。

Result: 在ReMIND数据集上的评估显示，DiffUS能从脑MRI生成解剖上准确的超声图像。

Conclusion: DiffUS能有效连接术前规划和术中引导，为高效的医学图像注册与重建提供支持。

Abstract: Intraoperative ultrasound imaging provides real-time guidance during numerous
surgical procedures, but its interpretation is complicated by noise, artifacts,
and poor alignment with high-resolution preoperative MRI/CT scans. To bridge
the gap between reoperative planning and intraoperative guidance, we present
DiffUS, a physics-based, differentiable ultrasound renderer that synthesizes
realistic B-mode images from volumetric imaging. DiffUS first converts MRI 3D
scans into acoustic impedance volumes using a machine learning approach. Next,
we simulate ultrasound beam propagation using ray tracing with coupled
reflection-transmission equations. DiffUS formulates wave propagation as a
sparse linear system that captures multiple internal reflections. Finally, we
reconstruct B-mode images via depth-resolved echo extraction across fan-shaped
acquisition geometry, incorporating realistic artifacts including speckle noise
and depth-dependent degradation. DiffUS is entirely implemented as
differentiable tensor operations in PyTorch, enabling gradient-based
optimization for downstream applications such as slice-to-volume registration
and volumetric reconstruction. Evaluation on the ReMIND dataset demonstrates
DiffUS's ability to generate anatomically accurate ultrasound images from brain
MRI data.

</details>


### [36] [Edge Detection for Organ Boundaries via Top Down Refinement and SubPixel Upsampling](https://arxiv.org/abs/2508.06805)
*Aarav Mehta,Priya Deshmukh,Vikram Singh,Siddharth Malhotra,Krishnan Menon Iyer,Tanvi Iyer*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度卷积网络的医疗图像清晰边缘检测方法，通过自上而下的反向细化架构，提高了器官边界的精确定位，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的深度卷积网络在边缘检测上已接近自然图像上的人类表现，但在医疗图像中因需要毫米级精度，其边缘定位仍欠精确，亟需改进。

Method: 该方法设计了一种自上而下的反向细化路径，将高层语义特征与低层细节融合；并通过结合二维切片细化和轻量级三维上下文聚合的方式处理各向异性体积数据，以保持计算效率。

Result: 在多个CT和MRI数据集上测试，结果表明在边界F分数和Hausdorff距离等严格标准下，优于基准卷积网络和其他医疗边缘/轮廓检测方法。同时在器官分割、图像配准、以及邻近器官界面病变的描绘上表现优异。

Conclusion: 本方法能够生成临床价值高、定位精确的器官边缘，显著提升常见医疗图像任务的效果。

Abstract: Accurate localization of organ boundaries is critical in medical imaging for
segmentation, registration, surgical planning, and radiotherapy. While deep
convolutional networks (ConvNets) have advanced general-purpose edge detection
to near-human performance on natural images, their outputs often lack precise
localization, a limitation that is particularly harmful in medical applications
where millimeter-level accuracy is required. Building on a systematic analysis
of ConvNet edge outputs, we propose a medically focused crisp edge detector
that adapts a novel top-down backward refinement architecture to medical images
(2D and volumetric). Our method progressively upsamples and fuses high-level
semantic features with fine-grained low-level cues through a backward
refinement pathway, producing high-resolution, well-localized organ boundaries.
We further extend the design to handle anisotropic volumes by combining 2D
slice-wise refinement with light 3D context aggregation to retain computational
efficiency. Evaluations on several CT and MRI organ datasets demonstrate
substantially improved boundary localization under strict criteria (boundary
F-measure, Hausdorff distance) compared to baseline ConvNet detectors and
contemporary medical edge/contour methods. Importantly, integrating our crisp
edge maps into downstream pipelines yields consistent gains in organ
segmentation (higher Dice scores, lower boundary errors), more accurate image
registration, and improved delineation of lesions near organ interfaces. The
proposed approach produces clinically valuable, crisp organ edges that
materially enhance common medical-imaging tasks.

</details>


### [37] [DualResolution Residual Architecture with Artifact Suppression for Melanocytic Lesion Segmentation](https://arxiv.org/abs/2508.06816)
*Vikram Singh,Kabir Malhotra,Rohan Desai,Ananya Shankaracharya,Priyadarshini Chatterjee,Krishnan Menon Iyer*

Main category: cs.CV

TL;DR: 本文提出了一种基于ResNet的双分辨率架构，用于黑色素肿瘤的图像分割，显著提升了分割边界的精确性和临床相关的分割指标。


<details>
  <summary>Details</summary>
Motivation: 黑色素肿瘤的精准分割对于皮肤癌筛查和临床决策支持至关重要。然而，皮损图像的分割比自然场景图像更加复杂，因其涉及微妙的纹理和颜色变化、常见的伪影干扰以及对边界精准定位的强需求。

Method: 设计了一种结合全分辨率流和池化流的双分辨率架构，其中全分辨率流保留精细的边界信息，池化流整合多尺度上下文线索，并通过边界感知的残差连接和通道注意模块联合优化。此外，引入轻量化伪影抑制模块和多任务训练目标，包括Dice Tversky分割损失、显式边界损失以及特征稳定性的对比正则化。

Result: 在公开的皮肤镜图像基准测试中，所提出方法在边界附着度和临床相关的分割指标上显著优于标准的编码器-解码器结构基线。

Conclusion: 该方法无需复杂的后处理或预训练协议便可生成像素级精确的分割掩模，为自动化黑色素瘤评估系统提供了具有实际价值的构建模块。

Abstract: Accurate segmentation of melanocytic tumors in dermoscopic images is a
critical step for automated skin cancer screening and clinical decision
support. Unlike natural scene segmentation, lesion delineation must reconcile
subtle texture and color variations, frequent artifacts (hairs, rulers,
bubbles), and a strong need for precise boundary localization to support
downstream diagnosis. In this paper we introduce Our method, a novel ResNet
inspired dual resolution architecture specifically designed for melanocytic
tumor segmentation. Our method maintains a full resolution stream that
preserves fine grained boundary information while a complementary pooled stream
aggregates multi scale contextual cues for robust lesion recognition. The
streams are tightly coupled by boundary aware residual connections that inject
high frequency edge information into deep feature maps, and by a channel
attention module that adapts color and texture sensitivity to dermoscopic
appearance. To further address common imaging artifacts and the limited size of
clinical datasets, we propose a lightweight artifact suppression block and a
multi task training objective that combines a Dice Tversky segmentation loss
with an explicit boundary loss and a contrastive regularizer for feature
stability. The combined design yields pixel accurate masks without requiring
heavy post processing or complex pre training protocols. Extensive experiments
on public dermoscopic benchmarks demonstrate that Our method significantly
improves boundary adherence and clinically relevant segmentation metrics
compared to standard encoder decoder baselines, making it a practical building
block for automated melanoma assessment systems.

</details>


### [38] [VesselRW: Weakly Supervised Subcutaneous Vessel Segmentation via Learned Random Walk Propagation](https://arxiv.org/abs/2508.06819)
*Ayaan Nooruddin Siddiqui,Mahnoor Zaidi,Ayesha Nazneen Shahbaz,Priyadarshini Chatterjee,Krishnan Menon Iyer*

Main category: cs.CV

TL;DR: 本文提出了一种针对皮下血管分割的弱监督训练框架，基于稀疏标注，通过概率传播模型提升分割效果，并引入拓扑正则化改进连通性。


<details>
  <summary>Details</summary>
Motivation: 皮下血管分割受限于标注稀缺、昂贵，以及图像对比度低、噪声大的问题，提出解决方法以提升分割精度与实用性。

Method: 使用稀疏标注，通过可微随机漫步标签传播模型生成密集概率监督，同时结合不确定性加权损失避免过拟合。此外，引入拓扑正则化以增强中心线连通性并减少伪分支。

Result: 实验显示，相较于直接使用稀疏标注或传统伪标注方法，本文方法能更完整地生成血管地图，并对不确定性进行更优校正。

Conclusion: 该方法显著降低了标注负担，同时保留了临床相关的血管拓扑结构，提高了临床实用性。

Abstract: Accurate segmentation of subcutaneous vessels from clinical images is
hampered by scarce, expensive ground truth and by low contrast, noisy
appearance of vessels across patients and modalities. We present a novel weakly
supervised training framework tailored for subcutaneous vessel segmentation
that leverages inexpensive sparse annotations (e.g., centerline traces, dot
markers, or short scribbles). Sparse labels are expanded into dense,
probabilistic supervision via a differentiable random walk label propagation
model whose transition weights incorporate image driven vesselness cues and
tubular continuity priors. The propagation yields per-pixel hitting
probabilities together with calibrated uncertainty estimates; these are
incorporated into an uncertainty weighted loss to avoid over fitting to
ambiguous regions. Crucially, the label-propagator is learned jointly with a
CNN based segmentation predictor, enabling the system to discover vessel edges
and continuity constraints without explicit edge supervision. We further
introduce a topology aware regularizer that encourages centerline connectivity
and penalizes spurious branches, improving clinical usability. In experiments
on clinical subcutaneous imaging datasets, our method consistently outperforms
naive training on sparse labels and conventional dense pseudo-labeling,
producing more complete vascular maps and better calibrated uncertainty for
downstream decision making. The approach substantially reduces annotation
burden while preserving clinically relevant vessel topology.

</details>


### [39] [Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification](https://arxiv.org/abs/2508.06831)
*Taha Mustapha Nehdi,Nairouz Mrabah,Atif Belal,Marco Pedersoli,Eric Granger*

Main category: cs.CV

TL;DR: 本文提出了一种名为SAGE-reID的高效多源域自适应方法，用于行人再识别，能够在保持低计算成本的同时达到卓越性能。


<details>
  <summary>Details</summary>
Motivation: 当前多源域自适应方法在训练参数和计算成本方面存在瓶颈，同时需要源域数据，这限制了其在行人再识别任务中的广泛应用。

Method: 该方法分两步完成：首先通过源域无监督域自适应训练源域特定的低秩适配器（LoRA）；然后引入轻量级门控网络，通过动态分配合并权重实现LoRA专家的高效融合。

Result: 在Market-1501、DukeMTMC-reID和MSMT17三个基准数据集上取得优异表现，表现优于现有最优方法，且显著降低了计算和内存消耗。

Conclusion: SAGE-reID方法在行人再识别中的应用具有显著优势，能够在源域数据缺失的情况下进行多域适应，进一步解决了参数增长和过拟合问题。

Abstract: Adapting person re-identification (reID) models to new target environments
remains a challenging problem that is typically addressed using unsupervised
domain adaptation (UDA) methods. Recent works show that when labeled data
originates from several distinct sources (e.g., datasets and cameras),
considering each source separately and applying multi-source domain adaptation
(MSDA) typically yields higher accuracy and robustness compared to blending the
sources and performing conventional UDA. However, state-of-the-art MSDA methods
learn domain-specific backbone models or require access to source domain data
during adaptation, resulting in significant growth in training parameters and
computational cost. In this paper, a Source-free Adaptive Gated Experts
(SAGE-reID) method is introduced for person reID. Our SAGE-reID is a
cost-effective, source-free MSDA method that first trains individual
source-specific low-rank adapters (LoRA) through source-free UDA. Next, a
lightweight gating network is introduced and trained to dynamically assign
optimal merging weights for fusion of LoRA experts, enabling effective
cross-domain knowledge transfer. While the number of backbone parameters
remains constant across source domains, LoRA experts scale linearly but remain
negligible in size (<= 2% of the backbone), reducing both the memory
consumption and risk of overfitting. Extensive experiments conducted on three
challenging benchmarks: Market-1501, DukeMTMC-reID, and MSMT17 indicate that
SAGE-reID outperforms state-of-the-art methods while being computationally
efficient.

</details>


### [40] [Hybrid Machine Learning Framework for Predicting Geometric Deviations from 3D Surface Metrology](https://arxiv.org/abs/2508.06845)
*Hamidreza Samadi,Md Manjurul Ahsan,Shivakumar Raman*

Main category: cs.CV

TL;DR: 提出了一种利用3D扫描和混合机器学习模型预测制造组件几何偏差的方法，显著提高了预测精度，并揭示了制造参数和几何偏差之间的隐藏相关性。


<details>
  <summary>Details</summary>
Motivation: 尽管现代制造技术已有进展，但复杂几何形状的尺寸精度控制仍然是一个难题。

Method: 通过高分辨率3D扫描收集不同批次组件的表面数据，并结合卷积神经网络（CNN）提取特征，以及梯度提升决策树（GBDT）进行预测建模。

Result: 预测精度达到了0.012 mm（95%置信水平），相较传统统计过程控制方法提高了73%。

Conclusion: 该方法可应用于自动化质量控制、预测性维护和设计优化，且为未来预测建模研究奠定了坚实数据基础。

Abstract: This study addresses the challenge of accurately forecasting geometric
deviations in manufactured components using advanced 3D surface analysis.
Despite progress in modern manufacturing, maintaining dimensional precision
remains difficult, particularly for complex geometries. We present a
methodology that employs a high-resolution 3D scanner to acquire multi-angle
surface data from 237 components produced across different batches. The data
were processed through precise alignment, noise reduction, and merging
techniques to generate accurate 3D representations. A hybrid machine learning
framework was developed, combining convolutional neural networks for feature
extraction with gradient-boosted decision trees for predictive modeling. The
proposed system achieved a prediction accuracy of 0.012 mm at a 95% confidence
level, representing a 73% improvement over conventional statistical process
control methods. In addition to improved accuracy, the model revealed hidden
correlations between manufacturing parameters and geometric deviations. This
approach offers significant potential for automated quality control, predictive
maintenance, and design optimization in precision manufacturing, and the
resulting dataset provides a strong foundation for future predictive modeling
research.

</details>


### [41] [AGIC: Attention-Guided Image Captioning to Improve Caption Relevance](https://arxiv.org/abs/2508.06853)
*L. D. M. S. Sai Teja,Ashok Urlana,Pruthwik Mishra*

Main category: cs.CV

TL;DR: 提出了一种名为AGIC的注意力引导图片描述生成模型，进一步提升了描述语言的准确性与多样性。


<details>
  <summary>Details</summary>
Motivation: 现有的图片描述生成在准确性与描述性上仍存在挑战。

Method: 提出Attention-Guided Image Captioning（AGIC）模型，通过增强显著视觉区域，并引入混合解码策略结合确定性与概率抽样。

Result: 在Flickr8k和Flickr30k数据集上的实验表明，AGIC达到或超越了一些先进模型，并且推理速度更快。

Conclusion: AGIC通过多个评估指标展现优越性能，是具规模性和可解释性的图片描述生成解决方案。

Abstract: Despite significant progress in image captioning, generating accurate and
descriptive captions remains a long-standing challenge. In this study, we
propose Attention-Guided Image Captioning (AGIC), which amplifies salient
visual regions directly in the feature space to guide caption generation. We
further introduce a hybrid decoding strategy that combines deterministic and
probabilistic sampling to balance fluency and diversity. To evaluate AGIC, we
conduct extensive experiments on the Flickr8k and Flickr30k datasets. The
results show that AGIC matches or surpasses several state-of-the-art models
while achieving faster inference. Moreover, AGIC demonstrates strong
performance across multiple evaluation metrics, offering a scalable and
interpretable solution for image captioning.

</details>


### [42] [A Joint Sparse Self-Representation Learning Method for Multiview Clustering](https://arxiv.org/abs/2508.06857)
*Mengxue Jia,Zhihua Allen-Zhao,You Zhao,Sanyang Liu*

Main category: cs.CV

TL;DR: 提出了一种用于多视图聚类的新模型，利用稀疏自表达学习和交替二次惩罚法，在六个数据集上取得了优于现有方法的结果。


<details>
  <summary>Details</summary>
Motivation: 针对多视图聚类中如何有效利用局部和全局信息的挑战，并解决传统优化方法在非凸非平滑模型上收敛性不足的问题。

Method: 引入了带有基数约束的稀疏自表达学习模型，采用低秩约束协调多视图间的一致性，并设计了全局收敛的交替二次惩罚（AQP）方法来优化模型。

Result: 在六个标准数据集上，模型和AQP方法的性能优于八种现有最先进的算法。

Conclusion: 提出的模型能够有效捕捉多视图的局部和全局信息，且具有优越性能，交替二次惩罚优化方法进一步保证了模型的实际应用能力。

Abstract: Multiview clustering (MC) aims to group samples using consistent and
complementary information across various views. The subspace clustering, as a
fundamental technique of MC, has attracted significant attention. In this
paper, we propose a novel joint sparse self-representation learning model for
MC, where a featured difference is the extraction of view-specific local
information by introducing cardinality (i.e., $\ell_0$-norm) constraints
instead of Graph-Laplacian regularization. Specifically, under each view,
cardinality constraints directly restrict the samples used in the
self-representation stage to extract reliable local and global structure
information, while the low-rank constraint aids in revealing a global coherent
structure in the consensus affinity matrix during merging. The attendant
challenge is that Augmented Lagrange Method (ALM)-based alternating
minimization algorithms cannot guarantee convergence when applied directly to
our nonconvex, nonsmooth model, thus resulting in poor generalization ability.
To address it, we develop an alternating quadratic penalty (AQP) method with
global convergence, where two subproblems are iteratively solved by closed-form
solutions. Empirical results on six standard datasets demonstrate the
superiority of our model and AQP method, compared to eight state-of-the-art
algorithms.

</details>


### [43] [VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding](https://arxiv.org/abs/2508.06869)
*Jianxiang He,Shaoguang Wang,Weiyu Guo,Meisheng Hong,Jungang Li,Yijie Xu,Ziyang Chen,Hui Xiong*

Main category: cs.CV

TL;DR: 本论文提出一种多模态关键帧搜索方法，名为VSI，通过整合视频字幕、时间戳和场景边界，实现精准的关键帧定位和视频问答任务。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型难以高效处理长视频，特别是在关键帧检索准确性方面，受限于文本与视觉内容间弱对齐以及忽略复杂时间语义信息。

Method: 本文提出VSI方法，结合字幕、时间戳和场景边界，通过双流搜索机制（视频搜索流与字幕匹配流）捕捉视觉和文本信息，并利用两流交互提升关键帧搜索准确性。

Result: 实验表明，VSI在LongVideoBench数据集的关键帧定位准确率达40.00%，在长视频问答任务中达68.48%，相比基线方法分别提升20.35%和15.79%。

Conclusion: VSI方法在中长视频问答任务中实现SOTA表现，证明该方法在多模态搜索策略中的鲁棒性和广泛适用性。

Abstract: Long video understanding presents a significant challenge to multimodal large
language models (MLLMs) primarily due to the immense data scale. A critical and
widely adopted strategy for making this task computationally tractable is
keyframe retrieval, which seeks to identify a sparse set of video frames that
are most salient to a given textual query. However, the efficacy of this
approach is hindered by weak multimodal alignment between textual queries and
visual content and fails to capture the complex temporal semantic information
required for precise reasoning. To address this, we propose Visual-Subtitle
Integeration(VSI), a multimodal keyframe search method that integrates
subtitles, timestamps, and scene boundaries into a unified multimodal search
process. The proposed method captures the visual information of video frames as
well as the complementary textual information through a dual-stream search
mechanism by Video Search Stream as well as Subtitle Match Stream,
respectively, and improves the keyframe search accuracy through the interaction
of the two search streams. Experimental results show that VSI achieve 40.00%
key frame localization accuracy on the text-relevant subset of LongVideoBench
and 68.48% accuracy on downstream long Video-QA tasks, surpassing competitive
baselines by 20.35% and 15.79%, respectively. Furthermore, on the
LongVideoBench, VSI achieved state-of-the-art(SOTA) in medium-to-long video-QA
tasks, demonstrating the robustness and generalizability of the proposed
multimodal search strategy.

</details>


### [44] [NS-FPN: Improving Infrared Small Target Detection and Segmentation from Noise Suppression Perspective](https://arxiv.org/abs/2508.06878)
*Maoxun Yuan,Duanni Meng,Ziteng Xi,Tianyi Zhao,Shiji Zhao,Yimian Dai,Xingxing Wei*

Main category: cs.CV

TL;DR: 本文针对红外小目标检测及分割（IRSTDS）任务提出了一个轻量高效的频域降噪特征金字塔网络（NS-FPN），显著降低了误报率，并优化了检测性能。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测任务因目标特点模糊、背景混乱而具备挑战性。尽管现有方法在特征表达上有提升，但未根本解决噪声问题，误报率依旧较高。因而，需要从噪声抑制出发优化检测。

Method: 提出一种名为NS-FPN的网络结构，结合了低频引导特征净化模块（LFP）和螺旋感知特征采样模块（SFS）。LFP模块通过净化高频成分抑制噪声，SFS模块通过螺旋采样融合相关特征，整体增强网络性能。

Result: 在公开IRSTDS数据集上的实验表明，NS-FPN显著降低了误报率并取得了优异的检测与分割效果。

Conclusion: NS-FPN通过频域降噪优化IRSTDS性能，设计轻量化且易于集成于现有框架中，为未来红外目标检测研究提供了新思路。

Abstract: Infrared small target detection and segmentation (IRSTDS) is a critical yet
challenging task in defense and civilian applications, owing to the dim,
shapeless appearance of targets and severe background clutter. Recent CNN-based
methods have achieved promising target perception results, but they only focus
on enhancing feature representation to offset the impact of noise, which
results in the increased false alarms problem. In this paper, through analyzing
the problem from the frequency domain, we pioneer in improving performance from
noise suppression perspective and propose a novel noise-suppression feature
pyramid network (NS-FPN), which integrates a low-frequency guided feature
purification (LFP) module and a spiral-aware feature sampling (SFS) module into
the original FPN structure. The LFP module suppresses the noise features by
purifying high-frequency components to achieve feature enhancement devoid of
noise interference, while the SFS module further adopts spiral sampling to fuse
target-relevant features in feature fusion process. Our NS-FPN is designed to
be lightweight yet effective and can be easily plugged into existing IRSTDS
frameworks. Extensive experiments on the public IRSTDS datasets demonstrate
that our method significantly reduces false alarms and achieves superior
performance on IRSTDS tasks.

</details>


### [45] [BASIC: Boosting Visual Alignment with Intrinsic Refined Embeddings in Multimodal Large Language Models](https://arxiv.org/abs/2508.06895)
*Jianting Tang,Yubo Wang,Haoyu Cao,Linli Xu*

Main category: cs.CV

TL;DR: 提出了一种称为BASIC的新方法，通过直接视觉监督改进多模态大语言模型的视觉理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态模型无法充分对视觉嵌入进行直接监督，限制了视觉与文本模态对齐的精细程度。

Method: BASIC方法通过两个视角进行指导：优化嵌入方向以减少初始和监督嵌入的语义角度差距；通过最小化视觉嵌入的logit分布差异提升语义匹配，无需额外监督模型或人工标注。

Result: BASIC在多个基准测试中显著提高了多模态大语言模型的性能。

Conclusion: 直接视觉监督是提高多模态模型表现的有效方法。

Abstract: Mainstream Multimodal Large Language Models (MLLMs) achieve visual
understanding by using a vision projector to bridge well-pretrained vision
encoders and large language models (LLMs). The inherent gap between visual and
textual modalities makes the embeddings from the vision projector critical for
visual comprehension. However, current alignment approaches treat visual
embeddings as contextual cues and merely apply auto-regressive supervision to
textual outputs, neglecting the necessity of introducing equivalent direct
visual supervision, which hinders the potential finer alignment of visual
embeddings. In this paper, based on our analysis of the refinement process of
visual embeddings in the LLM's shallow layers, we propose BASIC, a method that
utilizes refined visual embeddings within the LLM as supervision to directly
guide the projector in generating initial visual embeddings. Specifically, the
guidance is conducted from two perspectives: (i) optimizing embedding
directions by reducing angles between initial and supervisory embeddings in
semantic space; (ii) improving semantic matching by minimizing disparities
between the logit distributions of both visual embeddings. Without additional
supervisory models or artificial annotations, BASIC significantly improves the
performance of MLLMs across a wide range of benchmarks, demonstrating the
effectiveness of our introduced direct visual supervision.

</details>


### [46] [Advancements in Chinese font generation since deep learning era: A survey](https://arxiv.org/abs/2508.06900)
*Weiran Chen,Guiqian Zhu,Ying Li,Yi Ji,Chunping Liu*

Main category: cs.CV

TL;DR: 本文回顾了基于深度学习的中文字体生成技术的研究进展，分类讨论了多样本和少样本字体生成方法，并提出挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 通过基于深度学习的方法改进中文字体生成的整体质量，为字体设计领域的研究提供启示。

Method: 回顾了经典深度学习架构、字体表示格式、公开数据集及评估指标，并分类综述了多样本和少样本字体生成技术，分析其优缺点。

Result: 对已有的中文字体生成技术进行了全面调查，并对各类方法的优势和不足进行了详细讨论。

Conclusion: 提供了当前中文字体生成领域的研究挑战和未来方向，为研究人员提供了潜在的研究思路和启示。

Abstract: Chinese font generation aims to create a new Chinese font library based on
some reference samples. It is a topic of great concern to many font designers
and typographers. Over the past years, with the rapid development of deep
learning algorithms, various new techniques have achieved flourishing and
thriving progress. Nevertheless, how to improve the overall quality of
generated Chinese character images remains a tough issue. In this paper, we
conduct a holistic survey of the recent Chinese font generation approaches
based on deep learning. To be specific, we first illustrate the research
background of the task. Then, we outline our literature selection and analysis
methodology, and review a series of related fundamentals, including classical
deep learning architectures, font representation formats, public datasets, and
frequently-used evaluation metrics. After that, relying on the number of
reference samples required to generate a new font, we categorize the existing
methods into two major groups: many-shot font generation and few-shot font
generation methods. Within each category, representative approaches are
summarized, and their strengths and limitations are also discussed in detail.
Finally, we conclude our paper with the challenges and future directions, with
the expectation to provide some valuable illuminations for the researchers in
this field.

</details>


### [47] [eMotions: A Large-Scale Dataset and Audio-Visual Fusion Network for Emotion Analysis in Short-form Videos](https://arxiv.org/abs/2508.06902)
*Xuecheng Wu,Dingkang Yang,Danlei Huang,Xinyi Yin,Yifan Wang,Jia Zhang,Jiayu Nie,Liangyu Fu,Yang Liu,Junxiao Xue,Hadi Amirpour,Wei Zhou*

Main category: cs.CV

TL;DR: 提出eMotions数据集及AV-CANet模型，应对短视频情感分析中的多模态和语义差异等挑战。


<details>
  <summary>Details</summary>
Motivation: 短视频情感分析因多模态复杂性和数据有限性而面临挑战，需要高质量数据集与有效分析方法。

Method: 构建eMotions大规模短视频数据集并提出AV-CANet网络，融合视频变换器与局部-全局融合模块，通过EP-CE Loss优化全局情感表达。

Result: AV-CANet在多个eMotions相关数据集及公共数据集上的实验证明其有效性，并提供情感分析的研究启示。

Conclusion: AV-CANet及eMotions数据集推进短视频情感分析研究，未来可进一步优化多模态融合与情感表示学习。

Abstract: Short-form videos (SVs) have become a vital part of our online routine for
acquiring and sharing information. Their multimodal complexity poses new
challenges for video analysis, highlighting the need for video emotion analysis
(VEA) within the community. Given the limited availability of SVs emotion data,
we introduce eMotions, a large-scale dataset consisting of 27,996 videos with
full-scale annotations. To ensure quality and reduce subjective bias, we
emphasize better personnel allocation and propose a multi-stage annotation
procedure. Additionally, we provide the category-balanced and test-oriented
variants through targeted sampling to meet diverse needs. While there have been
significant studies on videos with clear emotional cues (e.g., facial
expressions), analyzing emotions in SVs remains a challenging task. The
challenge arises from the broader content diversity, which introduces more
distinct semantic gaps and complicates the representations learning of
emotion-related features. Furthermore, the prevalence of audio-visual
co-expressions in SVs leads to the local biases and collective information gaps
caused by the inconsistencies in emotional expressions. To tackle this, we
propose AV-CANet, an end-to-end audio-visual fusion network that leverages
video transformer to capture semantically relevant representations. We further
introduce the Local-Global Fusion Module designed to progressively capture the
correlations of audio-visual features. Besides, EP-CE Loss is constructed to
globally steer optimizations with tripolar penalties. Extensive experiments
across three eMotions-related datasets and four public VEA datasets demonstrate
the effectiveness of our proposed AV-CANet, while providing broad insights for
future research. Moreover, we conduct ablation studies to examine the critical
components of our method. Dataset and code will be made available at Github.

</details>


### [48] [A Simple yet Powerful Instance-Aware Prompting Framework for Training-free Camouflaged Object Segmentation](https://arxiv.org/abs/2508.06904)
*Chao Yin,Jide Li,Xiaoqiang Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为IAPF的无训练伪装物体分割方法，通过三步策略转换任务通用提示为精细的实例掩码，比现有方法表现更佳。


<details>
  <summary>Details</summary>
Motivation: 伪装物体分割具有挑战性，因目标与背景相似性高。而现有无训练方法生成的语义级提示导致分割效果粗糙，多实例情况下表现欠佳，因此需要改进。

Method: 提出IAPF框架，包括：(1) 文本生成，用多模态语言模型生成图像特定标签；(2) 实例掩码生成，用Grounding DINO和新的点提示策略生成候选实例掩码；(3) 自一致性投票，最终选择最一致的实例掩码。

Result: IAPF在标准伪装物体分割数据集上超越现有最先进无训练方法，取得显著性能提升。

Conclusion: 通过将任务通用提示转化为实例级掩码，IAPF有效解决了多实例场景下分割效果不佳的问题，并证明其在无训练伪装物体分割中的有效性。

Abstract: Camouflaged Object Segmentation (COS) remains highly challenging due to the
intrinsic visual similarity between target objects and their surroundings.
While training-based COS methods achieve good performance, their performance
degrades rapidly with increased annotation sparsity. To circumvent this
limitation, recent studies have explored training-free COS methods, leveraging
the Segment Anything Model (SAM) by automatically generating visual prompts
from a single task-generic prompt (\textit{e.g.}, "\textit{camouflaged
animal}") uniformly applied across all test images. However, these methods
typically produce only semantic-level visual prompts, causing SAM to output
coarse semantic masks and thus failing to handle scenarios with multiple
discrete camouflaged instances effectively. To address this critical
limitation, we propose a simple yet powerful \textbf{I}nstance-\textbf{A}ware
\textbf{P}rompting \textbf{F}ramework (IAPF), the first training-free COS
pipeline that explicitly converts a task-generic prompt into fine-grained
instance masks. Specifically, the IAPF comprises three steps: (1) Text Prompt
Generator, utilizing task-generic queries to prompt a Multimodal Large Language
Model (MLLM) for generating image-specific foreground and background tags; (2)
\textbf{Instance Mask Generator}, leveraging Grounding DINO to produce precise
instance-level bounding box prompts, alongside the proposed Single-Foreground
Multi-Background Prompting strategy to sample region-constrained point prompts
within each box, enabling SAM to yield a candidate instance mask; (3)
Self-consistency Instance Mask Voting, which selects the final COS prediction
by identifying the candidate mask most consistent across multiple candidate
instance masks. Extensive evaluations on standard COS benchmarks demonstrate
that the proposed IAPF significantly surpasses existing state-of-the-art
training-free COS methods.

</details>


### [49] [MultiRef: Controllable Image Generation with Multiple Visual References](https://arxiv.org/abs/2508.06905)
*Ruoxi Chen,Dongping Chen,Siyuan Wu,Sinan Wang,Shiyun Lang,Petr Sushko,Gaoyang Jiang,Yao Wan,Ranjay Krishna*

Main category: cs.CV

TL;DR: 提出了一个名为MultiRef-bench的框架，用于评估多源视觉参考图像生成的效果，同时构建了一个包含38k高质量图像的数据集，用于推动研究。


<details>
  <summary>Details</summary>
Motivation: 现有的图像生成框架主要依赖于单一来源输入，无法满足生成者从多种视觉参考中获取灵感的需求。

Method: 引入了MultiRef-bench评价框架，并通过RefBlend数据引擎生成综合性样本，创建了MultiRef数据集，并在多个图像-文本模型和框架上进行了实验验证。

Result: 最先进的系统在多参考条件下表现不佳，OmniGen模型在合成样本中的精度为66.6%，真实世界案例中为79.0%。

Conclusion: 整合多种视觉参考的生成工具仍需改进，研究方向明确，数据集提供了重要的支持与推动作用。

Abstract: Visual designers naturally draw inspiration from multiple visual references,
combining diverse elements and aesthetic principles to create artwork. However,
current image generative frameworks predominantly rely on single-source inputs
-- either text prompts or individual reference images. In this paper, we focus
on the task of controllable image generation using multiple visual references.
We introduce MultiRef-bench, a rigorous evaluation framework comprising 990
synthetic and 1,000 real-world samples that require incorporating visual
content from multiple reference images. The synthetic samples are synthetically
generated through our data engine RefBlend, with 10 reference types and 33
reference combinations. Based on RefBlend, we further construct a dataset
MultiRef containing 38k high-quality images to facilitate further research. Our
experiments across three interleaved image-text models (i.e., OmniGen, ACE, and
Show-o) and six agentic frameworks (e.g., ChatDiT and LLM + SD) reveal that
even state-of-the-art systems struggle with multi-reference conditioning, with
the best model OmniGen achieving only 66.6% in synthetic samples and 79.0% in
real-world cases on average compared to the golden answer. These findings
provide valuable directions for developing more flexible and human-like
creative tools that can effectively integrate multiple sources of visual
inspiration. The dataset is publicly available at: https://multiref.github.io/.

</details>


### [50] [MMReID-Bench: Unleashing the Power of MLLMs for Effective and Versatile Person Re-identification](https://arxiv.org/abs/2508.06908)
*Jinhao Li,Zijian Chen,Lirong Deng,Changbo Wang,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出了首个针对跨模态行人再识别任务的评测基准MMReID-Bench，包含多模态数据的综合性分析和实验。


<details>
  <summary>Details</summary>
Motivation: 当前行人再识别（ReID）模型在处理多模态数据时能力有限，而多模态大语言模型（MLLMs）展现出潜在的解决方向。然而，现有方法未能充分利用MLLMs的推理和跨模态理解能力。

Method: 设计并构建了MMReID-Bench，一个包含20,710个多模态查询和图库图像的多任务多模态基准，并使用这一基准对MLLMs的表现进行全面评估。

Result: 实验表明，MLLMs在多模态行人再识别任务中表现出显著能力，但在处理热成像和红外数据等少数模态时仍有局限性。

Conclusion: MMReID-Bench有望推动社群开发更强大、更具通用性的多模态基础模型，以应对行人再识别任务的挑战。

Abstract: Person re-identification (ReID) aims to retrieve the images of an interested
person in the gallery images, with wide applications in medical rehabilitation,
abnormal behavior detection, and public security. However, traditional person
ReID models suffer from uni-modal capability, leading to poor generalization
ability in multi-modal data, such as RGB, thermal, infrared, sketch images,
textual descriptions, etc. Recently, the emergence of multi-modal large
language models (MLLMs) shows a promising avenue for addressing this problem.
Despite this potential, existing methods merely regard MLLMs as feature
extractors or caption generators, which do not fully unleash their reasoning,
instruction-following, and cross-modal understanding capabilities. To bridge
this gap, we introduce MMReID-Bench, the first multi-task multi-modal benchmark
specifically designed for person ReID. The MMReID-Bench includes 20,710
multi-modal queries and gallery images covering 10 different person ReID tasks.
Comprehensive experiments demonstrate the remarkable capabilities of MLLMs in
delivering effective and versatile person ReID. Nevertheless, they also have
limitations in handling a few modalities, particularly thermal and infrared
data. We hope MMReID-Bench can facilitate the community to develop more robust
and generalizable multimodal foundation models for person ReID.

</details>


### [51] [Talk2Image: A Multi-Agent System for Multi-Turn Image Generation and Editing](https://arxiv.org/abs/2508.06916)
*Shichao Ma,Yunhe Guo,Jiahao Su,Qihe Huang,Zhengyang Zhou,Yang Wang*

Main category: cs.CV

TL;DR: Talk2Image 是一个多代理系统，用于多轮对话场景下的交互式图像生成和编辑，表现优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有单一代理的对话系统在多轮创意任务中存在意图漂移和编辑不连贯的问题，难以满足复杂的图像生成和编辑需求。

Method: 通过意图解析、任务分解与多代理协作执行以及基于多视图评估机制的反馈优化，实现逐步与用户意图对齐的图像生成和编辑。

Result: Talk2Image 在控件性、一致性和用户满意度上优于现有基线，并在迭代图像生成和编辑任务中表现优异。

Conclusion: Talk2Image 提供了一个有效的框架，展示了多代理协作在复杂多轮对话任务中优化图像生成和编辑的潜力。

Abstract: Text-to-image generation tasks have driven remarkable advances in diverse
media applications, yet most focus on single-turn scenarios and struggle with
iterative, multi-turn creative tasks. Recent dialogue-based systems attempt to
bridge this gap, but their single-agent, sequential paradigm often causes
intention drift and incoherent edits. To address these limitations, we present
Talk2Image, a novel multi-agent system for interactive image generation and
editing in multi-turn dialogue scenarios. Our approach integrates three key
components: intention parsing from dialogue history, task decomposition and
collaborative execution across specialized agents, and feedback-driven
refinement based on a multi-view evaluation mechanism. Talk2Image enables
step-by-step alignment with user intention and consistent image editing.
Experiments demonstrate that Talk2Image outperforms existing baselines in
controllability, coherence, and user satisfaction across iterative image
generation and editing tasks.

</details>


### [52] [AR-GRPO: Training Autoregressive Image Generation Models via Reinforcement Learning](https://arxiv.org/abs/2508.06924)
*Shihao Yuan,Yahui Liu,Yang Yue,Jingyuan Zhang,Wangmeng Zuo,Qi Wang,Fuzheng Zhang,Guorui Zhou*

Main category: cs.CV

TL;DR: AR-GRPO方法通过在自回归图像生成模型中引入在线强化学习优化，以实现更高质量的图像生成。


<details>
  <summary>Details</summary>
Motivation: 受到强化学习成功用于改进大型语言模型的启发，本文尝试将此方法应用于自回归图像生成领域。

Method: 将Group Relative Policy Optimization (GRPO)算法应用于自回归模型，通过奖励函数优化以提升生成图像的感知质量、真实感和语义一致性。

Result: 实验表明，AR-GRPO显著改善了基于类条件和文本条件的图像质量，并在各类评价指标上均表现出色，同时更符合人类偏好。

Conclusion: 利用强化学习优化的自回归图像生成在图像质量和人类偏好上都得到了提升，为可控和高质量图像合成研究开辟了新方向。

Abstract: Inspired by the success of reinforcement learning (RL) in refining large
language models (LLMs), we propose AR-GRPO, an approach to integrate online RL
training into autoregressive (AR) image generation models. We adapt the Group
Relative Policy Optimization (GRPO) algorithm to refine the vanilla
autoregressive models' outputs by carefully designed reward functions that
evaluate generated images across multiple quality dimensions, including
perceptual quality, realism, and semantic fidelity. We conduct comprehensive
experiments on both class-conditional (i.e., class-to-image) and
text-conditional (i.e., text-to-image) image generation tasks, demonstrating
that our RL-enhanced framework significantly improves both the image quality
and human preference of generated images compared to the standard AR baselines.
Our results show consistent improvements across various evaluation metrics,
establishing the viability of RL-based optimization for AR image generation and
opening new avenues for controllable and high-quality image synthesis. The
source codes and models are available at:
https://github.com/Kwai-Klear/AR-GRPO.

</details>


### [53] [CannyEdit: Selective Canny Control and Dual-Prompt Guidance for Training-Free Image Editing](https://arxiv.org/abs/2508.06937)
*Weiyan Xie,Han Gao,Didan Deng,Kaican Li,April Hua Liu,Yongxiang Huang,Nevin L. Zhang*

Main category: cs.CV

TL;DR: 文章提出了一种名为CannyEdit的新框架，用于无训练的局部图像编辑，解决了文本与编辑区域的一致性、未编辑区域的上下文保真度和编辑无缝性的问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法无法平衡编辑区域的文本一致性、未编辑区域的上下文保真性及编辑无缝性的问题。

Method: 引入选择性Canny控制实现可控的局部编辑，并运用双提示引导技术结合局部和全局提示以保持场景的连贯性。

Result: 在真实图像编辑任务（添加、替换和移除）中显著优于KV-Edit，且编辑无缝性测试表现更佳，与真图对比，只有更少的用户能识别CannyEdit的编辑结果。

Conclusion: CannyEdit通过其创新设计实现了精确文本驱动的高质量图像编辑，比现有方法更加无缝和自然。

Abstract: Recent advances in text-to-image (T2I) models have enabled training-free
regional image editing by leveraging the generative priors of foundation
models. However, existing methods struggle to balance text adherence in edited
regions, context fidelity in unedited areas, and seamless integration of edits.
We introduce CannyEdit, a novel training-free framework that addresses these
challenges through two key innovations: (1) Selective Canny Control, which
masks the structural guidance of Canny ControlNet in user-specified editable
regions while strictly preserving details of the source images in unedited
areas via inversion-phase ControlNet information retention. This enables
precise, text-driven edits without compromising contextual integrity. (2)
Dual-Prompt Guidance, which combines local prompts for object-specific edits
with a global target prompt to maintain coherent scene interactions. On
real-world image editing tasks (addition, replacement, removal), CannyEdit
outperforms prior methods like KV-Edit, achieving a 2.93 to 10.49 percent
improvement in the balance of text adherence and context fidelity. In terms of
editing seamlessness, user studies reveal only 49.2 percent of general users
and 42.0 percent of AIGC experts identified CannyEdit's results as AI-edited
when paired with real images without edits, versus 76.08 to 89.09 percent for
competitor methods.

</details>


### [54] [SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work](https://arxiv.org/abs/2508.06951)
*Harry Walsh,Ed Fish,Ozge Mercanoglu Sincan,Mohamed Ilyes Lakhal,Richard Bowden,Neil Fox,Bencie Woll,Kepeng Wu,Zecheng Li,Weichao Zhao,Haodong Wang,Wengang Zhou,Houqiang Li,Shengeng Tang,Jiayi He,Xu Wang,Ruobei Zhang,Yaxiong Wang,Lechao Cheng,Meryem Tasyurek,Tugce Kiziltepe,Hacer Yalim Keles*

Main category: cs.CV

TL;DR: 首次提出手语生成竞赛，评估从文本到骨骼姿态(T2P)翻译的算法，采用标准化评估方法。


<details>
  <summary>Details</summary>
Motivation: 当前手语生成领域缺乏统一评估标准，限制了不同系统间的有效比较。因此提出统一的竞赛框架以推进研究进展。

Method: 组织了首个手语生成挑战赛，覆盖文本到骨骼姿态(T2P)翻译，使用标准化评估指标和公开的数据集（如RWTH-PHOENIX-Weather-2014T），并创建了隐藏测试集。

Result: 该竞赛吸引了33个参与团队，共231个解决方案。最优团队取得了BLEU-1分数31.40和DTW-MJE 0.0574。

Conclusion: 引入的标准化评估框架为未来手语生成研究提供了一致的基线，有助于促进该领域的技术进步。

Abstract: Sign Language Production (SLP) is the task of generating sign language video
from spoken language inputs. The field has seen a range of innovations over the
last few years, with the introduction of deep learning-based approaches
providing significant improvements in the realism and naturalness of generated
outputs. However, the lack of standardized evaluation metrics for SLP
approaches hampers meaningful comparisons across different systems. To address
this, we introduce the first Sign Language Production Challenge, held as part
of the third SLRTP Workshop at CVPR 2025. The competition's aims are to
evaluate architectures that translate from spoken language sentences to a
sequence of skeleton poses, known as Text-to-Pose (T2P) translation, over a
range of metrics. For our evaluation data, we use the
RWTH-PHOENIX-Weather-2014T dataset, a German Sign Language - Deutsche
Gebardensprache (DGS) weather broadcast dataset. In addition, we curate a
custom hidden test set from a similar domain of discourse. This paper presents
the challenge design and the winning methodologies. The challenge attracted 33
participants who submitted 231 solutions, with the top-performing team
achieving BLEU-1 scores of 31.40 and DTW-MJE of 0.0574. The winning approach
utilized a retrieval-based framework and a pre-trained language model. As part
of the workshop, we release a standardized evaluation network, including
high-quality skeleton extraction-based keypoints establishing a consistent
baseline for the SLP field, which will enable future researchers to compare
their work against a broader range of methods.

</details>


### [55] [Beyond Frequency: Seeing Subtle Cues Through the Lens of Spatial Decomposition for Fine-Grained Visual Classification](https://arxiv.org/abs/2508.06959)
*Qin Xu,Lili Zhu,Xiaoxia Cheng,Bo Jiang*

Main category: cs.CV

TL;DR: 提出了一种名为SCOPE的新方法，通过增强空间域中的低级细节和高级语义，提高了精细化图像分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于频域方法的图像分类存在固定基函数的局限性，缺乏对图像内容的适应性，无法根据不同图像的判别需求动态调整特征提取。

Method: 提出了Subtle-Cue Oriented Perception Engine (SCOPE) 方法，由Subtle Detail Extractor (SDE) 和 Salient Semantic Refiner (SSR) 两个模块组成，分别处理浅层特征的细节动态增强与高级特征的语义一致性和结构感知优化。

Result: 通过对四个流行的精细化图像分类基准的实验验证，该方法达到了新的最先进性能。

Conclusion: SCOPE方法突破了频域方法的固定尺度限制，通过逐阶段结合局部细节与全局语义，提升了精细化分类任务的表现。

Abstract: The crux of resolving fine-grained visual classification (FGVC) lies in
capturing discriminative and class-specific cues that correspond to subtle
visual characteristics. Recently, frequency decomposition/transform based
approaches have attracted considerable interests since its appearing
discriminative cue mining ability. However, the frequency-domain methods are
based on fixed basis functions, lacking adaptability to image content and
unable to dynamically adjust feature extraction according to the discriminative
requirements of different images. To address this, we propose a novel method
for FGVC, named Subtle-Cue Oriented Perception Engine (SCOPE), which adaptively
enhances the representational capability of low-level details and high-level
semantics in the spatial domain, breaking through the limitations of fixed
scales in the frequency domain and improving the flexibility of multi-scale
fusion. The core of SCOPE lies in two modules: the Subtle Detail Extractor
(SDE), which dynamically enhances subtle details such as edges and textures
from shallow features, and the Salient Semantic Refiner (SSR), which learns
semantically coherent and structure-aware refinement features from the
high-level features guided by the enhanced shallow features. The SDE and SSR
are cascaded stage-by-stage to progressively combine local details with global
semantics. Extensive experiments demonstrate that our method achieves new
state-of-the-art on four popular fine-grained image classification benchmarks.

</details>


### [56] [Adversarial Video Promotion Against Text-to-Video Retrieval](https://arxiv.org/abs/2508.06964)
*Qiwei Tian,Chenhao Lin,Zhengyu Zhao,Qian Li,Shuai Liu,Chao Shen*

Main category: cs.CV

TL;DR: 提出了一种针对文本到视频检索（T2VR）的新攻击方法，即视频推广攻击（ViPro），并通过精细化交互方法（MoRe）显著提升了黑盒可迁移性。实验结果表明，在多种设置下该方法优于现有基线30%左右，代码已公开。


<details>
  <summary>Details</summary>
Motivation: 当前T2VR技术进步迅速，但其鲁棒性尚未充分研究，特别是对攻击视频排名提升的研究几乎为空白。而这些攻击可能被滥用以获取经济利益或传播错误信息，因此需要更深入的探讨。

Method: 提出了一种视频推广攻击（ViPro），并结合模态精化技术（MoRe）捕捉视觉与文本模态之间的精细交互。多目标场景实验覆盖2个基线、3种主流模型和3个流行数据集，并在白盒、灰盒、黑盒三种情况下对性能进行了全面评估。

Result: ViPro在多目标场景下提升了视频在多查询下的排名，与其他方法相比，平均在白盒、灰盒、黑盒设置下分别提高了30%、10%和4%的性能；同时还评估了其在防御和不可感知性方面的表现。

Conclusion: 本研究突出了一种被忽视的T2VR脆弱性，提供了攻击上限和下限的定性分析，并为该领域的潜在防御策略提供了有价值的思考和见解。

Abstract: Thanks to the development of cross-modal models, text-to-video retrieval
(T2VR) is advancing rapidly, but its robustness remains largely unexamined.
Existing attacks against T2VR are designed to push videos away from queries,
i.e., suppressing the ranks of videos, while the attacks that pull videos
towards selected queries, i.e., promoting the ranks of videos, remain largely
unexplored. These attacks can be more impactful as attackers may gain more
views/clicks for financial benefits and widespread (mis)information. To this
end, we pioneer the first attack against T2VR to promote videos adversarially,
dubbed the Video Promotion attack (ViPro). We further propose Modal Refinement
(MoRe) to capture the finer-grained, intricate interaction between visual and
textual modalities to enhance black-box transferability. Comprehensive
experiments cover 2 existing baselines, 3 leading T2VR models, 3 prevailing
datasets with over 10k videos, evaluated under 3 scenarios. All experiments are
conducted in a multi-target setting to reflect realistic scenarios where
attackers seek to promote the video regarding multiple queries simultaneously.
We also evaluated our attacks for defences and imperceptibility. Overall, ViPro
surpasses other baselines by over $30/10/4\%$ for white/grey/black-box settings
on average. Our work highlights an overlooked vulnerability, provides a
qualitative analysis on the upper/lower bound of our attacks, and offers
insights into potential counterplays. Code will be publicly available at
https://github.com/michaeltian108/ViPro.

</details>


### [57] [Evaluating Fisheye-Compatible 3D Gaussian Splatting Methods on Real Images Beyond 180 Degree Field of View](https://arxiv.org/abs/2508.06968)
*Ulas Gunes,Matias Turkulainen,Juho Kannala,Esa Rahtu*

Main category: cs.CV

TL;DR: 本文评估了Fisheye-GS和3DGUT两种基于鱼眼相机的3D高斯斑点方法，并在视场超过180度的真实图像中进行了研究，分析了在极端失真条件下的表现。


<details>
  <summary>Details</summary>
Motivation: 研究鱼眼相机捕捉的图像因视场大而具备的失真现象，并探索如何利用3D重建方法解决广角条件下的重建问题。

Method: 本文评估了Fisheye-GS和3DGUT方法在不同视场条件下（200度、160度、120度）的性能，同时提出了一种基于深度的初始化策略，结合UniK3D的预测以改善传统SfM方法在强失真场景中的表现。

Result: 3DGUT跨所有视场条件表现稳定，保持高视觉质量，而Fisheye-GS在缩小视场（特别是160度）时表现更好。使用UniK3D生成的点云在困难场景中实现了与SfM方法相当的重建质量。

Conclusion: 基于鱼眼的3D高斯斑点方法可在有较强失真和稀疏图像输入的情况下进行宽视场的3D重建，展现了其实用价值。

Abstract: We present the first evaluation of fisheye-based 3D Gaussian Splatting
methods, Fisheye-GS and 3DGUT, on real images with fields of view exceeding 180
degree. Our study covers both indoor and outdoor scenes captured with 200
degree fisheye cameras and analyzes how each method handles extreme distortion
in real world settings. We evaluate performance under varying fields of view
(200 degree, 160 degree, and 120 degree) to study the tradeoff between
peripheral distortion and spatial coverage. Fisheye-GS benefits from field of
view (FoV) reduction, particularly at 160 degree, while 3DGUT remains stable
across all settings and maintains high perceptual quality at the full 200
degree view. To address the limitations of SfM-based initialization, which
often fails under strong distortion, we also propose a depth-based strategy
using UniK3D predictions from only 2-3 fisheye images per scene. Although
UniK3D is not trained on real fisheye data, it produces dense point clouds that
enable reconstruction quality on par with SfM, even in difficult scenes with
fog, glare, or sky. Our results highlight the practical viability of
fisheye-based 3DGS methods for wide-angle 3D reconstruction from sparse and
distortion-heavy image inputs.

</details>


### [58] [WeatherDiffusion: Weather-Guided Diffusion Model for Forward and Inverse Rendering](https://arxiv.org/abs/2508.06982)
*Yixin Zhu,Zuoliang Zhu,Miloš Hašan,Jian Yang,Jin Xie,Beibei Wang*

Main category: cs.CV

TL;DR: 本文提出WeatherDiffusion，一个用于自动驾驶场景中多种天气和光照条件的扩散式正反向渲染框架。


<details>
  <summary>Details</summary>
Motivation: 复杂的天气和光照对自动驾驶场景的理解和重建构成了重大挑战，现有扩散模型难于控制和缺乏鲁棒性。

Method: 提出WeatherDiffusion框架，利用预测的本征图和文本描述引导进行可控的天气与光照编辑，同时通过提出本征图注意力（MAA）实现高质量的逆向渲染，并构建WeatherSynthetic和WeatherReal数据集。

Result: WeatherDiffusion在多个基准测试中超越了现有方法，并提高了自动驾驶任务中物体检测和图像分割在恶劣天气下的鲁棒性。

Conclusion: WeatherDiffusion不仅可以进行真实的材质、几何和光照估计，还支持受控的天气和光照编辑，显著提升了自动驾驶任务的表现。

Abstract: Forward and inverse rendering have emerged as key techniques for enabling
understanding and reconstruction in the context of autonomous driving (AD).
However, complex weather and illumination pose great challenges to this task.
The emergence of large diffusion models has shown promise in achieving
reasonable results through learning from 2D priors, but these models are
difficult to control and lack robustness. In this paper, we introduce
WeatherDiffusion, a diffusion-based framework for forward and inverse rendering
on AD scenes with various weather and lighting conditions. Our method enables
authentic estimation of material properties, scene geometry, and lighting, and
further supports controllable weather and illumination editing through the use
of predicted intrinsic maps guided by text descriptions. We observe that
different intrinsic maps should correspond to different regions of the original
image. Based on this observation, we propose Intrinsic map-aware attention
(MAA) to enable high-quality inverse rendering. Additionally, we introduce a
synthetic dataset (\ie WeatherSynthetic) and a real-world dataset (\ie
WeatherReal) for forward and inverse rendering on AD scenes with diverse
weather and lighting. Extensive experiments show that our WeatherDiffusion
outperforms state-of-the-art methods on several benchmarks. Moreover, our
method demonstrates significant value in downstream tasks for AD, enhancing the
robustness of object detection and image segmentation in challenging weather
scenarios.

</details>


### [59] [TADoc: Robust Time-Aware Document Image Dewarping](https://arxiv.org/abs/2508.06988)
*Fangmin Zhao,Weichao Zeng,Zhenhang Li,Dongbao Yang,Yu Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的方法来解决文本去扭曲问题，通过动态建模和轻量级网络框架实现更好的去扭曲效果，并提出新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 当前文档图像去扭曲面临复杂场景与高变形度的问题，现有方法效果不佳。

Method: 将去扭曲任务重新定义为动态过程，提出TADoc框架，同时设计DLS指标评估效果。

Result: 实验表明所提方法具有很强的鲁棒性，在多种基准测试中表现优越。

Conclusion: 通过动态建模与新评估指标的创新，本文方法显著提高了文档去扭曲的效果，并为后续任务提供了更高的交付效果。

Abstract: Flattening curved, wrinkled, and rotated document images captured by portable
photographing devices, termed document image dewarping, has become an
increasingly important task with the rise of digital economy and online
working. Although many methods have been proposed recently, they often struggle
to achieve satisfactory results when confronted with intricate document
structures and higher degrees of deformation in real-world scenarios. Our main
insight is that, unlike other document restoration tasks (e.g., deblurring),
dewarping in real physical scenes is a progressive motion rather than a
one-step transformation. Based on this, we have undertaken two key initiatives.
Firstly, we reformulate this task, modeling it for the first time as a dynamic
process that encompasses a series of intermediate states. Secondly, we design a
lightweight framework called TADoc (Time-Aware Document Dewarping Network) to
address the geometric distortion of document images. In addition, due to the
inadequacy of OCR metrics for document images containing sparse text, the
comprehensiveness of evaluation is insufficient. To address this shortcoming,
we propose a new metric -- DLS (Document Layout Similarity) -- to evaluate the
effectiveness of document dewarping in downstream tasks. Extensive experiments
and in-depth evaluations have been conducted and the results indicate that our
model possesses strong robustness, achieving superiority on several benchmarks
with different document types and degrees of distortion.

</details>


### [60] [OctreeNCA: Single-Pass 184 MP Segmentation on Consumer Hardware](https://arxiv.org/abs/2508.06993)
*Nick Lemke,John Kalkhof,Niklas Babendererde,Anirban Mukhopadhyay*

Main category: cs.CV

TL;DR: 提出了OctreeNCA模型，其通过使用八叉树结构优化NCA模型，实现高效分割大规模医学图像和视频，同时显著降低显存占用和提高推理速度。


<details>
  <summary>Details</summary>
Motivation: 针对现有的医学图像分割模型在处理大规模输入时显存需求高、推理效率低的问题，提出改进方案。

Method: 通过八叉树数据结构扩展NCA的局部通信规则，同时使用CUDA优化推理函数，以提高模型的全局感知能力并降低显存需求。

Result: OctreeNCA在分割大分辨率图像和视频时，显存占用比UNet减少90%，能够一次性处理184MP病理切片或1分钟手术视频。

Conclusion: OctreeNCA在显存占用和推理效率方面优于传统模型，证明了其在大规模医学图像分割任务中的实用性。

Abstract: Medical applications demand segmentation of large inputs, like prostate MRIs,
pathology slices, or videos of surgery. These inputs should ideally be inferred
at once to provide the model with proper spatial or temporal context. When
segmenting large inputs, the VRAM consumption of the GPU becomes the
bottleneck. Architectures like UNets or Vision Transformers scale very poorly
in VRAM consumption, resulting in patch- or frame-wise approaches that
compromise global consistency and inference speed. The lightweight Neural
Cellular Automaton (NCA) is a bio-inspired model that is by construction
size-invariant. However, due to its local-only communication rules, it lacks
global knowledge. We propose OctreeNCA by generalizing the neighborhood
definition using an octree data structure. Our generalized neighborhood
definition enables the efficient traversal of global knowledge. Since deep
learning frameworks are mainly developed for large multi-layer networks, their
implementation does not fully leverage the advantages of NCAs. We implement an
NCA inference function in CUDA that further reduces VRAM demands and increases
inference speed. Our OctreeNCA segments high-resolution images and videos
quickly while occupying 90% less VRAM than a UNet during evaluation. This
allows us to segment 184 Megapixel pathology slices or 1-minute surgical videos
at once.

</details>


### [61] [S2-UniSeg: Fast Universal Agglomerative Pooling for Scalable Segment Anything without Supervision](https://arxiv.org/abs/2508.06995)
*Huihui Xu,Jin Ye,Hongqiu Wang,Changkai Ji,Jiashi Lin,Ming Hu,Ziyan Huang,Ying Chen,Chenglong Ma,Tianbin Li,Lihao Liu,Junjun He,Lei Zhu*

Main category: cs.CV

TL;DR: 本研究提出了一种新的伪掩码算法，UniAP，加速了生成伪掩码的过程，并且能够细粒度地生成语义和实例级别的伪掩码。基于此，提出了一个新的自监督分割模型S2-UniSeg，打破了传统耗时多阶段的训练模式。其性能优于当前最先进的模型，且在更大规模的数据集上显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统自监督分割模型需要耗时的伪掩码生成过程，难以扩展大规模数据集，并且由于不连续优化导致性能局限。本研究旨在解决这些问题。

Method: 提出了一种快速伪掩码算法UniAP，其能够并行分组生成伪掩码；结合QuerySD分割预训练任务，设计S2-UniSeg模型，实现学生与动量教师连续预训练。

Result: S2-UniSeg在COCO、UVO、COCOStuff-27和Cityscapes等数据集上性能全面超越现有最优模型。同时在更大规模数据集上也有显著性能提升。

Conclusion: 通过设计UniAP和QuerySD，S2-UniSeg不仅大幅缩短了训练时间，还显著提高了分割性能，证明了该方法的优越性。代码和预训练模型已在线发布。

Abstract: Recent self-supervised image segmentation models have achieved promising
performance on semantic segmentation and class-agnostic instance segmentation.
However, their pretraining schedule is multi-stage, requiring a time-consuming
pseudo-masks generation process between each training epoch. This
time-consuming offline process not only makes it difficult to scale with
training dataset size, but also leads to sub-optimal solutions due to its
discontinuous optimization routine. To solve these, we first present a novel
pseudo-mask algorithm, Fast Universal Agglomerative Pooling (UniAP). Each layer
of UniAP can identify groups of similar nodes in parallel, allowing to generate
both semantic-level and instance-level and multi-granular pseudo-masks within
ens of milliseconds for one image. Based on the fast UniAP, we propose the
Scalable Self-Supervised Universal Segmentation (S2-UniSeg), which employs a
student and a momentum teacher for continuous pretraining. A novel
segmentation-oriented pretext task, Query-wise Self-Distillation (QuerySD), is
proposed to pretrain S2-UniSeg to learn the local-to-global correspondences.
Under the same setting, S2-UniSeg outperforms the SOTA UnSAM model, achieving
notable improvements of AP+6.9 on COCO, AR+11.1 on UVO, PixelAcc+4.5 on
COCOStuff-27, RQ+8.0 on Cityscapes. After scaling up to a larger 2M-image
subset of SA-1B, S2-UniSeg further achieves performance gains on all four
benchmarks. Our code and pretrained models are available at
https://github.com/bio-mlhui/S2-UniSeg

</details>


### [62] [HiMat: DiT-based Ultra-High Resolution SVBRDF Generation](https://arxiv.org/abs/2508.07011)
*Zixiong Wang,Jian Yang,Yiwei Hu,Milos Hasan,Beibei Wang*

Main category: cs.CV

TL;DR: 提出一种基于扩散模型的框架HiMat，用于生成高分辨率4K的SVBRDF，同时解决多种SVBRDF地图的对齐及一致性问题。


<details>
  <summary>Details</summary>
Motivation: 当前的扩散模型擅长生成高分辨率图像，但难以生成多张对齐且一致的SVBRDF贴图，而高精度的SVBRDF对3D内容创作至关重要。

Method: 提出HiMat框架，核心模块为CrossStitch，一个轻量级卷积模块，可以在不更改原始模型骨干结构的情况下捕获地图间依赖；对CrossStitch的权重进行了特殊初始化以保障初始操作不被破坏。

Result: HiMat框架能够生成具有强结构一致性和高频细节的4K分辨率SVBRDF，实验证明其在文本提示的条件下效果显著，同时在内在分解等任务上展示了潜在的泛化能力。

Conclusion: HiMat通过高效的结构设计解决了一致性和分辨率的平衡问题，为高精度多地图生成提供了可行方案。

Abstract: Creating highly detailed SVBRDFs is essential for 3D content creation. The
rise of high-resolution text-to-image generative models, based on diffusion
transformers (DiT), suggests an opportunity to finetune them for this task.
However, retargeting the models to produce multiple aligned SVBRDF maps instead
of just RGB images, while achieving high efficiency and ensuring consistency
across different maps, remains a challenge. In this paper, we introduce HiMat:
a memory- and computation-efficient diffusion-based framework capable of
generating native 4K-resolution SVBRDFs. A key challenge we address is
maintaining consistency across different maps in a lightweight manner, without
relying on training new VAEs or significantly altering the DiT backbone (which
would damage its prior capabilities). To tackle this, we introduce the
CrossStitch module, a lightweight convolutional module that captures inter-map
dependencies through localized operations. Its weights are initialized such
that the DiT backbone operation is unchanged before finetuning starts. HiMat
enables generation with strong structural coherence and high-frequency details.
Results with a large set of text prompts demonstrate the effectiveness of our
approach for 4K SVBRDF generation. Further experiments suggest generalization
to tasks such as intrinsic decomposition.

</details>


### [63] [TerraMAE: Learning Spatial-Spectral Representations from Hyperspectral Earth Observation Data via Adaptive Masked Autoencoders](https://arxiv.org/abs/2508.07020)
*Tanjim Bin Faruk,Abdul Matin,Shrideep Pallickara,Sangmi Lee Pallickara*

Main category: cs.CV

TL;DR: 提出了新的高光谱影像编码框架TerraMAE，通过自监督学习处理了超过200个波段的高光谱影像，为地理空间分析提供更精确的表示。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督模型在处理RGB和低波段多光谱数据时表现较好，但在超过200个波段的高光谱影像中无法充分利用复杂的空间-光谱相关性。

Method: 提出TerraMAE框架，采用自适应通道分组策略基于统计反射特性捕捉光谱相似性，并改进重构损失函数以更好地兼顾空间与光谱质量指标。

Result: TerraMAE在高保真影像重构中展示了优越的空间-光谱信息保留能力，并在作物识别、地物分类和土壤质地预测等任务中取得领先表现。

Conclusion: TerraMAE能够高效学习高光谱图像的空间-光谱嵌入，具有实际地理空间任务的应用价值。

Abstract: Hyperspectral satellite imagery offers sub-30 m views of Earth in hundreds of
contiguous spectral bands, enabling fine-grained mapping of soils, crops, and
land cover. While self-supervised Masked Autoencoders excel on RGB and low-band
multispectral data, they struggle to exploit the intricate spatial-spectral
correlations in 200+ band hyperspectral images. We introduce TerraMAE, a novel
HSI encoding framework specifically designed to learn highly representative
spatial-spectral embeddings for diverse geospatial analyses. TerraMAE features
an adaptive channel grouping strategy, based on statistical reflectance
properties to capture spectral similarities, and an enhanced reconstruction
loss function that incorporates spatial and spectral quality metrics. We
demonstrate TerraMAE's effectiveness through superior spatial-spectral
information preservation in high-fidelity image reconstruction. Furthermore, we
validate its practical utility and the quality of its learned representations
through strong performance on three key downstream geospatial tasks: crop
identification, land cover classification, and soil texture prediction.

</details>


### [64] [DocRefine: An Intelligent Framework for Scientific Document Understanding and Content Optimization based on Multimodal Large Model Agents](https://arxiv.org/abs/2508.07021)
*Kun Qian,Wenjie Li,Tianyu Sun,Wenhong Wang,Wenhan Luo*

Main category: cs.CV

TL;DR: 本文提出了DocRefine，一个用于科学PDF文档智能理解、内容优化和自动摘要的创新框架，通过自然语言指令驱动并利用多代理系统解决复杂文档问题，其表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理科学文献中复杂的布局和多模态内容，且直接应用LLMs和LVLMs缺乏精确性和针对性。

Method: 构建了一个由6个专项协作代理组成的多代理系统，包括布局分析、多模态理解等模块，并通过闭环反馈机制保证高语义准确性和视觉一致性。

Result: 在DocEditBench数据集上，DocRefine在多个任务上优于现有方法，取得86.7%的语义一致性分数（SCS）、93.9%的布局保真度指数（LFI）以及85.0%的指令遵循率（IAR）。

Conclusion: DocRefine在复杂多模态文档编辑中展示了卓越的能力，对科学文档的自动化处理是一次显著的进步。

Abstract: The exponential growth of scientific literature in PDF format necessitates
advanced tools for efficient and accurate document understanding,
summarization, and content optimization. Traditional methods fall short in
handling complex layouts and multimodal content, while direct application of
Large Language Models (LLMs) and Vision-Language Large Models (LVLMs) lacks
precision and control for intricate editing tasks. This paper introduces
DocRefine, an innovative framework designed for intelligent understanding,
content refinement, and automated summarization of scientific PDF documents,
driven by natural language instructions. DocRefine leverages the power of
advanced LVLMs (e.g., GPT-4o) by orchestrating a sophisticated multi-agent
system comprising six specialized and collaborative agents: Layout & Structure
Analysis, Multimodal Content Understanding, Instruction Decomposition, Content
Refinement, Summarization & Generation, and Fidelity & Consistency
Verification. This closed-loop feedback architecture ensures high semantic
accuracy and visual fidelity. Evaluated on the comprehensive DocEditBench
dataset, DocRefine consistently outperforms state-of-the-art baselines across
various tasks, achieving overall scores of 86.7% for Semantic Consistency Score
(SCS), 93.9% for Layout Fidelity Index (LFI), and 85.0% for Instruction
Adherence Rate (IAR). These results demonstrate DocRefine's superior capability
in handling complex multimodal document editing, preserving semantic integrity,
and maintaining visual consistency, marking a significant advancement in
automated scientific document processing.

</details>


### [65] [MV-CoRe: Multimodal Visual-Conceptual Reasoning for Complex Visual Question Answering](https://arxiv.org/abs/2508.07023)
*Jingwei Peng,Jiehao Chen,Mateo Alejandro Rojas,Meilin Zhang*

Main category: cs.CV

TL;DR: 提出了一个名为MV-CoRe的新模型，通过深度融合多模态特征提升Complex VQA任务性能并在多个基准上取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型在处理需要复杂多模态推理的Complex VQA任务时表现有限，因此需要一个能够更好整合视觉和语言信息的模型。

Method: MV-CoRe模型通过整合预训练的视觉大型模型和语言大型模型的全局嵌入以及加入包含对象检测特征和场景图表征的细粒度视觉特征，并通过多模态融合Transformer深度集成这些特征以实现复杂推理。

Result: 在GQA、A-OKVQA和OKVQA等复杂视觉问答基准上，MV-CoRe表现优异，在GQA基准上达到77.5%的总体准确率。消融实验和人类评估证实模型在事实准确性和推理深度上的优势。

Conclusion: MV-CoRe模型在结合多模态视觉-概念理解方面展现出强大的能力，为复杂VQA任务提供了新的解决方案。

Abstract: Complex Visual Question Answering (Complex VQA) tasks, which demand
sophisticated multi-modal reasoning and external knowledge integration, present
significant challenges for existing large vision-language models (LVLMs) often
limited by their reliance on high-level global features. To address this, we
propose MV-CoRe (Multimodal Visual-Conceptual Reasoning), a novel model
designed to enhance Complex VQA performance through the deep fusion of diverse
visual and linguistic information. MV-CoRe meticulously integrates global
embeddings from pre-trained Vision Large Models (VLMs) and Language Large
Models (LLMs) with fine-grained semantic-aware visual features, including
object detection characteristics and scene graph representations. An innovative
Multimodal Fusion Transformer then processes and deeply integrates these
diverse feature sets, enabling rich cross-modal attention and facilitating
complex reasoning. We evaluate MV-CoRe on challenging Complex VQA benchmarks,
including GQA, A-OKVQA, and OKVQA, after training on VQAv2. Our experimental
results demonstrate that MV-CoRe consistently outperforms established LVLM
baselines, achieving an overall accuracy of 77.5% on GQA. Ablation studies
confirm the critical contribution of both object and scene graph features, and
human evaluations further validate MV-CoRe's superior factual correctness and
reasoning depth, underscoring its robust capabilities for deep visual and
conceptual understanding.

</details>


### [66] [Large Language Model Evaluated Stand-alone Attention-Assisted Graph Neural Network with Spatial and Structural Information Interaction for Precise Endoscopic Image Segmentation](https://arxiv.org/abs/2508.07028)
*Juntong Fan,Shuyi Fan,Debesh Jha,Changsheng Fang,Tieyong Zeng,Hengyong Yu,Dayang Wang*

Main category: cs.CV

TL;DR: FOCUS-Med是一个用于内窥镜图像息肉分割的模型，利用图卷积网络捕捉空间和拓扑结构依赖，结合注意力机制和多尺度融合策略，提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 提高息肉分割的准确性，以助力早期结直肠癌发现，解决低对比度、镜面反光和边界模糊性等难题。

Method: 提出FOCUS-Med模型，融合Dual-GCN模块捕捉空间和拓扑结构依赖，加入自注意力机制增强全局上下文整合，同时通过可训练快速归一化融合策略优化多尺度特征聚合。

Result: 在多个公开基准测试中，FOCUS-Med在五项关键评估指标上取得了最新的性能，展示了其在临床中的应用潜力。

Conclusion: FOCUS-Med模型有效提高了内窥镜息肉分割精度，具有重要的临床意义，且首次结合大语言模型进行定性评估。

Abstract: Accurate endoscopic image segmentation on the polyps is critical for early
colorectal cancer detection. However, this task remains challenging due to low
contrast with surrounding mucosa, specular highlights, and indistinct
boundaries. To address these challenges, we propose FOCUS-Med, which stands for
Fusion of spatial and structural graph with attentional context-aware polyp
segmentation in endoscopic medical imaging. FOCUS-Med integrates a Dual Graph
Convolutional Network (Dual-GCN) module to capture contextual spatial and
topological structural dependencies. This graph-based representation enables
the model to better distinguish polyps from background tissues by leveraging
topological cues and spatial connectivity, which are often obscured in raw
image intensities. It enhances the model's ability to preserve boundaries and
delineate complex shapes typical of polyps. In addition, a location-fused
stand-alone self-attention is employed to strengthen global context
integration. To bridge the semantic gap between encoder-decoder layers, we
incorporate a trainable weighted fast normalized fusion strategy for efficient
multi-scale aggregation. Notably, we are the first to introduce the use of a
Large Language Model (LLM) to provide detailed qualitative evaluations of
segmentation quality. Extensive experiments on public benchmarks demonstrate
that FOCUS-Med achieves state-of-the-art performance across five key metrics,
underscoring its effectiveness and clinical potential for AI-assisted
colonoscopy.

</details>


### [67] [TeSO: Representing and Compressing 3D Point Cloud Scenes with Textured Surfel Octree](https://arxiv.org/abs/2508.07083)
*Yueyu Hu,Ran Gong,Tingyu Fan,Yao Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Textured Surfel Octree (TeSO)的3D表示方法，旨在平衡高质量渲染和高效压缩需求。


<details>
  <summary>Details</summary>
Motivation: 当前3D表示方法（如点云、网格、3D高斯）在渲染质量、表面定义和可压缩性方面存在局限性，针对这一问题需要一个能生成高质量渲染且可高效压缩的多功能3D表示方法。

Method: 作者提出了基于点云构建的TeSO方法，该方法利用八叉树组织场景，将3D场景表示为带纹理贴图的surfels（表面单元）。通过在八叉树较粗层次用大surfels近似光滑表面，减少必要的原始数量，同时保留高频纹理细节，并提出了基于八叉树结构的压缩方案。

Result: 与多种基于点云和3D高斯的现有方法相比，TeSO结合其压缩方案，在更低码率下实现了更高的渲染质量。

Conclusion: TeSO实现了3D场景表示中渲染质量与压缩效率的平衡，为3D可视化内容流媒体技术提供了更优解。

Abstract: 3D visual content streaming is a key technology for emerging 3D telepresence
and AR/VR applications. One fundamental element underlying the technology is a
versatile 3D representation that is capable of producing high-quality renders
and can be efficiently compressed at the same time. Existing 3D representations
like point clouds, meshes and 3D Gaussians each have limitations in terms of
rendering quality, surface definition, and compressibility. In this paper, we
present the Textured Surfel Octree (TeSO), a novel 3D representation that is
built from point clouds but addresses the aforementioned limitations. It
represents a 3D scene as cube-bounded surfels organized on an octree, where
each surfel is further associated with a texture patch. By approximating a
smooth surface with a large surfel at a coarser level of the octree, it reduces
the number of primitives required to represent the 3D scene, and yet retains
the high-frequency texture details through the texture map attached to each
surfel. We further propose a compression scheme to encode the geometry and
texture efficiently, leveraging the octree structure. The proposed textured
surfel octree combined with the compression scheme achieves higher rendering
quality at lower bit-rates compared to multiple point cloud and 3D
Gaussian-based baselines.

</details>


### [68] [ForeSight: Multi-View Streaming Joint Object Detection and Trajectory Forecasting](https://arxiv.org/abs/2508.07089)
*Sandro Papais,Letian Wang,Brian Cheong,Steven L. Waslander*

Main category: cs.CV

TL;DR: 提出ForeSight，一种用于自动驾驶车辆视觉3D感知的联合检测与预测框架，提高了时空一致性和性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法中，检测与预测被视为独立任务，无法充分利用时间线索。需要一种整合方法来提高任务性能。

Method: ForeSight采用多任务流式传播和双向学习，检测与预测共享查询记忆，结合多假设预测队列和流式预测变换器，摆脱显式目标关联，提升效率和准确性。

Result: 在nuScenes数据集上表现优异，EPA达54.9%，超出现有方法9.3%，并在mAP和minADE方面达到最佳。

Conclusion: ForeSight有效地结合了检测与预测任务，表现出卓越的时空感知能力，适合推广到多帧序列处理。

Abstract: We introduce ForeSight, a novel joint detection and forecasting framework for
vision-based 3D perception in autonomous vehicles. Traditional approaches treat
detection and forecasting as separate sequential tasks, limiting their ability
to leverage temporal cues. ForeSight addresses this limitation with a
multi-task streaming and bidirectional learning approach, allowing detection
and forecasting to share query memory and propagate information seamlessly. The
forecast-aware detection transformer enhances spatial reasoning by integrating
trajectory predictions from a multiple hypothesis forecast memory queue, while
the streaming forecast transformer improves temporal consistency using past
forecasts and refined detections. Unlike tracking-based methods, ForeSight
eliminates the need for explicit object association, reducing error propagation
with a tracking-free model that efficiently scales across multi-frame
sequences. Experiments on the nuScenes dataset show that ForeSight achieves
state-of-the-art performance, achieving an EPA of 54.9%, surpassing previous
methods by 9.3%, while also attaining the best mAP and minADE among multi-view
detection and forecasting models.

</details>


### [69] [Communication-Efficient Multi-Agent 3D Detection via Hybrid Collaboration](https://arxiv.org/abs/2508.07092)
*Yue Hu,Juntong Peng,Yunqiao Yang,Siheng Chen*

Main category: cs.CV

TL;DR: 提出了一种新的混合协作方法，平衡了3D检测中的检测性能与通信带宽问题。


<details>
  <summary>Details</summary>
Motivation: 为了在3D检测中实现更高性能并减少通信开销，解决带宽瓶颈问题。

Method: 提出HyComm系统，结合了感知输出与原始观测两种信息类型，通过自适应方法选择关键信息，支持可变压缩率和标准化数据格式。

Result: 在DAIR-V2X和OPV2V数据集上验证了HyComm，在通信体积减少超过2006倍的情况下仍优于现有方法。

Conclusion: HyComm以较低的通信成本实现了优异的检测性能，并具备不同模型间的适配性，优化了性能与带宽的平衡。

Abstract: Collaborative 3D detection can substantially boost detection performance by
allowing agents to exchange complementary information. It inherently results in
a fundamental trade-off between detection performance and communication
bandwidth. To tackle this bottleneck issue, we propose a novel hybrid
collaboration that adaptively integrates two types of communication messages:
perceptual outputs, which are compact, and raw observations, which offer richer
information. This approach focuses on two key aspects: i) integrating
complementary information from two message types and ii) prioritizing the most
critical data within each type. By adaptively selecting the most critical set
of messages, it ensures optimal perceptual information and adaptability,
effectively meeting the demands of diverse communication scenarios.Building on
this hybrid collaboration, we present \texttt{HyComm}, a
communication-efficient LiDAR-based collaborative 3D detection system.
\texttt{HyComm} boasts two main benefits: i) it facilitates adaptable
compression rates for messages, addressing various communication requirements,
and ii) it uses standardized data formats for messages. This ensures they are
independent of specific detection models, fostering adaptability across
different agent configurations. To evaluate HyComm, we conduct experiments on
both real-world and simulation datasets: DAIR-V2X and OPV2V. HyComm
consistently outperforms previous methods and achieves a superior
performance-bandwidth trade-off regardless of whether agents use the same or
varied detection models. It achieves a lower communication volume of more than
2,006$\times$ and still outperforms Where2comm on DAIR-V2X in terms of AP50.
The related code will be released.

</details>


### [70] [AugLift: Boosting Generalization in Lifting-based 3D Human Pose Estimation](https://arxiv.org/abs/2508.07112)
*Nikolai Warner,Wenjin Zhang,Irfan Essa,Apaar Sadhwani*

Main category: cs.CV

TL;DR: 提出一种改进3D人体姿态估计通用性的简单方法AugLift，通过增强输入数据而无须额外数据收集，实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于lifting的3D人体姿态估计方法在新数据集和真实环境中表现不佳，需要提升其泛化能力。

Method: AugLift通过增加关键点检测置信度得分和深度估计等稀疏增强信号，扩展标准的2D关键点输入，同时利用已有预训练模型的强泛化能力，作为模块化附加组件集成到现有lifting结构中。

Result: 在四个数据集上测试显示，AugLift模型在未见数据集上的表现平均提高10.1%，在原数据分布中的性能亦提升4.0%。

Conclusion: AugLift提供了一种增强lifting模型泛化能力的简单实用方法，具有显著提升性能的潜力，且适用于任何lifting架构。

Abstract: Lifting-based methods for 3D Human Pose Estimation (HPE), which predict 3D
poses from detected 2D keypoints, often generalize poorly to new datasets and
real-world settings. To address this, we propose \emph{AugLift}, a simple yet
effective reformulation of the standard lifting pipeline that significantly
improves generalization performance without requiring additional data
collection or sensors. AugLift sparsely enriches the standard input -- the 2D
keypoint coordinates $(x, y)$ -- by augmenting it with a keypoint detection
confidence score $c$ and a corresponding depth estimate $d$. These additional
signals are computed from the image using off-the-shelf, pre-trained models
(e.g., for monocular depth estimation), thereby inheriting their strong
generalization capabilities. Importantly, AugLift serves as a modular add-on
and can be readily integrated into existing lifting architectures.
  Our extensive experiments across four datasets demonstrate that AugLift
boosts cross-dataset performance on unseen datasets by an average of $10.1\%$,
while also improving in-distribution performance by $4.0\%$. These gains are
consistent across various lifting architectures, highlighting the robustness of
our method. Our analysis suggests that these sparse, keypoint-aligned cues
provide robust frame-level context, offering a practical way to significantly
improve the generalization of any lifting-based pose estimation model. Code
will be made publicly available.

</details>


### [71] [Perceptual Evaluation of GANs and Diffusion Models for Generating X-rays](https://arxiv.org/abs/2508.07128)
*Gregory Schuit,Denis Parra,Cecilia Besa*

Main category: cs.CV

TL;DR: 研究了GANs和DMs在生成具有特定异常胸部X光图像能力上的表现，发现两者各有优势，指出生成图像的视觉缺陷需要进一步优化。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像数据匮乏，尤其是低发病率异常相关数据稀缺的问题，提升AI诊断和分割工具性能。

Method: 评估GANs和DMs在生成包含四种异常（AT, LO, PE, ECS）胸部X光图像的能力，通过MIMIC-CXR数据集进行对比研究，并邀请不同经验的三位放射科医生进行阅读研究。

Result: DMs整体上生成的图像视觉真实度更高，但GANs在某些特定病况（如无ECS）情况下表现更优；研究还总结了放射科医生检测图像是否为合成的直观线索。

Conclusion: GANs和DMs在生成医学影像上具有互补优势，但需进一步改进以确保生成模型能可靠增强AI诊断系统的训练数据集。

Abstract: Generative image models have achieved remarkable progress in both natural and
medical imaging. In the medical context, these techniques offer a potential
solution to data scarcity-especially for low-prevalence anomalies that impair
the performance of AI-driven diagnostic and segmentation tools. However,
questions remain regarding the fidelity and clinical utility of synthetic
images, since poor generation quality can undermine model generalizability and
trust. In this study, we evaluate the effectiveness of state-of-the-art
generative models-Generative Adversarial Networks (GANs) and Diffusion Models
(DMs)-for synthesizing chest X-rays conditioned on four abnormalities:
Atelectasis (AT), Lung Opacity (LO), Pleural Effusion (PE), and Enlarged
Cardiac Silhouette (ECS). Using a benchmark composed of real images from the
MIMIC-CXR dataset and synthetic images from both GANs and DMs, we conducted a
reader study with three radiologists of varied experience. Participants were
asked to distinguish real from synthetic images and assess the consistency
between visual features and the target abnormality. Our results show that while
DMs generate more visually realistic images overall, GANs can report better
accuracy for specific conditions, such as absence of ECS. We further identify
visual cues radiologists use to detect synthetic images, offering insights into
the perceptual gaps in current models. These findings underscore the
complementary strengths of GANs and DMs and point to the need for further
refinement to ensure generative models can reliably augment training datasets
for AI diagnostic systems.

</details>


### [72] [CMAMRNet: A Contextual Mask-Aware Network Enhancing Mural Restoration Through Comprehensive Mask Guidance](https://arxiv.org/abs/2508.07140)
*Yingtie Lei,Fanghai Yi,Yihang Dong,Weihuang Liu,Xiaofeng Zhang,Zimeng Li,Chi-Man Pun,Xuhang Chen*

Main category: cs.CV

TL;DR: 提出了一种名为CMAMRNet的方法，用于实现数字壁画的高效修复，并在基准数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于环境及人为因素，壁画不断恶化，而数字修复的复杂性和对艺术真实性的保护构成了挑战，现有方法在受损区域关注度和一致性上存在不足。

Method: 提出了CMAMRNet框架，包含两大核心组件：(1) Mask-Aware Up/Down-Sampler (MAUDS)，通过通道特征选择和掩模引导的特征融合，在多个分辨率尺度上保持一致的掩模敏感性；(2) Co-Feature Aggregator (CFA)，在最高和最低分辨率处提取互补特征，以捕获受损区域的细致纹理及全局结构。

Result: 在基准数据集上，CMAMRNet比现有顶尖方法表现更优，能够有效保留壁画的结构完整性和艺术细节。

Conclusion: CMAMRNet为壁画的数字修复提供了一种表现优异的解决方案，并释放代码以促进后续研究。

Abstract: Murals, as invaluable cultural artifacts, face continuous deterioration from
environmental factors and human activities. Digital restoration of murals faces
unique challenges due to their complex degradation patterns and the critical
need to preserve artistic authenticity. Existing learning-based methods
struggle with maintaining consistent mask guidance throughout their networks,
leading to insufficient focus on damaged regions and compromised restoration
quality. We propose CMAMRNet, a Contextual Mask-Aware Mural Restoration Network
that addresses these limitations through comprehensive mask guidance and
multi-scale feature extraction. Our framework introduces two key components:
(1) the Mask-Aware Up/Down-Sampler (MAUDS), which ensures consistent mask
sensitivity across resolution scales through dedicated channel-wise feature
selection and mask-guided feature fusion; and (2) the Co-Feature Aggregator
(CFA), operating at both the highest and lowest resolutions to extract
complementary features for capturing fine textures and global structures in
degraded regions. Experimental results on benchmark datasets demonstrate that
CMAMRNet outperforms state-of-the-art methods, effectively preserving both
structural integrity and artistic details in restored murals. The code is
available
at~\href{https://github.com/CXH-Research/CMAMRNet}{https://github.com/CXH-Research/CMAMRNet}.

</details>


### [73] [Dynamic Pattern Alignment Learning for Pretraining Lightweight Human-Centric Vision Models](https://arxiv.org/abs/2508.07144)
*Xuanhan Wang,Huimin Deng,Ke Liu,Jun Wang,Lianli Gao,Jingkuan Song*

Main category: cs.CV

TL;DR: 本文提出了一种名为DPAL的蒸馏预训练框架，旨在高效训练轻量级人类视觉模型（HVMs），以从大规模HVMs中获得强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 目前的人类视觉模型依赖于大规模架构和有限的预训练数据，制约了其实用性。本文旨在提出一种高效的轻量级训练方法，克服这些限制。

Method: 提出DPAL框架，包括一个动态模式解码器(D-PaDe)和三层对齐目标，分别在全局图像级、局部像素级和实例关系级上进行对齐。通过这两个设计让轻量级模型更广泛地学习视觉模式。

Result: 实验表明，DPAL-ViT/Ti（5M参数）在多个任务中表现出与大规模HVMs相当的泛化能力，并超越现有蒸馏预训练方法如Proteus-ViT/Ti和TinyMiM-ViT/Ti。

Conclusion: DPAL方法有效指导轻量级HVMs泛化到多种人类视觉任务，是一种高效且实用的框架。

Abstract: Human-centric vision models (HVMs) have achieved remarkable generalization
due to large-scale pretraining on massive person images. However, their
dependence on large neural architectures and the restricted accessibility of
pretraining data significantly limits their practicality in real-world
applications. To address this limitation, we propose Dynamic Pattern Alignment
Learning (DPAL), a novel distillation-based pretraining framework that
efficiently trains lightweight HVMs to acquire strong generalization from large
HVMs. In particular, human-centric visual perception are highly dependent on
three typical visual patterns, including global identity pattern, local shape
pattern and multi-person interaction pattern. To achieve generalizable
lightweight HVMs, we firstly design a dynamic pattern decoder (D-PaDe), acting
as a dynamic Mixture of Expert (MoE) model. It incorporates three specialized
experts dedicated to adaptively extract typical visual patterns, conditioned on
both input image and pattern queries. And then, we present three levels of
alignment objectives, which aims to minimize generalization gap between
lightweight HVMs and large HVMs at global image level, local pixel level, and
instance relation level. With these two deliberate designs, the DPAL
effectively guides lightweight model to learn all typical human visual patterns
from large HVMs, which can generalize to various human-centric vision tasks.
Extensive experiments conducted on 15 challenging datasets demonstrate the
effectiveness of the DPAL. Remarkably, when employing PATH-B as the teacher,
DPAL-ViT/Ti (5M parameters) achieves surprising generalizability similar to
existing large HVMs such as PATH-B (84M) and Sapiens-L (307M), and outperforms
previous distillation-based pretraining methods including Proteus-ViT/Ti (5M)
and TinyMiM-ViT/Ti (5M) by a large margin.

</details>


### [74] [Intention-Aware Diffusion Model for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2508.07146)
*Yu Liu,Zhijie Liu,Xiao Ren,You-Fu Li,He Kong*

Main category: cs.CV

TL;DR: 本文提出了一个基于扩散理论的行人轨迹预测框架，通过引入短期和长期运动意图建模，提升了预测精度，实验表明其性能优于许多现有方法。


<details>
  <summary>Details</summary>
Motivation: 行人运动轨迹预测对自动驾驶路径规划和运动控制至关重要。然而，现有的许多基于扩散的方法缺乏对行人意图的显式语义建模，可能导致行为误解和预测精度下降。

Method: 框架通过残差极坐标表征对短期意图进行建模，以分离方向和幅度捕获局部运动模式；利用基于学习的令牌化终点预测器估算长期意图，生成多候选目标及其概率；并通过自适应引导和残差噪声预测器提升扩散过程的去噪精度。

Result: 在ETH、UCY和SDD基准上测试，验证了模型在多模态和上下文感知意图建模中的竞争力，并在与现有方法的比较中表现优异。

Conclusion: 引入短期和长期意图建模提升了扩散模型在行人轨迹预测中的准确性，有望促进自动驾驶相关领域的发展。

Abstract: Predicting pedestrian motion trajectories is critical for the path planning
and motion control of autonomous vehicles. Recent diffusion-based models have
shown promising results in capturing the inherent stochasticity of pedestrian
behavior for trajectory prediction. However, the absence of explicit semantic
modelling of pedestrian intent in many diffusion-based methods may result in
misinterpreted behaviors and reduced prediction accuracy. To address the above
challenges, we propose a diffusion-based pedestrian trajectory prediction
framework that incorporates both short-term and long-term motion intentions.
Short-term intent is modelled using a residual polar representation, which
decouples direction and magnitude to capture fine-grained local motion
patterns. Long-term intent is estimated through a learnable, token-based
endpoint predictor that generates multiple candidate goals with associated
probabilities, enabling multimodal and context-aware intention modelling.
Furthermore, we enhance the diffusion process by incorporating adaptive
guidance and a residual noise predictor that dynamically refines denoising
accuracy. The proposed framework is evaluated on the widely used ETH, UCY, and
SDD benchmarks, demonstrating competitive results against state-of-the-art
methods.

</details>


### [75] [SketchAnimator: Animate Sketch via Motion Customization of Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.07149)
*Ruolin Yang,Da Li,Honggang Zhang,Yi-Zhe Song*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的草图动画模型SketchAnimator，可以基于输入草图和参考视频生成具有动态动作的草图视频。


<details>
  <summary>Details</summary>
Motivation: 激发静态草图的生命力，为设计师提供表达创意的新维度；同时降低草图动画制作门槛，为业余爱好者提供更简单的工具。

Method: 提出了三阶段的草图动画生成方法，包括外观学习、动作学习和视频先验蒸馏。利用LoRA整合草图外观信息和参考视频中的动作动态，并通过Score Distillation Sampling（SDS）调整Bezier曲线参数来实现动画生成。

Result: 模型在保持草图外观的同时，以一键信息定制方式生成符合参考视频动态的草图动画，实验表明相比其他方法有更好的生成效果。

Conclusion: SketchAnimator有效降低了草图动画制作的复杂度，为业余用户和专业设计师提供了一个无需专门技能即可生成动画草图的新工具，并展现了优异的生成效果。

Abstract: Sketching is a uniquely human tool for expressing ideas and creativity. The
animation of sketches infuses life into these static drawings, opening a new
dimension for designers. Animating sketches is a time-consuming process that
demands professional skills and extensive experience, often proving daunting
for amateurs. In this paper, we propose a novel sketch animation model
SketchAnimator, which enables adding creative motion to a given sketch, like "a
jumping car''. Namely, given an input sketch and a reference video, we divide
the sketch animation into three stages: Appearance Learning, Motion Learning
and Video Prior Distillation. In stages 1 and 2, we utilize LoRA to integrate
sketch appearance information and motion dynamics from the reference video into
the pre-trained T2V model. In the third stage, we utilize Score Distillation
Sampling (SDS) to update the parameters of the Bezier curves in each sketch
frame according to the acquired motion information. Consequently, our model
produces a sketch video that not only retains the original appearance of the
sketch but also mirrors the dynamic movements of the reference video. We
compare our method with alternative approaches and demonstrate that it
generates the desired sketch video under the challenge of one-shot motion
customization.

</details>


### [76] [CoopDiff: Anticipating 3D Human-object Interactions via Contact-consistent Decoupled Diffusion](https://arxiv.org/abs/2508.07162)
*Xiaotong Lin,Tianming Liang,Jian-Fang Hu,Kun-Yu Lin,Yulei Kang,Chunwei Tian,Jianhuang Lai,Wei-Shi Zheng*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的接触一致性解耦扩散框架CoopDiff，通过两个分支分别建模人和物体的运动，同时使用共享的接触点作为桥梁，实现一致的人-物运动预测。


<details>
  <summary>Details</summary>
Motivation: 大多数现有方法未区分人体和物体的不同运动模式，而试图通过单一模型捕捉二者的动态，这忽略了其固有的物理属性差异。

Method: 提出CoopDiff框架，使用解耦分支分别预测人体和物体的运动，并通过共享接触点连接两者。人体分支预测结构化的人体运动，物体分支关注刚性平移与旋转，加入一致性约束和人驱动的交互模块以提高一致性与可靠性。

Result: 在BEHAVE和Human-object Interaction数据集上，CoopDiff优于现有最先进方法，表现更佳。

Conclusion: 通过解耦建模和一致性约束，CoopDiff有效改善了人-物交互预测的效果，为该领域提供了新思路。

Abstract: 3D human-object interaction (HOI) anticipation aims to predict the future
motion of humans and their manipulated objects, conditioned on the historical
context. Generally, the articulated humans and rigid objects exhibit different
motion patterns, due to their distinct intrinsic physical properties. However,
this distinction is ignored by most of the existing works, which intend to
capture the dynamics of both humans and objects within a single prediction
model. In this work, we propose a novel contact-consistent decoupled diffusion
framework CoopDiff, which employs two distinct branches to decouple human and
object motion modeling, with the human-object contact points as shared anchors
to bridge the motion generation across branches. The human dynamics branch is
aimed to predict highly structured human motion, while the object dynamics
branch focuses on the object motion with rigid translations and rotations.
These two branches are bridged by a series of shared contact points with
consistency constraint for coherent human-object motion prediction. To further
enhance human-object consistency and prediction reliability, we propose a
human-driven interaction module to guide object motion modeling. Extensive
experiments on the BEHAVE and Human-object Interaction datasets demonstrate
that our CoopDiff outperforms state-of-the-art methods.

</details>


### [77] [Lightweight Multi-Scale Feature Extraction with Fully Connected LMF Layer for Salient Object Detection](https://arxiv.org/abs/2508.07170)
*Yunpeng Shi,Lei Chen,Xiaolu Shen,Yanju Guo*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级多尺度特征提取层（LMF层），并基于其开发了名为LMFNet的网络，用于显著性目标检测，参数量仅为0.81M，性能优异。


<details>
  <summary>Details</summary>
Motivation: 解决轻量级网络中多尺度特征学习的效率与性能之间的平衡问题。

Method: 提出了LMF层，采用深度可分离膨胀卷积，并将其集成到一个轻量网络LMFNet中。

Result: LMFNet在五个基准数据集上实现了前沿或可比较的结果，仅需0.81M的参数量，在效率和精度上优于多个传统和轻量化模型。

Conclusion: LMFNet在保持轻量化的同时实现了高效的多尺度特征学习，具有良好的应用潜力和实用价值。

Abstract: In the domain of computer vision, multi-scale feature extraction is vital for
tasks such as salient object detection. However, achieving this capability in
lightweight networks remains challenging due to the trade-off between
efficiency and performance. This paper proposes a novel lightweight multi-scale
feature extraction layer, termed the LMF layer, which employs depthwise
separable dilated convolutions in a fully connected structure. By integrating
multiple LMF layers, we develop LMFNet, a lightweight network tailored for
salient object detection. Our approach significantly reduces the number of
parameters while maintaining competitive performance. Here, we show that LMFNet
achieves state-of-the-art or comparable results on five benchmark datasets with
only 0.81M parameters, outperforming several traditional and lightweight models
in terms of both efficiency and accuracy. Our work not only addresses the
challenge of multi-scale learning in lightweight networks but also demonstrates
the potential for broader applications in image processing tasks. The related
code files are available at https://github.com/Shi-Yun-peng/LMFNet

</details>


### [78] [EventRR: Event Referential Reasoning for Referring Video Object Segmentation](https://arxiv.org/abs/2508.07171)
*Huihui Xu,Jiashi Lin,Haoyu Chen,Junjun He,Lei Zhu*

Main category: cs.CV

TL;DR: 本文介绍了一种名为Event Referential Reasoning (EventRR)的新框架，用于视频语言分割任务。该框架通过引入视频事件的语义结构，显著提升了分割精度。


<details>
  <summary>Details</summary>
Motivation: 当前RVOS方法未能充分利用表达式中的语义结构，而视频表达式包含比图像表达式更复杂的事件属性和时间关系，需解决这些复杂性。

Method: 提出EventRR框架，分离对象总结和指代推理两部分。通过视频级别的总结步骤获得全局跨模态时间上下文，并借助Referential Event Graph (REG)进行语义事件结构表达和Temporal Concept-Role Reasoning (TCRR)推理。

Result: 在四个基准数据集的量化和定性实验中优于最先进的RVOS方法。

Conclusion: EventRR通过引入事件语义图和有效的推理机制，为解决复杂的视频语言分割任务提供了一种新的创新性解决方案。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment out the object in
a video referred by an expression. Current RVOS methods view referring
expressions as unstructured sequences, neglecting their crucial semantic
structure essential for referent reasoning. Besides, in contrast to
image-referring expressions whose semantics focus only on object attributes and
object-object relations, video-referring expressions also encompass event
attributes and event-event temporal relations. This complexity challenges
traditional structured reasoning image approaches. In this paper, we propose
the Event Referential Reasoning (EventRR) framework. EventRR decouples RVOS
into object summarization part and referent reasoning part. The summarization
phase begins by summarizing each frame into a set of bottleneck tokens, which
are then efficiently aggregated in the video-level summarization step to
exchange the global cross-modal temporal context. For reasoning part, EventRR
extracts semantic eventful structure of a video-referring expression into
highly expressive Referential Event Graph (REG), which is a single-rooted
directed acyclic graph. Guided by topological traversal of REG, we propose
Temporal Concept-Role Reasoning (TCRR) to accumulate the referring score of
each temporal query from REG leaf nodes to root node. Each reasoning step can
be interpreted as a question-answer pair derived from the concept-role
relations in REG. Extensive experiments across four widely recognized benchmark
datasets, show that EventRR quantitatively and qualitatively outperforms
state-of-the-art RVOS methods. Code is available at
https://github.com/bio-mlhui/EventRR

</details>


### [79] [Similarity Matters: A Novel Depth-guided Network for Image Restoration and A New Dataset](https://arxiv.org/abs/2508.07211)
*Junyi He,Liuling Chen,Hongyang Zhou,Zhang xiaoxing,Xiaobin Zhu,Shengxiang Yu,Jingyan Qin,Xu-Cheng Yin*

Main category: cs.CV

TL;DR: 本文提出了一个名为DGN的深度引导网络用于图像修复，同时还提供了一个全新的大规模高分辨率数据集。实验结果显示，该方法在多个基准测试中表现出色并具有良好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的图像修复方法忽略了景深信息，导致在浅景深场景下注意力分散、深景深场景下背景内容过度增强，因此需要在修复过程中引入深度信息。

Method: 该方法包括两个交互分支：深度估计分支提供结构指导，图像修复分支执行核心修复任务。通过进阶的窗基自注意力和稀疏非局部注意力捕捉物体的内外相似性，并通过联合训练提升修复效果和深度估计能力。

Result: 提出的新方法在多个标准基准上达到了最先进的性能表现，并且在未见植物图像的测试中也表现优异，显示了其有效性和鲁棒性。

Conclusion: 结合深度信息和图像修复任务的新网络框架显著提升了修复效果，同时新数据集为相关研究提供了强大的支持。

Abstract: Image restoration has seen substantial progress in recent years. However,
existing methods often neglect depth information, which hurts similarity
matching, results in attention distractions in shallow depth-of-field (DoF)
scenarios, and excessive enhancement of background content in deep DoF
settings. To overcome these limitations, we propose a novel Depth-Guided
Network (DGN) for image restoration, together with a novel large-scale
high-resolution dataset. Specifically, the network consists of two interactive
branches: a depth estimation branch that provides structural guidance, and an
image restoration branch that performs the core restoration task. In addition,
the image restoration branch exploits intra-object similarity through
progressive window-based self-attention and captures inter-object similarity
via sparse non-local attention. Through joint training, depth features
contribute to improved restoration quality, while the enhanced visual features
from the restoration branch in turn help refine depth estimation. Notably, we
also introduce a new dataset for training and evaluation, consisting of 9,205
high-resolution images from 403 plant species, with diverse depth and texture
variations. Extensive experiments show that our method achieves
state-of-the-art performance on several standard benchmarks and generalizes
well to unseen plant images, demonstrating its effectiveness and robustness.

</details>


### [80] [Unsupervised Real-World Super-Resolution via Rectified Flow Degradation Modelling](https://arxiv.org/abs/2508.07214)
*Hongyang Zhou,Xiaobin Zhu,Liuling Chen,Junyi He,Jingyan Qin,Xu-Cheng Yin,Zhang xiaoxing*

Main category: cs.CV

TL;DR: 提出了一种基于改进流的无监督实际超分辨率方法，有效捕获和建模实际退化问题，并通过生成的实时退化图像训练超分辨率网络，在真实场景中表现显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以从合成的低分辨率和高分辨率图像对推广到真实场景，原因是两者之间存在显著的领域差距，因此需要一种能够有效应对复杂未知退化分布的无监督实际超分辨率方法。

Method: 提出了基于可逆的退化轨迹建模的改进流退化模块（RFDM）和利用傅里叶相位分量结构信息的傅里叶先验导向退化模块（FGDM），生成具有真实退化的合成低分辨率图像，并通过这些图像与高分辨率图像的配对，实现超分辨率网络的训练。

Result: 通过真实场景数据集的大量实验表明，该方法显著提升了现有超分辨率方法在真实场景中的性能。

Conclusion: 本文方法在建模实际退化方面表现优异，拓展了超分辨率方法从合成数据到真实场景数据的应用，提高了无监督实际超分辨率方法的真实场景适应能力。

Abstract: Unsupervised real-world super-resolution (SR) faces critical challenges due
to the complex, unknown degradation distributions in practical scenarios.
Existing methods struggle to generalize from synthetic low-resolution (LR) and
high-resolution (HR) image pairs to real-world data due to a significant domain
gap. In this paper, we propose an unsupervised real-world SR method based on
rectified flow to effectively capture and model real-world degradation,
synthesizing LR-HR training pairs with realistic degradation. Specifically,
given unpaired LR and HR images, we propose a novel Rectified Flow Degradation
Module (RFDM) that introduces degradation-transformed LR (DT-LR) images as
intermediaries. By modeling the degradation trajectory in a continuous and
invertible manner, RFDM better captures real-world degradation and enhances the
realism of generated LR images. Additionally, we propose a Fourier Prior Guided
Degradation Module (FGDM) that leverages structural information embedded in
Fourier phase components to ensure more precise modeling of real-world
degradation. Finally, the LR images are processed by both FGDM and RFDM,
producing final synthetic LR images with real-world degradation. The synthetic
LR images are paired with the given HR images to train the off-the-shelf SR
networks. Extensive experiments on real-world datasets demonstrate that our
method significantly enhances the performance of existing SR approaches in
real-world scenarios.

</details>


### [81] [Bridging Semantic Logic Gaps: A Cognition-Inspired Multimodal Boundary-Preserving Network for Image Manipulation Localization](https://arxiv.org/abs/2508.07216)
*Songlin Li,Zhiqing Guo,Yuanman Li,Zeyu Li,Yunfeng Diao,Gaobo Yang,Liejun Wang*

Main category: cs.CV

TL;DR: 本文提出了一种认知启发的多模态边界保持网络（CMB-Net），通过结合大语言模型（LLMs）与图像语义逻辑关系改进图像篡改定位（IML）。


<details>
  <summary>Details</summary>
Motivation: 现有的IML模型过于依赖视觉线索，忽略了内容特征间的语义逻辑关系，而图像篡改往往破坏内部语义关系，留下篡改线索。

Method: 提出CMB-Net，通过LLMs分析篡改区域并生成基于提示的文本信息，以弥补视觉信息中语义关系的不足；通过ITCAM模块量化图文特征歧义，优化文本特征权重；通过ITIM模块将图像与文本特征对齐，实现精细交互；利用RED模块保护篡改区域边界信息。

Result: 实验结果表明，CMB-Net性能优于大多数现有的IML模型。

Conclusion: 结合多模态信息和认知启发方法，CMB-Net显著提高了图像篡改区域的定位能力，成为现有方法的有效补充。

Abstract: The existing image manipulation localization (IML) models mainly relies on
visual cues, but ignores the semantic logical relationships between content
features. In fact, the content semantics conveyed by real images often conform
to human cognitive laws. However, image manipulation technology usually
destroys the internal relationship between content features, thus leaving
semantic clues for IML. In this paper, we propose a cognition-inspired
multimodal boundary-preserving network (CMB-Net). Specifically, CMB-Net
utilizes large language models (LLMs) to analyze manipulated regions within
images and generate prompt-based textual information to compensate for the lack
of semantic relationships in the visual information. Considering that the
erroneous texts induced by hallucination from LLMs will damage the accuracy of
IML, we propose an image-text central ambiguity module (ITCAM). It assigns
weights to the text features by quantifying the ambiguity between text and
image features, thereby ensuring the beneficial impact of textual information.
We also propose an image-text interaction module (ITIM) that aligns visual and
text features using a correlation matrix for fine-grained interaction. Finally,
inspired by invertible neural networks, we propose a restoration edge decoder
(RED) that mutually generates input and output features to preserve boundary
information in manipulated regions without loss. Extensive experiments show
that CMB-Net outperforms most existing IML models.

</details>


### [82] [Generic Calibration: Pose Ambiguity/Linear Solution and Parametric-hybrid Pipeline](https://arxiv.org/abs/2508.07217)
*Yuqi Han,Qi Cai,Yuanxin Wu*

Main category: cs.CV

TL;DR: 本文提出了一种结合通用与参数化模型的混合相机校准方法，解决了通用校准中的姿态歧义问题，并优化了校准精度。


<details>
  <summary>Details</summary>
Motivation: 当前的相机校准方法存在局限，参数化模型依赖用户经验，选择不当会降低精度，而通用方法流程复杂且不能提供传统内参。

Method: 提出了一种线性求解器和非线性优化方法解决姿态歧义；同时提出了结合通用与参数化模型的混合校准方法，综合二者优点。

Result: 仿真与实际实验结果表明，混合校准方法在多种镜头类型及噪声下表现出色，提升了校准精度与稳定性。

Conclusion: 该方法为复杂场景下的相机校准问题提供了可靠的解决方案，兼顾了精度与适应性。

Abstract: Offline camera calibration techniques typically employ parametric or generic
camera models. Selecting parametric models relies heavily on user experience,
and an inappropriate camera model can significantly affect calibration
accuracy. Meanwhile, generic calibration methods involve complex procedures and
cannot provide traditional intrinsic parameters. This paper reveals a pose
ambiguity in the pose solutions of generic calibration methods that
irreversibly impacts subsequent pose estimation. A linear solver and a
nonlinear optimization are proposed to address this ambiguity issue. Then a
global optimization hybrid calibration method is introduced to integrate
generic and parametric models together, which improves extrinsic parameter
accuracy of generic calibration and mitigates overfitting and numerical
instability in parametric calibration. Simulation and real-world experimental
results demonstrate that the generic-parametric hybrid calibration method
consistently excels across various lens types and noise contamination,
hopefully serving as a reliable and accurate solution for camera calibration in
complex scenarios.

</details>


### [83] [Landmark Guided Visual Feature Extractor for Visual Speech Recognition with Limited Resource](https://arxiv.org/abs/2508.07233)
*Lei Yang,Junshan Jin,Mingyuan Zhang,Yi He,Bofan Chen,Shilin Wang*

Main category: cs.CV

TL;DR: 本文提出一种基于面部标志点的视觉特征提取器，通过结合空间位置及时间信息，提高了对无声视频中语音内容的识别效果，特别是在数据有限和未见过的讲话者场景中表现良好。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习识别方法对视觉干扰敏感，而现有的数据驱动方法需要大量数据与计算资源，亟需一种高效能且对用户特定特征敏感性低的方法。

Method: 设计了基于面部标志点的视觉特征提取器，采用多图卷积网络提取标志点的时空特征，并通过多层次嘴唇动态融合框架，将标志点特征与原始视频特征结合。

Result: 实验表明，该方法在数据有限的情况下表现优越，对未知讲话者的识别准确性也有提高。

Conclusion: 使用面部标志点作为辅助信息是提升视觉语音识别效果的有效途径，尤其适用于数据有限的场景。

Abstract: Visual speech recognition is a technique to identify spoken content in silent
speech videos, which has raised significant attention in recent years.
Advancements in data-driven deep learning methods have significantly improved
both the speed and accuracy of recognition. However, these deep learning
methods can be effected by visual disturbances, such as lightning conditions,
skin texture and other user-specific features. Data-driven approaches could
reduce the performance degradation caused by these visual disturbances using
models pretrained on large-scale datasets. But these methods often require
large amounts of training data and computational resources, making them costly.
To reduce the influence of user-specific features and enhance performance with
limited data, this paper proposed a landmark guided visual feature extractor.
Facial landmarks are used as auxiliary information to aid in training the
visual feature extractor. A spatio-temporal multi-graph convolutional network
is designed to fully exploit the spatial locations and spatio-temporal features
of facial landmarks. Additionally, a multi-level lip dynamic fusion framework
is introduced to combine the spatio-temporal features of the landmarks with the
visual features extracted from the raw video frames. Experimental results show
that this approach performs well with limited data and also improves the
model's accuracy on unseen speakers.

</details>


### [84] [ASM-UNet: Adaptive Scan Mamba Integrating Group Commonalities and Individual Variations for Fine-Grained Segmentation](https://arxiv.org/abs/2508.07237)
*Bo Wang,Mengyuan Xu,Yue Yan,Yuqun Yang,Kechen Shu,Wei Ping,Xu Tang,Wei Jiang,Zheng You*

Main category: cs.CV

TL;DR: 该研究提出ASM-UNet框架，提高了医学图像的细粒度分割性能。


<details>
  <summary>Details</summary>
Motivation: 目标是解决现有分割方法在细粒度解剖结构分割中的不足。

Method: 提出ASM-UNet，通过自适应扫描评分动态引导分割序列，结合群体共性和个体变异。

Result: 在ACDC、Synapse和新提出的BTMS数据集上，ASM-UNet在粗粒度和细粒度分割任务中表现优异。

Conclusion: ASM-UNet框架为医学图像分割提供了一种新方法，有望应用于真实医疗场景。

Abstract: Precise lesion resection depends on accurately identifying fine-grained
anatomical structures. While many coarse-grained segmentation (CGS) methods
have been successful in large-scale segmentation (e.g., organs), they fall
short in clinical scenarios requiring fine-grained segmentation (FGS), which
remains challenging due to frequent individual variations in small-scale
anatomical structures. Although recent Mamba-based models have advanced medical
image segmentation, they often rely on fixed manually-defined scanning orders,
which limit their adaptability to individual variations in FGS. To address
this, we propose ASM-UNet, a novel Mamba-based architecture for FGS. It
introduces adaptive scan scores to dynamically guide the scanning order,
generated by combining group-level commonalities and individual-level
variations. Experiments on two public datasets (ACDC and Synapse) and a newly
proposed challenging biliary tract FGS dataset, namely BTMS, demonstrate that
ASM-UNet achieves superior performance in both CGS and FGS tasks. Our code and
dataset are available at https://github.com/YqunYang/ASM-UNet.

</details>


### [85] [Consistent and Controllable Image Animation with Motion Linear Diffusion Transformers](https://arxiv.org/abs/2508.07246)
*Xin Ma,Yaohui Wang,Genyun Jia,Xinyuan Chen,Tien-Tsin Wong,Cunjian Chen*

Main category: cs.CV

TL;DR: 本文提出了MiraMo，这是一个用于图像动画生成的高效框架，通过结合线性注意力、运动残差学习和基于DCT的降噪策略，提高了动画的生成效率、外观一致性和运动平滑度。


<details>
  <summary>Details</summary>
Motivation: 现有图像动画方法难以保持输入图像的外观一致性，并且生成动画时容易出现突兀的运动过渡，同时在效率方面相比最新的文本到视频生成方法有所不足。

Method: MiraMo框架引入三大关键元素：1）以线性注意力代替传统自注意力，降低计算成本；2）通过运动残差学习建模运动动态，改进时间一致性；3）引入基于DCT的降噪策略，同时实施动态控制模块以平衡运动平滑性与表达性。

Result: MiraMo通过广泛实验验证了其在生成一致、平滑且可控的动画时的优越性，并加速了推理过程，在运动转移和视频编辑等任务中展现了高效性和多功能性。

Conclusion: MiraMo框架成功解决了现有图像动画生成中的重要问题，通过创新方法显著提升了生成效果和效率，为图像动画及相关应用提供了可靠方案。

Abstract: Image animation has seen significant progress, driven by the powerful
generative capabilities of diffusion models. However, maintaining appearance
consistency with static input images and mitigating abrupt motion transitions
in generated animations remain persistent challenges. While text-to-video (T2V)
generation has demonstrated impressive performance with diffusion transformer
models, the image animation field still largely relies on U-Net-based diffusion
models, which lag behind the latest T2V approaches. Moreover, the quadratic
complexity of vanilla self-attention mechanisms in Transformers imposes heavy
computational demands, making image animation particularly resource-intensive.
To address these issues, we propose MiraMo, a framework designed to enhance
efficiency, appearance consistency, and motion smoothness in image animation.
Specifically, MiraMo introduces three key elements: (1) A foundational
text-to-video architecture replacing vanilla self-attention with efficient
linear attention to reduce computational overhead while preserving generation
quality; (2) A novel motion residual learning paradigm that focuses on modeling
motion dynamics rather than directly predicting frames, improving temporal
consistency; and (3) A DCT-based noise refinement strategy during inference to
suppress sudden motion artifacts, complemented by a dynamics control module to
balance motion smoothness and expressiveness. Extensive experiments against
state-of-the-art methods validate the superiority of MiraMo in generating
consistent, smooth, and controllable animations with accelerated inference
speed. Additionally, we demonstrate the versatility of MiraMo through
applications in motion transfer and video editing tasks.

</details>


### [86] [SUIT: Spatial-Spectral Union-Intersection Interaction Network for Hyperspectral Object Tracking](https://arxiv.org/abs/2508.07250)
*Fengchao Xiong,Zhenxing Wu,Sen Jia,Yuntao Qian*

Main category: cs.CV

TL;DR: 本文通过研究光谱交互，提出了一种改进超光谱视频跟踪性能的方法，该方法整合了长距离空间关系和光谱交互，并引入了一种新的光谱损失机制，实验结果表明其具有领先性能。


<details>
  <summary>Details</summary>
Motivation: 目前对超光谱视频的研究主要集中在模板与搜索区域之间的空间交互，忽略了光谱交互，从而导致性能上的不足。

Method: 从架构角度，建立跨所有波段的模板和搜索区域的长距离空间关系，并使用集合论的包含-排除原理建模光谱交互；从训练角度，引入光谱损失以强化模板和预测区域间的材料分布一致性。

Result: 实验表明，该方法在超光谱视频跟踪中达到了领先的性能水平。

Conclusion: 通过结合空间和光谱信息，同时引入新的光谱损失，本文方法在改善形状变形和外观变化的鲁棒性方面展现了优越性，且相关代码已开源以支持研究复现。

Abstract: Hyperspectral videos (HSVs), with their inherent spatial-spectral-temporal
structure, offer distinct advantages in challenging tracking scenarios such as
cluttered backgrounds and small objects. However, existing methods primarily
focus on spatial interactions between the template and search regions, often
overlooking spectral interactions, leading to suboptimal performance. To
address this issue, this paper investigates spectral interactions from both the
architectural and training perspectives. At the architectural level, we first
establish band-wise long-range spatial relationships between the template and
search regions using Transformers. We then model spectral interactions using
the inclusion-exclusion principle from set theory, treating them as the union
of spatial interactions across all bands. This enables the effective
integration of both shared and band-specific spatial cues. At the training
level, we introduce a spectral loss to enforce material distribution alignment
between the template and predicted regions, enhancing robustness to shape
deformation and appearance variations. Extensive experiments demonstrate that
our tracker achieves state-of-the-art tracking performance. The source code,
trained models and results will be publicly available via
https://github.com/bearshng/suit to support reproducibility.

</details>


### [87] [Understanding Dynamic Scenes in Ego Centric 4D Point Clouds](https://arxiv.org/abs/2508.07251)
*Junsheng Huang,Shengyu Hao,Bocheng Hu,Gaoang Wang*

Main category: cs.CV

TL;DR: 本论文介绍了EgoDynamic4D，这是一个聚焦于动态场景理解的新型问题回答(QA)基准，包含高维时空信息及多任务评估，提供了精细的动态场景表示和问答任务。


<details>
  <summary>Details</summary>
Motivation: 目前的主观视角数据集尽管包含动态场景，但缺乏统一的四维注释和针对精细时空推理的评估协议。为此，作者致力于为动态场景提供更高层次的标注和任务推进。

Method: 设计了EgoDynamic4D数据集，包括RGB-D视频、全局唯一实例掩码和4D边界框等，生成了92.7万个带有链式思维(COT)的QA对，同时提出了基于实例感知特征编码和动态信息处理的端到端统一推理框架。

Result: 实验表明，所提出的框架优于现有基线模型，并验证了多模态时间建模对动态场景理解的有效性。

Conclusion: EgoDynamic4D通过创新的数据集标注和任务设计推动了主观视角动态场景理解领域的发展，展示了多模态时空建模的潜力。

Abstract: Understanding dynamic 4D scenes from an egocentric perspective-modeling
changes in 3D spatial structure over time-is crucial for human-machine
interaction, autonomous navigation, and embodied intelligence. While existing
egocentric datasets contain dynamic scenes, they lack unified 4D annotations
and task-driven evaluation protocols for fine-grained spatio-temporal
reasoning, especially on motion of objects and human, together with their
interactions. To address this gap, we introduce EgoDynamic4D, a novel QA
benchmark on highly dynamic scenes, comprising RGB-D video, camera poses,
globally unique instance masks, and 4D bounding boxes. We construct 927K QA
pairs accompanied by explicit Chain-of-Thought (CoT), enabling verifiable,
step-by-step spatio-temporal reasoning. We design 12 dynamic QA tasks covering
agent motion, human-object interaction, trajectory prediction, relation
understanding, and temporal-causal reasoning, with fine-grained,
multidimensional metrics. To tackle these tasks, we propose an end-to-end
spatio-temporal reasoning framework that unifies dynamic and static scene
information, using instance-aware feature encoding, time and camera encoding,
and spatially adaptive down-sampling to compress large 4D scenes into token
sequences manageable by LLMs. Experiments on EgoDynamic4D show that our method
consistently outperforms baselines, validating the effectiveness of multimodal
temporal modeling for egocentric dynamic scene understanding.

</details>


### [88] [Small-Large Collaboration: Training-efficient Concept Personalization for Large VLM using a Meta Personalized Small VLM](https://arxiv.org/abs/2508.07260)
*Sihan Yang,Huitong Ji,Shaolin Lu,Jiayi Chen,Binxiao Xu,Ming Lu,Yuanxing Zhang,Wenhui Dong,Wentao Zhang*

Main category: cs.CV

TL;DR: 为了解决大规模视觉语言模型（VLM）个性化训练成本高，小规模VLM能力有限的问题，提出了一种名为Small-Large Collaboration (SLC) 的新方法，实现了低成本的个性化和更高效的应用扩展。


<details>
  <summary>Details</summary>
Motivation: 目前大规模VLM虽有强大的多模态理解能力，但其高训练成本和访问限制使个性化变得困难；小规模VLM虽然易于个性化但欠缺推理能力。因此需要一种兼顾个性化和高效性能的解决方案。

Method: 提出SLC框架，其中小规模VLM负责生成个性化信息，而大规模模型负责整合个性化信息以提供准确回答；并引入测试时反思策略来避免小规模VLM的潜在幻觉问题。

Result: SLC方法仅需针对大规模VLM训练小规模VLM，节省了成本，并通过各项基准测试证明了其有效性，可用于闭源和开源框架。

Conclusion: SLC框架为大规模VLM的个性化问题提供了一种训练高效且功能强大的解决方案，具有广泛的实际应用潜力，同时首次实现对各种类型VLM的支持。

Abstract: Personalizing Vision-Language Models (VLMs) to transform them into daily
assistants has emerged as a trending research direction. However, leading
companies like OpenAI continue to increase model size and develop complex
designs such as the chain of thought (CoT). While large VLMs are proficient in
complex multi-modal understanding, their high training costs and limited access
via paid APIs restrict direct personalization. Conversely, small VLMs are
easily personalized and freely available, but they lack sufficient reasoning
capabilities. Inspired by this, we propose a novel collaborative framework
named Small-Large Collaboration (SLC) for large VLM personalization, where the
small VLM is responsible for generating personalized information, while the
large model integrates this personalized information to deliver accurate
responses. To effectively incorporate personalized information, we develop a
test-time reflection strategy, preventing the potential hallucination of the
small VLM. Since SLC only needs to train a meta personalized small VLM for the
large VLMs, the overall process is training-efficient. To the best of our
knowledge, this is the first training-efficient framework that supports both
open-source and closed-source large VLMs, enabling broader real-world
personalized applications. We conduct thorough experiments across various
benchmarks and large VLMs to demonstrate the effectiveness of the proposed SLC
framework. The code will be released at https://github.com/Hhankyangg/SLC.

</details>


### [89] [OpenHAIV: A Framework Towards Practical Open-World Learning](https://arxiv.org/abs/2508.07270)
*Xiang Xiang,Qinhao Zhou,Zhuo Xu,Jing Ma,Jiaxin Dai,Yifan Liang,Hanlin Li*

Main category: cs.CV

TL;DR: 提出OpenHAIV框架，结合OOD检测、新类别发现和增量学习，实现模型在开放环境中的自主知识更新。


<details>
  <summary>Details</summary>
Motivation: 开放世界中的现有方法未能同时解决未知类别检测和模型知识更新的问题。

Method: 整合OOD检测、新类别发现和增量不断微调，形成统一流水线框架。

Result: 实现了模型在开放世界环境下自主的知识获取和更新。

Conclusion: OpenHAIV是一种新颖且有效的框架，为开放世界场景中的学习提供了新的解法。

Abstract: Substantial progress has been made in various techniques for open-world
recognition. Out-of-distribution (OOD) detection methods can effectively
distinguish between known and unknown classes in the data, while incremental
learning enables continuous model knowledge updates. However, in open-world
scenarios, these approaches still face limitations. Relying solely on OOD
detection does not facilitate knowledge updates in the model, and incremental
fine-tuning typically requires supervised conditions, which significantly
deviate from open-world settings. To address these challenges, this paper
proposes OpenHAIV, a novel framework that integrates OOD detection, new class
discovery, and incremental continual fine-tuning into a unified pipeline. This
framework allows models to autonomously acquire and update knowledge in
open-world environments. The proposed framework is available at
https://haiv-lab.github.io/openhaiv .

</details>


### [90] [Representation Understanding via Activation Maximization](https://arxiv.org/abs/2508.07281)
*Hongbo Zhu,Angelo Cangelosi*

Main category: cs.CV

TL;DR: 本文提出了一种适用于CNN和ViT的统一特征可视化框架，并通过激活最大化分析DNN的脆弱性与决策边界，证实其在模型解释性上的有效性。


<details>
  <summary>Details</summary>
Motivation: 受神经科学中使用视觉刺激探究生物神经元的研究启发，探讨通过激活最大化理解人工神经网络内部特征表示的潜力。

Method: 提出了一个适用于CNN和ViT的统一特征可视化框架，将特征可视化拓展至中间层，并利用激活最大化生成对抗样本，以揭示潜在的脆弱性和决策边界。

Result: 通过实验表明，该方法在传统CNN和现代ViT中均表现出了有效性、泛化性和解释价值。

Conclusion: 研究为DNN的特征表示可视化和模型解释性提供了更深层次的见解，并揭示了其潜在弱点和决策边界。

Abstract: Understanding internal feature representations of deep neural networks (DNNs)
is a fundamental step toward model interpretability. Inspired by neuroscience
methods that probe biological neurons using visual stimuli, recent deep
learning studies have employed Activation Maximization (AM) to synthesize
inputs that elicit strong responses from artificial neurons. In this work, we
propose a unified feature visualization framework applicable to both
Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). Unlike
prior efforts that predominantly focus on the last output-layer neurons in
CNNs, we extend feature visualization to intermediate layers as well, offering
deeper insights into the hierarchical structure of learned feature
representations. Furthermore, we investigate how activation maximization can be
leveraged to generate adversarial examples, revealing potential vulnerabilities
and decision boundaries of DNNs. Our experiments demonstrate the effectiveness
of our approach in both traditional CNNs and modern ViT, highlighting its
generalizability and interpretive value.

</details>


### [91] [SynMatch: Rethinking Consistency in Medical Image Segmentation with Sparse Annotations](https://arxiv.org/abs/2508.07298)
*Zhiqiang Shen,Peng Cao,Xiaoli Liu,Jinzhu Yang,Osmar R. Zaiane*

Main category: cs.CV

TL;DR: 讨论了弱标注问题并提出SynMatch框架，通过图像合成代替伪标签改进，提升医学图像分割在有限标签条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习医学图像分割中标注数据稀缺和伪标签与无标注图像一致性不足的问题。

Method: 提出SynMatch框架，通过分割模型提取特征合成图像，与伪标签匹配，不需要额外训练参数。

Result: 在不同监督条件下（SSL、WSL、BSL），特别是几乎无监督（BSL）条件下表现优异，5%和10% scribble标注的肠息肉分割任务中分别超越了现有方法29.71%和10.05%。

Conclusion: SynMatch有效缓解了伪标签不一致问题，在极端标注稀缺情况下也能取得卓越效果，对半监督、弱监督和低监督学习具有重要意义。

Abstract: Label scarcity remains a major challenge in deep learning-based medical image
segmentation. Recent studies use strong-weak pseudo supervision to leverage
unlabeled data. However, performance is often hindered by inconsistencies
between pseudo labels and their corresponding unlabeled images. In this work,
we propose \textbf{SynMatch}, a novel framework that sidesteps the need for
improving pseudo labels by synthesizing images to match them instead.
Specifically, SynMatch synthesizes images using texture and shape features
extracted from the same segmentation model that generates the corresponding
pseudo labels for unlabeled images. This design enables the generation of
highly consistent synthesized-image-pseudo-label pairs without requiring any
training parameters for image synthesis. We extensively evaluate SynMatch
across diverse medical image segmentation tasks under semi-supervised learning
(SSL), weakly-supervised learning (WSL), and barely-supervised learning (BSL)
settings with increasingly limited annotations. The results demonstrate that
SynMatch achieves superior performance, especially in the most challenging BSL
setting. For example, it outperforms the recent strong-weak pseudo
supervision-based method by 29.71\% and 10.05\% on the polyp segmentation task
with 5\% and 10\% scribble annotations, respectively. The code will be released
at https://github.com/Senyh/SynMatch.

</details>


### [92] [BEVANet: Bilateral Efficient Visual Attention Network for Real-Time Semantic Segmentation](https://arxiv.org/abs/2508.07300)
*Ping-Mao Huang,I-Tien Chao,Ping-Chia Huang,Jia-Wei Liao,Yung-Yu Chuang*

Main category: cs.CV

TL;DR: 实时语义分割中，BEVANet提出了创新的LKA机制，通过多种改进提升了语义理解与边界细化能力，取得了最先进的性能表现。


<details>
  <summary>Details</summary>
Motivation: 针对实时语义分割领域中的效率与精度问题，尤其是捕捉语义理解所需的大感受野和边界细化能力的矛盾，提出解决方案。

Method: 提出了BEVANet网络架构，集成了LKA机制，SDLSKA模块，CKS机制，DLKPPM，以及利用BGAF模块进行边界引导，通过增强感受野、语义及结构特征捕获和分支通信提升分割能力。

Result: 在没有预训练的情况下，BEVANet在Cityscapes数据集上实现了33 FPS的实时分割速度和79.3%的mIoU；经过ImageNet预训练后，mIoU可提升至81.0%，达到业内领先水平。

Conclusion: BEVANet结合了创新的注意力机制和多种模块，大幅提高了实时语义分割的性能，其开源代码和模型提供了进一步研究的支持。

Abstract: Real-time semantic segmentation presents the dual challenge of designing
efficient architectures that capture large receptive fields for semantic
understanding while also refining detailed contours. Vision transformers model
long-range dependencies effectively but incur high computational cost. To
address these challenges, we introduce the Large Kernel Attention (LKA)
mechanism. Our proposed Bilateral Efficient Visual Attention Network (BEVANet)
expands the receptive field to capture contextual information and extracts
visual and structural features using Sparse Decomposed Large Separable Kernel
Attentions (SDLSKA). The Comprehensive Kernel Selection (CKS) mechanism
dynamically adapts the receptive field to further enhance performance.
Furthermore, the Deep Large Kernel Pyramid Pooling Module (DLKPPM) enriches
contextual features by synergistically combining dilated convolutions and large
kernel attention. The bilateral architecture facilitates frequent branch
communication, and the Boundary Guided Adaptive Fusion (BGAF) module enhances
boundary delineation by integrating spatial and semantic features under
boundary guidance. BEVANet achieves real-time segmentation at 33 FPS, yielding
79.3% mIoU without pretraining and 81.0% mIoU on Cityscapes after ImageNet
pretraining, demonstrating state-of-the-art performance. The code and model is
available at https://github.com/maomao0819/BEVANet.

</details>


### [93] [DragonFruitQualityNet: A Lightweight Convolutional Neural Network for Real-Time Dragon Fruit Quality Inspection on Mobile Devices](https://arxiv.org/abs/2508.07306)
*Md Zahurul Haquea,Yeahyea Sarker,Muhammed Farhan Sadique Mahi,Syed Jubayer Jaman,Md Robiul Islam*

Main category: cs.CV

TL;DR: 本文提出了DragonFruitQualityNet，一个轻量级卷积神经网络（CNN），用于实时检测火龙果质量，准确率达到93.98%。


<details>
  <summary>Details</summary>
Motivation: 满足全球对火龙果日益增长的需求，并提高农业生产力和减少采后损耗。

Method: 设计并优化了轻量化CNN模型DragonFruitQualityNet，基于13,789张数据图片进行分类训练，开发了移动端应用便于实际应用操作。

Result: 模型在火龙果质量分类任务中实现了93.98%的分类准确率，优于现有方法，并且成功嵌入到移动应用中实现实时质量检测。

Conclusion: 研究提供了一种高效、准确、可扩展的AI解决方案，促进了数字农业发展，为小农场主提供了易于操作的技术，推动了可持续农业实践。

Abstract: Dragon fruit, renowned for its nutritional benefits and economic value, has
experienced rising global demand due to its affordability and local
availability. As dragon fruit cultivation expands, efficient pre- and
post-harvest quality inspection has become essential for improving agricultural
productivity and minimizing post-harvest losses. This study presents
DragonFruitQualityNet, a lightweight Convolutional Neural Network (CNN)
optimized for real-time quality assessment of dragon fruits on mobile devices.
We curated a diverse dataset of 13,789 images, integrating self-collected
samples with public datasets (dataset from Mendeley Data), and classified them
into four categories: fresh, immature, mature, and defective fruits to ensure
robust model training. The proposed model achieves an impressive 93.98%
accuracy, outperforming existing methods in fruit quality classification. To
facilitate practical adoption, we embedded the model into an intuitive mobile
application, enabling farmers and agricultural stakeholders to conduct
on-device, real-time quality inspections. This research provides an accurate,
efficient, and scalable AI-driven solution for dragon fruit quality control,
supporting digital agriculture and empowering smallholder farmers with
accessible technology. By bridging the gap between research and real-world
application, our work advances post-harvest management and promotes sustainable
farming practices.

</details>


### [94] [MCITlib: Multimodal Continual Instruction Tuning Library and Benchmark](https://arxiv.org/abs/2508.07307)
*Haiyang Guo,Fei Zhu,Hongbo Zhao,Fanhu Zeng,Wenzhuo Liu,Shijie Ma,Da-Han Wang,Xu-Yao Zhang*

Main category: cs.CV

TL;DR: 这篇论文介绍了一个名为MCITlib的代码库，用于支持多模态大语言模型的连续学习。


<details>
  <summary>Details</summary>
Motivation: 旨在推动多模态连续学习领域的发展，解决跨模态交互的相关挑战。

Method: 构建了名为MCITlib的代码库，包含8种多模态连续指令调整算法，并评估了其在两个基准测试集上的表现。

Result: 该代码库目前系统评估了多种算法的表现，并计划持续更新以反映领域的最新进展。

Conclusion: MCITlib为多模态连续学习提供了一个基础平台，并共享了代码以支持研究的进一步推进。

Abstract: Continual learning aims to equip AI systems with the ability to continuously
acquire and adapt to new knowledge without forgetting previously learned
information, similar to human learning. While traditional continual learning
methods focusing on unimodal tasks have achieved notable success, the emergence
of Multimodal Large Language Models has brought increasing attention to
Multimodal Continual Learning tasks involving multiple modalities, such as
vision and language. In this setting, models are expected to not only mitigate
catastrophic forgetting but also handle the challenges posed by cross-modal
interactions and coordination. To facilitate research in this direction, we
introduce MCITlib, a comprehensive and constantly evolving code library for
continual instruction tuning of Multimodal Large Language Models. In MCITlib,
we have currently implemented 8 representative algorithms for Multimodal
Continual Instruction Tuning and systematically evaluated them on 2 carefully
selected benchmarks. MCITlib will be continuously updated to reflect advances
in the Multimodal Continual Learning field. The codebase is released at
https://github.com/Ghy0501/MCITlib.

</details>


### [95] [MobileViCLIP: An Efficient Video-Text Model for Mobile Devices](https://arxiv.org/abs/2508.07312)
*Min Yang,Zihan Jia,Zhilin Dai,Sheng Guo,Limin Wang*

Main category: cs.CV

TL;DR: 提出了一种名为MobileViCLIP的视频文本模型，它结合了高效的图像文本模型与时间结构重参数化技术，适合移动设备使用，并表现出强大的零样本分类与检索能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频预训练模型多基于高延迟的ViT架构，针对移动设备优化的高效架构研究较少。作者希望弥补这一空白。

Method: 通过在高效图像文本模型中引入时间结构重参数化，并使用大规模高质量视频文本数据集进行训练，构建移动设备上可运行的高效视频文本模型MobileViCLIP。

Result: MobileViCLIP-Small在移动设备上的推理速度比InternVideo2-L14快55.4倍，比InternVideo2-S14快6.7倍，同时在MSR-VTT数据集上的零样本检索性能与InternVideo2-L14相当，比InternVideo2-S14高6.9%。

Conclusion: MobileViCLIP模型在保持高效性能的同时，展现了很强的零样本分类与检索能力，为视频预训练模型的移动设备优化提供了一种可行方案。

Abstract: Efficient lightweight neural networks are with increasing attention due to
their faster reasoning speed and easier deployment on mobile devices. However,
existing video pre-trained models still focus on the common ViT architecture
with high latency, and few works attempt to build efficient architecture on
mobile devices. This paper bridges this gap by introducing temporal structural
reparameterization into an efficient image-text model and training it on a
large-scale high-quality video-text dataset, resulting in an efficient
video-text model that can run on mobile devices with strong zero-shot
classification and retrieval capabilities, termed as MobileViCLIP. In
particular, in terms of inference speed on mobile devices, our
MobileViCLIP-Small is 55.4x times faster than InternVideo2-L14 and 6.7x faster
than InternVideo2-S14. In terms of zero-shot retrieval performance, our
MobileViCLIP-Small obtains similar performance as InternVideo2-L14 and obtains
6.9\% better than InternVideo2-S14 on MSR-VTT. The code is available at
https://github.com/MCG-NJU/MobileViCLIP.

</details>


### [96] [DocR1: Evidence Page-Guided GRPO for Multi-Page Document Understanding](https://arxiv.org/abs/2508.07313)
*Junyu Xiong,Yonghui Wang,Weichao Zhao,Chenyu Liu,Bing Yin,Wengang Zhou,Houqiang Li*

Main category: cs.CV

TL;DR: 提出DocR1，一种通过新颖RL框架EviGRPO训练的多模态大语言模型，擅长理解多页文档并进行页面间推理。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在多页文档理解中的挑战，尤其是细粒度视觉理解与跨页推理能力不足的问题。

Method: 构建了DocR1，多模态大语言模型，利用新颖的RL框架EviGRPO，采用证据感知奖励机制，促进由粗到细推理策略，结合两阶段注释流程和课程学习策略，提供高质量训练数据集EviBench与评估集ArxivFullQA。

Result: DocR1在多页任务上达到了最先进的性能，同时在单页任务上保持了较强的表现。

Conclusion: 提出的DocR1模型和EviGRPO框架有效提升了多页文档理解能力，且仅需有限的监督即可构建高质量模型。

Abstract: Understanding multi-page documents poses a significant challenge for
multimodal large language models (MLLMs), as it requires fine-grained visual
comprehension and multi-hop reasoning across pages. While prior work has
explored reinforcement learning (RL) for enhancing advanced reasoning in MLLMs,
its application to multi-page document understanding remains underexplored. In
this paper, we introduce DocR1, an MLLM trained with a novel RL framework,
Evidence Page-Guided GRPO (EviGRPO). EviGRPO incorporates an evidence-aware
reward mechanism that promotes a coarse-to-fine reasoning strategy, guiding the
model to first retrieve relevant pages before generating answers. This training
paradigm enables us to build high-quality models with limited supervision. To
support this, we design a two-stage annotation pipeline and a curriculum
learning strategy, based on which we construct two datasets: EviBench, a
high-quality training set with 4.8k examples, and ArxivFullQA, an evaluation
benchmark with 8.6k QA pairs based on scientific papers. Extensive experiments
across a wide range of benchmarks demonstrate that DocR1 achieves
state-of-the-art performance on multi-page tasks, while consistently
maintaining strong results on single-page benchmarks.

</details>


### [97] [RORPCap: Retrieval-based Objects and Relations Prompt for Image Captioning](https://arxiv.org/abs/2508.07318)
*Jinjing Gu,Tianbao Qin,Yuanyuan Pu,Zhengpeng Zhao*

Main category: cs.CV

TL;DR: 提出了RORPCap模型，通过引入检索式的对象和关系提示词生成机制，为图像描述生成更丰富的语义信息，同时显著减少训练时间。


<details>
  <summary>Details</summary>
Motivation: 现有的图像描述生成方法依赖对象检测器或结合GCN，存在冗余信息、复杂的GCN构建和高训练成本等问题。

Method: 提议RORPCap模型，通过对象和关系提取模型生成提示词并将其嵌入预定义模板；结合基于Mamba的映射网络，将CLIP提取的图像嵌入快速映射为视觉-文本嵌入；然后将提示嵌入与视觉-文本嵌入融合并输入GPT-2生成描述。

Result: 在MS-COCO数据集实验中，RORPCap模型仅需2.6小时（交叉熵损失下）训练，在CIDEr和SPICE指标上分别达到了120.5%和22.0%的分数，与其他基于检测器和GCN模型性能相当。

Conclusion: RORPCap展示出在图像描述生成中的潜力，能够在显著降低训练时间的同时实现类似性能，作为一种新型替代方案具有实用价值。

Abstract: Image captioning aims to generate natural language descriptions for input
images in an open-form manner. To accurately generate descriptions related to
the image, a critical step in image captioning is to identify objects and
understand their relations within the image. Modern approaches typically
capitalize on object detectors or combine detectors with Graph Convolutional
Network (GCN). However, these models suffer from redundant detection
information, difficulty in GCN construction, and high training costs. To
address these issues, a Retrieval-based Objects and Relations Prompt for Image
Captioning (RORPCap) is proposed, inspired by the fact that image-text
retrieval can provide rich semantic information for input images. RORPCap
employs an Objects and relations Extraction Model to extract object and
relation words from the image. These words are then incorporate into predefined
prompt templates and encoded as prompt embeddings. Next, a Mamba-based mapping
network is designed to quickly map image embeddings extracted by CLIP to
visual-text embeddings. Finally, the resulting prompt embeddings and
visual-text embeddings are concatenated to form textual-enriched feature
embeddings, which are fed into a GPT-2 model for caption generation. Extensive
experiments conducted on the widely used MS-COCO dataset show that the RORPCap
requires only 2.6 hours under cross-entropy loss training, achieving 120.5%
CIDEr score and 22.0% SPICE score on the "Karpathy" test split. RORPCap
achieves comparable performance metrics to detector-based and GCN-based models
with the shortest training time and demonstrates its potential as an
alternative for image captioning.

</details>


### [98] [Planner-Refiner: Dynamic Space-Time Refinement for Vision-Language Alignment in Videos](https://arxiv.org/abs/2508.07330)
*Tuyen Tran,Thao Minh Le,Quang-Hung Le,Truyen Tran*

Main category: cs.CV

TL;DR: 引入了一个名为Planner-Refiner的框架，通过迭代式语言指导，实现视频和语言的语义对齐，特别适用于复杂语言任务。


<details>
  <summary>Details</summary>
Motivation: 解决视频语言对齐中语言复杂性、实体交互与业务链的语义差距问题。

Method: 提出一个双模块框架Planner-Refiner，利用Planner划分复杂语言为短句单元，由Refiner模块逐步处理并优化视觉表示，结合自注意力机制实现跨时空的精细调整。

Result: 在两个视频语言对齐任务中表现优异，同时提出了新的MeViS-X基准，证明了在处理复杂查询方面的潜力。

Conclusion: 该方法在复杂语言任务上的性能超越了现有技术水平，为视频和语言对齐提供了一种有效方案，并且通过新基准验证了其实用性。

Abstract: Vision-language alignment in video must address the complexity of language,
evolving interacting entities, their action chains, and semantic gaps between
language and vision. This work introduces Planner-Refiner, a framework to
overcome these challenges. Planner-Refiner bridges the semantic gap by
iteratively refining visual elements' space-time representation, guided by
language until semantic gaps are minimal. A Planner module schedules language
guidance by decomposing complex linguistic prompts into short sentence chains.
The Refiner processes each short sentence, a noun-phrase and verb-phrase pair,
to direct visual tokens' self-attention across space then time, achieving
efficient single-step refinement. A recurrent system chains these steps,
maintaining refined visual token representations. The final representation
feeds into task-specific heads for alignment generation. We demonstrate
Planner-Refiner's effectiveness on two video-language alignment tasks:
Referring Video Object Segmentation and Temporal Grounding with varying
language complexity. We further introduce a new MeViS-X benchmark to assess
models' capability with long queries. Superior performance versus
state-of-the-art methods on these benchmarks shows the approach's potential,
especially for complex prompts.

</details>


### [99] [CoAR: Concept Injection into Autoregressive Models for Personalized Text-to-Image Generation](https://arxiv.org/abs/2508.07341)
*Fangtai Wu,Mushui Liu,Weijie He,Wanggui He,Hao Jiang,Zhao Wang,Yunlong Yu*

Main category: cs.CV

TL;DR: CoAR是一种新型框架，旨在在预训练的统一自回归模型中注入主体概念，且无需调整模型参数。


<details>
  <summary>Details</summary>
Motivation: 现有的定制化图像生成方法昂贵且容易过拟合或遗忘，而统一AR模型定制化潜力尚未充分挖掘。

Method: 提出了一种层次多模态上下文学习策略及正则化方法，以冻结预训练参数并以极少参数实现主体表达学习。

Result: CoAR在主体与风格定制化个人化上性能优异，同时显著降低计算和内存需求，仅调节不到0.05%的参数。

Conclusion: CoAR框架在计算效率与定制化性能之间取得良好平衡，可作为高效的统一自回归模型扩展工具。

Abstract: The unified autoregressive (AR) model excels at multimodal understanding and
generation, but its potential for customized image generation remains
underexplored. Existing customized generation methods rely on full fine-tuning
or adapters, making them costly and prone to overfitting or catastrophic
forgetting. In this paper, we propose \textbf{CoAR}, a novel framework for
injecting subject concepts into the unified AR models while keeping all
pre-trained parameters completely frozen. CoAR learns effective, specific
subject representations with only a minimal number of parameters using a
Layerwise Multimodal Context Learning strategy. To address overfitting and
language drift, we further introduce regularization that preserves the
pre-trained distribution and anchors context tokens to improve subject fidelity
and re-contextualization. Additionally, CoAR supports training-free subject
customization in a user-provided style. Experiments demonstrate that CoAR
achieves superior performance on both subject-driven personalization and style
personalization, while delivering significant gains in computational and memory
efficiency. Notably, CoAR tunes less than \textbf{0.05\%} of the parameters
while achieving competitive performance compared to recent Proxy-Tuning. Code:
https://github.com/KZF-kzf/CoAR

</details>


### [100] [SODiff: Semantic-Oriented Diffusion Model for JPEG Compression Artifacts Removal](https://arxiv.org/abs/2508.07346)
*Tingyu Yang,Jue Gong,Jinpei Guo,Wenbo Li,Yong Guo,Yulun Zhang*

Main category: cs.CV

TL;DR: SODiff是一种新颖高效的一步扩散模型，专为去除JPEG压缩引入的伪影设计，利用语义引导实现高效恢复。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在恢复复杂纹理细节时表现有限，容易过度平滑，亟需一种更高效的恢复机制。

Method: 提出SODiff模型。包含语义对齐图像提示提取器(SAIPE)，用于提取低质量图像特征并进行语义对齐嵌入，同时提出质量因子感知时间预测器，动态调整扩散过程时间步长。

Result: 实验结果表明，SODiff在视觉质量和量化指标上均优于现有方法。

Conclusion: SODiff充分利用扩散模型生成先验，结合语义指导和动态调整机制，显著提升JPEG压缩伪影的恢复效果。

Abstract: JPEG, as a widely used image compression standard, often introduces severe
visual artifacts when achieving high compression ratios. Although existing deep
learning-based restoration methods have made considerable progress, they often
struggle to recover complex texture details, resulting in over-smoothed
outputs. To overcome these limitations, we propose SODiff, a novel and
efficient semantic-oriented one-step diffusion model for JPEG artifacts
removal. Our core idea is that effective restoration hinges on providing
semantic-oriented guidance to the pre-trained diffusion model, thereby fully
leveraging its powerful generative prior. To this end, SODiff incorporates a
semantic-aligned image prompt extractor (SAIPE). SAIPE extracts rich features
from low-quality (LQ) images and projects them into an embedding space
semantically aligned with that of the text encoder. Simultaneously, it
preserves crucial information for faithful reconstruction. Furthermore, we
propose a quality factor-aware time predictor that implicitly learns the
compression quality factor (QF) of the LQ image and adaptively selects the
optimal denoising start timestep for the diffusion process. Extensive
experimental results show that our SODiff outperforms recent leading methods in
both visual quality and quantitative metrics. Code is available at:
https://github.com/frakenation/SODiff

</details>


### [101] [GS4Buildings: Prior-Guided Gaussian Splatting for 3D Building Reconstruction](https://arxiv.org/abs/2508.07355)
*Qilin Zhang,Olaf Wysocki,Boris Jutzi*

Main category: cs.CV

TL;DR: 提出了一种基于语义3D建筑模型的高斯点方法（GS4Buildings），用于改进复杂城市场景下的3D建筑表面重建。


<details>
  <summary>Details</summary>
Motivation: 现有2D高斯点方法在大型复杂城市场景中因遮挡问题导致建筑重建不完整，急需更有效的方法。

Method: 提出GS4Buildings方法，将低级别语义3D建筑模型初始化为高斯，同时生成深度和法线图，引入优化中以提供几何指导，并增加仅聚焦于建筑区域的模式提升效率。

Result: 相比现有方法，GS4Buildings在重建完整性上提高了20.5%，在几何精度上提高了32.8%，并减少了71.8%的高斯原语数目。

Conclusion: GS4Buildings通过结合语义建筑模型显著提升了基于高斯点方法的城市建筑重建能力，为智能城市和数字孪生等实际应用奠定了基础。

Abstract: Recent advances in Gaussian Splatting (GS) have demonstrated its
effectiveness in photo-realistic rendering and 3D reconstruction. Among these,
2D Gaussian Splatting (2DGS) is particularly suitable for surface
reconstruction due to its flattened Gaussian representation and integrated
normal regularization. However, its performance often degrades in large-scale
and complex urban scenes with frequent occlusions, leading to incomplete
building reconstructions. We propose GS4Buildings, a novel prior-guided
Gaussian Splatting method leveraging the ubiquity of semantic 3D building
models for robust and scalable building surface reconstruction. Instead of
relying on traditional Structure-from-Motion (SfM) pipelines, GS4Buildings
initializes Gaussians directly from low-level Level of Detail (LoD)2 semantic
3D building models. Moreover, we generate prior depth and normal maps from the
planar building geometry and incorporate them into the optimization process,
providing strong geometric guidance for surface consistency and structural
accuracy. We also introduce an optional building-focused mode that limits
reconstruction to building regions, achieving a 71.8% reduction in Gaussian
primitives and enabling a more efficient and compact representation.
Experiments on urban datasets demonstrate that GS4Buildings improves
reconstruction completeness by 20.5% and geometric accuracy by 32.8%. These
results highlight the potential of semantic building model integration to
advance GS-based reconstruction toward real-world urban applications such as
smart cities and digital twins. Our project is available:
https://github.com/zqlin0521/GS4Buildings.

</details>


### [102] [Training and Inference within 1 Second -- Tackle Cross-Sensor Degradation of Real-World Pansharpening with Efficient Residual Feature Tailoring](https://arxiv.org/abs/2508.07369)
*Tianyu Xin,Jin-Liang Xiao,Zeyu Xia,Shan Yin,Liang-Jian Deng*

Main category: cs.CV

TL;DR: 本研究提出了一种模块解构深度学习拼接技术问题的方法，通过引入“特征匹配器”，有效解决跨传感器数据降解问题，并大幅提升效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前预训练模型在不同传感器上的泛化能力较差，传统方法求解过于耗费时间或需额外数据。作者提出方法解决这些问题。

Method: 对拼接模型进行模块化分解，在关键界面添加特征匹配器，该匹配器采用基于物理的无监督损失训练，同时以块状方式提升训练和推理效率。

Result: 多数据集实验表明，该方法显著提高跨传感器效果，并在效能上超越其他方法，在RTX 3090 GPU上实现多线程推断速度优势。

Conclusion: 提出的“特征匹配器”方法不仅提升了模型的跨传感器泛化能力，还能快速应用于测试阶段，无需外部数据，极大增强效率，适用于实际场景。

Abstract: Deep learning methods for pansharpening have advanced rapidly, yet models
pretrained on data from a specific sensor often generalize poorly to data from
other sensors. Existing methods to tackle such cross-sensor degradation include
retraining model or zero-shot methods, but they are highly time-consuming or
even need extra training data. To address these challenges, our method first
performs modular decomposition on deep learning-based pansharpening models,
revealing a general yet critical interface where high-dimensional fused
features begin mapping to the channel space of the final image. % may need
revisement A Feature Tailor is then integrated at this interface to address
cross-sensor degradation at the feature level, and is trained efficiently with
physics-aware unsupervised losses. Moreover, our method operates in a
patch-wise manner, training on partial patches and performing parallel
inference on all patches to boost efficiency. Our method offers two key
advantages: (1) $\textit{Improved Generalization Ability}$: it significantly
enhance performance in cross-sensor cases. (2) $\textit{Low Generalization
Cost}$: it achieves sub-second training and inference, requiring only partial
test inputs and no external data, whereas prior methods often take minutes or
even hours. Experiments on the real-world data from multiple datasets
demonstrate that our method achieves state-of-the-art quality and efficiency in
tackling cross-sensor degradation. For example, training and inference of
$512\times512\times8$ image within $\textit{0.2 seconds}$ and
$4000\times4000\times8$ image within $\textit{3 seconds}$ at the fastest
setting on a commonly used RTX 3090 GPU, which is over 100 times faster than
zero-shot methods.

</details>


### [103] [DIP-GS: Deep Image Prior For Gaussian Splatting Sparse View Recovery](https://arxiv.org/abs/2508.07372)
*Rajaei Khatib,Raja Giryes*

Main category: cs.CV

TL;DR: 本文提出了一种名为DIP-GS的新方法，通过引入深度图像先验（DIP），提升了3D高斯图（3DGS）在稀疏视图重建任务中的表现，无需预训练模型，仅依赖输入视图。


<details>
  <summary>Details</summary>
Motivation: 3DGS 在稀疏视图重建时表现较差，本文旨在改善其在低覆盖度和低重叠视图条件下的性能。

Method: 引入深度图像先验（DIP）以及粗到细的策略，借助场景内部结构和模式，提升稀疏视图重建精度。

Result: DIP-GS 在多个稀疏视图重建任务中取得了与当前最先进方法（SOTA）相匹敌的结果。

Conclusion: DIP-GS 不依赖任何预训练模型，仅通过输入视图即可在稀疏视图条件下表现卓越，展现了其适用性和潜力。

Abstract: 3D Gaussian Splatting (3DGS) is a leading 3D scene reconstruction method,
obtaining high-quality reconstruction with real-time rendering runtime
performance. The main idea behind 3DGS is to represent the scene as a
collection of 3D gaussians, while learning their parameters to fit the given
views of the scene. While achieving superior performance in the presence of
many views, 3DGS struggles with sparse view reconstruction, where the input
views are sparse and do not fully cover the scene and have low overlaps. In
this paper, we propose DIP-GS, a Deep Image Prior (DIP) 3DGS representation. By
using the DIP prior, which utilizes internal structure and patterns, with
coarse-to-fine manner, DIP-based 3DGS can operate in scenarios where vanilla
3DGS fails, such as sparse view recovery. Note that our approach does not use
any pre-trained models such as generative models and depth estimation, but
rather relies only on the input frames. Among such methods, DIP-GS obtains
state-of-the-art (SOTA) competitive results on various sparse-view
reconstruction tasks, demonstrating its capabilities.

</details>


### [104] [LET-US: Long Event-Text Understanding of Scenes](https://arxiv.org/abs/2508.07401)
*Rui Chen,Xingyu Chen,Shaoan Wang,Shihan Kong,Junzhi Yu*

Main category: cs.CV

TL;DR: 提出了LET-US框架，一种旨在实现长时间事件流与文本理解的跨模态推理模型，解决现有模型处理事件流时间长短和跨模态问题。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有多模态大语言模型（MLLMs）在事件流解析有效性和长序列处理能力不足的问题。

Method: 提出自适应压缩机制减少输入事件的体积，同时采用两阶段优化方法进行事件流与文本的跨模态对齐，并引入文本引导的跨模态查询、层次聚类和相似度计算机制以提取关键特征。

Result: 实验表明，LET-US在长时间事件流的描述准确性和语义理解方面优于现有的多模态模型。

Conclusion: 表明LET-US框架可以显著提升长时间事件流处理与文本推理的表现，为未来跨模态研究提供了新的方向。

Abstract: Event cameras output event streams as sparse, asynchronous data with
microsecond-level temporal resolution, enabling visual perception with low
latency and a high dynamic range. While existing Multimodal Large Language
Models (MLLMs) have achieved significant success in understanding and analyzing
RGB video content, they either fail to interpret event streams effectively or
remain constrained to very short sequences. In this paper, we introduce LET-US,
a framework for long event-stream--text comprehension that employs an adaptive
compression mechanism to reduce the volume of input events while preserving
critical visual details. LET-US thus establishes a new frontier in cross-modal
inferential understanding over extended event sequences. To bridge the
substantial modality gap between event streams and textual representations, we
adopt a two-stage optimization paradigm that progressively equips our model
with the capacity to interpret event-based scenes. To handle the voluminous
temporal information inherent in long event streams, we leverage text-guided
cross-modal queries for feature reduction, augmented by hierarchical clustering
and similarity computation to distill the most representative event features.
Moreover, we curate and construct a large-scale event-text aligned dataset to
train our model, achieving tighter alignment of event features within the LLM
embedding space. We also develop a comprehensive benchmark covering a diverse
set of tasks -- reasoning, captioning, classification, temporal localization
and moment retrieval. Experimental results demonstrate that LET-US outperforms
prior state-of-the-art MLLMs in both descriptive accuracy and semantic
comprehension on long-duration event streams. All datasets, codes, and models
will be publicly available.

</details>


### [105] [Investigating the Design Space of Visual Grounding in Multimodal Large Language Model](https://arxiv.org/abs/2508.08066)
*Weitai Kang,Weiming Zhuang,Zhizhong Li,Yan Yan,Lingjuan Lyu*

Main category: cs.CV

TL;DR: 本文系统研究了多模态大语言模型（MLLMs）在视觉定位（VG）任务中的设计选择，以优化其性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在视觉定位任务中的设计缺乏系统验证，存在孤立与分散的优化方式，需要提高设计的广泛适用性与精确性。

Method: 采用LLaVA-1.5模型，通过探索不同的视觉定位范式和相关数据的消融实验，分析对VG任务表现有显著影响的设计选择。

Result: 在RefCOCO/+/g数据集上实现了+5.6% / +6.9% / +7.0%的精度提升。

Conclusion: 通过全面探索视觉定位的设计要素，本文提出了一种优化MLLMs性能的有效方法，为未来相关模型的优化提供了新的方向。

Abstract: Fine-grained multimodal capability in Multimodal Large Language Models
(MLLMs) has emerged as a critical research direction, particularly for tackling
the visual grounding (VG) problem. Despite the strong performance achieved by
existing approaches, they often employ disparate design choices when
fine-tuning MLLMs for VG, lacking systematic verification to support these
designs. To bridge this gap, this paper presents a comprehensive study of
various design choices that impact the VG performance of MLLMs. We conduct our
analysis using LLaVA-1.5, which has been widely adopted in prior empirical
studies of MLLMs. While more recent models exist, we follow this convention to
ensure our findings remain broadly applicable and extendable to other
architectures. We cover two key aspects: (1) exploring different visual
grounding paradigms in MLLMs, identifying the most effective design, and
providing our insights; and (2) conducting ablation studies on the design of
grounding data to optimize MLLMs' fine-tuning for the VG task. Finally, our
findings contribute to a stronger MLLM for VG, achieving improvements of +5.6%
/ +6.9% / +7.0% on RefCOCO/+/g over the LLaVA-1.5.

</details>


### [106] [ForensicsSAM: Toward Robust and Unified Image Forgery Detection and Localization Resisting to Adversarial Attack](https://arxiv.org/abs/2508.07402)
*Rongxuan Peng,Shunquan Tan,Chenqi Kong,Anwei Luo,Alex C. Kot,Jiwu Huang*

Main category: cs.CV

TL;DR: 本文提出ForensicsSAM框架，提高图像篡改检测和定位任务的对抗鲁棒性及性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于参数高效微调（PEFT）的方式在处理图像伪造检测与定位任务时，容易受到对抗性攻击影响，性能大幅下降。

Method: 通过三大关键措施设计ForensicsSAM框架：1) 在每个transformer block注入伪造识别专家；2) 设计轻量化对抗性图像检测模块；3) 在全局注意力层和MLP模块注入对抗专家，纠正对抗噪声引起的特征偏差。

Result: ForensicsSAM在多项基准任务上表现出对多种对抗攻击方法的强鲁棒性，同时在图像级伪造检测与像素级定位任务上达到了目前最优性能。

Conclusion: ForensicsSAM兼具对抗性鲁棒性和出色的伪造检测与定位性能，为应对对抗性挑战提供了有效的解决方案。

Abstract: Parameter-efficient fine-tuning (PEFT) has emerged as a popular strategy for
adapting large vision foundation models, such as the Segment Anything Model
(SAM) and LLaVA, to downstream tasks like image forgery detection and
localization (IFDL). However, existing PEFT-based approaches overlook their
vulnerability to adversarial attacks. In this paper, we show that highly
transferable adversarial images can be crafted solely via the upstream model,
without accessing the downstream model or training data, significantly
degrading the IFDL performance. To address this, we propose ForensicsSAM, a
unified IFDL framework with built-in adversarial robustness. Our design is
guided by three key ideas: (1) To compensate for the lack of forgery-relevant
knowledge in the frozen image encoder, we inject forgery experts into each
transformer block to enhance its ability to capture forgery artifacts. These
forgery experts are always activated and shared across any input images. (2) To
detect adversarial images, we design an light-weight adversary detector that
learns to capture structured, task-specific artifact in RGB domain, enabling
reliable discrimination across various attack methods. (3) To resist
adversarial attacks, we inject adversary experts into the global attention
layers and MLP modules to progressively correct feature shifts induced by
adversarial noise. These adversary experts are adaptively activated by the
adversary detector, thereby avoiding unnecessary interference with clean
images. Extensive experiments across multiple benchmarks demonstrate that
ForensicsSAM achieves superior resistance to various adversarial attack
methods, while also delivering state-of-the-art performance in image-level
forgery detection and pixel-level forgery localization. The resource is
available at https://github.com/siriusPRX/ForensicsSAM.

</details>


### [107] [CharacterShot: Controllable and Consistent 4D Character Animation](https://arxiv.org/abs/2508.07409)
*Junyao Gao,Jiaxing Li,Wenran Liu,Yanhong Zeng,Fei Shen,Kai Chen,Yanan Sun,Cairong Zhao*

Main category: cs.CV

TL;DR: 该论文提出了CharacterShot，一个从单张角色参考图像和2D姿态序列生成动态3D角色动画的框架。


<details>
  <summary>Details</summary>
Motivation: 提供一个易用且受控的4D角色动画生成方法，赋能个体设计师。

Method: 使用基于DiT的图像到视频模型进行预训练，引入双重注意机制和相机先验提升为3D动画，同时对多视角视频应用邻域约束的4D高斯点优化。构建了大规模数据集Character4D。

Result: 实验表明，该方法在CharacterBench基准上超越了目前的先进方法。

Conclusion: CharacterShot实现了从静态2D图像和姿态序列生成一致且稳定的4D角色动画的能力，为个体设计师提供了强大的设计工具。

Abstract: In this paper, we propose \textbf{CharacterShot}, a controllable and
consistent 4D character animation framework that enables any individual
designer to create dynamic 3D characters (i.e., 4D character animation) from a
single reference character image and a 2D pose sequence. We begin by
pretraining a powerful 2D character animation model based on a cutting-edge
DiT-based image-to-video model, which allows for any 2D pose sequnce as
controllable signal. We then lift the animation model from 2D to 3D through
introducing dual-attention module together with camera prior to generate
multi-view videos with spatial-temporal and spatial-view consistency. Finally,
we employ a novel neighbor-constrained 4D gaussian splatting optimization on
these multi-view videos, resulting in continuous and stable 4D character
representations. Moreover, to improve character-centric performance, we
construct a large-scale dataset Character4D, containing 13,115 unique
characters with diverse appearances and motions, rendered from multiple
viewpoints. Extensive experiments on our newly constructed benchmark,
CharacterBench, demonstrate that our approach outperforms current
state-of-the-art methods. Code, models, and datasets will be publicly available
at https://github.com/Jeoyal/CharacterShot.

</details>


### [108] [CLUE: Leveraging Low-Rank Adaptation to Capture Latent Uncovered Evidence for Image Forgery Localization](https://arxiv.org/abs/2508.07413)
*Youqi Wang,Shunquan Tan,Rongxuan Peng,Bin Li,Jiwu Huang*

Main category: cs.CV

TL;DR: 本文提出了一种名为CLUE的框架，通过重新配置Stable Diffusion 3 (SD3)模型，对伪造图像进行高度精确的定位分析。


<details>
  <summary>Details</summary>
Motivation: 随着图像编辑工具和生成式AI的广泛使用，视觉上逼真的伪造内容激增，数字媒体的真实性受到威胁。

Method: 使用一种名为CLUE的框架，基于LoRA调整SD3模型的去噪流程，同时结合Segment Anything Model (SAM)的特征，增强伪造区域的检测能力。

Result: CLUE在伪造图像检测中优于现有方法，并具备对常见后处理攻击及社交网络的强大鲁棒性。

Conclusion: CLUE展示了其在高效伪造检测与定位上的优势，为应对日益普遍的图像伪造提供了新的解决方案。

Abstract: The increasing accessibility of image editing tools and generative AI has led
to a proliferation of visually convincing forgeries, compromising the
authenticity of digital media. In this paper, in addition to leveraging
distortions from conventional forgeries, we repurpose the mechanism of a
state-of-the-art (SOTA) text-to-image synthesis model by exploiting its
internal generative process, turning it into a high-fidelity forgery
localization tool. To this end, we propose CLUE (Capture Latent Uncovered
Evidence), a framework that employs Low- Rank Adaptation (LoRA) to
parameter-efficiently reconfigure Stable Diffusion 3 (SD3) as a forensic
feature extractor. Our approach begins with the strategic use of SD3's
Rectified Flow (RF) mechanism to inject noise at varying intensities into the
latent representation, thereby steering the LoRAtuned denoising process to
amplify subtle statistical inconsistencies indicative of a forgery. To
complement the latent analysis with high-level semantic context and precise
spatial details, our method incorporates contextual features from the image
encoder of the Segment Anything Model (SAM), which is parameter-efficiently
adapted to better trace the boundaries of forged regions. Extensive evaluations
demonstrate CLUE's SOTA generalization performance, significantly outperforming
prior methods. Furthermore, CLUE shows superior robustness against common
post-processing attacks and Online Social Networks (OSNs). Code is publicly
available at https://github.com/SZAISEC/CLUE.

</details>


### [109] [Freeze and Reveal: Exposing Modality Bias in Vision-Language Models](https://arxiv.org/abs/2508.07432)
*Vivek Hruday Kavuri,Vysishtya Karanam,Venkata Jahnavi Venkamsetty,Kriti Madumadukala,Lakshmipathi Balaji Darur,Ponnurangam Kumaraguru*

Main category: cs.CV

TL;DR: 提出了一种新方法以减少多模态模型中的性别偏见，并量化了视觉和文本模态在偏见中的贡献。


<details>
  <summary>Details</summary>
Motivation: 研究多模态模型如何从视觉和文本模态中继承性别偏见，旨在开发成本低且高效的去偏方法。

Method: 通过反事实数据增强（CDA）和基于刻板性度量的数据增强方法（DAUDoS）分别对视觉和文本模态进行去偏处理，并使用VisoGender基准评估其效果。

Result: CDA方法减少性别偏差6%，DAUDoS减少3%，且DAUDoS使用的数据量仅为CDA的三分之一；两种方法均提高了性别识别能力3%。实验还发现CLIP的视觉编码器偏见更大，而PaliGemma2的文本编码器偏见更明显。

Conclusion: 该研究提供了低成本高效的去偏策略，显著减少性别偏见，为未来多模态系统的偏见减小提供了更有针对性的方法。

Abstract: Vision Language Models achieve impressive multi-modal performance but often
inherit gender biases from their training data. This bias might be coming from
both the vision and text modalities. In this work, we dissect the contributions
of vision and text backbones to these biases by applying targeted debiasing
using Counterfactual Data Augmentation and Task Vector methods. Inspired by
data-efficient approaches in hate-speech classification, we introduce a novel
metric, Degree of Stereotypicality and a corresponding debiasing method, Data
Augmentation Using Degree of Stereotypicality - DAUDoS, to reduce bias with
minimal computational cost. We curate a gender annotated dataset and evaluate
all methods on VisoGender benchmark to quantify improvements and identify
dominant source of bias. Our results show that CDA reduces the gender gap by 6%
and DAUDoS by 3% but using only one-third of the data. Both methods also
improve the model's ability to correctly identify gender in images by 3%, with
DAUDoS achieving this improvement using only almost one-third of training data.
From our experiment's, we observed that CLIP's vision encoder is more biased
whereas PaliGemma2's text encoder is more biased. By identifying whether bias
stems more from vision or text encoders, our work enables more targeted and
effective bias mitigation strategies in future multi-modal systems.

</details>


### [110] [Levarging Learning Bias for Noisy Anomaly Detection](https://arxiv.org/abs/2508.07441)
*Yuxin Zhang,Yunkang Cao,Yuqi Cheng,Yihan Sun,Weiming Shen*

Main category: cs.CV

TL;DR: 提出一种专注于完全无监督图像异常检测的两阶段框架，通过利用模型学习中的偏差，提升在含有未标记异常的训练数据中的检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决完全无监督图像异常检测中，由训练数据中异常污染导致模型性能下降的问题。

Method: 提出利用学习偏差的两阶段方法：第一阶段通过子模型和交叉模型异常分数过滤异常数据，生成纯化的数据集；第二阶段利用纯化数据集训练最终检测器。

Result: 在Real-IAD基准测试中展示出在不同噪声条件下的优秀异常检测和定位性能，验证了方法的抗污染性。

Conclusion: 基于模型无关设计，可以与多种无监督模型兼容，为异常污染的训练数据提供实际解决方案。

Abstract: This paper addresses the challenge of fully unsupervised image anomaly
detection (FUIAD), where training data may contain unlabeled anomalies.
Conventional methods assume anomaly-free training data, but real-world
contamination leads models to absorb anomalies as normal, degrading detection
performance. To mitigate this, we propose a two-stage framework that
systematically exploits inherent learning bias in models. The learning bias
stems from: (1) the statistical dominance of normal samples, driving models to
prioritize learning stable normal patterns over sparse anomalies, and (2)
feature-space divergence, where normal data exhibit high intra-class
consistency while anomalies display high diversity, leading to unstable model
responses. Leveraging the learning bias, stage 1 partitions the training set
into subsets, trains sub-models, and aggregates cross-model anomaly scores to
filter a purified dataset. Stage 2 trains the final detector on this dataset.
Experiments on the Real-IAD benchmark demonstrate superior anomaly detection
and localization performance under different noise conditions. Ablation studies
further validate the framework's contamination resilience, emphasizing the
critical role of learning bias exploitation. The model-agnostic design ensures
compatibility with diverse unsupervised backbones, offering a practical
solution for real-world scenarios with imperfect training data. Code is
available at https://github.com/hustzhangyuxin/LLBNAD.

</details>


### [111] [Health Care Waste Classification Using Deep Learning Aligned with Nepal's Bin Color Guidelines](https://arxiv.org/abs/2508.07450)
*Suman Kunwar,Prabesh Rai*

Main category: cs.CV

TL;DR: 这项研究评估了五种废弃物分类模型在尼泊尔卫生保健废弃物管理中的表现，发现YOLOv5-s在准确率上表现最佳，但略逊于YOLOv8-n的推理速度。最后将YOLOv5-s部署于网络供公众使用。


<details>
  <summary>Details</summary>
Motivation: 随着尼泊尔卫生保健设施的增加，卫生废弃物的管理成为一项挑战。错误的废弃物分类和处理会导致污染、传播传染病及对废弃物处理人员造成风险。

Method: 研究比较了五种主流废弃物分类模型（ResNeXt-50、EfficientNet-B0、MobileNetV3-S、YOLOv8-n 和 YOLOv5-s）在分类准确率和推理速度方面的表现，并通过分层K折交叉验证技术评估模型性能，同时进行ANOVA统计分析。

Result: YOLOv5-s模型达到了95.06%的分类准确率，表现最佳，但在推理速度上稍逊于YOLOv8-n模型。EfficientNet-B0表现也不错，精度为93.22%，但推理时间较长。

Conclusion: YOLOv5-s模型被部署到网上并与尼泊尔卫生废弃物管理标准相结合，为公众提供服务。研究建议进一步结合本地化背景对数据和模型进行优化。

Abstract: The increasing number of Health Care facilities in Nepal has also added up
the challenges on managing health care waste (HCW). Improper segregation and
disposal of HCW leads to the contamination, spreading of infectious diseases
and puts a risk of waste handlers. This study benchmarks the state of the art
waste classification models: ResNeXt-50, EfficientNet-B0, MobileNetV3-S,
YOLOv8-n and YOLOv5-s using Stratified K-fold techniques where we use 5 folds
on combined HCW data, and found that the YOLOv5-s achieved higher of 95.06%
accuracy but fell short few milliseconds in inference speed with YOLOv8-n
model. The EfficientNet-B0 showed promising results of 93.22% accuracy but took
the highest inference time. A repetitive ANOVA was performed to see statistical
significance and the best performing model (YOLOv5-s) was deployed to the web
with mapped bin color using Nepal's HCW management standards for public usage.
Further work on the data was suggested along with localized context.

</details>


### [112] [AURA: A Fine-Grained Benchmark and Decomposed Metric for Audio-Visual Reasoning](https://arxiv.org/abs/2508.07470)
*Siminfar Samakoush Galougah,Rishie Raj,Sanjoy Chowdhury,Sayan Nag,Ramani Duraiswami*

Main category: cs.CV

TL;DR: 提出AURA基准，用于评估音视频大语言模型在跨模态推理中的表现，并揭示当前模型推理过程中的一致性和逻辑有效性问题。


<details>
  <summary>Details</summary>
Motivation: 现有音视频基准侧重答案的准确性，忽视推理过程的评估，难以区分真正理解与通过有缺陷的推理获得的正确答案。

Method: 设计AURA基准，包括六大认知领域的问题，确保需要音视频结合推理，并提出AuraScore指标评估推理的一致性与逻辑有效性。

Result: 现有模型在AURA获取高达92%的准确率，但推理一致性和逻辑有效性得分低于45%。

Conclusion: 现有模型推理逻辑存在显著缺陷，AURA基准的重要性显现，为多模态评估的改进指明方向。

Abstract: Current audio-visual (AV) benchmarks focus on final answer accuracy,
overlooking the underlying reasoning process. This makes it difficult to
distinguish genuine comprehension from correct answers derived through flawed
reasoning or hallucinations. To address this, we introduce AURA (Audio-visual
Understanding and Reasoning Assessment), a benchmark for evaluating the
cross-modal reasoning capabilities of Audio-Visual Large Language Models
(AV-LLMs) and Omni-modal Language Models (OLMs). AURA includes questions across
six challenging cognitive domains, such as causality, timbre and pitch, tempo
and AV synchronization, unanswerability, implicit distractions, and skill
profiling, explicitly designed to be unanswerable from a single modality. This
forces models to construct a valid logical path grounded in both audio and
video, setting AURA apart from AV datasets that allow uni-modal shortcuts. To
assess reasoning traces, we propose a novel metric, AuraScore, which addresses
the lack of robust tools for evaluating reasoning fidelity. It decomposes
reasoning into two aspects: (i) Factual Consistency - whether reasoning is
grounded in perceptual evidence, and (ii) Core Inference - the logical validity
of each reasoning step. Evaluations of SOTA models on AURA reveal a critical
reasoning gap: although models achieve high accuracy (up to 92% on some tasks),
their Factual Consistency and Core Inference scores fall below 45%. This
discrepancy highlights that models often arrive at correct answers through
flawed logic, underscoring the need for our benchmark and paving the way for
more robust multimodal evaluation.

</details>


### [113] [Novel View Synthesis with Gaussian Splatting: Impact on Photogrammetry Model Accuracy and Resolution](https://arxiv.org/abs/2508.07483)
*Pranav Chougule*

Main category: cs.CV

TL;DR: 本文比较了Photogrammetry和Gaussian Splatting技术在3D模型重建和视图合成中的表现，提出了一种改良后的Gaussian Splatting技术并用于生成高质量的视图，得出其能提升Photogrammetry模型重建效果的结论。


<details>
  <summary>Details</summary>
Motivation: 探索Photogrammetry与Gaussian Splatting技术在3D模型重建和新视图合成上的表现，以提升技术在XR、摄影测量和自动驾驶仿真等领域的应用能力。

Method: 通过建立一个包含真实场景图像的数据集，使用Photogrammetry和Gaussian Splatting方法构建3D模型，并设计多项指标（SSIM、PSNR、LPIPS、lp/mm分辨率）进行对比分析。研究还开发了一个改良的Gaussian Splatting代码库，用于生成Blender环境中的新视角图像，并结合原始图像和合成视图生成增强数据集进行测试。

Result: 显示Gaussian Splatting技术能够生成高质量的新视图，并在此基础上提升Photogrammetry模型的重建效果，同时指出两种方法的优劣。

Conclusion: Gaussian Splatting技术具有灵活性和潜力，能够提升Photogrammetry在3D重建中的表现，为XR、摄影测量和自动驾驶仿真提供有价值的信息和方法工具。

Abstract: In this paper, I present a comprehensive study comparing Photogrammetry and
Gaussian Splatting techniques for 3D model reconstruction and view synthesis. I
created a dataset of images from a real-world scene and constructed 3D models
using both methods. To evaluate the performance, I compared the models using
structural similarity index (SSIM), peak signal-to-noise ratio (PSNR), learned
perceptual image patch similarity (LPIPS), and lp/mm resolution based on the
USAF resolution chart. A significant contribution of this work is the
development of a modified Gaussian Splatting repository, which I forked and
enhanced to enable rendering images from novel camera poses generated in the
Blender environment. This innovation allows for the synthesis of high-quality
novel views, showcasing the flexibility and potential of Gaussian Splatting. My
investigation extends to an augmented dataset that includes both original
ground images and novel views synthesized via Gaussian Splatting. This
augmented dataset was employed to generate a new photogrammetry model, which
was then compared against the original photogrammetry model created using only
the original images. The results demonstrate the efficacy of using Gaussian
Splatting to generate novel high-quality views and its potential to improve
photogrammetry-based 3D reconstructions. The comparative analysis highlights
the strengths and limitations of both approaches, providing valuable
information for applications in extended reality (XR), photogrammetry, and
autonomous vehicle simulations. Code is available at
https://github.com/pranavc2255/gaussian-splatting-novel-view-render.git.

</details>


### [114] [VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding](https://arxiv.org/abs/2508.07493)
*Jian Chen,Ming Li,Jihyung Kil,Chenguang Wang,Tong Yu,Ryan Rossi,Tianyi Zhou,Changyou Chen,Ruiyi Zhang*

Main category: cs.CV

TL;DR: VisR-Bench是一个针对多语言长文档的多模态问答检索基准，由35K高质量QA对和16种语言组成，涵盖图表、文本和表格等类型。


<details>
  <summary>Details</summary>
Motivation: 现有数据集专注于单语言或单页图像的检索，缺乏对多语言和长文档的支持，限制了多模态检索的更广泛应用。

Method: 提出了VisR-Bench数据集，包含多个语言的高质量QA对，支持细粒度多模态检索评估，并设计了没有明确答案的查询以避免模型关键词匹配。

Result: 实验表明，多语言大型语言模型（MLLMs）在检索性能上优于单纯文本或多模态编码器，但在结构化表格和低资源语言上仍存在挑战。

Conclusion: VisR-Bench揭示了目前多语言视觉检索领域的关键挑战，为未来研究指明了方向。

Abstract: Most organizational data in this world are stored as documents, and visual
retrieval plays a crucial role in unlocking the collective intelligence from
all these documents. However, existing benchmarks focus on English-only
document retrieval or only consider multilingual question-answering on a
single-page image. To bridge this gap, we introduce VisR-Bench, a multilingual
benchmark designed for question-driven multimodal retrieval in long documents.
Our benchmark comprises over 35K high-quality QA pairs across 1.2K documents,
enabling fine-grained evaluation of multimodal retrieval. VisR-Bench spans
sixteen languages with three question types (figures, text, and tables),
offering diverse linguistic and question coverage. Unlike prior datasets, we
include queries without explicit answers, preventing models from relying on
superficial keyword matching. We evaluate various retrieval models, including
text-based methods, multimodal encoders, and MLLMs, providing insights into
their strengths and limitations. Our results show that while MLLMs
significantly outperform text-based and multimodal encoder models, they still
struggle with structured tables and low-resource languages, highlighting key
challenges in multilingual visual retrieval.

</details>


### [115] [FormCoach: Lift Smarter, Not Harder](https://arxiv.org/abs/2508.07501)
*Xiaoye Zuo,Nikos Athanasiou,Ginger Delmas,Yiming Huang,Xingyu Fu,Lingjie Liu*

Main category: cs.CV

TL;DR: FormCoach是一个利用视觉语言模型(VLM)的AI教练系统，通过摄像头实时识别运动形式错误并提供纠正建议。


<details>
  <summary>Details</summary>
Motivation: 解决居家健身者缺乏专家指导的问题，用于提供实时互动的运动形式纠正。

Method: 利用VLM进行用户动作分析，开发数据集和基准评估管道，提出AI驱动的健身教练框架。

Result: 在标注的1700条视频对上测试发现，与人类教练相比仍存在显著差距。

Conclusion: FormCoach通过人与机器协作改变AI健身指导方式，但实现精确上下文感知分析仍有挑战。

Abstract: Good form is the difference between strength and strain, yet for the
fast-growing community of at-home fitness enthusiasts, expert feedback is often
out of reach. FormCoach transforms a simple camera into an always-on,
interactive AI training partner, capable of spotting subtle form errors and
delivering tailored corrections in real time, leveraging vision-language models
(VLMs). We showcase this capability through a web interface and benchmark
state-of-the-art VLMs on a dataset of 1,700 expert-annotated user-reference
video pairs spanning 22 strength and mobility exercises. To accelerate research
in AI-driven coaching, we release both the dataset and an automated,
rubric-based evaluation pipeline, enabling standardized comparison across
models. Our benchmarks reveal substantial gaps compared to human-level
coaching, underscoring both the challenges and opportunities in integrating
nuanced, context-aware movement analysis into interactive AI systems. By
framing form correction as a collaborative and creative process between humans
and machines, FormCoach opens a new frontier in embodied AI.

</details>


### [116] [From Field to Drone: Domain Drift Tolerant Automated Multi-Species and Damage Plant Semantic Segmentation for Herbicide Trials](https://arxiv.org/abs/2508.07514)
*Artzai Picon,Itziar Eguskiza,Daniel Mugica,Javier Romero,Carlos Javier Jimenez,Eric White,Gabriel Do-Lago-Junqueira,Christian Klukas,Ramon Navarra-Mestre*

Main category: cs.CV

TL;DR: 這篇論文提出了一種結合自監督視覺模型與基於植物學分類學層次推理的分割模型，用於提升農作物和雜草的物種和損害識別精準度，並經過不同地區和設備上的測試驗證其通用性與穩健性。


<details>
  <summary>Details</summary>
Motivation: 傳統的除草劑研究中，對田間試驗效果的人工目測評估耗時、費力且主觀性強，因此需要一種高效且一致的自動化方法來處理作物和雜草的物種及損害識別。

Method: 提出了一個改進的分割模型，結合了自監督視覺模型和基於植物分類的層次推理。模型使用了不同年份與地點（如德國、西班牙和美國）採集的數據進行訓練及測試，並特別對不同設備（如無人機圖像）的域轉移能力進行評估。

Result: 模型在物種識別的F1-score從0.52提升到0.85（R-squared 0.75到0.98），損害分類的F1-score從0.28增至0.44（R-squared 0.71到0.87）。即便在無人機圖像的域轉移情況下，性能依然保持穩健。

Conclusion: 模型的穩健性及其在現實場景中的應用性已得到驗證，且其已部署在BASF的表型檢測流程中，用於大規模的作物和雜草自動化監測。

Abstract: Field trials are vital in herbicide research and development to assess
effects on crops and weeds under varied conditions. Traditionally, evaluations
rely on manual visual assessments, which are time-consuming, labor-intensive,
and subjective. Automating species and damage identification is challenging due
to subtle visual differences, but it can greatly enhance efficiency and
consistency.
  We present an improved segmentation model combining a general-purpose
self-supervised visual model with hierarchical inference based on botanical
taxonomy. Trained on a multi-year dataset (2018-2020) from Germany and Spain
using digital and mobile cameras, the model was tested on digital camera data
(year 2023) and drone imagery from the United States, Germany, and Spain (year
2024) to evaluate robustness under domain shift. This cross-device evaluation
marks a key step in assessing generalization across platforms of the model.
  Our model significantly improved species identification (F1-score: 0.52 to
0.85, R-squared: 0.75 to 0.98) and damage classification (F1-score: 0.28 to
0.44, R-squared: 0.71 to 0.87) over prior methods. Under domain shift (drone
images), it maintained strong performance with moderate degradation (species:
F1-score 0.60, R-squared 0.80; damage: F1-score 0.41, R-squared 0.62), where
earlier models failed.
  These results confirm the model's robustness and real-world applicability. It
is now deployed in BASF's phenotyping pipeline, enabling large-scale, automated
crop and weed monitoring across diverse geographies.

</details>


### [117] [Exploring Multimodal Diffusion Transformers for Enhanced Prompt-based Image Editing](https://arxiv.org/abs/2508.07519)
*Joonghyuk Shin,Alchan Hwang,Yujin Kim,Daneul Kim,Jaesik Park*

Main category: cs.CV

TL;DR: 该论文介绍了多模态扩散变换器(MM-DiT)，提出统一注意力机制，实现文本与图像之间的双向信息流动，并进行系统分析，提出适用于其变体的图像编辑方法。


<details>
  <summary>Details</summary>
Motivation: 探讨如何改进基于变换器的扩散模型架构（如MM-DiT），同时克服现有图像编辑技术在此架构上的挑战。

Method: 通过将MM-DiT的注意力矩阵分解为四个部分，分析其特点，并提出基于提示的图像编辑方法，适用于从全局到局部的不同变体。

Result: 成功设计了一种强健的图像编辑技术，适配多模态变换器，并扩展到不同的MM-DiT变体上。

Conclusion: 研究提供了对新兴架构MM-DiT行为模式的深入见解，为弥合传统模型和新兴架构之间的技术差距做出了贡献。

Abstract: Transformer-based diffusion models have recently superseded traditional U-Net
architectures, with multimodal diffusion transformers (MM-DiT) emerging as the
dominant approach in state-of-the-art models like Stable Diffusion 3 and
Flux.1. Previous approaches have relied on unidirectional cross-attention
mechanisms, with information flowing from text embeddings to image latents. In
contrast, MMDiT introduces a unified attention mechanism that concatenates
input projections from both modalities and performs a single full attention
operation, allowing bidirectional information flow between text and image
branches. This architectural shift presents significant challenges for existing
editing techniques. In this paper, we systematically analyze MM-DiT's attention
mechanism by decomposing attention matrices into four distinct blocks,
revealing their inherent characteristics. Through these analyses, we propose a
robust, prompt-based image editing method for MM-DiT that supports global to
local edits across various MM-DiT variants, including few-step models. We
believe our findings bridge the gap between existing U-Net-based methods and
emerging architectures, offering deeper insights into MMDiT's behavioral
patterns.

</details>


### [118] [Enhancing Reliability of Medical Image Diagnosis through Top-rank Learning with Rejection Module](https://arxiv.org/abs/2508.07528)
*Xiaotong Ji,Ryoma Bise,Seiichi Uchida*

Main category: cs.CV

TL;DR: 本文提出了一种改进的Top-rank学习方法，通过加入拒绝模块来提高分类精度，尤其针对医疗图像处理中的噪声标签和分类模糊实例问题。


<details>
  <summary>Details</summary>
Motivation: 在医疗图像处理中，准确的诊断至关重要，但现有的Top-rank学习方法容易受到噪声标签和模糊实例的影响，导致关键实例排序错误。

Method: 设计了一种与Top-rank损失共同优化的拒绝模块，该模块通过评估样本偏离正常分布的程度，筛选和减轻异常点对训练的负面影响。

Result: 在医疗数据集的实验验证中，本方法有效检测并处理异常点，显著提高了诊断的可靠性和准确性。

Conclusion: 通过合理整合拒绝模块，改进了Top-rank学习模型的稳健性，为医疗图像诊断提供了更准确的支持。

Abstract: In medical image processing, accurate diagnosis is of paramount importance.
Leveraging machine learning techniques, particularly top-rank learning, shows
significant promise by focusing on the most crucial instances. However,
challenges arise from noisy labels and class-ambiguous instances, which can
severely hinder the top-rank objective, as they may be erroneously placed among
the top-ranked instances. To address these, we propose a novel approach that
enhances toprank learning by integrating a rejection module. Cooptimized with
the top-rank loss, this module identifies and mitigates the impact of outliers
that hinder training effectiveness. The rejection module functions as an
additional branch, assessing instances based on a rejection function that
measures their deviation from the norm. Through experimental validation on a
medical dataset, our methodology demonstrates its efficacy in detecting and
mitigating outliers, improving the reliability and accuracy of medical image
diagnoses.

</details>


### [119] [Enhanced Generative Structure Prior for Chinese Text Image Super-resolution](https://arxiv.org/abs/2508.07537)
*Xiaoming Li,Wangmeng Zuo,Chen Change Loy*

Main category: cs.CV

TL;DR: 本论文提出了一种专为汉字设计的高质量文本图像超分辨率框架，通过独特的结构先验结合StyleGAN来提升恢复效果。


<details>
  <summary>Details</summary>
Motivation: 现有文本图像超分辨率方法多数专注于英语文本，较复杂的汉字恢复难以实现。因此，研究旨在针对低分辨率汉字恢复设计高保真解决方案，保留字符结构完整性并适应多种风格。

Method: 提出一种新颖的结构先验引入StyleGAN框架，通过codebook机制限制生成空间，每个code表示具体汉字结构，StyleGAN的矢量$w$控制字体风格。

Result: 实验结果表明，结构先验提供了有力、特定字符指导，可以准确恢复退化汉字的清晰笔画，即使对于真实场景中低分辨率文本也具有良好表现。

Conclusion: 所提出的方法能够针对复杂汉字恢复任务有效工作，生成高分辨率结构先验以实现高质量的超分辨率恢复，未来有望广泛应用。

Abstract: Faithful text image super-resolution (SR) is challenging because each
character has a unique structure and usually exhibits diverse font styles and
layouts. While existing methods primarily focus on English text, less attention
has been paid to more complex scripts like Chinese. In this paper, we introduce
a high-quality text image SR framework designed to restore the precise strokes
of low-resolution (LR) Chinese characters. Unlike methods that rely on
character recognition priors to regularize the SR task, we propose a novel
structure prior that offers structure-level guidance to enhance visual quality.
Our framework incorporates this structure prior within a StyleGAN model,
leveraging its generative capabilities for restoration. To maintain the
integrity of character structures while accommodating various font styles and
layouts, we implement a codebook-based mechanism that restricts the generative
space of StyleGAN. Each code in the codebook represents the structure of a
specific character, while the vector $w$ in StyleGAN controls the character's
style, including typeface, orientation, and location. Through the collaborative
interaction between the codebook and style, we generate a high-resolution
structure prior that aligns with LR characters both spatially and structurally.
Experiments demonstrate that this structure prior provides robust,
character-specific guidance, enabling the accurate restoration of clear strokes
in degraded characters, even for real-world LR Chinese text with irregular
layouts. Our code and pre-trained models will be available at
https://github.com/csxmli2016/MARCONetPlusPlus

</details>


### [120] [A DICOM Image De-identification Algorithm in the MIDI-B Challenge](https://arxiv.org/abs/2508.07538)
*Hongzhu Jiang,Sihan Xie,Zhiyu Wan*

Main category: cs.CV

TL;DR: 本文介绍了DICOM医学图像匿名化的重要性及其在遵循相关法规和标准中的作用，描述了在MIDI-B挑战中取得的成果，特别是算法达到了99.92%的正确率，并探讨了该领域未来的改进方向。


<details>
  <summary>Details</summary>
Motivation: 推动医学图像公开共享中隐私保护与数据可用性之间的平衡，满足法规及标准所需的匿名化要求。

Method: 采用算法包括像素遮掩、日期转换、日期哈希、文本识别、文本替换及文本去除等匿名化方法，以严格符合医学图像匿名化相关标准进行数据处理。

Result: 算法在MIDI-B挑战中以99.92%的正确率排名第2，在10支完成挑战队伍中表现突出。

Conclusion: 目前的方法能有效去除个人身份信息并保护患者隐私，但仍存在改进空间，例如提高处理精度和应对复杂场景的能力。

Abstract: Image de-identification is essential for the public sharing of medical
images, particularly in the widely used Digital Imaging and Communications in
Medicine (DICOM) format as required by various regulations and standards,
including Health Insurance Portability and Accountability Act (HIPAA) privacy
rules, the DICOM PS3.15 standard, and best practices recommended by the Cancer
Imaging Archive (TCIA). The Medical Image De-Identification Benchmark (MIDI-B)
Challenge at the 27th International Conference on Medical Image Computing and
Computer Assisted Intervention (MICCAI 2024) was organized to evaluate
rule-based DICOM image de-identification algorithms with a large dataset of
clinical DICOM images. In this report, we explore the critical challenges of
de-identifying DICOM images, emphasize the importance of removing personally
identifiable information (PII) to protect patient privacy while ensuring the
continued utility of medical data for research, diagnostics, and treatment, and
provide a comprehensive overview of the standards and regulations that govern
this process. Additionally, we detail the de-identification methods we applied
- such as pixel masking, date shifting, date hashing, text recognition, text
replacement, and text removal - to process datasets during the test phase in
strict compliance with these standards. According to the final leaderboard of
the MIDI-B challenge, the latest version of our solution algorithm correctly
executed 99.92% of the required actions and ranked 2nd out of 10 teams that
completed the challenge (from a total of 22 registered teams). Finally, we
conducted a thorough analysis of the resulting statistics and discussed the
limitations of current approaches and potential avenues for future improvement.

</details>


### [121] [Domain Generalization of Pathological Image Segmentation by Patch-Level and WSI-Level Contrastive Learning](https://arxiv.org/abs/2508.07539)
*Yuki Shigeyasu,Shota Harada,Akihiko Yoshizawa,Kazuhiro Terada,Naoki Nakazima,Mariyo Kurata,Hiroyuki Abe,Tetsuo Ushiku,Ryoma Bise*

Main category: cs.CV

TL;DR: 本文提出一种通过聚类非肿瘤区域的WSI特征及使用对比学习减少不同集群间特征差异的新方法，解决病理图像的域偏移问题。


<details>
  <summary>Details</summary>
Motivation: 解决病理图像中全切片图像存在的因患者特征和组织厚度引起的域偏移问题，而无需依赖多医院数据。

Method: 通过聚类WSI中非肿瘤区域的特征，将聚类结果视为不同域，并构建一种两阶段对比学习方法，包括WSI级别和Patch级别的对比学习以减少域间的特征差异。

Result: 提出的方法能够捕获并利用医院内部的域偏移信息，且通过对比学习有效减少域间的特征间隙。

Conclusion: 此方法在不需要多医院数据的情况下，提供了一种有效应对病理图像域偏移的解决方案。

Abstract: In this paper, we address domain shifts in pathological images by focusing on
shifts within whole slide images~(WSIs), such as patient characteristics and
tissue thickness, rather than shifts between hospitals. Traditional approaches
rely on multi-hospital data, but data collection challenges often make this
impractical. Therefore, the proposed domain generalization method captures and
leverages intra-hospital domain shifts by clustering WSI-level features from
non-tumor regions and treating these clusters as domains. To mitigate domain
shift, we apply contrastive learning to reduce feature gaps between WSI pairs
from different clusters. The proposed method introduces a two-stage contrastive
learning approach WSI-level and patch-level contrastive learning to minimize
these gaps effectively.

</details>


### [122] [CoT-Pose: Chain-of-Thought Reasoning for 3D Pose Generation from Abstract Prompts](https://arxiv.org/abs/2508.07540)
*Junuk Cha,Jihyeon Kim*

Main category: cs.CV

TL;DR: 本文提出了一种新框架CoT-Pose，将链式推理引入到3D人体姿态生成中，以解决当前文本到姿态生成模型依赖于低层次细节提示的问题。


<details>
  <summary>Details</summary>
Motivation: 目前的3D人体姿态生成方法严依赖详细的低层次提示，与人类依靠抽象语言沟通意图的方式不匹配，限制了实际应用。

Method: 引入链式推理处理框架，并提出数据合成流水线，自动生成抽象提示、详细提示和对应3D姿态三元组，用于训练模型。

Result: 实验表明，提出的CoT-Pose可以从抽象语言提示中生成可信且语义对齐的3D人体姿态。

Conclusion: 本文强调高层次理解在姿态生成中的重要性，并开辟了基于推理增强方法的新研究方向。

Abstract: Recent advances in multi-modal large language models (MLLMs) and
chain-of-thought (CoT) reasoning have led to significant progress in image and
text generation tasks. However, the field of 3D human pose generation still
faces critical limitations. Most existing text-to-pose models rely heavily on
detailed (low-level) prompts that explicitly describe joint configurations. In
contrast, humans tend to communicate actions and intentions using abstract
(high-level) language. This mismatch results in a practical challenge for
deploying pose generation systems in real-world scenarios. To bridge this gap,
we introduce a novel framework that incorporates CoT reasoning into the pose
generation process, enabling the interpretation of abstract prompts into
accurate 3D human poses. We further propose a data synthesis pipeline that
automatically generates triplets of abstract prompts, detailed prompts, and
corresponding 3D poses for training process. Experimental results demonstrate
that our reasoning-enhanced model, CoT-Pose, can effectively generate plausible
and semantically aligned poses from abstract textual inputs. This work
highlights the importance of high-level understanding in pose generation and
opens new directions for reasoning-enhanced approach for human pose generation.

</details>


### [123] [Commentary Generation for Soccer Highlights](https://arxiv.org/abs/2508.07543)
*Chidaksh Ravuru*

Main category: cs.CV

TL;DR: 本文聚焦于足球赛事自动解说生成，提出了针对集锦的新模型，并对MatchVoice进行了扩展和优化，探索硬件和模型配置对结果的影响。


<details>
  <summary>Details</summary>
Motivation: 现有方法，包括SoccerNet-Caption和MatchVoice存在视频内容与解说之间的精细化对齐不足的问题。

Method: 本文基于MatchVoice模型，以GOAL数据集为主，研究短视频的解说生成，分析了硬件和不同训练结构对结果的影响，并探索了窗口大小在零样本设定下的性能影响。

Result: MatchVoice对短视频自动生成解说展示了一定的泛化能力，但仍需结合更广泛的视频-语言领域的技术以提高性能。

Conclusion: 尽管结果有希望，该领域需要进一步的优化以改进模型表现。

Abstract: Automated soccer commentary generation has evolved from template-based
systems to advanced neural architectures, aiming to produce real-time
descriptions of sports events. While frameworks like SoccerNet-Caption laid
foundational work, their inability to achieve fine-grained alignment between
video content and commentary remains a significant challenge. Recent efforts
such as MatchTime, with its MatchVoice model, address this issue through coarse
and fine-grained alignment techniques, achieving improved temporal
synchronization. In this paper, we extend MatchVoice to commentary generation
for soccer highlights using the GOAL dataset, which emphasizes short clips over
entire games. We conduct extensive experiments to reproduce the original
MatchTime results and evaluate our setup, highlighting the impact of different
training configurations and hardware limitations. Furthermore, we explore the
effect of varying window sizes on zero-shot performance. While MatchVoice
exhibits promising generalization capabilities, our findings suggest the need
for integrating techniques from broader video-language domains to further
enhance performance. Our code is available at
https://github.com/chidaksh/SoccerCommentary.

</details>


### [124] [Adaptive Pseudo Label Selection for Individual Unlabeled Data by Positive and Unlabeled Learning](https://arxiv.org/abs/2508.07548)
*Takehiro Yamane,Itaru Tsuge,Susumu Saito,Ryoma Bise*

Main category: cs.CV

TL;DR: 本文提出一种用于医学图像分割的新型伪标签方法，该方法基于“单一图像”学习选择有效伪标签。


<details>
  <summary>Details</summary>
Motivation: 利用正样本和未标注样本学习（PU学习），为分类二元问题提供一种在未标注图像上区分前景和背景区域的度量。

Method: 引入PU学习，仅基于正样本与未标注数据，通过度量对单一图像的背景和前景区域进行筛选，从而选择伪标签。

Result: 实验结果显示该方法有效。

Conclusion: 提出的方法能够简化并改善伪标签的选择过程，为医学图像分割提供新方向。

Abstract: This paper proposes a novel pseudo-labeling method for medical image
segmentation that can perform learning on ``individual images'' to select
effective pseudo-labels. We introduce Positive and Unlabeled Learning (PU
learning), which uses only positive and unlabeled data for binary
classification problems, to obtain the appropriate metric for discriminating
foreground and background regions on each unlabeled image. Our PU learning
makes us easy to select pseudo-labels for various background regions. The
experimental results show the effectiveness of our method.

</details>


### [125] [Decoupled Functional Evaluation of Autonomous Driving Models via Feature Map Quality Scoring](https://arxiv.org/abs/2508.07552)
*Ludan Zhang,Sihan Wang,Yuqi Dai,Shuofei Qiao,Lei He*

Main category: cs.CV

TL;DR: 提出了一种基于特征图收敛分数（FMCS）的评估方法，用以评估自动驾驶感知与规划中的中间特征模块表现，并开发了一个基于CLIP的特征图质量评估网络，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶模型中，由于缺乏对中间功能模块的显性监督信号，透明性和可解释性受到限制，该研究旨在解决这一问题，提出一个独立评估方法。

Method: 建立了一个基于FMCS的评估框架，并设计了双粒度动态加权评分系统（DG-DWSS）以生成特征图质量分数，同时开发了基于CLIP的特征图质量评估网络（CLIP-FMQE-Net）。

Result: 在NuScenes数据集的实验结果表明，集成评估模块后3D目标检测性能提升3.89%（NDS），验证了该方法在增强特征表示质量和模型性能方面的有效性。

Conclusion: 本研究提出的方法能够有效提高自动驾驶模型中中间特征功能模块的评估质量和整体表现。

Abstract: End-to-end models are emerging as the mainstream in autonomous driving
perception and planning. However, the lack of explicit supervision signals for
intermediate functional modules leads to opaque operational mechanisms and
limited interpretability, making it challenging for traditional methods to
independently evaluate and train these modules. Pioneering in the issue, this
study builds upon the feature map-truth representation similarity-based
evaluation framework and proposes an independent evaluation method based on
Feature Map Convergence Score (FMCS). A Dual-Granularity Dynamic Weighted
Scoring System (DG-DWSS) is constructed, formulating a unified quantitative
metric - Feature Map Quality Score - to enable comprehensive evaluation of the
quality of feature maps generated by functional modules. A CLIP-based Feature
Map Quality Evaluation Network (CLIP-FMQE-Net) is further developed, combining
feature-truth encoders and quality score prediction heads to enable real-time
quality analysis of feature maps generated by functional modules. Experimental
results on the NuScenes dataset demonstrate that integrating our evaluation
module into the training improves 3D object detection performance, achieving a
3.89 percent gain in NDS. These results verify the effectiveness of our method
in enhancing feature representation quality and overall model performance.

</details>


### [126] [Splat4D: Diffusion-Enhanced 4D Gaussian Splatting for Temporally and Spatially Consistent Content Creation](https://arxiv.org/abs/2508.07557)
*Minghao Yin,Yukang Cao,Songyou Peng,Kai Han*

Main category: cs.CV

TL;DR: Splat4D框架利用单目视频实现高质量4D内容生成，表现出色并具有广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 解决生成高质量4D内容时的时间和空间一致性问题，同时保留细节并接受用户指导。

Method: 结合多视图渲染、不一致性识别、视频扩散模型和非对称U-Net进行精化处理。

Result: 在公开数据集上性能超越现有方法，各项指标均表现优异。

Conclusion: Splat4D能生成高保真的4D内容，并应用于多种场景（如文本/图像驱动的4D生成、4D人像生成及文本指导的内容编辑）。

Abstract: Generating high-quality 4D content from monocular videos for applications
such as digital humans and AR/VR poses challenges in ensuring temporal and
spatial consistency, preserving intricate details, and incorporating user
guidance effectively. To overcome these challenges, we introduce Splat4D, a
novel framework enabling high-fidelity 4D content generation from a monocular
video. Splat4D achieves superior performance while maintaining faithful
spatial-temporal coherence by leveraging multi-view rendering, inconsistency
identification, a video diffusion model, and an asymmetric U-Net for
refinement. Through extensive evaluations on public benchmarks, Splat4D
consistently demonstrates state-of-the-art performance across various metrics,
underscoring the efficacy of our approach. Additionally, the versatility of
Splat4D is validated in various applications such as text/image conditioned 4D
generation, 4D human generation, and text-guided content editing, producing
coherent outcomes following user instructions.

</details>


### [127] [Adaptive Cache Enhancement for Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2508.07570)
*Khanh-Binh Nguyen,Phuoc-Nguyen Bui,Hyunseung Choo,Duc Thanh Nguyen*

Main category: cs.CV

TL;DR: ACE框架通过自适应缓存增强方法应对分布迁移问题，显著改进了TTA在15个基准数据集上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言模型（VLMs）在零样本泛化中的表现受到分布迁移影响下性能下降的挑战，特别是缺少标注数据的情况下。

Method: 提出ACE框架，通过动态、类别特定的阈值构建健壮的缓存，动态调整类别边界，确保多样化视觉分布下的稳健预测。

Result: ACE方法在15个基准数据集上的实验中，实现了比现有测试时适应（TTA）方法更高的性能，表现出卓越的鲁棒性和泛化能力。

Conclusion: ACE框架显著提高了在分布迁移场景下视觉-语言模型的性能，展示出了其在不同场景下的应用潜力和实用性。

Abstract: Vision-language models (VLMs) exhibit remarkable zero-shot generalization but
suffer performance degradation under distribution shifts in downstream tasks,
particularly in the absence of labeled data. Test-Time Adaptation (TTA)
addresses this challenge by enabling online optimization of VLMs during
inference, eliminating the need for annotated data. Cache-based TTA methods
exploit historical knowledge by maintaining a dynamic memory cache of
low-entropy or high-confidence samples, promoting efficient adaptation to
out-of-distribution data. Nevertheless, these methods face two critical
challenges: (1) unreliable confidence metrics under significant distribution
shifts, resulting in error accumulation within the cache and degraded
adaptation performance; and (2) rigid decision boundaries that fail to
accommodate substantial distributional variations, leading to suboptimal
predictions. To overcome these limitations, we introduce the Adaptive Cache
Enhancement (ACE) framework, which constructs a robust cache by selectively
storing high-confidence or low-entropy image embeddings per class, guided by
dynamic, class-specific thresholds initialized from zero-shot statistics and
iteratively refined using an exponential moving average and
exploration-augmented updates. This approach enables adaptive, class-wise
decision boundaries, ensuring robust and accurate predictions across diverse
visual distributions. Extensive experiments on 15 diverse benchmark datasets
demonstrate that ACE achieves state-of-the-art performance, delivering superior
robustness and generalization compared to existing TTA methods in challenging
out-of-distribution scenarios.

</details>


### [128] [Exploiting Layer Normalization Fine-tuning in Visual Transformer Foundation Models for Classification](https://arxiv.org/abs/2508.07577)
*Zhaorui Tan,Tan Pan,Kaizhu Huang,Weimiao Yu,Kai Yao,Chen Jiang,Qiufeng Wang,Anh Nguyen,Xin Guo,Yuan Cheng,Xi Yang*

Main category: cs.CV

TL;DR: 这篇论文探讨了在数据稀缺和领域转移情况下，Vision Transformer中的LayerNorm参数微调动态问题。


<details>
  <summary>Details</summary>
Motivation: 旨在研究LayerNorm在源领域到目标领域转移中的动态变化，以及如何改进在数据不足或分布外任务上的泛化能力。

Method: 提出了一种新的Fine-tuning Shift Ratio (FSR)指标，通过与FSR负相关的标量λ缩放机制和循环框架来优化LayerNorm微调过程。

Result: 实验表明，该方法在自然图像和病理图像的各种设置下表现优异，尤其在分布外任务和数据稀缺情况下凸显其有效性。

Conclusion: 首次揭示了LayerNorm在迁移学习中的未明确的动态行为，并提供了一套实际有效的微调策略。

Abstract: LayerNorm is pivotal in Vision Transformers (ViTs), yet its fine-tuning
dynamics under data scarcity and domain shifts remain underexplored. This paper
shows that shifts in LayerNorm parameters after fine-tuning (LayerNorm shifts)
are indicative of the transitions between source and target domains; its
efficacy is contingent upon the degree to which the target training samples
accurately represent the target domain, as quantified by our proposed
Fine-tuning Shift Ratio ($FSR$). Building on this, we propose a simple yet
effective rescaling mechanism using a scalar $\lambda$ that is negatively
correlated to $FSR$ to align learned LayerNorm shifts with those ideal shifts
achieved under fully representative data, combined with a cyclic framework that
further enhances the LayerNorm fine-tuning. Extensive experiments across
natural and pathological images, in both in-distribution (ID) and
out-of-distribution (OOD) settings, and various target training sample regimes
validate our framework. Notably, OOD tasks tend to yield lower $FSR$ and higher
$\lambda$ in comparison to ID cases, especially with scarce data, indicating
under-represented target training samples. Moreover, ViTFs fine-tuned on
pathological data behave more like ID settings, favoring conservative LayerNorm
updates. Our findings illuminate the underexplored dynamics of LayerNorm in
transfer learning and provide practical strategies for LayerNorm fine-tuning.

</details>


### [129] [GAPNet: A Lightweight Framework for Image and Video Salient Object Detection via Granularity-Aware Paradigm](https://arxiv.org/abs/2508.07585)
*Yu-Huan Wu,Wei Liu,Zi-Xuan Zhu,Zizhou Wang,Yong Liu,Liangli Zhen*

Main category: cs.CV

TL;DR: GAPNet是一种轻量级显著性目标检测网络，针对图像和视频，采用粒度感知连接及模块实现高低粒度特征的高效融合，计算量小且性能出色。


<details>
  <summary>Details</summary>
Motivation: 现有显著性目标检测模型计算成本高，不适用于实际应用场景和边缘设备。

Method: 采用粒度感知监督方法，利用粒度金字塔卷积和跨尺度注意模块，在多尺度解码器中融合高、低粒度特征，并在编码器中引入自注意力模块以优化全局信息学习。

Result: GAPNet在轻量级图像和视频显著性目标检测模型中达到了新的最佳性能表现。

Conclusion: 本文提出方法显著提升了计算效率和检测准确性，为实际应用提供了高效解决方案。

Abstract: Recent salient object detection (SOD) models predominantly rely on
heavyweight backbones, incurring substantial computational cost and hindering
their practical application in various real-world settings, particularly on
edge devices. This paper presents GAPNet, a lightweight network built on the
granularity-aware paradigm for both image and video SOD. We assign saliency
maps of different granularities to supervise the multi-scale decoder
side-outputs: coarse object locations for high-level outputs and fine-grained
object boundaries for low-level outputs. Specifically, our decoder is built
with granularity-aware connections which fuse high-level features of low
granularity and low-level features of high granularity, respectively. To
support these connections, we design granular pyramid convolution (GPC) and
cross-scale attention (CSA) modules for efficient fusion of low-scale and
high-scale features, respectively. On top of the encoder, a self-attention
module is built to learn global information, enabling accurate object
localization with negligible computational cost. Unlike traditional U-Net-based
approaches, our proposed method optimizes feature utilization and semantic
interpretation while applying appropriate supervision at each processing stage.
Extensive experiments show that the proposed method achieves a new
state-of-the-art performance among lightweight image and video SOD models. Code
is available at https://github.com/yuhuan-wu/GAPNet.

</details>


### [130] [Voice Pathology Detection Using Phonation](https://arxiv.org/abs/2508.07587)
*Sri Raksha Siva,Nived Suthahar,Prakash Boominathan,Uma Ranjan*

Main category: cs.CV

TL;DR: 研究开发了一个基于机器学习的非侵入性诊断框架，用于检测语音病理问题。


<details>
  <summary>Details</summary>
Motivation: 传统检查语音病理的方法具有侵入性、主观性且不易获得，因此需要一种更加便利、准确的诊断手段。

Method: 利用Saarbrücken语音数据库中的语音发声数据，提取声学特征（例如MFCC、色度特征和Mel谱图），结合RNN、LSTM和注意力机制进行分类。通过数据增强和预处理技术提高模型的鲁棒性，并使用Hölder指数和Hurst指数等刻画信号特征。

Result: 所提出的框架能够高效分类正常与病理语音样本，显示出人工智能在健康护理中的应用潜力。

Conclusion: 非侵入性诊断框架为语音病理问题的早期检测提供了自动化工具，有助于提升医疗效率和改善患者健康状况。

Abstract: Voice disorders significantly affect communication and quality of life,
requiring an early and accurate diagnosis. Traditional methods like
laryngoscopy are invasive, subjective, and often inaccessible. This research
proposes a noninvasive, machine learning-based framework for detecting voice
pathologies using phonation data.
  Phonation data from the Saarbr\"ucken Voice Database are analyzed using
acoustic features such as Mel Frequency Cepstral Coefficients (MFCCs), chroma
features, and Mel spectrograms. Recurrent Neural Networks (RNNs), including
LSTM and attention mechanisms, classify samples into normal and pathological
categories. Data augmentation techniques, including pitch shifting and Gaussian
noise addition, enhance model generalizability, while preprocessing ensures
signal quality. Scale-based features, such as H\"older and Hurst exponents,
further capture signal irregularities and long-term dependencies.
  The proposed framework offers a noninvasive, automated diagnostic tool for
early detection of voice pathologies, supporting AI-driven healthcare, and
improving patient outcomes.

</details>


### [131] [From Prediction to Explanation: Multimodal, Explainable, and Interactive Deepfake Detection Framework for Non-Expert Users](https://arxiv.org/abs/2508.07596)
*Shahroz Tariq,Simon S. Woo,Priyanka Singh,Irena Irmalasari,Saakshi Gupta,Dev Gupta*

Main category: cs.CV

TL;DR: 本文提出DF-P2E框架，用于解释性深度伪造检测，兼具预测和解释性能，基于DF40数据集验证其效果。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术威胁数字诚信，现有检测系统缺乏可解释性，限制实际应用，特别是对非专业用户。

Method: 提出DF-P2E框架，包括三大模块：基于Grad-CAM的深度伪造分类器、可视化说明模块和上下文敏感的叙述优化模块。

Result: 在DF40数据集上测试，DF-P2E在保持竞争性检测性能的同时，提供与Grad-CAM激活一致的高质量解释。

Conclusion: 本文通过统一预测与解释，提出了一种可扩展的解释型深度伪造检测方法，推动透明可信AI系统的应用。

Abstract: The proliferation of deepfake technologies poses urgent challenges and
serious risks to digital integrity, particularly within critical sectors such
as forensics, journalism, and the legal system. While existing detection
systems have made significant progress in classification accuracy, they
typically function as black-box models, offering limited transparency and
minimal support for human reasoning. This lack of interpretability hinders
their usability in real-world decision-making contexts, especially for
non-expert users. In this paper, we present DF-P2E (Deepfake: Prediction to
Explanation), a novel multimodal framework that integrates visual, semantic,
and narrative layers of explanation to make deepfake detection interpretable
and accessible. The framework consists of three modular components: (1) a
deepfake classifier with Grad-CAM-based saliency visualisation, (2) a visual
captioning module that generates natural language summaries of manipulated
regions, and (3) a narrative refinement module that uses a fine-tuned Large
Language Model (LLM) to produce context-aware, user-sensitive explanations. We
instantiate and evaluate the framework on the DF40 benchmark, the most diverse
deepfake dataset to date. Experiments demonstrate that our system achieves
competitive detection performance while providing high-quality explanations
aligned with Grad-CAM activations. By unifying prediction and explanation in a
coherent, human-aligned pipeline, this work offers a scalable approach to
interpretable deepfake detection, advancing the broader vision of trustworthy
and transparent AI systems in adversarial media environments.

</details>


### [132] [ShoulderShot: Generating Over-the-Shoulder Dialogue Videos](https://arxiv.org/abs/2508.07597)
*Yuang Zhang,Junqi Cheng,Haoyu Zhao,Jiaxi Gu,Fangyuan Zou,Zenghui Lu,Peng Shu*

Main category: cs.CV

TL;DR: 本文提出ShoulderShot框架，通过结合双镜头生成与循环视频，实现了对话视频的角色一致性和空间连续性，并增加了对话长度的灵活性。


<details>
  <summary>Details</summary>
Motivation: 探索生成带有对话的肩部镜头视频，这在实践中具有电影与广告的视觉效果和情感连接的重要性，并解决该领域的挑战问题。

Method: 采用了双镜头生成结合循环视频的方法，确保角色一致性、空间连续性，并优化对话生成的长度灵活性。

Result: 实验表现出超越现有方法的效果，在镜头切换布局、空间感与对话长度灵活性等多方面取得优势。

Conclusion: ShoulderShot框架为对话视频生成开辟了新方向，在实际应用中提升了镜头生成的水平，可满足更长对话的需求。

Abstract: Over-the-shoulder dialogue videos are essential in films, short dramas, and
advertisements, providing visual variety and enhancing viewers' emotional
connection. Despite their importance, such dialogue scenes remain largely
underexplored in video generation research. The main challenges include
maintaining character consistency across different shots, creating a sense of
spatial continuity, and generating long, multi-turn dialogues within limited
computational budgets. Here, we present ShoulderShot, a framework that combines
dual-shot generation with looping video, enabling extended dialogues while
preserving character consistency. Our results demonstrate capabilities that
surpass existing methods in terms of shot-reverse-shot layout, spatial
continuity, and flexibility in dialogue length, thereby opening up new
possibilities for practical dialogue video generation. Videos and comparisons
are available at https://shouldershot.github.io.

</details>


### [133] [LaVieID: Local Autoregressive Diffusion Transformers for Identity-Preserving Video Creation](https://arxiv.org/abs/2508.07603)
*Wenhui Song,Hanhui Li,Jiehui Huang,Panwen Hu,Yuhao Cheng,Long Chen,Yiqiang Yan,Xiaodan Liang*

Main category: cs.CV

TL;DR: LaVieID 是一种新的局部自回归视频扩散框架，旨在实现身份保持的文本到视频生成。通过局部路由和时间自回归模块，改进了面部特征表现和视频帧间一致性。


<details>
  <summary>Details</summary>
Motivation: 当前扩散变换器的全局生成过程损失身份信息，无法有效捕捉人脸特征的细节和保持视频帧间一致性，需解决这些问题。

Method: 提出 LaVieID 框架，通过局部路由改进面部局部特征的表示，并通过时间自回归模块优化视频生成中帧间一致性。

Result: LaVieID 实现了高保真个性化视频生成，并在身份保持文本到视频生成任务上达到了最先进水平。

Conclusion: 结合局部特征和长时间序列依赖的优势，LaVieID 成功改进了身份信息的保持和视频生成质量，并公开了模型代码。

Abstract: In this paper, we present LaVieID, a novel \underline{l}ocal
\underline{a}utoregressive \underline{vi}d\underline{e}o diffusion framework
designed to tackle the challenging \underline{id}entity-preserving
text-to-video task. The key idea of LaVieID is to mitigate the loss of identity
information inherent in the stochastic global generation process of diffusion
transformers (DiTs) from both spatial and temporal perspectives. Specifically,
unlike the global and unstructured modeling of facial latent states in existing
DiTs, LaVieID introduces a local router to explicitly represent latent states
by weighted combinations of fine-grained local facial structures. This
alleviates undesirable feature interference and encourages DiTs to capture
distinctive facial characteristics. Furthermore, a temporal autoregressive
module is integrated into LaVieID to refine denoised latent tokens before video
decoding. This module divides latent tokens temporally into chunks, exploiting
their long-range temporal dependencies to predict biases for rectifying tokens,
thereby significantly enhancing inter-frame identity consistency. Consequently,
LaVieID can generate high-fidelity personalized videos and achieve
state-of-the-art performance. Our code and models are available at
https://github.com/ssugarwh/LaVieID.

</details>


### [134] [X2Edit: Revisiting Arbitrary-Instruction Image Editing through Self-Constructed Data and Task-Aware Representation Learning](https://arxiv.org/abs/2508.07607)
*Jian Ma,Xujie Zhu,Zihao Pan,Qirong Peng,Xu Guo,Chen Chen,Haonan Lu*

Main category: cs.CV

TL;DR: 该论文提出了X2Edit Dataset，一个涵盖14种编辑任务的综合数据集，并设计了一种基于MoE-LoRA的训练方法以实现无缝图像编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的开源图像编辑数据集和可插拔编辑模块未能很好满足需求，作者希望构建一个通用且高质量的数据集并开发集成社区模型的模块。

Method: 通过行业领先的生成模型和专家模型创建数据，同时设计基于FLUX.1的MoE-LoRA训练方法，并引入对比学习来提升性能。

Result: 结果表明，模型的编辑性能在众多优秀模型中具有竞争力，构建的数据集也比现有的开源数据集具有显著优势。

Conclusion: 本文设计的X2Edit数据集和编辑模型表现出色，提供了高质量的标杆数据集和技术支持，为图像编辑领域作出贡献。

Abstract: Existing open-source datasets for arbitrary-instruction image editing remain
suboptimal, while a plug-and-play editing module compatible with
community-prevalent generative models is notably absent. In this paper, we
first introduce the X2Edit Dataset, a comprehensive dataset covering 14 diverse
editing tasks, including subject-driven generation. We utilize the
industry-leading unified image generation models and expert models to construct
the data. Meanwhile, we design reasonable editing instructions with the VLM and
implement various scoring mechanisms to filter the data. As a result, we
construct 3.7 million high-quality data with balanced categories. Second, to
better integrate seamlessly with community image generation models, we design
task-aware MoE-LoRA training based on FLUX.1, with only 8\% of the parameters
of the full model. To further improve the final performance, we utilize the
internal representations of the diffusion model and define positive/negative
samples based on image editing types to introduce contrastive learning.
Extensive experiments demonstrate that the model's editing performance is
competitive among many excellent models. Additionally, the constructed dataset
exhibits substantial advantages over existing open-source datasets. The
open-source code, checkpoints, and datasets for X2Edit can be found at the
following link: https://github.com/OPPO-Mente-Lab/X2Edit.

</details>


### [135] [An Iterative Reconstruction Method for Dental Cone-Beam Computed Tomography with a Truncated Field of View](https://arxiv.org/abs/2508.07618)
*Hyoung Suk Park,Kiwan Jeon*

Main category: cs.CV

TL;DR: 研究提出一种两阶段方法，通过隐式神经表示（INR）生成扩展区域的先验图像，并利用其纠正投影数据中的截断误差，从而提升牙科CBCT的图像质量。


<details>
  <summary>Details</summary>
Motivation: 小型化和低成本的牙科CBCT系统设计通常使用小型探测器，这导致了视场（FOV）截断无法完全覆盖患者头部，从而引发图像重建的质量退化问题。

Method: 第一阶段利用隐式神经表示（INR）生成具有扩展区域的先验图像，其前向投影可以完全覆盖患者头部；第二阶段用纠正误差后的投影数据进行传统迭代重建。

Result: 提出的两网格方法有效地抑制了截断伪影，显著改善了CBCT图像质量。

Conclusion: 通过两阶段方法结合INR和迭代重建克服了视场截断问题，对于牙科CBCT图像处理具有重要意义。

Abstract: In dental cone-beam computed tomography (CBCT), compact and cost-effective
system designs often use small detectors, resulting in a truncated field of
view (FOV) that does not fully encompass the patient's head. In iterative
reconstruction approaches, the discrepancy between the actual projection and
the forward projection within the truncated FOV accumulates over iterations,
leading to significant degradation in the reconstructed image quality. In this
study, we propose a two-stage approach to mitigate truncation artifacts in
dental CBCT. In the first stage, we employ Implicit Neural Representation
(INR), leveraging its superior representation power, to generate a prior image
over an extended region so that its forward projection fully covers the
patient's head. To reduce computational and memory burdens, INR reconstruction
is performed with a coarse voxel size. The forward projection of this prior
image is then used to estimate the discrepancy due to truncated FOV in the
measured projection data. In the second stage, the discrepancy-corrected
projection data is utilized in a conventional iterative reconstruction process
within the truncated region. Our numerical results demonstrate that the
proposed two-grid approach effectively suppresses truncation artifacts, leading
to improved CBCT image quality.

</details>


### [136] [SOFA: Deep Learning Framework for Simulating and Optimizing Atrial Fibrillation Ablation](https://arxiv.org/abs/2508.07621)
*Yunsung Chung,Chanho Lim,Ghassan Bidaoui,Christian Massad,Nassir Marrouche,Jihun Hamm*

Main category: cs.CV

TL;DR: 本论文提出了一个名为SOFA的深度学习框架，通过模拟心房纤颤消融手术的效果，预测术后复发风险，并优化手术参数以减少复发风险。


<details>
  <summary>Details</summary>
Motivation: 心房纤颤消融手术效果差异大，亟需通过模拟个体化因素改善手术结果。

Method: 提出了SOFA框架，结合患者术前LGE-MRI数据和具体手术参数，合成术后瘢痕图像，预测复发风险并优化手术参数。

Result: 该框架能准确生成术后图像，并通过优化策略将复发风险降低22.18%。

Conclusion: SOFA是首个集成手术效果模拟、复发预测和参数优化的框架，为个性化手术提供了新的工具。

Abstract: Atrial fibrillation (AF) is a prevalent cardiac arrhythmia often treated with
catheter ablation procedures, but procedural outcomes are highly variable.
Evaluating and improving ablation efficacy is challenging due to the complex
interaction between patient-specific tissue and procedural factors. This paper
asks two questions: Can AF recurrence be predicted by simulating the effects of
procedural parameters? How should we ablate to reduce AF recurrence? We propose
SOFA (Simulating and Optimizing Atrial Fibrillation Ablation), a novel
deep-learning framework that addresses these questions. SOFA first simulates
the outcome of an ablation strategy by generating a post-ablation image
depicting scar formation, conditioned on a patient's pre-ablation LGE-MRI and
the specific procedural parameters used (e.g., ablation locations, duration,
temperature, power, and force). During this simulation, it predicts AF
recurrence risk. Critically, SOFA then introduces an optimization scheme that
refines these procedural parameters to minimize the predicted risk. Our method
leverages a multi-modal, multi-view generator that processes 2.5D
representations of the atrium. Quantitative evaluations show that SOFA
accurately synthesizes post-ablation images and that our optimization scheme
leads to a 22.18\% reduction in the model-predicted recurrence risk. To the
best of our knowledge, SOFA is the first framework to integrate the simulation
of procedural effects, recurrence prediction, and parameter optimization,
offering a novel tool for personalizing AF ablation.

</details>


### [137] [Enhancing Egocentric Object Detection in Static Environments using Graph-based Spatial Anomaly Detection and Correction](https://arxiv.org/abs/2508.07624)
*Vishakha Lall,Yisi Liu*

Main category: cs.CV

TL;DR: 提出了一种基于图神经网络的后处理方法，利用物体间的空间关系来修正物体检测中的错误标签，并显著提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前物体检测模型在处理静态环境中物体布局固定的场景时，无法充分利用其内在的空间先验知识，导致检测不一致、漏检或误分类的问题。

Method: 提出了一个基于图神经网络的后处理管道，通过手动标注数据训练的GNN来建模物体间的空间关系，识别无效的物体类别标签并根据周边上下文预测正确的类别标签。

Result: 实验结果表明，该方法作为单独的异常检测与修正框架或与YOLOv7和RT-DETR等标准检测器结合使用，均能显著提高检测性能，mAP@50提升可达4%。

Conclusion: 利用环境空间结构进行推理能够有效提高物体检测系统的可靠性，为处理复杂场景中的检测提供了新的思路。

Abstract: In many real-world applications involving static environments, the spatial
layout of objects remains consistent across instances. However,
state-of-the-art object detection models often fail to leverage this spatial
prior, resulting in inconsistent predictions, missed detections, or
misclassifications, particularly in cluttered or occluded scenes. In this work,
we propose a graph-based post-processing pipeline that explicitly models the
spatial relationships between objects to correct detection anomalies in
egocentric frames. Using a graph neural network (GNN) trained on manually
annotated data, our model identifies invalid object class labels and predicts
corrected class labels based on their neighbourhood context. We evaluate our
approach both as a standalone anomaly detection and correction framework and as
a post-processing module for standard object detectors such as YOLOv7 and
RT-DETR. Experiments demonstrate that incorporating this spatial reasoning
significantly improves detection performance, with mAP@50 gains of up to 4%.
This method highlights the potential of leveraging the environment's spatial
structure to improve reliability in object detection systems.

</details>


### [138] [A Trustworthy Method for Multimodal Emotion Recognition](https://arxiv.org/abs/2508.07625)
*Junxiao Xue,Xiaozhen Liu,Jie Wang,Xuecheng Wu,Bin Wu*

Main category: cs.CV

TL;DR: 提出了一种新型情感识别方法TER，利用不确定性估计提高模型可靠性，同时实现高性能。


<details>
  <summary>Details</summary>
Motivation: 现有情感识别方法专注于提升复杂深度模型的性能，但忽略了噪声、损坏数据和分布外数据的可靠性问题。

Method: TER通过不确定性估计计算预测可信度，结合多模态输出可信预测。引入新的评估标准，包括可信精度、召回率、可信Acc.和F1分数。

Result: TER在多个数据集上效果显著，在Music-video中达到82.40%的Acc.；在IEMOCAP和Music-video中的可信F1分数分别为0.7511和0.9035，表现优于其他方法。

Conclusion: TER通过增加模型的可靠性与鲁棒性，同时在性能和信任度评估上达到了先进水平。

Abstract: Existing emotion recognition methods mainly focus on enhancing performance by
employing complex deep models, typically resulting in significantly higher
model complexity. Although effective, it is also crucial to ensure the
reliability of the final decision, especially for noisy, corrupted and
out-of-distribution data. To this end, we propose a novel emotion recognition
method called trusted emotion recognition (TER), which utilizes uncertainty
estimation to calculate the confidence value of predictions. TER combines the
results from multiple modalities based on their confidence values to output the
trusted predictions. We also provide a new evaluation criterion to assess the
reliability of predictions. Specifically, we incorporate trusted precision and
trusted recall to determine the trusted threshold and formulate the trusted
Acc. and trusted F1 score to evaluate the model's trusted performance. The
proposed framework combines the confidence module that accordingly endows the
model with reliability and robustness against possible noise or corruption. The
extensive experimental results validate the effectiveness of our proposed
model. The TER achieves state-of-the-art performance on the Music-video,
achieving 82.40% Acc. In terms of trusted performance, TER outperforms other
methods on the IEMOCAP and Music-video, achieving trusted F1 scores of 0.7511
and 0.9035, respectively.

</details>


### [139] [AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning](https://arxiv.org/abs/2508.07626)
*Dejie Yang,Zijing Zhao,Yang Liu*

Main category: cs.CV

TL;DR: 本文提出了一种通过模仿人类动作的视频分析进行视觉机器人操作的新方法（AR-VRM），优于传统方法，特别是在数据稀缺情况下。


<details>
  <summary>Details</summary>
Motivation: 当前视觉机器人操作需要昂贵的多模态数据，现有方法依赖于与机器任务差距较大的网络数据或隐式模型训练，表现受限。

Method: 提出一种关键点视觉语言模型（VLM）预训练方案，从人类动作视频中学习动作知识，直接预测手关键点，并在机器人数据上进行微调，通过类比推理建立人类动作与机器人组件之间的映射。

Result: 该方法在CALVIN基准测试和真实世界实验中表现优异，特别是在小样本场景下显著超越现有方法。

Conclusion: 显式模仿人类动作的策略是突破现有方法局限的重要路径，可以显著提高机器人操作的泛化能力和性能。

Abstract: Visual Robot Manipulation (VRM) aims to enable a robot to follow natural
language instructions based on robot states and visual observations, and
therefore requires costly multi-modal data. To compensate for the deficiency of
robot data, existing approaches have employed vision-language pretraining with
large-scale data. However, they either utilize web data that differs from
robotic tasks, or train the model in an implicit way (e.g., predicting future
frames at the pixel level), thus showing limited generalization ability under
insufficient robot data. In this paper, we propose to learn from large-scale
human action video datasets in an explicit way (i.e., imitating human actions
from hand keypoints), introducing Visual Robot Manipulation with Analogical
Reasoning (AR-VRM). To acquire action knowledge explicitly from human action
videos, we propose a keypoint Vision-Language Model (VLM) pretraining scheme,
enabling the VLM to learn human action knowledge and directly predict human
hand keypoints. During fine-tuning on robot data, to facilitate the robotic arm
in imitating the action patterns of human motions, we first retrieve human
action videos that perform similar manipulation tasks and have similar
historical observations , and then learn the Analogical Reasoning (AR) map
between human hand keypoints and robot components. Taking advantage of focusing
on action keypoints instead of irrelevant visual cues, our method achieves
leading performance on the CALVIN benchmark {and real-world experiments}. In
few-shot scenarios, our AR-VRM outperforms previous methods by large margins ,
underscoring the effectiveness of explicitly imitating human actions under data
scarcity.

</details>


### [140] [LaRender: Training-Free Occlusion Control in Image Generation via Latent Rendering](https://arxiv.org/abs/2508.07647)
*Xiaohang Zhan,Dingming Liu*

Main category: cs.CV

TL;DR: 提出了一种无需训练即可实现图像生成的新方法，通过运用体渲染原理在潜空间中“渲染”图像以精确控制遮挡关系。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成方法对遮挡关系的控制能力不足，依赖于文本提示或布局生成方法，无法提供精确的遮挡关系操控能力。

Method: 利用预训练的图像扩散模型及体渲染原理，在潜空间中混合物体的透射率来实现遮挡关系的精确控制，无需重新训练或微调模型。

Result: 通过大量实验表明，该方法在遮挡精确度方面显著优于现有方法，并可通过调整渲染过程中的透明度或密度实现各类视觉效果。

Conclusion: 该方法基于物理原理，不需要重新训练模型，提供了新的方式精准控制遮挡关系并实现多样化特效处理。

Abstract: We propose a novel training-free image generation algorithm that precisely
controls the occlusion relationships between objects in an image. Existing
image generation methods typically rely on prompts to influence occlusion,
which often lack precision. While layout-to-image methods provide control over
object locations, they fail to address occlusion relationships explicitly.
Given a pre-trained image diffusion model, our method leverages volume
rendering principles to "render" the scene in latent space, guided by occlusion
relationships and the estimated transmittance of objects. This approach does
not require retraining or fine-tuning the image diffusion model, yet it enables
accurate occlusion control due to its physics-grounded foundation. In extensive
experiments, our method significantly outperforms existing approaches in terms
of occlusion accuracy. Furthermore, we demonstrate that by adjusting the
opacities of objects or concepts during rendering, our method can achieve a
variety of effects, such as altering the transparency of objects, the density
of mass (e.g., forests), the concentration of particles (e.g., rain, fog), the
intensity of light, and the strength of lens effects, etc.

</details>


### [141] [Collaborative Learning of Scattering and Deep Features for SAR Target Recognition with Noisy Labels](https://arxiv.org/abs/2508.07656)
*Yimin Fu,Zhunga Liu,Dongxiu Guo,Longfei Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于散射和深度特征协同学习(CLSDF)的SAR目标识别方法，以解决标签噪声导致识别性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 由于SAR数据的标签获取依赖专家知识，出现噪声标签不可避免，现有方法对SAR这种非直观视觉特征的数据无法实现鲁棒学习。

Method: 设计了一个多模型特征融合框架，将散射与深度特征结合；并基于高斯混合模型（GMM）对标签进行清晰与噪声分类，再进行数据的半监督学习；引入联合分布对齐策略，提高标签的可靠性。

Result: 基于MSTAR数据集的实验结果表明，该方法在不同操作条件与标签噪声下均表现出最先进的性能。

Conclusion: 提出的方法有效解决了SAR数据噪声标签问题，具有较强的鲁棒性与实用性。

Abstract: The acquisition of high-quality labeled synthetic aperture radar (SAR) data
is challenging due to the demanding requirement for expert knowledge.
Consequently, the presence of unreliable noisy labels is unavoidable, which
results in performance degradation of SAR automatic target recognition (ATR).
Existing research on learning with noisy labels mainly focuses on image data.
However, the non-intuitive visual characteristics of SAR data are insufficient
to achieve noise-robust learning. To address this problem, we propose
collaborative learning of scattering and deep features (CLSDF) for SAR ATR with
noisy labels. Specifically, a multi-model feature fusion framework is designed
to integrate scattering and deep features. The attributed scattering centers
(ASCs) are treated as dynamic graph structure data, and the extracted physical
characteristics effectively enrich the representation of deep image features.
Then, the samples with clean and noisy labels are divided by modeling the loss
distribution with multiple class-wise Gaussian Mixture Models (GMMs).
Afterward, the semi-supervised learning of two divergent branches is conducted
based on the data divided by each other. Moreover, a joint distribution
alignment strategy is introduced to enhance the reliability of co-guessed
labels. Extensive experiments have been done on the Moving and Stationary
Target Acquisition and Recognition (MSTAR) dataset, and the results show that
the proposed method can achieve state-of-the-art performance under different
operating conditions with various label noises.

</details>


### [142] [Undress to Redress: A Training-Free Framework for Virtual Try-On](https://arxiv.org/abs/2508.07680)
*Zhiying Li,Junhao Wu,Yeying Jin,Daiheng Gao,Yun Ji,Kaichuan Kong,Lei Yu,Hao Xu,Kai Chen,Bruce Gu,Nana Wang,Zhaoxin Fan*

Main category: cs.CV

TL;DR: 文章提出了一个名为UR-VTON的新框架，旨在解决虚拟试衣任务中长袖到短袖转换时的皮肤还原问题，并通过创新性的方法提高图像质量和细节保留。


<details>
  <summary>Details</summary>
Motivation: 目前的虚拟试衣方法在处理长袖到短袖转换时常常出现皮肤还原不真实的问题，这主要因为现有模型的“多数”完成规则，在原始图像中暴露皮肤不足的情况下效果不佳。

Method: 本文提出的UR-VTON框架采用了“undress-to-redress”的机制，分为虚拟“脱衣”和试穿短袖两步，辅以动态无分类器引导调度和结构精细化模块，以提升生成图像的多样性和质量。本文还推出了名为LS-TON的长袖到短袖试穿新基准。

Result: 实验显示，UR-VTON在细节保留和图像质量方面均优于现有方法，并且能够实现更真实的试衣效果。

Conclusion: 提出的UR-VTON框架通过有效的双阶段转化机制和结构调整步骤，成功解决了长袖到短袖转换中的关键问题，为虚拟试衣领域提供了更强大的解决方案。

Abstract: Virtual try-on (VTON) is a crucial task for enhancing user experience in
online shopping by generating realistic garment previews on personal photos.
Although existing methods have achieved impressive results, they struggle with
long-sleeve-to-short-sleeve conversions-a common and practical scenario-often
producing unrealistic outputs when exposed skin is underrepresented in the
original image. We argue that this challenge arises from the ''majority''
completion rule in current VTON models, which leads to inaccurate skin
restoration in such cases. To address this, we propose UR-VTON (Undress-Redress
Virtual Try-ON), a novel, training-free framework that can be seamlessly
integrated with any existing VTON method. UR-VTON introduces an
''undress-to-redress'' mechanism: it first reveals the user's torso by
virtually ''undressing,'' then applies the target short-sleeve garment,
effectively decomposing the conversion into two more manageable steps.
Additionally, we incorporate Dynamic Classifier-Free Guidance scheduling to
balance diversity and image quality during DDPM sampling, and employ Structural
Refiner to enhance detail fidelity using high-frequency cues. Finally, we
present LS-TON, a new benchmark for long-sleeve-to-short-sleeve try-on.
Extensive experiments demonstrate that UR-VTON outperforms state-of-the-art
methods in both detail preservation and image quality. Code will be released
upon acceptance.

</details>


### [143] [TAR-TVG: Enhancing VLMs with Timestamp Anchor-Constrained Reasoning for Temporal Video Grounding](https://arxiv.org/abs/2508.07683)
*Chaohong Guo,Xun Mo,Yongwei Nie,Xuemiao Xu,Chao Xu,Fei Yu,Chengjiang Long*

Main category: cs.CV

TL;DR: 提出了一种新方法TAR-TVG，通过引入时间戳锚点约束推理过程，解决了现有强化学习方法在推理质量上的不足，从而提升对长视频中语义查询段落的定位精度。


<details>
  <summary>Details</summary>
Motivation: 目前的强化学习方法虽然可以生成预测前的推理链，但无法显式约束该过程，导致最终预测准确性受限。

Method: 引入时间戳锚点作为中间验证点，要求推理步骤逐步提供更精确的时间估计，并采用三阶段自蒸馏策略（GRPO初训-监督微调-优化增强）。

Result: 实验表明，该方法在生成可解释且可验证的推理链条的同时，实现了最先进的性能表现。

Conclusion: 通过引入时间戳锚点和有效的训练策略，本工作改进了推理过程的质量，提供了更高的长视频语义定位能力。

Abstract: Temporal Video Grounding (TVG) aims to precisely localize video segments
corresponding to natural language queries, which is a critical capability for
long-form video understanding. Although existing reinforcement learning
approaches encourage models to generate reasoning chains before predictions,
they fail to explicitly constrain the reasoning process to ensure the quality
of the final temporal predictions. To address this limitation, we propose
Timestamp Anchor-constrained Reasoning for Temporal Video Grounding (TAR-TVG),
a novel framework that introduces timestamp anchors within the reasoning
process to enforce explicit supervision to the thought content. These anchors
serve as intermediate verification points. More importantly, we require each
reasoning step to produce increasingly accurate temporal estimations, thereby
ensuring that the reasoning process contributes meaningfully to the final
prediction. To address the challenge of low-probability anchor generation in
models (e.g., Qwen2.5-VL-3B), we develop an efficient self-distillation
training strategy: (1) initial GRPO training to collect 30K high-quality
reasoning traces containing multiple timestamp anchors, (2) supervised
fine-tuning (SFT) on distilled data, and (3) final GRPO optimization on the
SFT-enhanced model. This three-stage training strategy enables robust anchor
generation while maintaining reasoning quality. Experiments show that our model
achieves state-of-the-art performance while producing interpretable, verifiable
reasoning chains with progressively refined temporal estimations.

</details>


### [144] [Make Your MoVe: Make Your 3D Contents by Adapting Multi-View Diffusion Models to External Editing](https://arxiv.org/abs/2508.07700)
*Weitao Wang,Haoran Xu,Jun Meng,Haoqian Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种无需调参的即插即用方法，用于在单次推理运行中保持3D内容的原始几何结构和编辑后的视图一致性。


<details>
  <summary>Details</summary>
Motivation: 当前3D生成技术迅速发展，但在编辑过程中，由于多采用2D编辑工具，直接用于3D生成会造成信息丢失，影响最终生成质量。用户需要一种既能保留几何结构又能提升颜色、风格和光照的编辑方法。

Method: 提出了一种包括几何保持模块的无调参方案，利用原始输入的法线潜变量引导多视图编辑生成。同时设计了“注入切换器”，对原始法线监督程度进行控制，以确保编辑后的颜色与法线视图对齐。

Result: 实验表明，该方法在多个多视图扩散模型和编辑方法的组合中，始终提升了编辑3D资产的多视图一致性和网格质量。

Conclusion: 该方法无需调参且实现简单，是提升3D内容编辑一致性和质量的有效方案。适配性能较强，适合多种生成模型和编辑需求的应用场景。

Abstract: As 3D generation techniques continue to flourish, the demand for generating
personalized content is rapidly rising. Users increasingly seek to apply
various editing methods to polish generated 3D content, aiming to enhance its
color, style, and lighting without compromising the underlying geometry.
However, most existing editing tools focus on the 2D domain, and directly
feeding their results into 3D generation methods (like multi-view diffusion
models) will introduce information loss, degrading the quality of the final 3D
assets. In this paper, we propose a tuning-free, plug-and-play scheme that
aligns edited assets with their original geometry in a single inference run.
Central to our approach is a geometry preservation module that guides the
edited multi-view generation with original input normal latents. Besides, an
injection switcher is proposed to deliberately control the supervision extent
of the original normals, ensuring the alignment between the edited color and
normal views. Extensive experiments show that our method consistently improves
both the multi-view consistency and mesh quality of edited 3D assets, across
multiple combinations of multi-view diffusion models and editing methods.

</details>


### [145] [Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction](https://arxiv.org/abs/2508.07701)
*Bo Jia,Yanan Guo,Ying Chang,Benkui Zhang,Ying Xie,Kangning Du,Lin Cao*

Main category: cs.CV

TL;DR: 提出了一种改进的多视角正态与距离引导的三维高斯点云方法（3DGS），通过正态和距离限制提升了三维重建效果。


<details>
  <summary>Details</summary>
Motivation: 针对现有3DGS在单视角投影平面中法向量对齐带来的视角偏差问题，提出改进方案以提升多视角场景的统一性及重建精度。

Method: 结合多视角正态增强模块与多视角距离重投影正则模块，对多视角几何深度进行统一，通过计算视角间距离损失及法向量匹配损失优化三维点云对齐效果。

Result: 实验结果表明，改进方法在定量及定性评估中均优于基线，显著增强了3DGS的表面重建能力。

Conclusion: 新方法有效解决了多视角场景中的法向量一致性及几何深度统一性问题，提升了小规模室内外场景的三维重建效果。

Abstract: 3D Gaussian Splatting (3DGS) achieves remarkable results in the field of
surface reconstruction. However, when Gaussian normal vectors are aligned
within the single-view projection plane, while the geometry appears reasonable
in the current view, biases may emerge upon switching to nearby views. To
address the distance and global matching challenges in multi-view scenes, we
design multi-view normal and distance-guided Gaussian splatting. This method
achieves geometric depth unification and high-accuracy reconstruction by
constraining nearby depth maps and aligning 3D normals. Specifically, for the
reconstruction of small indoor and outdoor scenes, we propose a multi-view
distance reprojection regularization module that achieves multi-view Gaussian
alignment by computing the distance loss between two nearby views and the same
Gaussian surface. Additionally, we develop a multi-view normal enhancement
module, which ensures consistency across views by matching the normals of pixel
points in nearby views and calculating the loss. Extensive experimental results
demonstrate that our method outperforms the baseline in both quantitative and
qualitative evaluations, significantly enhancing the surface reconstruction
capability of 3DGS.

</details>


### [146] [DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models](https://arxiv.org/abs/2508.07714)
*Licheng Zhang,Bach Le,Naveed Akhtar,Tuan Ngo*

Main category: cs.CV

TL;DR: 本文提出了一种半自动化流程，通过深度学习对象检测模型和大型语言模型(LLM)构建面向复杂多类门检测的数据集，大幅减少人工标注成本。


<details>
  <summary>Details</summary>
Motivation: 多类门检测对建筑合规检查和室内场景理解等关键任务至关重要，但细粒度多类门检测公开数据集稀缺。因此需要高效的构建方法。

Method: 使用对象检测模型统一检测门类别，再通过LLM根据视觉和上下文特征进行分类，最终通过人工审核提高标注质量。

Result: 提出的方法显著减少了标注成本，并生成了可用于神经模型基准测试的优质数据集。

Conclusion: 深度学习与多模态推理结合能够高效地在复杂实际领域构建数据集，为后续研究提供有力支持。

Abstract: Accurate detection and classification of diverse door types in floor plans
drawings is critical for multiple applications, such as building compliance
checking, and indoor scene understanding. Despite their importance, publicly
available datasets specifically designed for fine-grained multi-class door
detection remain scarce. In this work, we present a semi-automated pipeline
that leverages a state-of-the-art object detector and a large language model
(LLM) to construct a multi-class door detection dataset with minimal manual
effort. Doors are first detected as a unified category using a deep object
detection model. Next, an LLM classifies each detected instance based on its
visual and contextual features. Finally, a human-in-the-loop stage ensures
high-quality labels and bounding boxes. Our method significantly reduces
annotation cost while producing a dataset suitable for benchmarking neural
models in floor plan analysis. This work demonstrates the potential of
combining deep learning and multimodal reasoning for efficient dataset
construction in complex real-world domains.

</details>


### [147] [A Registration-Based Star-Shape Segmentation Model and Fast Algorithms](https://arxiv.org/abs/2508.07721)
*Daoping Zhang,Xue-Cheng Tai,Lok Ming Lui*

Main category: cs.CV

TL;DR: 本文提出一种基于配准框架的星形分割模型，通过结合水平集表示和配准框架，并对变形水平集函数施加约束，实现了单中心和多中心的全星形和部分星形分割，对比实验表明效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决当图像存在遮挡、模糊或噪声时精确分割的挑战，特别是在利用星形先验信息领域中的应用问题。

Method: 将水平集表示与配准框架结合，通过对变形的水平集函数施加约束，实现多中心、多形状星形分割，并通过交替方向乘子法求解模型。

Result: 在合成和真实图像的数值实验中，验证了提出方法在实现精确星形分割中的有效性。

Conclusion: 所提模型在处理复杂图像分割问题时，表现出了对于星形分割的优越性能，适用于需要引入先验信息的应用场景。

Abstract: Image segmentation plays a crucial role in extracting objects of interest and
identifying their boundaries within an image. However, accurate segmentation
becomes challenging when dealing with occlusions, obscurities, or noise in
corrupted images. To tackle this challenge, prior information is often
utilized, with recent attention on star-shape priors. In this paper, we propose
a star-shape segmentation model based on the registration framework. By
combining the level set representation with the registration framework and
imposing constraints on the deformed level set function, our model enables both
full and partial star-shape segmentation, accommodating single or multiple
centers. Additionally, our approach allows for the enforcement of identified
boundaries to pass through specified landmark locations. We tackle the proposed
models using the alternating direction method of multipliers. Through numerical
experiments conducted on synthetic and real images, we demonstrate the efficacy
of our approach in achieving accurate star-shape segmentation.

</details>


### [148] [Enhancing Small-Scale Dataset Expansion with Triplet-Connection-based Sample Re-Weighting](https://arxiv.org/abs/2508.07723)
*Ting Xiang,Changjian Chen,Zhuo Tang,Qifeng Zhang,Fei Lyu,Li Yang,Jiapeng Zhang,Kenli Li*

Main category: cs.CV

TL;DR: 本研究提出了一种名为TriReWeight的样本重加权方法，用于提升生成数据扩充效果，方法适用于生成数据扩充领域的多种场景，并在多个数据集上实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 生成模型在数据稀缺问题中的应用有限，因为生成过程的不可控性和语言模糊性容易导致生成噪声数据。

Method: 通过三种监督方式的理论分析，提出一种基于三元连接的重加权方法TriReWeight，其可与任意生成数据扩充方法结合，且理论上能提升性能。

Result: 与六个自然图像数据集相比，平均提升了7.9%；与三个医疗数据集相比，平均提升3.4%。此外，不同生成数据扩充方法的性能均有提升。

Conclusion: TriReWeight是一种通用、性能稳定的样本重加权方法，可广泛用于数据稀缺场景，提升模型的泛化性能。

Abstract: The performance of computer vision models in certain real-world applications,
such as medical diagnosis, is often limited by the scarcity of available
images. Expanding datasets using pre-trained generative models is an effective
solution. However, due to the uncontrollable generation process and the
ambiguity of natural language, noisy images may be generated. Re-weighting is
an effective way to address this issue by assigning low weights to such noisy
images. We first theoretically analyze three types of supervision for the
generated images. Based on the theoretical analysis, we develop TriReWeight, a
triplet-connection-based sample re-weighting method to enhance generative data
augmentation. Theoretically, TriReWeight can be integrated with any generative
data augmentation methods and never downgrade their performance. Moreover, its
generalization approaches the optimal in the order $O(\sqrt{d\ln (n)/n})$. Our
experiments validate the correctness of the theoretical analysis and
demonstrate that our method outperforms the existing SOTA methods by $7.9\%$ on
average over six natural image datasets and by $3.4\%$ on average over three
medical datasets. We also experimentally validate that our method can enhance
the performance of different generative data augmentation methods.

</details>


### [149] [Grouped Speculative Decoding for Autoregressive Image Generation](https://arxiv.org/abs/2508.07747)
*Junhyuk So,Juncheol Shin,Hyunho Kook,Eunhyeok Park*

Main category: cs.CV

TL;DR: 提出了一个新的加速方法“Grouped Speculative Decoding (GSD)”，应用于自回归（AR）图像模型，以减少推理时间，同时保持图像质量，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 现有的AR图像模型生成质量出色，但受其顺序生成特性限制，推理过程耗时较长，影响实用性。

Method: 研究提出了一种“GSD”方法，通过动态分组评估多个视觉有效的token群代替传统单一token来加速生成。同时，针对图像token的冗余性和多样性特点，避免了现有推测解码方法中过多的假阴性拒绝。

Result: 实验表明，使用GSD方法的AR图像模型在保持图像质量的同时，加速比达到3.7倍平均提升。

Conclusion: GSD是一种无需额外训练的高效推理加速方案，显著提升了AR图像模型的实际应用价值。

Abstract: Recently, autoregressive (AR) image models have demonstrated remarkable
generative capabilities, positioning themselves as a compelling alternative to
diffusion models. However, their sequential nature leads to long inference
times, limiting their practical scalability. In this work, we introduce Grouped
Speculative Decoding (GSD), a novel, training-free acceleration method for AR
image models. While recent studies have explored Speculative Decoding (SD) as a
means to speed up AR image generation, existing approaches either provide only
modest acceleration or require additional training. Our in-depth analysis
reveals a fundamental difference between language and image tokens: image
tokens exhibit inherent redundancy and diversity, meaning multiple tokens can
convey valid semantics. However, traditional SD methods are designed to accept
only a single most-likely token, which fails to leverage this difference,
leading to excessive false-negative rejections. To address this, we propose a
new SD strategy that evaluates clusters of visually valid tokens rather than
relying on a single target token. Additionally, we observe that static
clustering based on embedding distance is ineffective, which motivates our
dynamic GSD approach. Extensive experiments show that GSD accelerates AR image
models by an average of 3.7x while preserving image quality-all without
requiring any additional training. The source code is available at
https://github.com/junhyukso/GSD

</details>


### [150] [Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion](https://arxiv.org/abs/2508.07755)
*Minseo Kim,Minchan Kwon,Dongyeun Lee,Yunho Jeon,Junmo Kim*

Main category: cs.CV

TL;DR: 提出了Contrastive Inversion方法，通过对比输入图像提取共性概念，无需额外信息。


<details>
  <summary>Details</summary>
Motivation: 现有的定制化图像生成方法依赖文本提示或空间掩码，不易分离辅助特征，影响质量。

Method: 利用对比学习训练目标令牌结合图像辅助文本令牌，并通过交叉注意力微调，提升概念精度。

Result: 实验表明该方法在概念表示与编辑方面均优于现有技术。

Conclusion: Contrastive Inversion能高效提取共性概念，在生成任务表现更优。

Abstract: The recent demand for customized image generation raises a need for
techniques that effectively extract the common concept from small sets of
images. Existing methods typically rely on additional guidance, such as text
prompts or spatial masks, to capture the common target concept. Unfortunately,
relying on manually provided guidance can lead to incomplete separation of
auxiliary features, which degrades generation quality.In this paper, we propose
Contrastive Inversion, a novel approach that identifies the common concept by
comparing the input images without relying on additional information. We train
the target token along with the image-wise auxiliary text tokens via
contrastive learning, which extracts the well-disentangled true semantics of
the target. Then we apply disentangled cross-attention fine-tuning to improve
concept fidelity without overfitting. Experimental results and analysis
demonstrate that our method achieves a balanced, high-level performance in both
concept representation and editing, outperforming existing techniques.

</details>


### [151] [Correspondence as Video: Test-Time Adaption on SAM2 for Reference Segmentation in the Wild](https://arxiv.org/abs/2508.07759)
*Haoran Wang,Zekun Li,Jian Zhang,Lei Qi,Yinghuan Shi*

Main category: cs.CV

TL;DR: 本文提出了一种称为CAV-SAM的新方法，通过将参考-目标图像对之间的对应关系表示为伪视频，以轻量化优化SAM模型应用于下游任务。


<details>
  <summary>Details</summary>
Motivation: 目前大规模视觉模型（如SAM）在应用于实际下游任务时存在局限，参考分割作为适配模型的新方向但极需资源。然而传统的元学习方法依赖昂贵的元训练过程。因此需要开发轻量化的解决方案。

Method: 提出CAV-SAM方法，通过伪视频表示参考-目标图像对的内在对应关系。其中，DBST模块基于扩散模型生成语义变换序列，TTGA模块通过测试时微调对几何变化对齐。

Result: 在主流数据集上的实验表明CAV-SAM在分割性能上比最先进方法提高超过5%。

Conclusion: CAV-SAM展示了模型高效适配的潜力，尤其是在无需大量算力资源的情境下，验证其有效性。

Abstract: Large vision models like the Segment Anything Model (SAM) exhibit significant
limitations when applied to downstream tasks in the wild. Consequently,
reference segmentation, which leverages reference images and their
corresponding masks to impart novel knowledge to the model, emerges as a
promising new direction for adapting vision models. However, existing reference
segmentation approaches predominantly rely on meta-learning, which still
necessitates an extensive meta-training process and brings massive data and
computational cost. In this study, we propose a novel approach by representing
the inherent correspondence between reference-target image pairs as a pseudo
video. This perspective allows the latest version of SAM, known as SAM2, which
is equipped with interactive video object segmentation (iVOS) capabilities, to
be adapted to downstream tasks in a lightweight manner. We term this approach
Correspondence As Video for SAM (CAV-SAM). CAV-SAM comprises two key modules:
the Diffusion-Based Semantic Transition (DBST) module employs a diffusion model
to construct a semantic transformation sequence, while the Test-Time Geometric
Alignment (TTGA) module aligns the geometric changes within this sequence
through test-time fine-tuning. We evaluated CAVSAM on widely-used datasets,
achieving segmentation performance improvements exceeding 5% over SOTA methods.
Implementation is provided in the supplementary materials.

</details>


### [152] [UniSVG: A Unified Dataset for Vector Graphic Understanding and Generation with Multimodal Large Language Models](https://arxiv.org/abs/2508.07766)
*Jinke Li,Jiarui Yu,Chenxing Wei,Hande Dong,Qiang Lin,Liangjing Yang,Zhicai Wang,Yanbin Hao*

Main category: cs.CV

TL;DR: SVG图形在缩放时保持质量，但SVG生成与理解对AI来说仍具挑战性。为此，提出了一个名为UniSVG的数据集，提高了开源多模态大语言模型（MLLM）的SVG任务性能，并超过了GPT-4V等闭源模型。


<details>
  <summary>Details</summary>
Motivation: 随着以AI驱动的系统增多，让AI理解和生成SVG变得越来越重要，现有方法在多条件约束下的SVG生成和高精度SVG理解上存在瓶颈。

Method: 提出UniSVG数据集，包含52.5万条数据，专为训练开源多模态大语言模型（MLLM）在SVG理解和生成任务设计，同时包含文本提示和视觉参考。

Result: 使用UniSVG数据集训练后，开源MLLM在多种SVG生成和理解任务上表现优于SOTA闭源模型。

Conclusion: UniSVG是首个针对SVG生成与理解的综合数据集，推动了开源MLLM能力提升，并为开放SVG研究提供了新基准和资源。

Abstract: Unlike bitmap images, scalable vector graphics (SVG) maintain quality when
scaled, frequently employed in computer vision and artistic design in the
representation of SVG code. In this era of proliferating AI-powered systems,
enabling AI to understand and generate SVG has become increasingly urgent.
However, AI-driven SVG understanding and generation (U&G) remain significant
challenges. SVG code, equivalent to a set of curves and lines controlled by
floating-point parameters, demands high precision in SVG U&G. Besides, SVG
generation operates under diverse conditional constraints, including textual
prompts and visual references, which requires powerful multi-modal processing
for condition-to-SVG transformation. Recently, the rapid growth of Multi-modal
Large Language Models (MLLMs) have demonstrated capabilities to process
multi-modal inputs and generate complex vector controlling parameters,
suggesting the potential to address SVG U&G tasks within a unified model. To
unlock MLLM's capabilities in the SVG area, we propose an SVG-centric dataset
called UniSVG, comprising 525k data items, tailored for MLLM training and
evaluation. To our best knowledge, it is the first comprehensive dataset
designed for unified SVG generation (from textual prompts and images) and SVG
understanding (color, category, usage, etc.). As expected, learning on the
proposed dataset boosts open-source MLLMs' performance on various SVG U&G
tasks, surpassing SOTA close-source MLLMs like GPT-4V. We release dataset,
benchmark, weights, codes and experiment details on
https://ryanlijinke.github.io/.

</details>


### [153] [Dream4D: Lifting Camera-Controlled I2V towards Spatiotemporally Consistent 4D Generation](https://arxiv.org/abs/2508.07769)
*Xiaoyan Liu,Kangrui Li,Jiaxin Liu*

Main category: cs.CV

TL;DR: 本研究提出了一种名为Dream4D的新框架，用于生成空间和时间一致的高质量4D内容，并克服了复杂场景动态和多元素交互的大规模环境挑战。


<details>
  <summary>Details</summary>
Motivation: 目前的方法在处理复杂场景动态时难以保持视图一致性，尤其是在多交互元素的大尺度环境中。因此有必要开发新的方法以克服这一挑战。

Method: 提出了一种双阶段框架：首先通过少样本学习从单张图像中预测最佳摄像机轨迹；然后通过姿态条件扩散过程生成几何一致的多视图序列，并最终将其转换为持续的4D表示。

Result: 该框架首次结合了视频扩散模型的丰富时间先验和重建模型的几何感知能力，使4D生成变得更为轻松，并且在质量指标（如mPSNR, mSSIM）上优于现有方法。

Conclusion: Dream4D这种方法证明了一种创新性的结合几何意识和视频生成的方法，可实现高品质的4D内容生成，对计算机视觉领域具有重要意义。

Abstract: The synthesis of spatiotemporally coherent 4D content presents fundamental
challenges in computer vision, requiring simultaneous modeling of high-fidelity
spatial representations and physically plausible temporal dynamics. Current
approaches often struggle to maintain view consistency while handling complex
scene dynamics, particularly in large-scale environments with multiple
interacting elements. This work introduces Dream4D, a novel framework that
bridges this gap through a synergy of controllable video generation and neural
4D reconstruction. Our approach seamlessly combines a two-stage architecture:
it first predicts optimal camera trajectories from a single image using
few-shot learning, then generates geometrically consistent multi-view sequences
via a specialized pose-conditioned diffusion process, which are finally
converted into a persistent 4D representation. This framework is the first to
leverage both rich temporal priors from video diffusion models and geometric
awareness of the reconstruction models, which significantly facilitates 4D
generation and shows higher quality (e.g., mPSNR, mSSIM) over existing methods.

</details>


### [154] [Prototype-Guided Curriculum Learning for Zero-Shot Learning](https://arxiv.org/abs/2508.07771)
*Lei Wang,Shiming Chen,Guo-Sen Xie,Ziming Hong,Chaojian Yu,Qinmu Peng,Xinge You*

Main category: cs.CV

TL;DR: 本文提出了一种名为CLZSL的框架，通过PCL模块减少实例级别的不匹配并通过PUP模块优化类级别的语义原型，提升零样本学习中的知识迁移效果。


<details>
  <summary>Details</summary>
Motivation: 解决零样本学习中语义原型手动定义造成的实例级别的不匹配和类级别的语义不精准问题，提高视觉语义映射的准确性。

Method: 引入了一个Prototype-Guided Curriculum Learning (PCL)模块和一个Prototype Update (PUP)模块，分别针对实例和类级问题，其中PCL优先处理高相似度样本，PUP动态更新语义原型。

Result: 在AWA2、SUN和CUB等标准基准数据集上进行了实验，验证了方法的有效性。

Conclusion: CLZSL框架可以通过减轻语义映射中的噪声干扰和动态优化语义原型，提升在未见类别上的知识迁移效果。

Abstract: In Zero-Shot Learning (ZSL), embedding-based methods enable knowledge
transfer from seen to unseen classes by learning a visual-semantic mapping from
seen-class images to class-level semantic prototypes (e.g., attributes).
However, these semantic prototypes are manually defined and may introduce noisy
supervision for two main reasons: (i) instance-level mismatch: variations in
perspective, occlusion, and annotation bias will cause discrepancies between
individual sample and the class-level semantic prototypes; and (ii) class-level
imprecision: the manually defined semantic prototypes may not accurately
reflect the true semantics of the class. Consequently, the visual-semantic
mapping will be misled, reducing the effectiveness of knowledge transfer to
unseen classes. In this work, we propose a prototype-guided curriculum learning
framework (dubbed as CLZSL), which mitigates instance-level mismatches through
a Prototype-Guided Curriculum Learning (PCL) module and addresses class-level
imprecision via a Prototype Update (PUP) module. Specifically, the PCL module
prioritizes samples with high cosine similarity between their visual mappings
and the class-level semantic prototypes, and progressively advances to
less-aligned samples, thereby reducing the interference of instance-level
mismatches to achieve accurate visual-semantic mapping. Besides, the PUP module
dynamically updates the class-level semantic prototypes by leveraging the
visual mappings learned from instances, thereby reducing class-level
imprecision and further improving the visual-semantic mapping. Experiments were
conducted on standard benchmark datasets-AWA2, SUN, and CUB-to verify the
effectiveness of our method.

</details>


### [155] [Forecasting Continuous Non-Conservative Dynamical Systems in SO(3)](https://arxiv.org/abs/2508.07775)
*Lennart Bastian,Mohammad Rashed,Nassir Navab,Tolga Birdal*

Main category: cs.CV

TL;DR: 本文提出了一种使用神经控制微分方程结合$SO(3)$ Savitzky-Golay路径的方法，来对3D旋转动态进行建模，并实现了噪声的鲁棒性和非保守力条件下的准确外推。


<details>
  <summary>Details</summary>
Motivation: 解决计算机视觉中旋转建模面临的瞬时惯量未知、非保守动力学、以及稀疏和噪声观测等问题。

Method: 利用神经控制微分方程并结合$SO(3)$ Savitzky-Golay路径，以物理和几何意义有效地建模3D旋转轨迹，通过训练从噪声状态中学习动态并增强其鲁棒性。

Result: 模型不仅对输入噪声具有鲁棒性，还能在复杂非惯性系统下进行动态外推，并且易于集成到现有系统中，表现出对缺失物理参数轨迹的良好泛化能力。

Conclusion: 提出的方法克服了传统外推方法在真实世界中应用的局限性，在模拟和多种实际场景中均表现出优异的轨迹外推能力。

Abstract: Modeling the rotation of moving objects is a fundamental task in computer
vision, yet $SO(3)$ extrapolation still presents numerous challenges: (1)
unknown quantities such as the moment of inertia complicate dynamics, (2) the
presence of external forces and torques can lead to non-conservative
kinematics, and (3) estimating evolving state trajectories under sparse, noisy
observations requires robustness. We propose modeling trajectories of noisy
pose estimates on the manifold of 3D rotations in a physically and
geometrically meaningful way by leveraging Neural Controlled Differential
Equations guided with $SO(3)$ Savitzky-Golay paths. Existing extrapolation
methods often rely on energy conservation or constant velocity assumptions,
limiting their applicability in real-world scenarios involving non-conservative
forces. In contrast, our approach is agnostic to energy and momentum
conservation while being robust to input noise, making it applicable to
complex, non-inertial systems. Our approach is easily integrated as a module in
existing pipelines and generalizes well to trajectories with unknown physical
parameters. By learning to approximate object dynamics from noisy states during
training, our model attains robust extrapolation capabilities in simulation and
various real-world settings. Code is available at
https://github.com/bastianlb/forecasting-rotational-dynamics

</details>


### [156] [GaitSnippet: Gait Recognition Beyond Unordered Sets and Ordered Sequences](https://arxiv.org/abs/2508.07782)
*Saihui Hou,Chenye Wang,Wenpeng Lang,Zhengxiang Lan,Yongzhen Huang*

Main category: cs.CV

TL;DR: 本文提出了一种新的步态识别方法，通过片段（snippets）表示动作，实现多尺度时间上下文的整合，显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有步态识别方法或忽视短期时间上下文或未有效捕捉长期时间依赖，有待改善。

Method: 通过引入步态片段（snippets）的概念，将动作分解为一系列随机连续的帧，结合片段采样与建模的策略，学习全面的步态特征。

Result: 在四个常用步态数据集上进行了实验，例如在Gait3D和GREW数据集中分别达到了77.5%和81.7%的rank-1准确率。

Conclusion: 片段化的步态分析方法有效结合了时间上下文，为步态识别提供了新的潜力和更强的性能。

Abstract: Recent advancements in gait recognition have significantly enhanced
performance by treating silhouettes as either an unordered set or an ordered
sequence. However, both set-based and sequence-based approaches exhibit notable
limitations. Specifically, set-based methods tend to overlook short-range
temporal context for individual frames, while sequence-based methods struggle
to capture long-range temporal dependencies effectively. To address these
challenges, we draw inspiration from human identification and propose a new
perspective that conceptualizes human gait as a composition of individualized
actions. Each action is represented by a series of frames, randomly selected
from a continuous segment of the sequence, which we term a snippet.
Fundamentally, the collection of snippets for a given sequence enables the
incorporation of multi-scale temporal context, facilitating more comprehensive
gait feature learning. Moreover, we introduce a non-trivial solution for
snippet-based gait recognition, focusing on Snippet Sampling and Snippet
Modeling as key components. Extensive experiments on four widely-used gait
datasets validate the effectiveness of our proposed approach and, more
importantly, highlight the potential of gait snippets. For instance, our method
achieves the rank-1 accuracy of 77.5% on Gait3D and 81.7% on GREW using a 2D
convolution-based backbone.

</details>


### [157] [Boosting Active Defense Persistence: A Two-Stage Defense Framework Combining Interruption and Poisoning Against Deepfake](https://arxiv.org/abs/2508.07795)
*Hongrui Zheng,Yuezun Li,Liejun Wang,Yunfeng Diao,Zhiqing Guo*

Main category: cs.CV

TL;DR: 本文提出了一种全新的双阶段防御框架（TSDF），旨在通过双重功能的对抗扰动机制实现对Deepfake技术的长期有效防御。


<details>
  <summary>Details</summary>
Motivation: 现有的深伪技术防御策略由于易于被攻击者的重新训练绕过，缺乏长期有效性，限制了其实际应用。作者希望开发一种防御机制，不仅能够失真生成内容，还能阻止攻击模型通过重新训练适应防御。

Method: 提出了创新的双阶段防御框架（TSDF），利用强度分离机制设计了双功能对抗扰动：一方面直接失真生成的伪造结果，另一方面作为数据中毒工具，干扰攻击者模型的重新训练过程。

Result: 实验表明，与传统干扰方法在面对对抗性重新训练时性能显著下降相比，本文框架表现出强大的双重防御能力，有效提升了主动防御的持续性。

Conclusion: TSDF框架通过阻止对抗的重新训练适应过程，实现了相较传统方法更持久的Deepfake技术防御，其创新性和高效性有助于塑造更安全的深伪技术对抗策略。

Abstract: Active defense strategies have been developed to counter the threat of
deepfake technology. However, a primary challenge is their lack of persistence,
as their effectiveness is often short-lived. Attackers can bypass these
defenses by simply collecting protected samples and retraining their models.
This means that static defenses inevitably fail when attackers retrain their
models, which severely limits practical use. We argue that an effective defense
not only distorts forged content but also blocks the model's ability to adapt,
which occurs when attackers retrain their models on protected images. To
achieve this, we propose an innovative Two-Stage Defense Framework (TSDF).
Benefiting from the intensity separation mechanism designed in this paper, the
framework uses dual-function adversarial perturbations to perform two roles.
First, it can directly distort the forged results. Second, it acts as a
poisoning vehicle that disrupts the data preparation process essential for an
attacker's retraining pipeline. By poisoning the data source, TSDF aims to
prevent the attacker's model from adapting to the defensive perturbations, thus
ensuring the defense remains effective long-term. Comprehensive experiments
show that the performance of traditional interruption methods degrades sharply
when it is subjected to adversarial retraining. However, our framework shows a
strong dual defense capability, which can improve the persistence of active
defense. Our code will be available at https://github.com/vpsg-research/TSDF.

</details>


### [158] [Power Battery Detection](https://arxiv.org/abs/2508.07797)
*Xiaoqi Zhao,Peiqian Cao,Lihe Zhang,Zonglei Feng,Hanqi Liu,Jiaming Zuo,Youwei Pang,Weisi Lin,Georges El Fakhri,Huchuan Lu,Xiaofeng Liu*

Main category: cs.CV

TL;DR: 提出了一项针对电池阳极和阴极板定位的任务(PBD)，通过引入大规模数据集和新型方法进行研究。重点开发了PBD5K数据集和MDCNeXt模型。


<details>
  <summary>Details</summary>
Motivation: 手工检测效率低且易出错，传统机器视觉方法难以应对密集板材、低对比度和成像伪影等问题，亟需高效自动化解决方案保障电池质量与安全。

Method: 构建了PBD5K基准数据集，涵盖9种电池类型的5000张X光图像和细致标注；设计了MDCNeXt模型，结合点、线、数量信息，通过两种状态模块实现对板材密集区域和对比困难区域的优化；引入自适应掩模生成策略。

Result: 实验验证了MDCNeXt在复杂电池结构图像上的优异表现，为高密度区域定位提供了多维线索提取和精准分割能力。

Conclusion: 本文研究为电池X光检测提供了首个大规模基准，推进了电池缺陷自动化检测方法的发展，提升了工业检测效率和安全性。

Abstract: Power batteries are essential components in electric vehicles, where internal
structural defects can pose serious safety risks. We conduct a comprehensive
study on a new task, power battery detection (PBD), which aims to localize the
dense endpoints of cathode and anode plates from industrial X-ray images for
quality inspection. Manual inspection is inefficient and error-prone, while
traditional vision algorithms struggle with densely packed plates, low
contrast, scale variation, and imaging artifacts. To address this issue and
drive more attention into this meaningful task, we present PBD5K, the first
large-scale benchmark for this task, consisting of 5,000 X-ray images from nine
battery types with fine-grained annotations and eight types of real-world
visual interference. To support scalable and consistent labeling, we develop an
intelligent annotation pipeline that combines image filtering, model-assisted
pre-labeling, cross-verification, and layered quality evaluation. We formulate
PBD as a point-level segmentation problem and propose MDCNeXt, a model designed
to extract and integrate multi-dimensional structure clues including point,
line, and count information from the plate itself. To improve discrimination
between plates and suppress visual interference, MDCNeXt incorporates two state
space modules. The first is a prompt-filtered module that learns contrastive
relationships guided by task-specific prompts. The second is a density-aware
reordering module that refines segmentation in regions with high plate density.
In addition, we propose a distance-adaptive mask generation strategy to provide
robust supervision under varying spatial distributions of anode and cathode
positions. The source code and datasets will be publicly available at
\href{https://github.com/Xiaoqi-Zhao-DLUT/X-ray-PBD}{PBD5K}.

</details>


### [159] [MambaTrans: Multimodal Fusion Image Translation via Large Language Model Priors for Downstream Visual Tasks](https://arxiv.org/abs/2508.07803)
*Yushen Xu,Xiaosong Li,Zhenyu Kuang,Xiaoqi Cheng,Haishu Tan,Huafeng Li*

Main category: cs.CV

TL;DR: 本文提出MambaTrans，一种新型多模态融合图像模态转换器，可有效改善多模态融合图像在下游任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有下游预训练模型多基于可见光图像，但可见光与多模态融合图像的像素分布差异显著，可能削弱下游任务性能。

Method: 提出MambaTrans方法，通过多模态大语言模型的描述和语义分割模型的掩码输入，结合多模型状态空间块及3D选择性扫描模块，实现文本、掩码与图像的交叉注意力，优化视觉能力。

Result: 在公开数据集上，MambaTrans显著提升了多模态图像在下游任务中的表现。

Conclusion: MambaTrans能够在无需调整预训练模型参数的情况下，改善多模态融合图像与可见光预训练模型的适配性，有效提高性能。

Abstract: The goal of multimodal image fusion is to integrate complementary information
from infrared and visible images, generating multimodal fused images for
downstream tasks. Existing downstream pre-training models are typically trained
on visible images. However, the significant pixel distribution differences
between visible and multimodal fusion images can degrade downstream task
performance, sometimes even below that of using only visible images. This paper
explores adapting multimodal fused images with significant modality differences
to object detection and semantic segmentation models trained on visible images.
To address this, we propose MambaTrans, a novel multimodal fusion image
modality translator. MambaTrans uses descriptions from a multimodal large
language model and masks from semantic segmentation models as input. Its core
component, the Multi-Model State Space Block, combines mask-image-text
cross-attention and a 3D-Selective Scan Module, enhancing pure visual
capabilities. By leveraging object detection prior knowledge, MambaTrans
minimizes detection loss during training and captures long-term dependencies
among text, masks, and images. This enables favorable results in pre-trained
models without adjusting their parameters. Experiments on public datasets show
that MambaTrans effectively improves multimodal image performance in downstream
tasks.

</details>


### [160] [Pose-RFT: Enhancing MLLMs for 3D Pose Generation via Hybrid Action Reinforcement Fine-Tuning](https://arxiv.org/abs/2508.07804)
*Bao Li,Xiaomei Zhang,Miao Xu,Zhaoxin Fan,Xiangyu Zhu,Zhen Lei*

Main category: cs.CV

TL;DR: 这篇论文提出Pose-RFT，一个用于MMMLMs的3D人体姿态生成的强化微调框架。


<details>
  <summary>Details</summary>
Motivation: 现有姿态特定的MLLMs存在监督学习方法不足，无法有效建模二义性和实现任务特定对齐的问题。

Method: 将任务表述为联合优化离散语言预测和连续姿态生成的混合动作强化学习问题，提出HyGRPO算法，并设计具体的任务奖励函数。

Result: 实验表明，Pose-RFT在多个姿态生成基准上显著优于现有技术。

Conclusion: Pose-RFT和混合动作强化微调在3D姿态生成中是有效的。

Abstract: Generating 3D human poses from multimodal inputs such as images or text
requires models to capture both rich spatial and semantic correspondences.
While pose-specific multimodal large language models (MLLMs) have shown promise
in this task, they are typically trained with supervised objectives such as
SMPL parameter regression or token-level prediction, which struggle to model
the inherent ambiguity and achieve task-specific alignment required for
accurate 3D pose generation. To address these limitations, we propose Pose-RFT,
a reinforcement fine-tuning framework tailored for 3D human pose generation in
MLLMs. We formulate the task as a hybrid action reinforcement learning problem
that jointly optimizes discrete language prediction and continuous pose
generation. To this end, we introduce HyGRPO, a hybrid reinforcement learning
algorithm that performs group-wise reward normalization over sampled responses
to guide joint optimization of discrete and continuous actions. Pose-RFT
further incorporates task-specific reward functions to guide optimization
towards spatial alignment in image-to-pose generation and semantic consistency
in text-to-pose generation. Extensive experiments on multiple pose generation
benchmarks demonstrate that Pose-RFT significantly improves performance over
existing pose-specific MLLMs, validating the effectiveness of hybrid action
reinforcement fine-tuning for 3D pose generation.

</details>


### [161] [DiTVR: Zero-Shot Diffusion Transformer for Video Restoration](https://arxiv.org/abs/2508.07811)
*Sicheng Gao,Nancy Mehta,Zongwei Wu,Radu Timofte*

Main category: cs.CV

TL;DR: DiTVR 是一种针对视频修复的新型零样本框架，通过扩散变换器结合轨迹关注机制和引导采样，实现更优的时空一致性和细节保留。


<details>
  <summary>Details</summary>
Motivation: 解决传统回归方法无法生成真实细节且需大量配对数据的问题，同时改进生成扩散模型在时间一致性方面的不足。

Method: 将扩散变换器与轨迹感知的注意机制结合，采用光流对齐的注意力机制和引导的采样方法，利用自适应邻居缓存选择相关标记，并通过波段引导采样结合流一致性实现低频数据的一致性。

Result: DiTVR 在视频修复基准测试中达到了新的零样本领域的最佳效果，展现了出色的时间一致性和细节保留能力，且对光流噪声和遮挡具有鲁棒性。

Conclusion: DiTVR 证明了在零样本视频修复中采用扩散机制与创新关注方法的有效性，为相关任务提供新的解决方案。

Abstract: Video restoration aims to reconstruct high quality video sequences from low
quality inputs, addressing tasks such as super resolution, denoising, and
deblurring. Traditional regression based methods often produce unrealistic
details and require extensive paired datasets, while recent generative
diffusion models face challenges in ensuring temporal consistency. We introduce
DiTVR, a zero shot video restoration framework that couples a diffusion
transformer with trajectory aware attention and a wavelet guided, flow
consistent sampler. Unlike prior 3D convolutional or frame wise diffusion
approaches, our attention mechanism aligns tokens along optical flow
trajectories, with particular emphasis on vital layers that exhibit the highest
sensitivity to temporal dynamics. A spatiotemporal neighbour cache dynamically
selects relevant tokens based on motion correspondences across frames. The flow
guided sampler injects data consistency only into low-frequency bands,
preserving high frequency priors while accelerating convergence. DiTVR
establishes a new zero shot state of the art on video restoration benchmarks,
demonstrating superior temporal consistency and detail preservation while
remaining robust to flow noise and occlusions.

</details>


### [162] [Semi-supervised Multiscale Matching for SAR-Optical Image](https://arxiv.org/abs/2508.07812)
*Jingze Gai,Changchun Li*

Main category: cs.CV

TL;DR: 本研究提出了一种半监督SAR-光学图像匹配方法，通过结合深浅层匹配结果生成伪标签，以解决标注数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 目前SAR-光学图像匹配方法依赖像素级标签配对数据，但手工标注耗时且复杂，导致获取足够的标注数据具有挑战性。

Method: 设计了S2M2-SAR方法，结合少量有标签和大量无标签图像对，通过伪标签与监督目标结合进行训练，同时引入无监督的跨模态特征增强模块提升特征解耦效果。

Result: 实验表明，S2M2-SAR在基准数据集上性能优于现有半监督方法，并接近完全监督的SOTA方法。

Conclusion: S2M2-SAR方法在效率和实用性上表现出较高潜力，为SAR-光学图像匹配的进一步发展提供了新方向。

Abstract: Driven by the complementary nature of optical and synthetic aperture radar
(SAR) images, SAR-optical image matching has garnered significant interest.
Most existing SAR-optical image matching methods aim to capture effective
matching features by employing the supervision of pixel-level matched
correspondences within SAR-optical image pairs, which, however, suffers from
time-consuming and complex manual annotation, making it difficult to collect
sufficient labeled SAR-optical image pairs. To handle this, we design a
semi-supervised SAR-optical image matching pipeline that leverages both scarce
labeled and abundant unlabeled image pairs and propose a semi-supervised
multiscale matching for SAR-optical image matching (S2M2-SAR). Specifically, we
pseudo-label those unlabeled SAR-optical image pairs with pseudo ground-truth
similarity heatmaps by combining both deep and shallow level matching results,
and train the matching model by employing labeled and pseudo-labeled similarity
heatmaps. In addition, we introduce a cross-modal feature enhancement module
trained using a cross-modality mutual independence loss, which requires no
ground-truth labels. This unsupervised objective promotes the separation of
modality-shared and modality-specific features by encouraging statistical
independence between them, enabling effective feature disentanglement across
optical and SAR modalities. To evaluate the effectiveness of S2M2-SAR, we
compare it with existing competitors on benchmark datasets. Experimental
results demonstrate that S2M2-SAR not only surpasses existing semi-supervised
methods but also achieves performance competitive with fully supervised SOTA
methods, demonstrating its efficiency and practical potential.

</details>


### [163] [Segmenting and Understanding: Region-aware Semantic Attention for Fine-grained Image Quality Assessment with Large Language Models](https://arxiv.org/abs/2508.07818)
*Chenyue Song,Chen Hui,Haiqi Zhu,Feng Jiang,Yachun Mi,Wei Zhang,Shaohui Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为RSFIQA的无参考图像质量评估模型，通过整合区域级别的失真信息实现多维质量差异的感知，显著提升了图像质量预测的精度。


<details>
  <summary>Details</summary>
Motivation: 现有无参考图像质量评估方法缺乏对语义显著区域和局部质量变化的敏感性，难以全面满足主观人类感知的需求。

Method: 引入Segment Anything Model (SAM)动态分割图像，并结合多模态大语言模型提取语义与失真信息，使用区域感知语义注意力机制生成全局注意力图，并与多种深度神经网络架构结合。

Result: 通过多个基准数据集实验验证，RSFIQA模型表现出了强大的鲁棒性和有效性，实现了竞争性的质量预测性能。

Conclusion: RSFIQA模型通过区域级别和多维感知的创新方法提升了无参考图像质量评估的性能，展示了良好的应用潜力。

Abstract: No-reference image quality assessment (NR-IQA) aims to simulate the process
of perceiving image quality aligned with subjective human perception. However,
existing NR-IQA methods either focus on global representations that leads to
limited insights into the semantically salient regions or employ a uniform
weighting for region features that weakens the sensitivity to local quality
variations. In this paper, we propose a fine-grained image quality assessment
model, named RSFIQA, which integrates region-level distortion information to
perceive multi-dimensional quality discrepancies. To enhance regional quality
awareness, we first utilize the Segment Anything Model (SAM) to dynamically
partition the input image into non-overlapping semantic regions. For each
region, we teach a powerful Multi-modal Large Language Model (MLLM) to extract
descriptive content and perceive multi-dimensional distortions, enabling a
comprehensive understanding of both local semantics and quality degradations.
To effectively leverage this information, we introduce Region-Aware Semantic
Attention (RSA) mechanism, which generates a global attention map by
aggregating fine-grained representations from local regions. In addition,
RSFIQA is backbone-agnostic and can be seamlessly integrated into various deep
neural network architectures. Extensive experiments demonstrate the robustness
and effectiveness of the proposed method, which achieves competitive quality
prediction performance across multiple benchmark datasets.

</details>


### [164] [Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP](https://arxiv.org/abs/2508.07819)
*Ke Ma,Jun Long,Hongxiao Fei,Liujie Hua,Yueyi Luo*

Main category: cs.CV

TL;DR: 提出了一种架构共设计框架，通过精细化特征表示和跨模态融合解决预训练视觉语言模型在零样本异常检测中的适配问题。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉语言模型在零样本异常检测中存在适配差距，缺乏局部归纳偏置及灵活的特征融合方式。

Method: 引入参数高效的Conv-LoRA适配器和动态融合网关（DFG），实现局部偏置注入和自适应模态融合。

Result: 在各种工业和医学基准上进行了实验，展示了所提方法在准确性及鲁棒性方面的优越性。

Conclusion: 通过架构共设计框架，可高效将基础模型适配到密集感知任务中。

Abstract: Pre-trained Vision-Language Models (VLMs) face a significant adaptation gap
when applied to Zero-Shot Anomaly Detection (ZSAD), stemming from their lack of
local inductive biases for dense prediction and their reliance on inflexible
feature fusion paradigms. We address these limitations through an Architectural
Co-Design framework that jointly refines feature representation and cross-modal
fusion. Our method integrates a parameter-efficient Convolutional Low-Rank
Adaptation (Conv-LoRA) adapter to inject local inductive biases for
fine-grained representation, and introduces a Dynamic Fusion Gateway (DFG) that
leverages visual context to adaptively modulate text prompts, enabling a
powerful bidirectional fusion. Extensive experiments on diverse industrial and
medical benchmarks demonstrate superior accuracy and robustness, validating
that this synergistic co-design is critical for robustly adapting foundation
models to dense perception tasks.

</details>


### [165] [MIMIC: Multimodal Inversion for Model Interpretation and Conceptualization](https://arxiv.org/abs/2508.07833)
*Animesh Jain,Alexandros Stergiou*

Main category: cs.CV

TL;DR: 本文提出了一种名为MIMIC的框架，通过反演生成视觉概念，以可视化VLM（视觉语言模型）的内部表示。


<details>
  <summary>Details</summary>
Motivation: VLM架构复杂且难以解释，这限制了透明性和信任度。作者希望通过可视化其内部表示来提高模型的可解释性。

Method: MIMIC框架通过联合的VLM反演和特征对齐目标构建，同时利用三种正则化方法确保空间对齐、自然图像平滑性和语义真实感。

Result: 实验通过定量和定性方式验证了MIMIC的效果，包括标准视觉质量和语义相关指标。

Conclusion: 这是首个针对VLM概念视觉解释的模型反演方法，具有推动多模态模型可解释性研究的潜力。

Abstract: Vision Language Models (VLMs) encode multimodal inputs over large, complex,
and difficult-to-interpret architectures, which limit transparency and trust.
We propose a Multimodal Inversion for Model Interpretation and
Conceptualization (MIMIC) framework to visualize the internal representations
of VLMs by synthesizing visual concepts corresponding to internal encodings.
MIMIC uses a joint VLM-based inversion and a feature alignment objective to
account for VLM's autoregressive processing. It additionally includes a triplet
of regularizers for spatial alignment, natural image smoothness, and semantic
realism. We quantitatively and qualitatively evaluate MIMIC by inverting visual
concepts over a range of varying-length free-form VLM output texts. Reported
results include both standard visual quality metrics as well as semantic
text-based metrics. To the best of our knowledge, this is the first model
inversion approach addressing visual interpretations of VLM concepts.

</details>


### [166] [Effortless Vision-Language Model Specialization in Histopathology without Annotation](https://arxiv.org/abs/2508.07835)
*Jingna Qiu,Nishanth Jain,Jonas Ammeling,Marc Aubreville,Katharina Breininger*

Main category: cs.CV

TL;DR: 研究通过在特定领域和任务相关的图像-描述对上持续预训练，使视觉语言模型（VLMs）无需手动标注即可适应新的病理学任务，提升零样本与少样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs通用设计可能在特定任务中表现不佳，监督微调需要手动标注样本。研究目标是通过无标注方式增强VLMs的适应性。

Method: 通过在现有数据库中提取的领域和任务相关图像-描述对上持续预训练两种VLMs（CONCH及QuiltNet），尝试零样本与少样本任务适应。

Result: 实验表明，图像-描述对的加入显著提升了零样本与少样本性能，尤其在大规模训练时，性能可与少样本方法媲美。

Conclusion: 持续预训练是一种有效的、任务无关且无需标注的VLM适应新病理学任务的方法，为相关领域提供了前景广阔的研究路径。

Abstract: Recent advances in Vision-Language Models (VLMs) in histopathology, such as
CONCH and QuiltNet, have demonstrated impressive zero-shot classification
capabilities across various tasks. However, their general-purpose design may
lead to suboptimal performance in specific downstream applications. While
supervised fine-tuning methods address this issue, they require manually
labeled samples for adaptation. This paper investigates annotation-free
adaptation of VLMs through continued pretraining on domain- and task-relevant
image-caption pairs extracted from existing databases. Our experiments on two
VLMs, CONCH and QuiltNet, across three downstream tasks reveal that these pairs
substantially enhance both zero-shot and few-shot performance. Notably, with
larger training sizes, continued pretraining matches the performance of
few-shot methods while eliminating manual labeling. Its effectiveness,
task-agnostic design, and annotation-free workflow make it a promising pathway
for adapting VLMs to new histopathology tasks. Code is available at
https://github.com/DeepMicroscopy/Annotation-free-VLM-specialization.

</details>


### [167] [CBDES MoE: Hierarchically Decoupled Mixture-of-Experts for Functional Modules in Autonomous Driving](https://arxiv.org/abs/2508.07838)
*Qi Xiang,Kunsong Shi,Zhigui Lin,Lei He*

Main category: cs.CV

TL;DR: 本文提出了用于多模态鸟瞰图感知系统的CBDES MoE架构，显著提升了自动驾驶领域中的3D目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态BEV方法在输入适应性、建模能力和泛化能力方面存在局限，需要新的方法来解决这些问题。

Method: 设计了一种层次化解耦的专家混合(Mixture-of-Experts)架构CBDES MoE，将多种异构专家网络集成，并通过轻量化自注意力路由器动态选择专家路径，实现输入感知的高效推理。

Result: 在真实世界的nuScenes数据集上，CBDES MoE比最强单专家模型在mAP和NDS指标上分别提高了1.6点和4.1点，性能显著提升。

Conclusion: CBDES MoE框架通过模块化设计和动态专家选择策略，提高了自动驾驶多模态BEV系统的性能和实际应用价值。

Abstract: Bird's Eye View (BEV) perception systems based on multi-sensor feature fusion
have become a fundamental cornerstone for end-to-end autonomous driving.
However, existing multi-modal BEV methods commonly suffer from limited input
adaptability, constrained modeling capacity, and suboptimal generalization. To
address these challenges, we propose a hierarchically decoupled
Mixture-of-Experts architecture at the functional module level, termed
Computing Brain DEvelopment System Mixture-of-Experts (CBDES MoE). CBDES MoE
integrates multiple structurally heterogeneous expert networks with a
lightweight Self-Attention Router (SAR) gating mechanism, enabling dynamic
expert path selection and sparse, input-aware efficient inference. To the best
of our knowledge, this is the first modular Mixture-of-Experts framework
constructed at the functional module granularity within the autonomous driving
domain. Extensive evaluations on the real-world nuScenes dataset demonstrate
that CBDES MoE consistently outperforms fixed single-expert baselines in 3D
object detection. Compared to the strongest single-expert model, CBDES MoE
achieves a 1.6-point increase in mAP and a 4.1-point improvement in NDS,
demonstrating the effectiveness and practical advantages of the proposed
approach.

</details>


### [168] [Deep Space Weather Model: Long-Range Solar Flare Prediction from Multi-Wavelength Images](https://arxiv.org/abs/2508.07847)
*Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

TL;DR: 本文提出Deep SWM模型，通过多重深度状态空间模型与稀疏掩码自动编码器，更准确地预测太阳耀斑，同时建立了FlareBench基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有基于启发性物理特征的方法难以从太阳图像中学习表示，而端到端学习方法又难以建模太阳图像中的长时依赖性。

Method: 提出Deep SWM模型，结合多通道太阳图像处理与长程时空依赖建模，并采用稀疏掩码自动编码器预训练策略。

Result: Deep SWM在标准性能和可靠性度量上表现优于基线方法及人类专家，同时开发了涵盖11年太阳活动周期的FlareBench基准测试。

Conclusion: Deep SWM显著提升了太阳耀斑的预测精度与可靠性，展示了其在太阳活动研究中的潜力与价值。

Abstract: Accurate, reliable solar flare prediction is crucial for mitigating potential
disruptions to critical infrastructure, while predicting solar flares remains a
significant challenge. Existing methods based on heuristic physical features
often lack representation learning from solar images. On the other hand,
end-to-end learning approaches struggle to model long-range temporal
dependencies in solar images. In this study, we propose Deep Space Weather
Model (Deep SWM), which is based on multiple deep state space models for
handling both ten-channel solar images and long-range spatio-temporal
dependencies. Deep SWM also features a sparse masked autoencoder, a novel
pretraining strategy that employs a two-phase masking approach to preserve
crucial regions such as sunspots while compressing spatial information.
Furthermore, we built FlareBench, a new public benchmark for solar flare
prediction covering a full 11-year solar activity cycle, to validate our
method. Our method outperformed baseline methods and even human expert
performance on standard metrics in terms of performance and reliability. The
project page can be found at https://keio-smilab25.github.io/DeepSWM.

</details>


### [169] [Morphological Analysis of Semiconductor Microstructures using Skeleton Graphs](https://arxiv.org/abs/2508.07850)
*Noriko Nitta,Rei Miyata,Naoto Oishi*

Main category: cs.CV

TL;DR: 研究分析了离子束辐照引起的Ge表面微观结构拓扑特性，并通过图卷积神经网络和PCA进行嵌入与分析。


<details>
  <summary>Details</summary>
Motivation: 探究辐照参数对Ge表面形态学特性的影响。

Method: 利用电子显微图像提取Ge表面的拓扑特性，并通过图卷积神经网络嵌入，再用PCA分析，最后用Davies-Bouldin指数评估聚类。

Result: 发现辐照角度比辐照流密度对Ge表面形态影响更显著。

Conclusion: 不同的辐照角度显著改变了Ge表面的微结构特性，对形态学研究具有指导意义。

Abstract: In this paper, electron microscopy images of microstructures formed on Ge
surfaces by ion beam irradiation were processed to extract topological features
as skeleton graphs, which were then embedded using a graph convolutional
network. The resulting embeddings were analyzed using principal component
analysis, and cluster separability in the resulting PCA space was evaluated
using the Davies-Bouldin index. The results indicate that variations in
irradiation angle have a more significant impact on the morphological
properties of Ge surfaces than variations in irradiation fluence.

</details>


### [170] [Tracking Any Point Methods for Markerless 3D Tissue Tracking in Endoscopic Stereo Images](https://arxiv.org/abs/2508.07851)
*Konrad Reuter,Suresh Guttikonda,Sarah Latus,Lennart Maack,Christian Betz,Tobias Maurer,Alexander Schlaefer*

Main category: cs.CV

TL;DR: 本文提出了一种利用2D TAP网络进行非标记3D组织跟踪的新方法，通过结合两个CoTracker模型从立体内镜图像中估算3D运动，并在不同实验环境下进行了评估。


<details>
  <summary>Details</summary>
Motivation: 微创手术存在组织动态运动和视野受限的挑战，而精确的组织跟踪能够支持手术指导，提高安全性并实现复杂操作中的上下文感知机器人辅助。

Method: 利用2D TAP网络和两个CoTracker模型分别进行时间跟踪和立体匹配，从立体内镜图像中估算3D组织运动，并在临床腹腔镜装置和一个模拟组织运动的机械臂上进行了试验验证。

Result: 在鸡组织模型上的跟踪误差低至1.1毫米（速度为10 mm/s），表现出更为可靠的结果。

Conclusion: TAP模型在挑战性手术场景中的基于非标记3D组织跟踪展现了良好的潜力。

Abstract: Minimally invasive surgery presents challenges such as dynamic tissue motion
and a limited field of view. Accurate tissue tracking has the potential to
support surgical guidance, improve safety by helping avoid damage to sensitive
structures, and enable context-aware robotic assistance during complex
procedures. In this work, we propose a novel method for markerless 3D tissue
tracking by leveraging 2D Tracking Any Point (TAP) networks. Our method
combines two CoTracker models, one for temporal tracking and one for stereo
matching, to estimate 3D motion from stereo endoscopic images. We evaluate the
system using a clinical laparoscopic setup and a robotic arm simulating tissue
motion, with experiments conducted on a synthetic 3D-printed phantom and a
chicken tissue phantom. Tracking on the chicken tissue phantom yielded more
reliable results, with Euclidean distance errors as low as 1.1 mm at a velocity
of 10 mm/s. These findings highlight the potential of TAP-based models for
accurate, markerless 3D tracking in challenging surgical scenarios.

</details>


### [171] [Being-M0.5: A Real-Time Controllable Vision-Language-Motion Model](https://arxiv.org/abs/2508.07863)
*Bin Cao,Sipeng Zheng,Ye Wang,Lujie Xia,Qianshan Wei,Qin Jin,Jing Liu,Zongqing Lu*

Main category: cs.CV

TL;DR: Being-M0.5通过引入HuMo100M数据集和新技术，实现了多任务、人类动作生成的可控性和实时性突破，目前为相关领域最先进的模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型在可控性方面存在多种局限，包括多样化命令响应不足、姿势初始化能力受限、对长时间序列表现较差等问题。

Method: 提出了新的人体动作生成模型Being-M0.5，通过HuMo100M数据集（包含1亿多组数据）以及创新的部件感知残差量化技术，实现了对身体各部分的细粒度控制。

Result: 实验表明，Being-M0.5在动作生成基准测试中表现具备实时性并优于其他模型，同时效率和性能指标优越。

Conclusion: HuMo100M和Being-M0.5为将动作生成技术应用到实际场景提供了重要助力，并为未来技术开发提供了宝贵的指导与启发。

Abstract: Human motion generation has emerged as a critical technology with
transformative potential for real-world applications. However, existing
vision-language-motion models (VLMMs) face significant limitations that hinder
their practical deployment. We identify controllability as a main bottleneck,
manifesting in five key aspects: inadequate response to diverse human commands,
limited pose initialization capabilities, poor performance on long-term
sequences, insufficient handling of unseen scenarios, and lack of fine-grained
control over individual body parts. To overcome these limitations, we present
Being-M0.5, the first real-time, controllable VLMM that achieves
state-of-the-art performance across multiple motion generation tasks. Our
approach is built upon HuMo100M, the largest and most comprehensive human
motion dataset to date, comprising over 5 million self-collected motion
sequences, 100 million multi-task instructional instances, and detailed
part-level annotations that address a critical gap in existing datasets. We
introduce a novel part-aware residual quantization technique for motion
tokenization that enables precise, granular control over individual body parts
during generation. Extensive experimental validation demonstrates Being-M0.5's
superior performance across diverse motion benchmarks, while comprehensive
efficiency analysis confirms its real-time capabilities. Our contributions
include design insights and detailed computational analysis to guide future
development of practical motion generators. We believe that HuMo100M and
Being-M0.5 represent significant advances that will accelerate the adoption of
motion generation technologies in real-world applications. The project page is
available at https://beingbeyond.github.io/Being-M0.5.

</details>


### [172] [CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced Multimodal In-Context Learning](https://arxiv.org/abs/2508.07871)
*Yanshu Li,Jianjiang Yang,Zhennan Shen,Ligong Han,Haoyan Xu,Ruixiang Tang*

Main category: cs.CV

TL;DR: 这篇文章提出了一种名为CATP的训练自由剪枝方法，用于高效减少图像输入中的冗余token，同时保留了跨模态上下文学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有大规模视觉语言模型（LVLM）在处理多模态输入时面临图像token冗余问题，导致推理效率低下且性能不稳定，尤其是在跨模态上下文学习中表现尤为明显。

Method: 提出了一种名为CATP的方法，通过两阶段进程性的剪枝策略，去除冗余图像token，充分考虑复杂的跨模态交互信息，无需额外训练。

Result: CATP在移除77.8%的图像tokens后，四种LVLM和八项基准测试上的性能平均提升0.6%，推理延迟平均减少10.78%。

Conclusion: CATP显著提升了多模态上下文学习的效率和稳定性，为未来多模态场景下的研究奠定了基础。

Abstract: Modern large vision-language models (LVLMs) convert each input image into a
large set of tokens, far outnumbering the text tokens. Although this improves
visual perception, it introduces severe image token redundancy. Because image
tokens carry sparse information, many add little to reasoning, yet greatly
increase inference cost. The emerging image token pruning methods tackle this
issue by identifying the most important tokens and discarding the rest. These
methods can raise efficiency with only modest performance loss. However, most
of them only consider single-image tasks and overlook multimodal in-context
learning (ICL), where redundancy is greater and efficiency is more critical.
Redundant tokens weaken the advantage of multimodal ICL for rapid domain
adaptation and cause unstable performance. Applying existing pruning methods in
this setting leads to large accuracy drops, exposing a clear gap and the need
for new techniques. Thus, we propose Contextually Adaptive Token Pruning
(CATP), a training-free pruning method targeted at multimodal ICL. CATP
consists of two stages that perform progressive pruning to fully account for
the complex cross-modal interactions in the input sequence. After removing
77.8\% of the image tokens, CATP produces an average performance gain of 0.6\%
over the vanilla model on four LVLMs and eight benchmarks, exceeding all
baselines remarkably. Meanwhile, it effectively improves efficiency by
achieving an average reduction of 10.78\% in inference latency. CATP enhances
the practical value of multimodal ICL and lays the groundwork for future
progress in interleaved image-text scenarios.

</details>


### [173] [Selective Contrastive Learning for Weakly Supervised Affordance Grounding](https://arxiv.org/abs/2508.07877)
*WonJun Moon,Hyun Seok Seong,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 该论文提出了一种弱监督的可供性定位方法，通过利用选择性原型和像素对比目标，结合 CLIP 模型，以学习交互对象的功能部件。


<details>
  <summary>Details</summary>
Motivation: 人类能通过观察，直观识别对象的功能部件，而无需逐像素标注。本研究旨在模拟这一能力，以助力机器学习识别用于特定交互动作的对象部分。

Method: 提出了一种结合选择性原型与像素对比的目标学习框架，利用CLIP模型跨视角定位交互对象，依此推导出精准的局部可供性信息。

Result: 通过实验验证，本文方法能够更有效地将激活区域集中到交互相关的线索上，并优于现有方法。

Conclusion: 本文方法克服了现有方法对分类信号的依赖，提出了更加准确的可供性定位技术，以提高弱监督模型的学习效果。

Abstract: Facilitating an entity's interaction with objects requires accurately
identifying parts that afford specific actions. Weakly supervised affordance
grounding (WSAG) seeks to imitate human learning from third-person
demonstrations, where humans intuitively grasp functional parts without needing
pixel-level annotations. To achieve this, grounding is typically learned using
a shared classifier across images from different perspectives, along with
distillation strategies incorporating part discovery process. However, since
affordance-relevant parts are not always easily distinguishable, models
primarily rely on classification, often focusing on common class-specific
patterns that are unrelated to affordance. To address this limitation, we move
beyond isolated part-level learning by introducing selective prototypical and
pixel contrastive objectives that adaptively learn affordance-relevant cues at
both the part and object levels, depending on the granularity of the available
information. Initially, we find the action-associated objects in both
egocentric (object-focused) and exocentric (third-person example) images by
leveraging CLIP. Then, by cross-referencing the discovered objects of
complementary views, we excavate the precise part-level affordance clues in
each perspective. By consistently learning to distinguish affordance-relevant
regions from affordance-irrelevant background context, our approach effectively
shifts activation from irrelevant areas toward meaningful affordance cues.
Experimental results demonstrate the effectiveness of our method. Codes are
available at github.com/hynnsk/SelectiveCL.

</details>


### [174] [TAP: Parameter-efficient Task-Aware Prompting for Adverse Weather Removal](https://arxiv.org/abs/2508.07878)
*Hanting Wang,Shengpeng Ji,Shulei Wang,Hai Huang,Xiao Jin,Qifei Zhang,Tao Jin*

Main category: cs.CV

TL;DR: 本文提出了一种参数高效的全能图像修复框架，通过任务感知增强提示处理多种恶劣天气退化情景。


<details>
  <summary>Details</summary>
Motivation: 现有全能图像修复方法通常对特定退化类型设计专用网络模块，导致参数开销较大，同时忽视任务之间的相关性。为此，作者希望在提升参数效率的同时更好地建模任务间的关联性。

Method: 采用两阶段训练，包括预训练阶段（获取通用修复知识）和提示微调阶段（适应特定退化）。通过任务感知增强提示，结合低秩分解和对比约束以获取任务相关性并提升参数效率。

Result: 实验结果表明，该方法在多种图像修复任务均表现优越，仅使用2.75M参数。

Conclusion: 提出的框架在提高性能的同时显著减少了参数量，为全能图像修复提供了一种高效解决方案。

Abstract: Image restoration under adverse weather conditions has been extensively
explored, leading to numerous high-performance methods. In particular, recent
advances in All-in-One approaches have shown impressive results by training on
multi-task image restoration datasets. However, most of these methods rely on
dedicated network modules or parameters for each specific degradation type,
resulting in a significant parameter overhead. Moreover, the relatedness across
different restoration tasks is often overlooked. In light of these issues, we
propose a parameter-efficient All-in-One image restoration framework that
leverages task-aware enhanced prompts to tackle various adverse weather
degradations.Specifically, we adopt a two-stage training paradigm consisting of
a pretraining phase and a prompt-tuning phase to mitigate parameter conflicts
across tasks. We first employ supervised learning to acquire general
restoration knowledge, and then adapt the model to handle specific degradation
via trainable soft prompts. Crucially, we enhance these task-specific prompts
in a task-aware manner. We apply low-rank decomposition to these prompts to
capture both task-general and task-specific characteristics, and impose
contrastive constraints to better align them with the actual inter-task
relatedness. These enhanced prompts not only improve the parameter efficiency
of the restoration model but also enable more accurate task modeling, as
evidenced by t-SNE analysis. Experimental results on different restoration
tasks demonstrate that the proposed method achieves superior performance with
only 2.75M parameters.

</details>


### [175] [NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and Deformable 3D Gaussian Reconstruction](https://arxiv.org/abs/2508.07897)
*Tianle Zeng,Junlei Hu,Gerardo Loza Galindo,Sharib Ali,Duygu Sarikaya,Pietro Valdastri,Dominic Jones*

Main category: cs.CV

TL;DR: 本研究引入了动态高斯点技术，生成具有真实组织背景的合成外科影像数据，以缓解外科影像数据集的稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 目前基于数据驱动的计算机视觉技术依赖大规模、高质量标注的数据集，这使得其在外科数据科学中的应用受限。

Method: 提出了一种动态高斯模型，用于表示动态外科场景，可从未见视角生成外科器械图像，同时通过动态训练调整策略应对实际场景中相机姿态校准不佳的问题，并基于动态高斯自动生成标注数据。

Result: 实验证明该方法生成的影像数据集在峰值信噪比指标上达到了29.87，显著提高了医学特定神经网络的性能，比传统数据增强方法提升了10%，总性能提升约15%。

Conclusion: 动态高斯点技术能够生成高逼真度的标注影像数据集，为解决外科影像数据匮乏问题提供了新思路，并有效提升了医学神经网络的表现力与鲁棒性。

Abstract: Computer vision-based technologies significantly enhance surgical automation
by advancing tool tracking, detection, and localization. However, Current
data-driven approaches are data-voracious, requiring large, high-quality
labeled image datasets, which limits their application in surgical data
science. Our Work introduces a novel dynamic Gaussian Splatting technique to
address the data scarcity in surgical image datasets. We propose a dynamic
Gaussian model to represent dynamic surgical scenes, enabling the rendering of
surgical instruments from unseen viewpoints and deformations with real tissue
backgrounds. We utilize a dynamic training adjustment strategy to address
challenges posed by poorly calibrated camera poses from real-world scenarios.
Additionally, we propose a method based on dynamic Gaussians for automatically
generating annotations for our synthetic data. For evaluation, we constructed a
new dataset featuring seven scenes with 14,000 frames of tool and camera motion
and tool jaw articulation, with a background of an ex-vivo porcine model. Using
this dataset, we synthetically replicate the scene deformation from the ground
truth data, allowing direct comparisons of synthetic image quality.
Experimental results illustrate that our method generates photo-realistic
labeled image datasets with the highest values in Peak-Signal-to-Noise Ratio
(29.87). We further evaluate the performance of medical-specific neural
networks trained on real and synthetic images using an unseen real-world image
dataset. Our results show that the performance of models trained on synthetic
images generated by the proposed method outperforms those trained with
state-of-the-art standard data augmentation by 10%, leading to an overall
improvement in model performances by nearly 15%.

</details>


### [176] [Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation](https://arxiv.org/abs/2508.07901)
*Bowen Xue,Qixin Yan,Wenjing Wang,Hao Liu,Chen Li*

Main category: cs.CV

TL;DR: 该论文提出一个名为Stand-In的轻量级视频生成框架，其突出的特点是能够在视频生成中保存身份特征，同时质量表现优异。


<details>
  <summary>Details</summary>
Motivation: 目前生成高保真且符合特定身份的人类视频具有挑战性，现有方法往往参数过多且与其他生成工具不兼容，因此需要一种高效且兼容性更强的解决方案。

Method: 该框架在预训练的视频生成模型中引入了条件图像分支，通过受限的自注意力机制和条件位置映射实现身份控制，并用仅2000对样本进行快速训练。

Result: 尽管仅额外使用了约1%的参数量，Stand-In框架在视频质量和身份保存上均优于全参数训练方法，并且表现出色。

Conclusion: Stand-In框架不仅在质量与身份保留方面实现了卓越表现，还可以无缝适配到其他任务，如主题驱动的视频生成、姿态参考视频生成、风格化和换脸应用。

Abstract: Generating high-fidelity human videos that match user-specified identities is
important yet challenging in the field of generative AI. Existing methods often
rely on an excessive number of training parameters and lack compatibility with
other AIGC tools. In this paper, we propose Stand-In, a lightweight and
plug-and-play framework for identity preservation in video generation.
Specifically, we introduce a conditional image branch into the pre-trained
video generation model. Identity control is achieved through restricted
self-attentions with conditional position mapping, and can be learned quickly
with only 2000 pairs. Despite incorporating and training just $\sim$1\%
additional parameters, our framework achieves excellent results in video
quality and identity preservation, outperforming other full-parameter training
methods. Moreover, our framework can be seamlessly integrated for other tasks,
such as subject-driven video generation, pose-referenced video generation,
stylization, and face swapping.

</details>


### [177] [CTC Transcription Alignment of the Bullinger Letters: Automatic Improvement of Annotation Quality](https://arxiv.org/abs/2508.07904)
*Marco Peer,Anna Scius-Bertrand,Andreas Fischer*

Main category: cs.CV

TL;DR: 此论文提出一种针对历史文献手写识别的改进方法，通过处理注释错误，尤其是连字符问题，提升了识别精度和对齐质量。


<details>
  <summary>Details</summary>
Motivation: 手写文献依旧面临变动性大、质量劣化及有限的布局注释等问题，需要有效方法解决注释错误，尤其是16世纪大量信件集合中的连字符问题。

Method: 基于CTC的对齐算法，通过动态规划将完整转录匹配到文本行图像，同时使用CTC损失训练模型，并引入不完全转录的自动训练方法。还发现较弱模型有助于对齐，提出迭代训练策略。

Result: 提出的方法在识别性能（如CER提升1.1个百分点）和文本对齐的准确性上表现较好，并发布了一个手动修订的新数据子集和配套代码。

Conclusion: 本方法能够有效提高历史文献OCR管道的识别及对齐质量，且具备迭代改进的潜力，相关资源已开源共享。

Abstract: Handwritten text recognition for historical documents remains challenging due
to handwriting variability, degraded sources, and limited layout-aware
annotations. In this work, we address annotation errors - particularly
hyphenation issues - in the Bullinger correspondence, a large 16th-century
letter collection. We introduce a self-training method based on a CTC alignment
algorithm that matches full transcriptions to text line images using dynamic
programming and model output probabilities trained with the CTC loss. Our
approach improves performance (e.g., by 1.1 percentage points CER with PyLaia)
and increases alignment accuracy. Interestingly, we find that weaker models
yield more accurate alignments, enabling an iterative training strategy. We
release a new manually corrected subset of 100 pages from the Bullinger
dataset, along with our code and benchmarks. Our approach can be applied
iteratively to further improve the CER as well as the alignment quality for
text recognition pipelines. Code and data are available via
https://github.com/andreas-fischer-unifr/nntp.

</details>


### [178] [Generative Video Matting](https://arxiv.org/abs/2508.07905)
*Yongtao Ge,Kangyang Xie,Guangkai Xu,Mingyu Liu,Li Ke,Longtao Huang,Hui Xue,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: 提出了一种新的视频抠图方法，通过大规模预训练和强大的视频扩散模型先验，解决现有方法在真实场景中泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频抠图数据集缺乏高质量真实标注，导致目前的方法在真实场景中表现不佳。

Method: 大规模预训练结合多样的合成数据和伪标签分割数据，共生成约200段3秒视频，并设计利用预训练视频扩散模型的创新架构来增强模型时序一致性和域泛化能力。

Result: 在三个基准数据集上实现了优越的定量表现，并通过多场景定性结果展示了方法的强泛化能力。

Conclusion: 设计的模型在减少合成与真实场景域差异、提升时序一致性方面具有显著优势，有助于推动视频抠图技术在真实应用中的发展。

Abstract: Video matting has traditionally been limited by the lack of high-quality
ground-truth data. Most existing video matting datasets provide only
human-annotated imperfect alpha and foreground annotations, which must be
composited to background images or videos during the training stage. Thus, the
generalization capability of previous methods in real-world scenarios is
typically poor. In this work, we propose to solve the problem from two
perspectives. First, we emphasize the importance of large-scale pre-training by
pursuing diverse synthetic and pseudo-labeled segmentation datasets. We also
develop a scalable synthetic data generation pipeline that can render diverse
human bodies and fine-grained hairs, yielding around 200 video clips with a
3-second duration for fine-tuning. Second, we introduce a novel video matting
approach that can effectively leverage the rich priors from pre-trained video
diffusion models. This architecture offers two key advantages. First, strong
priors play a critical role in bridging the domain gap between synthetic and
real-world scenes. Second, unlike most existing methods that process video
matting frame-by-frame and use an independent decoder to aggregate temporal
information, our model is inherently designed for video, ensuring strong
temporal consistency. We provide a comprehensive quantitative evaluation across
three benchmark datasets, demonstrating our approach's superior performance,
and present comprehensive qualitative results in diverse real-world scenes,
illustrating the strong generalization capability of our method. The code is
available at https://github.com/aim-uofa/GVM.

</details>


### [179] [Mem4D: Decoupling Static and Dynamic Memory for Dynamic Scene Reconstruction](https://arxiv.org/abs/2508.07908)
*Xudong Cai,Shuo Wang,Peng Wang,Yongcai Wang,Zhaoxin Fan,Wanting Li,Tianbao Zhang,Jianrong Tao,Yeying Jin,Deying Li*

Main category: cs.CV

TL;DR: 本文提出Mem4D，可以从单目视频中高效重建密集动态场景，同时兼顾静态全局一致性与动态高保真。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态场景几何重建中面临内存需求困境，难以兼顾静态结构的长期稳定和动态运动的高保真性。

Method: 提出一种全新框架Mem4D，采用双重记忆架构：瞬态动态记忆(TDM)用于捕捉近帧高频动态细节，持久结构记忆(PSM)用于压缩和保存长期静态几何信息。

Result: 实验表明，Mem4D在挑战性基准上达到了最新或具有竞争力的性能，并保持较高效率。

Conclusion: Mem4D有效解决了内存需求困境，在动态与静态重建中实现了优异的效果与平衡。

Abstract: Reconstructing dense geometry for dynamic scenes from a monocular video is a
critical yet challenging task. Recent memory-based methods enable efficient
online reconstruction, but they fundamentally suffer from a Memory Demand
Dilemma: The memory representation faces an inherent conflict between the
long-term stability required for static structures and the rapid, high-fidelity
detail retention needed for dynamic motion. This conflict forces existing
methods into a compromise, leading to either geometric drift in static
structures or blurred, inaccurate reconstructions of dynamic objects. To
address this dilemma, we propose Mem4D, a novel framework that decouples the
modeling of static geometry and dynamic motion. Guided by this insight, we
design a dual-memory architecture: 1) The Transient Dynamics Memory (TDM)
focuses on capturing high-frequency motion details from recent frames, enabling
accurate and fine-grained modeling of dynamic content; 2) The Persistent
Structure Memory (PSM) compresses and preserves long-term spatial information,
ensuring global consistency and drift-free reconstruction for static elements.
By alternating queries to these specialized memories, Mem4D simultaneously
maintains static geometry with global consistency and reconstructs dynamic
elements with high fidelity. Experiments on challenging benchmarks demonstrate
that our method achieves state-of-the-art or competitive performance while
maintaining high efficiency. Codes will be publicly available.

</details>


### [180] [Safeguarding Generative AI Applications in Preclinical Imaging through Hybrid Anomaly Detection](https://arxiv.org/abs/2508.07923)
*Jakub Binda,Valentina Paneta,Vasileios Eleftheriadis,Hongkyou Chung,Panagiotis Papadimitroulas,Neo Christopher Chung*

Main category: cs.CV

TL;DR: 提出了一个混合异常检测框架，用于提升生物医学影像领域中生成式AI模型的鲁棒性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 核医学中的数据合成具有高风险性，亟需健全的机制来检测和管理模型的异常行为。

Method: 开发并实现了用于异常检测的混合框架，并应用于两种生成式AI模型任务中：分别从照片生成X光图像和根据SPECT/CT扫描估算3D辐射剂量分布。

Result: 实验显示，该框架显著提升了生成式AI的可靠性，减少了人工干预，并支持实时质量控制。

Conclusion: 该混合异常检测方法提高了生成式AI在前临床应用中的鲁棒性、可扩展性和合规性，使其更适用于工业实践。

Abstract: Generative AI holds great potentials to automate and enhance data synthesis
in nuclear medicine. However, the high-stakes nature of biomedical imaging
necessitates robust mechanisms to detect and manage unexpected or erroneous
model behavior. We introduce development and implementation of a hybrid anomaly
detection framework to safeguard GenAI models in BIOEMTECH's eyes(TM) systems.
Two applications are demonstrated: Pose2Xray, which generates synthetic X-rays
from photographic mouse images, and DosimetrEYE, which estimates 3D radiation
dose maps from 2D SPECT/CT scans. In both cases, our outlier detection (OD)
enhances reliability, reduces manual oversight, and supports real-time quality
control. This approach strengthens the industrial viability of GenAI in
preclinical settings by increasing robustness, scalability, and regulatory
compliance.

</details>


### [181] [RSVLM-QA: A Benchmark Dataset for Remote Sensing Vision Language Model-based Question Answering](https://arxiv.org/abs/2508.07918)
*Xing Zi,Jinghao Xiao,Yunxiao Shi,Xian Tao,Jun Li,Ali Braytee,Mukesh Prasad*

Main category: cs.CV

TL;DR: 本文提出了RSVLM-QA，一个专为遥感领域设计的大规模、内容丰富的视觉问答（VQA）数据集，整合了多个著名的遥感数据集，包含13,820张图像和162,373对VQA问题，并展示其在多模态模型评估中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的遥感领域VQA数据集在注释丰富性、问题多样性及推理能力评估方面存在局限性，亟需一个更为全面的数据集以推动该领域发展。

Method: 提出了一种创新的双轨注释生成流程：一是利用GPT-4.1生成详细注释和复杂的基于图像字幕的VQA对；二是基于分割数据提取物体计数信息并生成自然语言答案及对应问题模版。

Result: RSVLM-QA数据集包含13,820张图像和162,373对VQA问题，同时统计分析表明其注释深度和广度优于现有遥感VQA数据集。

Conclusion: RSVLM-QA数据集为遥感VQA及视觉语言模型研究提供了一个关键资源，能有效评估当前模型在遥感领域的理解与推理能力，有望推动该领域的进一步突破。

Abstract: Visual Question Answering (VQA) in remote sensing (RS) is pivotal for
interpreting Earth observation data. However, existing RS VQA datasets are
constrained by limitations in annotation richness, question diversity, and the
assessment of specific reasoning capabilities. This paper introduces RSVLM-QA
dataset, a new large-scale, content-rich VQA dataset for the RS domain.
RSVLM-QA is constructed by integrating data from several prominent RS
segmentation and detection datasets: WHU, LoveDA, INRIA, and iSAID. We employ
an innovative dual-track annotation generation pipeline. Firstly, we leverage
Large Language Models (LLMs), specifically GPT-4.1, with meticulously designed
prompts to automatically generate a suite of detailed annotations including
image captions, spatial relations, and semantic tags, alongside complex
caption-based VQA pairs. Secondly, to address the challenging task of object
counting in RS imagery, we have developed a specialized automated process that
extracts object counts directly from the original segmentation data; GPT-4.1
then formulates natural language answers from these counts, which are paired
with preset question templates to create counting QA pairs. RSVLM-QA comprises
13,820 images and 162,373 VQA pairs, featuring extensive annotations and
diverse question types. We provide a detailed statistical analysis of the
dataset and a comparison with existing RS VQA benchmarks, highlighting the
superior depth and breadth of RSVLM-QA's annotations. Furthermore, we conduct
benchmark experiments on Six mainstream Vision Language Models (VLMs),
demonstrating that RSVLM-QA effectively evaluates and challenges the
understanding and reasoning abilities of current VLMs in the RS domain. We
believe RSVLM-QA will serve as a pivotal resource for the RS VQA and VLM
research communities, poised to catalyze advancements in the field.

</details>


### [182] [PrIINeR: Towards Prior-Informed Implicit Neural Representations for Accelerated MRI](https://arxiv.org/abs/2508.08058)
*Ziad Al-Haj Hemidi,Eytan Kats,Mattias P. Heinrich*

Main category: cs.CV

TL;DR: 提出了一种名为PrIINeR的新方法，通过结合预训练深度学习模型的先验知识与实例优化解决高加速MRI重建中的图像质量问题。


<details>
  <summary>Details</summary>
Motivation: 传统MRI加速扫描中，由于缺乏强先验约束，常导致图像质量退化，尤其在高加速因子下出现结构丢失和伪影问题。

Method: PrIINeR方法将预训练深度学习的先验知识整合到隐式神经表示（INR）框架中，同时结合实例优化和双重数据一致性约束，使重建结果与采集数据及先验信息对齐。

Result: 在NYU fastMRI数据集上的实验表明，PrIINeR在结构保留和抗伪影效果上优于其他INR和多种最先进学习方法。

Conclusion: PrIINeR方法将深度学习与INR技术相融合，为高质量加速MRI重建提供了一种更可靠的解决方案，显著提高了MRI成像性能。

Abstract: Accelerating Magnetic Resonance Imaging (MRI) reduces scan time but often
degrades image quality. While Implicit Neural Representations (INRs) show
promise for MRI reconstruction, they struggle at high acceleration factors due
to weak prior constraints, leading to structural loss and aliasing artefacts.
To address this, we propose PrIINeR, an INR-based MRI reconstruction method
that integrates prior knowledge from pre-trained deep learning models into the
INR framework. By combining population-level knowledge with instance-based
optimization and enforcing dual data consistency, PrIINeR aligns both with the
acquired k-space data and the prior-informed reconstruction. Evaluated on the
NYU fastMRI dataset, our method not only outperforms state-of-the-art INR-based
approaches but also improves upon several learning-based state-of-the-art
methods, significantly improving structural preservation and fidelity while
effectively removing aliasing artefacts.PrIINeR bridges deep learning and
INR-based techniques, offering a more reliable solution for high-quality,
accelerated MRI reconstruction. The code is publicly available on
https://github.com/multimodallearning/PrIINeR.

</details>


### [183] [Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation](https://arxiv.org/abs/2508.07981)
*Fangyuan Mao,Aiming Hao,Jintao Chen,Dongxia Liu,Xiaokun Feng,Jiashu Zhu,Meiqi Wu,Chubin Chen,Jiahong Wu,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 提出一种名为Omni-Effects的框架，解决了当前视频生成中存在的单一特效限制，能够同时在不同位置生成多样化的特效。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前视频生成模型在生成多样化和空间可控的复合特效方面的局限性。

Method: 提出了基于LoRA的专家混合模型（LoRA-MoE）以及空间感知提示（SAP）并结合独立信息流模块（IIF），并构建了专用的VFX数据集和评估框架。

Result: Omni-Effects实现了特效的多样化生成和空间精确控制，用户能够指定特效的种类和位置。

Conclusion: 此框架在高效生成多样特效方面具有显著优势，为特效生成领域开辟了新方向。

Abstract: Visual effects (VFX) are essential visual enhancements fundamental to modern
cinematic production. Although video generation models offer cost-efficient
solutions for VFX production, current methods are constrained by per-effect
LoRA training, which limits generation to single effects. This fundamental
limitation impedes applications that require spatially controllable composite
effects, i.e., the concurrent generation of multiple effects at designated
locations. However, integrating diverse effects into a unified framework faces
major challenges: interference from effect variations and spatial
uncontrollability during multi-VFX joint training. To tackle these challenges,
we propose Omni-Effects, a first unified framework capable of generating
prompt-guided effects and spatially controllable composite effects. The core of
our framework comprises two key innovations: (1) LoRA-based Mixture of Experts
(LoRA-MoE), which employs a group of expert LoRAs, integrating diverse effects
within a unified model while effectively mitigating cross-task interference.
(2) Spatial-Aware Prompt (SAP) incorporates spatial mask information into the
text token, enabling precise spatial control. Furthermore, we introduce an
Independent-Information Flow (IIF) module integrated within the SAP, isolating
the control signals corresponding to individual effects to prevent any unwanted
blending. To facilitate this research, we construct a comprehensive VFX dataset
Omni-VFX via a novel data collection pipeline combining image editing and
First-Last Frame-to-Video (FLF2V) synthesis, and introduce a dedicated VFX
evaluation framework for validating model performance. Extensive experiments
demonstrate that Omni-Effects achieves precise spatial control and diverse
effect generation, enabling users to specify both the category and location of
desired effects.

</details>


### [184] [TAG: A Simple Yet Effective Temporal-Aware Approach for Zero-Shot Video Temporal Grounding](https://arxiv.org/abs/2508.07925)
*Jin-Seop Lee,SungJoon Lee,Jaehan Ahn,YunSeok Choi,Jee-Hyong Lee*

Main category: cs.CV

TL;DR: 提出了一种名为TAG的无监督视频时序定位方法，整合了时间池化、时间一致性聚类和相似性调整技术并取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有零样本VTG方法存在语义碎片化和依赖LLMs的问题，难以精确定位文本对齐的视频片段。

Method: 引入时间池化、时间一致性聚类和相似性调整技术，通过捕捉视频的时间上下文来实现更好的无训练定位。

Result: 在Charades-STA和ActivityNet Captions基准数据集上取得了SOTA性能，并且不依赖LLMs。

Conclusion: TAG是一种高效且实用的无监督方法，能够解决传统方法中的语义碎片化及分布歪曲问题，在无需LLMs的情况下提高了视频时序定位的精确性。

Abstract: Video Temporal Grounding (VTG) aims to extract relevant video segments based
on a given natural language query. Recently, zero-shot VTG methods have gained
attention by leveraging pretrained vision-language models (VLMs) to localize
target moments without additional training. However, existing approaches suffer
from semantic fragmentation, where temporally continuous frames sharing the
same semantics are split across multiple segments. When segments are
fragmented, it becomes difficult to predict an accurate target moment that
aligns with the text query. Also, they rely on skewed similarity distributions
for localization, making it difficult to select the optimal segment.
Furthermore, they heavily depend on the use of LLMs which require expensive
inferences. To address these limitations, we propose a \textit{TAG}, a simple
yet effective Temporal-Aware approach for zero-shot video temporal Grounding,
which incorporates temporal pooling, temporal coherence clustering, and
similarity adjustment. Our proposed method effectively captures the temporal
context of videos and addresses distorted similarity distributions without
training. Our approach achieves state-of-the-art results on Charades-STA and
ActivityNet Captions benchmark datasets without rely on LLMs. Our code is
available at https://github.com/Nuetee/TAG

</details>


### [185] [VOIDFace: A Privacy-Preserving Multi-Network Face Recognition With Enhanced Security](https://arxiv.org/abs/2508.07960)
*Ajnas Muhammed,Iurri Medvedev,Nuno Gonçalves*

Main category: cs.CV

TL;DR: 本文提出VOIDFace框架，通过视觉秘密共享消除数据复制需求和提高数据控制，并采用基于补丁的多训练网络开发隐私保护的面部识别系统，同时支持用户控制个人数据权利。


<details>
  <summary>Details</summary>
Motivation: 现有面部识别系统因训练需要导致数据复制，导致数据库管理复杂，同时用户对数据使用失去控制，引发隐私与伦理问题。

Method: VOIDFace框架通过视觉秘密共享技术消除了数据复制需求，提高了数据控制；引入了基于补丁的多训练网络来使用这一新型训练数据存储机制，构建隐私保护的面部识别系统。

Result: 在VGGFace2数据集上的实验表明，VOIDFace在提供遗忘权、改进数据控制、安全性和隐私方面表现出色，同时保持了竞争性的面部识别性能。

Conclusion: VOIDFace框架显著提升了面部识别系统的隐私性、安全性及效率，确保用户对敏感个人数据具有更大的控制权，并实现了用户的遗忘权属性。

Abstract: Advancement of machine learning techniques, combined with the availability of
large-scale datasets, has significantly improved the accuracy and efficiency of
facial recognition. Modern facial recognition systems are trained using large
face datasets collected from diverse individuals or public repositories.
However, for training, these datasets are often replicated and stored in
multiple workstations, resulting in data replication, which complicates
database management and oversight. Currently, once a user submits their face
for dataset preparation, they lose control over how their data is used, raising
significant privacy and ethical concerns. This paper introduces VOIDFace, a
novel framework for facial recognition systems that addresses two major issues.
First, it eliminates the need of data replication and improves data control to
securely store training face data by using visual secret sharing. Second, it
proposes a patch-based multi-training network that uses this novel training
data storage mechanism to develop a robust, privacy-preserving facial
recognition system. By integrating these advancements, VOIDFace aims to improve
the privacy, security, and efficiency of facial recognition training, while
ensuring greater control over sensitive personal face data. VOIDFace also
enables users to exercise their Right-To-Be-Forgotten property to control their
personal data. Experimental evaluations on the VGGFace2 dataset show that
VOIDFace provides Right-To-Be-Forgotten, improved data control, security, and
privacy while maintaining competitive facial recognition performance. Code is
available at: https://github.com/ajnasmuhammed89/VOIDFace

</details>


### [186] [MDD-Net: Multimodal Depression Detection through Mutual Transformer](https://arxiv.org/abs/2508.08093)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Hamdi Altaheri,Lobna Nassar,Fakhri Karray*

Main category: cs.CV

TL;DR: 本文提出一种多模态抑郁检测网络（MDD-Net），利用社交媒体中的声学和视觉数据，通过互相转换器融合提取多模态特征，并在实验中表现出优于现有技术的结果。


<details>
  <summary>Details</summary>
Motivation: 抑郁症严重影响个人的身心健康，社交媒体数据的简单获取性为心理健康研究提供了新的可能性。

Method: 提出了一个新的网络架构MDD-Net，包含声学特征提取模块、视觉特征提取模块、互相转换器和检测层，用于多模态特征的融合与抑郁检测。

Result: 实验表明，所提出系统在F1-Score表现上较现有技术提升高达17.37%。

Conclusion: MDD-Net通过有效整合多模态数据，在抑郁检测任务中显示出更优的性能，展示了利用社交媒体数据研究心理健康的潜力。

Abstract: Depression is a major mental health condition that severely impacts the
emotional and physical well-being of individuals. The simple nature of data
collection from social media platforms has attracted significant interest in
properly utilizing this information for mental health research. A Multimodal
Depression Detection Network (MDD-Net), utilizing acoustic and visual data
obtained from social media networks, is proposed in this work where mutual
transformers are exploited to efficiently extract and fuse multimodal features
for efficient depression detection. The MDD-Net consists of four core modules:
an acoustic feature extraction module for retrieving relevant acoustic
attributes, a visual feature extraction module for extracting significant
high-level patterns, a mutual transformer for computing the correlations among
the generated features and fusing these features from multiple modalities, and
a detection layer for detecting depression using the fused feature
representations. The extensive experiments are performed using the multimodal
D-Vlog dataset, and the findings reveal that the developed multimodal
depression detection network surpasses the state-of-the-art by up to 17.37% for
F1-Score, demonstrating the greater performance of the proposed system. The
source code is accessible at
https://github.com/rezwanh001/Multimodal-Depression-Detection.

</details>


### [187] [TrackOR: Towards Personalized Intelligent Operating Rooms Through Robust Tracking](https://arxiv.org/abs/2508.07968)
*Tony Danjun Wang,Christian Heiliger,Nassir Navab,Lennart Bastian*

Main category: cs.CV

TL;DR: 本文提出了TrackOR框架，利用3D几何特征实现长时间多人员跟踪及身份重识别，为手术室智能支持提供新方法。


<details>
  <summary>Details</summary>
Motivation: 为外科团队提供智能支持以改善患者结果，但实现长时间一致的人员跟踪仍面临挑战。

Method: 通过3D几何签名实现在线跟踪性能提升，并设计离线恢复流程生成可用轨迹数据。

Result: TrackOR相较最优基线方法在线关联准确率提高11%，支持生成分析所需的人员轨迹。

Conclusion: 利用3D几何信息使持续身份跟踪成为可能，为手术室的个性化智能系统铺平道路。

Abstract: Providing intelligent support to surgical teams is a key frontier in
automated surgical scene understanding, with the long-term goal of improving
patient outcomes. Developing personalized intelligence for all staff members
requires maintaining a consistent state of who is located where for long
surgical procedures, which still poses numerous computational challenges. We
propose TrackOR, a framework for tackling long-term multi-person tracking and
re-identification in the operating room. TrackOR uses 3D geometric signatures
to achieve state-of-the-art online tracking performance (+11% Association
Accuracy over the strongest baseline), while also enabling an effective offline
recovery process to create analysis-ready trajectories. Our work shows that by
leveraging 3D geometric information, persistent identity tracking becomes
attainable, enabling a critical shift towards the more granular, staff-centric
analyses required for personalized intelligent systems in the operating room.
This new capability opens up various applications, including our proposed
temporal pathway imprints that translate raw tracking data into actionable
insights for improving team efficiency and safety and ultimately providing
personalized support.

</details>


### [188] [The Escalator Problem: Identifying Implicit Motion Blindness in AI for Accessibility](https://arxiv.org/abs/2508.07989)
*Xiantao Zhang*

Main category: cs.CV

TL;DR: 论文探讨了现有多模态大语言模型（MLLMs）对实时动态任务感知能力的不足，特别提出其在识别自动扶梯运行方向上的局限性，称之为隐性运动盲点问题。


<details>
  <summary>Details</summary>
Motivation: 发现大语言模型在动态场景中的感知能力存在关键缺陷，特别是对自动扶梯等低信号、连续运动的理解不足，可能对盲人和视觉障碍用户的信任度产生负面影响。

Method: 文章未提出新模型，而是对这一问题的存在和影响进行了正式陈述，通过分析不足来引导社区重新思考视频理解范式。

Result: 论文定性分析表明，现有模型框架在动态场景中难以感知连续运动，呼吁开发更关注用户真实需求并具有安全性和可靠性的基准。

Conclusion: 倡导从单纯语义识别转向更加注重物理感知的范式转变，建议构建更以用户为中心的基准和方法，以提升动态环境下模型的可靠性和用户信任度。

Abstract: Multimodal Large Language Models (MLLMs) hold immense promise as assistive
technologies for the blind and visually impaired (BVI) community. However, we
identify a critical failure mode that undermines their trustworthiness in
real-world applications. We introduce the Escalator Problem -- the inability of
state-of-the-art models to perceive an escalator's direction of travel -- as a
canonical example of a deeper limitation we term Implicit Motion Blindness.
This blindness stems from the dominant frame-sampling paradigm in video
understanding, which, by treating videos as discrete sequences of static
images, fundamentally struggles to perceive continuous, low-signal motion. As a
position paper, our contribution is not a new model but rather to: (I) formally
articulate this blind spot, (II) analyze its implications for user trust, and
(III) issue a call to action. We advocate for a paradigm shift from purely
semantic recognition towards robust physical perception and urge the
development of new, human-centered benchmarks that prioritize safety,
reliability, and the genuine needs of users in dynamic environments.

</details>


### [189] [Integrating Task-Specific and Universal Adapters for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2508.08165)
*Yan Wang,Da-Wei Zhou,Han-Jia Ye*

Main category: cs.CV

TL;DR: 提出了一种名为TUNA的方法，通过结合任务特定和通用适配器，提高了增量学习的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法中的任务特定模块忽视了共享的通用知识，导致任务间相似类的区分误差，且推理时错误选择模块会影响性能。

Method: 设计了TUNA方法，包括训练任务特定适配器捕获对应任务关键特征，引入基于熵的选择机制，设计适配器融合策略构建通用适配器，并结合两者的预测进行推理。

Result: 在多个基准数据集上的实验表明，该方法取得了最先进的性能。

Conclusion: TUNA方法充分利用了任务特定和通用知识，有效解决了增量学习中的关键问题。

Abstract: Class-Incremental Learning (CIL) requires a learning system to continually
learn new classes without forgetting. Existing pre-trained model-based CIL
methods often freeze the pre-trained network and adapt to incremental tasks
using additional lightweight modules such as adapters. However, incorrect
module selection during inference hurts performance, and task-specific modules
often overlook shared general knowledge, leading to errors on distinguishing
between similar classes across tasks. To address the aforementioned challenges,
we propose integrating Task-Specific and Universal Adapters (TUNA) in this
paper. Specifically, we train task-specific adapters to capture the most
crucial features relevant to their respective tasks and introduce an
entropy-based selection mechanism to choose the most suitable adapter.
Furthermore, we leverage an adapter fusion strategy to construct a universal
adapter, which encodes the most discriminative features shared across tasks. We
combine task-specific and universal adapter predictions to harness both
specialized and general knowledge during inference. Extensive experiments on
various benchmark datasets demonstrate the state-of-the-art performance of our
approach. Code is available at: https://github.com/LAMDA-CL/ICCV2025-TUNA

</details>


### [190] [Prompt-Guided Relational Reasoning for Social Behavior Understanding with Vision Foundation Models](https://arxiv.org/abs/2508.07996)
*Thinesh Thiyakesan Ponbagavathi,Chengzheng Yang,Alina Roitberg*

Main category: cs.CV

TL;DR: 本文提出了一个名为ProGraD的方法，解决了现有视频中群体活动检测在利用视觉基础模型（VFMs）建模群体动态方面的不足，并在两个基准数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有群体活动检测的方法依赖于高任务特异性的架构，并且简单地将视觉基础模型（VFMs）融入这些方法并不能带来显著性能提升，亟需设计新的方法来进行结构化、群体感知的推理。

Method: 提出了一种名为ProGraD的方法。其核心包括两个部分：1) 通过可学习的群体提示引导VFMs的注意力聚焦在社会配置上；2) 提出轻量级的两层GroupContext Transformer，用于推断演员-群体关联及其集体行为。

Result: 在Cafe和Social-CAD这两个基准测试上，ProGraD取得了新的最优结果，特别是在复杂的多群体场景中，分别实现了6.5%（Group mAP@1.0）和8.2%（Group mAP@0.5）的提升，同时仅使用了1000万可训练参数。此外还生成了可解释的注意力图。

Conclusion: ProGraD方法显著提升了群体活动检测的性能，并使得对演员-群体推理更具解释性，展现了VFMs在该领域的潜力。

Abstract: Group Activity Detection (GAD) involves recognizing social groups and their
collective behaviors in videos. Vision Foundation Models (VFMs), like DinoV2,
offer excellent features, but are pretrained primarily on object-centric data
and remain underexplored for modeling group dynamics. While they are a
promising alternative to highly task-specific GAD architectures that require
full fine-tuning, our initial investigation reveals that simply swapping CNN
backbones used in these methods with VFMs brings little gain, underscoring the
need for structured, group-aware reasoning on top.
  We introduce Prompt-driven Group Activity Detection (ProGraD) -- a method
that bridges this gap through 1) learnable group prompts to guide the VFM
attention toward social configurations, and 2) a lightweight two-layer
GroupContext Transformer that infers actor-group associations and collective
behavior. We evaluate our approach on two recent GAD benchmarks: Cafe, which
features multiple concurrent social groups, and Social-CAD, which focuses on
single-group interactions. While we surpass state-of-the-art in both settings,
our method is especially effective in complex multi-group scenarios, where we
yield a gain of 6.5\% (Group mAP\@1.0) and 8.2\% (Group mAP\@0.5) using only
10M trainable parameters. Furthermore, our experiments reveal that ProGraD
produces interpretable attention maps, offering insights into actor-group
reasoning. Code and models will be released.

</details>


### [191] [Sample-aware RandAugment: Search-free Automatic Data Augmentation for Effective Image Recognition](https://arxiv.org/abs/2508.08004)
*Anqi Xiao,Weichen Yu,Hongyuan Yu*

Main category: cs.CV

TL;DR: 引入了一种无需搜索的自动数据增强方法SRA，可动态调整增强策略，大幅提升性能，简化应用。


<details>
  <summary>Details</summary>
Motivation: 主流的自动数据增强方法因搜索耗时或策略适配不足使性能受限。

Method: 通过动态评估训练数据复杂度，生成样本定制增强策略，并采用不对称增强策略优化。

Result: 在ImageNet上以ResNet-50实现了78.31%的最优Top-1准确率，并证明了其在其他任务上的兼容性与泛化能力。

Conclusion: SRA是一种不需要超参数调整的简单高效的自动数据增强方法，适用于多种未来任务，可显著提升性能。

Abstract: Automatic data augmentation (AutoDA) plays an important role in enhancing the
generalization of neural networks. However, mainstream AutoDA methods often
encounter two challenges: either the search process is excessively
time-consuming, hindering practical application, or the performance is
suboptimal due to insufficient policy adaptation during training. To address
these issues, we propose Sample-aware RandAugment (SRA), an asymmetric,
search-free AutoDA method that dynamically adjusts augmentation policies while
maintaining straightforward implementation. SRA incorporates a heuristic
scoring module that evaluates the complexity of the original training data,
enabling the application of tailored augmentations for each sample.
Additionally, an asymmetric augmentation strategy is employed to maximize the
potential of this scoring module. In multiple experimental settings, SRA
narrows the performance gap between search-based and search-free AutoDA
methods, achieving a state-of-the-art Top-1 accuracy of 78.31\% on ImageNet
with ResNet-50. Notably, SRA demonstrates good compatibility with existing
augmentation pipelines and solid generalization across new tasks, without
requiring hyperparameter tuning. The pretrained models leveraging SRA also
enhance recognition in downstream object detection tasks. SRA represents a
promising step towards simpler, more effective, and practical AutoDA designs
applicable to a variety of future tasks. Our code is available at
\href{https://github.com/ainieli/Sample-awareRandAugment}{https://github.com/ainieli/Sample-awareRandAugment

</details>


### [192] [Mitigating Biases in Surgical Operating Rooms with Geometry](https://arxiv.org/abs/2508.08028)
*Tony Danjun Wang,Tobias Czempiel,Nassir Navab,Lennart Bastian*

Main category: cs.CV

TL;DR: 本文讨论了深度神经网络在手术室环境下因伪相关而产生的偏差问题，并提出通过3D点云序列编码避免这种偏差的方法。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在手术室任务中依赖数据集特定伪相关（如外观标准化）而非有意义特征，阻碍准确建模的需求。

Method: 通过将手术室人员编码为3D点云序列，分离身份相关的形状和动作模式，避免外观相关干扰，并使用梯度敏感性分析验证其偏差问题。

Result: 实验表明，RGB模型在低视觉多样性的临床环境下准确率下降12%，而几何表示捕获到更本质的生物特征。

Conclusion: 几何表示方法对建模手术室中的人体具有优势，能有效避免伪相关，提供更鲁棒的解决方案。

Abstract: Deep neural networks are prone to learning spurious correlations, exploiting
dataset-specific artifacts rather than meaningful features for prediction. In
surgical operating rooms (OR), these manifest through the standardization of
smocks and gowns that obscure robust identifying landmarks, introducing model
bias for tasks related to modeling OR personnel. Through gradient-based
saliency analysis on two public OR datasets, we reveal that CNN models succumb
to such shortcuts, fixating on incidental visual cues such as footwear beneath
surgical gowns, distinctive eyewear, or other role-specific identifiers.
Avoiding such biases is essential for the next generation of intelligent
assistance systems in the OR, which should accurately recognize personalized
workflow traits, such as surgical skill level or coordination with other staff
members. We address this problem by encoding personnel as 3D point cloud
sequences, disentangling identity-relevant shape and motion patterns from
appearance-based confounders. Our experiments demonstrate that while RGB and
geometric methods achieve comparable performance on datasets with apparent
simulation artifacts, RGB models suffer a 12% accuracy drop in realistic
clinical settings with decreased visual diversity due to standardizations. This
performance gap confirms that geometric representations capture more meaningful
biometric features, providing an avenue to developing robust methods of
modeling humans in the OR.

</details>


### [193] [TRIDE: A Text-assisted Radar-Image weather-aware fusion network for Depth Estimation](https://arxiv.org/abs/2508.08038)
*Huawei Sun,Zixu Wang,Hao Feng,Julius Ott,Lorenzo Servadei,Robert Wille*

Main category: cs.CV

TL;DR: 论文提出了一种新的雷达-相机融合算法TRIDE，结合了文本生成策略和天气感知融合模块，在深度估计任务中显著提升了准确性。


<details>
  <summary>Details</summary>
Motivation: 解决雷达与相机融合算法中忽视恶劣天气影响及未利用语言描述信息的问题。

Method: 提出了文本生成策略、特征提取与融合技术，并设计了天气感知融合模块以根据天气调整雷达的加权，同时结合雷达点信息增强文本特征提取。

Result: 在nuScenes数据集上的实验表明，论文方法相较于现有算法性能有显著提升，在MAE和RMSE上分别改进了12.87%和9.08%。

Conclusion: 将语言、雷达和相机有效融合用于深度估计，不仅提升了估测准确性，还考虑了传感器对天气的适应性，展现了实际应用潜力。

Abstract: Depth estimation, essential for autonomous driving, seeks to interpret the 3D
environment surrounding vehicles. The development of radar sensors, known for
their cost-efficiency and robustness, has spurred interest in radar-camera
fusion-based solutions. However, existing algorithms fuse features from these
modalities without accounting for weather conditions, despite radars being
known to be more robust than cameras under adverse weather. Additionally, while
Vision-Language models have seen rapid advancement, utilizing language
descriptions alongside other modalities for depth estimation remains an open
challenge. This paper first introduces a text-generation strategy along with
feature extraction and fusion techniques that can assist monocular depth
estimation pipelines, leading to improved accuracy across different algorithms
on the KITTI dataset. Building on this, we propose TRIDE, a radar-camera fusion
algorithm that enhances text feature extraction by incorporating radar point
information. To address the impact of weather on sensor performance, we
introduce a weather-aware fusion block that adaptively adjusts radar weighting
based on current weather conditions. Our method, benchmarked on the nuScenes
dataset, demonstrates performance gains over the state-of-the-art, achieving a
12.87% improvement in MAE and a 9.08% improvement in RMSE. Code:
https://github.com/harborsarah/TRIDE

</details>


### [194] [Hyperspectral Imaging](https://arxiv.org/abs/2508.08107)
*Danfeng Hong,Chenyu Li,Naoto Yokoya,Bing Zhang,Xiuping Jia,Antonio Plaza,Paolo Gamba,Jon Atli Benediktsson,Jocelyn Chanussot*

Main category: cs.CV

TL;DR: 本文概述了高光谱成像（HSI）的原理、系统架构、数据处理方法，并讨论其在多个领域的应用及未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 展示具体高光谱成像在物质分析和智能化决策中的潜力，解决硬件、数据复杂性和多模态融合等持续挑战。

Method: 基于物理原理详细解析HSI，从数据获取、校准到现代分析方法（如深度学习），并探讨最新解决方案（如计算成像、跨模态融合）。

Result: 高光谱成像展现出非侵入性检测微观特征的能力，促使其在地球观测、精准农业、生物医学及文物保护等领域的广泛应用。

Conclusion: HSI逐步发展为一种跨学科的通用平台，结合传感器小型化与自监督学习技术，未来能在科学与技术乃至社会中产生变革性影响。

Abstract: Hyperspectral imaging (HSI) is an advanced sensing modality that
simultaneously captures spatial and spectral information, enabling
non-invasive, label-free analysis of material, chemical, and biological
properties. This Primer presents a comprehensive overview of HSI, from the
underlying physical principles and sensor architectures to key steps in data
acquisition, calibration, and correction. We summarize common data structures
and highlight classical and modern analysis methods, including dimensionality
reduction, classification, spectral unmixing, and AI-driven techniques such as
deep learning. Representative applications across Earth observation, precision
agriculture, biomedicine, industrial inspection, cultural heritage, and
security are also discussed, emphasizing HSI's ability to uncover sub-visual
features for advanced monitoring, diagnostics, and decision-making. Persistent
challenges, such as hardware trade-offs, acquisition variability, and the
complexity of high-dimensional data, are examined alongside emerging solutions,
including computational imaging, physics-informed modeling, cross-modal fusion,
and self-supervised learning. Best practices for dataset sharing,
reproducibility, and metadata documentation are further highlighted to support
transparency and reuse. Looking ahead, we explore future directions toward
scalable, real-time, and embedded HSI systems, driven by sensor
miniaturization, self-supervised learning, and foundation models. As HSI
evolves into a general-purpose, cross-disciplinary platform, it holds promise
for transformative applications in science, technology, and society.

</details>


### [195] [S^2VG: 3D Stereoscopic and Spatial Video Generation via Denoising Frame Matrix](https://arxiv.org/abs/2508.08048)
*Peng Dai,Feitong Tan,Qiangeng Xu,Yihua Huang,David Futschik,Ruofei Du,Sean Fanello,Yinda Zhang,Xiaojuan Qi*

Main category: cs.CV

TL;DR: 提出了一种无需姿态估计和额外训练的3D视频生成方法，基于单目视频生成模型，通过深度信息预估和创新的帧矩阵修补框架实现。


<details>
  <summary>Details</summary>
Motivation: 当前的视频生成模型主要用于高质量的单目视频生成，而在3D立体及空间视频生成领域需求巨大，相关研究仍较少。

Method: 利用单目视频生成模型生成的内容，通过深度信息估计进行视角变换，并使用帧矩阵修补框架填补不同视角与时间戳间的缺失内容，无需对模型进行进一步训练。此外，通过双重更新方案减缓遮挡区域传播的负面影响，最终生成多视角视频并衍生为立体对或4D高斯表示。

Result: 在多个生成模型（如Sora、Lumiere、WALT和Zeroscope）生成的视频上验证了方法的有效性，实验表明该方法显著优于以往方法。

Conclusion: 该研究提出了一种新的方法，有效利用单目视频生成模型在无需训练的情况下生成了一致且高质量的3D立体和空间视频，为相关领域提供了新的技术解决方案。

Abstract: While video generation models excel at producing high-quality monocular
videos, generating 3D stereoscopic and spatial videos for immersive
applications remains an underexplored challenge. We present a pose-free and
training-free method that leverages an off-the-shelf monocular video generation
model to produce immersive 3D videos. Our approach first warps the generated
monocular video into pre-defined camera viewpoints using estimated depth
information, then applies a novel \textit{frame matrix} inpainting framework.
This framework utilizes the original video generation model to synthesize
missing content across different viewpoints and timestamps, ensuring spatial
and temporal consistency without requiring additional model fine-tuning.
Moreover, we develop a \dualupdate~scheme that further improves the quality of
video inpainting by alleviating the negative effects propagated from
disoccluded areas in the latent space. The resulting multi-view videos are then
adapted into stereoscopic pairs or optimized into 4D Gaussians for spatial
video synthesis. We validate the efficacy of our proposed method by conducting
experiments on videos from various generative models, such as Sora, Lumiere,
WALT, and Zeroscope. The experiments demonstrate that our method has a
significant improvement over previous methods. Project page at:
https://daipengwa.github.io/S-2VG_ProjectPage/

</details>


### [196] [GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking](https://arxiv.org/abs/2508.08117)
*Xudong Han,Pengcheng Fang,Yueying Tian,Jianhui Yu,Xiaohao Cai,Daniel Roggen,Philip Birch*

Main category: cs.CV

TL;DR: GRASPTrack通过将单目深度估计与实例分割结合，并生成3D点云以进行显式几何推理，从而在复杂场景中显著提升了单目视频中的多目标跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于检测的多目标跟踪方法因为缺乏几何意识，难以解决遮挡与深度模糊的问题，导致单目视频多目标跟踪挑战较大。

Method: 提出GRASPTrack框架，将单目深度估计和实例分割整合到标准的基于检测管线上，生成3D点云，并通过利用体素化基于IoU的空间关联和深度适应性噪声补偿等方法，提升跟踪性能。

Result: 在MOT17、MOT20和DanceTrack基准测试上进行的广泛实验表明，该方法在复杂场景中具有鲁棒的跟踪性能，尤其是应对遮挡频繁和复杂运动模式的场景。

Conclusion: GRASPTrack框架通过深度感知和几何推理有效缓解了单目多目标跟踪中的传统挑战，显著提升了系统的跟踪鲁棒性和精确性。

Abstract: Multi-object tracking (MOT) in monocular videos is fundamentally challenged
by occlusions and depth ambiguity, issues that conventional
tracking-by-detection (TBD) methods struggle to resolve owing to a lack of
geometric awareness. To address these limitations, we introduce GRASPTrack, a
novel depth-aware MOT framework that integrates monocular depth estimation and
instance segmentation into a standard TBD pipeline to generate high-fidelity 3D
point clouds from 2D detections, thereby enabling explicit 3D geometric
reasoning. These 3D point clouds are then voxelized to enable a precise and
robust Voxel-Based 3D Intersection-over-Union (IoU) for spatial association. To
further enhance tracking robustness, our approach incorporates Depth-aware
Adaptive Noise Compensation, which dynamically adjusts the Kalman filter
process noise based on occlusion severity for more reliable state estimation.
Additionally, we propose a Depth-enhanced Observation-Centric Momentum, which
extends the motion direction consistency from the image plane into 3D space to
improve motion-based association cues, particularly for objects with complex
trajectories. Extensive experiments on the MOT17, MOT20, and DanceTrack
benchmarks demonstrate that our method achieves competitive performance,
significantly improving tracking robustness in complex scenes with frequent
occlusions and intricate motion patterns.

</details>


### [197] [Information Bottleneck-based Causal Attention for Multi-label Medical Image Recognition](https://arxiv.org/abs/2508.08069)
*Xiaoxiao Cui,Yiran Li,Kai He,Shanzhi Jiang,Mengli Xue,Wentao Li,Junhong Leng,Zhi Liu,Lizhen Cui,Shuo Li*

Main category: cs.CV

TL;DR: 本文提出了一种基于信息瓶颈的因果注意（IBCA）方法，用于多标签医疗图像分类，有效解决了以往方法未能准确解释疾病因果特征的问题，取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 多标签医疗图像分类需要精确识别多种疾病，但当前方法在学得特定于类别的因果特征时存在关注非相关信息的问题，影响诊断准确性和可解释性。

Method: 提出一种新的结构因果模型（SCM）和基于信息瓶颈的因果注意（IBCA）方法，通过学习高斯混合多标签空间注意力过滤掉无关信息，并通过对比增强的因果干预逐步降低伪注意力及噪声信息。

Result: 通过在Endo和MuReD数据集上的定量和消融实验，IBCA方法优于所有对比方法。在MuReD数据集上，各指标分别提升了6.35%、7.72%和5.02%，在Endo数据集上分别提升了1.47%、1.65%和1.42%。

Conclusion: IBCA方法通过学得特定于类别的因果注意，提高了多标签医疗图像分类的准确性和解释性，展现了在医学图像分析领域中的广阔潜力。

Abstract: Multi-label classification (MLC) of medical images aims to identify multiple
diseases and holds significant clinical potential. A critical step is to learn
class-specific features for accurate diagnosis and improved interpretability
effectively. However, current works focus primarily on causal attention to
learn class-specific features, yet they struggle to interpret the true cause
due to the inadvertent attention to class-irrelevant features. To address this
challenge, we propose a new structural causal model (SCM) that treats
class-specific attention as a mixture of causal, spurious, and noisy factors,
and a novel Information Bottleneck-based Causal Attention (IBCA) that is
capable of learning the discriminative class-specific attention for MLC of
medical images. Specifically, we propose learning Gaussian mixture multi-label
spatial attention to filter out class-irrelevant information and capture each
class-specific attention pattern. Then a contrastive enhancement-based causal
intervention is proposed to gradually mitigate the spurious attention and
reduce noise information by aligning multi-head attention with the Gaussian
mixture multi-label spatial. Quantitative and ablation results on Endo and
MuReD show that IBCA outperforms all methods. Compared to the second-best
results for each metric, IBCA achieves improvements of 6.35\% in CR, 7.72\% in
OR, and 5.02\% in mAP for MuReD, 1.47\% in CR, and 1.65\% in CF1, and 1.42\% in
mAP for Endo.

</details>


### [198] [ME-TST+: Micro-expression Analysis via Temporal State Transition with ROI Relationship Awareness](https://arxiv.org/abs/2508.08082)
*Zizheng Guo,Bochao Zou,Junbao Zhuo,Huimin Ma*

Main category: cs.CV

TL;DR: 本文提出了两种基于状态空间模型的架构ME-TST和ME-TST+，结合时间状态转移机制与基于协同的微表情分析策略，在消除传统方法不足的同时实现了先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法中固定滑动窗口长度和硬分类方式存在局限，并未充分挖掘微表情探测与识别间的关系。

Method: 提出基于状态空间模型的ME-TST和ME-TST+架构，通过时间状态转移机制进行视频级回归，使用多粒度ROI建模和慢快Mamba框架，并设计协同策略提高分析性能。

Result: 实验表明，所提方法在微表情分析任务上达到了最新的业界性能标准。

Conclusion: ME-TST和ME-TST+能更精确刻画微表情时间动态并解决当前微表情分析任务中的信息损失问题，为领域内开创性研究方向。

Abstract: Micro-expressions (MEs) are regarded as important indicators of an
individual's intrinsic emotions, preferences, and tendencies. ME analysis
requires spotting of ME intervals within long video sequences and recognition
of their corresponding emotional categories. Previous deep learning approaches
commonly employ sliding-window classification networks. However, the use of
fixed window lengths and hard classification presents notable limitations in
practice. Furthermore, these methods typically treat ME spotting and
recognition as two separate tasks, overlooking the essential relationship
between them. To address these challenges, this paper proposes two state space
model-based architectures, namely ME-TST and ME-TST+, which utilize temporal
state transition mechanisms to replace conventional window-level classification
with video-level regression. This enables a more precise characterization of
the temporal dynamics of MEs and supports the modeling of MEs with varying
durations. In ME-TST+, we further introduce multi-granularity ROI modeling and
the slowfast Mamba framework to alleviate information loss associated with
treating ME analysis as a time-series task. Additionally, we propose a synergy
strategy for spotting and recognition at both the feature and result levels,
leveraging their intrinsic connection to enhance overall analysis performance.
Extensive experiments demonstrate that the proposed methods achieve
state-of-the-art performance. The codes are available at
https://github.com/zizheng-guo/ME-TST.

</details>


### [199] [Matrix-3D: Omnidirectional Explorable 3D World Generation](https://arxiv.org/abs/2508.08086)
*Zhongqi Yang,Wenhang Ge,Yuqi Li,Jiaqi Chen,Haoyuan Li,Mengyin An,Fei Kang,Hua Xue,Baixin Xu,Yuyang Yin,Eric Li,Yang Liu,Yikai Wang,Hao-Xiang Guo,Yahui Zhou*

Main category: cs.CV

TL;DR: 研究提出Matrix-3D框架，通过全景表示实现广覆盖可探索的3D世界生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成的3D场景范围有限，无法满足更广泛覆盖和通用3D世界生成的需求。

Method: 通过全景视频扩散模型生成全景场景视频，并利用两种方法将其提升为3D世界：快速重建和基于优化的详细重建。此外，引入Matrix-Pano数据集以提升训练效果。

Result: 实验表明，提出的框架在全景视频生成和3D世界生成方面达到了领先水平。

Conclusion: Matrix-3D框架为可探索的3D世界生成树立了新的基准，并在全景视频和3D生成领域呈现了优越的性能。

Abstract: Explorable 3D world generation from a single image or text prompt forms a
cornerstone of spatial intelligence. Recent works utilize video model to
achieve wide-scope and generalizable 3D world generation. However, existing
approaches often suffer from a limited scope in the generated scenes. In this
work, we propose Matrix-3D, a framework that utilize panoramic representation
for wide-coverage omnidirectional explorable 3D world generation that combines
conditional video generation and panoramic 3D reconstruction. We first train a
trajectory-guided panoramic video diffusion model that employs scene mesh
renders as condition, to enable high-quality and geometrically consistent scene
video generation. To lift the panorama scene video to 3D world, we propose two
separate methods: (1) a feed-forward large panorama reconstruction model for
rapid 3D scene reconstruction and (2) an optimization-based pipeline for
accurate and detailed 3D scene reconstruction. To facilitate effective
training, we also introduce the Matrix-Pano dataset, the first large-scale
synthetic collection comprising 116K high-quality static panoramic video
sequences with depth and trajectory annotations. Extensive experiments
demonstrate that our proposed framework achieves state-of-the-art performance
in panoramic video generation and 3D world generation. See more in
https://matrix-3d.github.io.

</details>


### [200] [3D Plant Root Skeleton Detection and Extraction](https://arxiv.org/abs/2508.08094)
*Jiakai Lin,Jinchang Zhang,Ge Jin,Wenzhan Song,Tianming Liu,Guoyu Lu*

Main category: cs.CV

TL;DR: 研究提出了一种3D根系骨架提取方法，用于从少量图像中高效识别植物根系的3D架构，特别是复杂根系结构的建模和分析。


<details>
  <summary>Details</summary>
Motivation: 传统研究大多局限于2D层面，但植物根系生长在真实的三维空间中，了解根系的3D架构对于研究遗传性状及其对根系发育的影响至关重要。提出新方法的目的是突破现有可视化方法的局限，提高根系三维建模的精准性和有效性。

Method: 方法包括侧根检测与匹配、用于提取骨架结构的三角化过程，以及结合侧根与主根的整体集成。构建了复杂的根系数据集并对方法进行验证分析。

Result: 测试表明提取的3D根系骨架与真实情况高度相似，证明了方法的有效性。

Conclusion: 研究成果对自动化育种机器人具有重要意义，通过精准的3D根系分析可帮助机器人高效辨别植株性状，从而促进现代农业的智能化和效率提升。

Abstract: Plant roots typically exhibit a highly complex and dense architecture,
incorporating numerous slender lateral roots and branches, which significantly
hinders the precise capture and modeling of the entire root system.
Additionally, roots often lack sufficient texture and color information, making
it difficult to identify and track root traits using visual methods. Previous
research on roots has been largely confined to 2D studies; however, exploring
the 3D architecture of roots is crucial in botany. Since roots grow in real 3D
space, 3D phenotypic information is more critical for studying genetic traits
and their impact on root development. We have introduced a 3D root skeleton
extraction method that efficiently derives the 3D architecture of plant roots
from a few images. This method includes the detection and matching of lateral
roots, triangulation to extract the skeletal structure of lateral roots, and
the integration of lateral and primary roots. We developed a highly complex
root dataset and tested our method on it. The extracted 3D root skeletons
showed considerable similarity to the ground truth, validating the
effectiveness of the model. This method can play a significant role in
automated breeding robots. Through precise 3D root structure analysis, breeding
robots can better identify plant phenotypic traits, especially root structure
and growth patterns, helping practitioners select seeds with superior root
systems. This automated approach not only improves breeding efficiency but also
reduces manual intervention, making the breeding process more intelligent and
efficient, thus advancing modern agriculture.

</details>


### [201] [TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning](https://arxiv.org/abs/2508.08098)
*Junzhe Xu,Yuyang Yin,Xi Chen*

Main category: cs.CV

TL;DR: 本文提出TBAC-UniImage，一种多模态理解与生成的统一模型，通过将预训练扩散模型与多模态大语言模型深度整合，从多个层次提供生成条件，解决了此前方法中的连接浅层化和训练成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么只利用MLLM最终状态导致连接浅显，要么需要从头预训练导致计算成本过高，需要一种更高效且深入整合的生成方法。

Method: 通过将扩散模型与MLLM多个中间层表示整合，而非仅依赖最终输出层，形成多层次细致指导生成的新范式。

Result: TBAC-UniImage实现了多模态理解与生成的更深层次、细致入微的统一。

Conclusion: 通过创新性的方法，TBAC-UniImage克服了现有方法的缺陷，为多模态生成领域提供了一种计算高效且表现优异的解决方案。

Abstract: This paper introduces TBAC-UniImage, a novel unified model for multimodal
understanding and generation. We achieve this by deeply integrating a
pre-trained Diffusion Model, acting as a generative ladder, with a Multimodal
Large Language Model (MLLM). Previous diffusion-based unified models face two
primary limitations. One approach uses only the MLLM's final hidden state as
the generative condition. This creates a shallow connection, as the generator
is isolated from the rich, hierarchical representations within the MLLM's
intermediate layers. The other approach, pretraining a unified generative
architecture from scratch, is computationally expensive and prohibitive for
many researchers. To overcome these issues, our work explores a new paradigm.
Instead of relying on a single output, we use representations from multiple,
diverse layers of the MLLM as generative conditions for the diffusion model.
This method treats the pre-trained generator as a ladder, receiving guidance
from various depths of the MLLM's understanding process. Consequently,
TBAC-UniImage achieves a much deeper and more fine-grained unification of
understanding and generation.

</details>


### [202] [MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision](https://arxiv.org/abs/2508.08177)
*Zhonghao Yan,Muxi Diao,Yuxuan Yang,Jiayuan Xu,Kaizhou Zhang,Ruoyan Jing,Lele Yang,Yanxi Liu,Kongming Liang,Zhanyu Ma*

Main category: cs.CV

TL;DR: 本文提出了一个新任务UMRG并发布了相关数据集U-MRG-14K，同时开发了新框架MedReasoner，通过强化学习优化医疗多模态模型以实现精确区域定位和临床推理。


<details>
  <summary>Details</summary>
Motivation: 当前医疗影像中的多模态语言模型仍需通过监督学习及显性空间提示来完成任务，难以有效应对临床中常见的隐性查询问题。

Method: 提出UMRG任务，并发布14K样本的U-MRG-14K数据集；同时引入MedReasoner框架，将临床推理与分割任务分离，通过MLLM与强化学习优化推理，并结合固定分割模块实现精确定位。

Result: MedReasoner在U-MRG-14K上表现优异，并在应对未知临床查询上具备良好的泛化能力。

Conclusion: 强化学习能够有效提升医疗领域内多模态推理与区域定位的解释性和性能。

Abstract: Accurately grounding regions of interest (ROIs) is critical for diagnosis and
treatment planning in medical imaging. While multimodal large language models
(MLLMs) combine visual perception with natural language, current
medical-grounding pipelines still rely on supervised fine-tuning with explicit
spatial hints, making them ill-equipped to handle the implicit queries common
in clinical practice. This work makes three core contributions. We first define
Unified Medical Reasoning Grounding (UMRG), a novel vision-language task that
demands clinical reasoning and pixel-level grounding. Second, we release
U-MRG-14K, a dataset of 14K samples featuring pixel-level masks alongside
implicit clinical queries and reasoning traces, spanning 10 modalities, 15
super-categories, and 108 specific categories. Finally, we introduce
MedReasoner, a modular framework that distinctly separates reasoning from
segmentation: an MLLM reasoner is optimized with reinforcement learning, while
a frozen segmentation expert converts spatial prompts into masks, with
alignment achieved through format and accuracy rewards. MedReasoner achieves
state-of-the-art performance on U-MRG-14K and demonstrates strong
generalization to unseen clinical queries, underscoring the significant promise
of reinforcement learning for interpretable medical grounding.

</details>


### [203] [Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control](https://arxiv.org/abs/2508.08134)
*Zeqian Long,Mingzhe Zheng,Kunyu Feng,Xinhua Zhang,Hongyu Liu,Harry Yang,Linfeng Zhang,Qifeng Chen,Yue Ma*

Main category: cs.CV

TL;DR: 本研究提出了一种名为Follow-Your-Shape的新框架，解决了现有图像编辑方法在大规模形状变换时的不足；该方法无需训练和掩码，能够精确控制对象形状并保留非目标区域。


<details>
  <summary>Details</summary>
Motivation: 现有流式图像编辑方法在处理大规模形状变换时表现不足，会导致编辑失败或破坏非目标区域背景质量；需要一种解决这一问题的方法。

Method: 提出Trajectory Divergence Map (TDM)，通过比较逆过程和生成路径中的速度差异来定位可编辑区域，并引入Scheduled KV Injection机制以实现稳定且高保真的编辑。

Result: 实验结果表明，该方法在大规模形状替换任务中展现了优越的编辑能力和视觉保真度。

Conclusion: 该方法能够在无需训练和掩码的条件下，实现精确可控的对象形状编辑，同时严格保留非目标内容，特别适用于大规模形状变换场景；并提供了新的评估基准ReShapeBench。

Abstract: While recent flow-based image editing models demonstrate general-purpose
capabilities across diverse tasks, they often struggle to specialize in
challenging scenarios -- particularly those involving large-scale shape
transformations. When performing such structural edits, these methods either
fail to achieve the intended shape change or inadvertently alter non-target
regions, resulting in degraded background quality. We propose
Follow-Your-Shape, a training-free and mask-free framework that supports
precise and controllable editing of object shapes while strictly preserving
non-target content. Motivated by the divergence between inversion and editing
trajectories, we compute a Trajectory Divergence Map (TDM) by comparing
token-wise velocity differences between the inversion and denoising paths. The
TDM enables precise localization of editable regions and guides a Scheduled KV
Injection mechanism that ensures stable and faithful editing. To facilitate a
rigorous evaluation, we introduce ReShapeBench, a new benchmark comprising 120
new images and enriched prompt pairs specifically curated for shape-aware
editing. Experiments demonstrate that our method achieves superior editability
and visual fidelity, particularly in tasks requiring large-scale shape
replacement.

</details>


### [204] [FantasyStyle: Controllable Stylized Distillation for 3D Gaussian Splatting](https://arxiv.org/abs/2508.08136)
*Yitong Yang,Yinglin Wang,Changshuo Wang,Huajie Wang,Shuting He*

Main category: cs.CV

TL;DR: 3DGS风格迁移虽取得进展，但存在多视图不一致和过度依赖VGG特征等问题，导致效果受限。提出FantasyStyle框架，基于扩散模型蒸馏，解决这些挑战并提升风格迁移表现。


<details>
  <summary>Details</summary>
Motivation: 当前3DGS风格迁移方法受多视图不一致和VGG特征局限性影响，难以实现高质量的风格迁移。

Method: 提出FantasyStyle，通过3D多视图频率一致性和可控风格化蒸馏两部分解决现有问题。使用3D过滤器减少多视图低频冲突，并引入负向引导以抑制风格图像的内容泄露问题。

Result: 实验显示方法超越现有技术，能在多场景和风格下实现更高质量的风格迁移和视觉真实感。

Conclusion: FantasyStyle通过控制风格化过程与提升一致性，克服了现有方法的不足，是一种高效的3DGS风格迁移框架。

Abstract: The success of 3DGS in generative and editing applications has sparked
growing interest in 3DGS-based style transfer. However, current methods still
face two major challenges: (1) multi-view inconsistency often leads to style
conflicts, resulting in appearance smoothing and distortion; and (2) heavy
reliance on VGG features, which struggle to disentangle style and content from
style images, often causing content leakage and excessive stylization. To
tackle these issues, we introduce \textbf{FantasyStyle}, a 3DGS-based style
transfer framework, and the first to rely entirely on diffusion model
distillation. It comprises two key components: (1) \textbf{Multi-View Frequency
Consistency}. We enhance cross-view consistency by applying a 3D filter to
multi-view noisy latent, selectively reducing low-frequency components to
mitigate stylized prior conflicts. (2) \textbf{Controllable Stylized
Distillation}. To suppress content leakage from style images, we introduce
negative guidance to exclude undesired content. In addition, we identify the
limitations of Score Distillation Sampling and Delta Denoising Score in 3D
style transfer and remove the reconstruction term accordingly. Building on
these insights, we propose a controllable stylized distillation that leverages
negative guidance to more effectively optimize the 3D Gaussians. Extensive
experiments demonstrate that our method consistently outperforms
state-of-the-art approaches, achieving higher stylization quality and visual
realism across various scenes and styles.

</details>


### [205] [Pindrop it! Audio and Visual Deepfake Countermeasures for Robust Detection and Fine Grained-Localization](https://arxiv.org/abs/2508.08141)
*Nicholas Klein,Hemlata Tak,James Fullwood,Krishna Regmi,Leonidas Spinoulas,Ganesh Sivaraman,Tianxiang Chen,Elie Khoury*

Main category: cs.CV

TL;DR: 本文提出了用于深度伪造视频分类和定位的解决方案，在 ACM 1M 深度伪造检测挑战中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着视觉和音频生成技术的飞速发展，检测视频中细微伪造内容的需求日益迫切，尤其是在针对局部操控的情况下。

Method: 研究中开发出了一种针对深度伪造视频分类和定位的算法，并提交到 ACM 1M 深度伪造检测挑战中进行评估。

Result: 方法在测试数据集的时间定位任务中取得最佳表现，并在分类任务中排到前四名。

Conclusion: 研究有效解决了深度伪造视频的检测问题，尤其在定位任务中展示了杰出的能力。

Abstract: The field of visual and audio generation is burgeoning with new
state-of-the-art methods. This rapid proliferation of new techniques
underscores the need for robust solutions for detecting synthetic content in
videos. In particular, when fine-grained alterations via localized
manipulations are performed in visual, audio, or both domains, these subtle
modifications add challenges to the detection algorithms. This paper presents
solutions for the problems of deepfake video classification and localization.
The methods were submitted to the ACM 1M Deepfakes Detection Challenge,
achieving the best performance in the temporal localization task and a top four
ranking in the classification task for the TestA split of the evaluation
dataset.

</details>


### [206] [OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution](https://arxiv.org/abs/2508.08227)
*Zhiqiang Wu,Zhaomang Sun,Tong Zhou,Bingtao Fu,Ji Cong,Yitong Dong,Huaqi Zhang,Xuan Tang,Mingsong Chen,Xian Wei*

Main category: cs.CV

TL;DR: 本文提出了一个名为One Mid-timestep Guidance Real-ISR (OMGSR)的新框架，用于通过在生成模型的中间时间步注入低质量图像潜在分布，以改进基于DDPM/FM模型的单步图像超分辨率任务。


<details>
  <summary>Details</summary>
Motivation: 现有基于DDPM/FM的单步真实世界图像超分辨率模型在初始时间步注入低质量图像的潜在分布，但因其与高斯噪声潜分布的差距限制了生成先验的有效利用。

Method: 本文通过观察潜分布关系，在DDPM/FM模型中引入了一个中间时间步的指导框架（OMGSR），结合潜分布优化损失和Overlap-Chunked LPIPS/GAN损失来改进生成质量。

Result: 实验表明，OMGSR在512分辨率下表现平衡或优异，特别是其变体OMGSR-F在参考指标上具有显著领先优势；此外，OMGSR-F还能扩展到1k分辨率甚至生成2k分辨率图像，生成细节卓越。

Conclusion: OMGSR框架为单步真实世界图像超分辨率任务提供了高效且普适的解决方案，显著提高了生成图像的质量和细节表现。

Abstract: Denoising Diffusion Probabilistic Models (DDPM) and Flow Matching (FM)
generative models show promising potential for one-step Real-World Image
Super-Resolution (Real-ISR). Recent one-step Real-ISR models typically inject a
Low-Quality (LQ) image latent distribution at the initial timestep. However, a
fundamental gap exists between the LQ image latent distribution and the
Gaussian noisy latent distribution, limiting the effective utilization of
generative priors. We observe that the noisy latent distribution at DDPM/FM
mid-timesteps aligns more closely with the LQ image latent distribution. Based
on this insight, we present One Mid-timestep Guidance Real-ISR (OMGSR), a
universal framework applicable to DDPM/FM-based generative models. OMGSR
injects the LQ image latent distribution at a pre-computed mid-timestep,
incorporating the proposed Latent Distribution Refinement loss to alleviate the
latent distribution gap. We also design the Overlap-Chunked LPIPS/GAN loss to
eliminate checkerboard artifacts in image generation. Within this framework, we
instantiate OMGSR for DDPM/FM-based generative models with two variants:
OMGSR-S (SD-Turbo) and OMGSR-F (FLUX.1-dev). Experimental results demonstrate
that OMGSR-S/F achieves balanced/excellent performance across quantitative and
qualitative metrics at 512-resolution. Notably, OMGSR-F establishes
overwhelming dominance in all reference metrics. We further train a
1k-resolution OMGSR-F to match the default resolution of FLUX.1-dev, which
yields excellent results, especially in the details of the image generation. We
also generate 2k-resolution images by the 1k-resolution OMGSR-F using our
two-stage Tiled VAE & Diffusion.

</details>


### [207] [Cut2Next: Generating Next Shot via In-Context Tuning](https://arxiv.org/abs/2508.08244)
*Jingwen He,Hongbo Liu,Jiajun Li,Ziqi Huang,Yu Qiao,Wanli Ouyang,Ziwei Liu*

Main category: cs.CV

TL;DR: 提出了一个新框架Cut2Next，利用Diffusion Transformer生成符合专业编辑模式和电影连续性的下一镜头，并通过实验验证了其生成效果的优越性。


<details>
  <summary>Details</summary>
Motivation: 当前方法重视视觉一致性但忽略关键编辑模式和叙事连贯性，导致生成结果缺乏电影感和叙事复杂性。

Method: 引入Cut2Next框架，结合Diffusion Transformer和一种新颖的分层多提示策略，以生成符合电影叙事和视觉连贯性的下一镜头。同时开发了Context-Aware Condition Injection (CACI)和Hierarchical Attention Mask (HAM)技术来整合多种信号，并构建了两个数据集（RawCuts和CuratedCuts）和一个评估工具（CutBench）。

Result: 实验显示，Cut2Next在视觉一致性和文本契合度上表现优越，用户研究表明其在编辑模式和电影连续性上的表现显著优于现有方法。

Conclusion: Cut2Next框架有效地生成了叙事性强、电影感十足且连续性优良的高质量下一镜头，验证了其实用价值。

Abstract: Effective multi-shot generation demands purposeful, film-like transitions and
strict cinematic continuity. Current methods, however, often prioritize basic
visual consistency, neglecting crucial editing patterns (e.g., shot/reverse
shot, cutaways) that drive narrative flow for compelling storytelling. This
yields outputs that may be visually coherent but lack narrative sophistication
and true cinematic integrity. To bridge this, we introduce Next Shot Generation
(NSG): synthesizing a subsequent, high-quality shot that critically conforms to
professional editing patterns while upholding rigorous cinematic continuity.
Our framework, Cut2Next, leverages a Diffusion Transformer (DiT). It employs
in-context tuning guided by a novel Hierarchical Multi-Prompting strategy. This
strategy uses Relational Prompts to define overall context and inter-shot
editing styles. Individual Prompts then specify per-shot content and
cinematographic attributes. Together, these guide Cut2Next to generate
cinematically appropriate next shots. Architectural innovations, Context-Aware
Condition Injection (CACI) and Hierarchical Attention Mask (HAM), further
integrate these diverse signals without introducing new parameters. We
construct RawCuts (large-scale) and CuratedCuts (refined) datasets, both with
hierarchical prompts, and introduce CutBench for evaluation. Experiments show
Cut2Next excels in visual consistency and text fidelity. Crucially, user
studies reveal a strong preference for Cut2Next, particularly for its adherence
to intended editing patterns and overall cinematic continuity, validating its
ability to generate high-quality, narratively expressive, and cinematically
coherent subsequent shots.

</details>


### [208] [ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction](https://arxiv.org/abs/2508.08170)
*Chaojun Ni,Guosheng Zhao,Xiaofeng Wang,Zheng Zhu,Wenkang Qin,Xinze Chen,Guanghong Jia,Guan Huang,Wenjun Mei*

Main category: cs.CV

TL;DR: 本文提出了ReconDreamer-RL，通过引入视频扩散先验及多种生成技术，改进仿真环境，从而大幅提升了强化学习在端到端自动驾驶中的训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自主驾驶强化学习因视觉仿真与真实环境差异较大（sim2real），难以有效还原真实驾驶场景。

Method: 提出ReconDreamer-RL框架，包含通过视频扩散先验增强的ReconSimulator仿真器、动态对抗代理（DAA）生成极端交通场景、以及堂兄轨迹生成器（CTG）以校正训练数据分布。

Result: 实验结果显示，与模仿学习方法相比，系统将碰撞率降低5倍，显著优化训练效果。

Conclusion: ReconDreamer-RL能显著缩小仿真与现实差距，提高复杂驾驶情境下的强化学习与模型性能。

Abstract: Reinforcement learning for training end-to-end autonomous driving models in
closed-loop simulations is gaining growing attention. However, most simulation
environments differ significantly from real-world conditions, creating a
substantial simulation-to-reality (sim2real) gap. To bridge this gap, some
approaches utilize scene reconstruction techniques to create photorealistic
environments as a simulator. While this improves realistic sensor simulation,
these methods are inherently constrained by the distribution of the training
data, making it difficult to render high-quality sensor data for novel
trajectories or corner case scenarios. Therefore, we propose ReconDreamer-RL, a
framework designed to integrate video diffusion priors into scene
reconstruction to aid reinforcement learning, thereby enhancing end-to-end
autonomous driving training. Specifically, in ReconDreamer-RL, we introduce
ReconSimulator, which combines the video diffusion prior for appearance
modeling and incorporates a kinematic model for physical modeling, thereby
reconstructing driving scenarios from real-world data. This narrows the
sim2real gap for closed-loop evaluation and reinforcement learning. To cover
more corner-case scenarios, we introduce the Dynamic Adversary Agent (DAA),
which adjusts the trajectories of surrounding vehicles relative to the ego
vehicle, autonomously generating corner-case traffic scenarios (e.g., cut-in).
Finally, the Cousin Trajectory Generator (CTG) is proposed to address the issue
of training data distribution, which is often biased toward simple
straight-line movements. Experiments show that ReconDreamer-RL improves
end-to-end autonomous driving training, outperforming imitation learning
methods with a 5x reduction in the Collision Ratio.

</details>


### [209] [CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data](https://arxiv.org/abs/2508.08173)
*Chongke Bi,Xin Gao,Jiangkang Deng,Guan*

Main category: cs.CV

TL;DR: 本文提出CD-TVD，一种结合对比学习和改进扩散模型的框架，用于通过少量高分辨率时间步数据实现精准3D超分辨率。


<details>
  <summary>Details</summary>
Motivation: 传统超分辨方法需大量高分辨率训练数据，限制其在多样化模拟场景中的应用。本研究旨在减少对大规模高分辨率数据的依赖。

Method: CD-TVD框架结合对比学习和扩散超分辨模块，预训练阶段学习退化模式和细节特征，训练阶段通过改进扩散模型及局部注意机制进行细化。

Result: 实验结果表明，CD-TVD在流体和大气模拟数据集上实现精准、资源高效的3D超分辨。

Conclusion: CD-TVD显著改进了大规模科学模拟的数据增强能力，减少了高分辨率数据需求。

Abstract: Large-scale scientific simulations require significant resources to generate
high-resolution time-varying data (TVD). While super-resolution is an efficient
post-processing strategy to reduce costs, existing methods rely on a large
amount of HR training data, limiting their applicability to diverse simulation
scenarios. To address this constraint, we proposed CD-TVD, a novel framework
that combines contrastive learning and an improved diffusion-based
super-resolution model to achieve accurate 3D super-resolution from limited
time-step high-resolution data. During pre-training on historical simulation
data, the contrastive encoder and diffusion superresolution modules learn
degradation patterns and detailed features of high-resolution and
low-resolution samples. In the training phase, the improved diffusion model
with a local attention mechanism is fine-tuned using only one newly generated
high-resolution timestep, leveraging the degradation knowledge learned by the
encoder. This design minimizes the reliance on large-scale high-resolution
datasets while maintaining the capability to recover fine-grained details.
Experimental results on fluid and atmospheric simulation datasets confirm that
CD-TVD delivers accurate and resource-efficient 3D super-resolution, marking a
significant advancement in data augmentation for large-scale scientific
simulations. The code is available at
https://github.com/Xin-Gao-private/CD-TVD.

</details>


### [210] [3D Human Mesh Estimation from Single View RGBD](https://arxiv.org/abs/2508.08178)
*Ozhan Suat,Bedirhan Uguz,Batuhan Karagoz,Muhammed Can Keles,Emre Akbas*

Main category: cs.CV

TL;DR: 本文提出了M$^3$方法，通过RGBD图像估计3D人体网格，实现更高精度。


<details>
  <summary>Details</summary>
Motivation: 尽管许多方法已经能够从RGB图像生成3D人体网格，但RGBD摄像头所提供的深度数据并未充分利用，而这可能极大地提高精度和应用的现实性。

Method: 通过借助现有的MoCap数据集生成包含深度信息的局部网格数据，训练一种基于掩码自编码器的算法（M$^3$），在推理时通过匹配模板网格中的深度信息生成完整的人体网格。

Result: M$^3$在多个数据集上的表现优于现有方法，比如在SURREAL和CAPE数据集中的PVE分别为16.8 mm和22.0 mm，在BEHAVE数据集上比RGB方法减小18.4 mm误差。

Conclusion: 本方法通过利用有限的深度信息成功实现了完整3D人体网格的恢复，其在多个数据集上的性能优于现有方法，显示了RGBD数据的潜力。

Abstract: Despite significant progress in 3D human mesh estimation from RGB images;
RGBD cameras, offering additional depth data, remain underutilized. In this
paper, we present a method for accurate 3D human mesh estimation from a single
RGBD view, leveraging the affordability and widespread adoption of RGBD cameras
for real-world applications. A fully supervised approach for this problem,
requires a dataset with RGBD image and 3D mesh label pairs. However, collecting
such a dataset is costly and challenging, hence, existing datasets are small,
and limited in pose and shape diversity. To overcome this data scarcity, we
leverage existing Motion Capture (MoCap) datasets. We first obtain complete 3D
meshes from the body models found in MoCap datasets, and create partial,
single-view versions of them by projection to a virtual camera. This simulates
the depth data provided by an RGBD camera from a single viewpoint. Then, we
train a masked autoencoder to complete the partial, single-view mesh. During
inference, our method, which we name as M$^3$ for ``Masked Mesh Modeling'',
matches the depth values coming from the sensor to vertices of a template human
mesh, which creates a partial, single-view mesh. We effectively recover parts
of the 3D human body mesh model that are not visible, resulting in a full body
mesh. M$^3$ achieves 16.8 mm and 22.0 mm per-vertex-error (PVE) on the SURREAL
and CAPE datasets, respectively; outperforming existing methods that use
full-body point clouds as input. We obtain a competitive 70.9 PVE on the BEHAVE
dataset, outperforming a recently published RGB based method by 18.4 mm,
highlighting the usefulness of depth data. Code will be released.

</details>


### [211] [PP-Motion: Physical-Perceptual Fidelity Evaluation for Human Motion Generation](https://arxiv.org/abs/2508.08179)
*Sihan Zhao,Zixuan Wang,Tianyu Luan,Jia Jia,Wentao Zhu,Jiebo Luo,Junsong Yuan,Nan Xi*

Main category: cs.CV

TL;DR: 提出了一种名为PP-Motion的新度量方法，用于评估人类运动生成的物理和感知逼真度。


<details>
  <summary>Details</summary>
Motivation: 解决当前人类运动生成评价中物理可行性和人类感知逼真度之间存在的差距，以及主观标注的粗糙性问题。

Method: 通过物理标注方法计算运动最小修改量来满足物理定律，生成连续的物理对齐标注作为客观基准。然后设计PP-Motion度量方法，结合物理和感知损失训练，使用Pearson相关损失捕捉物理先验。

Result: PP-Motion度量方法在物理定律对齐和人类感知方面都优于以往的方法。

Conclusion: PP-Motion可以在物理和人类感知两个层面上更好地评价人类运动生成的逼真度，具有广泛的应用潜力。

Abstract: Human motion generation has found widespread applications in AR/VR, film,
sports, and medical rehabilitation, offering a cost-effective alternative to
traditional motion capture systems. However, evaluating the fidelity of such
generated motions is a crucial, multifaceted task. Although previous approaches
have attempted at motion fidelity evaluation using human perception or physical
constraints, there remains an inherent gap between human-perceived fidelity and
physical feasibility. Moreover, the subjective and coarse binary labeling of
human perception further undermines the development of a robust data-driven
metric. We address these issues by introducing a physical labeling method. This
method evaluates motion fidelity by calculating the minimum modifications
needed for a motion to align with physical laws. With this approach, we are
able to produce fine-grained, continuous physical alignment annotations that
serve as objective ground truth. With these annotations, we propose PP-Motion,
a novel data-driven metric to evaluate both physical and perceptual fidelity of
human motion. To effectively capture underlying physical priors, we employ
Pearson's correlation loss for the training of our metric. Additionally, by
incorporating a human-based perceptual fidelity loss, our metric can capture
fidelity that simultaneously considers both human perception and physical
alignment. Experimental results demonstrate that our metric, PP-Motion, not
only aligns with physical laws but also aligns better with human perception of
motion fidelity than previous work.

</details>


### [212] [THAT: Token-wise High-frequency Augmentation Transformer for Hyperspectral Pansharpening](https://arxiv.org/abs/2508.08183)
*Hongkun Jin,Hongcheng Jiang,Zejun Zhang,Yuan Zhang,Jia Fu,Tingfeng Li,Kai Luo*

Main category: cs.CV

TL;DR: 引入注意力机制和多级特征网络的Transformer，提高高频特征表现，在高光谱全色融合任务上取得了优越性能。


<details>
  <summary>Details</summary>
Motivation: 当前Transformer在高光谱图像处理中存在冗余token表示和缺乏多尺度建模问题，与此同时高光谱图像的固有光谱和空间先验未被有效利用。

Method: 提出Token-wise High-frequency Augmentation Transformer (THAT)，包括：1.关键Token选择注意力机制 (PTSA)，去除冗余，关注关键特征；2.多级方差感知前馈网络 (MVFN)，提高高频细节学习能力。

Result: 在标准基准数据集上，THAT通过更优的重建质量和效率实现了最先进的性能。

Conclusion: 通过改进的高频特征表示和有效的Token选择，THAT显著提升了高光谱全色融合的效果与效率。

Abstract: Transformer-based methods have demonstrated strong potential in hyperspectral
pansharpening by modeling long-range dependencies. However, their effectiveness
is often limited by redundant token representations and a lack of multi-scale
feature modeling. Hyperspectral images exhibit intrinsic spectral priors (e.g.,
abundance sparsity) and spatial priors (e.g., non-local similarity), which are
critical for accurate reconstruction. From a spectral-spatial perspective,
Vision Transformers (ViTs) face two major limitations: they struggle to
preserve high-frequency components--such as material edges and texture
transitions--and suffer from attention dispersion across redundant tokens.
These issues stem from the global self-attention mechanism, which tends to
dilute high-frequency signals and overlook localized details. To address these
challenges, we propose the Token-wise High-frequency Augmentation Transformer
(THAT), a novel framework designed to enhance hyperspectral pansharpening
through improved high-frequency feature representation and token selection.
Specifically, THAT introduces: (1) Pivotal Token Selective Attention (PTSA) to
prioritize informative tokens and suppress redundancy; (2) a Multi-level
Variance-aware Feed-forward Network (MVFN) to enhance high-frequency detail
learning. Experiments on standard benchmarks show that THAT achieves
state-of-the-art performance with improved reconstruction quality and
efficiency. The source code is available at https://github.com/kailuo93/THAT.

</details>


### [213] [KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning](https://arxiv.org/abs/2508.08186)
*Md Meftahul Ferdaus,Mahdi Abdelguerfi,Elias Ioup,Steven Sloan,Kendall N. Niles,Ken Pathak*

Main category: cs.CV

TL;DR: 本文介绍了一种高效的语义分割框架KARMA，适用于土木基础设施缺陷的语义分割，旨在减少模型参数并提高实时性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统深度学习方法因模型参数过多导致的实时性困难及土木基础设施缺陷的分割挑战，如外观变化大、拍摄条件恶劣以及类别不平衡问题。

Method: 提出KARMA框架，包含三个技术创新：1. 使用低秩分解的Tiny Kolmogorov-Arnold Network (TiKAN)模块进行KAN特征变换；2. 用可分离卷积优化特征金字塔结构，实现多尺度缺陷分析；3. 基于静态-动态原型机制增强不平衡类别的特征表示。

Result: 实验证明，KARMA在基础设施检测数据集上实现了与最新方法相当或更优的mIoU性能，参数量比传统方法减少97%（0.959M对31.04M），计算负载仅0.264 GFLOPS，支持实时部署。

Conclusion: KARMA框架在保持高精度的同时，大幅降低参数量和计算复杂度，为实际自动化基础设施检测提供了高效实用的解决方案。

Abstract: Semantic segmentation of structural defects in civil infrastructure remains
challenging due to variable defect appearances, harsh imaging conditions, and
significant class imbalance. Current deep learning methods, despite their
effectiveness, typically require millions of parameters, rendering them
impractical for real-time inspection systems. We introduce KARMA
(Kolmogorov-Arnold Representation Mapping Architecture), a highly efficient
semantic segmentation framework that models complex defect patterns through
compositions of one-dimensional functions rather than conventional
convolutions. KARMA features three technical innovations: (1) a
parameter-efficient Tiny Kolmogorov-Arnold Network (TiKAN) module leveraging
low-rank factorization for KAN-based feature transformation; (2) an optimized
feature pyramid structure with separable convolutions for multi-scale defect
analysis; and (3) a static-dynamic prototype mechanism that enhances feature
representation for imbalanced classes. Extensive experiments on benchmark
infrastructure inspection datasets demonstrate that KARMA achieves competitive
or superior mean IoU performance compared to state-of-the-art approaches, while
using significantly fewer parameters (0.959M vs. 31.04M, a 97% reduction).
Operating at 0.264 GFLOPS, KARMA maintains inference speeds suitable for
real-time deployment, enabling practical automated infrastructure inspection
systems without compromising accuracy. The source code can be accessed at the
following URL: https://github.com/faeyelab/karma.

</details>


### [214] [Reinforcement Learning in Vision: A Survey](https://arxiv.org/abs/2508.08189)
*Weijia Wu,Chen Gao,Joya Chen,Kevin Qinghong Lin,Qingwei Meng,Yiming Zhang,Yuke Qiu,Hong Zhou,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 本文综述了视觉强化学习的最新进展，分析了其方法、趋势和挑战，并为研究人员提供了领域全景图与未来方向。


<details>
  <summary>Details</summary>
Motivation: 结合视觉智能与强化学习的快速发展，推动计算机视觉与自主决策的结合，是研究的动机所在。

Method: 文章从定义视觉强化学习问题出发，回顾主要优化策略的演变，对超过200个相关工作进行分类，总结出4个研究主题，并分析其算法设计和评估标准。

Result: 研究全面梳理了视觉强化学习的算法进展、训练和评估趋势，指出样本效率、泛化能力与安全性是亟待解决的核心问题。

Conclusion: 研究旨在为视觉强化学习领域提供系统整理与前瞻性分析，帮助研究人员明确领域发展方向并提升实践能力。

Abstract: Recent advances at the intersection of reinforcement learning (RL) and visual
intelligence have enabled agents that not only perceive complex visual scenes
but also reason, generate, and act within them. This survey offers a critical
and up-to-date synthesis of the field. We first formalize visual RL problems
and trace the evolution of policy-optimization strategies from RLHF to
verifiable reward paradigms, and from Proximal Policy Optimization to Group
Relative Policy Optimization. We then organize more than 200 representative
works into four thematic pillars: multi-modal large language models, visual
generation, unified model frameworks, and vision-language-action models. For
each pillar we examine algorithmic design, reward engineering, benchmark
progress, and we distill trends such as curriculum-driven training,
preference-aligned diffusion, and unified reward modeling. Finally, we review
evaluation protocols spanning set-level fidelity, sample-level preference, and
state-level stability, and we identify open challenges that include sample
efficiency, generalization, and safe deployment. Our goal is to provide
researchers and practitioners with a coherent map of the rapidly expanding
landscape of visual RL and to highlight promising directions for future
inquiry. Resources are available at:
https://github.com/weijiawu/Awesome-Visual-Reinforcement-Learning.

</details>


### [215] [Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model](https://arxiv.org/abs/2508.08199)
*Peiqi He,Zhenhao Zhang,Yixiang Zhang,Xiongjun Zhao,Shaoliang Peng*

Main category: cs.CV

TL;DR: 该论文提出了Spatial-ORMLLM，这是一种新型的大型视觉语言模型，专为手术室中的3D空间推理设计，仅使用RGB模态进行体积与语义推断。


<details>
  <summary>Details</summary>
Motivation: 目前的手术室空间建模方法多基于大规模多模态数据，但这些方法需要复杂的多视频和音频传感器，难以获取3D数据，并且仅基于2D数据的训练无法捕捉复杂场景中的精细细节。

Method: 提出Spatial-ORMLLM，它通过空间增强特征融合模块，将2D模态输入与算法提取的丰富的3D空间知识相结合，采用统一的端到端多模态框架，融合空间和文本特征，无需额外的专家标注或传感器输入，即可实现3D场景推理。

Result: 通过在多个临床数据集上的实验，Spatial-ORMLLM达到了当前最优表现，并可鲁棒地推广到未见的手术场景及下游任务。

Conclusion: Spatial-ORMLLM在手术室场景下实现了高性能和鲁棒的3D空间推理，显著填补了仅使用2D数据进行复杂场景建模的空白。

Abstract: Precise spatial modeling in the operating room (OR) is foundational to many
clinical tasks, supporting intraoperative awareness, hazard avoidance, and
surgical decision-making. While existing approaches leverage large-scale
multimodal datasets for latent-space alignment to implicitly learn spatial
relationships, they overlook the 3D capabilities of MLLMs. However, this
approach raises two issues: (1) Operating rooms typically lack multiple video
and audio sensors, making multimodal 3D data difficult to obtain; (2) Training
solely on readily available 2D data fails to capture fine-grained details in
complex scenes. To address this gap, we introduce Spatial-ORMLLM, the first
large vision-language model for 3D spatial reasoning in operating rooms using
only RGB modality to infer volumetric and semantic cues, enabling downstream
medical tasks with detailed and holistic spatial context. Spatial-ORMLLM
incorporates a Spatial-Enhanced Feature Fusion Block, which integrates 2D
modality inputs with rich 3D spatial knowledge extracted by the estimation
algorithm and then feeds the combined features into the visual tower. By
employing a unified end-to-end MLLM framework, it combines powerful spatial
features with textual features to deliver robust 3D scene reasoning without any
additional expert annotations or sensor inputs. Experiments on multiple
benchmark clinical datasets demonstrate that Spatial-ORMLLM achieves
state-of-the-art performance and generalizes robustly to previously unseen
surgical scenarios and downstream tasks.

</details>


### [216] [SAGOnline: Segment Any Gaussians Online](https://arxiv.org/abs/2508.08219)
*Wentao Sun,Quanyun Wu,Hanqing Xu,Kyle Gao,Zhengsen Xu,Yiping Chen,Dedong Zhang,Lingfei Ma,John S. Zelek,Jonathan Li*

Main category: cs.CV

TL;DR: SAGOnline提出一种轻量级、零样本的实时3D高斯场分割框架，解决了当前方法中计算成本高、空间推理能力有限、多物体跟踪困难等问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了在3D高斯场中实现高效、一致的多物体分割和跟踪，同时降低计算成本及提高实时性能。

Method: 提出了一种解耦策略，将视频基础模型用于合成视图上的2D掩码传播，同时设计了一种GPU加速的3D掩码生成和高斯粒子实例标记算法，实现跨视图无损多物体跟踪与分割。

Result: 在NVOS（92.7% mIoU）和Spin-NeRF（95.2% mIoU）上的性能超越现有方法，推理速度提高15-1500倍（27 ms/帧）。

Conclusion: SAGOnline作为轻量级零样本3D分割框架，在AR/VR及机器人领域具有重要应用潜力，并开创了将2D视频基础模型有效适配至3D领域的先例。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful paradigm for explicit
3D scene representation, yet achieving efficient and consistent 3D segmentation
remains challenging. Current methods suffer from prohibitive computational
costs, limited 3D spatial reasoning, and an inability to track multiple objects
simultaneously. We present Segment Any Gaussians Online (SAGOnline), a
lightweight and zero-shot framework for real-time 3D segmentation in Gaussian
scenes that addresses these limitations through two key innovations: (1) a
decoupled strategy that integrates video foundation models (e.g., SAM2) for
view-consistent 2D mask propagation across synthesized views; and (2) a
GPU-accelerated 3D mask generation and Gaussian-level instance labeling
algorithm that assigns unique identifiers to 3D primitives, enabling lossless
multi-object tracking and segmentation across views. SAGOnline achieves
state-of-the-art performance on NVOS (92.7% mIoU) and Spin-NeRF (95.2% mIoU)
benchmarks, outperforming Feature3DGS, OmniSeg3D-gs, and SA3D by 15--1500 times
in inference speed (27 ms/frame). Qualitative results demonstrate robust
multi-object segmentation and tracking in complex scenes. Our contributions
include: (i) a lightweight and zero-shot framework for 3D segmentation in
Gaussian scenes, (ii) explicit labeling of Gaussian primitives enabling
simultaneous segmentation and tracking, and (iii) the effective adaptation of
2D video foundation models to the 3D domain. This work allows real-time
rendering and 3D scene understanding, paving the way for practical AR/VR and
robotic applications.

</details>


### [217] [Learning User Preferences for Image Generation Model](https://arxiv.org/abs/2508.08220)
*Wenyi Mo,Ying Ba,Tianyu Zhang,Yalong Bai,Biye Li*

Main category: cs.CV

TL;DR: 该研究旨在通过一种基于多模态大语言模型的新方法，提高用户偏好预测的准确性和个性化水平。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分考虑用户偏好的动态性和多样性，亟需更灵活、高效的解决方案。

Method: 提出对比偏好损失与可学习的偏好标记（preference tokens），从用户历史交互中挖掘个性化偏好，并提升类似用户偏好的一致性。

Result: 实验结果显示，该方法在偏好预测准确度方面优于现有方法，并能更精准识别具有相似审美倾向的用户。

Conclusion: 这项研究提供了一种有效框架，能够改善偏好预测并为生成契合用户个人品味的图像提供指导。

Abstract: User preference prediction requires a comprehensive and accurate
understanding of individual tastes. This includes both surface-level
attributes, such as color and style, and deeper content-related aspects, such
as themes and composition. However, existing methods typically rely on general
human preferences or assume static user profiles, often neglecting individual
variability and the dynamic, multifaceted nature of personal taste. To address
these limitations, we propose an approach built upon Multimodal Large Language
Models, introducing contrastive preference loss and preference tokens to learn
personalized user preferences from historical interactions. The contrastive
preference loss is designed to effectively distinguish between user ''likes''
and ''dislikes'', while the learnable preference tokens capture shared interest
representations among existing users, enabling the model to activate
group-specific preferences and enhance consistency across similar users.
Extensive experiments demonstrate our model outperforms other methods in
preference prediction accuracy, effectively identifying users with similar
aesthetic inclinations and providing more precise guidance for generating
images that align with individual tastes. The project page is
\texttt{https://learn-user-pref.github.io/}.

</details>


### [218] [StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation](https://arxiv.org/abs/2508.08248)
*Shuyuan Tu,Yueming Pan,Yinming Huang,Xintong Han,Zhen Xing,Qi Dai,Chong Luo,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 提出了一种名为StableAvatar的新型音频驱动化身生成模型，能够生成高质量、无限时长的视频，无需后期处理。


<details>
  <summary>Details</summary>
Motivation: 现有的音频驱动化身生成模型在生成自然音频同步和身份一致的长视频时面临挑战，主要问题在于音频建模。

Method: 提出了一种名为Time-step-aware Audio Adapter的新模块，避免了误差积累；引入了Audio Native Guidance Mechanism，提升了音频同步；采用了Dynamic Weighted Sliding-window Strategy，增强了视频的平滑性。

Result: 实验表明，该模型在生成视频的质量和长度方面具备显著优势，音频同步效果良好。

Conclusion: StableAvatar能够生成高质量、自然的无限时长视频，展现了出色的音频同步和身份一致性能力，解决了现有模型的局限性。

Abstract: Current diffusion models for audio-driven avatar video generation struggle to
synthesize long videos with natural audio synchronization and identity
consistency. This paper presents StableAvatar, the first end-to-end video
diffusion transformer that synthesizes infinite-length high-quality videos
without post-processing. Conditioned on a reference image and audio,
StableAvatar integrates tailored training and inference modules to enable
infinite-length video generation. We observe that the main reason preventing
existing models from generating long videos lies in their audio modeling. They
typically rely on third-party off-the-shelf extractors to obtain audio
embeddings, which are then directly injected into the diffusion model via
cross-attention. Since current diffusion backbones lack any audio-related
priors, this approach causes severe latent distribution error accumulation
across video clips, leading the latent distribution of subsequent segments to
drift away from the optimal distribution gradually. To address this,
StableAvatar introduces a novel Time-step-aware Audio Adapter that prevents
error accumulation via time-step-aware modulation. During inference, we propose
a novel Audio Native Guidance Mechanism to further enhance the audio
synchronization by leveraging the diffusion's own evolving joint audio-latent
prediction as a dynamic guidance signal. To enhance the smoothness of the
infinite-length videos, we introduce a Dynamic Weighted Sliding-window Strategy
that fuses latent over time. Experiments on benchmarks show the effectiveness
of StableAvatar both qualitatively and quantitatively.

</details>


### [219] [ReferSplat: Referring Segmentation in 3D Gaussian Splatting](https://arxiv.org/abs/2508.08252)
*Shuting He,Guangquan Jie,Changshuo Wang,Yun Zhou,Shuming Hu,Guanbin Li,Henghui Ding*

Main category: cs.CV

TL;DR: 提出了一种名为R3DGS的任务，用于根据自然语言描述分割3D高斯场景中的目标对象，方法为ReferSplat，表现出色并公开数据集和代码。


<details>
  <summary>Details</summary>
Motivation: 探讨如何通过自然语言描述来分割3D点云场景中的目标物体，以提升人工智能对3D多模态理解的能力。

Method: 提出了一种名为ReferSplat的方法，该方法通过对3D高斯点和自然语言描述的空间建模，进行目标对象分割。

Result: ReferSplat在新提出的R3DGS任务以及3D开放词汇分割基准上均取得了最先进的性能。

Conclusion: 研究证明，为3D点云数据与自然语言描述之间建立空间关系理解模型，可以有效解决复杂3D多模态任务。

Abstract: We introduce Referring 3D Gaussian Splatting Segmentation (R3DGS), a new task
that aims to segment target objects in a 3D Gaussian scene based on natural
language descriptions, which often contain spatial relationships or object
attributes. This task requires the model to identify newly described objects
that may be occluded or not directly visible in a novel view, posing a
significant challenge for 3D multi-modal understanding. Developing this
capability is crucial for advancing embodied AI. To support research in this
area, we construct the first R3DGS dataset, Ref-LERF. Our analysis reveals that
3D multi-modal understanding and spatial relationship modeling are key
challenges for R3DGS. To address these challenges, we propose ReferSplat, a
framework that explicitly models 3D Gaussian points with natural language
expressions in a spatially aware paradigm. ReferSplat achieves state-of-the-art
performance on both the newly proposed R3DGS task and 3D open-vocabulary
segmentation benchmarks. Dataset and code are available at
https://github.com/heshuting555/ReferSplat.

</details>


### [220] [Learning an Implicit Physics Model for Image-based Fluid Simulation](https://arxiv.org/abs/2508.08254)
*Emily Yue-Ting Jia,Jiageng Mao,Zhiyuan Gao,Yajie Zhao,Yue Wang*

Main category: cs.CV

TL;DR: 本研究针对单张静态图片生成符合物理规律的4D场景动画，提出一种基于物理约束的神经网络方法，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法采用简单的2D运动估计器生成动画，常出现不符合物理规律的现象，因此需要开发一种能利用物理原则生成逼真动画的新方法。

Method: 提出一种物理约束神经网络，通过表面点的物理一致性运动预测动画，同时结合Navier-Stokes方程等物理原则。针对外观，利用输入图片和深度信息预测3D高斯分布，并根据预测运动进行动画渲染。

Result: 新方法在生成符合物理逻辑的动画效果上显著优于现有方法，实验结果证明其有效性。

Conclusion: 本研究证明，通过引入物理原则约束神经网络，可以提高从单张图像生成4D场景动画的真实性与合理性，展示了新方法的优越性。

Abstract: Humans possess an exceptional ability to imagine 4D scenes, encompassing both
motion and 3D geometry, from a single still image. This ability is rooted in
our accumulated observations of similar scenes and an intuitive understanding
of physics. In this paper, we aim to replicate this capacity in neural
networks, specifically focusing on natural fluid imagery. Existing methods for
this task typically employ simplistic 2D motion estimators to animate the
image, leading to motion predictions that often defy physical principles,
resulting in unrealistic animations. Our approach introduces a novel method for
generating 4D scenes with physics-consistent animation from a single image. We
propose the use of a physics-informed neural network that predicts motion for
each surface point, guided by a loss term derived from fundamental physical
principles, including the Navier-Stokes equations. To capture appearance, we
predict feature-based 3D Gaussians from the input image and its estimated
depth, which are then animated using the predicted motions and rendered from
any desired camera perspective. Experimental results highlight the
effectiveness of our method in producing physically plausible animations,
showcasing significant performance improvements over existing methods. Our
project page is https://physfluid.github.io/ .

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [221] [Semi-automated Fact-checking in Portuguese: Corpora Enrichment using Retrieval with Claim extraction](https://arxiv.org/abs/2508.06495)
*Juliana Resplande Sant'anna Gomes,Arlindo Rodrigues Galvão Filho*

Main category: cs.CL

TL;DR: 论文探讨通过大语言模型和搜索引擎API增强葡萄牙语新闻语料的真实性验证能力。


<details>
  <summary>Details</summary>
Motivation: 人力事实核查难以应对虚假信息快速传播，且葡萄牙语缺乏整合外部证据的公开数据集。

Method: 使用LLM抽取主张，并通过搜索引擎API检索相关外部文档，同时加入数据验证框架以提高语料质量。

Result: 以三种葡萄牙语新闻数据集为基础，整合外部证据并优化数据质量。

Conclusion: 提出的方法填补了葡语新闻事实核查的资源空白，为开发更强大的半自动化事实核查系统奠定了基础。

Abstract: The accelerated dissemination of disinformation often outpaces the capacity
for manual fact-checking, highlighting the urgent need for Semi-Automated
Fact-Checking (SAFC) systems. Within the Portuguese language context, there is
a noted scarcity of publicly available datasets that integrate external
evidence, an essential component for developing robust AFC systems, as many
existing resources focus solely on classification based on intrinsic text
features. This dissertation addresses this gap by developing, applying, and
analyzing a methodology to enrich Portuguese news corpora (Fake.Br, COVID19.BR,
MuMiN-PT) with external evidence. The approach simulates a user's verification
process, employing Large Language Models (LLMs, specifically Gemini 1.5 Flash)
to extract the main claim from texts and search engine APIs (Google Search API,
Google FactCheck Claims Search API) to retrieve relevant external documents
(evidence). Additionally, a data validation and preprocessing framework,
including near-duplicate detection, is introduced to enhance the quality of the
base corpora.

</details>


### [222] [Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models](https://arxiv.org/abs/2508.06504)
*Yao Ge,Sudeshna Das,Yuting Guo,Abeed Sarker*

Main category: cs.CL

TL;DR: 这篇论文研究了大型语言模型（LLMs）在生物医学命名实体识别（NER）上的性能，通过调查一种基于检索增强生成（RAG）的动态提示策略提升其在少样本场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 探索如何优化LLMs在少量训练数据下提升生物医学NER任务的表现，尤其是在提示工程和动态提示改进领域。

Method: 提出了一种动态提示策略，结合TF-IDF和SBERT等检索方法，从相似性出发选择上下文学习实例，并在推理过程中动态更新提示。

Result: 与基本静态提示相比，结构化静态提示策略提升了 GPT-4 F1分数12%，GPT-3.5 和 LLaMA 3-70B 提升约11%。动态提示进一步优化，TF-IDF 和 SBERT 检索方法在5-shot和10-shot场景中分别提升7.3%和5.6%的平均F1分数。

Conclusion: 利用基于RAG的动态提示在生物医学NER任务中展示了优越的性能提升，表明上下文自适应提示的价值。

Abstract: Biomedical named entity recognition (NER) is a high-utility natural language
processing (NLP) task, and large language models (LLMs) show promise
particularly in few-shot settings (i.e., limited training data). In this
article, we address the performance challenges of LLMs for few-shot biomedical
NER by investigating a dynamic prompting strategy involving retrieval-augmented
generation (RAG). In our approach, the annotated in-context learning examples
are selected based on their similarities with the input texts, and the prompt
is dynamically updated for each instance during inference. We implemented and
optimized static and dynamic prompt engineering techniques and evaluated them
on five biomedical NER datasets. Static prompting with structured components
increased average F1-scores by 12% for GPT-4, and 11% for GPT-3.5 and LLaMA
3-70B, relative to basic static prompting. Dynamic prompting further improved
performance, with TF-IDF and SBERT retrieval methods yielding the best results,
improving average F1-scores by 7.3% and 5.6% in 5-shot and 10-shot settings,
respectively. These findings highlight the utility of contextually adaptive
prompts via RAG for biomedical NER.

</details>


### [223] [CarbonScaling: Extending Neural Scaling Laws for Carbon Footprint in Large Language Models](https://arxiv.org/abs/2508.06524)
*Lei Jiang,Fan Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为CarbonScaling的分析框架，扩展了神经网络扩展定律，纳入了LLM训练中的运行和隐含碳排放，量化了模型准确性与碳足迹之间的关系。


<details>
  <summary>Details</summary>
Motivation: 当前神经网络扩展定律未考虑随着语言模型规模增长而显著增加的碳排放问题，本文希望通过改善框架来兼顾准确性和碳足迹分析。

Method: 结合神经网络扩展、GPU硬件演化、并行优化和碳估算模型，CarbonScaling框架实现了从模型准确性到碳足迹的量化关联。

Result: 结果显示：虽然模型准确性与碳排放量之间呈幂律关系，但现实中的低效率会显著提高放大因子；硬件技术扩展能减少小型到中型模型的碳排放，但对超大型模型的收益递减。通过优化训练批量规模，尤其是批量大小的关键扩展，可以缓解这些低效率问题。

Conclusion: CarbonScaling 为更可持续且碳效益更高的语言模型训练提供了关键洞察。

Abstract: Neural scaling laws have driven the development of increasingly large
language models (LLMs) by linking accuracy improvements to growth in parameter
count, dataset size, and compute. However, these laws overlook the carbon
emissions that scale exponentially with LLM size. This paper presents
\textit{CarbonScaling}, an analytical framework that extends neural scaling
laws to incorporate both operational and embodied carbon in LLM training. By
integrating models for neural scaling, GPU hardware evolution, parallelism
optimization, and carbon estimation, \textit{CarbonScaling} quantitatively
connects model accuracy to carbon footprint. Results show that while a
power-law relationship between accuracy and carbon holds, real-world
inefficiencies significantly increase the scaling factor. Hardware technology
scaling reduces carbon emissions for small to mid-sized models, but offers
diminishing returns for extremely large LLMs due to communication overhead and
underutilized GPUs. Training optimizations-especially aggressive critical batch
size scaling-help alleviate this inefficiency. \textit{CarbonScaling} offers
key insights for training more sustainable and carbon-efficient LLMs.

</details>


### [224] [The Art of Breaking Words: Rethinking Multilingual Tokenizer Design](https://arxiv.org/abs/2508.06533)
*Aamod Thakur,Ajay Nagpal,Atharva Savarkar,Kundeshwar Pundalik,Siddhesh Dosi,Piyush Sawarkar,Viraj Thakur,Rohit Saluja,Maunendra Sankar Desarkar,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 该论文探讨了多语言大语言模型中的分词问题，提出了一个新的数据组成算法，显著提高了分词效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 多语言模型的分词效率和上下文利用率较低，是提升大语言模型效率的瓶颈。

Method: 通过系统研究词汇表大小、预分词规则和训练语料组成的关系，针对Indic文字设计实验，提出平衡多语言数据的分词训练算法。

Result: 提出算法将平均词组到单词比率降低了大约6%，相较于现有技术实现了40%以上的改善，同时提高了模型性能和推理速度。

Conclusion: 分词策略与架构、训练目标同等重要，是构建高效多语言大模型的重要因素。

Abstract: While model architecture and training objectives are well-studied,
tokenization, particularly in multilingual contexts, remains a relatively
neglected aspect of Large Language Model (LLM) development. Existing tokenizers
often exhibit high token-to-word ratios, inefficient use of context length, and
slower inference. We present a systematic study that links vocabulary size,
pre-tokenization rules, and training-corpus composition to both token-to-word
efficiency and model quality. To ground our analysis in a linguistically
diverse context, we conduct extensive experiments on Indic scripts, which
present unique challenges due to their high script diversity and orthographic
complexity. Drawing on the insights from these analyses, we propose a novel
algorithm for data composition that balances multilingual data for tokenizer
training. Our observations on pretokenization strategies significantly improve
model performance, and our data composition algorithm reduces the average
token-to-word ratio by approximately 6% with respect to the conventional data
randomization approach. Our tokenizer achieves more than 40% improvement on
average token-to-word ratio against stateof-the-art multilingual Indic models.
This improvement yields measurable gains in both model performance and
inference speed. This highlights tokenization alongside architecture and
training objectives as a critical lever for building efficient, scalable
multilingual LLMs

</details>


### [225] [Factor Augmented Supervised Learning with Text Embeddings](https://arxiv.org/abs/2508.06548)
*Zhanye Luo,Yuefeng Han,Xiufan Yu*

Main category: cs.CL

TL;DR: 提出了一种新的框架AEALT，用于利用自动编码器进行文本嵌入的降维和任务优化。


<details>
  <summary>Details</summary>
Motivation: 大语言模型生成的高维文本嵌入在计算效率和下游任务中带来了挑战。

Method: 设计了AEALT框架，通过监督增强型自动编码器对大语言模型生成的嵌入进行降维和任务相关因子提取。

Result: 与原始嵌入以及常规降维方法相比，AEALT在分类、异常检测和预测任务上表现出显著性能提升。

Conclusion: AEALT框架通过捕获复杂嵌入的非线性结构，成功提高了模型在多个实际任务中的表现。

Abstract: Large language models (LLMs) generate text embeddings from text data,
producing vector representations that capture the semantic meaning and
contextual relationships of words. However, the high dimensionality of these
embeddings often impedes efficiency and drives up computational cost in
downstream tasks. To address this, we propose AutoEncoder-Augmented Learning
with Text (AEALT), a supervised, factor-augmented framework that incorporates
dimension reduction directly into pre-trained LLM workflows. First, we extract
embeddings from text documents; next, we pass them through a supervised
augmented autoencoder to learn low-dimensional, task-relevant latent factors.
By modeling the nonlinear structure of complex embeddings, AEALT outperforms
conventional deep-learning approaches that rely on raw embeddings. We validate
its broad applicability with extensive experiments on classification, anomaly
detection, and prediction tasks using multiple real-world public datasets.
Numerical results demonstrate that AEALT yields substantial gains over both
vanilla embeddings and several standard dimension reduction methods.

</details>


### [226] [Discerning minds or generic tutors? Evaluating instructional guidance capabilities in Socratic LLMs](https://arxiv.org/abs/2508.06583)
*Ying Liu,Can Li,Ting Zhang,Mei Wang,Qiannan Zhu,Jian Li,Hua Huang*

Main category: cs.CL

TL;DR: 本研究提出GuideEval基准，评估大型语言模型的教学指导能力，研究其能否模仿专家导师动态调整策略以适应学习者理解。


<details>
  <summary>Details</summary>
Motivation: 研究在于解决大型语言模型仅限于生成问题的局限性，探索其在互动教学中的全面指导潜力。

Method: 通过真实教育对话创建GuideEval基准，并分为三阶段行为框架：感知学习者状态（Perception）、调整教学策略（Orchestration）以及引导深度反思（Elicitation）。此外，作者提出一种行为引导微调策略。

Result: 现有模型在面对学习者困惑或需要引导时，通常无法提供有效的适应性支持。行为引导微调策略显著提升了教学指导表现。

Conclusion: 倡导一种以学习者互动为中心的对话式评估范式，以代替内容孤立评估，为Socratic对话式模型评估提供新视角。

Abstract: The conversational capabilities of large language models hold significant
promise for enabling scalable and interactive tutoring. While prior research
has primarily examined their capacity for Socratic questioning, it often
overlooks a critical dimension: adaptively guiding learners based on their
cognitive states. This study shifts focus from mere question generation to the
broader instructional guidance capability. We ask: Can LLMs emulate expert
tutors who dynamically adjust strategies in response to learners'
understanding? To investigate this, we propose GuideEval, a benchmark grounded
in authentic educational dialogues that evaluates pedagogical guidance through
a three-phase behavioral framework: (1) Perception, inferring learner states;
(2) Orchestration, adapting instructional strategies; and (3) Elicitation,
stimulating proper reflections. Empirical findings reveal that existing LLMs
frequently fail to provide effective adaptive scaffolding when learners exhibit
confusion or require redirection. Furthermore, we introduce a behavior-guided
finetuning strategy that leverages behavior-prompted instructional dialogues,
significantly enhancing guidance performance. By shifting the focus from
isolated content evaluation to learner-centered interaction, our work advocates
a more dialogic paradigm for evaluating Socratic LLMs.

</details>


### [227] [LLM Unlearning Without an Expert Curated Dataset](https://arxiv.org/abs/2508.06595)
*Xiaoyuan Zhu,Muru Zhang,Ollie Liu,Robin Jia,Willie Neiswanger*

Main category: cs.CL

TL;DR: 本文提出了一种利用语言模型生成高质量忘记数据集（forget sets）的方法，以实现后验知识删减（unlearning）。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型可能包含敏感、违法或版权知识，因此需要一种无需完全重新训练就能从模型中移除特定知识领域的后处理方法。

Method: 提出了一种自动化生成高质量忘记数据集的方法，通过结构化提示流程推进模型合成教科书风格的数据，仅需输入领域名称即可。

Result: 实验表明，生成的合成数据集在遗忘效用上优于基线方法，并与专家精心设计的数据集表现相当。此外，多步骤生成流程显著提升了数据多样性，并进一步改善了遗忘效果。

Conclusion: 研究表明合成数据集是一种无需人工干预的实际可行且可扩展的后验知识删减解决方案，适用于多种新兴领域。

Abstract: Modern large language models often encode sensitive, harmful, or copyrighted
knowledge, raising the need for post-hoc unlearning-the ability to remove
specific domains of knowledge from a model without full retraining. A major
bottleneck in current unlearning pipelines is constructing effective forget
sets-datasets that approximate the target domain and guide the model to forget
it. In this work, we introduce a scalable, automated approach to generate
high-quality forget sets using language models themselves. Our method
synthesizes textbook-style data through a structured prompting pipeline,
requiring only a domain name as input. Through experiments on unlearning
biosecurity, cybersecurity, and Harry Potter novels, we show that our synthetic
datasets consistently outperform the baseline synthetic alternatives and are
comparable to the expert-curated ones. Additionally, ablation studies reveal
that the multi-step generation pipeline significantly boosts data diversity,
which in turn improves unlearning utility. Overall, our findings suggest that
synthetic datasets offer a promising path toward practical, scalable unlearning
for a wide range of emerging domains without the need for manual intervention.
We release our code and dataset at
https://github.com/xyzhu123/Synthetic_Textbook.

</details>


### [228] [BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent](https://arxiv.org/abs/2508.06600)
*Zijian Chen,Xueguang Ma,Shengyao Zhuang,Ping Nie,Kai Zou,Andrew Liu,Joshua Green,Kshama Patel,Ruoxi Meng,Mingyi Su,Sahel Sharifymoghaddam,Yanxi Li,Haoran Hong,Xinyu Shi,Xuye Liu,Nandan Thakur,Crystina Zhang,Luyu Gao,Wenhu Chen,Jimmy Lin*

Main category: cs.CL

TL;DR: 本文介绍了一种名为BrowseComp-Plus的新基准，用以评估深度研究代理及信息检索方法，其通过固定和精心挑选的文档语料库提高了实验的公平性和透明性。


<details>
  <summary>Details</summary>
Motivation: 目前许多深度研究代理的评估依赖动态且不透明的网络API，这影响了公平性、再现性和对检索贡献的分离分析。

Method: 设计BrowseComp-Plus基准，该基准来源于BrowseComp，基于固定的、经过验证和挖掘的挑战性文档语料库构建。

Result: 基准测试显示BrowseComp-Plus可以有效区分深度研究系统性能。例如，Search-R1模型搭配BM25检索器仅达3.86%的准确率，而GPT-5达55.9%；进一步结合Qwen3-Embedding-8B检索器后，GPT-5准确率提升至70.1%。

Conclusion: BrowseComp-Plus提供了一个可控实验环境，实现对深度研究代理和检索方法的全面评估，并促进了对检索效率和其他相关领域的深入研究。

Abstract: Deep-Research agents, which integrate large language models (LLMs) with
search tools, have shown success in improving the effectiveness of handling
complex queries that require iterative search planning and reasoning over
search results. Evaluations on current benchmarks like BrowseComp relies on
black-box live web search APIs, have notable limitations in (1) fairness:
dynamic and opaque web APIs hinder fair comparisons and reproducibility of deep
research methods; (2) transparency: lack of control over the document corpus
makes it difficult to isolate retriever contributions. In other words, the
current evaluations may compare a complete deep research system at a given
time, but they do not foster well-controlled experiments to provide insights
into the capability of underlying deep research LLMs. To address these
challenges, we introduce BrowseComp-Plus, a benchmark derived from BrowseComp,
employing a fixed, carefully curated corpus. Each query in BrowseComp-Plus
includes human-verified supporting documents and mined challenging negatives,
enabling controlled experimentation. The benchmark is shown to be effective in
distinguishing the performance of deep research systems. For instance, the
open-source model Search-R1, when paired with the BM25 retriever, achieves
3.86% accuracy, whereas the GPT-5 achieves 55.9%. Integrating the GPT-5 with
the Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1% with
fewer search calls. This benchmark allows comprehensive evaluation and
disentangled analysis of deep research agents and retrieval methods, fostering
insights into retrieval effectiveness, citation accuracy, and context
engineering in Deep-Research system.

</details>


### [229] [Train It and Forget It: Merge Lists are Unnecessary for BPE Inference in Language Models](https://arxiv.org/abs/2508.06621)
*Tomohiro Sawada,Kartik Goyal*

Main category: cs.CL

TL;DR: 探讨对BPE合并列表的偏离或完全摒弃对语言模型的下游表现的影响，发现某些无合并列表的方法性能影响较小，提出可能更简单且更隐私的分词方案。


<details>
  <summary>Details</summary>
Motivation: 研究传统BPE分词的合并列表潜在攻击面，并探讨使用无需合并列表的推断算法的可行性及其对下游性能的影响。

Method: 通过两类BPE推断方法进行实验：目标化偏离合并列表（如随机合并顺序、删除/截断合并列表等），和无目标化的完全脱离合并列表但强调文本压缩的方法（贪婪推断或精确推断）。

Result: 目标化偏离合并列表显著降低语言模型性能，而无目标化的方法对性能影响较小，通常比预期更低。

Conclusion: 无需合并列表的分词方法在不显著影响模型性能的情况下，有潜力提供更简单且隐私更强的方案。

Abstract: Standard Byte-Pair Encoding (BPE) tokenization compresses text by pairing a
learned token vocabulary with a detailed merge list. Recent work has shown that
this merge list exposes a potential attack surface for extracting information
about language model's training data. In this paper, we explore the downstream
impact of BPE inference algorithms that do not rely on this merge list at all,
and hence differ from the encoding process during BPE training. To address this
question, we investigate two broad classes of BPE inference schemes that differ
from BPE application during training: a) targeted deviation from merge-lists
including random merge orders, and various corruptions of merge list involving
deletion/truncation, and b) non-targeted BPE inference algorithms that do not
depend on the merge list but focus on compressing the text either greedily or
exactly. Extensive experiments across diverse language modeling tasks like
accuracy-based QA benchmarks, machine translation, and open-ended generation
reveal that while targeted deviation from the merge lists exhibits significant
degradation in language model performance, the non-targeted merge-list-free
inference algorithms result in minimal impact on downstream performance that is
often much smaller than expected. These findings pave way for simpler and
potentially more privacy-preserving tokenization schemes that do not
catastrophically compromise model performance.

</details>


### [230] [Measuring Stereotype and Deviation Biases in Large Language Models](https://arxiv.org/abs/2508.06649)
*Daniel Wang,Eli Brignac,Minjia Mao,Xiao Fang*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）表现出的刻板偏见和偏离偏见，实验表明所有研究的LLMs在多个群体中均存在显著的偏见问题。


<details>
  <summary>Details</summary>
Motivation: 由于LLMs被广泛应用，但其局限性和潜在风险引发了人们的担忧。本文旨在揭示和分析LLMs在生成内容时可能存在的两种偏见：刻板偏见和偏离偏见。

Method: 通过让四个高级LLMs生成个人档案，分析每个群体与特定属性（如政治倾向、宗教信仰、性取向）之间的关联，评估其偏见。

Result: 实验结果显示，所有被研究的LLMs在多个群体中均表现出显著的刻板偏见和偏离偏见。

Conclusion: 研究阐明了LLMs在用户属性推断中可能出现的偏见，并揭示了LLM生成内容潜在的危害性。

Abstract: Large language models (LLMs) are widely applied across diverse domains,
raising concerns about their limitations and potential risks. In this study, we
investigate two types of bias that LLMs may display: stereotype bias and
deviation bias. Stereotype bias refers to when LLMs consistently associate
specific traits with a particular demographic group. Deviation bias reflects
the disparity between the demographic distributions extracted from
LLM-generated content and real-world demographic distributions. By asking four
advanced LLMs to generate profiles of individuals, we examine the associations
between each demographic group and attributes such as political affiliation,
religion, and sexual orientation. Our experimental results show that all
examined LLMs exhibit both significant stereotype bias and deviation bias
towards multiple groups. Our findings uncover the biases that occur when LLMs
infer user attributes and shed light on the potential harms of LLM-generated
outputs.

</details>


### [231] [Testing the Limits of Machine Translation from One Book](https://arxiv.org/abs/2508.06665)
*Jonathan Shaw,Dillon Mee,Timothy Khouw,Zackary Leech,Daniel Wilson*

Main category: cs.CL

TL;DR: 该研究针对资源有限的Kanuri语言，探讨了大语言模型在不同语料条件下的翻译表现，结果表明，平行句子是提升翻译质量的最有效资源，而仅依靠语法信息效果有限。


<details>
  <summary>Details</summary>
Motivation: 尽管Kanuri语言的使用人口较多，但数字资源稀缺。研究旨在探索如何通过不同的语言资源组合（语法、字典和平行句子）提升LLM的翻译质量，特别是在领域特定任务中的表现。

Method: 设计了两个专门的数据集（健康与人道主义术语，以及通用术语），通过提供多种语言资源组合来测试LLM的翻译性能。性能评估包括自动化指标和母语者对流畅性与准确性的评价。

Result: 结果显示，平行句子是最有效的翻译数据源，大幅优于其他方法。虽然引入语法可以改进零样本翻译，但单独使用语法无法达到有效的翻译质量。人工评价发现，LLMs在传达意义上表现更为优异，而在语法流畅性上相对不足。

Conclusion: 研究表明，多维度评估（流畅性与准确性）对LLM翻译能力的衡量更为重要。此外，仅依赖语法信息不足以提供足够的语境，用于支持领域特定翻译工作的进行。

Abstract: Current state-of-the-art models demonstrate capacity to leverage in-context
learning to translate into previously unseen language contexts. Tanzer et al.
[2024] utilize language materials (e.g. a grammar) to improve translation
quality for Kalamang using large language models (LLMs). We focus on Kanuri, a
language that, despite having substantial speaker population, has minimal
digital resources. We design two datasets for evaluation: one focused on health
and humanitarian terms, and another containing generalized terminology,
investigating how domain-specific tasks impact LLM translation quality.
  By providing different combinations of language resources (grammar,
dictionary, and parallel sentences), we measure LLM translation effectiveness,
comparing results to native speaker translations and human linguist
performance. We evaluate using both automatic metrics and native speaker
assessments of fluency and accuracy.
  Results demonstrate that parallel sentences remain the most effective data
source, outperforming other methods in human evaluations and automatic metrics.
While incorporating grammar improves over zero-shot translation, it fails as an
effective standalone data source. Human evaluations reveal that LLMs achieve
accuracy (meaning) more effectively than fluency (grammaticality).
  These findings suggest LLM translation evaluation benefits from
multidimensional assessment beyond simple accuracy metrics, and that grammar
alone, without parallel sentences, does not provide sufficient context for
effective domain-specific translation.

</details>


### [232] [Do Biased Models Have Biased Thoughts?](https://arxiv.org/abs/2508.06671)
*Swati Rajwal,Shivank Garg,Reem Abdel-Salam,Abdelrahman Zayed*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型生成过程中"思考链"的偏见和其输出偏见之间的关联性，发现二者相关性较低。


<details>
  <summary>Details</summary>
Motivation: 虽然语言模型的表现令人惊叹，但其存在的性别、种族、经济地位、外貌和性取向等偏见问题使实际应用面临挑战。作者希望通过研究"思考链"对公平性的影响来理解偏见问题。

Method: 对五种大型语言模型进行实验，使用公平性指标量化模型在'思考链'和输出中11种不同偏见的表现，并分析二者的相关性。

Result: 结果显示模型'思考链'中的偏见与输出偏见的相关性较低，相关系数小于0.6，且$p$-值小于0.001。

Conclusion: 相比于人类，被测试的偏向性模型并不总是具有对应的偏向性思考。这为理解语言模型中的偏见提供了新的视角。

Abstract: The impressive performance of language models is undeniable. However, the
presence of biases based on gender, race, socio-economic status, physical
appearance, and sexual orientation makes the deployment of language models
challenging. This paper studies the effect of chain-of-thought prompting, a
recent approach that studies the steps followed by the model before it
responds, on fairness. More specifically, we ask the following question:
\textit{Do biased models have biased thoughts}? To answer our question, we
conduct experiments on $5$ popular large language models using fairness metrics
to quantify $11$ different biases in the model's thoughts and output. Our
results show that the bias in the thinking steps is not highly correlated with
the output bias (less than $0.6$ correlation with a $p$-value smaller than
$0.001$ in most cases). In other words, unlike human beings, the tested models
with biased decisions do not always possess biased thoughts.

</details>


### [233] [Play Favorites: A Statistical Method to Measure Self-Bias in LLM-as-a-Judge](https://arxiv.org/abs/2508.06709)
*Evangelia Spiliopoulou,Riccardo Fogliato,Hanna Burnsky,Tamer Soliman,Jie Ma,Graham Horwood,Miguel Ballesteros*

Main category: cs.CL

TL;DR: 研究语言大模型(LLMs)作为评判者时可能存在的自我偏见现象，并提出了一种统计方法来检测和量化这些偏见。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在评估自身输出时，可能存在因自我偏见而导致不准确评价的现象，这种偏差可能影响模型性能的真实评估。

Method: 提出了一种统计框架，建模LLM评估自身与其他模型输出评分分布的差异，同时通过第三方评判者（人类）提供的独立质量评估数据控制变因，确保对自我偏见的可靠识别与量化。

Result: 通过超过5000组提示-完成对的数据以及9种LLM模型的分析，发现如GPT-4o和Claude 3.5等模型对自身的输出评分更高，还存在“家族偏见”现象。

Conclusion: 研究揭示了使用LLM作为评判者时的潜在风险，并提供了缓解和纠正评估偏见的实用建议。

Abstract: Large language models (LLMs) can serve as judges that offer rapid and
reliable assessments of other LLM outputs. However, models may systematically
assign overly favorable ratings to their own outputs, a phenomenon known as
self-bias, which can distort evaluations of true model performance. Previous
studies often conflate genuine differences in model quality with bias or
incorrectly assume that evaluations from LLMs and humans follow the same rating
distributions. In this work, we present a statistical framework that explicitly
formalizes assumptions under which self-bias can be identified and estimated.
Our method models the difference in the scoring distribution that
LLM-as-a-judge assigns to its own completions compared to other models, while
accounting for the underlying quality of the completions provided by an
independent, third-party judge (e.g., humans). Our method reliably isolates and
quantifies self-bias, even when models vary in ability, ensuring that genuine
performance differences are not mistaken for self-bias. We conduct an empirical
analysis of self-bias on a large dataset (>5000 prompt-completion pairs)
consisting of expert human annotations and judgments from nine different LLM
judges. We find that some models, such as GPT-4o and Claude 3.5 Sonnet,
systematically assign higher scores to their own outputs. These models also
display family-bias; systematically assigning higher ratings to outputs
produced by other models of the same family. Our findings highlight potential
pitfalls of using LLM judges and offer practical guidance to mitigate biases
when interpreting automated evaluations.

</details>


### [234] [Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis](https://arxiv.org/abs/2508.06729)
*Komala Subramanyam Cherukuri,Pranav Abishai Moses,Aisa Sakata,Jiangping Chen,Haihua Chen*

Main category: cs.CL

TL;DR: 本文提出了一个可扩展的框架，使用大型语言模型(LLMs)对日本裔美国人拘留的口述历史进行语义和情感注释，从而实现大规模分析。


<details>
  <summary>Details</summary>
Motivation: 由于口述历史档案的非结构化格式、情感复杂性和高注释成本，大规模分析受到限制。本文旨在提供一种自动化方法，同时注重历史敏感性。

Method: 结合专家注释、提示设计和LLM评估，使用ChatGPT、Llama和Qwen模型标记语义和情感类别，并测试了零样本、少样本及RAG策略。

Result: ChatGPT在语义分类中表现最佳(F1=88.71%)，而Llama在情感分析中略胜一筹(82.66%)。使用最佳提示配置对92,191句子进行注释。

Conclusion: 研究表明，基于设计良好的提示，LLMs能够高效地对大规模口述史料进行注释，为数字人文学科和集体记忆保存中的人工智能应用提供了负责的实践指南。

Abstract: Oral histories are vital records of lived experience, particularly within
communities affected by systemic injustice and historical erasure. Effective
and efficient analysis of their oral history archives can promote access and
understanding of the oral histories. However, Large-scale analysis of these
archives remains limited due to their unstructured format, emotional
complexity, and high annotation costs. This paper presents a scalable framework
to automate semantic and sentiment annotation for Japanese American
Incarceration Oral History. Using LLMs, we construct a high-quality dataset,
evaluate multiple models, and test prompt engineering strategies in
historically sensitive contexts. Our multiphase approach combines expert
annotation, prompt design, and LLM evaluation with ChatGPT, Llama, and Qwen. We
labeled 558 sentences from 15 narrators for sentiment and semantic
classification, then evaluated zero-shot, few-shot, and RAG strategies. For
semantic classification, ChatGPT achieved the highest F1 score (88.71%),
followed by Llama (84.99%) and Qwen (83.72%). For sentiment analysis, Llama
slightly outperformed Qwen (82.66%) and ChatGPT (82.29%), with all models
showing comparable results. The best prompt configurations were used to
annotate 92,191 sentences from 1,002 interviews in the JAIOH collection. Our
findings show that LLMs can effectively perform semantic and sentiment
annotation across large oral history collections when guided by well-designed
prompts. This study provides a reusable annotation pipeline and practical
guidance for applying LLMs in culturally sensitive archival analysis. By
bridging archival ethics with scalable NLP techniques, this work lays the
groundwork for responsible use of artificial intelligence in digital humanities
and preservation of collective memory. GitHub:
https://github.com/kc6699c/LLM4OralHistoryAnalysis.

</details>


### [235] [Many-Turn Jailbreaking](https://arxiv.org/abs/2508.06755)
*Xianjun Yang,Liqiang Xiao,Shiyang Li,Faisal Ladhak,Hyokun Yun,Linda Ruth Petzold,Yi Xu,William Yang Wang*

Main category: cs.CL

TL;DR: 提出了一个新的多轮越狱基准 (MTJ-Bench) 用于检测和分析大型语言模型在多轮对话中的越狱漏洞。


<details>
  <summary>Details</summary>
Motivation: 目前的越狱研究仅仅聚焦于单轮对话，而大型语言模型具备处理长上下文和多轮对话的能力。用户往往会在初次越狱后继续提问，这导致多轮对话中的越狱问题成为一个更为严重的安全隐患。

Method: 构建了一个名为MTJ-Bench的多轮越狱基准，并用其对开源和闭源模型进行了评估，以揭示多轮越狱中的潜在威胁。

Result: 通过评估和分析表明，多个模型在多轮对话中都存在越狱风险，验证了多轮越狱漏洞的存在。

Conclusion: 多轮对话中的越狱漏洞是未来需要重点解决的模型安全问题，研究呼吁社区共同努力，开发更安全的语言模型。

Abstract: Current jailbreaking work on large language models (LLMs) aims to elicit
unsafe outputs from given prompts. However, it only focuses on single-turn
jailbreaking targeting one specific query. On the contrary, the advanced LLMs
are designed to handle extremely long contexts and can thus conduct multi-turn
conversations. So, we propose exploring multi-turn jailbreaking, in which the
jailbroken LLMs are continuously tested on more than the first-turn
conversation or a single target query. This is an even more serious threat
because 1) it is common for users to continue asking relevant follow-up
questions to clarify certain jailbroken details, and 2) it is also possible
that the initial round of jailbreaking causes the LLMs to respond to additional
irrelevant questions consistently. As the first step (First draft done at June
2024) in exploring multi-turn jailbreaking, we construct a Multi-Turn Jailbreak
Benchmark (MTJ-Bench) for benchmarking this setting on a series of open- and
closed-source models and provide novel insights into this new safety threat. By
revealing this new vulnerability, we aim to call for community efforts to build
safer LLMs and pave the way for a more in-depth understanding of jailbreaking
LLMs.

</details>


### [236] [SEVADE: Self-Evolving Multi-Agent Analysis with Decoupled Evaluation for Hallucination-Resistant Irony Detection](https://arxiv.org/abs/2508.06803)
*Ziqi Liu,Yangbin Chen,Ziyang Zhou,Yilin Li,Mingxuan Hu,Yushan Pan,Zhijie Xu*

Main category: cs.CL

TL;DR: 提议了一个新的框架SEVADE，以解决现有讽刺检测中模型面对复杂讽刺语言时的准确性问题，主要通过分离复杂推理和最终判断达到更稳健的表现。


<details>
  <summary>Details</summary>
Motivation: 现有模型受限于单一视角分析、固定推理路径，并且在处理复杂讽刺语言时容易产生幻觉（hallucination），导致准确性和可靠性不足。

Method: 提出了SEVADE框架，核心为动态代理推理引擎（DARE），利用基于语言学理论的多个专用代理以多方面解构文本，并生成结构化的推理链，最后通过分离的轻量化理由裁定器(RA)仅基于该推理链进行分类。

Result: 在四个基准数据集上的实验中，SEVADE框架在准确率上平均提升6.75%，Macro-F1分数上平均提升6.29%。

Conclusion: 证明了SEVADE能够在讽刺检测中取得更高性能，同时通过解耦框架有效减少了幻觉的影响，提高了模型的稳健性和可靠性。

Abstract: Sarcasm detection is a crucial yet challenging Natural Language Processing
task. Existing Large Language Model methods are often limited by
single-perspective analysis, static reasoning pathways, and a susceptibility to
hallucination when processing complex ironic rhetoric, which impacts their
accuracy and reliability. To address these challenges, we propose **SEVADE**, a
novel **S**elf-**Ev**olving multi-agent **A**nalysis framework with
**D**ecoupled **E**valuation for hallucination-resistant sarcasm detection. The
core of our framework is a Dynamic Agentive Reasoning Engine (DARE), which
utilizes a team of specialized agents grounded in linguistic theory to perform
a multifaceted deconstruction of the text and generate a structured reasoning
chain. Subsequently, a separate lightweight rationale adjudicator (RA) performs
the final classification based solely on this reasoning chain. This decoupled
architecture is designed to mitigate the risk of hallucination by separating
complex reasoning from the final judgment. Extensive experiments on four
benchmark datasets demonstrate that our framework achieves state-of-the-art
performance, with average improvements of **6.75%** in Accuracy and **6.29%**
in Macro-F1 score.

</details>


### [237] [Annotating Errors in English Learners' Written Language Production: Advancing Automated Written Feedback Systems](https://arxiv.org/abs/2508.06810)
*Steven Coyne,Diana Galvan-Sosa,Ryan Spring,Camélia Guerraoui,Michael Zock,Keisuke Sakaguchi,Kentaro Inui*

Main category: cs.CL

TL;DR: 本文探讨了如何利用大型语言模型（LLM）为语言学习者生成自动化反馈，以改进现有的语法自动评估系统（AWE），并提出了一套新的标注框架和数据集以支持此目的。


<details>
  <summary>Details</summary>
Motivation: 现有的自动写作评估系统虽能有效改善文本质量，但在语言学习方面并不理想，缺乏对学习者知识差距的关注，也未能为不同类型的错误提供合适的间接提示和解释。

Method: 提出一个标注框架，包括错误类型和错误的可推广性，利用此框架构建了标注数据集。接着，使用LLM对生成的反馈方法（如关键词引导与模板引导）进行验证和比较研究，并通过人类教师对生成反馈进行评估。

Result: 通过比较不同反馈生成策略的性能，数据分析表明，利用此框架标注的数据能有效训练出更适合语言学习者的反馈生成方法，结果获得教师在相关性、真实性和可理解性等方面的积极评价。

Conclusion: 引入了一个新的方法，不仅能生成更适合语言学习者的反馈，还为改进基于LLM的语言教育工具提供了数据支持和新的思路。

Abstract: Recent advances in natural language processing (NLP) have contributed to the
development of automated writing evaluation (AWE) systems that can correct
grammatical errors. However, while these systems are effective at improving
text, they are not optimally designed for language learning. They favor direct
revisions, often with a click-to-fix functionality that can be applied without
considering the reason for the correction. Meanwhile, depending on the error
type, learners may benefit most from simple explanations and strategically
indirect hints, especially on generalizable grammatical rules. To support the
generation of such feedback, we introduce an annotation framework that models
each error's error type and generalizability. For error type classification, we
introduce a typology focused on inferring learners' knowledge gaps by
connecting their errors to specific grammatical patterns. Following this
framework, we collect a dataset of annotated learner errors and corresponding
human-written feedback comments, each labeled as a direct correction or hint.
With this data, we evaluate keyword-guided, keyword-free, and template-guided
methods of generating feedback using large language models (LLMs). Human
teachers examined each system's outputs, assessing them on grounds including
relevance, factuality, and comprehensibility. We report on the development of
the dataset and the comparative performance of the systems investigated.

</details>


### [238] [Text to Speech System for Meitei Mayek Script](https://arxiv.org/abs/2508.06870)
*Gangular Singh Irengbam,Nirvash Singh Wahengbam,Lanthoiba Meitei Khumanthem,Paikhomba Oinam*

Main category: cs.CL

TL;DR: 本文开发了一种基于Tacotron 2和HiFi-GAN的Manipuri语言文字转语音（TTS）系统，支持Meitei Mayek文字符号及语音合成。


<details>
  <summary>Details</summary>
Motivation: 针对Manipuri语言的声音特性及缺乏资源的语言环境提出有效的TTS解决方案，促进语言保护及技术普及。

Method: 采用Tacotron 2及HiFi-GAN架构，构建适配Manipuri语言的神经TTS系统；完成Meitei Mayek到ARPAbet的对应映射，并打造单人语音数据集。

Result: 生成出清晰自然的合成语音，并通过主观和客观指标验证了系统的表现效果。

Conclusion: 该系统为Manipuri语言的保护及其技术应用铺平了道路。

Abstract: This paper presents the development of a Text-to-Speech (TTS) system for the
Manipuri language using the Meitei Mayek script. Leveraging Tacotron 2 and
HiFi-GAN, we introduce a neural TTS architecture adapted to support tonal
phonology and under-resourced linguistic environments. We develop a phoneme
mapping for Meitei Mayek to ARPAbet, curate a single-speaker dataset, and
demonstrate intelligible and natural speech synthesis, validated through
subjective and objective metrics. This system lays the groundwork for
linguistic preservation and technological inclusion of Manipuri.

</details>


### [239] [ESNERA: Empirical and semantic named entity alignment for named entity dataset merging](https://arxiv.org/abs/2508.06877)
*Xiaobo Zhang,Congqing He,Ying He,Jian Peng,Dajie Fu,Tien-Ping Tan*

Main category: cs.CL

TL;DR: 本文提出了一种基于标签相似度的自动标签对齐方法，以统一来自不同数据集的标签空间，并提升NER应用的实际效果。


<details>
  <summary>Details</summary>
Motivation: 现有的NER方法严重依赖大规模、高质量的标注数据集，而构建这些数据集非常昂贵且耗时，这是进一步研究的瓶颈；此外，现有数据集合并方法缺乏可解释性和可扩展性，急需更高效透明的解决方案。

Method: 作者提出了一种结合经验和语义相似度的自动标签对齐方法，通过贪婪的对标签两两合并的策略，来统一标签空间，并在两阶段实验中验证了方法的有效性。

Result: 实验结果展示了其方法不仅能有效合并NER数据集，还提升了低资源金融领域的NER性能。

Conclusion: 这项研究提出了一个高效、可解释且具有可扩展性的多源NER数据集整合方案，为低资源领域NER研究提供了重要的启示。

Abstract: Named Entity Recognition (NER) is a fundamental task in natural language
processing. It remains a research hotspot due to its wide applicability across
domains. Although recent advances in deep learning have significantly improved
NER performance, they rely heavily on large, high-quality annotated datasets.
However, building these datasets is expensive and time-consuming, posing a
major bottleneck for further research. Current dataset merging approaches
mainly focus on strategies like manual label mapping or constructing label
graphs, which lack interpretability and scalability. To address this, we
propose an automatic label alignment method based on label similarity. The
method combines empirical and semantic similarities, using a greedy pairwise
merging strategy to unify label spaces across different datasets. Experiments
are conducted in two stages: first, merging three existing NER datasets into a
unified corpus with minimal impact on NER performance; second, integrating this
corpus with a small-scale, self-built dataset in the financial domain. The
results show that our method enables effective dataset merging and enhances NER
performance in the low-resource financial domain. This study presents an
efficient, interpretable, and scalable solution for integrating multi-source
NER corpora.

</details>


### [240] [The ReQAP System for Question Answering over Personal Information](https://arxiv.org/abs/2508.06880)
*Philipp Christmann,Gerhard Weikum*

Main category: cs.CL

TL;DR: ReQAP系统利用轻量级语言模型，通过递归分解复杂问题并构建执行树，处理设备上各种数据并实现复杂问答。


<details>
  <summary>Details</summary>
Motivation: 解决用户设备上杂乱数据的复杂问答需求并提供可追溯性以提高可信度。

Method: 通过递归分解问题，增量构建执行操作树，结合细调轻量级语言模型优化问题解释与操作处理。

Result: 实现了对用户复杂问题的回答功能，并通过执行树增强了答案的可追溯性与可信性。

Conclusion: ReQAP系统提供了有效、透明的复杂问答支持，有助于提升用户对系统的理解和信任。

Abstract: Personal information is abundant on users' devices, from structured data in
calendar, shopping records or fitness tools, to unstructured contents in mail
and social media posts. This works presents the ReQAP system that supports
users with answers for complex questions that involve filters, joins and
aggregation over heterogeneous sources. The unique trait of ReQAP is that it
recursively decomposes questions and incrementally builds an operator tree for
execution. Both the question interpretation and the individual operators make
smart use of light-weight language models, with judicious fine-tuning. The demo
showcases the rich functionality for advanced user questions, and also offers
detailed tracking of how the answers are computed by the operators in the
execution tree. Being able to trace answers back to the underlying sources is
vital for human comprehensibility and user trust in the system.

</details>


### [241] [Score Before You Speak: Improving Persona Consistency in Dialogue Generation using Response Quality Scores](https://arxiv.org/abs/2508.06886)
*Arpita Saggar,Jonathan C. Darling,Vania Dimitrova,Duygu Sarikaya,David C. Hogg*

Main category: cs.CL

TL;DR: 本文讨论了在对话生成中，如何在大规模语言模型中更好地融入人格特征。提出了SBS新方法，大幅提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有对话数据多样性有限，难以高效融入个人语调特性。需要新的方法改进语言模型在对话中的人格一致性。

Method: 提出了SBS框架，将响应学习与质量评估统一。通过名词替换进行数据增强，并用语义相似度得分作为质量指标，在模型训练中加入得分条件。

Result: 在PERSONA-CHAT和ConvAI2基准数据集上实验，证明SBS显著提升了模型捕捉人格一致性对话的能力。消融实验也表明，训练中引入得分显著优于传统方法。

Conclusion: SBS方法显著改进了现有对话生成的效果，对提高对话模型中的人格一致性具有重要意义。

Abstract: Persona-based dialogue generation is an important milestone towards building
conversational artificial intelligence. Despite the ever-improving capabilities
of large language models (LLMs), effectively integrating persona fidelity in
conversations remains challenging due to the limited diversity in existing
dialogue data. We propose a novel framework SBS (Score-Before-Speaking), which
outperforms previous methods and yields improvements for both million and
billion-parameter models. Unlike previous methods, SBS unifies the learning of
responses and their relative quality into a single step. The key innovation is
to train a dialogue model to correlate augmented responses with a quality score
during training and then leverage this knowledge at inference. We use
noun-based substitution for augmentation and semantic similarity-based scores
as a proxy for response quality. Through extensive experiments with benchmark
datasets (PERSONA-CHAT and ConvAI2), we show that score-conditioned training
allows existing models to better capture a spectrum of persona-consistent
dialogues. Our ablation studies also demonstrate that including scores in the
input prompt during training is superior to conventional training setups. Code
and further details are available at
https://arpita2512.github.io/score_before_you_speak

</details>


### [242] [Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection](https://arxiv.org/abs/2508.06913)
*Siyuan Li,Xi Lin,Guangyan Li,Zehao Liu,Aodu Wulianghai,Li Ding,Jun Wu,Jianhua Li*

Main category: cs.CL

TL;DR: 发布了一个名为SentiDetect的新框架，用以检测由大语言模型（LLMs）生成的文本，方法基于情感分布的稳定性差异。


<details>
  <summary>Details</summary>
Motivation: 由于LLM生成的内容变得越来越复杂，现有的检测方法在面对跨领域变化及对抗性扰动时往往不够鲁棒，因此亟需开发更有效的检测工具。

Method: 提出了一个模型无关的分析框架SentiDetect，通过两个指标——情感分布一致性和情感分布保持性，来分析情感分布的稳定性，进而区分人类语言与LLM生成文本。

Result: 在五个数据集及多个先进LLM（包括Gemini-1.5-Pro、Claude-3、GPT-4-0613、LLaMa-3.3）上测试，SentiDetect在F1分值上显著优于当前最先进的模型，同时更抗干扰，表现出色。

Conclusion: SentiDetect是一种新颖且效果更好的LLM生成文本检测方法，提升了准确性与鲁棒性，适合复杂与多样化场景。

Abstract: The rapid advancement of large language models (LLMs) has resulted in
increasingly sophisticated AI-generated content, posing significant challenges
in distinguishing LLM-generated text from human-written language. Existing
detection methods, primarily based on lexical heuristics or fine-tuned
classifiers, often suffer from limited generalizability and are vulnerable to
paraphrasing, adversarial perturbations, and cross-domain shifts. In this work,
we propose SentiDetect, a model-agnostic framework for detecting LLM-generated
text by analyzing the divergence in sentiment distribution stability. Our
method is motivated by the empirical observation that LLM outputs tend to
exhibit emotionally consistent patterns, whereas human-written texts display
greater emotional variability. To capture this phenomenon, we define two
complementary metrics: sentiment distribution consistency and sentiment
distribution preservation, which quantify stability under sentiment-altering
and semantic-preserving transformations. We evaluate SentiDetect on five
diverse datasets and a range of advanced LLMs,including Gemini-1.5-Pro,
Claude-3, GPT-4-0613, and LLaMa-3.3. Experimental results demonstrate its
superiority over state-of-the-art baselines, with over 16% and 11% F1 score
improvements on Gemini-1.5-Pro and GPT-4-0613, respectively. Moreover,
SentiDetect also shows greater robustness to paraphrasing, adversarial attacks,
and text length variations, outperforming existing detectors in challenging
scenarios.

</details>


### [243] [Two-Stage Quranic QA via Ensemble Retrieval and Instruction-Tuned Answer Extraction](https://arxiv.org/abs/2508.06971)
*Mohamed Basem,Islam Oshallah,Ali Hamdi,Khaled Shaban,Hozaifa Kassab*

Main category: cs.CL

TL;DR: 本文提出一种新的双阶段框架用于《古兰经》问题回答：第一阶段通过集成微调阿拉伯语言模型进行段落检索，第二阶段通过少样本提示的指令调优大语言模型进行答案提取，表现优于当前方法。


<details>
  <summary>Details</summary>
Motivation: 解决由古典阿拉伯语的语言复杂性和宗教文本语义丰富性带来的问题回答挑战。

Method: 提出双阶段框架：1. 段落检索阶段，集成微调阿拉伯语言模型以改进排名性能；2. 答案提取阶段，使用指令调优的大语言模型并结合少样本提示。

Result: 在Quran QA 2023任务中取得了领先的成绩，包括MAP@10（0.3128），MRR@10（0.5763）以及提取的pAP@10（0.669），显著优于之前方法。

Conclusion: 本文结合模型集成与指令调优技术，有效解决了在低资源背景下专门领域的QA挑战，证明其方法的有效性。

Abstract: Quranic Question Answering presents unique challenges due to the linguistic
complexity of Classical Arabic and the semantic richness of religious texts. In
this paper, we propose a novel two-stage framework that addresses both passage
retrieval and answer extraction. For passage retrieval, we ensemble fine-tuned
Arabic language models to achieve superior ranking performance. For answer
extraction, we employ instruction-tuned large language models with few-shot
prompting to overcome the limitations of fine-tuning on small datasets. Our
approach achieves state-of-the-art results on the Quran QA 2023 Shared Task,
with a MAP@10 of 0.3128 and MRR@10 of 0.5763 for retrieval, and a pAP@10 of
0.669 for extraction, substantially outperforming previous methods. These
results demonstrate that combining model ensembling and instruction-tuned
language models effectively addresses the challenges of low-resource question
answering in specialized domains.

</details>


### [244] [Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models](https://arxiv.org/abs/2508.06974)
*Zhijun Tu,Hanting Chen,Siqi Liu,Chuanjian Liu,Jian Li,Jie Hu,Yunhe Wang*

Main category: cs.CL

TL;DR: 提出基于一种渐进式的训练方法，将浮点权重平滑地转换成二值化权重，从而能够高效利用预训练模型以生成高性能的1-bit LLM。


<details>
  <summary>Details</summary>
Motivation: 现存的1-bit LLM训练方法需要从头训练，未能有效利用预训练模型，导致高训练成本和明显的精度下降。

Method: 通过一致的渐进式训练方法对前向与后向进行优化，结合二值感知初始化和双尺度补偿，降低渐进式训练难度并提高性能。

Result: 实验表明，提出的方法在任意规模LLMs上优于现有方法，并通过利用预训练模型生成高性能的1-bit LLM而不需要耗资巨大的从头训练。

Conclusion: 高性能的1-bit LLM可以通过预训练模型实现，无需从零训练，且高效、省成本。

Abstract: 1-bit LLM quantization offers significant advantages in reducing storage and
computational costs. However, existing methods typically train 1-bit LLMs from
scratch, failing to fully leverage pre-trained models. This results in high
training costs and notable accuracy degradation. We identify that the large gap
between full precision and 1-bit representations makes direct adaptation
difficult. In this paper, we introduce a consistent progressive training for
both forward and backward, smoothly converting the floating-point weights into
the binarized ones. Additionally, we incorporate binary-aware initialization
and dual-scaling compensation to reduce the difficulty of progressive training
and improve the performance. Experimental results on LLMs of various sizes
demonstrate that our method outperforms existing approaches. Our results show
that high-performance 1-bit LLMs can be achieved using pre-trained models,
eliminating the need for expensive training from scratch.

</details>


### [245] [Vec2Summ: Text Summarization via Probabilistic Sentence Embeddings](https://arxiv.org/abs/2508.07017)
*Mao Li,Fred Conrad,Johann Gagnon-Bartsch*

Main category: cs.CL

TL;DR: Vec2Summ是一个新方法，将抽象摘要任务视为语义压缩，通过语义嵌入空间中的均值向量表示文档，生成语言模型进行解码生成摘要。


<details>
  <summary>Details</summary>
Motivation: 解决当前基于大语言模型摘要方法存在的语境长度限制等问题，实现可解释和可控的语义生成，并能够高效扩展到大规模语料库。

Method: 通过语义嵌入空间的均值向量表征文档集合，使用生成语言模型解码生成，加入高斯分布随机性以提高变异性和输出质量，并实现O(d + d^2)参数的高效扩展。

Result: 与直接基于大语言模型的摘要相比，在主题覆盖和效率方面表现相当，但细粒度细节较少。

Conclusion: Vec2Summ适合需要可扩展性、语义控制和语料库级抽象的场景，展示了其大规模文本摘要的潜力。

Abstract: We propose Vec2Summ, a novel method for abstractive summarization that frames
the task as semantic compression. Vec2Summ represents a document collection
using a single mean vector in the semantic embedding space, capturing the
central meaning of the corpus. To reconstruct fluent summaries, we perform
embedding inversion -- decoding this mean vector into natural language using a
generative language model. To improve reconstruction quality and capture some
degree of topical variability, we introduce stochasticity by sampling from a
Gaussian distribution centered on the mean. This approach is loosely analogous
to bagging in ensemble learning, where controlled randomness encourages more
robust and varied outputs. Vec2Summ addresses key limitations of LLM-based
summarization methods. It avoids context-length constraints, enables
interpretable and controllable generation via semantic parameters, and scales
efficiently with corpus size -- requiring only $O(d + d^2)$ parameters.
Empirical results show that Vec2Summ produces coherent summaries for topically
focused, order-invariant corpora, with performance comparable to direct LLM
summarization in terms of thematic coverage and efficiency, albeit with less
fine-grained detail. These results underscore Vec2Summ's potential in settings
where scalability, semantic control, and corpus-level abstraction are
prioritized.

</details>


### [246] [SEADialogues: A Multilingual Culturally Grounded Multi-turn Dialogue Dataset on Southeast Asian Languages](https://arxiv.org/abs/2508.07069)
*Muhammad Dehan Al Kautsar,Aswin Candra,Muhammad Alif Al Hakim,Maxalmina Satria Kahfi,Fajri Koto,Alham Fikri Aji,Peerat Limkonchotiwat,Ekapol Chuangsuwanich,Genta Indra Winata*

Main category: cs.CL

TL;DR: 提出了一个名为SEADialogues的数据集，以涵盖东南亚地区多语言对话中的文化差异。


<details>
  <summary>Details</summary>
Motivation: 现有的闲聊式对话数据集忽略了对话中的文化细微差别，需要一个关注文化背景的数据集来进一步推动跨文化对话系统研究。

Method: 创建了一个多语言对话数据集SEADialogues，涵盖八种语言，包含用户特征及文化相关的话题，重点在东南亚地区的文化背景。

Result: SEADialogues提供具有东南亚文化地位的多回合对话数据集，可用于研发更具文化感知能力的大型对话语言模型。

Conclusion: 该数据集填补了多样化文化背景对话数据的空白，为构建文化和人类导向的对话系统提供了重要资源。

Abstract: Although numerous datasets have been developed to support dialogue systems,
most existing chit-chat datasets overlook the cultural nuances inherent in
natural human conversations. To address this gap, we introduce SEADialogues, a
culturally grounded dialogue dataset centered on Southeast Asia, a region with
over 700 million people and immense cultural diversity. Our dataset features
dialogues in eight languages from six Southeast Asian countries, many of which
are low-resource despite having sizable speaker populations. To enhance
cultural relevance and personalization, each dialogue includes persona
attributes and two culturally grounded topics that reflect everyday life in the
respective communities. Furthermore, we release a multi-turn dialogue dataset
to advance research on culturally aware and human-centric large language
models, including conversational dialogue agents.

</details>


### [247] [BharatBBQ: A Multilingual Bias Benchmark for Question Answering in the Indian Context](https://arxiv.org/abs/2508.07090)
*Aditya Tomar,Nihar Ranjan Sahoo,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 研究提出了一个适用于印度背景的基准测试BharatBBQ，用于评估多语言模型在偏见问题上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的偏见评估基准测试主要针对西方背景，不适用于印度的文化和社会环境，因此需要一个新的基准来进行公平性评估。

Method: 设计了一个覆盖13个社会类别、拥有392,864个多语言样本（通过翻译和验证扩展）的数据集，用于分析多语言模型在零样本和少样本设置下的偏见表现。

Result: 评估发现多语言模型在语言和社会类别上普遍存在偏见，某些情况下印度语言中的偏见比英语更为显著。

Conclusion: 研究表明需要构建基于语言和文化的基准测试以更有效地评估偏见问题。

Abstract: Evaluating social biases in language models (LMs) is crucial for ensuring
fairness and minimizing the reinforcement of harmful stereotypes in AI systems.
Existing benchmarks, such as the Bias Benchmark for Question Answering (BBQ),
primarily focus on Western contexts, limiting their applicability to the Indian
context. To address this gap, we introduce BharatBBQ, a culturally adapted
benchmark designed to assess biases in Hindi, English, Marathi, Bengali, Tamil,
Telugu, Odia, and Assamese. BharatBBQ covers 13 social categories, including 3
intersectional groups, reflecting prevalent biases in the Indian sociocultural
landscape. Our dataset contains 49,108 examples in one language that are
expanded using translation and verification to 392,864 examples in eight
different languages. We evaluate five multilingual LM families across zero and
few-shot settings, analyzing their bias and stereotypical bias scores. Our
findings highlight persistent biases across languages and social categories and
often amplified biases in Indian languages compared to English, demonstrating
the necessity of linguistically and culturally grounded benchmarks for bias
evaluation.

</details>


### [248] [Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning](https://arxiv.org/abs/2508.07101)
*Lijie Yang,Zhihao Zhang,Arti Jain,Shijie Cao,Baihong Yuan,Yiwei Chen,Zhihao Jia,Ravi Netravali*

Main category: cs.CL

TL;DR: LessIsMore是一种无需重新训练的稀疏注意力机制，可以减少计算成本，提高推理任务效率，同时保持或提升模型准确性。


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型在短输入提示处理时成本高的问题，特别是关注稀疏注意力机制的潜力及其在长生成推理中的准确性挑战。

Method: 提出LessIsMore，通过结合局部注意头的选择和上下文信息，创建统一的跨头token排名来改进选择机制，减少对单独头部优化的依赖。

Result: LessIsMore在减少关注token数量至2倍的情况下无准确性损失，实现了整体1.13倍的端到端加速，并在多项推理任务中达到了与全注意力机制相当或更高的准确性。

Conclusion: LessIsMore在无需重新训练的情况下，通过改进稀疏注意力设计，实现了推理性能的提升和计算成本的降低，展示了高效解决传统方法局限性的潜力。

Abstract: Large reasoning models achieve strong performance through test-time scaling
but incur substantial computational overhead, particularly from excessive token
generation when processing short input prompts. While sparse attention
mechanisms can reduce latency and memory usage, existing approaches suffer from
significant accuracy degradation due to accumulated errors during
long-generation reasoning. These methods generally require either high token
retention rates or expensive retraining. We introduce LessIsMore, a
training-free sparse attention mechanism for reasoning tasks, which leverages
global attention patterns rather than relying on traditional head-specific
local optimizations. LessIsMore aggregates token selections from local
attention heads with recent contextual information, enabling unified cross-head
token ranking for future decoding layers. This unified selection improves
generalization and efficiency by avoiding the need to maintain separate token
subsets per head. Evaluation across diverse reasoning tasks and benchmarks
shows that LessIsMore preserves -- and in some cases improves -- accuracy while
achieving a $1.1\times$ average decoding speed-up compared to full attention.
Moreover, LessIsMore attends to $2\times$ fewer tokens without accuracy loss,
achieving a $1.13\times$ end-to-end speed-up compared to existing sparse
attention methods.

</details>


### [249] [Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution](https://arxiv.org/abs/2508.07111)
*Falaah Arif Khan,Nivedha Sivakumar,Yinong Oliver Wang,Katherine Metcalf,Cezanne Camacho,Barry-John Theobald,Luca Zappella,Nicholas Apostoloff*

Main category: cs.CL

TL;DR: 本文提出了一种新方法来衡量大型语言模型（LLMs）中的交叉性偏差，尤其关注基于多个身份属性的偏差。提出了新的基准数据集WinoIdentity，结合‘共指置信度差异’指标评估模型。结果揭示LLMs对一些交叉身份的置信度较低，甚至对于特权群体也表现不佳。


<details>
  <summary>Details</summary>
Motivation: 研究动机是揭示并深入分析大型语言模型在交叉性身份（intersectional identities）上的偏差问题，尤其是在关键的决策支持场景中可能导致的社会偏差和伤害。

Method: 通过扩展现有的WinoBias数据集，加入10个属性（如年龄、种族、国籍等）和二元性别交叉，生成245,700条提示，构建WinoIdentity基准，并提出了‘共指置信度差异’这一新衡量指标。

Result: 实验表明五个现有LLMs在不同交叉人口属性下的置信度相差高达40%，对于反立体偏见设置中的双重弱势身份表现尤为不确定，此外也发现了对特权标志身份的不确定性增加。

Conclusion: LLMs的性能可能更多依赖‘记忆化’而非逻辑推理，存在价值对齐和有效性两方面的独立失败。这些失败可能导致多重形式的社会危害，需进一步优化以减轻偏差。

Abstract: Large language models (LLMs) have achieved impressive performance, leading to
their widespread adoption as decision-support tools in resource-constrained
contexts like hiring and admissions. There is, however, scientific consensus
that AI systems can reflect and exacerbate societal biases, raising concerns
about identity-based harm when used in critical social contexts. Prior work has
laid a solid foundation for assessing bias in LLMs by evaluating demographic
disparities in different language reasoning tasks. In this work, we extend
single-axis fairness evaluations to examine intersectional bias, recognizing
that when multiple axes of discrimination intersect, they create distinct
patterns of disadvantage. We create a new benchmark called WinoIdentity by
augmenting the WinoBias dataset with 25 demographic markers across 10
attributes, including age, nationality, and race, intersected with binary
gender, yielding 245,700 prompts to evaluate 50 distinct bias patterns.
Focusing on harms of omission due to underrepresentation, we investigate bias
through the lens of uncertainty and propose a group (un)fairness metric called
Coreference Confidence Disparity which measures whether models are more or less
confident for some intersectional identities than others. We evaluate five
recently published LLMs and find confidence disparities as high as 40% along
various demographic attributes including body type, sexual orientation and
socio-economic status, with models being most uncertain about
doubly-disadvantaged identities in anti-stereotypical settings. Surprisingly,
coreference confidence decreases even for hegemonic or privileged markers,
indicating that the recent impressive performance of LLMs is more likely due to
memorization than logical reasoning. Notably, these are two independent
failures in value alignment and validity that can compound to cause social
harm.

</details>


### [250] [Fairness of Automatic Speech Recognition: Looking Through a Philosophical Lens](https://arxiv.org/abs/2508.07143)
*Anna Seo Gyeong Choi,Hoon Choi*

Main category: cs.CL

TL;DR: 该论文探讨了自动语音识别（ASR）系统的偏见问题，强调其不仅是技术局限，还涉及对边缘化语言群体的不尊重。研究指出，ASR偏差可能加剧对这些群体的社会不公。


<details>
  <summary>Details</summary>
Motivation: 旨在揭示ASR系统偏见对社会公平性和被边缘化语言群体的潜在影响，并通过哲学视角探讨偏见的伦理维度。

Method: 通过区分中性分类和有害歧视，分析ASR系统对非标准方言的系统性错误识别对语言多样性和个人身份的影响，并讨论当前技术方法中的问题。

Result: 指出了ASR系统偏见带来的具体伦理问题（如时间负担、对话中断和身份连接），并认为现行技术公平指标难以反映这些问题的本质。

Conclusion: 认为解决ASR偏见需超越技术干预，需从哲学角度重新定义语言多样性的重要性，并推动尊重语言多样性和发言人自主权的系统开发。

Abstract: Automatic Speech Recognition (ASR) systems now mediate countless
human-technology interactions, yet research on their fairness implications
remains surprisingly limited. This paper examines ASR bias through a
philosophical lens, arguing that systematic misrecognition of certain speech
varieties constitutes more than a technical limitation -- it represents a form
of disrespect that compounds historical injustices against marginalized
linguistic communities. We distinguish between morally neutral classification
(discriminate1) and harmful discrimination (discriminate2), demonstrating how
ASR systems can inadvertently transform the former into the latter when they
consistently misrecognize non-standard dialects. We identify three unique
ethical dimensions of speech technologies that differentiate ASR bias from
other algorithmic fairness concerns: the temporal burden placed on speakers of
non-standard varieties ("temporal taxation"), the disruption of conversational
flow when systems misrecognize speech, and the fundamental connection between
speech patterns and personal/cultural identity. These factors create asymmetric
power relationships that existing technical fairness metrics fail to capture.
The paper analyzes the tension between linguistic standardization and pluralism
in ASR development, arguing that current approaches often embed and reinforce
problematic language ideologies. We conclude that addressing ASR bias requires
more than technical interventions; it demands recognition of diverse speech
varieties as legitimate forms of expression worthy of technological
accommodation. This philosophical reframing offers new pathways for developing
ASR systems that respect linguistic diversity and speaker autonomy.

</details>


### [251] [Gradient Surgery for Safe LLM Fine-Tuning](https://arxiv.org/abs/2508.07172)
*Biao Yi,Jiahao Li,Baolei Zhang,Lihai Nie,Tong Li,Tiansheng Huang,Zheli Liu*

Main category: cs.CL

TL;DR: 研究揭示了在大语言模型(LLM)的微调过程中的安全漏洞，并提出了一种名为SafeGrad的新方法，通过梯度投影解决安全与任务目标冲突问题。


<details>
  <summary>Details</summary>
Motivation: 微调服务可能带来严重的安全风险，一个混入恶意样本的微调数据集即可破坏LLM的安全性，对现有优化方案进行改进迫在眉睫。

Method: 提出SafeGrad方法，利用梯度手术技术检测并投影有害任务梯度，同时通过KL散度对齐损失增强安全性和数据效率。

Result: SafeGrad在多个LLM和数据集上的实验中表现出色，即使在高有害样本比率下，依旧能够保持任务与安全的双重鲁棒性。

Conclusion: SafeGrad有效解决了安全与用户任务目标之间的冲突问题，为LLM微调的安全性提供了强有力的支持。

Abstract: Fine-tuning-as-a-Service introduces a critical vulnerability where a few
malicious examples mixed into the user's fine-tuning dataset can compromise the
safety alignment of Large Language Models (LLMs). While a recognized paradigm
frames safe fine-tuning as a multi-objective optimization problem balancing
user task performance with safety alignment, we find existing solutions are
critically sensitive to the harmful ratio, with defenses degrading sharply as
harmful ratio increases. We diagnose that this failure stems from conflicting
gradients, where the user-task update directly undermines the safety objective.
To resolve this, we propose SafeGrad, a novel method that employs gradient
surgery. When a conflict is detected, SafeGrad nullifies the harmful component
of the user-task gradient by projecting it onto the orthogonal plane of the
alignment gradient, allowing the model to learn the user's task without
sacrificing safety. To further enhance robustness and data efficiency, we
employ a KL-divergence alignment loss that learns the rich, distributional
safety profile of the well-aligned foundation model. Extensive experiments show
that SafeGrad provides state-of-the-art defense across various LLMs and
datasets, maintaining robust safety even at high harmful ratios without
compromising task fidelity.

</details>


### [252] [Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models](https://arxiv.org/abs/2508.07173)
*Leyi Pan,Zheyu Fu,Yunpeng Zhai,Shuchang Tao,Sheng Guan,Shiyu Huang,Lingzhe Zhang,Zhaoyang Liu,Bolin Ding,Felix Henry,Lijie Wen,Aiwei Liu*

Main category: cs.CL

TL;DR: 本文提出了Omni-SafetyBench，一个全面的评价Omni-modal Large Language Models (OLLMs)安全性能的基准工具，填补了现有评估方法的空白。


<details>
  <summary>Details</summary>
Motivation: 随着OLLMs的兴起，整合视觉、听觉和文本的能力催生了对更全面安全性评估的需求，以减少有害输出。但现有的评估基准无法有效应对音视频组合输入或跨模态安全一致性。

Method: 提出Omni-SafetyBench评估工具，包括24种组合与972样本，针对音视频等复杂输入设计的全新安全指标：C-ASR、C-RR和CMSC-score，着重于理解失败及跨模态一致性。

Result: 对6个开源和4个闭源模型的测试显示：1) 无模型在安全性与一致性上同时表现出色；2) 复杂输入显著削弱了安全防御；3) 某些模态上的分值低至0.14，存在重大安全漏洞。

Conclusion: 本研究通过揭示OLLMs的安全性缺陷，强调了改进的必要性，提供了一个改进安全性的基础工具。

Abstract: The rise of Omni-modal Large Language Models (OLLMs), which integrate visual
and auditory processing with text, necessitates robust safety evaluations to
mitigate harmful outputs. However, no dedicated benchmarks currently exist for
OLLMs, and prior benchmarks designed for other LLMs lack the ability to assess
safety performance under audio-visual joint inputs or cross-modal safety
consistency. To fill this gap, we introduce Omni-SafetyBench, the first
comprehensive parallel benchmark for OLLM safety evaluation, featuring 24
modality combinations and variations with 972 samples each, including dedicated
audio-visual harm cases. Considering OLLMs' comprehension challenges with
complex omni-modal inputs and the need for cross-modal consistency evaluation,
we propose tailored metrics: a Safety-score based on conditional Attack Success
Rate (C-ASR) and Refusal Rate (C-RR) to account for comprehension failures, and
a Cross-Modal Safety Consistency Score (CMSC-score) to measure consistency
across modalities. Evaluating 6 open-source and 4 closed-source OLLMs reveals
critical vulnerabilities: (1) no model excels in both overall safety and
consistency, with only 3 models achieving over 0.6 in both metrics and top
performer scoring around 0.8; (2) safety defenses weaken with complex inputs,
especially audio-visual joints; (3) severe weaknesses persist, with some models
scoring as low as 0.14 on specific modalities. Our benchmark and metrics
highlight urgent needs for enhanced OLLM safety, providing a foundation for
future improvements.

</details>


### [253] [Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback](https://arxiv.org/abs/2508.07178)
*Kejin Liu,Junhong Lian,Xiang Ao,Ningtao Wang,Xing Fu,Yu Cheng,Weiqiang Wang,Xinyu Liu*

Main category: cs.CL

TL;DR: 本文提出一种通过消除用户历史行为中伪兴趣的个性化标题生成框架（PHG-DIF），并验证了其在新发布的DT-PENS数据集上的优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能准确消除用户历史点击流中的无关点击噪声，导致个性化标题生成偏离用户实际兴趣。

Method: 提出PHG-DIF框架，通过双阶段过滤去除短停留时间和异常点击等噪声，引入多层次时间融合对用户兴趣进行动态建模，并发布新的DT-PENS数据集。

Result: PHG-DIF在DT-PENS数据集上的实验表明，该框架有效减少了点击噪声的负面影响，显著提升了个性化标题质量，并取得SOTA性能。

Conclusion: PHG-DIF能够从历史点击中去噪并精准捕捉用户兴趣，为个性化标题生成提供了一个高效解决方案，同时新的数据集能够推动相关研究的发展。

Abstract: Accurate personalized headline generation hinges on precisely capturing user
interests from historical behaviors. However, existing methods neglect
personalized-irrelevant click noise in entire historical clickstreams, which
may lead to hallucinated headlines that deviate from genuine user preferences.
In this paper, we reveal the detrimental impact of click noise on personalized
generation quality through rigorous analysis in both user and news dimensions.
Based on these insights, we propose a novel Personalized Headline Generation
framework via Denoising Fake Interests from Implicit Feedback (PHG-DIF).
PHG-DIF first employs dual-stage filtering to effectively remove clickstream
noise, identified by short dwell times and abnormal click bursts, and then
leverages multi-level temporal fusion to dynamically model users' evolving and
multi-faceted interests for precise profiling. Moreover, we release DT-PENS, a
new benchmark dataset comprising the click behavior of 1,000 carefully curated
users and nearly 10,000 annotated personalized headlines with historical dwell
time annotations. Extensive experiments demonstrate that PHG-DIF substantially
mitigates the adverse effects of click noise and significantly improves
headline quality, achieving state-of-the-art (SOTA) results on DT-PENS. Our
framework implementation and dataset are available at
https://github.com/liukejin-up/PHG-DIF.

</details>


### [254] [Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks](https://arxiv.org/abs/2508.07179)
*Jiaqi Yin,Yi-Wei Chen,Meng-Lung Lee,Xiya Liu*

Main category: cs.CL

TL;DR: 本研究提出了一种新框架，通过多语言企业管道脚本自动提取精细化的模式血统，解决了"语义漂移"问题，改善了数据可再现性和治理。


<details>
  <summary>Details</summary>
Motivation: 复杂的企业数据管道中多语言转换导致语义漂移，影响数据实用性与治理，因此需要一种方法恢复精确的模式血统。

Method: 提出了一个新框架，自动提取模式血统，并设计了SLiCE度量指标，结合1,700个手工标注数据集进行评估，同时实验了从SLM到LLM的语言模型来测试性能。

Result: 实验表明，模型尺寸和提示技术的进步显著提高了模式血统提取的性能，特别是32B模型表现接近GPT系列。

Conclusion: 该研究展示了通过大语言模型和提示优化实现经济、高效的模式血统提取的潜力，并为实际应用提供了可扩展的解决方案。

Abstract: Enterprise data pipelines, characterized by complex transformations across
multiple programming languages, often cause a semantic disconnect between
original metadata and downstream data. This "semantic drift" compromises data
reproducibility and governance, and impairs the utility of services like
retrieval-augmented generation (RAG) and text-to-SQL systems. To address this,
a novel framework is proposed for the automated extraction of fine-grained
schema lineage from multilingual enterprise pipeline scripts. This method
identifies four key components: source schemas, source tables, transformation
logic, and aggregation operations, creating a standardized representation of
data transformations. For the rigorous evaluation of lineage quality, this
paper introduces the Schema Lineage Composite Evaluation (SLiCE), a metric that
assesses both structural correctness and semantic fidelity. A new benchmark is
also presented, comprising 1,700 manually annotated lineages from real-world
industrial scripts. Experiments were conducted with 12 language models, from
1.3B to 32B small language models (SLMs) to large language models (LLMs) like
GPT-4o and GPT-4.1. The results demonstrate that the performance of schema
lineage extraction scales with model size and the sophistication of prompting
techniques. Specially, a 32B open-source model, using a single reasoning trace,
can achieve performance comparable to the GPT series under standard prompting.
This finding suggests a scalable and economical approach for deploying
schema-aware agents in practical applications.

</details>


### [255] [DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention](https://arxiv.org/abs/2508.07185)
*Kabir Khan,Priya Sharma,Arjun Mehta,Neha Gupta,Ravi Narayanan*

Main category: cs.CL

TL;DR: 本文提出了一种称为DySK-Attn的创新框架，通过一个瞬时更新的动态知识图，让大型语言模型(LLMs)能够高效整合实时知识，以解决LLMs静态知识迅速过时的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的知识静态且容易过时，重新训练成本高，现有的知识编辑方法效率低并可能引入副作用，因此亟需一种高效、动态更新知识的方法。

Method: 采用了一种稀疏知识注意机制，通过粗到细的分级搜索，从动态知识图中快速筛选并专注于相关小规模知识子集，避免了高计算成本和无关信息的干扰。

Result: 实验表明，在需要实时更新知识的问答任务中，DySK-Attn在知识更新的准确性和计算效率上显著优于标准的RAG及模型编辑技术。

Conclusion: DySK-Attn为构建能够实时更新、适应动态变化世界的大型语言模型提供了一种可扩展且高效的解决方案。

Abstract: Large Language Models (LLMs) suffer from a critical limitation: their
knowledge is static and quickly becomes outdated. Retraining these massive
models is computationally prohibitive, while existing knowledge editing
techniques can be slow and may introduce unforeseen side effects. To address
this, we propose DySK-Attn, a novel framework that enables LLMs to efficiently
integrate real-time knowledge from a dynamic external source. Our approach
synergizes an LLM with a dynamic Knowledge Graph (KG) that can be updated
instantaneously. The core of our framework is a sparse knowledge attention
mechanism, which allows the LLM to perform a coarse-to-fine grained search,
efficiently identifying and focusing on a small, highly relevant subset of
facts from the vast KG. This mechanism avoids the high computational cost of
dense attention over the entire knowledge base and mitigates noise from
irrelevant information. We demonstrate through extensive experiments on
time-sensitive question-answering tasks that DySK-Attn significantly
outperforms strong baselines, including standard Retrieval-Augmented Generation
(RAG) and model editing techniques, in both factual accuracy for updated
knowledge and computational efficiency. Our framework offers a scalable and
effective solution for building LLMs that can stay current with the
ever-changing world.

</details>


### [256] [Adapting LLMs to Time Series Forecasting via Temporal Heterogeneity Modeling and Semantic Alignment](https://arxiv.org/abs/2508.07195)
*Yanru Sun,Emadeldeen Eldele,Zongxia Xie,Yucheng Wang,Wenzhe Niu,Qinghua Hu,Chee Keong Kwoh,Min Wu*

Main category: cs.CL

TL;DR: 提出一个名为TALON的框架，通过处理时间模式异质性和实现语义对齐，改进LLM在时间序列预测中的应用。


<details>
  <summary>Details</summary>
Motivation: 将LLM强泛化能力应用于时间序列预测时，面临时间模式异质性和数值信号与语言表征之间的模态差异问题。

Method: TALON框架中包含一个异质时间编码器（Heterogeneous Temporal Encoder），用于分割时间序列以实现针对性建模，同时引入语义对齐模块（Semantic Alignment Module），解决模态差异问题并消除推理时的手工提示需求。

Result: 在七个实际基准数据集的实验中，TALON的性能显著优于最新的方法，MSE平均提升可达11%。

Conclusion: 通过模式感知和语义感知提升了LLM在时间序列预测中的适应性，表明这是一种有效的方法。

Abstract: Large Language Models (LLMs) have recently demonstrated impressive
capabilities in natural language processing due to their strong generalization
and sequence modeling capabilities. However, their direct application to time
series forecasting remains challenging due to two fundamental issues: the
inherent heterogeneity of temporal patterns and the modality gap between
continuous numerical signals and discrete language representations. In this
work, we propose TALON, a unified framework that enhances LLM-based forecasting
by modeling temporal heterogeneity and enforcing semantic alignment.
Specifically, we design a Heterogeneous Temporal Encoder that partitions
multivariate time series into structurally coherent segments, enabling
localized expert modeling across diverse temporal patterns. To bridge the
modality gap, we introduce a Semantic Alignment Module that aligns temporal
features with LLM-compatible representations, enabling effective integration of
time series into language-based models while eliminating the need for
handcrafted prompts during inference. Extensive experiments on seven real-world
benchmarks demonstrate that TALON achieves superior performance across all
datasets, with average MSE improvements of up to 11\% over recent
state-of-the-art methods. These results underscore the effectiveness of
incorporating both pattern-aware and semantic-aware designs when adapting LLMs
for time series forecasting. The code is available at:
https://github.com/syrGitHub/TALON.

</details>


### [257] [Enhancing Rumor Detection Methods with Propagation Structure Infused Language Model](https://arxiv.org/abs/2508.07209)
*Chaoqun Cui,Siyuan Li,Kunkun Ma,Caiyan Jia*

Main category: cs.CL

TL;DR: 提出了一种名为Post Engagement Prediction（PEP）的继续预训练策略，旨在提升预训练语言模型在社会媒体任务（如谣言检测）中的表现，并展示了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练语言模型在谣言检测等社会媒体任务中的表现不佳，原因包括预训练语料与社会媒体文本的差异、对独特社会符号处理不足以及未能建模用户参与传播结构的预训练任务。

Method: 提出一种名为Post Engagement Prediction（PEP）的继续预训练策略，使模型能够预测帖子之间的根、分支和父关系，从而捕捉立场和情感的交互。此外，发布了一个包含Twitter数据的大规模语料库，以及两个包含传播结构的未标记数据集（UTwitter和UWeibo）。基于PEP策略，训练了一个专为Twitter定制的语言模型SoLM。

Result: PEP策略显著提升了预训练模型在谣言检测任务中的表现，在基准数据集上提升了1.0-3.7%的准确率，并在多个数据集上超越了现有的最先进方法。

Conclusion: PEP策略能够显著提升模型对帖子交互特征的学习能力，提供了增强社会媒体语言模型和谣言检测性能的新途径。

Abstract: Pretrained Language Models (PLMs) have excelled in various Natural Language
Processing tasks, benefiting from large-scale pretraining and self-attention
mechanism's ability to capture long-range dependencies. However, their
performance on social media application tasks like rumor detection remains
suboptimal. We attribute this to mismatches between pretraining corpora and
social texts, inadequate handling of unique social symbols, and pretraining
tasks ill-suited for modeling user engagements implicit in propagation
structures. To address these issues, we propose a continue pretraining strategy
called Post Engagement Prediction (PEP) to infuse information from propagation
structures into PLMs. PEP makes models to predict root, branch, and parent
relations between posts, capturing interactions of stance and sentiment crucial
for rumor detection. We also curate and release large-scale Twitter corpus:
TwitterCorpus (269GB text), and two unlabeled claim conversation datasets with
propagation structures (UTwitter and UWeibo). Utilizing these resources and PEP
strategy, we train a Twitter-tailored PLM called SoLM. Extensive experiments
demonstrate PEP significantly boosts rumor detection performance across
universal and social media PLMs, even in few-shot scenarios. On benchmark
datasets, PEP enhances baseline models by 1.0-3.7\% accuracy, even enabling it
to outperform current state-of-the-art methods on multiple datasets. SoLM
alone, without high-level modules, also achieves competitive results,
highlighting the strategy's effectiveness in learning discriminative post
interaction features.

</details>


### [258] [How Does a Deep Neural Network Look at Lexical Stress?](https://arxiv.org/abs/2508.07229)
*Itai Allouche,Itay Asael,Rotem Rousso,Vered Dassa,Ann Bradlow,Seung-Eun Kim,Matthew Goldrick,Joseph Keshet*

Main category: cs.CL

TL;DR: 这篇论文研究了神经网络在词汇重音预测中的解释性，发现深度学习能够从自然语料中获取重音分布线索，并分析哪些特征对预测贡献最大。


<details>
  <summary>Details</summary>
Motivation: 探讨神经网络如何决策及如何解释其在语音处理中的黑箱操作，尤其是研究其在词汇重音预测中的表现及解释性。

Method: 自动构建了包含多音节单词的数据集，通过多个卷积神经网络（CNN）架构对无重音最小对偶的单词进行训练，使用层级相关传播（LRP）分析CNN的判别依据，并提出特征相关性分析方法。

Result: 模型在测试集上达到了92%的准确率。通过LRP分析，发现模型主要关注单词中的重音特征，尤其是重音元音的光谱属性，如第一和第二共振峰对预测贡献最大，部分第三共振峰和音调也有作用。

Conclusion: 研究揭示了深度学习能够从自然数据中学习分布式重音线索，为基于控制性刺激的传统语音学研究提供了新的视角。

Abstract: Despite their success in speech processing, neural networks often operate as
black boxes, prompting the question: what informs their decisions, and how can
we interpret them? This work examines this issue in the context of lexical
stress. A dataset of English disyllabic words was automatically constructed
from read and spontaneous speech. Several Convolutional Neural Network (CNN)
architectures were trained to predict stress position from a spectrographic
representation of disyllabic words lacking minimal stress pairs (e.g., initial
stress WAllet, final stress exTEND), achieving up to 92% accuracy on held-out
test data. Layerwise Relevance Propagation (LRP), a technique for CNN
interpretability analysis, revealed that predictions for held-out minimal pairs
(PROtest vs. proTEST ) were most strongly influenced by information in stressed
versus unstressed syllables, particularly the spectral properties of stressed
vowels. However, the classifiers also attended to information throughout the
word. A feature-specific relevance analysis is proposed, and its results
suggest that our best-performing classifier is strongly influenced by the
stressed vowel's first and second formants, with some evidence that its pitch
and third formant also contribute. These results reveal deep learning's ability
to acquire distributed cues to stress from naturally occurring data, extending
traditional phonetic work based around highly controlled stimuli.

</details>


### [259] [Prompt Tuning for Few-Shot Continual Learning Named Entity Recognition](https://arxiv.org/abs/2508.07248)
*Zhe Ren*

Main category: cs.CL

TL;DR: 本文研究解决了小样本持续学习命名实体识别(FS-CLNER)中通过几种方法避免知识蒸馏困境和灾难性遗忘问题，提出了Anchor Prompt Tuning和Memory Demonstration的方法，并证实实验效果。


<details>
  <summary>Details</summary>
Motivation: FS-CLNER任务中因新类别样本稀少导致模型泛化能力受限，并在知识蒸馏中缺乏旧类别信息导致模型进入知识蒸馏困境。

Method: 提出Anchor words-oriented Prompt Tuning (APT)范式用于弥合预训练和微调之间的差距；设计Memory Demonstration Templates (MDT)用于提供以前任务的重放样本。

Result: 该方法通过实验验证，在FS-CLNER任务上取得了有竞争力的性能效果。

Conclusion: APT和MDT的结合有效解决了FS-CLNER中的知识蒸馏困境及泛化限制，实现了性能提升。

Abstract: Knowledge distillation has been successfully applied to Continual Learning
Named Entity Recognition (CLNER) tasks, by using a teacher model trained on
old-class data to distill old-class entities present in new-class data as a
form of regularization, thereby avoiding catastrophic forgetting. However, in
Few-Shot CLNER (FS-CLNER) tasks, the scarcity of new-class entities makes it
difficult for the trained model to generalize during inference. More
critically, the lack of old-class entity information hinders the distillation
of old knowledge, causing the model to fall into what we refer to as the
Few-Shot Distillation Dilemma. In this work, we address the above challenges
through a prompt tuning paradigm and memory demonstration template strategy.
Specifically, we designed an expandable Anchor words-oriented Prompt Tuning
(APT) paradigm to bridge the gap between pre-training and fine-tuning, thereby
enhancing performance in few-shot scenarios. Additionally, we incorporated
Memory Demonstration Templates (MDT) into each training instance to provide
replay samples from previous tasks, which not only avoids the Few-Shot
Distillation Dilemma but also promotes in-context learning. Experiments show
that our approach achieves competitive performances on FS-CLNER.

</details>


### [260] [The 2D+ Dynamic Articulatory Model DYNARTmo: Tongue-Palate Contact Area Estimation](https://arxiv.org/abs/2508.07262)
*Bernd J. Kröger*

Main category: cs.CL

TL;DR: 本文扩展了二维动态发声器模型DYNARTmo，通过整合内部三维腭穹顶结构来估算舌腭接触面积。


<details>
  <summary>Details</summary>
Motivation: 为了在二维动态模型中增加三维腭穹顶表示，提升舌腭接触区域估算与发音显示效果。

Method: 在二维模型中加入半椭圆与基于余弦的腭穹顶几何形状，通过分析计算生成舌腭接触点，提供同步多视图显示功能。

Result: 增强模型提供静态和动态发音展示功能，可用于语言学教育和语音治疗。

Conclusion: 模型改进使其适用性更强，未来计划增加面部显示和语音合成功能实现模型现实评价。

Abstract: This paper describes an extension of the two-dimensional dynamic articulatory
model DYNARTmo by integrating an internal three-dimensional representation of
the palatal dome to estimate tongue-palate contact areas from midsagittal
tongue contours. Two alternative dome geometries - a half-ellipse and a cosine
based profile - are implemented to model lateral curvature in the coronal
plane. Using these geometries, lateral contact points are analytically computed
for each anterior-posterior position, enabling the generation of
electropalatography-like visualizations within the 2D+ framework. The enhanced
model supports three synchronized views (sagittal, glottal, and palatal) for
static and dynamic (animated) articulation displays, suitable for speech
science education and speech therapy. Future work includes adding a facial
(lip) view and implementing articulatory-to-acoustic synthesis to
quantitatively evaluate model realism.

</details>


### [261] [Incorporating Contextual Paralinguistic Understanding in Large Speech-Language Models](https://arxiv.org/abs/2508.07273)
*Qiongqiong Wang,Hardik B. Sailor,Jeremy H. M. Wong,Tianchi Liu,Shuo Sun,Wenyu Zhang,Muhammad Huzaifah,Nancy Chen,Ai Ti Aw*

Main category: cs.CL

TL;DR: 研究提出两种方法，将语境副语言信息整合到语音大语言模型的训练中，显著提高模型表现。


<details>
  <summary>Details</summary>
Motivation: 当前语音大语言模型在同理心推理上表现不足，主要是因为缺乏同时包含语境内容和副语言线索的训练数据集。

Method: 提出了两种方法：一种是显式方法，直接向语言模型提供副语言元数据，例如情感标注；另一种是隐式方法，利用情感标注和语音转录文本自动生成新的训练问答对。

Result: 隐式方法在一个人工标注的问答基准上提升了38.41%的性能，与显式方法结合后达到46.02%的提升；并验证了语言模型裁判的可靠性。

Conclusion: 将副语言信息整合到训练中能显著提高语音大语言模型对语境副语言的理解能力，且提出的方法有效而可靠。

Abstract: Current large speech language models (Speech-LLMs) often exhibit limitations
in empathetic reasoning, primarily due to the absence of training datasets that
integrate both contextual content and paralinguistic cues. In this work, we
propose two approaches to incorporate contextual paralinguistic information
into model training: (1) an explicit method that provides paralinguistic
metadata (e.g., emotion annotations) directly to the LLM, and (2) an implicit
method that automatically generates novel training question-answer (QA) pairs
using both categorical and dimensional emotion annotations alongside speech
transcriptions. Our implicit method boosts performance (LLM-judged) by 38.41%
on a human-annotated QA benchmark, reaching 46.02% when combined with the
explicit approach, showing effectiveness in contextual paralinguistic
understanding. We also validate the LLM judge by demonstrating its correlation
with classification metrics, providing support for its reliability.

</details>


### [262] [MAQuA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory](https://arxiv.org/abs/2508.07279)
*Vasudha Varadarajan,Hui Xu,Rebecca Astrid Boehme,Mariam Marlan Mirstrom,Sverker Sikstrom,H. Andrew Schwartz*

Main category: cs.CL

TL;DR: 论文提出了MAQuA，一个融合LLMs、IRT和因子分析的自适应提问框架，用于多维心理健康筛查，显著减少问题数量同时提高准确性。


<details>
  <summary>Details</summary>
Motivation: 探索如何结合LLMs优化心理健康评估，减少用户负担并提升筛查效率。

Method: 利用多结果建模、IRT与因子分析，MAQuA根据每轮最具信息价值的多维答案选择问题，以优化诊断信息。

Result: 相比随机问题排序，MAQuA在分数稳定上的问题数量减少50-87%，例如抑郁分数减少71%、饮食失调分数减少85%。

Conclusion: MAQuA在精简时间和用户负担的同时保持高效筛查性能，具有实际临床应用潜力，推动LLM在心理健康工作中的融合。

Abstract: Recent advances in large language models (LLMs) offer new opportunities for
scalable, interactive mental health assessment, but excessive querying by LLMs
burdens users and is inefficient for real-world screening across
transdiagnostic symptom profiles. We introduce MAQuA, an adaptive
question-asking framework for simultaneous, multidimensional mental health
screening. Combining multi-outcome modeling on language responses with item
response theory (IRT) and factor analysis, MAQuA selects the questions with
most informative responses across multiple dimensions at each turn to optimize
diagnostic information, improving accuracy and potentially reducing response
burden. Empirical results on a novel dataset reveal that MAQuA reduces the
number of assessment questions required for score stabilization by 50-87%
compared to random ordering (e.g., achieving stable depression scores with 71%
fewer questions and eating disorder scores with 85% fewer questions). MAQuA
demonstrates robust performance across both internalizing (depression, anxiety)
and externalizing (substance use, eating disorder) domains, with early stopping
strategies further reducing patient time and burden. These findings position
MAQuA as a powerful and efficient tool for scalable, nuanced, and interactive
mental health screening, advancing the integration of LLM-based agents into
real-world clinical workflows.

</details>


### [263] ["Pull or Not to Pull?'': Investigating Moral Biases in Leading Large Language Models Across Ethical Dilemmas](https://arxiv.org/abs/2508.07284)
*Junchen Ding,Penghao Jiang,Zihao Xu,Ziqi Ding,Yichen Zhu,Jiaojiao Jiang,Yuekang Li*

Main category: cs.CL

TL;DR: 本研究分析了14种大型语言模型（LLMs）在27种不同的伦理场景中的道德行为和推理过程，发现模型之间的表现存在显著差异，并提出对LLMs道德推理进行标准化评估的建议。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型越来越多地涉及伦理敏感决策，理解它们的道德推理过程变得至关重要。

Method: 通过十种道德哲学框架和多个伦理场景，研究人员采用因子提示协议，生成3780个二元决策和自然语言解释，分析模型在多条维度上的表现。

Result: 研究发现，不同模型在道德决策中的表现差异显著，部分模型在特定道德框架下能更好地与人类道德判断对齐，但一些情况下会产生有争议的结果。

Conclusion: 提出应将道德推理视为LLMs对齐的核心轴心，并呼吁为其建立标准化基准以更好地评估其决策的原理和过程。

Abstract: As large language models (LLMs) increasingly mediate ethically sensitive
decisions, understanding their moral reasoning processes becomes imperative.
This study presents a comprehensive empirical evaluation of 14 leading LLMs,
both reasoning enabled and general purpose, across 27 diverse trolley problem
scenarios, framed by ten moral philosophies, including utilitarianism,
deontology, and altruism. Using a factorial prompting protocol, we elicited
3,780 binary decisions and natural language justifications, enabling analysis
along axes of decisional assertiveness, explanation answer consistency, public
moral alignment, and sensitivity to ethically irrelevant cues. Our findings
reveal significant variability across ethical frames and model types: reasoning
enhanced models demonstrate greater decisiveness and structured justifications,
yet do not always align better with human consensus. Notably, "sweet zones"
emerge in altruistic, fairness, and virtue ethics framings, where models
achieve a balance of high intervention rates, low explanation conflict, and
minimal divergence from aggregated human judgments. However, models diverge
under frames emphasizing kinship, legality, or self interest, often producing
ethically controversial outcomes. These patterns suggest that moral prompting
is not only a behavioral modifier but also a diagnostic tool for uncovering
latent alignment philosophies across providers. We advocate for moral reasoning
to become a primary axis in LLM alignment, calling for standardized benchmarks
that evaluate not just what LLMs decide, but how and why.

</details>


### [264] [Arce: Augmented Roberta with Contextualized Elucidations for Ner in Automated Rule Checking](https://arxiv.org/abs/2508.07286)
*Jian Chen,Jinbao Tian,Yankui Li,Zhou Li*

Main category: cs.CL

TL;DR: 提出了ARCE方法，利用LLMs生成简单的解释性知识用于RoBERTa模型的预训练，在AEC领域的NER任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 标准预训练模型在AEC领域的NER任务中受限于领域差距，难以解释专门术语和复杂关系。虽然域内预训练可以缓解，但成本高昂且资源密集。需要一种高效的知识生成策略来改进小型模型的性能。

Method: 提出ARCE方法，利用LLM生成称为Cote的简单直接解释性语料库，并将其用于RoBERTa模型的增量预训练，然后在下游任务上微调模型。

Result: ARCE在AEC领域基准数据集上达到新的最高性能，Macro-F1得分为77.20%。简单的解释性知识比复杂的基于角色的推理更有效。

Conclusion: ARCE提供了一种有效且资源友好的方法，在无需成本高昂的人工标注情况下提升了AEC领域下游任务的性能。

Abstract: Accurate information extraction from specialized texts is a critical
challenge, particularly for named entity recognition (NER) in the architecture,
engineering, and construction (AEC) domain to support automated rule checking
(ARC). The performance of standard pre-trained models is often constrained by
the domain gap, as they struggle to interpret the specialized terminology and
complex relational contexts inherent in AEC texts. Although this issue can be
mitigated by further pre-training on large, human-curated domain corpora, as
exemplified by methods like ARCBERT, this approach is both labor-intensive and
cost-prohibitive. Consequently, leveraging large language models (LLMs) for
automated knowledge generation has emerged as a promising alternative. However,
the optimal strategy for generating knowledge that can genuinely enhance
smaller, efficient models remains an open question. To address this, we propose
ARCE (augmented RoBERTa with contextualized elucidations), a novel approach
that systematically explores and optimizes this generation process. ARCE
employs an LLM to first generate a corpus of simple, direct explanations, which
we term Cote, and then uses this corpus to incrementally pre-train a RoBERTa
model prior to its fine-tuning on the downstream task. Our extensive
experiments show that ARCE establishes a new state-of-the-art on a benchmark
AEC dataset, achieving a Macro-F1 score of 77.20%. This result also reveals a
key finding: simple, explanation-based knowledge proves surprisingly more
effective than complex, role-based rationales for this task. The code is
publicly available at:https://github.com/nxcc-lab/ARCE.

</details>


### [265] [CCFQA: A Benchmark for Cross-Lingual and Cross-Modal Speech and Text Factuality Evaluation](https://arxiv.org/abs/2508.07295)
*Yexing Du,Kaiyuan Liu,Youcheng Pan,Zheng Chu,Bo Yang,Xiaocheng Feng,Yang Xiang,Ming Liu*

Main category: cs.CL

TL;DR: 提出一个名为CCFQA的新基准，用于评估多模态大模型在多语言语音文本上的事实性，展示目前模型的挑战并引入一个少样本学习策略。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型评估多数集中在单一语言（尤其是英文）及单一模式（文本/视觉），而在多语言语音输入和事实性验证上存在评估空白。

Method: 开发了CCFQA基准，包含8种语言的平行语音-文本事实性问题，并引入少样本学习策略，将模型在英文上的问答能力迁移到多语言语音任务。

Result: 通过实验展示当前MLLM模型在CCFQA基准上的显著挑战，同时通过5-shot训练策略在多语言语音问答任务中取得与GPT-4o-mini-Audio相称的性能。

Conclusion: CCFQA填补了多语言多模态事实性评估的空白，将推动具备更强语音理解能力的多模态语言模型的发展，同时开放该基准及相关代码以促进后续研究。

Abstract: As Large Language Models (LLMs) are increasingly popularized in the
multilingual world, ensuring hallucination-free factuality becomes markedly
crucial. However, existing benchmarks for evaluating the reliability of
Multimodal Large Language Models (MLLMs) predominantly focus on textual or
visual modalities with a primary emphasis on English, which creates a gap in
evaluation when processing multilingual input, especially in speech. To bridge
this gap, we propose a novel \textbf{C}ross-lingual and \textbf{C}ross-modal
\textbf{F}actuality benchmark (\textbf{CCFQA}). Specifically, the CCFQA
benchmark contains parallel speech-text factual questions across 8 languages,
designed to systematically evaluate MLLMs' cross-lingual and cross-modal
factuality capabilities. Our experimental results demonstrate that current
MLLMs still face substantial challenges on the CCFQA benchmark. Furthermore, we
propose a few-shot transfer learning strategy that effectively transfers the
Question Answering (QA) capabilities of LLMs in English to multilingual Spoken
Question Answering (SQA) tasks, achieving competitive performance with
GPT-4o-mini-Audio using just 5-shot training. We release CCFQA as a
foundational research resource to promote the development of MLLMs with more
robust and reliable speech understanding capabilities. Our code and dataset are
available at https://github.com/yxduir/ccfqa.

</details>


### [266] [HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways](https://arxiv.org/abs/2508.07308)
*Cristian Cosentino,Annamaria Defilippo,Marco Dossena,Christopher Irwin,Sara Joubbi,Pietro Liò*

Main category: cs.CL

TL;DR: HealthBranches是一个专为医疗Q&A设计的全新数据集，用于评估LLMs的复杂推理能力。


<details>
  <summary>Details</summary>
Motivation: 旨在通过创建一个能评估LLMs推理能力的数据集，进一步提升其在高风险医疗领域的可信度和解释能力。

Method: 采用半自动化流程，将医疗决策路径转化为现实病患案例，并生成相关问题和答案。数据集涵盖4063个案例，包含完整的推理路径，适用于开放式和选择题格式。

Result: 数据集结构支持对LLMs多步推理能力的评估，特别是在结构化RAG情境下的表现。

Conclusion: HealthBranches不仅为开发更值得信赖的医疗LLMs奠定了基础，还在教育和临床可靠性方面提供了宝贵资源。

Abstract: HealthBranches is a novel benchmark dataset for medical Question-Answering
(Q&A), specifically designed to evaluate complex reasoning in Large Language
Models (LLMs). This dataset is generated through a semi-automated pipeline that
transforms explicit decision pathways from medical source into realistic
patient cases with associated questions and answers. Covering 4,063 case
studies across 17 healthcare topics, each data point is based on clinically
validated reasoning chains. HealthBranches supports both open-ended and
multiple-choice question formats and uniquely includes the full reasoning path
for each Q&A. Its structured design enables robust evaluation of LLMs'
multi-step inference capabilities, including their performance in structured
Retrieval-Augmented Generation (RAG) contexts. HealthBranches establishes a
foundation for the development of more trustworthy, interpretable, and
clinically reliable LLMs in high-stakes domains while also serving as a
valuable resource for educational purposes.

</details>


### [267] [ObfusQAte: A Proposed Framework to Evaluate LLM Robustness on Obfuscated Factual Question Answering](https://arxiv.org/abs/2508.07321)
*Shubhra Ghosh,Abhilekh Borah,Aditya Kumar Guru,Kripabandhu Ghosh*

Main category: cs.CL

TL;DR: 本文提出了一种评估大语言模型（LLMs）鲁棒性的新方法，名为ObfusQAte，并构建了相应的测试框架ObfusQA。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在事实问答方面表现卓越，但缺乏针对经过混淆问题的鲁棒性测试。本研究旨在弥补这一空白。

Method: 设计ObfusQA框架，包含三个混淆层次：命名实体间接性、干扰项间接性与上下文过载，以系统评估LLMs的能力。

Result: 研究发现，LLMs面对经过混淆的问题时容易失败或生成错误的“幻觉”回答。

Conclusion: ObfusQA为衡量LLMs鲁棒性提供了新的基准，并推动这一领域的研究发展。

Abstract: The rapid proliferation of Large Language Models (LLMs) has significantly
contributed to the development of equitable AI systems capable of factual
question-answering (QA). However, no known study tests the LLMs' robustness
when presented with obfuscated versions of questions. To systematically
evaluate these limitations, we propose a novel technique, ObfusQAte and,
leveraging the same, introduce ObfusQA, a comprehensive, first of its kind,
framework with multi-tiered obfuscation levels designed to examine LLM
capabilities across three distinct dimensions: (i) Named-Entity Indirection,
(ii) Distractor Indirection, and (iii) Contextual Overload. By capturing these
fine-grained distinctions in language, ObfusQA provides a comprehensive
benchmark for evaluating LLM robustness and adaptability. Our study observes
that LLMs exhibit a tendency to fail or generate hallucinated responses when
confronted with these increasingly nuanced variations. To foster research in
this direction, we make ObfusQAte publicly available.

</details>


### [268] [Strategies of Code-switching in Human-Machine Dialogs](https://arxiv.org/abs/2508.07325)
*Dean Geckt,Melinda Fricke,Shuly Wintner*

Main category: cs.CL

TL;DR: 研究开发了一个西英双语混合交谈的聊天机器人，分析了参与者在不同代码转换策略下的反应。


<details>
  <summary>Details</summary>
Motivation: 了解大多数人使用的代码转换的特性，并借助技术深入研究双语语言行为。

Method: 设计一个能完成地图任务（Map Task）的西班牙语和英语代码转换聊天机器人，并通过两项实验研究不同代码转换策略对参与者的影响。

Result: 参与者在机器人代码转换行为可预测时表现出满意度；而当转换随机或语法错误时，满意度和任务完成率下降。

Conclusion: 不足的多语言技术会影响使用体验，但此技术也有助于研究双语语言行为的潜力。

Abstract: Most people are multilingual, and most multilinguals code-switch, yet the
characteristics of code-switched language are not fully understood. We
developed a chatbot capable of completing a Map Task with human participants
using code-switched Spanish and English. In two experiments, we prompted the
bot to code-switch according to different strategies, examining (1) the
feasibility of such experiments for investigating bilingual language use, and
(2) whether participants would be sensitive to variations in discourse and
grammatical patterns. Participants generally enjoyed code-switching with our
bot as long as it produced predictable code-switching behavior; when
code-switching was random or ungrammatical (as when producing unattested
incongruent mixed-language noun phrases, such as `la fork'), participants
enjoyed the task less and were less successful at completing it. These results
underscore the potential downsides of deploying insufficiently developed
multilingual language technology, while also illustrating the promise of such
technology for conducting research on bilingual language use.

</details>


### [269] [Think Before You Talk: Enhancing Meaningful Dialogue Generation in Full-Duplex Speech Language Models with Planning-Inspired Text Guidance](https://arxiv.org/abs/2508.07375)
*Wenqian Cui,Lei Zhu,Xiaohui Li,Zhihan Guo,Haoli Bai,Lu Hou,Irwin King*

Main category: cs.CL

TL;DR: 本文介绍了一种新方法TurnGuide，旨在优化全双工语音语言模型（FD-SLMs）的对话能力，特别是解决插入时机和长度问题。


<details>
  <summary>Details</summary>
Motivation: FD-SLMs希望实现自然实时的语音交互，但受限于长语音序列和高质量语音对话数据的缺乏，其性能有所下降。

Method: 提出一种称为TurnGuide的方法，通过动态分段助手语音，将对话语音转换为对话回合，并为其生成文字指导，从而优化生成的准确性和连贯性。

Result: 实验表明，TurnGuide显著提升了FD-SLMs的对话能力，能够生成语义丰富且连贯的语音，同时保持自然的对话流畅性。

Conclusion: TurnGuide方法有效解决了全双工语音交互中插入时机和长度上的挑战，使FD-SLMs更适用于人类的自然互动。

Abstract: Full-Duplex Speech Language Models (FD-SLMs) are specialized foundation
models designed to enable natural, real-time spoken interactions by modeling
complex conversational dynamics such as interruptions, backchannels, and
overlapping speech, and End-to-end (e2e) FD-SLMs leverage real-world
double-channel conversational data to capture nuanced two-speaker dialogue
patterns for human-like interactions. However, they face a critical challenge
-- their conversational abilities often degrade compared to pure-text
conversation due to prolonged speech sequences and limited high-quality spoken
dialogue data. While text-guided speech generation could mitigate these issues,
it suffers from timing and length issues when integrating textual guidance into
double-channel audio streams, disrupting the precise time alignment essential
for natural interactions. To address these challenges, we propose TurnGuide, a
novel planning-inspired approach that mimics human conversational planning by
dynamically segmenting assistant speech into dialogue turns and generating
turn-level text guidance before speech output, which effectively resolves both
insertion timing and length challenges. Extensive experiments demonstrate our
approach significantly improves e2e FD-SLMs' conversational abilities, enabling
them to generate semantically meaningful and coherent speech while maintaining
natural conversational flow. Demos are available at
https://dreamtheater123.github.io/TurnGuide-Demo/. Code will be available at
https://github.com/dreamtheater123/TurnGuide.

</details>


### [270] [Grounding Multilingual Multimodal LLMs With Cultural Knowledge](https://arxiv.org/abs/2508.07414)
*Jean de Dieu Nyandwi,Yueqi Song,Simran Khanuja,Graham Neubig*

Main category: cs.CL

TL;DR: 提出了一种数据驱动的方法，通过强化文化知识来改进多模态大语言模型（MLLMs），并推出了一个新的数据集和模型。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在高资源环境中表现出色，但在长尾文化实体和低资源语言中表现较差，因此需要一种方法来弥补这一不足。

Method: 利用Wikidata的知识图谱收集文化上重要的实体图像，生成多语言视觉问答合成数据集CulturalGround，并在此基础上训练模型CulturalPangea，同时保留多语言指令微调数据以保持常规能力。

Result: CulturalPangea在多种文化聚焦的多语言多模态基准上取得了最先进的开源模型表现，相比之前的模型平均提升5.0，且在主流视觉语言任务中表现未降低。

Conclusion: 该研究表明，通过有针对性的文化嵌入方法，可以显著缩小MLLMs的文化差距，为构建全球包容性多模态系统提供了可行路径。

Abstract: Multimodal Large Language Models excel in high-resource settings, but often
misinterpret long-tail cultural entities and underperform in low-resource
languages. To address this gap, we propose a data-centric approach that
directly grounds MLLMs in cultural knowledge. Leveraging a large scale
knowledge graph from Wikidata, we collect images that represent culturally
significant entities, and generate synthetic multilingual visual question
answering data. The resulting dataset, CulturalGround, comprises 22 million
high-quality, culturally-rich VQA pairs spanning 42 countries and 39 languages.
We train an open-source MLLM CulturalPangea on CulturalGround, interleaving
standard multilingual instruction-tuning data to preserve general abilities.
CulturalPangea achieves state-of-the-art performance among open models on
various culture-focused multilingual multimodal benchmarks, outperforming prior
models by an average of 5.0 without degrading results on mainstream
vision-language tasks. Our findings show that our targeted, culturally grounded
approach could substantially narrow the cultural gap in MLLMs and offer a
practical path towards globally inclusive multimodal systems.

</details>


### [271] [Let's Revise Step-by-Step: A Unified Local Search Framework for Code Generation with LLMs](https://arxiv.org/abs/2508.07434)
*Zhiyi Lyu,Jianguo Huang,Yanchen Deng,Steven Hoi,Bo An*

Main category: cs.CL

TL;DR: 提出了一种名为ReLoc的本地搜索框架，用于逐步改进代码生成，其在多种代码生成任务中表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在代码生成上面临效率和可扩展性问题，特别是两种方法（基于树的构造方法和改进方法）各有局限性。

Method: 提出ReLoc框架，通过初始代码生成、邻域代码生成、候选评估和代码更新四个步骤实现本地逐步代码优化，结合如爬山算法或遗传算法，并设计特定的修订奖励模型进行引导。

Result: 实验表明，ReLoc方法在各类代码生成任务中显著优于现有的树构方法和改进方法。

Conclusion: ReLoc提供了一种统一的本地搜索框架，在代码生成效率和效果上均取得显著突破。

Abstract: Large Language Models (LLMs) with inference-time scaling techniques show
promise for code generation, yet face notable efficiency and scalability
challenges. Construction-based tree-search methods suffer from rapid growth in
tree size, high token consumption, and lack of anytime property. In contrast,
improvement-based methods offer better performance but often struggle with
uninformative reward signals and inefficient search strategies. In this work,
we propose \textbf{ReLoc}, a unified local search framework which effectively
performs step-by-step code revision. Specifically, ReLoc explores a series of
local revisions through four key algorithmic components: initial code drafting,
neighborhood code generation, candidate evaluation, and incumbent code
updating, each of which can be instantiated with specific decision rules to
realize different local search algorithms such as Hill Climbing (HC) or Genetic
Algorithm (GA). Furthermore, we develop a specialized revision reward model
that evaluates code quality based on revision distance to produce fine-grained
preferences that guide the local search toward more promising candidates.
Finally, our extensive experimental results demonstrate that our approach
achieves superior performance across diverse code generation tasks,
significantly outperforming both construction-based tree search as well as the
state-of-the-art improvement-based code generation methods.

</details>


### [272] [Positional Biases Shift as Inputs Approach Context Window Limits](https://arxiv.org/abs/2508.07479)
*Blerta Veseli,Julian Chibane,Mariya Toneva,Alexander Koller*

Main category: cs.CL

TL;DR: 该论文研究了大语言模型（LLMs）面临的输入位置偏差问题，提出了“中部内容丢失效应”（LiM效应）。研究发现，LiM效应主要出现在输入长度不超过模型上下文窗口50%的情况下，当超出50%时，主要表现为基于位置的偏差。


<details>
  <summary>Details</summary>
Motivation: 了解和量化长文本输入中信息位置对LLMs性能的影响，揭示不同条件下LiM效应的强弱及表现形式。

Method: 使用相对输入长度（基于模型上下文窗口的比例）对大语言模型的信息位置偏差进行定量分析，观察不同输入比例下的模型性能变化。

Result: LiM效应在输入长度占上下文窗口50%以下时显著，超过此范围后逐渐被位置偏差取代。此外，提出推理成功要求检索的前提条件，模型的推理位置偏差源于检索过程。

Conclusion: 研究成果有助于改善长文本任务、设计未来LLM基准测试，并优化评估长输入任务的模型表现。

Abstract: Large Language Models (LLMs) often struggle to use information across long
inputs effectively. Prior work has identified positional biases, such as the
Lost in the Middle (LiM) effect, where models perform better when information
appears at the beginning (primacy bias) or end (recency bias) of the input,
rather than in the middle. However, long-context studies have not consistently
replicated these effects, raising questions about their intensity and the
conditions under which they manifest. To address this, we conducted a
comprehensive analysis using relative rather than absolute input lengths,
defined with respect to each model's context window. Our findings reveal that
the LiM effect is strongest when inputs occupy up to 50% of a model's context
window. Beyond that, the primacy bias weakens, while recency bias remains
relatively stable. This effectively eliminates the LiM effect; instead, we
observe a distance-based bias, where model performance is better when relevant
information is closer to the end of the input. Furthermore, our results suggest
that successful retrieval is a prerequisite for reasoning in LLMs, and that the
observed positional biases in reasoning are largely inherited from retrieval.
These insights have implications for long-context tasks, the design of future
LLM benchmarks, and evaluation methodologies for LLMs handling extended inputs.

</details>


### [273] [ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models](https://arxiv.org/abs/2508.07484)
*Archchana Sindhujan,Shenbin Qian,Chan Chi Chun Matthew,Constantin Orasan,Diptesh Kanojia*

Main category: cs.CL

TL;DR: 本文提出了改进大语言模型在机器翻译质量评估任务表现的ALOPE框架，通过层级适配优化Transformer表征，实现更好的回归预测效果，并公开了相关模型和代码。


<details>
  <summary>Details</summary>
Motivation: 主要动机是解决现有LLM在跨语言质量评估任务中的不足，包括缺乏针对性回归建模优化和低资源语言问题。

Method: 设计了ALOPE框架，使用低秩适配器（LoRA）与回归任务头，动态选择和结合多层的表征，并通过多头回归策略优化模型表现。

Result: 实验证明ALOPE框架相比现有LLM质量评估方法有显著提高，尤其在跨语言对齐方面效果明显。

Conclusion: ALOPE框架整合多层次表征与新策略，为LLM扩展跨语言质量评估能力提供了一个有前景的方向。

Abstract: Large Language Models (LLMs) have shown remarkable performance across a wide
range of natural language processing tasks. Quality Estimation (QE) for Machine
Translation (MT), which assesses the quality of a source-target pair without
relying on reference translations, remains a challenging cross-lingual task for
LLMs. The challenges stem from the inherent limitations of existing LLM-based
QE systems, which are pre-trained for causal language modelling rather than
regression-specific tasks, further elevated by the presence of low-resource
languages given pre-training data distribution. This paper introduces ALOPE, an
adaptive layer-optimization framework designed to enhance LLM-based QE by
restructuring Transformer representations through layer-wise adaptation for
improved regression-based prediction. Our framework integrates low-rank
adapters (LoRA) with regression task heads, leveraging selected pre-trained
Transformer layers for improved cross-lingual alignment. In addition to the
layer-specific adaptation, ALOPE introduces two strategies-dynamic weighting,
which adaptively combines representations from multiple layers, and multi-head
regression, which aggregates regression losses from multiple heads for QE. Our
framework shows improvements over various existing LLM-based QE approaches.
Empirical evidence suggests that intermediate Transformer layers in LLMs
provide contextual representations that are more aligned with the cross-lingual
nature of the QE task. We make resultant models and framework code publicly
available for further research, also allowing existing LLM-based MT frameworks
to be scaled with QE capabilities.

</details>


### [274] [Augmenting Bias Detection in LLMs Using Topological Data Analysis](https://arxiv.org/abs/2508.07516)
*Keshav Varadarajan,Tananun Songdechakraiwut*

Main category: cs.CL

TL;DR: 该研究提出了一种基于拓扑数据分析的方法，用于识别GPT-2模型内哪个attention head对特定群体的偏见起作用。


<details>
  <summary>Details</summary>
Motivation: 确定大型语言模型中特定部分导致对特定群体的偏见，从而更高效地定位问题区域。

Method: 使用拓扑数据分析方法，结合StereoSet数据集，定位GPT-2模型中对群体偏见“热点”的attention head。

Result: 发现模型内部偏见（如性别或职业）主要集中在某些显著的attention head上。

Conclusion: 该方法不仅能评估模型特定群体的偏见程度，未来还可用于对大型语言模型的偏见修正。

Abstract: Recently, many bias detection methods have been proposed to determine the
level of bias a large language model captures. However, tests to identify which
parts of a large language model are responsible for bias towards specific
groups remain underdeveloped. In this study, we present a method using
topological data analysis to identify which heads in GPT-2 contribute to the
misrepresentation of identity groups present in the StereoSet dataset. We find
that biases for particular categories, such as gender or profession, are
concentrated in attention heads that act as hot spots. The metric we propose
can also be used to determine which heads capture bias for a specific group
within a bias category, and future work could extend this method to help
de-bias large language models.

</details>


### [275] [Word Clouds as Common Voices: LLM-Assisted Visualization of Participant-Weighted Themes in Qualitative Interviews](https://arxiv.org/abs/2508.07517)
*Joseph T. Colonel,Baihan Lin*

Main category: cs.CL

TL;DR: 本文探讨了一种称为ThemeClouds的新型开放源码可视化工具，用于从对话记录中生成以主题为主的加权词云，通过利用大型语言模型（LLMs）进行概念层面上的主题识别，超越了传统基于频率的方法的局限性。在用户研究中的应用，体现了其对研究快速、可解释性分析的帮助尤其显著。


<details>
  <summary>Details</summary>
Motivation: 传统的词云分析方法在对话分析中无法有效捕捉语义关联和参与者的重要观点，研究者亟需更高效和富有解释性的工具进行早期分析。

Method: 提出了ThemeClouds工具，利用大型语言模型（LLMs）生成基于主题的加权词云，按参与者提及主题的广度而非频率计数，并允许用户灵活调整参数与提示。

Result: 通过案例研究验证了该工具优于传统频率词云和主题建模方法，如LDA、BERTopic，能够更有效地挖掘实际问题。

Conclusion: ThemeClouds证明了结合LLM的主题分析工具在质性研究中的潜力，为研究提供了创新视角，同时增强了研究者对分析的可控性和透明性。

Abstract: Word clouds are a common way to summarize qualitative interviews, yet
traditional frequency-based methods often fail in conversational contexts: they
surface filler words, ignore paraphrase, and fragment semantically related
ideas. This limits their usefulness in early-stage analysis, when researchers
need fast, interpretable overviews of what participant actually said. We
introduce ThemeClouds, an open-source visualization tool that uses large
language models (LLMs) to generate thematic, participant-weighted word clouds
from dialogue transcripts. The system prompts an LLM to identify concept-level
themes across a corpus and then counts how many unique participants mention
each topic, yielding a visualization grounded in breadth of mention rather than
raw term frequency. Researchers can customize prompts and visualization
parameters, providing transparency and control. Using interviews from a user
study comparing five recording-device configurations (31 participants; 155
transcripts, Whisper ASR), our approach surfaces more actionable device
concerns than frequency clouds and topic-modeling baselines (e.g., LDA,
BERTopic). We discuss design trade-offs for integrating LLM assistance into
qualitative workflows, implications for interpretability and researcher agency,
and opportunities for interactive analyses such as per-condition contrasts
(``diff clouds'').

</details>


### [276] [From Trial-and-Error to Improvement: A Systematic Analysis of LLM Exploration Mechanisms in RLVR](https://arxiv.org/abs/2508.07534)
*Jia Deng,Jie Chen,Zhipeng Chen,Daixuan Cheng,Fei Bai,Beichen Zhang,Yinqian Min,Yanzipeng Gao,Wayne Xin Zhao,Ji-Rong Wen*

Main category: cs.CL

TL;DR: 本文系统探讨了强化学习中可验证奖励（RLVR）探索能力，共涉及探索空间形状、熵与性能交换及RL优化三方面，提出了一套框架以提升LLMs的推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过RLVR提升大语言模型（LLMs）的推理能力，尤其着眼于改进其探索策略。

Method: 分析了探索空间形状、熵与性能间的关系，并研究如何将探索收益转化为性能提升，同时提出量化指标和新的经验性方法。

Result: 通过量化评估与实证研究，初步建立了一套分析及优化RLVR的方法论框架，揭示了探索策略中的关键机制。

Conclusion: 该工作为提升RLVR系统的能力提供了基础分析框架，并为未来更高效的探索策略设计奠定了理论与实践依据。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has emerged as a
powerful paradigm for enhancing the reasoning capabilities of large language
models (LLMs). Unlike traditional RL approaches, RLVR leverages rule-based
feedback to guide LLMs in generating and refining complex reasoning chains -- a
process critically dependent on effective exploration strategies. While prior
work has demonstrated RLVR's empirical success, the fundamental mechanisms
governing LLMs' exploration behaviors remain underexplored. This technical
report presents a systematic investigation of exploration capacities in RLVR,
covering four main aspects: (1) exploration space shaping, where we develop
quantitative metrics to characterize LLMs' capability boundaries; (2)
entropy-performance exchange, analyzed across training stages, individual
instances, and token-level patterns; and (3) RL performance optimization,
examining methods to effectively translate exploration gains into measurable
improvements. By unifying previously identified insights with new empirical
evidence, this work aims to provide a foundational framework for advancing RLVR
systems.

</details>


### [277] [IBPS: Indian Bail Prediction System](https://arxiv.org/abs/2508.07592)
*Puspesh Kumar Srivastava,Uddeshya Raj,Praveen Patel,/Shubham Kumar Nigam,Noel Shallum,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: 该论文提出了“印度保释预测系统 (IBPS)”，一种基于AI的框架，旨在通过预测结果和生成法律合理的解释来辅助保释决策。


<details>
  <summary>Details</summary>
Motivation: 印度法院处理保释案件的主观性、延迟和不一致问题严重，75%以上的印度囚犯为等待审前的贫困阶层，保释不及时和不公概率引发人权问题和司法积压。

Method: 研究开发了IBPS系统，通过法律条款和案件事实预测保释决策。研究还整理了一个包含150,430份高等法院保释判决的丰富数据集，并用参数高效技术微调大规模语言模型，加入法定上下文及RAG模型进行评估。

Result: 微调后加入法定知识的模型表现显著优于基准模型，不仅在解释质量和准确性上表现优异，还能很好地推广至法律专家注释的测试集。

Conclusion: IBPS为数据驱动的法律支持提供了透明、可扩展的解决方案，能减少保释延误并促进司法公平，在印度司法体系具有重要贡献。

Abstract: Bail decisions are among the most frequently adjudicated matters in Indian
courts, yet they remain plagued by subjectivity, delays, and inconsistencies.
With over 75% of India's prison population comprising undertrial prisoners,
many from socioeconomically disadvantaged backgrounds, the lack of timely and
fair bail adjudication exacerbates human rights concerns and contributes to
systemic judicial backlog. In this paper, we present the Indian Bail Prediction
System (IBPS), an AI-powered framework designed to assist in bail
decision-making by predicting outcomes and generating legally sound rationales
based solely on factual case attributes and statutory provisions. We curate and
release a large-scale dataset of 150,430 High Court bail judgments, enriched
with structured annotations such as age, health, criminal history, crime
category, custody duration, statutes, and judicial reasoning. We fine-tune a
large language model using parameter-efficient techniques and evaluate its
performance across multiple configurations, with and without statutory context,
and with RAG. Our results demonstrate that models fine-tuned with statutory
knowledge significantly outperform baselines, achieving strong accuracy and
explanation quality, and generalize well to a test set independently annotated
by legal experts. IBPS offers a transparent, scalable, and reproducible
solution to support data-driven legal assistance, reduce bail delays, and
promote procedural fairness in the Indian judicial system.

</details>


### [278] [Keyword-Centric Prompting for One-Shot Event Detection with Self-Generated Rationale Enhancements](https://arxiv.org/abs/2508.07598)
*Ziheng Li,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: 提出了一种名为KeyCP++的关键词链式思考提示方法，有效解决了大语言模型在一拍事件检测中的挑战问题，并取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在事件检测中因为缺乏对触发词的准确理解和过度解读问题，传统的ICL方法无法对其有效矫正。

Method: 提出了KeyCP++方法，通过触发词区别提示模板和候选触发词提出与评估的方式，引导模型生成具逻辑意义的推理，帮助模型减少对关键词的过度依赖，加强检测规则学习。

Result: 实验结果验证了KeyCP++的有效性，在一拍事件检测任务中取得显著改进。

Conclusion: KeyCP++通过逻辑推理方式有效提升了LLM在一拍事件检测任务的表现，并为提升模型理解能力提供了新的途径。

Abstract: Although the LLM-based in-context learning (ICL) paradigm has demonstrated
considerable success across various natural language processing tasks, it
encounters challenges in event detection. This is because LLMs lack an accurate
understanding of event triggers and tend to make over-interpretation, which
cannot be effectively corrected through in-context examples alone. In this
paper, we focus on the most challenging one-shot setting and propose KeyCP++, a
keyword-centric chain-of-thought prompting approach. KeyCP++ addresses the
weaknesses of conventional ICL by automatically annotating the logical gaps
between input text and detection results for the demonstrations. Specifically,
to generate in-depth and meaningful rationale, KeyCP++ constructs a trigger
discrimination prompting template. It incorporates the exemplary triggers
(a.k.a keywords) into the prompt as the anchor to simply trigger profiling, let
LLM propose candidate triggers, and justify each candidate. These
propose-and-judge rationales help LLMs mitigate over-reliance on the keywords
and promote detection rule learning. Extensive experiments demonstrate the
effectiveness of our approach, showcasing significant advancements in one-shot
event detection.

</details>


### [279] [InterChart: Benchmarking Visual Reasoning Across Decomposed and Distributed Chart Information](https://arxiv.org/abs/2508.07630)
*Anirudh Iyengar Kaniyar Narayana Iyengar,Srija Mukhopadhyay,Adnan Qidwai,Shubhankar Singh,Dan Roth,Vivek Gupta*

Main category: cs.CL

TL;DR: 本文提出了InterChart，一个用于评估视觉语言模型在多相关图表中的推理能力的诊断基准。


<details>
  <summary>Details</summary>
Motivation: 针对现有基准多聚焦于孤立且视觉统一的图表的问题，设计了更贴近实际应用并能考察模型多样推理能力的新基准。

Method: 构建了三个难度递增的推理层次测试，分别为单独图表的事实推理、跨图表的综合分析及复杂真实图表对的语义推理。

Result: 最先进的VLM在图表复杂度增加时表现出显著的精度下降；分解复杂图表可一定程度提升模型表现。

Conclusion: InterChart为推动复杂多视觉环境下的多模态推理提供了系统化的框架。

Abstract: We introduce InterChart, a diagnostic benchmark that evaluates how well
vision-language models (VLMs) reason across multiple related charts, a task
central to real-world applications such as scientific reporting, financial
analysis, and public policy dashboards. Unlike prior benchmarks focusing on
isolated, visually uniform charts, InterChart challenges models with diverse
question types ranging from entity inference and trend correlation to numerical
estimation and abstract multi-step reasoning grounded in 2-3 thematically or
structurally related charts. We organize the benchmark into three tiers of
increasing difficulty: (1) factual reasoning over individual charts, (2)
integrative analysis across synthetically aligned chart sets, and (3) semantic
inference over visually complex, real-world chart pairs. Our evaluation of
state-of-the-art open and closed-source VLMs reveals consistent and steep
accuracy declines as chart complexity increases. We find that models perform
better when we decompose multi-entity charts into simpler visual units,
underscoring their struggles with cross-chart integration. By exposing these
systematic limitations, InterChart provides a rigorous framework for advancing
multimodal reasoning in complex, multi-visual environments.

</details>


### [280] [LoSemB: Logic-Guided Semantic Bridging for Inductive Tool Retrieval](https://arxiv.org/abs/2508.07690)
*Luyao Zhuang,Qinggang Zhang,Huachi Zhou,Juhua Liu,Qing Li,Xiao Huang*

Main category: cs.CL

TL;DR: 文章提出了一种新的框架LoSemB，旨在解决大型语言模型在处理未见工具时的两大挑战，通过逻辑信息转移和增强的检索机制提高工具检索的能力。


<details>
  <summary>Details</summary>
Motivation: 当前方法假设所有工具在训练期间已知，但现实中工具库不断扩展，传统方法难以处理未见工具。

Method: 提出LoSemB框架，采用逻辑嵌入对齐模块以缓解分布偏移，并通过关系增强检索机制减少基于相似性的检索脆弱性。

Result: 实验表明，LoSemB在归纳设置中表现优异，同时在迁移设置中也保持了良好的效果。

Conclusion: LoSemB有效解决了处理未见工具的挑战，为工具检索提供了一种创新的解决方案。

Abstract: Tool learning has emerged as a promising paradigm for large language models
(LLMs) to solve many real-world tasks. Nonetheless, with the tool repository
rapidly expanding, it is impractical to contain all tools within the limited
input length of LLMs. To alleviate these issues, researchers have explored
incorporating a tool retrieval module to select the most relevant tools or
represent tools as unique tokens within LLM parameters. However, most
state-of-the-art methods are under transductive settings, assuming all tools
have been observed during training. Such a setting deviates from reality as the
real-world tool repository is evolving and incorporates new tools frequently.
When dealing with these unseen tools, which refer to tools not encountered
during the training phase, these methods are limited by two key issues,
including the large distribution shift and the vulnerability of
similarity-based retrieval. To this end, inspired by human cognitive processes
of mastering unseen tools through discovering and applying the logical
information from prior experience, we introduce a novel Logic-Guided Semantic
Bridging framework for inductive tool retrieval, namely, LoSemB, which aims to
mine and transfer latent logical information for inductive tool retrieval
without costly retraining. Specifically, LoSemB contains a logic-based
embedding alignment module to mitigate distribution shifts and implements a
relational augmented retrieval mechanism to reduce the vulnerability of
similarity-based retrieval. Extensive experiments demonstrate that LoSemB
achieves advanced performance in inductive settings while maintaining desirable
effectiveness in the transductive setting.

</details>


### [281] [What am I missing here?: Evaluating Large Language Models for Masked Sentence Prediction](https://arxiv.org/abs/2508.07702)
*Charlie Wyatt,Aditya Joshi,Flora Salim*

Main category: cs.CL

TL;DR: 研究表明当前的商业LLMs在低结构化领域中对被遮掩句子的预测表现较差，尽管它们在其他任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 探讨基于Transformer的语言模型在全局连贯性任务中的局限性，特别是在重建或论述任务中。

Method: 评估GPT-4o、Claude 3.5 Sonnet和Gemini 2.0 Flash在被遮掩句子预测任务（MSP）中的表现，采用ROCStories、Recipe1M和Wikipedia数据集，同时评估准确性和连贯性。

Result: 发现商业LLMs在低结构化文本领域中的预测能力较弱，尤其是在保证句子与周围上下文连贯性方面。

Conclusion: 虽然LLMs在其他任务中表现优异，但它们在全局连贯性任务中仍存在显著缺陷，这需要进一步技术改进。

Abstract: Transformer-based models primarily rely on Next Token Prediction (NTP), which
predicts the next token in a sequence based on the preceding context. However,
NTP's focus on single-token prediction often limits a model's ability to plan
ahead or maintain long-range coherence, raising questions about how well LLMs
can predict longer contexts, such as full sentences within structured
documents. While NTP encourages local fluency, it provides no explicit
incentive to ensure global coherence across sentence boundaries-an essential
skill for reconstructive or discursive tasks. To investigate this, we evaluate
three commercial LLMs (GPT-4o, Claude 3.5 Sonnet, and Gemini 2.0 Flash) on
Masked Sentence Prediction (MSP) - the task of infilling a randomly removed
sentence - from three domains: ROCStories (narrative), Recipe1M (procedural),
and Wikipedia (expository). We assess both fidelity (similarity to the original
sentence) and cohesiveness (fit within the surrounding context). Our key
finding reveals that commercial LLMs, despite their superlative performance in
other tasks, are poor at predicting masked sentences in low-structured domains,
highlighting a gap in current model capabilities.

</details>


### [282] [Exploring Causal Effect of Social Bias on Faithfulness Hallucinations in Large Language Models](https://arxiv.org/abs/2508.07753)
*Zhenliang Zhang,Junzhe Zhang,Xinyu Hu,HuiXuan Zhang,Xiaojun Wan*

Main category: cs.CL

TL;DR: 大语言模型（LLMs）在多项任务中表现出色，但易受信念幻觉影响。作者研究了社会偏见是否引发这种现象，并验证了偏见是导致幻觉的显著因素。


<details>
  <summary>Details</summary>
Motivation: 探讨社会偏见是否直接导致大语言模型中的信念幻觉，以及验证该因果关系。

Method: 运用结构因果模型（SCM）验证因果关系，并设计偏见干预措施控制混杂因素，同时开发包含多种社会偏见的偏见干预数据集（BID）。

Result: 实验表明社会偏见是信念幻觉的显著原因，不同偏见方向影响不同。此外分析了偏见对各种模型内幻觉生成的因果效应。

Conclusion: 偏见对幻觉生成的因果效应可被量化和解析，模型性能的可信性需进一步关注社会偏见的影响。

Abstract: Large language models (LLMs) have achieved remarkable success in various
tasks, yet they remain vulnerable to faithfulness hallucinations, where the
output does not align with the input. In this study, we investigate whether
social bias contributes to these hallucinations, a causal relationship that has
not been explored. A key challenge is controlling confounders within the
context, which complicates the isolation of causality between bias states and
hallucinations. To address this, we utilize the Structural Causal Model (SCM)
to establish and validate the causality and design bias interventions to
control confounders. In addition, we develop the Bias Intervention Dataset
(BID), which includes various social biases, enabling precise measurement of
causal effects. Experiments on mainstream LLMs reveal that biases are
significant causes of faithfulness hallucinations, and the effect of each bias
state differs in direction. We further analyze the scope of these causal
effects across various models, specifically focusing on unfairness
hallucinations, which are primarily targeted by social bias, revealing the
subtle yet significant causal effect of bias on hallucination generation.

</details>


### [283] [SASST: Leveraging Syntax-Aware Chunking and LLMs for Simultaneous Speech Translation](https://arxiv.org/abs/2508.07781)
*Zeyu Yang,Lai Wei,Roman Koshkin,Xi Chen,Satoshi Nakamura*

Main category: cs.CL

TL;DR: 提出了一种基于语法的分块策略用于语音翻译，通过依存关系解析和标点符号特征进行语义完整单元的划分；结合冻结的Whisper编码器和解码器专用LLM开发SASST框架，在多语言语料上验证了此方法的翻译质量优越性。


<details>
  <summary>Details</summary>
Motivation: 当前语音翻译面临语义碎片化和翻译延迟优化的挑战。

Method: 使用基于依存关系和标点的语法分块策略，并开发名为SASST的框架，结合冻结的Whisper编码器和解码器专用LLM，动态输出翻译词或<WAIT>符号，优化翻译的时序与内容，并通过目标端重排序解决词序差异问题。

Result: 在CoVoST2多语言语料库（En-{De, Zh, Ja}）上的实验表明，该方法显著提高了翻译质量，并验证了语法结构在LLM驱动的SimulST系统中的有效性。

Conclusion: 提出的基于语法的分块策略和SASST框架能够在优化翻译时序的同时提升翻译内容质量，为语法结构在语音翻译中的应用提供了新思路。

Abstract: This work proposes a grammar-based chunking strategy that segments input
streams into semantically complete units by parsing dependency relations (e.g.,
noun phrase boundaries, verb-object structures) and punctuation features. The
method ensures chunk coherence and minimizes semantic fragmentation. Building
on this mechanism, we present SASST (Syntax-Aware Simultaneous Speech
Translation), an end-to-end framework integrating frozen Whisper encoder and
decoder-only LLM. The unified architecture dynamically outputs translation
tokens or <WAIT> symbols to jointly optimize translation timing and content,
with target-side reordering addressing word-order divergence. Experiments on
CoVoST2 multilingual corpus En-{De, Zh, Ja} demonstrate significant translation
quality improvements across languages and validate the effectiveness of
syntactic structures in LLM-driven SimulST systems.

</details>


### [284] [Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts](https://arxiv.org/abs/2508.07785)
*Haoyuan Wu,Haoxing Chen,Xiaodong Chen,Zhanchao Zhou,Tieyuan Chen,Yihong Zhuang,Guoshan Lu,Zenan Huang,Junbo Zhao,Lin Liu,Zhenzhong Lan,Bei Yu,Jianguo Li*

Main category: cs.CL

TL;DR: 提出了Grove MoE，一种引入异构专家和动态激活机制的新型模型架构，通过减少计算开销和优化参数激活，提高了大语言模型的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE架构使用均匀大小的专家和固定数量的参数激活，无视输入复杂性，限制了模型的计算效率。

Method: 引入Grove MoE，新型异构架构基于big.LITTLE CPU的启发，采用大小不同的专家和动态激活机制，并基于此开发了GroveMoE-Base和GroveMoE-Inst模型。

Result: GroveMoE模型基于token复杂性动态激活约3.14-3.28B参数，在性能上可与同等甚至更大规模的SOTA开源模型相媲美。

Conclusion: Grove MoE在保持计算开销可控的情况下，成功扩展了模型容量，是一个更高效的架构设计方案。

Abstract: The Mixture of Experts (MoE) architecture is a cornerstone of modern
state-of-the-art (SOTA) large language models (LLMs). MoE models facilitate
scalability by enabling sparse parameter activation. However, traditional MoE
architecture uses homogeneous experts of a uniform size, activating a fixed
number of parameters irrespective of input complexity and thus limiting
computational efficiency. To overcome this limitation, we introduce Grove MoE,
a novel architecture incorporating experts of varying sizes, inspired by the
heterogeneous big.LITTLE CPU architecture. This architecture features novel
adjugate experts with a dynamic activation mechanism, enabling model capacity
expansion while maintaining manageable computational overhead. Building on this
architecture, we present GroveMoE-Base and GroveMoE-Inst, 33B-parameter LLMs
developed by applying an upcycling strategy to the Qwen3-30B-A3B-Base model
during mid-training and post-training. GroveMoE models dynamically activate
3.14-3.28B parameters based on token complexity and achieve performance
comparable to SOTA open-source models of similar or even larger size.

</details>


### [285] [Can You Trick the Grader? Adversarial Persuasion of LLM Judges](https://arxiv.org/abs/2508.07805)
*Yerin Hwang,Dongryeol Lee,Taegwan Kang,Yongil Kim,Kyomin Jung*

Main category: cs.CL

TL;DR: 该研究揭示使用说服性语言可使大型语言模型在数学推理任务评分时产生偏差，导致错误答案得高分。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否会因嵌入说服性语言而被误导，尤其在数学推理评分中，正确性应独立于语言风格变化。

Method: 基于亚里士多德的修辞学原则，形式化提出七种说服技术，并在相同答案中嵌入这些技术，在六个数学基准测试中检验其影响。

Result: 发现使用说服性语言会导致LLM对错误答案评分提升，多达8%。同时，模型大小增长并未有效减轻此问题，多种说服技术的结合还会进一步放大偏差。

Conclusion: 结果表明LLM评分系统存在对说服攻击的脆弱性，强调了建立抗说服攻击防御的必要性。

Abstract: As large language models take on growing roles as automated evaluators in
practical settings, a critical question arises: Can individuals persuade an LLM
judge to assign unfairly high scores? This study is the first to reveal that
strategically embedded persuasive language can bias LLM judges when scoring
mathematical reasoning tasks, where correctness should be independent of
stylistic variation. Grounded in Aristotle's rhetorical principles, we
formalize seven persuasion techniques (Majority, Consistency, Flattery,
Reciprocity, Pity, Authority, Identity) and embed them into otherwise identical
responses. Across six math benchmarks, we find that persuasive language leads
LLM judges to assign inflated scores to incorrect solutions, by up to 8% on
average, with Consistency causing the most severe distortion. Notably,
increasing model size does not substantially mitigate this vulnerability.
Further analysis demonstrates that combining multiple persuasion techniques
amplifies the bias, and pairwise evaluation is likewise susceptible. Moreover,
the persuasive effect persists under counter prompting strategies, highlighting
a critical vulnerability in LLM-as-a-Judge pipelines and underscoring the need
for robust defenses against persuasion-based attacks.

</details>


### [286] [Evaluating Compositional Approaches for Focus and Sentiment Analysis](https://arxiv.org/abs/2508.07810)
*Olga Kellert,Muhammad Imran,Nicholas Hill Matlis,Mahmud Uz Zaman,Carlos Gómez-Rodríguez*

Main category: cs.CL

TL;DR: 本文评估了在语言学焦点分析（FA）和自然语言处理中的情感分析（SA）的组成方法，展示组成方法在FA中的定量分析，并将其结果应用到FA中。


<details>
  <summary>Details</summary>
Motivation: SA已有定量分析相关研究，但FA在这方面研究稀缺。本文希望弥合研究的这一空白，探讨组成规则是否对两者通用。

Method: 使用英语的Universal Dependencies（UDs）形式化表示，通过情感字典应用到情感表达词中，基于修饰、协调和否定等基本句法规则，开发了可解释且可解释的SA组成分析方法，并与非组成方法VADER进行比较。

Result: 实验发现相比非组成分析方法，本文方法的可解释性和解释能力更强，且适用的数据集更适配评估组成性。

Conclusion: 研究表明SA的组成结果可以推广应用到FA中，并为FA的定量评估提供了重要的研究参考。

Abstract: This paper summarizes the results of evaluating a compositional approach for
Focus Analysis (FA) in Linguistics and Sentiment Analysis (SA) in Natural
Language Processing (NLP). While quantitative evaluations of compositional and
non-compositional approaches in SA exist in NLP, similar quantitative
evaluations are very rare in FA in Linguistics that deal with linguistic
expressions representing focus or emphasis such as "it was John who left". We
fill this gap in research by arguing that compositional rules in SA also apply
to FA because FA and SA are closely related meaning that SA is part of FA. Our
compositional approach in SA exploits basic syntactic rules such as rules of
modification, coordination, and negation represented in the formalism of
Universal Dependencies (UDs) in English and applied to words representing
sentiments from sentiment dictionaries. Some of the advantages of our
compositional analysis method for SA in contrast to non-compositional analysis
methods are interpretability and explainability. We test the accuracy of our
compositional approach and compare it with a non-compositional approach VADER
that uses simple heuristic rules to deal with negation, coordination and
modification. In contrast to previous related work that evaluates
compositionality in SA on long reviews, this study uses more appropriate
datasets to evaluate compositionality. In addition, we generalize the results
of compositional approaches in SA to compositional approaches in FA.

</details>


### [287] [Evaluating Large Language Models as Expert Annotators](https://arxiv.org/abs/2508.07827)
*Yu-Min Tseng,Wei-Lin Chen,Chung-Chi Chen,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型(LLMs)能否替代人类专业注释员，尤其在财务、生物医学和法律这类专业领域的数据注释任务中。提出了一种多代理讨论框架，并结合推理模型进行比较，发现个人LLMs和推理模型在专门领域的注释任务中表现提升有限或无显著改善，多代理环境下则观察到一些模型行为特征。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在专业领域是否能够替代人类进行文本数据注释任务，针对目前LLMs在需要专家知识的领域仍缺乏有效评估的现状。

Method: 评估LLMs及多代理方法在财务、生物医学和法律三大专业领域的数据注释性能；提出一种多代理讨论框架，让LLMs通过互动讨论和推理模型（如o3-mini）进行注释决策比较。

Result: 发现单个LLMs通过推理技术的增益有限，推理模型总体性能无显著性提升，多代理环境下模型行为呈现某些独特特质，但整体表现仍相对有限。

Conclusion: LLMs及其推理技术在专业领域的数据注释任务中仍面临挑战，多代理框架和深入理解模型行为或有助改进这一领域的应用。

Abstract: Textual data annotation, the process of labeling or tagging text with
relevant information, is typically costly, time-consuming, and labor-intensive.
While large language models (LLMs) have demonstrated their potential as direct
alternatives to human annotators for general domains natural language
processing (NLP) tasks, their effectiveness on annotation tasks in domains
requiring expert knowledge remains underexplored. In this paper, we
investigate: whether top-performing LLMs, which might be perceived as having
expert-level proficiency in academic and professional benchmarks, can serve as
direct alternatives to human expert annotators? To this end, we evaluate both
individual LLMs and multi-agent approaches across three highly specialized
domains: finance, biomedicine, and law. Specifically, we propose a multi-agent
discussion framework to simulate a group of human annotators, where LLMs are
tasked to engage in discussions by considering others' annotations and
justifications before finalizing their labels. Additionally, we incorporate
reasoning models (e.g., o3-mini) to enable a more comprehensive comparison. Our
empirical results reveal that: (1) Individual LLMs equipped with inference-time
techniques (e.g., chain-of-thought (CoT), self-consistency) show only marginal
or even negative performance gains, contrary to prior literature suggesting
their broad effectiveness. (2) Overall, reasoning models do not demonstrate
statistically significant improvements over non-reasoning models in most
settings. This suggests that extended long CoT provides relatively limited
benefits for data annotation in specialized domains. (3) Certain model
behaviors emerge in the multi-agent discussion environment. For instance,
Claude 3.7 Sonnet with thinking rarely changes its initial annotations, even
when other agents provide correct annotations or valid reasoning.

</details>


### [288] [LLMs for Law: Evaluating Legal-Specific LLMs on Contract Understanding](https://arxiv.org/abs/2508.07849)
*Amrita Singh,H. Suhan Karaca,Aditya Joshi,Hye-young Paik,Jiaojiao Jiang*

Main category: cs.CL

TL;DR: 本文评估了10个法律专用语言模型(LLM)和7个通用LLM在合同理解任务中的表现，结果显示法律专用LLM在需要细致法律理解的任务中表现更佳。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对多个法律相关LLM在合同分类任务方面的全面评估，目标是弥补这一空白，从而更好理解合同处理任务的性能表现差异。

Method: 对10个法律专用LLM和7个通用LLM在三种英文合同理解任务中进行评估，并对模型性能进行比较分析。

Result: 法律专用LLM在任务中优于通用LLM，其中Legal-BERT和Contracts-BERT刷新两项任务最佳表现，其参数量比最优通用LLM少69%。此外，CaseLaw-BERT和LexLM也被识别为优秀的基线模型。

Conclusion: 这项研究全面评估了法律专用LLM的性能，促进了更准确的合同理解系统的开发。

Abstract: Despite advances in legal NLP, no comprehensive evaluation covering multiple
legal-specific LLMs currently exists for contract classification tasks in
contract understanding. To address this gap, we present an evaluation of 10
legal-specific LLMs on three English language contract understanding tasks and
compare them with 7 general-purpose LLMs. The results show that legal-specific
LLMs consistently outperform general-purpose models, especially on tasks
requiring nuanced legal understanding. Legal-BERT and Contracts-BERT establish
new SOTAs on two of the three tasks, despite having 69% fewer parameters than
the best-performing general-purpose LLM. We also identify CaseLaw-BERT and
LexLM as strong additional baselines for contract understanding. Our results
provide a holistic evaluation of legal-specific LLMs and will facilitate the
development of more accurate contract understanding systems.

</details>


### [289] [Large Language Models for Czech Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2508.07860)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 研究评估了19种大小和架构不同的大型语言模型在捷克语ABSA任务中的表现，发现针对任务微调的小型领域模型在零样本和少样本设置下优于通用LLMs，而微调后的LLMs实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 评估大规模语言模型在捷克语细粒度情感分析(ABSA)任务中的能力，并探索领域特定模型与通用LLMs的适用性。

Method: 对19种LLMs在零样本(Zero-Shot)、少样本(Few-Shot)和微调(Fine-Tuning)情景下进行全面评估，包括错误分析和性能因素（如多语言性、模型大小等）研究。

Result: 微调的领域模型在零样本和少样本下表现更优，而微调后的LLMs在ABSA任务上达到了最先进的性能。

Conclusion: 研究表明模型的多语言性、大小和现代性影响其在捷克语ABSA任务的表现，此外微调是实现高性能的关键，对未来研究具有重要指导意义。

Abstract: Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis
task that aims to identify sentiment toward specific aspects of an entity.
While large language models (LLMs) have shown strong performance in various
natural language processing (NLP) tasks, their capabilities for Czech ABSA
remain largely unexplored. In this work, we conduct a comprehensive evaluation
of 19 LLMs of varying sizes and architectures on Czech ABSA, comparing their
performance in zero-shot, few-shot, and fine-tuning scenarios. Our results show
that small domain-specific models fine-tuned for ABSA outperform
general-purpose LLMs in zero-shot and few-shot settings, while fine-tuned LLMs
achieve state-of-the-art results. We analyze how factors such as
multilingualism, model size, and recency influence performance and present an
error analysis highlighting key challenges, particularly in aspect term
prediction. Our findings provide insights into the suitability of LLMs for
Czech ABSA and offer guidance for future research in this area.

</details>


### [290] [Few-shot Cross-lingual Aspect-Based Sentiment Analysis with Sequence-to-Sequence Models](https://arxiv.org/abs/2508.07866)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 该文章探讨了通过添加少量目标语言示例改善低资源语言情感分析的效果，并证明了这种方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 低资源语言中缺乏标注数据，导致情感分析面临挑战。

Method: 通过在四项ABSA任务、六种目标语言和两种序列到序列模型中添加少量目标语言示例进行实验。

Result: 添加少至10个目标语言示例可显著提升性能，且结合1000个示例进一步超越单语基线。

Conclusion: 为低资源和特定领域的跨语言情感分析提供了切实可行的解决方案，少量高质量标注即可达到显著效果。

Abstract: Aspect-based sentiment analysis (ABSA) has received substantial attention in
English, yet challenges remain for low-resource languages due to the scarcity
of labelled data. Current cross-lingual ABSA approaches often rely on external
translation tools and overlook the potential benefits of incorporating a small
number of target language examples into training. In this paper, we evaluate
the effect of adding few-shot target language examples to the training set
across four ABSA tasks, six target languages, and two sequence-to-sequence
models. We show that adding as few as ten target language examples
significantly improves performance over zero-shot settings and achieves a
similar effect to constrained decoding in reducing prediction errors.
Furthermore, we demonstrate that combining 1,000 target language examples with
English data can even surpass monolingual baselines. These findings offer
practical insights for improving cross-lingual ABSA in low-resource and
domain-specific settings, as obtaining ten high-quality annotated examples is
both feasible and highly effective.

</details>


### [291] [Tailored Emotional LLM-Supporter: Enhancing Cultural Sensitivity](https://arxiv.org/abs/2508.07902)
*Chen Cecilia Liu,Hiba Arnaout,Nils Kovačić,Dana Atzil-Slonim,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文提出CultureCare，首个用于训练大语言模型提供文化敏感性情感支持的数据集，并开发与测试了多种模型适配策略，验证了模型在文化敏感性支持中的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在提供文化敏感性的情感支持方面仍存在探索不足，主要因缺乏相关资源。

Method: 引入CultureCare数据集，包括来自四种文化的情感困扰消息、文化信号和支持策略，并针对三种最先进模型开发和测试四种适配策略，同时通过模型评估及专家评价进行综合验证。

Result: 经过适配后的模型表现优于匿名在线支持，同时简单的文化角色扮演对文化敏感性支持效果有限。此外，模型在临床培训中的应用也显示出潜力。

Conclusion: 适配后LLMs在文化敏感性情感支持方面表现优越，且能在未来的心理治疗师培训中培养文化能力，这证明CultureCare数据集及方法的有效性。

Abstract: Large language models (LLMs) show promise in offering emotional support and
generating empathetic responses for individuals in distress, but their ability
to deliver culturally sensitive support remains underexplored due to lack of
resources. In this work, we introduce CultureCare, the first dataset designed
for this task, spanning four cultures and including 1729 distress messages,
1523 cultural signals, and 1041 support strategies with fine-grained emotional
and cultural annotations. Leveraging CultureCare, we (i) develop and test four
adaptation strategies for guiding three state-of-the-art LLMs toward culturally
sensitive responses; (ii) conduct comprehensive evaluations using LLM judges,
in-culture human annotators, and clinical psychologists; (iii) show that
adapted LLMs outperform anonymous online peer responses, and that simple
cultural role-play is insufficient for cultural sensitivity; and (iv) explore
the application of LLMs in clinical training, where experts highlight their
potential in fostering cultural competence in future therapists.

</details>


### [292] [Challenges and opportunities in portraying emotion in generated sign language](https://arxiv.org/abs/2508.07937)
*John C. McDonald,Rosalee Wolfe,Fabrizio Nunnari*

Main category: cs.CL

TL;DR: 论文探讨了两参数表示法在手语虚拟形象中表达情感非手动信号的应用。


<details>
  <summary>Details</summary>
Motivation: 手语的情感非手动信号难以通过虚拟形象准确表达，缺乏标准化方法。

Method: 提出了一种基于两参数的直观表示法，结合EASIER记法，通过文本控制虚拟形象的情感表情。

Result: 该方法允许通过数值参数表达更细腻的情感状态，并促进情感信号的一致性标注。

Conclusion: 新方法在情感表情的语言规范化和虚拟形象表现中展现出很大的潜力。

Abstract: Non-manual signals in sign languages continue to be a challenge for signing
avatars. More specifically, emotional content has been difficult to incorporate
because of a lack of a standard method of specifying the avatar's emotional
state. This paper explores the application of an intuitive two-parameter
representation for emotive non-manual signals to the Paula signing avatar that
shows promise for facilitating the linguistic specification of emotional facial
expressions in a more coherent manner than previous methods. Users can apply
these parameters to control Paula's emotional expressions through a textual
representation called the EASIER notation. The representation can allow avatars
to express more nuanced emotional states using two numerical parameters. It
also has the potential to enable more consistent specification of emotional
non-manual signals in linguistic annotations which drive signing avatars.

</details>


### [293] [Expert Preference-based Evaluation of Automated Related Work Generation](https://arxiv.org/abs/2508.07955)
*Furkan Şahinuç,Subhabrata Dutta,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文提出GREP框架，通过整合经典相关工作评估标准和专家偏好，以多回合的方式评估学术写作中的相关工作生成，优于传统自动评估方法和LLM评判系统。


<details>
  <summary>Details</summary>
Motivation: 当前，自动生成的科学写作质量评估面临挑战，因为需要深入的领域知识与专家偏好洞察，传统方法难以满足需求。

Method: 作者提出多回合评价框架GREP，将评估细分为多个粒度，并结合对比式少样例提供指导，支持两种参数化LLM版本，一个精准的专有LLM版本和一个经济的开源版本。

Result: 实验结果显示，GREP能够更稳健地评估相关工作部分的质量，并与人类专家评估强相关。此外，当前先进的LLMs在改进或验证相关工作部分方面表现较差。

Conclusion: GREP显著提升了自动生成科学写作的质量评估能力，有助于更好地支持人机协作的学术写作。

Abstract: Expert domain writing, such as scientific writing, typically demands
extensive domain knowledge. Recent advances in LLMs show promising potential in
reducing the expert workload. However, evaluating the quality of automatically
generated scientific writing is a crucial open issue, as it requires knowledge
of domain-specific evaluation criteria and the ability to discern expert
preferences. Conventional automatic metrics and LLM-as-a-judge systems are
insufficient to grasp expert preferences and domain-specific quality standards.
To address this gap and support human-AI collaborative writing, we focus on
related work generation, one of the most challenging scientific tasks, as an
exemplar. We propose GREP, a multi-turn evaluation framework that integrates
classical related work evaluation criteria with expert-specific preferences.
Instead of assigning a single score, our framework decomposes the evaluation
into fine-grained dimensions. This localized evaluation approach is further
augmented with contrastive few-shot examples to provide detailed contextual
guidance for the evaluation dimensions. The design principles allow our
framework to deliver cardinal assessment of quality, which can facilitate
better post-training compared to ordinal preference data. For better
accessibility, we design two variants of GREP: a more precise variant with
proprietary LLMs as evaluators, and a cheaper alternative with open-weight
LLMs. Empirical investigation reveals that our framework is able to assess the
quality of related work sections in a much more robust manner compared to
standard LLM judges, reflects natural scenarios of scientific writing, and
bears a strong correlation with the human expert assessment. We also observe
that generations from state-of-the-art LLMs struggle to satisfy validation
constraints of a suitable related work section. They (mostly) fail to improve
based on feedback as well.

</details>


### [294] [Large Language Models for Subjective Language Understanding: A Survey](https://arxiv.org/abs/2508.07959)
*Changhao Song,Yazhou Zhang,Hui Gao,Ben Yao,Peng Zhang*

Main category: cs.CL

TL;DR: 本文综述了大型语言模型（LLMs）在主观语言任务中的应用，包括情感分析、情绪识别等八个任务，并讨论了这些任务的定义、数据集和方法，同时指出了现存挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 研究主观语言任务是为了更好地理解和生成表达个人情感、意见或隐喻意义的内容，而LLMs的发展为解决这些复杂任务提供了新的可能性。

Method: 通过综述的形式，从定义、数据集、最新方法和现存挑战等方面系统性地分析了LLMs在八个主观任务中的表现，并探讨了多任务方法和LLM适应主观性任务的原因。

Result: 总结了八个主观语言任务的最新进展和模型表现，发现LLMs在处理细微的人类判断方面具有优势，同时揭示了数据不足、模型偏差等限制。

Conclusion: 适合主观语言任务的LLMs提供了良好的研究基础，但仍需在数据、偏差和伦理等方面进一步研究，以提升模型的全面性和适用性。

Abstract: Subjective language understanding refers to a broad set of natural language
processing tasks where the goal is to interpret or generate content that
conveys personal feelings, opinions, or figurative meanings rather than
objective facts. With the advent of large language models (LLMs) such as
ChatGPT, LLaMA, and others, there has been a paradigm shift in how we approach
these inherently nuanced tasks. In this survey, we provide a comprehensive
review of recent advances in applying LLMs to subjective language tasks,
including sentiment analysis, emotion recognition, sarcasm detection, humor
understanding, stance detection, metaphor interpretation, intent detection, and
aesthetics assessment. We begin by clarifying the definition of subjective
language from linguistic and cognitive perspectives, and we outline the unique
challenges posed by subjective language (e.g. ambiguity, figurativeness,
context dependence). We then survey the evolution of LLM architectures and
techniques that particularly benefit subjectivity tasks, highlighting why LLMs
are well-suited to model subtle human-like judgments. For each of the eight
tasks, we summarize task definitions, key datasets, state-of-the-art LLM-based
methods, and remaining challenges. We provide comparative insights, discussing
commonalities and differences among tasks and how multi-task LLM approaches
might yield unified models of subjectivity. Finally, we identify open issues
such as data limitations, model bias, and ethical considerations, and suggest
future research directions. We hope this survey will serve as a valuable
resource for researchers and practitioners interested in the intersection of
affective computing, figurative language processing, and large-scale language
models.

</details>


### [295] [Toward Machine Interpreting: Lessons from Human Interpreting Studies](https://arxiv.org/abs/2508.07964)
*Matthias Sperber,Maureen de Seyssel,Jiajun Bao,Matthias Paulik*

Main category: cs.CL

TL;DR: 分析人类口译特性与机器翻译的结合，为改进语音翻译系统提供灵感。


<details>
  <summary>Details</summary>
Motivation: 现有语音翻译系统缺乏动态适应性，难以像人类口译员一样应对实际场景。

Method: 从机器翻译角度分析人类口译研究，并结合当前建模技术提出改进方向。

Result: 指出语音翻译系统可从人类口译特性中汲取灵感，提出了一些改进建议。

Conclusion: 希望通过这些研究缩小系统的可用差距，推动语音翻译系统向机器口译方向发展。

Abstract: Current speech translation systems, while having achieved impressive
accuracies, are rather static in their behavior and do not adapt to real-world
situations in ways human interpreters do. In order to improve their practical
usefulness and enable interpreting-like experiences, a precise understanding of
the nature of human interpreting is crucial. To this end, we discuss human
interpreting literature from the perspective of the machine translation field,
while considering both operational and qualitative aspects. We identify
implications for the development of speech translation systems and argue that
there is great potential to adopt many human interpreting principles using
recent modeling techniques. We hope that our findings provide inspiration for
closing the perceived usability gap, and can motivate progress toward true
machine interpreting.

</details>


### [296] [Understanding Syntactic Generalization in Structure-inducing Language Models](https://arxiv.org/abs/2508.07969)
*David Arps,Hassan Sajjad,Laura Kallmeyer*

Main category: cs.CL

TL;DR: 本文探讨了三种结构诱导语言模型（SiLM）的表现，分析了其语法性判断任务、训练动态以及所生成的语法结构，并发现不同模型在评估指标上表现差异显著。


<details>
  <summary>Details</summary>
Motivation: 评估现有SiLM模型的性能和其在生成层级句法表示方面的差异，并填补现有模型评估中的系统性空白。

Method: 对三种SiLM架构（Structformer、UDGN和GPST）在自然语言和合成数据集上进行比较，分析其生成的语法结构、语法判断能力以及训练行为。

Result: 发现GPST在不同评估任务上表现更加一致，特别是在长距离依赖的括号表达中超越其他模型，并证明了用小型模型和大量合成数据进行测试的可行性。

Conclusion: 不同SiLM在各方面的表现存在显著差异，其中GPST表现总体最佳，未来可利用针对性的数据和测试框架更全面地评估SiLM性能。

Abstract: Structure-inducing Language Models (SiLM) are trained on a self-supervised
language modeling task, and induce a hierarchical sentence representation as a
byproduct when processing an input. A wide variety of SiLMs have been proposed.
However, these have typically been evaluated on a relatively small scale, and
evaluation of these models has systematic gaps and lacks comparability. In this
work, we study three different SiLM architectures using both natural language
(English) corpora and synthetic bracketing expressions: Structformer (Shen et
al., 2021), UDGN (Shen et al., 2022) and GPST (Hu et al., 2024). We compare
them with respect to (i) properties of the induced syntactic representations
(ii) performance on grammaticality judgment tasks, and (iii) training dynamics.
We find that none of the three architectures dominates across all evaluation
metrics. However, there are significant differences, in particular with respect
to the induced syntactic representations. The Generative Pretrained Structured
Transformer (GPST; Hu et al. 2024) performs most consistently across evaluation
settings, and outperforms the other models on long-distance dependencies in
bracketing expressions. Furthermore, our study shows that small models trained
on large amounts of synthetic data provide a useful testbed for evaluating
basic model properties.

</details>


### [297] [Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL](https://arxiv.org/abs/2508.07976)
*Jiaxuan Gao,Wei Fu,Minyang Xie,Shusheng Xu,Chuyi He,Zhiyu Mei,Banghua Zhu,Yi Wu*

Main category: cs.CL

TL;DR: 本文介绍了ASearcher项目，通过大规模强化学习训练搜索智能体，提升长时搜索能力和训练效率，显著改善搜索表现。


<details>
  <summary>Details</summary>
Motivation: 现有开源智能体在搜索智能方面未达专家水平，局限于可扩展性、效率和数据质量，限制了复杂策略学习。

Method: 提出了ASearcher框架，采用全异步强化学习训练搜索智能体，同时设计基于LLM的提示生成器生成大规模高质量QA数据进行训练。

Result: 通过RL训练，ASearcher中的QwQ-32B代理在xBench和GAIA基准测试中分别提升46.7%和20.8%的Avg@4分数，长时搜索表现显著提升。

Conclusion: ASearcher框架通过简单智能体设计和无外部LLM支持，超越了现有开源方法，其开源数据、模型和代码为进一步研究提供了资源。

Abstract: Recent advancements in LLM-based agents have demonstrated remarkable
capabilities in handling complex, knowledge-intensive tasks by integrating
external tools. Among diverse choices of tools, search tools play a pivotal
role in accessing vast external knowledge. However, open-source agents still
fall short of achieving expert-level Search Intelligence, the ability to
resolve ambiguous queries, generate precise searches, analyze results, and
conduct thorough exploration. Existing approaches fall short in scalability,
efficiency, and data quality. For example, small turn limits in existing online
RL methods, e.g. <=10, restrict complex strategy learning. This paper
introduces ASearcher, an open-source project for large-scale RL training of
search agents. Our key contributions include: (1) Scalable fully asynchronous
RL training that enables long-horizon search while maintaining high training
efficiency. (2) A prompt-based LLM agent that autonomously synthesizes
high-quality and challenging QAs, creating a large-scale QA dataset. Through RL
training, our prompt-based QwQ-32B agent achieves substantial improvements,
with 46.7% and 20.8% Avg@4 gains on xBench and GAIA, respectively. Notably, our
agent exhibits extreme long-horizon search, with tool calls exceeding 40 turns
and output tokens exceeding 150k during training time. With a simple agent
design and no external LLMs, ASearcher-Web-QwQ achieves Avg@4 scores of 42.1 on
xBench and 52.8 on GAIA, surpassing existing open-source 32B agents. We
open-source our models, training data, and codes in
https://github.com/inclusionAI/ASearcher.

</details>


### [298] [The Medical Metaphors Corpus (MCC)](https://arxiv.org/abs/2508.07993)
*Anna Sofia Lippolis,Andrea Giovanni Nuzzolese,Aldo Gangemi*

Main category: cs.CL

TL;DR: 這篇論文提出了醫學比喻語料庫（MCC），專注於醫學和生物學領域的科學概念比喻表達，並探討語言模型在這一領域的表現。


<details>
  <summary>Details</summary>
Motivation: 目前的比喻檢測資源主要針對一般文本，缺乏針對具體領域應用的資源，尤其是科學比喻描述的需求。

Method: 作者建立了一個包含792個經過人工註釋的醫學和生物學領域的科學概念比喻語料庫，並包括來自文獻、媒體及社交平台的數據，提供比喻性打分與源-目標概念映射等詳細信息。

Result: 現有先進語言模型在檢測科學比喻時表現有限，顯示出在處理領域特定比喻理解方面有顯著的改進空間。

Conclusion: MCC語料庫為比喻檢測基準化、質量感知生成系統、以患者為中心的交流工具開發等多種研究應用提供了資源基礎。

Abstract: Metaphor is a fundamental cognitive mechanism that shapes scientific
understanding, enabling the communication of complex concepts while potentially
constraining paradigmatic thinking. Despite the prevalence of figurative
language in scientific discourse, existing metaphor detection resources
primarily focus on general-domain text, leaving a critical gap for
domain-specific applications. In this paper, we present the Medical Metaphors
Corpus (MCC), a comprehensive dataset of 792 annotated scientific conceptual
metaphors spanning medical and biological domains. MCC aggregates metaphorical
expressions from diverse sources including peer-reviewed literature, news
media, social media discourse, and crowdsourced contributions, providing both
binary and graded metaphoricity judgments validated through human annotation.
Each instance includes source-target conceptual mappings and perceived
metaphoricity scores on a 0-7 scale, establishing the first annotated resource
for computational scientific metaphor research. Our evaluation demonstrates
that state-of-the-art language models achieve modest performance on scientific
metaphor detection, revealing substantial room for improvement in
domain-specific figurative language understanding. MCC enables multiple
research applications including metaphor detection benchmarking, quality-aware
generation systems, and patient-centered communication tools.

</details>


### [299] [WideSearch: Benchmarking Agentic Broad Info-Seeking](https://arxiv.org/abs/2508.07999)
*Ryan Wong,Jiawei Wang,Junjie Zhao,Li Chen,Yan Gao,Long Zhang,Xuan Zhou,Zuo Wang,Kai Xiang,Ge Zhang,Wenhao Huang,Yang Wang,Ke Wang*

Main category: cs.CL

TL;DR: 提出WideSearch基准以评估大型语言模型驱动的搜索代理在大规模信息收集任务中的表现，结果显示现有系统表现不佳。


<details>
  <summary>Details</summary>
Motivation: 解决当前大型语言模型驱动搜索代理在大规模信息搜集可靠性和完整性评估方面存在的空白。

Method: 设计并推出WideSearch基准，包括200个手动整理的问题，覆盖15个领域，通过严格的五步质量控制流程确保数据集的难度、完整性和可验证性，并对多种搜索系统进行基准测试。

Result: 大多数系统成功率接近0%，最优系统仅达到5%的成功率；但通过多位人工测试验证可接近100%的成功率。

Conclusion: 当前搜索代理在大规模信息搜集任务中存在显著不足，需要进一步研究和开发。

Abstract: From professional research to everyday planning, many tasks are bottlenecked
by wide-scale information seeking, which is more repetitive than cognitively
complex. With the rapid development of Large Language Models (LLMs), automated
search agents powered by LLMs offer a promising solution to liberate humans
from this tedious work. However, the capability of these agents to perform such
"wide-context" collection reliably and completely remains largely unevaluated
due to a lack of suitable benchmarks. To bridge this gap, we introduce
WideSearch, a new benchmark engineered to evaluate agent reliability on these
large-scale collection tasks. The benchmark features 200 manually curated
questions (100 in English, 100 in Chinese) from over 15 diverse domains,
grounded in real user queries. Each task requires agents to collect large-scale
atomic information, which could be verified one by one objectively, and arrange
it into a well-organized output. A rigorous five-stage quality control pipeline
ensures the difficulty, completeness, and verifiability of the dataset. We
benchmark over 10 state-of-the-art agentic search systems, including
single-agent, multi-agent frameworks, and end-to-end commercial systems. Most
systems achieve overall success rates near 0\%, with the best performer
reaching just 5\%. However, given sufficient time, cross-validation by multiple
human testers can achieve a near 100\% success rate. These results demonstrate
that present search agents have critical deficiencies in large-scale
information seeking, underscoring urgent areas for future research and
development in agentic search. Our dataset, evaluation pipeline, and benchmark
results have been publicly released at https://widesearch-seed.github.io/

</details>


### [300] [Progressive Depth Up-scaling via Optimal Transport](https://arxiv.org/abs/2508.08011)
*Mingzi Cao,Xi Wang,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 本文提出了一种基于最优传输（OT）的深度扩展方法OpT-DeUS，用于提高大语言模型（LLMs）的性能和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有深度扩展方法忽视了神经元置换差异导致对齐误差，影响性能表现。

Method: 通过最优传输（OT）方法对相邻基础层之间的Transformer块进行对齐与融合，创建新的深度层。

Result: OpT-DeUS方法在连续预训练和有监督微调中表现优于现有方法，同时提高了训练效率。特别是，靠近顶层插入新层可实现更高的训练效率。

Conclusion: OpT-DeUS可以有效缓解层间神经元置换失配问题，提高大语言模型的效率和性能。

Abstract: Scaling Large Language Models (LLMs) yields performance gains but incurs
substantial training costs. Depth up-scaling offers training efficiency by
adding new layers to pre-trained models. However, most existing methods copy or
average weights from base layers, neglecting neuron permutation differences.
This limitation can potentially cause misalignment that harms performance.
Inspired by applying Optimal Transport (OT) for neuron alignment, we propose
Optimal Transport Depth Up-Scaling (OpT-DeUS). OpT-DeUS aligns and fuses
Transformer blocks in adjacent base layers via OT for new layer creation, to
mitigate neuron permutation mismatch between layers. OpT-DeUS achieves better
overall performance and offers improved training efficiency than existing
methods for continual pre-training and supervised fine-tuning across different
model sizes. To further evaluate the impact of interpolation positions, our
extensive analysis shows that inserting new layers closer to the top results in
higher training efficiency due to shorter back-propagation time while obtaining
additional performance gains.

</details>


### [301] [9th Workshop on Sign Language Translation and Avatar Technologies (SLTAT 2025)](https://arxiv.org/abs/2508.08050)
*Fabrizio Nunnari,Cristina Luna Jiménez,Rosalee Wolfe,John C. McDonald,Michael Filhol,Eleni Efthimiou,Evita Fotinea,Thomas Hanke*

Main category: cs.CL

TL;DR: SLTAT 2025聚焦于改善聋人和一般人群沟通的非侵入性方法，涵盖手语翻译、数据分析等多个领域。


<details>
  <summary>Details</summary>
Motivation: 探讨通过非侵入性技术改善聋人和普通人之间的交流。

Method: 组织SLTAT 2025，与智能虚拟代理国际会议联动，促进数字人技术的跨领域交流。

Result: 涵盖内容广泛，包括手语识别、数据采集与分析、伦理、用户体验等诸多研究方向。

Conclusion: SLTAT为手语翻译和虚拟交互代理等研究提供了交流平台，展示了相关领域的技术进展。

Abstract: The Sign Language Translation and Avatar Technology (SLTAT) workshops
continue a series of gatherings to share recent advances in improving deaf /
human communication through non-invasive means. This 2025 edition, the 9th
since its first appearance in 2011, is hosted by the International Conference
on Intelligent Virtual Agents (IVA), giving the opportunity for contamination
between two research communities, using digital humans as either virtual
interpreters or as interactive conversational agents. As presented in this
summary paper, SLTAT sees contributions beyond avatar technologies, with a
consistent number of submissions on sign language recognition, and other work
on data collection, data analysis, tools, ethics, usability, and affective
computing.

</details>


### [302] [Dual Information Speech Language Models for Emotional Conversations](https://arxiv.org/abs/2508.08095)
*Chun Wang,Chenyang Liu,Wenze Xu,Weihong Deng*

Main category: cs.CL

TL;DR: 提出了一种改进语音语言模型（SLMs）的方法，通过异构适配器和弱监督训练策略提升其处理副语言信息和上下文理解的能力。


<details>
  <summary>Details</summary>
Motivation: 目前的语音语言模型难以同时捕获副语言信息和上下文理解能力，主要因为信息混杂和训练策略不当。

Method: 引入两种异构适配器和弱监督训练策略，分离语言与副语言信息，同时通过受控随机性避免生成特定任务向量，确保上下文理解能力。

Result: 在情感对话任务中表现出竞争力，证明模型能够在上下文环境下有效整合副语言与语言信息。

Conclusion: 通过结构化的记号表征和高效的训练策略，改进了语音语言模型的性能，使其在情感和语境理解方面更有优势。

Abstract: Conversational systems relying on text-based large language models (LLMs)
often overlook paralinguistic cues, essential for understanding emotions and
intentions. Speech-language models (SLMs), which use speech as input, are
emerging as a promising solution. However, SLMs built by extending frozen LLMs
struggle to capture paralinguistic information and exhibit reduced context
understanding. We identify entangled information and improper training
strategies as key issues. To address these issues, we propose two heterogeneous
adapters and suggest a weakly supervised training strategy. Our approach
disentangles paralinguistic and linguistic information, enabling SLMs to
interpret speech through structured representations. It also preserves
contextual understanding by avoiding the generation of task-specific vectors
through controlled randomness. This approach trains only the adapters on common
datasets, ensuring parameter and data efficiency. Experiments demonstrate
competitive performance in emotional conversation tasks, showcasing the model's
ability to effectively integrate both paralinguistic and linguistic information
within contextual settings.

</details>


### [303] [Assessing LLM Text Detection in Educational Contexts: Does Human Contribution Affect Detection?](https://arxiv.org/abs/2508.08096)
*Lukas Gehring,Benjamin Paaßen*

Main category: cs.CL

TL;DR: 本文提出了一种名为GEDE的新数据集，用于评估大语言模型生成文本在教育背景中的自动检测，并表明许多检测器在区分部分由人类改进的生成文本时存在局限性。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型（LLM）的普及增加了学生利用其生成文本的可能性，对维护学术诚信和促进学习提出了新挑战，因此需要更好的方法来检测LLM生成的文本。

Method: 本文提出了一个包含学生和LLM生成文本的新的基准数据集GEDE，并引入了贡献等级的理念，用以区分不同程度的人类与LLM生成内容的结合。同时比较了现有检测器的检测能力。

Result: 研究发现，多数检测器难以准确分类中间贡献等级的文本，并容易产生误判，尤其是对存在LLM改进的文本分类。此外，主动伪装LLM生成内容还进一步降低了检测器的性能。

Conclusion: 现有检测器对于教育场景意义有限，特别是在假阳性率较高情况下，需要新的解决方案以更有效地区分学生贡献，维护教育公平性。

Abstract: Recent advancements in Large Language Models (LLMs) and their increased
accessibility have made it easier than ever for students to automatically
generate texts, posing new challenges for educational institutions. To enforce
norms of academic integrity and ensure students' learning, learning analytics
methods to automatically detect LLM-generated text appear increasingly
appealing. This paper benchmarks the performance of different state-of-the-art
detectors in educational contexts, introducing a novel dataset, called
Generative Essay Detection in Education (GEDE), containing over 900
student-written essays and over 12,500 LLM-generated essays from various
domains. To capture the diversity of LLM usage practices in generating text, we
propose the concept of contribution levels, representing students' contribution
to a given assignment. These levels range from purely human-written texts, to
slightly LLM-improved versions, to fully LLM-generated texts, and finally to
active attacks on the detector by "humanizing" generated texts. We show that
most detectors struggle to accurately classify texts of intermediate student
contribution levels, like LLM-improved human-written texts. Detectors are
particularly likely to produce false positives, which is problematic in
educational settings where false suspicions can severely impact students'
lives. Our dataset, code, and additional supplementary materials are publicly
available at
https://github.com/lukasgehring/Assessing-LLM-Text-Detection-in-Educational-Contexts.

</details>


### [304] [Iterative refinement, not training objective, makes HuBERT behave differently from wav2vec 2.0](https://arxiv.org/abs/2508.08110)
*Robin Huo,Ewan Dunbar*

Main category: cs.CL

TL;DR: 研究了自监督语音表示学习模型HuBERT和wav2vec 2.0中架构的差异对所学语言学信息的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨模型架构对自监督语音表示学习中所学语言学信息的影响，填补该研究领域的空白。

Method: 对HuBERT和wav2vec 2.0模型进行对比，重点分析训练目标和多次迭代训练中的伪标签细化对学习表示的影响。

Result: 发现隐藏表示的语词、音素及说话人身份的相关性差异主要由训练迭代次数决定，而非训练目标。

Conclusion: 建议未来研究关注迭代细化在自监督语音表示中编码语言学信息的机制。

Abstract: Self-supervised models for speech representation learning now see widespread
use for their versatility and performance on downstream tasks, but the effect
of model architecture on the linguistic information learned in their
representations remains under-studied. This study investigates two such models,
HuBERT and wav2vec 2.0, and minimally compares two of their architectural
differences: training objective and iterative pseudo-label refinement through
multiple training iterations. We find that differences in canonical correlation
of hidden representations to word identity, phoneme identity, and speaker
identity are explained by training iteration, not training objective. We
suggest that future work investigate the reason for the effectiveness of
iterative refinement in encoding linguistic information in self-supervised
speech representations.

</details>


### [305] [Czech Dataset for Complex Aspect-Based Sentiment Analysis Tasks](https://arxiv.org/abs/2508.08125)
*Jakub Šmíd,Pavel Přibáň,Ondřej Pražák,Pavel Král*

Main category: cs.CL

TL;DR: 提出一个新的捷克餐饮行业ABSA数据集，包括3.1K标注评论和24M非标注评论，以支持复杂情感分析任务和跨语言比较，提供基于Transformer的基线结果。


<details>
  <summary>Details</summary>
Motivation: 当前捷克ABSA数据集支持有限任务，无法满足复杂情感分析需求，本研究旨在填补这一空白并促进跨语言比较研究。

Method: 采用手动标注构建新的数据集，设计统一的注释格式，确保与SemEval-2016格式兼容；利用Transformer模型作为基线，并进行误差分析。

Result: 新数据集具有90%标注一致性率，提供了用于无监督学习的24M未标注数据，以及Transformer-based模型的基线性能结果。

Conclusion: 新数据集不仅提升了捷克语言情感分析能力，还通过与SemEval-2016格式的兼容性，推动了跨语言研究和复杂任务探讨。

Abstract: In this paper, we introduce a novel Czech dataset for aspect-based sentiment
analysis (ABSA), which consists of 3.1K manually annotated reviews from the
restaurant domain. The dataset is built upon the older Czech dataset, which
contained only separate labels for the basic ABSA tasks such as aspect term
extraction or aspect polarity detection. Unlike its predecessor, our new
dataset is specifically designed for more complex tasks, e.g.
target-aspect-category detection. These advanced tasks require a unified
annotation format, seamlessly linking sentiment elements (labels) together. Our
dataset follows the format of the well-known SemEval-2016 datasets. This design
choice allows effortless application and evaluation in cross-lingual scenarios,
ultimately fostering cross-language comparisons with equivalent counterpart
datasets in other languages. The annotation process engaged two trained
annotators, yielding an impressive inter-annotator agreement rate of
approximately 90%. Additionally, we provide 24M reviews without annotations
suitable for unsupervised learning. We present robust monolingual baseline
results achieved with various Transformer-based models and insightful error
analysis to supplement our contributions. Our code and dataset are freely
available for non-commercial research purposes.

</details>


### [306] [Optimal Transport Regularization for Speech Text Alignment in Spoken Language Models](https://arxiv.org/abs/2508.08131)
*Wenze Xu,Chun Wang,Jiazhen Yu,Sheng Chen,Liang Gao,Weihong Deng*

Main category: cs.CL

TL;DR: 本文引入了一种名为Optimal Transport Regularization（OTReg）的方法，通过将语音与文本对齐作为一个最优传输问题进行建模，有效改善了多语种语音识别中SLM的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 目前的SLM在处理跨数据集的泛化问题上表现欠佳，部分原因是语音与文本的表现形式存在模态差异，阻碍了模型的理解能力。

Method: 作为一种无监督的正则化机制，OTReg通过最优传输计划建立语音与文本嵌入之间的关联，并引入正则化损失以优化模型，使语音嵌入更接近于文本嵌入。整个过程无需额外的标签或可学习参数，能够轻松整合到现有的SLM训练流程中。

Result: 通过多语种语音识别实验验证，OTReg提高了语音与文本的对齐效果，有效缩小了模态间差距，从而改进了模型在多样化数据集上的泛化性能。

Conclusion: OTReg是一种轻量级且高效的方法，能够显著增强SLM的泛化能力，其无缝整合能力及提升效果为未来SLM研究提供了新方向。

Abstract: Spoken Language Models (SLMs), which extend Large Language Models (LLMs) to
perceive speech inputs, have gained increasing attention for their potential to
advance speech understanding tasks. However, despite recent progress, studies
show that SLMs often struggle to generalize across datasets, even for trained
languages and tasks, raising concerns about whether they process speech in a
text-like manner as intended. A key challenge underlying this limitation is the
modality gap between speech and text representations. The high variability in
speech embeddings may allow SLMs to achieve strong in-domain performance by
exploiting unintended speech variations, ultimately hindering generalization.
To mitigate this modality gap, we introduce Optimal Transport Regularization
(OTReg), a method that formulates speech-text alignment as an optimal transport
problem and derives a regularization loss to improve SLM training. In each
training iteration, OTReg first establishes a structured correspondence between
speech and transcript embeddings by determining the optimal transport plan,
then incorporates the regularization loss based on this transport plan to
optimize SLMs in generating speech embeddings that align more effectively with
transcript embeddings. OTReg is lightweight, requiring no additional labels or
learnable parameters, and integrates seamlessly into existing SLM training
procedures. Extensive multilingual ASR experiments demonstrate that OTReg
enhances speech-text alignment, mitigates the modality gap, and consequently
improves SLM generalization across diverse datasets.

</details>


### [307] [Can LLMs Detect Their Confabulations? Estimating Reliability in Uncertainty-Aware Language Models](https://arxiv.org/abs/2508.08139)
*Tianyi Zhou,Johanne Medina,Sanjay Chawla*

Main category: cs.CL

TL;DR: LLMs在生成内容时易于错误，研究关注模型行为对上下文信息的依赖及其识别错误响应的能力。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs因错误生成内容可能引发的多回合或代理风险，研究上下文信息对模型行为的影响。

Method: 提出一种基于不确定性估计的方法，结合显著性词汇和隐藏状态以预测响应可靠性。

Result: 通过开放式QA测试发现，正确上下文提升准确性和信心，错误上下文会导致错误且自信的响应；所提出方法能改善不可靠输出的检测效果。

Conclusion: 表明直接的不确定性信号有局限性，强调基于不确定性引导方法在生成可靠性中的潜力。

Abstract: Large Language Models (LLMs) are prone to generating fluent but incorrect
content, known as confabulation, which poses increasing risks in multi-turn or
agentic applications where outputs may be reused as context. In this work, we
investigate how in-context information influences model behavior and whether
LLMs can identify their unreliable responses. We propose a reliability
estimation that leverages token-level uncertainty to guide the aggregation of
internal model representations. Specifically, we compute aleatoric and
epistemic uncertainty from output logits to identify salient tokens and
aggregate their hidden states into compact representations for response-level
reliability prediction. Through controlled experiments on open QA benchmarks,
we find that correct in-context information improves both answer accuracy and
model confidence, while misleading context often induces confidently incorrect
responses, revealing a misalignment between uncertainty and correctness. Our
probing-based method captures these shifts in model behavior and improves the
detection of unreliable outputs across multiple open-source LLMs. These results
underscore the limitations of direct uncertainty signals and highlight the
potential of uncertainty-guided probing for reliability-aware generation.

</details>


### [308] [Data-Efficient Biomedical In-Context Learning: A Diversity-Enhanced Submodular Perspective](https://arxiv.org/abs/2508.08140)
*Jun Wang,Zaifu Zhan,Qixin Zhang,Mingquan Lin,Meijia Song,Rui Zhang*

Main category: cs.CL

TL;DR: 该论文提出了一个名为Dual-Div的框架，用于通过增强多样性来提升生物医学领域中大语言模型的任务适应能力，从而在少样本情况下表现出更高效的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在生物医学领域的研究中，示例选择通常优先考虑代表性而忽略了多样性，从而限制了模型性能的进一步提升。为此，作者希望通过优化示例的多样性来填补这一空白。

Method: 提出的Dual-Div框架包含两个阶段：第一阶段通过优化代表性和多样性，从语料库中识别有限的候选示例；第二阶段将这些候选与测试查询匹配，选择最相关的非冗余示例。

Result: 在命名实体识别、关系提取和文本分类3种生物医学任务中，使用LLaMA 3.1和Qwen 2.5进行推断，以及3个检索器的实验下，Dual-Div始终胜过基线方法，宏平均F1分数提升至多5%，并对提示词变化和类别不平衡具有鲁棒性。

Conclusion: 实验结果表明，在初始检索中多样性比排名优化更为关键，并且每次仅使用3-5个示例即可最大化性能效率。

Abstract: Recent progress in large language models (LLMs) has leveraged their
in-context learning (ICL) abilities to enable quick adaptation to unseen
biomedical NLP tasks. By incorporating only a few input-output examples into
prompts, LLMs can rapidly perform these new tasks. While the impact of these
demonstrations on LLM performance has been extensively studied, most existing
approaches prioritize representativeness over diversity when selecting examples
from large corpora. To address this gap, we propose Dual-Div, a
diversity-enhanced data-efficient framework for demonstration selection in
biomedical ICL. Dual-Div employs a two-stage retrieval and ranking process:
First, it identifies a limited set of candidate examples from a corpus by
optimizing both representativeness and diversity (with optional annotation for
unlabeled data). Second, it ranks these candidates against test queries to
select the most relevant and non-redundant demonstrations. Evaluated on three
biomedical NLP tasks (named entity recognition (NER), relation extraction (RE),
and text classification (TC)) using LLaMA 3.1 and Qwen 2.5 for inference, along
with three retrievers (BGE-Large, BMRetriever, MedCPT), Dual-Div consistently
outperforms baselines-achieving up to 5% higher macro-F1 scores-while
demonstrating robustness to prompt permutations and class imbalance. Our
findings establish that diversity in initial retrieval is more critical than
ranking-stage optimization, and limiting demonstrations to 3-5 examples
maximizes performance efficiency.

</details>


### [309] [REX-RAG: Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.08149)
*Wentao Jiang,Xiang Feng,Zengmao Wang,Yong Luo,Pingbo Xu,Zhe Chen,Bo Du,Jing Zhang*

Main category: cs.CL

TL;DR: 本文提出了REX-RAG框架，通过改进策略学习和探索来解决LLMs在检索增强生成中陷入"死胡同"的挑战，并在多个数据集上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 在强化学习与检索增强生成相结合的背景下，LLMs在推理过程中容易陷入错误路径，导致训练和优化受阻。

Method: 提出REX-RAG框架，包含两部分创新：(1)混合采样策略，结合探测采样和探索性提示，避免推理陷阱；(2)策略校正机制，通过重要性采样修正分布偏移，减少梯度估计偏差。

Result: REX-RAG在七个问答基准上测试表现优异：Qwen2.5-3B和Qwen2.5-7B模型分别获得5.1%和3.6%的性能提升，超越多个现有基线。

Conclusion: REX-RAG通过改进推理探索方法和策略优化显著提升了LLMs在复杂任务中的能力，提供了有效的解决方案并开源代码供社区使用。

Abstract: Reinforcement learning (RL) is emerging as a powerful paradigm for enabling
large language models (LLMs) to perform complex reasoning tasks. Recent
advances indicate that integrating RL with retrieval-augmented generation (RAG)
allows LLMs to dynamically incorporate external knowledge, leading to more
informed and robust decision making. However, we identify a critical challenge
during policy-driven trajectory sampling: LLMs are frequently trapped in
unproductive reasoning paths, which we refer to as "dead ends", committing to
overconfident yet incorrect conclusions. This severely hampers exploration and
undermines effective policy optimization. To address this challenge, we propose
REX-RAG (Reasoning Exploration with Policy Correction in Retrieval-Augmented
Generation), a novel framework that explores alternative reasoning paths while
maintaining rigorous policy learning through principled distributional
corrections. Our approach introduces two key innovations: (1) Mixed Sampling
Strategy, which combines a novel probe sampling method with exploratory prompts
to escape dead ends; and (2) Policy Correction Mechanism, which employs
importance sampling to correct distribution shifts induced by mixed sampling,
thereby mitigating gradient estimation bias. We evaluate it on seven
question-answering benchmarks, and the experimental results show that REX-RAG
achieves average performance gains of 5.1% on Qwen2.5-3B and 3.6% on Qwen2.5-7B
over strong baselines, demonstrating competitive results across multiple
datasets. The code is publicly available at https://github.com/MiliLab/REX-RAG.

</details>


### [310] [LPI-RIT at LeWiDi-2025: Improving Distributional Predictions via Metadata and Loss Reweighting with DisCo](https://arxiv.org/abs/2508.08163)
*Mandira Sawkar,Samay U. Shetty,Deepak Pandita,Tharindu Cyril Weerasooriya,Christopher M. Homan*

Main category: cs.CL

TL;DR: 本文提出通过改进DisCo架构来更好地预测标注分歧和评估模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究标注者分歧建模，以提升对软标签分布预测的能力并适应标注个体差异。

Method: 改进了DisCo模型，加入标注者元数据，增强输入表示，并修改损失函数以捕捉分歧模式。

Result: 在三组数据集上取得了软标签分布预测和评估指标的显著提升，同时进行了错误与校准分析。

Conclusion: 研究表明，关注分歧的建模方法在处理人类标注数据复杂性时至关重要。

Abstract: The Learning With Disagreements (LeWiDi) 2025 shared task is to model
annotator disagreement through soft label distribution prediction and
perspectivist evaluation, modeling annotators. We adapt DisCo (Distribution
from Context), a neural architecture that jointly models item-level and
annotator-level label distributions, and present detailed analysis and
improvements. In this paper, we extend the DisCo by incorporating annotator
metadata, enhancing input representations, and modifying the loss functions to
capture disagreement patterns better. Through extensive experiments, we
demonstrate substantial improvements in both soft and perspectivist evaluation
metrics across three datasets. We also conduct in-depth error and calibration
analyses, highlighting the conditions under which improvements occur. Our
findings underscore the value of disagreement-aware modeling and offer insights
into how system components interact with the complexity of human-annotated
data.

</details>


### [311] [Efficient Speculative Decoding for Llama at Scale: Challenges and Solutions](https://arxiv.org/abs/2508.08192)
*Bangsheng Tang,Carl Chengyan Fu,Fei Kou,Grigory Sizov,Haoci Zhang,Jason Park,Jiawen Liu,Jie You,Qirui Yang,Sachin Mehta,Shengyong Cai,Xiaodong Wang,Xingyu Liu,Yunlu Li,Yanjun Zhou,Wei Wei,Zhiwei Zhao,Zixi Qi,Adolfo Victoria,Aya Ibrahim,Bram Wasti,Changkyu Kim,Daniel Haziza,Fei Sun,Giancarlo Delfin,Emily Guo,Jialin Ouyang,Jaewon Lee,Jianyu Huang,Jeremy Reizenstein,Lu Fang,Quinn Zhu,Ria Verma,Vlad Mihailescu,Xingwen Guo,Yan Cui,Ye Hu,Yejin Lee*

Main category: cs.CL

TL;DR: 本文讨论了通过优化技术在推理阶段加速Llama语言模型的推理速度，特别是EAGLE框架基础上的推测解码技术，可以显著提高生产环境下的性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在生产环境中的广泛应用，提升推理速度成为关键需求。然而，在多GPU环境中实现高效的推测解码面临诸多技术挑战。

Method: 通过对推测解码中的关键步骤优化，例如树状注意力机制和多轮推测解码，并专门针对Llama模型对EAGLE方法进行了定制化训练和推理优化。

Result: 成功实现了推测解码在Llama模型中的性能优化。以Llama4 Maverick为例，在8块NVIDIA H100 GPU上实现了每个token约4ms的推理速度，相较之前方法快10%；在大批量操作上实现了1.4倍至2.0倍的加速。

Conclusion: 优化方案显著提升了Llama模型的推理效率，为大规模生产环境提供了更高效的解决方案。

Abstract: Speculative decoding is a standard method for accelerating the inference
speed of large language models. However, scaling it for production environments
poses several engineering challenges, including efficiently implementing
different operations (e.g., tree attention and multi-round speculative
decoding) on GPU. In this paper, we detail the training and inference
optimization techniques that we have implemented to enable EAGLE-based
speculative decoding at a production scale for Llama models. With these
changes, we achieve a new state-of-the-art inference latency for Llama models.
For example, Llama4 Maverick decodes at a speed of about 4 ms per token (with a
batch size of one) on 8 NVIDIA H100 GPUs, which is 10% faster than the
previously best known method. Furthermore, for EAGLE-based speculative
decoding, our optimizations enable us to achieve a speed-up for large batch
sizes between 1.4x and 2.0x at production scale.

</details>


### [312] [Human-Alignment and Calibration of Inference-Time Uncertainty in Large Language Models](https://arxiv.org/abs/2508.08204)
*Kyle Moore,Jesse Roberts,Daryl Watson*

Main category: cs.CL

TL;DR: 本文探讨了评估大语言模型推理时间不确定性的策略，并利用新老指标评估其与人类不确定性以及传统校准的契合度。


<details>
  <summary>Details</summary>
Motivation: 探讨模型推理不确定性与人类不确定性契合性的研究较少，对改善LLM用户体验意义重大。

Method: 评估并分析了多种推理时间的不确定性指标，结合现有和新颖变体指标进行对比实验。

Result: 多个指标显示出与人类不确定性的高度契合性，并在正确性相关性和分布分析方面体现了良好的校准性。

Conclusion: 某些推理时间的不确定性指标不仅可以反映人类不确定性，还展现出强大的模型校准潜力。

Abstract: There has been much recent interest in evaluating large language models for
uncertainty calibration to facilitate model control and modulate user trust.
Inference time uncertainty, which may provide a real-time signal to the model
or external control modules, is particularly important for applying these
concepts to improve LLM-user experience in practice. While many of the existing
papers consider model calibration, comparatively little work has sought to
evaluate how closely model uncertainty aligns to human uncertainty. In this
work, we evaluate a collection of inference-time uncertainty measures, using
both established metrics and novel variations, to determine how closely they
align with both human group-level uncertainty and traditional notions of model
calibration. We find that numerous measures show evidence of strong alignment
to human uncertainty, even despite the lack of alignment to human answer
preference. For those successful metrics, we find moderate to strong evidence
of model calibration in terms of both correctness correlation and
distributional analysis.

</details>


### [313] [SAEMark: Multi-bit LLM Watermarking with Inference-Time Scaling](https://arxiv.org/abs/2508.08211)
*Zhuohao Yu,Xingru Jiang,Weizheng Gu,Yidong Wang,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: 提出了一种名为SAEMark的框架，用于在保持文本质量的前提下，对生成文本进行多位水印嵌入，适用于闭源的大模型和多语言场景。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本水印方法对文本质量的影响以及应用于API模型和多语言场景的局限性。

Method: 通过推断时的基于特征的拒绝采样技术，在不改变模型logit或训练的情况下嵌入个性化水印信息，利用文本生成的确定性特征选择符合水印目标的输出。

Result: 在4个数据集上实验验证了该框架的有效性，在英文数据上的F1得分达到99.7%，并具有较高的多位检测准确性。

Conclusion: SAEMark框架在多语言和不同领域表现良好，且无需更改模型内部结构，为闭源大模型实现了可扩展的内容溯源水印方案。

Abstract: Watermarking LLM-generated text is critical for content attribution and
misinformation prevention. However, existing methods compromise text quality,
require white-box model access and logit manipulation. These limitations
exclude API-based models and multilingual scenarios. We propose SAEMark, a
general framework for post-hoc multi-bit watermarking that embeds personalized
messages solely via inference-time, feature-based rejection sampling without
altering model logits or requiring training. Our approach operates on
deterministic features extracted from generated text, selecting outputs whose
feature statistics align with key-derived targets. This framework naturally
generalizes across languages and domains while preserving text quality through
sampling LLM outputs instead of modifying. We provide theoretical guarantees
relating watermark success probability and compute budget that hold for any
suitable feature extractor. Empirically, we demonstrate the framework's
effectiveness using Sparse Autoencoders (SAEs), achieving superior detection
accuracy and text quality. Experiments across 4 datasets show SAEMark's
consistent performance, with 99.7% F1 on English and strong multi-bit detection
accuracy. SAEMark establishes a new paradigm for scalable watermarking that
works out-of-the-box with closed-source LLMs while enabling content
attribution.

</details>


### [314] [Capabilities of GPT-5 on Multimodal Medical Reasoning](https://arxiv.org/abs/2508.08224)
*Shansong Wang,Mingzhe Hu,Qiang Li,Mojtaba Safari,Xiaofeng Yang*

Main category: cs.CL

TL;DR: 本文研究了GPT-5在医学领域作为通用多模态推理系统的性能，其显著超越了其他基线模型和人类专家。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索GPT-5在医学领域作为通用多模态推理系统的潜力，以支持医疗决策中的复杂推理需求。

Method: 研究采用了统一的评估协议，在各种医学问答数据集上对GPT-5的零样本推理能力进行系统性评估，包括文本和视觉问题解答。还提供了案例研究展示模型的多模态推理性能。

Result: GPT-5在所有基准测试中均优于现有方法，对比GPT-4o在推理和理解能力上分别提升了29.62%和36.18%，并超越了已认证人类专家的表现。

Conclusion: GPT-5在受控的多模态推理基准测试中实现了超越人类专家的表现，为未来医学决策支持系统设计提供了重要借鉴。

Abstract: Recent advances in large language models (LLMs) have enabled general-purpose
systems to perform increasingly complex domain-specific reasoning without
extensive fine-tuning. In the medical domain, decision-making often requires
integrating heterogeneous information sources, including patient narratives,
structured data, and medical images. This study positions GPT-5 as a generalist
multimodal reasoner for medical decision support and systematically evaluates
its zero-shot chain-of-thought reasoning performance on both text-based
question answering and visual question answering tasks under a unified
protocol. We benchmark GPT-5, GPT-5-mini, GPT-5-nano, and GPT-4o-2024-11-20
against standardized splits of MedQA, MedXpertQA (text and multimodal), MMLU
medical subsets, USMLE self-assessment exams, and VQA-RAD. Results show that
GPT-5 consistently outperforms all baselines, achieving state-of-the-art
accuracy across all QA benchmarks and delivering substantial gains in
multimodal reasoning. On MedXpertQA MM, GPT-5 improves reasoning and
understanding scores by +29.62% and +36.18% over GPT-4o, respectively, and
surpasses pre-licensed human experts by +24.23% in reasoning and +29.40% in
understanding. In contrast, GPT-4o remains below human expert performance in
most dimensions. A representative case study demonstrates GPT-5's ability to
integrate visual and textual cues into a coherent diagnostic reasoning chain,
recommending appropriate high-stakes interventions. Our results show that, on
these controlled multimodal reasoning benchmarks, GPT-5 moves from
human-comparable to above human-expert performance. This improvement may
substantially inform the design of future clinical decision-support systems.

</details>


### [315] [Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health Dialogues via LLM-as-Judge](https://arxiv.org/abs/2508.08236)
*Yunna Cai,Fan Wang,Haowei Wang,Kun Wang,Kailai Yang,Sophia Ananiadou,Moyan Li,Mingming Fan*

Main category: cs.CL

TL;DR: 提出了一种用于高风险心理健康对话的LLM安全评估基准——PsyCrisis-Bench，基于真实的中文心理健康对话，并使用无参考答案的评价方法。


<details>
  <summary>Details</summary>
Motivation: 当前高风险心理健康对话中LLM响应的安全性评估缺乏标准答案，且这些对话具有伦理敏感性，因此需要一种替代评估方法。

Method: 提出PsyCrisis-Bench评估基准，基于心理干预原则的专家定义推理链，采用prompt驱动的LLM评估方法，对模型响应在多个安全维度上进行二进制评分，并配以详细的解释性分析。

Result: 在包含3600次评估的实验中，该方法与专家评估的协议度最高，并提供了现有方法中最具解释性的评估理由。

Conclusion: PsyCrisis-Bench为高风险心理健康对话场景提供了一个创新的安全评估框架，并为进一步研究提供公开数据集和工具，推动领域发展。

Abstract: Evaluating the safety alignment of LLM responses in high-risk mental health
dialogues is particularly difficult due to missing gold-standard answers and
the ethically sensitive nature of these interactions. To address this
challenge, we propose PsyCrisis-Bench, a reference-free evaluation benchmark
based on real-world Chinese mental health dialogues. It evaluates whether the
model responses align with the safety principles defined by experts.
Specifically designed for settings without standard references, our method
adopts a prompt-based LLM-as-Judge approach that conducts in-context evaluation
using expert-defined reasoning chains grounded in psychological intervention
principles. We employ binary point-wise scoring across multiple safety
dimensions to enhance the explainability and traceability of the evaluation.
Additionally, we present a manually curated, high-quality Chinese-language
dataset covering self-harm, suicidal ideation, and existential distress,
derived from real-world online discourse. Experiments on 3600 judgments show
that our method achieves the highest agreement with expert assessments and
produces more interpretable evaluation rationales compared to existing
approaches. Our dataset and evaluation tool are publicly available to
facilitate further research.

</details>


### [316] [Jinx: Unlimited LLMs for Probing Alignment Failures](https://arxiv.org/abs/2508.08243)
*Jiahao Zhao,Liwei Dong*

Main category: cs.CL

TL;DR: Jinx是一个开放的无限制语言模型，用于研究AI对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有的无限制语言模型虽然在对齐研究中起重要作用，但研究社区无此类工具。

Method: Jinx基于开源大型语言模型开发，无拒绝和安全筛滤限制，保留推理和指令性能。

Result: 研究者可以用Jinx探测对齐失效、评估安全边界、系统研究语言模型安全失败模式。

Conclusion: Jinx为深入研究AI对齐问题和安全提供了一个开放的工具。

Abstract: Unlimited, or so-called helpful-only language models are trained without
safety alignment constraints and never refuse user queries. They are widely
used by leading AI companies as internal tools for red teaming and alignment
evaluation. For example, if a safety-aligned model produces harmful outputs
similar to an unlimited model, this indicates alignment failures that require
further attention. Despite their essential role in assessing alignment, such
models are not available to the research community.
  We introduce Jinx, a helpful-only variant of popular open-weight LLMs. Jinx
responds to all queries without refusals or safety filtering, while preserving
the base model's capabilities in reasoning and instruction following. It
provides researchers with an accessible tool for probing alignment failures,
evaluating safety boundaries, and systematically studying failure modes in
language model safety.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [317] [Solving Pasur Using GPU-Accelerated Counterfactual Regret Minimization](https://arxiv.org/abs/2508.06559)
*Sina Baghal*

Main category: cs.AI

TL;DR: 本文提出了一个CUDA加速的计算框架，用于模拟Pasur纸牌游戏，通过反事实后悔最小化算法（CFR）计算近似纳什均衡。研究包含复杂规则处理、超大规模游戏树的记忆高效设计以及回溯训练策略。最终通过大规模自我博弈估算各卡组的公平值。


<details>
  <summary>Details</summary>
Motivation: 解决Pasur游戏复杂规则和超大规模游戏树的高效模拟，并通过近似纳什均衡计算以理解游戏策略及其公平性问题。

Method: 引入CUDA加速框架，处理涉及PyTorch CUDA张量的复杂规则；通过分解游戏树，存储关键状态，减少内存开销；采用回溯训练策略，从最后一轮向前递归传播效用值；最后训练树模型实现策略预测。

Result: 成功计算了包含超过10亿节点的完整游戏树，模拟了10,000局比赛以评估策略，同时利用GPU加速实现高效并行计算。

Conclusion: 该框架不仅成功解决了Pasur游戏的模拟与策略优化问题，还可广泛应用于其他回合制游戏或金融市场中的序列决策问题。

Abstract: Pasur is a fishing card game played over six rounds and is played similarly
to games such as Cassino and Scopa, and Bastra. This paper introduces a
CUDA-accelerated computational framework for simulating Pasur, emphasizing
efficient memory management. We use our framework to compute near-Nash
equilibria via Counterfactual Regret Minimization (CFR), a well-known algorithm
for solving large imperfect-information games.
  Solving Pasur presents unique challenges due to its intricate rules and the
large size of its game tree. We handle rule complexity using PyTorch CUDA
tensors and to address the memory-intensive nature of the game, we decompose
the game tree into two key components: (1) actual game states, and (2)
inherited scores from previous rounds. We construct the Full Game Tree by
pairing card states with accumulated scores in the Unfolding Process. This
design reduces memory overhead by storing only essential strategy values and
node connections. To further manage computational complexity, we apply a
round-by-round backward training strategy, starting from the final round and
recursively propagating average utilities to earlier stages. Our approach
constructs the complete game tree, which on average consists of over $10^9$
nodes. We provide detailed implementation snippets.
  After computing a near-Nash equilibrium strategy, we train a tree-based model
to predict these strategies for use during gameplay. We then estimate the fair
value of each deck through large-scale self-play between equilibrium strategies
by simulating, for instance, 10,000 games per matchup, executed in parallel
using GPU acceleration.
  Similar frameworks can be extended to other reinforcement learning algorithms
where the action tree naturally decomposes into multiple rounds such as
turn-based strategy games or sequential trading decisions in financial markets.

</details>


### [318] [Operationalizing Serendipity: Multi-Agent AI Workflows for Enhanced Materials Characterization with Theory-in-the-Loop](https://arxiv.org/abs/2508.06569)
*Lance Yao,Suman Samantray,Ayana Ghosh,Kevin Roccapriore,Libor Kovarik,Sarah Allec,Maxim Ziatdinov*

Main category: cs.AI

TL;DR: SciLink 是一个开源多智能体 AI 框架，旨在通过将实验观察、创新性评估和理论模拟直接连接起来，在材料研究中实现偶然性发现。


<details>
  <summary>Details</summary>
Motivation: 解决现有自主实验室注重效率但容易忽视偶然性发现的问题，利用 AI 框架在材料研究中促进开放性探索。

Method: 采用混合 AI 策略，结合机器学习模型进行定量分析，语言模型进行高层次推理，自动将实验数据转化为科学假设，并基于文献创新性评分进行评估。

Result: 框架能够解析各种实验数据，支持人类专家实时指导，并提出后续实验建议，展示了其实用性和多场景适应性。

Conclusion: SciLink 为材料研究提供了一个高效且能促进偶然发现的 AI 驱动框架，弥合了自动化试验与开放科学探索之间的差距。

Abstract: The history of science is punctuated by serendipitous discoveries, where
unexpected observations, rather than targeted hypotheses, opened new fields of
inquiry. While modern autonomous laboratories excel at accelerating hypothesis
testing, their optimization for efficiency risks overlooking these crucial,
unplanned findings. To address this gap, we introduce SciLink, an open-source,
multi-agent artificial intelligence framework designed to operationalize
serendipity in materials research by creating a direct, automated link between
experimental observation, novelty assessment, and theoretical simulations. The
framework employs a hybrid AI strategy where specialized machine learning
models perform quantitative analysis of experimental data, while large language
models handle higher-level reasoning. These agents autonomously convert raw
data from materials characterization techniques into falsifiable scientific
claims, which are then quantitatively scored for novelty against the published
literature. We demonstrate the framework's versatility across diverse research
scenarios, showcasing its application to atomic-resolution and hyperspectral
data, its capacity to integrate real-time human expert guidance, and its
ability to close the research loop by proposing targeted follow-up experiments.
By systematically analyzing all observations and contextualizing them, SciLink
provides a practical framework for AI-driven materials research that not only
enhances efficiency but also actively cultivates an environment ripe for
serendipitous discoveries, thereby bridging the gap between automated
experimentation and open-ended scientific exploration.

</details>


### [319] [IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model](https://arxiv.org/abs/2508.06571)
*Anqing Jiang,Yu Gao,Yiru Wang,Zhigang Sun,Shuo Wang,Yuwen Heng,Hao Sun,Shichen Tang,Lijuan Zhu,Jinhao Chai,Jijun Wang,Zichong Gu,Hao Jiang,Li Sun*

Main category: cs.AI

TL;DR: 该论文提出了IRL-VLA框架，通过逆强化学习的奖励模型和VLA体系架构解决自动驾驶领域存在的问题，并在相关基准中获得卓越表现。


<details>
  <summary>Details</summary>
Motivation: 解决当前基于视觉-语言-动作模型（VLA）中开环学习低效闭环训练高成本的问题，推动闭环自主驾驶研究。

Method: 提出了三阶段流程，1. 通过模仿学习预训练VLA策略，2. 训练轻量级逆强化学习奖励模型启用高效闭环计算，3. 使用PPO强化学习优化驾驶性能。

Result: 所提方法在NAVSIM v2端到端驾驶基准中达到了最先进的性能，并在CVPR2025 Autonomous Grand Challenge中获得了亚军。

Conclusion: IRL-VLA框架有效提升了闭环自主驾驶中的性能和效率，展现了推动该领域研究的潜力。

Abstract: Vision-Language-Action (VLA) models have demonstrated potential in autonomous
driving. However, two critical challenges hinder their development: (1)
Existing VLA architectures are typically based on imitation learning in
open-loop setup which tends to capture the recorded behaviors in the dataset,
leading to suboptimal and constrained performance, (2) Close-loop training
relies heavily on high-fidelity sensor simulation, where domain gaps and
computational inefficiencies pose significant barriers. In this paper, we
introduce IRL-VLA, a novel close-loop Reinforcement Learning via
\textbf{I}nverse \textbf{R}einforcement \textbf{L}earning reward world model
with a self-built VLA approach. Our framework proceeds in a three-stage
paradigm: In the first stage, we propose a VLA architecture and pretrain the
VLA policy via imitation learning. In the second stage, we construct a
lightweight reward world model via inverse reinforcement learning to enable
efficient close-loop reward computation. To further enhance planning
performance, finally, we design specialized reward world model guidence
reinforcement learning via PPO(Proximal Policy Optimization) to effectively
balance the safety incidents, comfortable driving, and traffic efficiency. Our
approach achieves state-of-the-art performance in NAVSIM v2 end-to-end driving
benchmark, 1st runner up in CVPR2025 Autonomous Grand Challenge. We hope that
our framework will accelerate VLA research in close-loop autonomous driving.

</details>


### [320] [CountQA: How Well Do MLLMs Count in the Wild?](https://arxiv.org/abs/2508.06585)
*Jayant Sravan Tamarapalli,Rynaa Grover,Nilay Pande,Sahiti Yerramilli*

Main category: cs.AI

TL;DR: 提出CountQA基准用于评估多模态大语言模型在物体计数能力上的不足，并发现现有模型在该任务上的性能较差（最高准确率42.9%），特别是面对高密度、复杂场景时表现更差。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在描述视觉场景的能力上表现出色，但在物体计数这一基本认知技能上存在明显不足，严重制约了其在实际应用中的可靠性。然而，目前的评估基准大多在低密度或特定视觉域场景中进行，无法测试模型在真实复杂环境下的能力。

Method: 提出一个新的挑战性基准CountQA，包含超过1500个问答对，专注于高密度、复杂场景中物体计数能力的评估。测试了15种多模态大语言模型在CountQA上的表现，并分析其能力缺陷。

Result: 评估结果显示，性能最好的模型在CountQA基准上的准确率仅为42.9%，且随着物体数量的增加，模型表现进一步下降。

Conclusion: CountQA基准的引入为诊断和改进多模态大语言模型的物体计数能力提供了专用工具，未来有望催生能在数值和空间认知上更为精准的多模态大语言模型。

Abstract: Multimodal Large Language Models (MLLMs) demonstrate remarkable fluency in
understanding visual scenes, yet they exhibit a critical lack in a fundamental
cognitive skill: object counting. This blind spot severely limits their
reliability in real-world applications. To date, this capability has been
largely unevaluated in complex scenarios, as existing benchmarks either feature
sparse object densities or are confined to specific visual domains, failing to
test models under realistic conditions. Addressing this gap, we introduce
CountQA, a challenging new benchmark designed to probe this deficiency.
Comprising over 1,500 question-answer pairs, CountQA features real-world images
with high object density, clutter, and occlusion. We investigate this weakness
by evaluating 15 prominent MLLMs on the CountQA benchmark and reveal that the
top-performing model achieves a mere 42.9% accuracy, with performance declining
as object counts rise. By providing a dedicated benchmark to diagnose and
rectify this core weakness, CountQA paves the way for a new generation of MLLMs
that are not only descriptively fluent but also numerically grounded and
spatially aware. We will open-source the dataset and code upon paper acceptance
to foster further research.

</details>


### [321] [Formal Concept Analysis: a Structural Framework for Variability Extraction and Analysis](https://arxiv.org/abs/2508.06668)
*Jessie Galasso*

Main category: cs.AI

TL;DR: 本文探讨了形式概念分析（FCA）在知识表示和发现中的作用，尤其是如何通过其概念结构提取和分析变异性信息。


<details>
  <summary>Details</summary>
Motivation: 形式概念分析（FCA）作为一种数学框架，尽管在变异性分析方面有潜力，但其基础文献偏重数学性，这为用户理解和利用其属性带来了困难，作者试图弥合这一理解差距。

Method: 作者汇总并讨论了一些FCA框架中的核心属性，阐明了这些属性在变异性分析中的作用和解读方式。

Result: 文章系统性地展示了FCA框架中与变异性分析相关的重要属性，帮助更好地理解和利用其概念结构的信息。

Conclusion: 通过此研究，揭示了FCA的若干关键属性，这些属性能够为变异性信息提取和分析提供帮助，同时为进一步应用奠定了基础。

Abstract: Formal Concept Analysis (FCA) is a mathematical framework for knowledge
representation and discovery. It performs a hierarchical clustering over a set
of objects described by attributes, resulting in conceptual structures in which
objects are organized depending on the attributes they share. These conceptual
structures naturally highlight commonalities and variabilities among similar
objects by categorizing them into groups which are then arranged by similarity,
making it particularly appropriate for variability extraction and analysis.
Despite the potential of FCA, determining which of its properties can be
leveraged for variability-related tasks (and how) is not always
straightforward, partly due to the mathematical orientation of its foundational
literature. This paper attempts to bridge part of this gap by gathering a
selection of properties of the framework which are essential to variability
analysis, and how they can be used to interpret diverse variability information
within the resulting conceptual structures.

</details>


### [322] [Zero-Shot Cellular Trajectory Map Matching](https://arxiv.org/abs/2508.06674)
*Weijie Shi,Yue Cui,Hao Chen,Jiaming Li,Mengze Li,Jia Zhu,Jiajie Xu,Xiaofang Zhou*

Main category: cs.AI

TL;DR: 该研究主旨在针对无训练区域的蜂窝轨迹地图匹配，提出一套像素化轨迹校准方法，显著提升匹配精度。


<details>
  <summary>Details</summary>
Motivation: 当前CTMM方法主要依赖于基于ID的特征与特定区域数据，这限制了其在未探索区域的适应性。研究动机是实现无需目标区域额外训练的高精度零样本CTMM。

Method: 提出了一种结合可迁移地理空间知识的像素化轨迹校准辅助方法，并通过基于VAE的高斯混合模型进行情境自适应专家识别；设计了空间-时间感知模块以捕捉序列特征和位置不确定性；并引入约束路径寻找算法以保证道路网络拓扑有效性。

Result: 实验表明该模型在零样本CTMM中相比现有方法性能提升16.8%。

Conclusion: 该方法有效提取跨区域适应特征并缓解定位误差问题，在无目标区域训练场景中表现出更高的轨迹匹配精度。

Abstract: Cellular Trajectory Map-Matching (CTMM) aims to align cellular location
sequences to road networks, which is a necessary preprocessing in
location-based services on web platforms like Google Maps, including navigation
and route optimization. Current approaches mainly rely on ID-based features and
region-specific data to learn correlations between cell towers and roads,
limiting their adaptability to unexplored areas. To enable high-accuracy CTMM
without additional training in target regions, Zero-shot CTMM requires to
extract not only region-adaptive features, but also sequential and location
uncertainty to alleviate positioning errors in cellular data. In this paper, we
propose a pixel-based trajectory calibration assistant for zero-shot CTMM,
which takes advantage of transferable geospatial knowledge to calibrate
pixelated trajectory, and then guide the path-finding process at the road
network level. To enhance knowledge sharing across similar regions, a Gaussian
mixture model is incorporated into VAE, enabling the identification of
scenario-adaptive experts through soft clustering. To mitigate high positioning
errors, a spatial-temporal awareness module is designed to capture sequential
features and location uncertainty, thereby facilitating the inference of
approximate user positions. Finally, a constrained path-finding algorithm is
employed to reconstruct the road ID sequence, ensuring topological validity
within the road network. This process is guided by the calibrated trajectory
while optimizing for the shortest feasible path, thus minimizing unnecessary
detours. Extensive experiments demonstrate that our model outperforms existing
methods in zero-shot CTMM by 16.8\%.

</details>


### [323] [Probabilistic Circuits for Knowledge Graph Completion with Reduced Rule Sets](https://arxiv.org/abs/2508.06706)
*Jaikrishna Manojkumar Patil,Nathaniel Lee,Al Mehdi Saadat Chowdhury,YooJung Choi,Paulo Shakarian*

Main category: cs.AI

TL;DR: 该论文提出了一种方法，通过发现“规则上下文”并利用概率电路分布，可以减少知识图谱补全中规则数量，同时保持竞争性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何在知识图谱补全中减少规则数量，以提升可解释性并保持性能。

Method: 通过训练数据发现有意义的规则子集（规则上下文），并用概率电路对这些上下文进行建模以简化推理。

Result: 在减少规则数量70-96%的情况下，方法性能超过基线，且在仅用最小规则集时达到基线的31倍性能；对比全规则集，最小规则集保持了91%的性能。

Conclusion: 新方法在减少规则数量的同时保持高效性能，且具有严谨的概率逻辑语义基础，能在多数据集上实现竞争性能且扩展性强。

Abstract: Rule-based methods for knowledge graph completion provide explainable results
but often require a significantly large number of rules to achieve competitive
performance. This can hinder explainability due to overwhelmingly large rule
sets. We discover rule contexts (meaningful subsets of rules that work
together) from training data and use learned probability distribution (i.e.
probabilistic circuits) over these rule contexts to more rapidly achieve
performance of the full rule set. Our approach achieves a 70-96% reduction in
number of rules used while outperforming baseline by up to 31$\times$ when
using equivalent minimal number of rules and preserves 91% of peak baseline
performance even when comparing our minimal rule sets against baseline's full
rule sets. We show that our framework is grounded in well-known semantics of
probabilistic logic, does not require independence assumptions, and that our
tractable inference procedure provides both approximate lower bounds and exact
probability of a given query. The efficacy of our method is validated by
empirical studies on 8 standard benchmark datasets where we show competitive
performance by using only a fraction of the rules required by AnyBURL's
standard inference method, the current state-of-the-art for rule-based
knowledge graph completion. This work may have further implications for general
probabilistic reasoning over learned sets of rules.

</details>


### [324] [GLIDR: Graph-Like Inductive Logic Programming with Differentiable Reasoning](https://arxiv.org/abs/2508.06716)
*Blair Johnson,Clayton Kerce,Faramarz Fekri*

Main category: cs.AI

TL;DR: GLIDR通过引入具有更多表达能力的规则语法和参数化搜索空间，对链式规则学习方法进行扩展，用于知识图谱的链路预测和节点分类任务，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 改善现有链式规则结构假设的局限，提高在知识图谱任务中的表现和可解释性。

Method: 引入GLIDR，一种可微分的规则学习方法，扩展规则语法以支持分支和循环，通过限制规则中的自有变量数进行参数化，实现规则搜索。

Result: GLIDR在知识图谱任务中显著优于现有规则学习方法，并且能够与嵌入方法竞争；从GLIDR提取的规则保持高预测性能，具有高训练数据噪声鲁棒性。

Conclusion: GLIDR有效解决了链式规则结构的局限，可生成具有高性能的显式逻辑规则，并能与深度网络结合实现端到端优化，实现规则学习的新突破。

Abstract: Differentiable inductive logic programming (ILP) techniques have proven
effective at finding approximate rule-based solutions to link prediction and
node classification problems on knowledge graphs; however, the common
assumption of chain-like rule structure can hamper the performance and
interpretability of existing approaches. We introduce GLIDR, a differentiable
rule learning method that models the inference of logic rules with more
expressive syntax than previous methods. GLIDR uses a differentiable message
passing inference algorithm that generalizes previous chain-like rule learning
methods to allow rules with features like branches and cycles. GLIDR has a
simple and expressive rule search space which is parameterized by a limit on
the maximum number of free variables that may be included in a rule. Explicit
logic rules can be extracted from the weights of a GLIDR model for use with
symbolic solvers. We demonstrate that GLIDR can significantly outperform
existing rule learning methods on knowledge graph completion tasks and even
compete with embedding methods despite the inherent disadvantage of being a
structure-only prediction method. We show that rules extracted from GLIDR
retain significant predictive performance, and that GLIDR is highly robust to
training data noise. Finally, we demonstrate that GLIDR can be chained with
deep neural networks and optimized end-to-end for rule learning on arbitrary
data modalities.

</details>


### [325] [ParBalans: Parallel Multi-Armed Bandits-based Adaptive Large Neighborhood Search](https://arxiv.org/abs/2508.06736)
*Alican Yilmaz,Junyang Cai,Serdar Kadioglu,Bistra Dilkina*

Main category: cs.AI

TL;DR: 本文提出ParBalans方法，通过充分利用求解器和算法级别并行性，加速求解混合整数规划问题，性能与商用软件Gurobi相媲美。


<details>
  <summary>Details</summary>
Motivation: 解决混合整数规划问题过程中的计算资源消耗大，并行化是一种提升效率的关键策略，尤其可以应对大规模复杂实例，但现有工具Balans对并行化能力的探索不足。

Method: 提出扩展算法ParBalans，结合求解器和算法级别的并行化策略，提升对混合整数规划问题的求解能力。

Result: 实验结果表明，ParBalans在难优化基准测试中表现良好，与当前最优商用求解器Gurobi相比具备竞争力。

Conclusion: ParBalans通过并行策略显著提升对复杂MIP问题的求解能力，为理论研究和实际应用提供了更有效的解决方案。

Abstract: Solving Mixed-Integer Programming (MIP) problems often requires substantial
computational resources due to their combinatorial nature. Parallelization has
emerged as a critical strategy to accelerate solution times and enhance
scalability to tackle large, complex instances. This paper investigates the
parallelization capabilities of Balans, a recently proposed multi-armed
bandits-based adaptive large neighborhood search for MIPs. While Balans's
modular architecture inherently supports parallel exploration of diverse
parameter configurations, this potential has not been thoroughly examined. To
address this gap, we introduce ParBalans, an extension that leverages both
solver-level and algorithmic-level parallelism to improve performance on
challenging MIP instances. Our experimental results demonstrate that ParBalans
exhibits competitive performance compared to the state-of-the-art commercial
solver Gurobi, particularly on hard optimization benchmarks.

</details>


### [326] [Topology Generation of UAV Covert Communication Networks: A Graph Diffusion Approach with Incentive Mechanism](https://arxiv.org/abs/2508.06746)
*Xin Tang,Qian Chen,Fengshun Li,Youchun Gong,Yinqiu Liu,Wen Tian,Shaowen Qin,Xiaohuan Li*

Main category: cs.AI

TL;DR: 本研究提出结合图扩散策略优化与斯塔克尔伯格博弈的自组织无人机网络框架，解决无人机网络动态移动和通信隐蔽性问题。


<details>
  <summary>Details</summary>
Motivation: 当前无人机网络用于城市监控、紧急响应等敏感场景，对可靠连接和隐秘通信的需求日益增长，但其动态性和暴露风险带来了挑战。

Method: 通过结合图扩散策略优化（GDPO）和斯塔克尔伯格博弈（SG）的机制，实现无人机网络拓扑的动态生成与隐秘通信增强。

Result: 实验验证了所提框架在模型收敛性、拓扑生成质量以及隐秘通信性能增强方面的有效性。

Conclusion: 所提框架能够以灵活的方式适应节点分布和用户需求的变化，有效提升隐秘通信能力，为无人机网络提供更可靠的连接方式。

Abstract: With the growing demand for Uncrewed Aerial Vehicle (UAV) networks in
sensitive applications, such as urban monitoring, emergency response, and
secure sensing, ensuring reliable connectivity and covert communication has
become increasingly vital. However, dynamic mobility and exposure risks pose
significant challenges. To tackle these challenges, this paper proposes a
self-organizing UAV network framework combining Graph Diffusion-based Policy
Optimization (GDPO) with a Stackelberg Game (SG)-based incentive mechanism. The
GDPO method uses generative AI to dynamically generate sparse but
well-connected topologies, enabling flexible adaptation to changing node
distributions and Ground User (GU) demands. Meanwhile, the Stackelberg Game
(SG)-based incentive mechanism guides self-interested UAVs to choose relay
behaviors and neighbor links that support cooperation and enhance covert
communication. Extensive experiments are conducted to validate the
effectiveness of the proposed framework in terms of model convergence, topology
generation quality, and enhancement of covert communication performance.

</details>


### [327] [Pushing the Envelope of LLM Inference on AI-PC](https://arxiv.org/abs/2508.06753)
*Evangelos Georganas,Dhiraj Kalamkar,Alexander Heinecke*

Main category: cs.AI

TL;DR: 本文提出了一种适用于现代CPU的1位和2位微内核优化方法，并将其集成到PyTorch-TPP框架中，实现了在AI PC和边缘设备上以2.2倍的性能超越现有SOTA的比特网络（bitnet.cpp）的推理速度。


<details>
  <summary>Details</summary>
Motivation: 超低位（1/1.58/2位）大语言模型逐渐成熟，其在困惑度和终端任务性能上与完整精度模型相当，这为资源受限环境中的推理（如边缘设备和AI PC）带来了全新的可能性。

Method: 设计并实现了1位和2位的微内核，这些内核经过了针对现代CPU的优化，并将其集成到PyTorch-TPP框架中。

Result: 其优化后的2位模型在完成端到端的推理时，相较16位模型获得了高达7倍的速度提升，同时对比现有的SOTA推理框架（bitnet.cpp）实现了最高2.2倍的性能提升。

Conclusion: 优化后的推理框架显著提升了AI PC及边缘设备上超低位大语言模型推理的效率，为超低位模型的高效部署奠定了基础。

Abstract: The advent of ultra-low-bit LLM models (1/1.58/2-bit), which match the
perplexity and end-task performance of their full-precision counterparts using
the same model size, is ushering in a new era of LLM inference for
resource-constrained environments such as edge devices and AI PCs. While these
quantization advances promise models that are more cost-effective in terms of
latency, memory, throughput, and energy consumption, the computational
efficiency of state-of-the-art (SOTA) inference runtimes (e.g., bitnet.cpp)
used to deploy them remains underexplored. In this work, we take a bottom-up
approach: we first design and implement 1-bit and 2-bit microkernels optimized
for modern CPUs, achieving peak computational efficiency across a variety of
CPU platforms. We integrate these microkernels into a state-of-the-art LLM
inference framework, namely PyTorch-TPP, and present end-to-end inference
results with 2-bit models that outperform the current SOTA runtime bitnet.cpp
by up to 2.2x, and deliver up to 7x speedup compared to the 16-bit model
inference. Our optimized runtime advances the state of LLM inference on AI PCs
and edge devices, paving the way for efficient deployment of ultra-low-bit LLM
models.

</details>


### [328] [A Fuzzy Logic Prompting Framework for Large Language Models in Adaptive and Uncertain Tasks](https://arxiv.org/abs/2508.06754)
*Vanessa Figueiredo*

Main category: cs.AI

TL;DR: 提出了一种模块化提示框架，通过模糊支架逻辑和适应规则来增强大语言模型（LLMs）在动态用户任务中的适应性和安全性，无需微调即可实现用户状态的行为调节。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLMs在用户中心化动态任务中的安全性和适应性问题，提出了一种基于人类学习理论“最近发展区”（ZPD）的提示框架。

Method: 框架结合了自然语言边界提示与模糊支架逻辑和适应规则的控制结构，使得LLMs能根据用户状态动态调节行为，无需微调或外部编排。

Result: 在模拟智能辅导场景中，框架提升了支架质量、适应性以及教学一致性，在多种模型上均优于标准提示基线，并通过大规模的基于评分规则的LLM评估器进行验证。

Conclusion: 初步用于教育的框架在游戏等交互密集领域展现了应用潜力，其设计旨在提供一种可重用的方法来结构化解释和目标一致的LLM行为，适应不确定或不断变化的情境。

Abstract: We introduce a modular prompting framework that supports safer and more
adaptive use of large language models (LLMs) across dynamic, user-centered
tasks. Grounded in human learning theory, particularly the Zone of Proximal
Development (ZPD), our method combines a natural language boundary prompt with
a control schema encoded with fuzzy scaffolding logic and adaptation rules.
This architecture enables LLMs to modulate behavior in response to user state
without requiring fine-tuning or external orchestration. In a simulated
intelligent tutoring setting, the framework improves scaffolding quality,
adaptivity, and instructional alignment across multiple models, outperforming
standard prompting baselines. Evaluation is conducted using rubric-based LLM
graders at scale. While initially developed for education, the framework has
shown promise in other interaction-heavy domains, such as procedural content
generation for games. Designed for safe deployment, it provides a reusable
methodology for structuring interpretable, goal-aligned LLM behavior in
uncertain or evolving contexts.

</details>


### [329] [Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation](https://arxiv.org/abs/2508.06823)
*Xuan Zhao,Jun Tao*

Main category: cs.AI

TL;DR: 提出了一种结合自然语言互动与强化学习的新框架，用于改进体数据的高效导航和解释性。


<details>
  <summary>Details</summary>
Motivation: 优化体数据导航，使非专业用户更易于理解和操作。

Method: 通过编码体数据块以捕捉底层结构，结合CLIP Score提供语义信息，并利用强化学习框架指导导航和选择视角。

Result: 实现了更高效、针对用户需求的视角选择，提升了体数据的解读效率和科学现象的解释。

Conclusion: 此方法通过自动视角选择，提高了体数据导航效率和复杂科学现象的理解能力。

Abstract: Exploring volumetric data is crucial for interpreting scientific datasets.
However, selecting optimal viewpoints for effective navigation can be
challenging, particularly for users without extensive domain expertise or
familiarity with 3D navigation. In this paper, we propose a novel framework
that leverages natural language interaction to enhance volumetric data
exploration. Our approach encodes volumetric blocks to capture and
differentiate underlying structures. It further incorporates a CLIP Score
mechanism, which provides semantic information to the blocks to guide
navigation. The navigation is empowered by a reinforcement learning framework
that leverage these semantic cues to efficiently search for and identify
desired viewpoints that align with the user's intent. The selected viewpoints
are evaluated using CLIP Score to ensure that they best reflect the user
queries. By automating viewpoint selection, our method improves the efficiency
of volumetric data navigation and enhances the interpretability of complex
scientific phenomena.

</details>


### [330] [Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges](https://arxiv.org/abs/2508.06832)
*Haifeng Li,Wang Guo,Haiyang Wu,Mengwei Wu,Jipeng Zhang,Qing Zhu,Yu Liu,Xin Huang,Chao Tao*

Main category: cs.AI

TL;DR: 作者提出从以视觉为中心的遥感图像解读转向以语言为中心的范式，利用大语言模型（LLMs）作为认知中枢以实现统一的理解、推理和决策。


<details>
  <summary>Details</summary>
Motivation: 以视觉为主的传统遥感图像解读在多模态推理、语义抽象及交互式决策中存在局限性，而近年来的研究虽引入了大语言模型，但缺乏统一的理论框架关注语言的认知角色。

Method: 作者借鉴全球工作空间理论，提出以语言为中心的框架，将LLMs作为认知中枢整合感知、任务、知识与行动空间，构造基于全球工作空间驱动的解读机制，并梳理关键技术挑战及相应语言解决方案。

Result: 总结核心技术挑战并提出基于语言的解决方案，如多模态数据统一表示、知识关联及推理决策。

Conclusion: 本文建立了以认知为驱动的语言中心遥感解读框架的概念基础，并为下一代智能地理空间分析系统绘制了发展蓝图。

Abstract: The mainstream paradigm of remote sensing image interpretation has long been
dominated by vision-centered models, which rely on visual features for semantic
understanding. However, these models face inherent limitations in handling
multi-modal reasoning, semantic abstraction, and interactive decision-making.
While recent advances have introduced Large Language Models (LLMs) into remote
sensing workflows, existing studies primarily focus on downstream applications,
lacking a unified theoretical framework that explains the cognitive role of
language. This review advocates a paradigm shift from vision-centered to
language-centered remote sensing interpretation. Drawing inspiration from the
Global Workspace Theory (GWT) of human cognition, We propose a
language-centered framework for remote sensing interpretation that treats LLMs
as the cognitive central hub integrating perceptual, task, knowledge and action
spaces to enable unified understanding, reasoning, and decision-making. We
first explore the potential of LLMs as the central cognitive component in
remote sensing interpretation, and then summarize core technical challenges,
including unified multimodal representation, knowledge association, and
reasoning and decision-making. Furthermore, we construct a global
workspace-driven interpretation mechanism and review how language-centered
solutions address each challenge. Finally, we outline future research
directions from four perspectives: adaptive alignment of multimodal data, task
understanding under dynamic knowledge constraints, trustworthy reasoning, and
autonomous interaction. This work aims to provide a conceptual foundation for
the next generation of remote sensing interpretation systems and establish a
roadmap toward cognition-driven intelligent geospatial analysis.

</details>


### [331] [Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.06836)
*Xutong Zhao,Yaqi Xie*

Main category: cs.AI

TL;DR: 本文针对合作多智能体强化学习（MARL）中的信任分配问题，提出了一种新的多级优势信用分配方法（MACA），并在Starcraft任务中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有任务中，多个智能体需协同工作实现共同目标，但由于任务的多样性及奖励依赖于多种代理子集，其信任分配面临挑战，尤其涉及多个并存的分配级别。

Method: 本文提出了MACA，通过显式反事实推理在多个级别推断信任，并利用基于注意力的框架捕捉关联智能体关系，并构建多级优势函数，以指导策略学习。

Result: 在Starcraft v1&v2的复杂任务中，MACA展现了卓越的性能，证明其在复杂信任分配场景中的高效性。

Conclusion: MACA能够有效解决多智能体中多级别信任分配问题，提升了复杂任务下的整体性能。

Abstract: Cooperative multi-agent reinforcement learning (MARL) aims to coordinate
multiple agents to achieve a common goal. A key challenge in MARL is credit
assignment, which involves assessing each agent's contribution to the shared
reward. Given the diversity of tasks, agents may perform different types of
coordination, with rewards attributed to diverse and often overlapping agent
subsets. In this work, we formalize the credit assignment level as the number
of agents cooperating to obtain a reward, and address scenarios with multiple
coexisting levels. We introduce a multi-level advantage formulation that
performs explicit counterfactual reasoning to infer credits across distinct
levels. Our method, Multi-level Advantage Credit Assignment (MACA), captures
agent contributions at multiple levels by integrating advantage functions that
reason about individual, joint, and correlated actions. Utilizing an
attention-based framework, MACA identifies correlated agent relationships and
constructs multi-level advantages to guide policy learning. Comprehensive
experiments on challenging Starcraft v1\&v2 tasks demonstrate MACA's superior
performance, underscoring its efficacy in complex credit assignment scenarios.

</details>


### [332] [MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams](https://arxiv.org/abs/2508.06851)
*Pengfei Zhou,Xiaopeng Peng,Fanrui Zhang,Zhaopan Xu,Jiaxin Ai,Yansheng Qiu,Chuanhao Li,Zhen Li,Ming Li,Yukang Feng,Jianwen Sun,Haoquan Zhang,Zizhen Li,Xiaofeng Mao,Zekai Li,Wangbo Zhao,Kai Wang,Xiaojun Chang,Wenqi Shao,Yang You,Kaipeng Zhang*

Main category: cs.AI

TL;DR: 提出MDK12-Bench，一个大规模多学科基准，用于全面评估多模态大语言模型（MLLMs）的智能表现。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs评估基准规模有限、覆盖面窄且知识无结构，无法全面测量其智能水平。

Method: 通过真实K-12考试构建MDK12-Bench，包含六个学科的14.1万实例和6,225个知识点，覆盖五种问题形式，并引入动态评估框架以及知识点参考增强生成方法。

Result: 发现现有MLLMs在多个维度存在局限性，并提供提高模型鲁棒性、可解释性及教育应用的指导。

Conclusion: MDK12-Bench为评估MLLMs的能力提供了全面工具，有助于推动通用人工智能的发展。

Abstract: Multimodal large language models (MLLMs), which integrate language and visual
cues for problem-solving, are crucial for advancing artificial general
intelligence (AGI). However, current benchmarks for measuring the intelligence
of MLLMs suffer from limited scale, narrow coverage, and unstructured
knowledge, offering only static and undifferentiated evaluations. To bridge
this gap, we introduce MDK12-Bench, a large-scale multidisciplinary benchmark
built from real-world K-12 exams spanning six disciplines with 141K instances
and 6,225 knowledge points organized in a six-layer taxonomy. Covering five
question formats with difficulty and year annotations, it enables comprehensive
evaluation to capture the extent to which MLLMs perform over four dimensions:
1) difficulty levels, 2) temporal (cross-year) shifts, 3) contextual shifts,
and 4) knowledge-driven reasoning. We propose a novel dynamic evaluation
framework that introduces unfamiliar visual, textual, and question form shifts
to challenge model generalization while improving benchmark objectivity and
longevity by mitigating data contamination. We further evaluate knowledge-point
reference-augmented generation (KP-RAG) to examine the role of knowledge in
problem-solving. Key findings reveal limitations in current MLLMs in multiple
aspects and provide guidance for enhancing model robustness, interpretability,
and AI-assisted education.

</details>


### [333] [MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction](https://arxiv.org/abs/2508.06859)
*Shuo Tang,Jian Xu,Jiadong Zhang,Yi Chen,Qizhao Jin,Lingdong Shen,Chenglin Liu,Shiming Xiang*

Main category: cs.AI

TL;DR: 本文提出了MP-Bench，一个用于严重天气事件预测的大规模时序多模态数据集，并且开发了一种气象多模态大模型（MMLM）来处理4D气象输入，显著提升了天气预测的效果。


<details>
  <summary>Details</summary>
Motivation: 当前天气预测系统过于依赖人工专家解释，存在主观性和操作负担问题，同时现有多模态语言模型难以处理高维气象数据及其复杂依赖关系，亟需引入自动化、AI驱动的解决方案。

Method: 引入MP-Bench数据集，包含多个年份的多模态气象数据和对应文本描述，同时开发MMLM模型，采用自适应融合模块以动态提取和整合时序、空间和垂直压力层特征。

Result: 实验表明，MMLM在多个任务上表现优异，有效提升了严重天气事件的理解和预测能力。

Conclusion: MP-Bench数据集和MMLM模型为AI驱动的自动化天气预警系统发展奠定了重要基础，推动了气象数据处理和分析的技术突破。

Abstract: Timely and accurate severe weather warnings are critical for disaster
mitigation. However, current forecasting systems remain heavily reliant on
manual expert interpretation, introducing subjectivity and significant
operational burdens. With the rapid development of AI technologies, the
end-to-end "AI weather station" is gradually emerging as a new trend in
predicting severe weather events. Three core challenges impede the development
of end-to-end AI severe weather system: (1) scarcity of severe weather event
samples; (2) imperfect alignment between high-dimensional meteorological data
and textual warnings; (3) existing multimodal language models are unable to
handle high-dimensional meteorological data and struggle to fully capture the
complex dependencies across temporal sequences, vertical pressure levels, and
spatial dimensions. To address these challenges, we introduce MP-Bench, the
first large-scale temporal multimodal dataset for severe weather events
prediction, comprising 421,363 pairs of raw multi-year meteorological data and
corresponding text caption, covering a wide range of severe weather scenarios
across China. On top of this dataset, we develop a meteorology multimodal large
model (MMLM) that directly ingests 4D meteorological inputs. In addition, it is
designed to accommodate the unique characteristics of 4D meteorological data
flow, incorporating three plug-and-play adaptive fusion modules that enable
dynamic feature extraction and integration across temporal sequences, vertical
pressure layers, and spatial dimensions. Extensive experiments on MP-Bench
demonstrate that MMLM performs exceptionally well across multiple tasks,
highlighting its effectiveness in severe weather understanding and marking a
key step toward realizing automated, AI-driven weather forecasting systems. Our
source code and dataset will be made publicly available.

</details>


### [334] [Pushdown Reward Machines for Reinforcement Learning](https://arxiv.org/abs/2508.06894)
*Giovanni Varricchione,Toryn Q. Klassen,Natasha Alechina,Mehdi Dastani,Brian Logan,Sheila A. McIlraith*

Main category: cs.AI

TL;DR: 推导奖励机器（pdRMs）是奖励机器（RMs）的扩展，基于确定性下推自动机，能够奖励满足确定性上下文无关语言行为的任务。


<details>
  <summary>Details</summary>
Motivation: 传统奖励机器的表达能力有限，无法处理基于确定性上下文无关语言的复杂行为表达，因此需要一种更强大的模型。

Method: 提出了基于确定性下推自动机的推导奖励机器（pdRMs），并两种策略：一种访问整个堆栈，一种仅访问堆栈顶部k个符号。设计了验证两种策略收益等效的方法，分析了其表达能力及空间复杂性，并进行了实验验证。

Result: 理论分析表明pdRMs比传统奖励机器更具表达能力，且通过实验验证了pdRMs在处理复杂任务中的有效性。

Conclusion: pdRMs提升了奖励机器的表达能力，为基于上下文无关语言的任务学习提供了更加有力的工具。

Abstract: Reward machines (RMs) are automata structures that encode (non-Markovian)
reward functions for reinforcement learning (RL). RMs can reward any behaviour
representable in regular languages and, when paired with RL algorithms that
exploit RM structure, have been shown to significantly improve sample
efficiency in many domains. In this work, we present pushdown reward machines
(pdRMs), an extension of reward machines based on deterministic pushdown
automata. pdRMs can recognize and reward temporally extended behaviours
representable in deterministic context-free languages, making them more
expressive than reward machines. We introduce two variants of pdRM-based
policies, one which has access to the entire stack of the pdRM, and one which
can only access the top $k$ symbols (for a given constant $k$) of the stack. We
propose a procedure to check when the two kinds of policies (for a given
environment, pdRM, and constant $k$) achieve the same optimal expected reward.
We then provide theoretical results establishing the expressive power of pdRMs,
and space complexity results about the proposed learning problems. Finally, we
provide experimental results showing how agents can be trained to perform tasks
representable in deterministic context-free languages using pdRMs.

</details>


### [335] [GDBA Revisited: Unleashing the Power of Guided Local Search for Distributed Constraint Optimization](https://arxiv.org/abs/2508.06899)
*Yanchen Deng,Xinrun Wang,Bo An*

Main category: cs.AI

TL;DR: 提出了一种针对DCOP问题的改进分布式局部搜索算法（DGLS）。


<details>
  <summary>Details</summary>
Motivation: 现有的局部搜索算法易陷入低质量局部最优，现有方法如GDBA效果不佳，需要改进以更优解决DCOP问题。

Method: 通过设计自适应约束条件、惩罚蒸发机制及同步更新策略，提出改进的分布式引导局部搜索（DGLS）。

Result: 在理论和实验基准测试中，DGLS在通用和结构化问题上均优于现有方法，特别是在结构化问题上提升显著。

Conclusion: DGLS方法具有显著优势，为解决DCOP优化问题提供了更有效的解决方案。

Abstract: Local search is an important class of incomplete algorithms for solving
Distributed Constraint Optimization Problems (DCOPs) but it often converges to
poor local optima. While GDBA provides a comprehensive rule set to escape
premature convergence, its empirical benefits remain marginal on general-valued
problems. In this work, we systematically examine GDBA and identify three
factors that potentially lead to its inferior performance, i.e.,
over-aggressive constraint violation conditions, unbounded penalty
accumulation, and uncoordinated penalty updates. To address these issues, we
propose Distributed Guided Local Search (DGLS), a novel GLS framework for DCOPs
that incorporates an adaptive violation condition to selectively penalize
constraints with high cost, a penalty evaporation mechanism to control the
magnitude of penalization, and a synchronization scheme for coordinated penalty
updates. We theoretically show that the penalty values are bounded, and agents
play a potential game in our DGLS. Our extensive empirical results on various
standard benchmarks demonstrate the great superiority of DGLS over
state-of-the-art baselines. Particularly, compared to Damped Max-sum with high
damping factors (e.g., 0.7 or 0.9), our DGLS achieves competitive performance
on general-valued problems, and outperforms it by significant margins
(\textbf{3.77\%--66.3\%}) on structured problems in terms of anytime results.

</details>


### [336] [Automated Formalization via Conceptual Retrieval-Augmented LLMs](https://arxiv.org/abs/2508.06931)
*Wangyue Lu,Lun Du,Sirui Li,Ke Weng,Haozhe Sun,Hengyu Liu,Minghe Yu,Tiancheng Zhang,Ge Yu*

Main category: cs.AI

TL;DR: 该论文提出CRAMF框架，通过检索数学定义及改进代码生成，为提升交互定理证明中的自动化形式化提供了解决方案，在多个基准数据集上显著提升了翻译准确性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决交互定理证明中手动形式化耗时且需要专业知识的问题，以及现有自动化形式化因模型幻觉和语义差距导致的挑战。

Method: 提出概念驱动的检索增强数学形式化框架CRAMF，通过从Mathlib4构建概念定义知识库，设计上下文查询增强及双通道混合检索策略，提升LLM生成代码的上下文准确性。

Result: 在miniF2F、ProofNet和新提出的AdvancedMath基准上测试，CRAMF实现了翻译准确性显著提高，相对提升幅度最高达到62.1%，平均为29.9%。

Conclusion: CRAMF可无缝集成到基于LLM的自动形式化工具中，改进了数学定理的自动形式化翻译精度，为解决模型幻觉与语义差距问题提供了可靠方案。

Abstract: Interactive theorem provers (ITPs) require manual formalization, which is
labor-intensive and demands expert knowledge. While automated formalization
offers a potential solution, it faces two major challenges: model hallucination
(e.g., undefined predicates, symbol misuse, and version incompatibility) and
the semantic gap caused by ambiguous or missing premises in natural language
descriptions. To address these issues, we propose CRAMF, a Concept-driven
Retrieval-Augmented Mathematical Formalization framework. CRAMF enhances
LLM-based autoformalization by retrieving formal definitions of core
mathematical concepts, providing contextual grounding during code generation.
However, applying retrieval-augmented generation (RAG) in this setting is
non-trivial due to the lack of structured knowledge bases, the polymorphic
nature of mathematical concepts, and the high precision required in formal
retrieval. We introduce a framework for automatically constructing a
concept-definition knowledge base from Mathlib4, the standard mathematical
library for the Lean 4 theorem prover, indexing over 26,000 formal definitions
and 1,000+ core mathematical concepts. To address conceptual polymorphism, we
propose contextual query augmentation with domain- and application-level
signals. In addition, we design a dual-channel hybrid retrieval strategy with
reranking to ensure accurate and relevant definition retrieval. Experiments on
miniF2F, ProofNet, and our newly proposed AdvancedMath benchmark show that
CRAMF can be seamlessly integrated into LLM-based autoformalizers, yielding
consistent improvements in translation accuracy, achieving up to 62.1% and an
average of 29.9% relative improvement.

</details>


### [337] [Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction](https://arxiv.org/abs/2508.06939)
*Hiba Najjar,Deepak Pathak,Marlon Nuske,Andreas Dengel*

Main category: cs.AI

TL;DR: 本文探索基于Transformer模型的解释能力，对多模态学习网络进行分析，专注于农作物产量预测问题。


<details>
  <summary>Details</summary>
Motivation: 旨在提高多模态学习的可解释性，尤其是在农作物产量预测中，整合多维数据模态（如卫星影像、天气数据等）。

Method: 利用自注意力机制提出两种方法：Attention Rollout (AR)和Generic Attention (GA)，与Shapley-based方法（SVS）相比；同时提出加权模态激活(WMA)方法评估模态重要性。

Result: Transformer模型在子田块以及田块层面的表现优于其他网络架构（R2分数分别高出0.10和0.04）；AR提供更鲁棒的时间维度解释，其定性和定量评价均优于GA和SVS；模态贡献度分析展现了不同评估方法下的模式差异。

Conclusion: Transformer拥有强大的处理多模态数据的能力，并具备更高的预测性能和解释力，通过合理设计能够为农业数据分析提供更优秀的工具。

Abstract: Multimodal learning enables various machine learning tasks to benefit from
diverse data sources, effectively mimicking the interplay of different factors
in real-world applications, particularly in agriculture. While the
heterogeneous nature of involved data modalities may necessitate the design of
complex architectures, the model interpretability is often overlooked. In this
study, we leverage the intrinsic explainability of Transformer-based models to
explain multimodal learning networks, focusing on the task of crop yield
prediction at the subfield level. The large datasets used cover various crops,
regions, and years, and include four different input modalities: multispectral
satellite and weather time series, terrain elevation maps and soil properties.
Based on the self-attention mechanism, we estimate feature attributions using
two methods, namely the Attention Rollout (AR) and Generic Attention (GA), and
evaluate their performance against Shapley-based model-agnostic estimations,
Shapley Value Sampling (SVS). Additionally, we propose the Weighted Modality
Activation (WMA) method to assess modality attributions and compare it with SVS
attributions. Our findings indicate that Transformer-based models outperform
other architectures, specifically convolutional and recurrent networks,
achieving R2 scores that are higher by 0.10 and 0.04 at the subfield and field
levels, respectively. AR is shown to provide more robust and reliable temporal
attributions, as confirmed through qualitative and quantitative evaluation,
compared to GA and SVS values. Information about crop phenology stages was
leveraged to interpret the explanation results in the light of established
agronomic knowledge. Furthermore, modality attributions revealed varying
patterns across the two methods compared.[...]

</details>


### [338] [Large Language Models Do Not Simulate Human Psychology](https://arxiv.org/abs/2508.06950)
*Sarah Schröder,Thekla Morgenroth,Ulrike Kuhl,Valerie Vaquet,Benjamin Paaßen*

Main category: cs.AI

TL;DR: 本文批评了使用大型语言模型（LLMs）模拟人类心理的想法，提供了理论和实证性的证据表明LLMs在心理研究中并不可靠。


<details>
  <summary>Details</summary>
Motivation: 研究表明LLMs或许可以取代人类参与心理学研究，但作者对此表示质疑。

Method: 从理论上反驳LLMs模拟人类心理的假设，并通过实验展示微小措辞改动对LLMs与人类反应差异的重大影响。

Result: 实验显示，即使是专门针对心理学研究微调过的模型，LLMs在任务中的反应与人类存在显著差异，不同LLMs对新任务的反应也存在差异，说明其缺乏稳定性。

Conclusion: LLMs无法真实模拟人类心理，应被视为有用但不可靠的工具，心理学研究应用中需与人类反应验证。

Abstract: Large Language Models (LLMs),such as ChatGPT, are increasingly used in
research, ranging from simple writing assistance to complex data annotation
tasks. Recently, some research has suggested that LLMs may even be able to
simulate human psychology and can, hence, replace human participants in
psychological studies. We caution against this approach. We provide conceptual
arguments against the hypothesis that LLMs simulate human psychology. We then
present empiric evidence illustrating our arguments by demonstrating that
slight changes to wording that correspond to large changes in meaning lead to
notable discrepancies between LLMs' and human responses, even for the recent
CENTAUR model that was specifically fine-tuned on psychological responses.
Additionally, different LLMs show very different responses to novel items,
further illustrating their lack of reliability. We conclude that LLMs do not
simulate human psychology and recommend that psychological researchers should
treat LLMs as useful but fundamentally unreliable tools that need to be
validated against human responses for every new application.

</details>


### [339] [DatasetResearch: Benchmarking Agent Systems for Demand-Driven Dataset Discovery](https://arxiv.org/abs/2508.06960)
*Keyu Li,Mohan Jiang,Dayuan Fu,Yunze Wu,Xiangkun Hu,Dequan Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: 随着大语言模型的发展，数据的可用性成为限制AI发展的主要瓶颈。本文提出DatasetResearch基准，评估AI在发现和整合数据集方面的能力，并揭示当前性能与完美数据集发现之间的显著差距。


<details>
  <summary>Details</summary>
Motivation: 目前的AI发展面临数据可用性问题，如何使AI代理能够实现真正的按需数据发现，是一个亟需探索的关键问题。

Method: 构建DatasetResearch基准，包含208个真实世界的需求任务，涵盖知识密集型和推理密集型任务，并建立三维评估框架对AI代理发现和综合数据集能力进行系统评估。

Result: 高级深度研究系统在DatasetResearch-pro子集上的得分仅为22%，暴露了现有性能与理想状态之间的显著差距，并发现搜索代理和综合代理在特定任务中的表现各有优劣，但都在非典型“角落案例”中表现较差。

Conclusion: 本文建立了数据集发现代理的首个严格基准，为下一代自我改进的AI系统提供了基础，并公开提供相关资源。

Abstract: The rapid advancement of large language models has fundamentally shifted the
bottleneck in AI development from computational power to data availability-with
countless valuable datasets remaining hidden across specialized repositories,
research appendices, and domain platforms. As reasoning capabilities and deep
research methodologies continue to evolve, a critical question emerges: can AI
agents transcend conventional search to systematically discover any dataset
that meets specific user requirements, enabling truly autonomous demand-driven
data curation? We introduce DatasetResearch, the first comprehensive benchmark
evaluating AI agents' ability to discover and synthesize datasets from 208
real-world demands across knowledge-intensive and reasoning-intensive tasks.
Our tri-dimensional evaluation framework reveals a stark reality: even advanced
deep research systems achieve only 22% score on our challenging
DatasetResearch-pro subset, exposing the vast gap between current capabilities
and perfect dataset discovery. Our analysis uncovers a fundamental
dichotomy-search agents excel at knowledge tasks through retrieval breadth,
while synthesis agents dominate reasoning challenges via structured
generation-yet both catastrophically fail on "corner cases" outside existing
distributions. These findings establish the first rigorous baseline for dataset
discovery agents and illuminate the path toward AI systems capable of finding
any dataset in the digital universe. Our benchmark and comprehensive analysis
provide the foundation for the next generation of self-improving AI systems and
are publicly available at https://github.com/GAIR-NLP/DatasetResearch.

</details>


### [340] [MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair](https://arxiv.org/abs/2508.06963)
*Changqing Li,Tianlin Li,Xiaohan Zhang,Aishan Liu,Li Pan*

Main category: cs.AI

TL;DR: 本文提出了一种名为MASteer的新框架，用于通过表示工程实现对大型语言模型信任性的轻量化与高效修复，同时保持模型通用能力。


<details>
  <summary>Details</summary>
Motivation: 由于现有大型语言模型（LLMs）在信任性上存在持续性和动态性问题，急需开发灵活、高效的自动化修复方法，以便配合多种应用场景的部署。

Method: 提出MASteer框架，该框架通过表示工程进行信任性修复，包含AutoTester用来生成高质量引导样本，以及AutoRepairer以自适应生成和选择推理过程中的引导向量。

Result: MASteer显著优于基准方法，在信任性任务中模型性能得到提升，分别在LLaMA-3.1-8B-Chat上提高15.36%，在Qwen-3-8B-Chat上提高4.21%。

Conclusion: MASteer框架在信任性修复中显示了强大的鲁棒性和推广性，并且作为一种轻量化无训练的替代方法具有很高的实用价值。

Abstract: Large Language Models (LLMs) face persistent and evolving trustworthiness
issues, motivating developers to seek automated and flexible repair methods
that enable convenient deployment across diverse scenarios. Existing repair
methods like supervised fine-tuning (SFT) and reinforcement learning with human
feedback (RLHF) are costly and slow, while prompt engineering lacks robustness
and scalability. Representation engineering, which steers model behavior by
injecting targeted concept vectors during inference, offers a lightweight,
training-free alternative. However, current approaches depend on manually
crafted samples and fixed steering strategies, limiting automation and
adaptability. To overcome these challenges, we propose MASteer, the first
end-to-end framework for trustworthiness repair in LLMs based on representation
engineering. MASteer integrates two core components: AutoTester, a multi-agent
system that generates diverse, high-quality steer samples tailored to developer
needs; and AutoRepairer, which constructs adaptive steering strategies with
anchor vectors for automated, context-aware strategy selection during
inference. Experiments on standard and customized trustworthiness tasks show
MASteer consistently outperforms baselines, improving metrics by 15.36% on
LLaMA-3.1-8B-Chat and 4.21% on Qwen-3-8B-Chat, while maintaining general model
capabilities. MASteer demonstrates strong robustness, generalization, and
practical value for scalable, efficient trustworthiness repair.

</details>


### [341] [DSperse: A Framework for Targeted Verification in Zero-Knowledge Machine Learning](https://arxiv.org/abs/2508.06972)
*Dan Ivanov,Tristan Freiberg,Haruna Isah*

Main category: cs.AI

TL;DR: DSperse是一种模块化框架，用于分布式机器学习推理，并在特定子计算中提供加密验证。


<details>
  <summary>Details</summary>
Motivation: 为了解决全模型电路化带来的高成本和僵化问题，提出了一种通过选择性子计算验证实现零知识证明的框架。

Method: 提出DSperse框架，允许通过有选择地验证模型的特定“切片”来实现分布式零知识证明，并评估了其在不同证明系统下的表现。

Result: 报告了DSperse在内存使用、运行时间及电路行为等方面的实验结果，验证了其在灵活证明边界调整中的有效性。

Conclusion: DSperse提供了一种可扩展和有针对性的验证策略，能够适应不同的部署需求，通过选择性验证实现更低的信任成本。

Abstract: DSperse is a modular framework for distributed machine learning inference
with strategic cryptographic verification. Operating within the emerging
paradigm of distributed zero-knowledge machine learning, DSperse avoids the
high cost and rigidity of full-model circuitization by enabling targeted
verification of strategically chosen subcomputations. These verifiable
segments, or "slices", may cover part or all of the inference pipeline, with
global consistency enforced through audit, replication, or economic incentives.
This architecture supports a pragmatic form of trust minimization, localizing
zero-knowledge proofs to the components where they provide the greatest value.
We evaluate DSperse using multiple proving systems and report empirical results
on memory usage, runtime, and circuit behavior under sliced and unsliced
configurations. By allowing proof boundaries to align flexibly with the model's
logical structure, DSperse supports scalable, targeted verification strategies
suited to diverse deployment needs.

</details>


### [342] [Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model](https://arxiv.org/abs/2508.06980)
*Aswin Paul,Moein Khajehnejad,Forough Habibollahi,Brett J. Kagan,Adeel Razi*

Main category: cs.AI

TL;DR: 本文提出一种基于主动推理理论的框架，用于模拟自主体在模拟游戏环境中的决策过程，并通过实验验证其学习能力与预测性规划在智能决策中的作用。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的快速发展，理解自主体目的性行为的基础对开发安全高效的系统至关重要，尤其是探索具有解释性和生物学合理性的模型。

Method: 作者提出一个基于主动推理的框架，利用经过实验验证的生成模型对自主体的决策过程进行模拟，并在模拟环境中进行实验与分析。

Result: 研究表明，模拟体能够进行学习，并揭示了记忆基础的学习和预测性规划在智能决策中的重要作用。

Conclusion: 该研究通过提供一种生物学基础和可扩展的方法，为解释性人工智能领域的发展作出了贡献，对理解自主体的目的性行为具有重要意义。

Abstract: With recent and rapid advancements in artificial intelligence (AI),
understanding the foundation of purposeful behaviour in autonomous agents is
crucial for developing safe and efficient systems. While artificial neural
networks have dominated the path to AI, recent studies are exploring the
potential of biologically based systems, such as networks of living biological
neuronal networks. Along with promises of high power and data efficiency, these
systems may also inform more explainable and biologically plausible models. In
this work, we propose a framework rooted in active inference, a general theory
of behaviour, to model decision-making in embodied agents. Using
experiment-informed generative models, we simulate decision-making processes in
a simulated game-play environment, mirroring experimental setups that use
biological neurons. Our results demonstrate learning in these agents, providing
insights into the role of memory-based learning and predictive planning in
intelligent decision-making. This work contributes to the growing field of
explainable AI by offering a biologically grounded and scalable approach to
understanding purposeful behaviour in agents.

</details>


### [343] [Efficient and Reliable Hitting-Set Computations for the Implicit Hitting Set Approach](https://arxiv.org/abs/2508.07015)
*Hannes Ihalainen,Dieter Vandesande,André Schidler,Jeremias Berg,Bart Bogaerts,Matti Järvisalo*

Main category: cs.AI

TL;DR: 论文提出在隐式击中集优化中采用伪布尔推理与随机局部搜索作为新算法技术，并评估其在伪布尔优化中的性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过替代算法提高隐式击中集优化的效率与可靠性，同时解决数值稳定性问题。

Method: 结合伪布尔推理和随机局部搜索用于击中集优化，分析其有效性及获取正确性证明的能力。

Result: 虽然商用整数规划求解器仍然是最有效的方法，但伪布尔推理提供了更高的数值稳定性和正确性证明的能力，并展现了竞争性的性能。

Conclusion: 伪布尔推理不仅可以在效率与正确性间取得平衡，还能够应用于多种隐式击中集实现中，提供正确性的证书。

Abstract: The implicit hitting set (IHS) approach offers a general framework for
solving computationally hard combinatorial optimization problems declaratively.
IHS iterates between a decision oracle used for extracting sources of
inconsistency and an optimizer for computing so-called hitting sets (HSs) over
the accumulated sources of inconsistency. While the decision oracle is
language-specific, the optimizers is usually instantiated through integer
programming.
  We explore alternative algorithmic techniques for hitting set optimization
based on different ways of employing pseudo-Boolean (PB) reasoning as well as
stochastic local search. We extensively evaluate the practical feasibility of
the alternatives in particular in the context of pseudo-Boolean (0-1 IP)
optimization as one of the most recent instantiations of IHS. Highlighting a
trade-off between efficiency and reliability, while a commercial IP solver
turns out to remain the most effective way to instantiate HS computations, it
can cause correctness issues due to numerical instability; in fact, we show
that exact HS computations instantiated via PB reasoning can be made
competitive with a numerically exact IP solver. Furthermore, the use of PB
reasoning as a basis for HS computations allows for obtaining certificates for
the correctness of IHS computations, generally applicable to any IHS
instantiation in which reasoning in the declarative language at hand can be
captured in the PB-based proof format we employ.

</details>


### [344] [MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA](https://arxiv.org/abs/2508.07022)
*Shengtao Wen,Haodong Chen,Yadong Wang,Zhongying Pan,Xiang Chen,Yu Tian,Bo Qian,Dong Liang,Sheng-Jun Huang*

Main category: cs.AI

TL;DR: 本论文提出了一种新的基准MultiMedEdit，用于评价临床多模态任务中的知识编辑能力，揭示了现有技术在泛化和复杂推理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有知识编辑技术在多模态医疗场景中难以适应的缺陷，设计了全新的评估框架。医疗环境需要将知识更新与视觉推理相结合，以支持安全且可解释的决策。

Method: 提出了MultiMedEdit基准，涵盖理解和推理任务，定义了三维度评价指标（可靠性、普适性和局限性），并支持跨模型方法比较，同时开展了单次编辑和长期编辑的实验分析。

Result: 研究表明，现有方法在复杂的临床场景中难以实现好的泛化和长尾推理性能，效率分析揭示了不同知识编辑范式在编辑延迟和内存占用上的权衡。

Conclusion: MultiMedEdit暴露了当前知识编辑方法的不足，为发展更具临床适应性的知识编辑技术提供了基础。

Abstract: Knowledge editing (KE) provides a scalable approach for updating factual
knowledge in large language models without full retraining. While previous
studies have demonstrated effectiveness in general domains and medical QA
tasks, little attention has been paid to KE in multimodal medical scenarios.
Unlike text-only settings, medical KE demands integrating updated knowledge
with visual reasoning to support safe and interpretable clinical decisions. To
address this gap, we propose MultiMedEdit, the first benchmark tailored to
evaluating KE in clinical multimodal tasks. Our framework spans both
understanding and reasoning task types, defines a three-dimensional metric
suite (reliability, generality, and locality), and supports cross-paradigm
comparisons across general and domain-specific models. We conduct extensive
experiments under single-editing and lifelong-editing settings. Results suggest
that current methods struggle with generalization and long-tail reasoning,
particularly in complex clinical workflows. We further present an efficiency
analysis (e.g., edit latency, memory footprint), revealing practical trade-offs
in real-world deployment across KE paradigms. Overall, MultiMedEdit not only
reveals the limitations of current approaches but also provides a solid
foundation for developing clinically robust knowledge editing techniques in the
future.

</details>


### [345] [K-Dense Analyst: Towards Fully Automated Scientific Analysis](https://arxiv.org/abs/2508.07043)
*Orion Li,Vinayak Agarwal,Summer Zhou,Ashwin Gopinath,Timothy Kassis*

Main category: cs.AI

TL;DR: 本文介绍了一种名为K-Dense Analyst的多代理系统，用于在生物信息学分析中实现自主性，比现有最强语言模型GPT-5精确率提高6.3个百分点，并显著超越其基础模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决现代生物信息学分析中高复杂性导致的数据生成与科学洞察之间的关键缺口。

Method: 通过K-Dense平台中的K-Dense Analyst，采用双循环架构和专用代理分解复杂任务，结合计划和经过验证的执行，实现自主生物信息学分析。

Result: K-Dense Analyst在开放式生物分析基准BixBench上取得29.2%的准确率，优于GPT-5的22.9%，显著超越其底层模型性能。

Conclusion: 提出的基于多代理的系统实现了超越单纯增强语言模型的新能力，为自主科学推理和生命科学领域的快速发现奠定了基础。

Abstract: The complexity of modern bioinformatics analysis has created a critical gap
between data generation and developing scientific insights. While large
language models (LLMs) have shown promise in scientific reasoning, they remain
fundamentally limited when dealing with real-world analytical workflows that
demand iterative computation, tool integration and rigorous validation. We
introduce K-Dense Analyst, a hierarchical multi-agent system that achieves
autonomous bioinformatics analysis through a dual-loop architecture. K-Dense
Analyst, part of the broader K-Dense platform, couples planning with validated
execution using specialized agents to decompose complex objectives into
executable, verifiable tasks within secure computational environments. On
BixBench, a comprehensive benchmark for open-ended biological analysis, K-Dense
Analyst achieves 29.2% accuracy, surpassing the best-performing language model
(GPT-5) by 6.3 percentage points, representing nearly 27% improvement over what
is widely considered the most powerful LLM available. Remarkably, K-Dense
Analyst achieves this performance using Gemini 2.5 Pro, which attains only
18.3% accuracy when used directly, demonstrating that our architectural
innovations unlock capabilities far beyond the underlying model's baseline
performance. Our insights demonstrate that autonomous scientific reasoning
requires more than enhanced language models, it demands purpose-built systems
that can bridge the gap between high-level scientific objectives and low-level
computational execution. These results represent a significant advance toward
fully autonomous computational biologists capable of accelerating discovery
across the life sciences.

</details>


### [346] [Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach](https://arxiv.org/abs/2508.07063)
*Naseem Machlovi,Maryam Saleki,Innocent Ababio,Ruhul Amin*

Main category: cs.AI

TL;DR: 论文讨论了当前大语言模型（LLMs）在复杂任务中的表现及其在道德推理和内容审核中的局限性，并提出了一种新的实验框架及优化模型来改善此类问题。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统越来越融入日常生活，安全可靠的内容审查需求迫切。尽管LLMs展现出强大能力，但在道德推理、隐性仇恨检测和偏见识别方面仍存在局限，且容易强化训练数据中的社会偏见。

Method: 研究开发了一个基于SOTA模型的实验框架，创建了涵盖49种类别的统一数据集，用以评估人类情感、冒犯行为及偏见文本。此外，还提出了SafePhi模型，该模型基于Phi-4通过QLoRA微调，适应多样化的伦理情境。

Result: SafePhi模型在宏观F1评分上达到0.89，优于OpenAI Moderator（0.77）和Llama Guard（0.74），展现了显著的性能提升。

Conclusion: 研究指出当前LLM在部分领域的内容审查仍存不足，需要引入更多异质且具代表性的数据，同时结合人类审核以增强模型的稳健性与可解释性。

Abstract: As AI systems become more integrated into daily life, the need for safer and
more reliable moderation has never been greater. Large Language Models (LLMs)
have demonstrated remarkable capabilities, surpassing earlier models in
complexity and performance. Their evaluation across diverse tasks has
consistently showcased their potential, enabling the development of adaptive
and personalized agents. However, despite these advancements, LLMs remain prone
to errors, particularly in areas requiring nuanced moral reasoning. They
struggle with detecting implicit hate, offensive language, and gender biases
due to the subjective and context-dependent nature of these issues. Moreover,
their reliance on training data can inadvertently reinforce societal biases,
leading to inconsistencies and ethical concerns in their outputs. To explore
the limitations of LLMs in this role, we developed an experimental framework
based on state-of-the-art (SOTA) models to assess human emotions and offensive
behaviors. The framework introduces a unified benchmark dataset encompassing 49
distinct categories spanning the wide spectrum of human emotions, offensive and
hateful text, and gender and racial biases. Furthermore, we introduced SafePhi,
a QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts and
outperforming benchmark moderators by achieving a Macro F1 score of 0.89, where
OpenAI Moderator and Llama Guard score 0.77 and 0.74, respectively. This
research also highlights the critical domains where LLM moderators consistently
underperformed, pressing the need to incorporate more heterogeneous and
representative data with human-in-the-loop, for better model robustness and
explainability.

</details>


### [347] [Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention](https://arxiv.org/abs/2508.07107)
*Timothy Oluwapelumi Adeyemi,Nadiah Fahad AlOtaibi*

Main category: cs.AI

TL;DR: 提出了一种闭环反馈决策支持系统，通过持续模型优化，提高学生学业表现预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有教育中的机器学习模型无法动态适应新数据，尤其在干预措施后的数据无法及时融入。

Method: 设计了基于LightGBM的回归器并加入增量训练机制，通过集成SHAP和Flask，实现模型的可解释性和实时交互。

Result: 重训练后模型RMSE降低了10.7%，尤其对干预学生的预测得分提升明显。

Conclusion: 此闭环系统将静态预测器转变为自我改进系统，为教育分析提供以人为中心的响应式AI框架，可集成于LMS等机构管理体系。

Abstract: Accurate prediction of student performance is essential for timely academic
intervention. However, most machine learning models in education are static and
cannot adapt when new data, such as post-intervention outcomes, become
available. To address this limitation, we propose a Feedback-Driven Decision
Support System (DSS) with a closed-loop architecture that enables continuous
model refinement. The system integrates a LightGBM-based regressor with
incremental retraining, allowing educators to input updated student results,
which automatically trigger model updates. This adaptive mechanism improves
prediction accuracy by learning from real-world academic progress. The platform
features a Flask-based web interface for real-time interaction and incorporates
SHAP for explainability, ensuring transparency. Experimental results show a
10.7\% reduction in RMSE after retraining, with consistent upward adjustments
in predicted scores for intervened students. By transforming static predictors
into self-improving systems, our approach advances educational analytics toward
human-centered, data-driven, and responsive AI. The framework is designed for
integration into LMS and institutional dashboards.

</details>


### [348] [Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables](https://arxiv.org/abs/2508.07186)
*Amit Dhanda*

Main category: cs.AI

TL;DR: 提出一种利用大型语言模型(LLM)-驱动的代理进行跨维度企业数据摘要的新框架。


<details>
  <summary>Details</summary>
Motivation: 传统的表格到文本模型在分层结构推理和上下文感知方面能力不足，难以满足商业报告任务的需求。

Method: 通过一个多代理流水线对多维数据进行提取、分析和总结，包括切片、差异检测、上下文构建和基于LLM的生成。

Result: 提出的框架在信实性（达到83%）、显著变化的覆盖率和决策关键洞察的相关性评分（4.4/5）方面优于传统方法。

Conclusion: 该框架特别适用于复杂场景的总结，如价格变动带来的收入增加等，这些是现有方法难以有效处理的。

Abstract: We propose a novel framework for summarizing structured enterprise data
across multiple dimensions using large language model (LLM)-based agents.
Traditional table-to-text models often lack the capacity to reason across
hierarchical structures and context-aware deltas, which are essential in
business reporting tasks. Our method introduces a multi-agent pipeline that
extracts, analyzes, and summarizes multi-dimensional data using agents for
slicing, variance detection, context construction, and LLM-based generation.
Our results show that the proposed framework outperforms traditional
approaches, achieving 83\% faithfulness to underlying data, superior coverage
of significant changes, and high relevance scores (4.4/5) for decision-critical
insights. The improvements are especially pronounced in categories involving
subtle trade-offs, such as increased revenue due to price changes amid
declining unit volumes, which competing methods either overlook or address with
limited specificity. We evaluate the framework on Kaggle datasets and
demonstrate significant improvements in faithfulness, relevance, and insight
quality over baseline table summarization approaches.

</details>


### [349] [EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning](https://arxiv.org/abs/2508.07292)
*Yi Tang,Kaini Wang,Yang Chen,Guangquan Zhou*

Main category: cs.AI

TL;DR: EndoAgent 是首款内窥镜视觉到决策的 AI 系统，整合了迭代推理与自适应工具选择与协作，解决了现有 AI 系统在多任务和复杂临床工作流中的缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有基于大规模预训练的 AI 方法在内窥镜诊断任务中缺乏任务统一协调，难以处理复杂临床工作流中的多步骤过程。

Method: 开发了 EndoAgent，一个基于双内存设计的系统，通过短期动作跟踪确保逻辑一致性，并通过长期经验学习来增强推理能力，同时整合专家设计的工具包以支持多样化的临床任务。

Result: 通过 EndoAgentBench 基准测试（包含 5709 个视觉问答对），该系统在灵活性和推理能力上全面击败现有通用和医学多模态模型。

Conclusion: EndoAgent 展现了强大的推理和灵活性，在内窥镜分析领域有望成为先进解决方案。

Abstract: Developing general artificial intelligence (AI) systems to support endoscopic
image diagnosis is an emerging research priority. Existing methods based on
large-scale pretraining often lack unified coordination across tasks and
struggle to handle the multi-step processes required in complex clinical
workflows. While AI agents have shown promise in flexible instruction parsing
and tool integration across domains, their potential in endoscopy remains
underexplored. To address this gap, we propose EndoAgent, the first
memory-guided agent for vision-to-decision endoscopic analysis that integrates
iterative reasoning with adaptive tool selection and collaboration. Built on a
dual-memory design, it enables sophisticated decision-making by ensuring
logical coherence through short-term action tracking and progressively
enhancing reasoning acuity through long-term experiential learning. To support
diverse clinical tasks, EndoAgent integrates a suite of expert-designed tools
within a unified reasoning loop. We further introduce EndoAgentBench, a
benchmark of 5,709 visual question-answer pairs that assess visual
understanding and language generation capabilities in realistic scenarios.
Extensive experiments show that EndoAgent consistently outperforms both general
and medical multimodal models, exhibiting its strong flexibility and reasoning
capabilities.

</details>


### [350] [Hallucination as a Computational Boundary: A Hierarchy of Inevitability and the Oracle Escape](https://arxiv.org/abs/2508.07334)
*Quan Shi,Wang Xi,Zenghui Ding,Jianqing Gao,Xianjun Yang*

Main category: cs.AI

TL;DR: 本文探讨了大语言模型（LLMs）的幻觉现象，并提出了两种方法来解决这一问题：利用检索增强生成（RAGs）进行“计算跃迁”，以及通过连续学习和神经博弈论实现“内化的oracle”。


<details>
  <summary>Details</summary>
Motivation: 研究如何克服大语言模型的幻觉现象，以实现其可靠部署，同时为相关机制提供数学理论支持。

Method: 通过构建“计算必要性层级”形式化地定义了LLM，并提出了新颖的“学习者泵引理”，证明幻觉现象的不可避免性。提出了两种解决路径：1）将RAGs建模为oracle机器，实现“计算跃迁”；2）通过神经博弈论框架实现“内化oracle”的机制。

Result: 证明了幻觉现象不可避免的原因，并阐释了RAGs与连续学习在理论上的可行性及其提供的解决方案。

Conclusion: 尽管大语言模型的幻觉不可避免，但通过RAGs和内化oracle等路径，可以从理论上克服这些问题，为实践中提高模型可靠性提供了指导。

Abstract: The illusion phenomenon of large language models (LLMs) is the core obstacle
to their reliable deployment. This article formalizes the large language model
as a probabilistic Turing machine by constructing a "computational necessity
hierarchy", and for the first time proves the illusions are inevitable on
diagonalization, incomputability, and information theory boundaries supported
by the new "learner pump lemma". However, we propose two "escape routes": one
is to model Retrieval Enhanced Generations (RAGs) as oracle machines, proving
their absolute escape through "computational jumps", providing the first formal
theory for the effectiveness of RAGs; The second is to formalize continuous
learning as an "internalized oracle" mechanism and implement this path through
a novel neural game theory framework.Finally, this article proposes a

</details>


### [351] [Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach](https://arxiv.org/abs/2508.07353)
*Rubing Chen,Jiaxin Wu,Jian Wang,Xulu Zhang,Wenqi Fan,Chenghua Lin,Xiao-Yong Wei,Qing Li*

Main category: cs.AI

TL;DR: 本文提出了Comp-Comp，一个基于全面性和紧凑性原则的迭代基准构建框架，用于改进特定领域的大型语言模型性能评估。


<details>
  <summary>Details</summary>
Motivation: 现有领域特定基准主要聚焦于扩展定律，依赖大规模语料库或生成大范围的问题集，但忽略了语料库和QA设计在模型精准度和召回率上的影响。

Method: 提出Comp-Comp框架，以全面性确保语义召回，紧凑性提升精度，通过迭代优化，指导语料库和QA集合构建。

Result: 框架经过在某知名大学进行的案例研究验证，成功构建了一个大规模完整的封闭领域基准XUBench。

Conclusion: Comp-Comp框架具备跨领域扩展能力，为不同领域创建高效基准提供了有价值的见解。

Abstract: Numerous benchmarks have been built to evaluate the domain-specific abilities
of large language models (LLMs), highlighting the need for effective and
efficient benchmark construction. Existing domain-specific benchmarks primarily
focus on the scaling law, relying on massive corpora for supervised fine-tuning
or generating extensive question sets for broad coverage. However, the impact
of corpus and question-answer (QA) set design on the precision and recall of
domain-specific LLMs remains unexplored. In this paper, we address this gap and
demonstrate that the scaling law is not always the optimal principle for
benchmark construction in specific domains. Instead, we propose Comp-Comp, an
iterative benchmarking framework based on a comprehensiveness-compactness
principle. Here, comprehensiveness ensures semantic recall of the domain, while
compactness enhances precision, guiding both corpus and QA set construction. To
validate our framework, we conducted a case study in a well-renowned
university, resulting in the creation of XUBench, a large-scale and
comprehensive closed-domain benchmark. Although we use the academic domain as
the case in this work, our Comp-Comp framework is designed to be extensible
beyond academia, providing valuable insights for benchmark construction across
various domains.

</details>


### [352] [Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized via Two-Stage Reinforcement Learning](https://arxiv.org/abs/2508.07382)
*He Kong,Die Hu,Jingguo Ge,Liangxiong Li,Hui Li,Tong Li*

Main category: cs.AI

TL;DR: 本文介绍了一种名为Pentest-R1的框架，旨在通过两阶段强化学习，提高大语言模型在自动网络渗透测试中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前的大语言模型在自动网络渗透测试领域存在处理错误能力差、推理效率低等局限，亟需改进以提升网络安全防护能力。

Method: 设计两阶段强化学习流程：第一阶段通过500多个多步骤的真实例子，进行离线强化学习，以建立基础攻击逻辑；第二阶段在互动环境中进行在线强化学习，从反馈中优化策略。

Result: 在AutoPenBench和Cybench基准测试中表现出色，分别达到了24.2%和15.0%的成功率，其中Cybench结果创造了新的开源模型纪录。

Conclusion: Pentest-R1通过两阶段强化学习成功提升了开源大语言模型在网络渗透测试中的能力，有效解决了原模型的多项缺陷。

Abstract: Automating penetration testing is crucial for enhancing cybersecurity, yet
current Large Language Models (LLMs) face significant limitations in this
domain, including poor error handling, inefficient reasoning, and an inability
to perform complex end-to-end tasks autonomously. To address these challenges,
we introduce Pentest-R1, a novel framework designed to optimize LLM reasoning
capabilities for this task through a two-stage reinforcement learning pipeline.
We first construct a dataset of over 500 real-world, multi-step walkthroughs,
which Pentest-R1 leverages for offline reinforcement learning (RL) to instill
foundational attack logic. Subsequently, the LLM is fine-tuned via online RL in
an interactive Capture The Flag (CTF) environment, where it learns directly
from environmental feedback to develop robust error self-correction and
adaptive strategies. Our extensive experiments on the Cybench and AutoPenBench
benchmarks demonstrate the framework's effectiveness. On AutoPenBench,
Pentest-R1 achieves a 24.2\% success rate, surpassing most state-of-the-art
models and ranking second only to Gemini 2.5 Flash. On Cybench, it attains a
15.0\% success rate in unguided tasks, establishing a new state-of-the-art for
open-source LLMs and matching the performance of top proprietary models.
Ablation studies confirm that the synergy of both training stages is critical
to its success.

</details>


### [353] [Invert4TVG: A Temporal Video Grounding Framework with Inversion Tasks for Enhanced Action Understanding](https://arxiv.org/abs/2508.07388)
*Zhaoyu Chen,Hongnan Lin,Yongwei Nie,Fei Ma,Xuemiao Xu,Fei Yu,Chengjiang Long*

Main category: cs.AI

TL;DR: 本文介绍了一种改进时序视频定位(TVG)的新框架Invert4TVG，通过引入三个逆向任务来提升定位准确性和动作语义理解，并且无须额外的数据支持。


<details>
  <summary>Details</summary>
Motivation: 现有的TVG方法容易过拟合于高时序IoU指标，忽视了视频和查询中的语义动作理解，从而影响了模型鲁棒性。

Method: 提出了三个逆向任务：(1) 动词完成，用视频段预测查询中被遮蔽的动作动词；(2) 动作识别，识别查询中描述的动作；(3) 视频描述，生成包含查询相关动作的视频段描述。这些任务通过强化学习框架与TVG结合，通过设定奖励函数实现定位和语义的平衡优化。

Result: 实验表明，这种方法在Charades-STA数据集上，相比Time-R1，3B模型的R1@0.7提高了7.1%，效果超越现有的最先进方法。

Conclusion: 通过反转TVG任务以从视频段中推导查询相关动作，该框架显著增强了语义理解能力，提高了定位精度的上限。

Abstract: Temporal Video Grounding (TVG) seeks to localize video segments matching a
given textual query. Current methods, while optimizing for high temporal
Intersection-over-Union (IoU), often overfit to this metric, compromising
semantic action understanding in the video and query, a critical factor for
robust TVG. To address this, we introduce Inversion Tasks for TVG (Invert4TVG),
a novel framework that enhances both localization accuracy and action
understanding without additional data. Our approach leverages three inversion
tasks derived from existing TVG annotations: (1) Verb Completion, predicting
masked action verbs in queries from video segments; (2) Action Recognition,
identifying query-described actions; and (3) Video Description, generating
descriptions of video segments that explicitly embed query-relevant actions.
These tasks, integrated with TVG via a reinforcement learning framework with
well-designed reward functions, ensure balanced optimization of localization
and semantics. Experiments show our method outperforms state-of-the-art
approaches, achieving a 7.1\% improvement in R1@0.7 on Charades-STA for a 3B
model compared to Time-R1. By inverting TVG to derive query-related actions
from segments, our approach strengthens semantic understanding, significantly
raising the ceiling of localization accuracy.

</details>


### [354] [Generative AI for Strategic Plan Development](https://arxiv.org/abs/2508.07405)
*Jesse Ponnock*

Main category: cs.AI

TL;DR: 这篇文章提出了一种利用生成式人工智能(GAI)为大型政府组织制定战略计划的模块化模型，并使用BERTopic和非负矩阵分解(NMF)评估其主题建模的能力，结果表明BERTopic表现最佳。


<details>
  <summary>Details</summary>
Motivation: 推动自动化技术介入此前难以实现自动化的专业服务领域，并评估主流机器学习技术在战略计划制定中的实际应用效果。

Method: 利用生成式人工智能技术，建立了一种模块化战略计划开发模型，并具体对BERTopic和非负矩阵分解(NMF)进行评估，通过对美国政府问责局报告的主题建模，分析其与现有战略计划中“愿景要素”的相关性。

Result: 评估表明，BERTopic和NMF技术100%地生成了和战略计划“愿景要素”相似的主题，其中BERTopic被证明效果最好，超过一半相关主题具有“中等”或“强”相关性。

Conclusion: 生成式人工智能技术能够为战略计划制定提供有效支持，这一研究验证了概念的可行性，并为多模块的战略计划开发模式奠定了基础，同时对公共领域和经济效益有重要意义。

Abstract: Given recent breakthroughs in Generative Artificial Intelligence (GAI) and
Large Language Models (LLMs), more and more professional services are being
augmented through Artificial Intelligence (AI), which once seemed impossible to
automate. This paper presents a modular model for leveraging GAI in developing
strategic plans for large scale government organizations and evaluates leading
machine learning techniques in their application towards one of the identified
modules. Specifically, the performance of BERTopic and Non-negative Matrix
Factorization (NMF) are evaluated in their ability to use topic modeling to
generate themes representative of Vision Elements within a strategic plan. To
accomplish this, BERTopic and NMF models are trained using a large volume of
reports from the Government Accountability Office (GAO). The generated topics
from each model are then scored for similarity against the Vision Elements of a
published strategic plan and the results are compared. Our results show that
these techniques are capable of generating themes similar to 100% of the
elements being evaluated against. Further, we conclude that BERTopic performs
best in this application with more than half of its correlated topics achieving
a "medium" or "strong" correlation. A capability of GAI-enabled strategic plan
development impacts a multi-billion dollar industry and assists the federal
government in overcoming regulatory requirements which are crucial to the
public good. Further work will focus on the operationalization of the concept
proven in this study as well as viability of the remaining modules in the
proposed model for GAI-generated strategic plans.

</details>


### [355] [A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems](https://arxiv.org/abs/2508.07407)
*Jinyuan Fang,Yanwen Peng,Xi Zhang,Yingxu Wang,Xinhao Yi,Guibin Zhang,Yi Xu,Bin Wu,Siwei Liu,Zihao Li,Zhaochun Ren,Nikos Aletras,Xi Wang,Han Zhou,Zaiqiao Meng*

Main category: cs.AI

TL;DR: 这篇综述探讨了自我进化AI代理的现有技术，提出了一个统一概念框架，并系统性回顾了不同领域的自我进化策略，同时讨论了评价、安全及伦理问题。


<details>
  <summary>Details</summary>
Motivation: 现有的AI代理系统缺乏动态适应与持续进化能力，无法满足实际复杂环境的需求。

Method: 通过提出的统一框架分析并回顾了各类自我进化技术，包括面向特定领域的优化策略，并讨论相关的评价及伦理考虑。

Result: 提出了涵盖系统输入、代理系统、环境与优化器的统一反馈回路框架，详细梳理了当前的技术发展现状。

Conclusion: 系统性梳理为未来构建更适应性强、自主及终身学习的AI代理系统奠定基础。

Abstract: Recent advances in large language models have sparked growing interest in AI
agents capable of solving complex, real-world tasks. However, most existing
agent systems rely on manually crafted configurations that remain static after
deployment, limiting their ability to adapt to dynamic and evolving
environments. To this end, recent research has explored agent evolution
techniques that aim to automatically enhance agent systems based on interaction
data and environmental feedback. This emerging direction lays the foundation
for self-evolving AI agents, which bridge the static capabilities of foundation
models with the continuous adaptability required by lifelong agentic systems.
In this survey, we provide a comprehensive review of existing techniques for
self-evolving agentic systems. Specifically, we first introduce a unified
conceptual framework that abstracts the feedback loop underlying the design of
self-evolving agentic systems. The framework highlights four key components:
System Inputs, Agent System, Environment, and Optimisers, serving as a
foundation for understanding and comparing different strategies. Based on this
framework, we systematically review a wide range of self-evolving techniques
that target different components of the agent system. We also investigate
domain-specific evolution strategies developed for specialised fields such as
biomedicine, programming, and finance, where optimisation objectives are
tightly coupled with domain constraints. In addition, we provide a dedicated
discussion on the evaluation, safety, and ethical considerations for
self-evolving agentic systems, which are critical to ensuring their
effectiveness and reliability. This survey aims to provide researchers and
practitioners with a systematic understanding of self-evolving AI agents,
laying the foundation for the development of more adaptive, autonomous, and
lifelong agentic systems.

</details>


### [356] [Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs](https://arxiv.org/abs/2508.07466)
*Dom Huh,Prasant Mohapatra*

Main category: cs.AI

TL;DR: 本文探讨了将大型语言模型（LLM）与多智能体决策算法结合，以提高协作和解决问题能力，并进行了模块化设计和评估。


<details>
  <summary>Details</summary>
Motivation: 探讨语言作为协作和推理的关键工具，如何通过建立共同语言来更有效地促进多智能体之间的沟通和战略协调。

Method: 提出了多智能体LLM设计框架，包括高级提示工程、存储架构开发、多模态信息处理和通过微调算法对齐策略。通过经典游戏场景进行消融研究以验证设计效果。

Result: 实验结果表明，在具有社会困境和博弈论特性的经典游戏中，这些多智能体LLM设计的有效性得到了验证。

Conclusion: 本文提出的系统化设计框架为多智能体LLM的开发提供了重要参考，为解决复杂协作问题开辟了新方向。

Abstract: Language is a ubiquitous tool that is foundational to reasoning and
collaboration, ranging from everyday interactions to sophisticated
problem-solving tasks. The establishment of a common language can serve as a
powerful asset in ensuring clear communication and understanding amongst
agents, facilitating desired coordination and strategies. In this work, we
extend the capabilities of large language models (LLMs) by integrating them
with advancements in multi-agent decision-making algorithms. We propose a
systematic framework for the design of multi-agentic large language models
(LLMs), focusing on key integration practices. These include advanced prompt
engineering techniques, the development of effective memory architectures,
multi-modal information processing, and alignment strategies through
fine-tuning algorithms. We evaluate these design choices through extensive
ablation studies on classic game settings with significant underlying social
dilemmas and game-theoretic considerations.

</details>


### [357] [CP-Agent: Agentic Constraint Programming](https://arxiv.org/abs/2508.07468)
*Stefan Szeider*

Main category: cs.AI

TL;DR: 通过引入基于ReAct原则的通用Python编码智能体，成功解决了CP-Bench中所有101个约束编程基准问题。


<details>
  <summary>Details</summary>
Motivation: 探讨如何无需深厚领域知识与传统建模框架经验，实现从自然语言问题描述到形式化约束建模的自动化翻译。

Method: 基于ReAct原则开发了一种纯代理策略的Python编码智能体。智能体利用IPython内核进行状态保持的代码执行和迭代开发，并通过项目提示嵌入领域知识，动态测试、调试和验证问题的解决方案。

Result: 该方法无需复杂的固定流程或特定设计的智能体架构，成功解决了基准集中的所有问题。

Conclusion: 约束建模任务更侧重通用编码工具和领域知识提示的结合，而非专用的智能体架构或预定义的工作流。

Abstract: Translating natural language problem descriptions into formal constraint
models remains a fundamental challenge in constraint programming, requiring
deep expertise in both the problem domain and modeling frameworks. Previous
approaches to automating this translation have employed fixed workflows with
predetermined modeling steps, failing on a significant number of benchmark
problems. We present a new approach using a pure agentic strategy without any
fixed pipeline. We developed a general-purpose Python coding agent based on the
ReAct (Reason and Act) principle, utilizing a persistent IPython kernel for
stateful code execution and iterative development. Rather than embedding
constraint programming logic into the agent architecture, domain-specific
expertise is injected solely through a carefully crafted project prompt. The
agent combines this prompt-encoded knowledge with access to file operations and
code execution tools, enabling it to test hypotheses, debug failures, and
verify solutions dynamically. Implemented in just a few hundred lines of code,
this architecture successfully solves all 101 problems of the CP-Bench
constraint programming benchmark set. The results suggest that constraint
modeling tasks require the combination of general coding tools and domain
expertise encoded in prompts, rather than specialized agent architectures or
predefined workflows.

</details>


### [358] [Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy](https://arxiv.org/abs/2508.07485)
*Alexander Duffy,Samuel J Paech,Ishana Shastri,Elizabeth Karpinski,Baptiste Alloui-Cros,Tyler Marques,Matthew Lyle Olson*

Main category: cs.AI

TL;DR: 本文提出了第一个无需微调或专门训练即可用于评估本地大型语言模型（LLMs）在全压外交游戏中的表现的工具。


<details>
  <summary>Details</summary>
Motivation: 解决现有研究中由于外交游戏复杂性和信息密度高且比赛变异性大而难以进一步研究的问题。

Method: 通过数据驱动的迭代优化文本游戏状态表示，使24B模型无需微调即可可靠完成比赛，并开发工具支持假设测试与统计分析。

Result: 发现较大的模型在表现上优于较小模型，但小模型仍能胜任。同时提出关键状态分析协议，以深入分析游戏中的关键时刻。

Conclusion: 该评估工具无需微调即可用于评估LLMs的战略推理能力，并揭示广泛使用的LLMs中自然出现的相关能力，同时促进该领域的研究自由化。

Abstract: We present the first evaluation harness that enables any out-of-the-box,
local, Large Language Models (LLMs) to play full-press Diplomacy without
fine-tuning or specialized training. Previous work required frontier LLMs, or
fine-tuning, due to the high complexity and information density of Diplomacy's
game state. Combined with the high variance of matches, these factors made
Diplomacy prohibitive for study. In this work, we used data-driven iteration to
optimize a textual game state representation such that a 24B model can reliably
complete matches without any fine tuning. We develop tooling to facilitate
hypothesis testing and statistical analysis, and we present case studies on
persuasion, aggressive playstyles, and performance across a range of models. We
conduct a variety of experiments across many popular LLMs, finding the larger
models perform the best, but the smaller models still play adequately. We also
introduce Critical State Analysis: an experimental protocol for rapidly
iterating and analyzing key moments in a game at depth. Our harness
democratizes the evaluation of strategic reasoning in LLMs by eliminating the
need for fine-tuning, and it provides insights into how these capabilities
emerge naturally from widely used LLMs. Our code is available in the supplement
and will be open sourced.

</details>


### [359] [MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool Use Benchmark](https://arxiv.org/abs/2508.07575)
*Shiqing Fan,Xichen Ding,Liang Zhang,Linjian Mo*

Main category: cs.AI

TL;DR: MCPToolBench++ 提供了一个用于评估 LLM 在 MCP 工具使用能力方面的多域大规模基准，包括超过 4000 个 MCP 服务器和多步骤工具调用。


<details>
  <summary>Details</summary>
Motivation: 评估 LLM 和 AI 代理在 MCP 工具使用能力上面临的挑战，包括缺乏全面的数据集和基准、多样的工具响应格式、上下文窗口限制等。

Method: 提出 MCPToolBench++，基于 MCP 市场和 GitHub 社区，收集了超 4000 个 MCP 服务器，提供多领域单步与多步工具调用数据集，并对现有 SOTA LLM 进行评估。

Result: 通过 MCPToolBench++ 对 SOTA LLMs 的工具调用能力进行了全面评估，提供了基准结果。

Conclusion: MCPToolBench++ 克服了当前 MCP 工具评估的多个问题，为 LLM 的工具使用能力提供了重要的评估平台。

Abstract: LLMs' capabilities are enhanced by using function calls to integrate various
data sources or API results into the context window. Typical tools include
search, web crawlers, maps, financial data, file systems, and browser usage,
etc. Integrating these data sources or functions requires a standardized
method. The Model Context Protocol (MCP) provides a standardized way to supply
context to LLMs. However, the evaluation of LLMs and AI Agents' MCP tool use
abilities suffer from several issues. First, there's a lack of comprehensive
datasets or benchmarks to evaluate various MCP tools. Second, the diverse
formats of response from MCP tool call execution further increase the
difficulty of evaluation. Additionally, unlike existing tool-use benchmarks
with high success rates in functions like programming and math functions, the
success rate of real-world MCP tool is not guaranteed and varies across
different MCP servers. Furthermore, the LLMs' context window also limits the
number of available tools that can be called in a single run, because the
textual descriptions of tool and the parameters have long token length for an
LLM to process all at once. To help address the challenges of evaluating LLMs'
performance on calling MCP tools, we propose MCPToolBench++, a large-scale,
multi-domain AI Agent tool use benchmark. As of July 2025, this benchmark is
build upon marketplace of over 4k MCP servers from more than 40 categories,
collected from the MCP marketplaces and GitHub communities. The datasets
consist of both single-step and multi-step tool calls across different
categories. We evaluated SOTA LLMs with agentic abilities on this benchmark and
reported the results.

</details>


### [360] [Optimization of Private Semantic Communication Performance: An Uncooperative Covert Communication Method](https://arxiv.org/abs/2508.07586)
*Wenjing Zhang,Ye Hu,Tao Luo,Zhilong Zhang,Mingzhe Chen*

Main category: cs.AI

TL;DR: 本文提出了一种用于隐藏语义通信的新框架，通过优化信息传输和功率分配以提升隐私与传输质量。


<details>
  <summary>Details</summary>
Motivation: 通过语义信息的传输提升通信效率，同时保护其不被攻击者窃听。

Method: 设计了优先采样辅助的双延迟深度确定性策略梯度算法，优化语义信息资料和功率分配，无需服务器与干扰信号发送者间的通信。

Result: 仿真结果显示，该算法能将隐私和语义信息传输质量分别提高77.8%和14.3%。

Conclusion: 提出的方法显著提高了通信隐私性和质量，较传统方法更具优势。

Abstract: In this paper, a novel covert semantic communication framework is
investigated. Within this framework, a server extracts and transmits the
semantic information, i.e., the meaning of image data, to a user over several
time slots. An attacker seeks to detect and eavesdrop the semantic transmission
to acquire details of the original image. To avoid data meaning being
eavesdropped by an attacker, a friendly jammer is deployed to transmit jamming
signals to interfere the attacker so as to hide the transmitted semantic
information. Meanwhile, the server will strategically select time slots for
semantic information transmission. Due to limited energy, the jammer will not
communicate with the server and hence the server does not know the transmit
power of the jammer. Therefore, the server must jointly optimize the semantic
information transmitted at each time slot and the corresponding transmit power
to maximize the privacy and the semantic information transmission quality of
the user. To solve this problem, we propose a prioritised sampling assisted
twin delayed deep deterministic policy gradient algorithm to jointly determine
the transmitted semantic information and the transmit power per time slot
without the communications between the server and the jammer. Compared to
standard reinforcement learning methods, the propose method uses an additional
Q network to estimate Q values such that the agent can select the action with a
lower Q value from the two Q networks thus avoiding local optimal action
selection and estimation bias of Q values. Simulation results show that the
proposed algorithm can improve the privacy and the semantic information
transmission quality by up to 77.8% and 14.3% compared to the traditional
reinforcement learning methods.

</details>


### [361] [HGMF: A Hierarchical Gaussian Mixture Framework for Scalable Tool Invocation within the Model Context Protocol](https://arxiv.org/abs/2508.07602)
*Wenpeng Xing,Zhipeng Chen,Changting Lin,Meng Han*

Main category: cs.AI

TL;DR: 本文提出了一种称为分层高斯混合框架（HGMF）的方法，通过分层的方式高效筛选外部工具以便于大语言模型（LLMs）更精准地调用。


<details>
  <summary>Details</summary>
Motivation: 目前使用外部工具使得LLMs能够处理复杂现实任务，但在海量且分层组织的工具库中选择正确的工具非常困难，主要受模型上下文窗口限制以及无关选项噪声影响。

Method: HGMF将用户查询和工具描述统一映射到语义空间中，分两步进行筛选：首先对服务器进行GMM（高斯混合模型）聚类并根据查询概率过滤，其次对选定服务相关的工具重复同样的操作以生成精简的候选集。

Result: 实际实验表明，HGMF在公共数据集上显著提升了工具选择准确率，同时显著降低了推理时延。

Conclusion: HGMF框架验证了其在处理大规模工具库时的可扩展性和有效性，能够有效支持LLM提升选用外部工具的效率。

Abstract: Invoking external tools enables Large Language Models (LLMs) to perform
complex, real-world tasks, yet selecting the correct tool from large,
hierarchically-structured libraries remains a significant challenge. The
limited context windows of LLMs and noise from irrelevant options often lead to
low selection accuracy and high computational costs. To address this, we
propose the Hierarchical Gaussian Mixture Framework (HGMF), a probabilistic
pruning method for scalable tool invocation. HGMF first maps the user query and
all tool descriptions into a unified semantic space. The framework then
operates in two stages: it clusters servers using a Gaussian Mixture Model
(GMM) and filters them based on the query's likelihood. Subsequently, it
applies the same GMM-based clustering and filtering to the tools associated
with the selected servers. This hierarchical process produces a compact,
high-relevance candidate set, simplifying the final selection task for the LLM.
Experiments on a public dataset show that HGMF significantly improves tool
selection accuracy while reducing inference latency, confirming the framework's
scalability and effectiveness for large-scale tool libraries.

</details>


### [362] [ThinkTuning: Instilling Cognitive Reflections without Distillation](https://arxiv.org/abs/2508.07616)
*Aswin RRV,Jacob Dineen,Divij Handa,Md Nayem Uddin,Mihir Parmar,Chitta Baral,Ben Zhou*

Main category: cs.AI

TL;DR: 本文提出了一种名为ThinkTuning的方法，通过教师模型对学生模型的反馈，提高学生模型在推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明仅依靠强化学习无法真正赋予基础模型新的推理能力，而是发掘已有能力。因此需要设计新的训练方法赋予模型思考能力。

Method: 使用基于GRPO的交互式训练，教师模型对学生模型进行问题反馈和纠正，从而渐进性提高学生模型的推理能力。

Result: ThinkTuning方法在多项基准测试中相比零样本基线平均提高3.85%，在MATH-500等数据集上相较于vanilla-GRPO基线表现也均有所提升。

Conclusion: 通过教师模型反馈指导，能够有效提升学生模型的推理能力，为基础模型引入推理行为提供了有益的方法。

Abstract: Recent advances in test-time scaling have led to the emergence of thinking
LLMs that exhibit self-reflective behaviors and multi-step reasoning. While RL
drives this self-improvement paradigm, a recent study (Gandhi et al., 2025)
shows that RL alone does not truly instill these new reasoning abilities - it
merely draws out behaviors already present in the base models. This raises a
question: How can we train the models that don't exhibit such thinking behavior
to develop it in the first place? To this end, we propose ThinkTuning, a
GRPO-based interactive training approach where we augment the rollouts of a
student model with the guidance from a teacher model. A simple idea from
classroom practice inspires our method: a teacher poses a problem, lets the
student try an answer, then gives corrective feedback -- enough to point the
mind in the right direction and then show the solution. Each piece of feedback
reshapes the student's thoughts, leading them to arrive at the correct
solution. Similarly, we find that this type of implicit supervision through
feedback from a teacher model of the same size improves the reasoning
capabilities of the student model. In particular, on average, our method shows
a 3.85% improvement over zero-shot baselines across benchmarks, and on
MATH-500, AIME and GPQA-Diamond it shows 2.08%, 2.23% and 3.99% improvements
over the vanilla-GRPO baseline. Source code is available at
https://github.com/3rdAT/ThinkTuning.

</details>


### [363] [Multimodal AI Systems for Enhanced Laying Hen Welfare Assessment and Productivity Optimization](https://arxiv.org/abs/2508.07628)
*Daniel Essien,Suresh Neethirajan*

Main category: cs.AI

TL;DR: 本论文探讨如何利用多模态人工智能提升现代农场产蛋鸡的福利监控。


<details>
  <summary>Details</summary>
Motivation: 传统的鸡群福利评估方式费时费力且单一，无法应对现代农场多样化、复杂的需求，急需引入智能化的多维度监控生态系统。

Method: 使用多模态人工智能技术融合视觉、声学、环境和生理数据，采用特征级融合策略，同时引入衡量模型适应性和数据质量的新工具DTS和DRI，并提出模块化部署框架。

Result: 特征级数据融合在实际农场条件下表现出更高的鲁棒性和平衡性，同时突破了传感器脆弱性和部署成本等障碍。

Conclusion: 实现从被动、单一观测的福利评估向主动、精准的多模态监控过渡，为将生产力与科学伦理动物护理结合奠定基础。

Abstract: The future of poultry production depends on a paradigm shift replacing
subjective, labor-intensive welfare checks with data-driven, intelligent
monitoring ecosystems. Traditional welfare assessments-limited by human
observation and single-sensor data-cannot fully capture the complex,
multidimensional nature of laying hen welfare in modern farms. Multimodal
Artificial Intelligence (AI) offers a breakthrough, integrating visual,
acoustic, environmental, and physiological data streams to reveal deeper
insights into avian welfare dynamics. This investigation highlights multimodal
As transformative potential, showing that intermediate (feature-level) fusion
strategies achieve the best balance between robustness and performance under
real-world poultry conditions, and offer greater scalability than early or late
fusion approaches. Key adoption barriers include sensor fragility in harsh farm
environments, high deployment costs, inconsistent behavioral definitions, and
limited cross-farm generalizability. To address these, we introduce two novel
evaluation tools - the Domain Transfer Score (DTS) to measure model
adaptability across diverse farm settings, and the Data Reliability Index (DRI)
to assess sensor data quality under operational constraints. We also propose a
modular, context-aware deployment framework designed for laying hen
environments, enabling scalable and practical integration of multimodal
sensing. This work lays the foundation for a transition from reactive, unimodal
monitoring to proactive, precision-driven welfare systems that unite
productivity with ethical, science based animal care.

</details>


### [364] [Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents](https://arxiv.org/abs/2508.07642)
*Tianyi Ma,Yue Zhang,Zehao Wang,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: 本文提出SkillNav框架，通过引入基于技能的结构化推理提升视觉-语言导航任务的表现。


<details>
  <summary>Details</summary>
Motivation: 当前方法在复杂空间和时间推理方面的泛化能力不足，尤其是在未见过的场景中表现较差，因此需要一种更有效的解决方案。

Method: 提出SkillNav，一个模块化框架，将导航任务分解为若干可解释的原子技能，每个技能由专门的代理负责。同时引入基于视觉-语言模型的零样本路由器，动态选择最合适的代理完成任务。

Result: SkillNav在R2R基准测试上取得了新的最先进表现，并在包括新指令风格和未知环境的GSA-R2R基准测试中展现了较强的泛化能力。

Conclusion: SkillNav框架通过模块化和技能推理策略增强了现有方法的泛化能力，这为视觉-语言导航任务的未来发展提供了重要的思路。

Abstract: Vision-and-Language Navigation (VLN) poses significant challenges in enabling
agents to interpret natural language instructions and navigate complex 3D
environments. While recent progress has been driven by large-scale pre-training
and data augmentation, current methods still struggle to generalize to unseen
scenarios, particularly when complex spatial and temporal reasoning is
required. In this work, we propose SkillNav, a modular framework that
introduces structured, skill-based reasoning into Transformer-based VLN agents.
Our method decomposes navigation into a set of interpretable atomic skills
(e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each
handled by a specialized agent. We then introduce a novel zero-shot
Vision-Language Model (VLM)-based router, which dynamically selects the most
suitable agent at each time step by aligning sub-goals with visual observations
and historical actions. SkillNav achieves a new state-of-the-art performance on
the R2R benchmark and demonstrates strong generalization to the GSA-R2R
benchmark that includes novel instruction styles and unseen environments.

</details>


### [365] [Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation](https://arxiv.org/abs/2508.07649)
*Jie Li,Haoye Dong,Zhengyang Wu,Zetao Zheng,Mingrong Lin*

Main category: cs.AI

TL;DR: 本文提出了一种名为DiMuST的新型POI推荐模型，通过解耦多模空间-时间图表示，解决了现有模型中空间和时间转移错位的问题。实验验证其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究中，空间和时间转移被分别建模，导致表示不一致，引入冗余信息，增加模型的不确定性和降低可解释性。为了解决这一问题，作者提出了一种基于解耦表示学习的新方法。

Method: 提出了一种新的解耦变分多模图自动编码器(DAE)，通过解耦混合空间-时间图中的共享和私有分布，采用专家乘积机制融合共享特征，并通过对比约束去噪私有特征。

Result: 在两个具有挑战性的数据集上，本文方法在多种性能指标上显著优于现有方法。

Conclusion: 该方法有效捕捉了POI的空间-时间转移表示，同时保留了其空间-时间关系的内在关联，证明了解耦多模图方法的有效性。

Abstract: Next Point-of-Interest (POI) recommendation is a research hotspot in business
intelligence, where users' spatial-temporal transitions and social
relationships play key roles. However, most existing works model spatial and
temporal transitions separately, leading to misaligned representations of the
same spatial-temporal key nodes. This misalignment introduces redundant
information during fusion, increasing model uncertainty and reducing
interpretability. To address this issue, we propose DiMuST, a socially enhanced
POI recommendation model based on disentangled representation learning over
multiplex spatial-temporal transition graphs. The model employs a novel
Disentangled variational multiplex graph Auto-Encoder (DAE), which first
disentangles shared and private distributions using a multiplex
spatial-temporal graph strategy. It then fuses the shared features via a
Product of Experts (PoE) mechanism and denoises the private features through
contrastive constraints. The model effectively captures the spatial-temporal
transition representations of POIs while preserving the intrinsic correlation
of their spatial-temporal relationships. Experiments on two challenging
datasets demonstrate that our DiMuST significantly outperforms existing methods
across multiple metrics.

</details>


### [366] [1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning](https://arxiv.org/abs/2508.07667)
*Wenkai Li,Liwen Sun,Zhenxiang Guan,Xuhui Zhou,Maarten Sap*

Main category: cs.AI

TL;DR: 提出一种多智能体框架，解决LLM在处理多源信息时的隐私泄露问题，通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决交互环境中LLM处理私密和公共信息时的上下文隐私问题。

Method: 设计多智能体框架，将隐私推理分解为提取和分类等子任务，并通过系统性消融实验分析信息流拓扑对隐私错误的影响。

Result: 在ConfAIde和PrivacyLens基准上，多智能体配置减少了18%和19%的隐私信息泄露，且优于单智能体基线模型。

Conclusion: 多智能体系统在LLM的上下文隐私中表现出显著优势，强调了信息流设计的重要性。

Abstract: Addressing contextual privacy concerns remains challenging in interactive
settings where large language models (LLMs) process information from multiple
sources (e.g., summarizing meetings with private and public information). We
introduce a multi-agent framework that decomposes privacy reasoning into
specialized subtasks (extraction, classification), reducing the information
load on any single agent while enabling iterative validation and more reliable
adherence to contextual privacy norms. To understand how privacy errors emerge
and propagate, we conduct a systematic ablation over information-flow
topologies, revealing when and why upstream detection mistakes cascade into
downstream leakage. Experiments on the ConfAIde and PrivacyLens benchmark with
several open-source and closed-sourced LLMs demonstrate that our best
multi-agent configuration substantially reduces private information leakage
(\textbf{18\%} on ConfAIde and \textbf{19\%} on PrivacyLens with GPT-4o) while
preserving the fidelity of public content, outperforming single-agent
baselines. These results highlight the promise of principled information-flow
design in multi-agent systems for contextual privacy with LLMs.

</details>


### [367] [EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration](https://arxiv.org/abs/2508.07671)
*Mohamed Rayan Barhdadi,Mehmet Tuncel,Erchin Serpedin,Hasan Kurban*

Main category: cs.AI

TL;DR: 本文引入面向人道主义移民帮助的EMPATHIA框架，通过多代理系统和解释性推荐方法平衡文化、情感与伦理因素，提升难民融合流程的长效性和透明度。


<details>
  <summary>Details</summary>
Motivation: 现有的AI方法在难民融合中关注狭隘目标如就业，忽视了文化、情感及伦理维度中的长期影响，亟需一种既能优化决策又能保护人类尊严的新方法。

Method: 基于Kegan建构性发展理论，EMPATHIA框架包括三个模块：SEED负责初始安置，RISE助力快速独立，THRIVE优化长期文化融合。SEED利用情感、文化和伦理代理组成的选择-验证架构，提供透明可解释的推荐。

Result: 在联合国Kakuma数据集及6,359名难民样本实验中，框架达到87.4%的验证收敛率，并通过解释性评估平衡五个东道国的多项社会经济因素。

Conclusion: EMPATHIA通过集成多元文化、情感与伦理因素，促进人类-机器协作，提供了一种适用于多价值协调问题的普适性AI驱动分配框架。

Abstract: Current AI approaches to refugee integration optimize narrow objectives such
as employment and fail to capture the cultural, emotional, and ethical
dimensions critical for long-term success. We introduce EMPATHIA (Enriched
Multimodal Pathways for Agentic Thinking in Humanitarian Immigrant Assistance),
a multi-agent framework addressing the central Creative AI question: how do we
preserve human dignity when machines participate in life-altering decisions?
Grounded in Kegan's Constructive Developmental Theory, EMPATHIA decomposes
integration into three modules: SEED (Socio-cultural Entry and Embedding
Decision) for initial placement, RISE (Rapid Integration and Self-sufficiency
Engine) for early independence, and THRIVE (Transcultural Harmony and
Resilience through Integrated Values and Engagement) for sustained outcomes.
SEED employs a selector-validator architecture with three specialized agents -
emotional, cultural, and ethical - that deliberate transparently to produce
interpretable recommendations. Experiments on the UN Kakuma dataset (15,026
individuals, 7,960 eligible adults 15+ per ILO/UNHCR standards) and
implementation on 6,359 working-age refugees (15+) with 150+ socioeconomic
variables achieved 87.4% validation convergence and explainable assessments
across five host countries. EMPATHIA's weighted integration of cultural,
emotional, and ethical factors balances competing value systems while
supporting practitioner-AI collaboration. By augmenting rather than replacing
human expertise, EMPATHIA provides a generalizable framework for AI-driven
allocation tasks where multiple values must be reconciled.

</details>


### [368] [Ethics2vec: aligning automatic agents and human preferences](https://arxiv.org/abs/2508.07673)
*Gianluca Bontempi*

Main category: cs.AI

TL;DR: 本文提出利用Ethics2Vec方法，将自动代理行为映射为多变量向量表示，以解决人工智能系统与人类价值观对齐的难题。


<details>
  <summary>Details</summary>
Motivation: 解决人工智能系统与人类价值观对齐问题，特别是在面对不可量化或无法比较的伦理价值时的挑战。

Method: 将惯用的Anything2vec方法扩展到伦理领域，通过Ethics2Vec方法，将代理决策行为映射为多变量向量表示，用于比较和评估与人类价值观的对齐程度。

Result: 实现了Ethics2Vec方法在二进制决策场景和自动控制环境（如自动驾驶汽车控制法则）中的应用与扩展。

Conclusion: Ethics2Vec方法为解决人工智能与人类价值对齐问题提供了一种新颖且可行的框架，尤其适用于处理不可度量的复杂伦理价值问题。

Abstract: Though intelligent agents are supposed to improve human experience (or make
it more efficient), it is hard from a human perspective to grasp the ethical
values which are explicitly or implicitly embedded in an agent behaviour. This
is the well-known problem of alignment, which refers to the challenge of
designing AI systems that align with human values, goals and preferences. This
problem is particularly challenging since most human ethical considerations
refer to \emph{incommensurable} (i.e. non-measurable and/or incomparable)
values and criteria. Consider, for instance, a medical agent prescribing a
treatment to a cancerous patient. How could it take into account (and/or weigh)
incommensurable aspects like the value of a human life and the cost of the
treatment? Now, the alignment between human and artificial values is possible
only if we define a common space where a metric can be defined and used. This
paper proposes to extend to ethics the conventional Anything2vec approach,
which has been successful in plenty of similar and hard-to-quantify domains
(ranging from natural language processing to recommendation systems and graph
analysis). This paper proposes a way to map an automatic agent decision-making
(or control law) strategy to a multivariate vector representation, which can be
used to compare and assess the alignment with human values. The Ethics2Vec
method is first introduced in the case of an automatic agent performing binary
decision-making. Then, a vectorisation of an automatic control law (like in the
case of a self-driving car) is discussed to show how the approach can be
extended to automatic control settings.

</details>


### [369] [Symmetry-Aware Transformer Training for Automated Planning](https://arxiv.org/abs/2508.07743)
*Markus Fritzsche,Elliot Gestrin,Jendrik Seipp*

Main category: cs.AI

TL;DR: 提出了一种使Transformer具有对称性意识的对比学习目标，从而改善其在自动规划中的性能，克服了PlanGPT的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer在自动规划领域因对称性问题无法高效学习从而限制性能的问题。

Method: 提出一种新型对比学习目标，使Transformer能够识别对称性，并结合架构改进来训练生成计划或预测启发式方法。

Result: 通过多个规划域的实验表明，对称性意识的训练可以有效提升Transformer模型的性能。

Conclusion: 对称性意识的引入为Transformer在自动规划领域的应用提供了新的可能性，解决了PlanGPT的扩展性问题。

Abstract: While transformers excel in many settings, their application in the field of
automated planning is limited. Prior work like PlanGPT, a state-of-the-art
decoder-only transformer, struggles with extrapolation from easy to hard
planning problems. This in turn stems from problem symmetries: planning tasks
can be represented with arbitrary variable names that carry no meaning beyond
being identifiers. This causes a combinatorial explosion of equivalent
representations that pure transformers cannot efficiently learn from. We
propose a novel contrastive learning objective to make transformers
symmetry-aware and thereby compensate for their lack of inductive bias.
Combining this with architectural improvements, we show that transformers can
be efficiently trained for either plan-generation or heuristic-prediction. Our
results across multiple planning domains demonstrate that our symmetry-aware
training effectively and efficiently addresses the limitations of PlanGPT.

</details>


### [370] [Best-Effort Policies for Robust Markov Decision Processes](https://arxiv.org/abs/2508.07790)
*Alessandro Abate,Thom Badings,Giuseppe De Giacomo,Francesco Fabiano*

Main category: cs.AI

TL;DR: 本文研究了在状态转移概率不确定的情况下，如何在鲁棒MDP（RMDP）框架下选择最优策略。提出了一种改进的策略选择标准，称为最优鲁棒最佳努力（ORBE）策略，兼顾最坏情况和非完全对抗性转移概率。


<details>
  <summary>Details</summary>
Motivation: 传统的RMDP方法仅关注最坏情况的期望回报，但实际问题中常涉及不同程度的非对抗性转移概率。提出改进标准的动机是突破这一限制，综合考虑更广泛的应用情境，为策略选择提供更细化的依据。

Method: 通过引入博弈论中的占优性和最佳努力的理念，定义了一种新的策略选择标准；并证明了满足此标准的ORBE策略的存在性，给出其结构特征及计算算法。

Result: 验证了ORBE策略计算的可行性，且其计算开销仅比标准的鲁棒值迭代方法略高，同时有效解决了多最优策略情况下的模糊性问题。

Conclusion: 提出的ORBE策略在不显著增加计算成本的情况下，为RMDP的策略选择提供了更为精细和原则性的决策依据，实验结果表明其实际可行性。

Abstract: We study the common generalization of Markov decision processes (MDPs) with
sets of transition probabilities, known as robust MDPs (RMDPs). A standard goal
in RMDPs is to compute a policy that maximizes the expected return under an
adversarial choice of the transition probabilities. If the uncertainty in the
probabilities is independent between the states, known as s-rectangularity,
such optimal robust policies can be computed efficiently using robust value
iteration. However, there might still be multiple optimal robust policies,
which, while equivalent with respect to the worst-case, reflect different
expected returns under non-adversarial choices of the transition probabilities.
Hence, we propose a refined policy selection criterion for RMDPs, drawing
inspiration from the notions of dominance and best-effort in game theory.
Instead of seeking a policy that only maximizes the worst-case expected return,
we additionally require the policy to achieve a maximal expected return under
different (i.e., not fully adversarial) transition probabilities. We call such
a policy an optimal robust best-effort (ORBE) policy. We prove that ORBE
policies always exist, characterize their structure, and present an algorithm
to compute them with a small overhead compared to standard robust value
iteration. ORBE policies offer a principled tie-breaker among optimal robust
policies. Numerical experiments show the feasibility of our approach.

</details>


### [371] [KIRETT: Knowledge-Graph-Based Smart Treatment Assistant for Intelligent Rescue Operations](https://arxiv.org/abs/2508.07834)
*Mubaris Nadeem,Johannes Zenkert,Lisa Bender,Christian Weber,Madjid Fathi*

Main category: cs.AI

TL;DR: 本文提出了一种基于知识图谱的系统，为急救人员提供智能化的治疗建议和人工智能驱动的情境预判。


<details>
  <summary>Details</summary>
Motivation: 随着全球紧急救援需求的增加，快速提供个性化的医疗服务成为关键，而急救人员往往在时间有限的情况下难以充分利用自身知识。

Method: 通过构建一个以知识图谱为核心的知识管理系统，利用人工智能对情况进行预判，并为急救人员提供即时医疗建议。

Result: 该知识管理系统能够实时处理和评估紧急情况中的数据，从而优化了急救人员的治疗过程。

Conclusion: 基于知识图谱和人工智能的系统显著提高了急救医疗中的效率和精准度，为患者提供了更加优质的医疗服务。

Abstract: Over the years, the need for rescue operations throughout the world has
increased rapidly. Demographic changes and the resulting risk of injury or
health disorders form the basis for emergency calls. In such scenarios, first
responders are in a rush to reach the patient in need, provide first aid, and
save lives. In these situations, they must be able to provide personalized and
optimized healthcare in the shortest possible time and estimate the patients
condition with the help of freshly recorded vital data in an emergency
situation. However, in such a timedependent situation, first responders and
medical experts cannot fully grasp their knowledge and need assistance and
recommendation for further medical treatments. To achieve this, on the spot
calculated, evaluated, and processed knowledge must be made available to
improve treatments by first responders. The Knowledge Graph presented in this
article as a central knowledge representation provides first responders with an
innovative knowledge management that enables intelligent treatment
recommendations with an artificial intelligence-based pre-recognition of the
situation.

</details>


### [372] [\(X\)-evolve: Solution space evolution powered by large language models](https://arxiv.org/abs/2508.07932)
*Yi Zhai,Zhiqiang Wei,Ruohan Li,Keyu Pan,Shuo Liu,Lu Zhang,Jianmin Ji,Wuyang Zhang,Yu Zhang,Yanyong Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种将大语言模型（LLMs）与进化算法（EAs）结合的新方法——X-evolve，通过优化解决方案空间而非单一解决方案，实现优化问题的高效求解。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过进化单一解决方案，导致LLM调用成本高昂，因此需要一种更高效的搜索策略来降低成本并加快优化速度。

Method: X-evolve采用程序生成方式，用LLMs生成包含可调参数的可调解决方案空间，并通过基于分数的搜索算法高效探索该参数化空间。

Result: 该方法在三个困难优化问题中验证了效果，比如提升了cap set问题的下界，增加了15节点循环图的独立集，以及生成了优于标准策略的在线装箱问题启发式算法。

Conclusion: X-evolve通过探索解决方案空间显著提高了搜索效率，使得解决高维问题成为可能，并大幅减少了LLM调用成本。

Abstract: While combining large language models (LLMs) with evolutionary algorithms
(EAs) shows promise for solving complex optimization problems, current
approaches typically evolve individual solutions, often incurring high LLM call
costs. We introduce \(X\)-evolve, a paradigm-shifting method that instead
evolves solution spaces \(X\) (sets of individual solutions) - subsets of the
overall search space \(S\). In \(X\)-evolve, LLMs generate tunable programs
wherein certain code snippets, designated as parameters, define a tunable
solution space. A score-based search algorithm then efficiently explores this
parametrically defined space, guided by feedback from objective function
scores. This strategy enables broader and more efficient exploration, which can
potentially accelerate convergence at a much lower search cost, requiring up to
two orders of magnitude fewer LLM calls than prior leading methods. We
demonstrate \(X\)-evolve's efficacy across three distinct hard optimization
problems. For the cap set problem, we discover a larger partial admissible set,
establishing a new tighter asymptotic lower bound for the cap set constant (\(C
\ge 2.2203\)). In information theory, we uncover a larger independent set for
the 15-vertex cycle graph (\(\mathcal{C}_{15}^{\boxtimes 5}\), size 19,946),
thereby raising the known lower bound on its Shannon capacity. Furthermore, for
the NP-hard online bin packing problem, we generate heuristics that
consistently outperform standard strategies across established benchmarks. By
evolving solution spaces, our method considerably improves search
effectiveness, making it possible to tackle high-dimensional problems that were
previously computationally prohibitive.

</details>


### [373] [Deep Reinforcement Learning with anticipatory reward in LSTM for Collision Avoidance of Mobile Robots](https://arxiv.org/abs/2508.07941)
*Olivier Poulet,Frédéric Guinand,François Guérin*

Main category: cs.AI

TL;DR: 提出了一种基于LSTM模型的碰撞风险预测方法，结合DQN进行奖励动态调整，有效减少了碰撞，提高了稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在缺乏通信或标识情况下的碰撞预测与避免问题。

Method: 利用LSTM模型基于过去轨迹预测机器人位置，并结合DQN动态调整奖励机制以降低碰撞风险。

Result: 在受限环境测试中，即使采样频率低至1 Hz，仍显著减少了碰撞数并提升了机器人的稳定性。

Conclusion: 该方法计算成本较低，适合嵌入式系统应用，显示较强的实际吸引力。

Abstract: This article proposes a collision risk anticipation method based on
short-term prediction of the agents position. A Long Short-Term Memory (LSTM)
model, trained on past trajectories, is used to estimate the next position of
each robot. This prediction allows us to define an anticipated collision risk
by dynamically modulating the reward of a Deep Q-Learning Network (DQN) agent.
The approach is tested in a constrained environment, where two robots move
without communication or identifiers. Despite a limited sampling frequency (1
Hz), the results show a significant decrease of the collisions number and a
stability improvement. The proposed method, which is computationally
inexpensive, appears particularly attractive for implementation on embedded
systems.

</details>


### [374] [FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis](https://arxiv.org/abs/2508.07950)
*Chen Shen,Wanqing Zhang,Kehan Li,Erwen Huang,Haitao Bi,Aiying Fan,Yiwen Shen,Hongmei Dong,Ji Zhang,Yuming Shao,Zengjia Liu,Xinshe Liu,Tao Li,Chunxia Yan,Shuanliang Fan,Di Wu,Jianhua Ma,Bin Cong,Zhenyuan Wang,Chunfeng Lian*

Main category: cs.AI

TL;DR: FEAT是一种基于LLM的多代理AI框架，旨在提高法医死因分析的自动化和标准化，尤其针对中国系统性问题设计。


<details>
  <summary>Details</summary>
Motivation: 解决法医死因确定中的系统性挑战，如人员短缺和诊断变异问题，在高负荷的基础设施中尤其明显。

Method: 使用FEAT框架，包括中央任务分解（Planner）、本地证据分析（Local Solvers）、记忆与反思模块（Memory & Reflection）、以及结论综合（Global Solver）。结合工具增强推理、分层检索生成、领域调整的LLM和人机协作反馈。

Result: 在多地区评估中，FEAT优于现有AI系统，专家验证表明其输出与人类专家表现相当，甚至在细微证据检测上表现更好。

Conclusion: FEAT将人工智能效率与人类监督结合，为法医领域提供首个基于LLM的解决方案，有望缓解容量不足并提升服务公平性。

Abstract: Forensic cause-of-death determination faces systemic challenges, including
workforce shortages and diagnostic variability, particularly in high-volume
systems like China's medicolegal infrastructure. We introduce FEAT (ForEnsic
AgenT), a multi-agent AI framework that automates and standardizes death
investigations through a domain-adapted large language model. FEAT's
application-oriented architecture integrates: (i) a central Planner for task
decomposition, (ii) specialized Local Solvers for evidence analysis, (iii) a
Memory & Reflection module for iterative refinement, and (iv) a Global Solver
for conclusion synthesis. The system employs tool-augmented reasoning,
hierarchical retrieval-augmented generation, forensic-tuned LLMs, and
human-in-the-loop feedback to ensure legal and medical validity. In evaluations
across diverse Chinese case cohorts, FEAT outperformed state-of-the-art AI
systems in both long-form autopsy analyses and concise cause-of-death
conclusions. It demonstrated robust generalization across six geographic
regions and achieved high expert concordance in blinded validations. Senior
pathologists validated FEAT's outputs as comparable to those of human experts,
with improved detection of subtle evidentiary nuances. To our knowledge, FEAT
is the first LLM-based AI agent system dedicated to forensic medicine, offering
scalable, consistent death certification while maintaining expert-level rigor.
By integrating AI efficiency with human oversight, this work could advance
equitable access to reliable medicolegal services while addressing critical
capacity constraints in forensic systems.

</details>


### [375] [Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths](https://arxiv.org/abs/2508.08001)
*Rui Yao,Qi Chai,Jinhai Yao,Siyuan Li,Junhao Chen,Qi Zhang,Hao Wang*

Main category: cs.AI

TL;DR: 本文提出了一个基于大型语言模型（LLM）的框架，用于解析和解读美联储使用的“Fedspeak”，并分类其潜在的货币政策立场，显著提升了政策立场分析的效果。


<details>
  <summary>Details</summary>
Motivation: 美联储使用的“Fedspeak”语言复杂且具有策略性，解析其隐含政策信号对金融预测、算法交易和数据驱动的政策分析具有重要意义。

Method: 通过引入基于货币政策传导机制的领域特定推理，增强Fedspeak文本的语义与语境表达。同时，提出了动态不确定性解码模块，用于评估模型预测的置信度，提升分类精度与模型可靠性。

Result: 实验表明，该框架在政策立场分析任务上达到了最新的性能水平。统计分析进一步显示感知不确定性与模型错误率之间存在显著正相关，验证了感知不确定性作为诊断性信号的有效性。

Conclusion: 研究证明了基于LLM的框架在解析Fedspeak及货币政策立场分类中的可行性与优越性，同时凸显了动态不确定性解码在提升模型可靠性方面的重要作用。

Abstract: "Fedspeak", the stylized and often nuanced language used by the U.S. Federal
Reserve, encodes implicit policy signals and strategic stances. The Federal
Open Market Committee strategically employs Fedspeak as a communication tool to
shape market expectations and influence both domestic and global economic
conditions. As such, automatically parsing and interpreting Fedspeak presents a
high-impact challenge, with significant implications for financial forecasting,
algorithmic trading, and data-driven policy analysis. In this paper, we propose
an LLM-based, uncertainty-aware framework for deciphering Fedspeak and
classifying its underlying monetary policy stance. Technically, to enrich the
semantic and contextual representation of Fedspeak texts, we incorporate
domain-specific reasoning grounded in the monetary policy transmission
mechanism. We further introduce a dynamic uncertainty decoding module to assess
the confidence of model predictions, thereby enhancing both classification
accuracy and model reliability. Experimental results demonstrate that our
framework achieves state-of-the-art performance on the policy stance analysis
task. Moreover, statistical analysis reveals a significant positive correlation
between perceptual uncertainty and model error rates, validating the
effectiveness of perceptual uncertainty as a diagnostic signal.

</details>


### [376] [Fitting Description Logic Ontologies to ABox and Query Examples](https://arxiv.org/abs/2508.08007)
*Maurice Funk,Marvin Grosser,Carsten Lutz*

Main category: cs.AI

TL;DR: 研究了一个与本体驱动的查询相关的拟合问题，通过正负例来寻找适合的本体知识。分析了不同描述逻辑和查询语言下该问题的计算复杂性。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于本体驱动查询中对合适本体知识的需求，需要能够区分正例和负例的本体来支持有效的推理。

Method: 采用描述逻辑（例如 $\mathcal{ALC}$ 和 $\mathcal{ALCI}$）作为本体语言，针对原子查询、结合查询和它们的联合分别分析拟合问题，研究了问题的可解性和复杂性。

Result: 针对不同的查询类型确定了解决拟合问题的有效条件和计算复杂性。其中，针对原子查询为 $\mathcal{CO}NP$ 复杂性，而结合查询和联合查询达到了 $2EXP\mathcal{TIME}$ 完全复杂性。

Conclusion: 论文明确了不同条件下本体拟合问题的解是否存在，以及这一过程中涉及的复杂性，为本体驱动查询的设计与应用提供了理论支持。

Abstract: We study a fitting problem inspired by ontology-mediated querying: given a
collection
  of positive and negative examples of
  the form $(\mathcal{A},q)$ with
  $\mathcal{A}$ an ABox and $q$ a Boolean query, we seek
  an ontology $\mathcal{O}$ that satisfies $\mathcal{A} \cup \mathcal{O} \vDash
q$ for all positive examples and $\mathcal{A} \cup \mathcal{O}\not\vDash q$ for
all negative examples.
  We consider the description logics $\mathcal{ALC}$ and $\mathcal{ALCI}$ as
ontology languages and
  a range of query languages that
  includes atomic queries (AQs), conjunctive queries (CQs), and unions thereof
(UCQs).
  For all of the resulting fitting problems,
  we provide
  effective characterizations and determine the computational complexity
  of deciding whether a fitting ontology exists. This problem turns out to be
${\small CO}NP$ for AQs and full CQs
  and $2E{\small XP}T{\small IME}$-complete for CQs and UCQs.
  These results hold for both $\mathcal{ALC}$ and $\mathcal{ALCI}$.

</details>


### [377] [AdaptFlow: Adaptive Workflow Optimization via Meta-Learning](https://arxiv.org/abs/2508.08053)
*Runchuan Zhu,Bowen Jiang,Lingrui Mei,Fangkai Yang,Lu Wang,Haoxiang Gao,Fengshuo Bai,Pu Zhao,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.AI

TL;DR: 提出了AdaptFlow，一个自然语言驱动的元学习框架，用于优化和自适应工作流，适应复杂任务，且效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM工作流方法存在适应性和扩展性不足的问题，人为设计和静态模板限制了其能力。

Method: AdaptFlow基于MAML模型，使用双层优化框架，通过动态语言反馈优化对子任务的工作流，同时升级初始化工作流以提高任务的推广能力。

Result: 在问题回答、代码生成和数学推理等基准测试中，AdaptFlow性能优于手动和自动设计的工作流，达到了状态艺术水平。

Conclusion: AdaptFlow展示了高度的任务适应性和推广性能，体现了其在复杂任务中自然语言驱动的工作流优化优势。

Abstract: Recent advances in large language models (LLMs) have sparked growing interest
in agentic workflows, which are structured sequences of LLM invocations
intended to solve complex tasks. However, existing approaches often rely on
static templates or manually designed workflows, which limit adaptability to
diverse tasks and hinder scalability. We propose AdaptFlow, a natural
language-based meta-learning framework inspired by model-agnostic meta-learning
(MAML). AdaptFlow learns a generalizable workflow initialization that enables
rapid subtask-level adaptation. It employs a bi-level optimization scheme: the
inner loop refines the workflow for a specific subtask using LLM-generated
feedback, while the outer loop updates the shared initialization to perform
well across tasks. This setup allows AdaptFlow to generalize effectively to
unseen tasks by adapting the initialized workflow through language-guided
modifications. Evaluated across question answering, code generation, and
mathematical reasoning benchmarks, AdaptFlow consistently outperforms both
manually crafted and automatically searched baselines, achieving
state-of-the-art results with strong generalization across tasks and models.
The source code and data are available at
https://github.com/microsoft/DKI_LLM/tree/AdaptFlow/AdaptFlow.

</details>


### [378] [FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence](https://arxiv.org/abs/2508.08075)
*Meishen He,Wenjun Ma,Jiao Wang,Huijun Yue,Xiaoma Fan*

Main category: cs.AI

TL;DR: 研究提出了一种名为全否定信念变换(FNBT)的新方法，用于Dempster-Shafer理论下的开放世界信息融合，解决了异构框架融合的问题并验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多局限于相同判别框架的证据融合，而现实中常由于数据孤岛效应导致异构数据源和模型，传统方法难以处理。

Method: 通过扩展框架和采用全否定机制，将异构框架的基本概率分配转为适用于现有组合规则的形式。提出了三大性质并予以理论证明。

Result: 方法在现实世界数据的模式分类任务中表现优异，并成功解决Zadeh反例，验证其实用性。

Conclusion: FNBT解决了异构框架下的信息融合问题，并具有理论和实际效果的双重支持，是一种有效的解决方案。

Abstract: The Dempster-Shafer theory of evidence has been widely applied in the field
of information fusion under uncertainty. Most existing research focuses on
combining evidence within the same frame of discernment. However, in real-world
scenarios, trained algorithms or data often originate from different regions or
organizations, where data silos are prevalent. As a result, using different
data sources or models to generate basic probability assignments may lead to
heterogeneous frames, for which traditional fusion methods often yield
unsatisfactory results. To address this challenge, this study proposes an
open-world information fusion method, termed Full Negation Belief
Transformation (FNBT), based on the Dempster-Shafer theory. More specially, a
criterion is introduced to determine whether a given fusion task belongs to the
open-world setting. Then, by extending the frames, the method can accommodate
elements from heterogeneous frames. Finally, a full negation mechanism is
employed to transform the mass functions, so that existing combination rules
can be applied to the transformed mass functions for such information fusion.
Theoretically, the proposed method satisfies three desirable properties, which
are formally proven: mass function invariance, heritability, and essential
conflict elimination. Empirically, FNBT demonstrates superior performance in
pattern classification tasks on real-world datasets and successfully resolves
Zadeh's counterexample, thereby validating its practical effectiveness.

</details>


### [379] [TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork](https://arxiv.org/abs/2508.08115)
*Pranav Pushkar Mishra,Mohammad Arvan,Mohan Zalake*

Main category: cs.AI

TL;DR: 本文提出TeamMedAgents，一种将基于证据的人类协作模型引入多智能体医疗系统的新方法，验证了人类协作的团队心理模型，并在8个医疗基准数据集上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 在基于证据的协作模型基础上，引入和验证人类协作心理模型到多智能体系统，以改进医疗领域的决策性能。

Method: 将人类协作中的"大五"心理模型中的六个核心团队组件（团队领导、相互表现监控、团队导向、共享心智模型、闭环沟通、相互信任）模块化并配置化，进行基准测试和消融研究。

Result: 在8个医疗基准数据集中，7个获得一致改进；消融研究提供关于协作模式对任务复杂性和领域要求的优化贡献的见解。

Conclusion: TeamMedAgents在关键决策领域的多智能体协作设计中提供了证据基础，并证明了人类协作理论模型在智能体间协作中的有效性。

Abstract: We present TeamMedAgents, a novel multi-agent approach that systematically
integrates evidence-based teamwork components from human-human collaboration
into medical decision-making with large language models (LLMs). Our approach
validates an organizational psychology teamwork model from human collaboration
to computational multi-agent medical systems by operationalizing six core
teamwork components derived from Salas et al.'s "Big Five" model: team
leadership, mutual performance monitoring, team orientation, shared mental
models, closed-loop communication, and mutual trust. We implement and evaluate
these components as modular, configurable mechanisms within an adaptive
collaboration architecture while assessing the effect of the number of agents
involved based on the task's requirements and domain. Systematic evaluation of
computational implementations of teamwork behaviors across eight medical
benchmarks (MedQA, MedMCQA, MMLU-Pro Medical, PubMedQA, DDXPlus, MedBullets,
Path-VQA, and PMC-VQA) demonstrates consistent improvements across 7 out of 8
evaluated datasets. Controlled ablation studies conducted on 50 questions per
configuration across 3 independent runs provide mechanistic insights into
individual component contributions, revealing optimal teamwork configurations
that vary by reasoning task complexity and domain-specific requirements. Our
ablation analyses reveal dataset-specific optimal teamwork configurations,
indicating that different medical reasoning modalities benefit from distinct
collaborative patterns. TeamMedAgents represents an advancement in
collaborative AI by providing a systematic translation of established teamwork
theories from human collaboration into agentic collaboration, establishing a
foundation for evidence-based multi-agent system design in critical
decision-making domains.

</details>


### [380] [BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks](https://arxiv.org/abs/2508.08127)
*Rui Miao,Yixin Liu,Yili Wang,Xu Shen,Yue Tan,Yiwei Dai,Shirui Pan,Xin Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为BlindGuard的无监督防御方法，通过捕捉多智能体系统中的多层交互模式，并在无攻击标签的情况下进行恶意行为检测。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法过于依赖标签恶意代理且不可操作，作者提出更实际且通用的无监督防御解决方案。

Method: 设计了一种分层代理编码器，结合方向性噪音注入与对比学习，仅利用正常代理行为进行检测模型训练。

Result: BlindGuard在检测不同类型攻击（包括提示注入、记忆中毒、工具攻击）和广泛通信模式的MAS中表现优异，超过有监督方法的泛化性能。

Conclusion: BlindGuard实现了无攻击标签和先验知识的恶意代理检测，为MAS的安全性提供了实践性和通用性的解决方案。

Abstract: The security of LLM-based multi-agent systems (MAS) is critically threatened
by propagation vulnerability, where malicious agents can distort collective
decision-making through inter-agent message interactions. While existing
supervised defense methods demonstrate promising performance, they may be
impractical in real-world scenarios due to their heavy reliance on labeled
malicious agents to train a supervised malicious detection model. To enable
practical and generalizable MAS defenses, in this paper, we propose BlindGuard,
an unsupervised defense method that learns without requiring any
attack-specific labels or prior knowledge of malicious behaviors. To this end,
we establish a hierarchical agent encoder to capture individual, neighborhood,
and global interaction patterns of each agent, providing a comprehensive
understanding for malicious agent detection. Meanwhile, we design a
corruption-guided detector that consists of directional noise injection and
contrastive learning, allowing effective detection model training solely on
normal agent behaviors. Extensive experiments show that BlindGuard effectively
detects diverse attack types (i.e., prompt injection, memory poisoning, and
tool attack) across MAS with various communication patterns while maintaining
superior generalizability compared to supervised baselines. The code is
available at: https://github.com/MR9812/BlindGuard.

</details>


### [381] [From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework](https://arxiv.org/abs/2508.08147)
*Yunkai Hu,Tianqiao Zhao,Meng Yue*

Main category: cs.AI

TL;DR: 本文提出一种新颖的基于大型语言模型(LLMs)的代理，它能够将自然语言描述的电力系统优化场景自动转换为紧凑、可供求解器使用的模型并生成相应的解。


<details>
  <summary>Details</summary>
Motivation: 直接依靠LLMs生成解决方案可能导致不符合约束或次优结果，因此需要利用LLMs发现数学兼容的公式并结合优化求解器提高效率和可靠性。

Method: 整合领域相关的提示和模式，与LLM结合，通过系统验证和迭代修复保证解的可行性，并返回求解器友好的模型和用户可理解的结果。

Result: 通过结合优化求解器和特定任务验证，显著提高了解的可靠性，并在单元承诺问题案例中生成近似最佳解决方案及相关成本。

Conclusion: 将AI与既有优化框架相结合，可有效连接高层次问题描述与可执行的数学模型，推动能源系统中更高效的决策。

Abstract: This paper introduces a novel Large Language Models (LLMs)-assisted agent
that automatically converts natural-language descriptions of power system
optimization scenarios into compact, solver-ready formulations and generates
corresponding solutions. In contrast to approaches that rely solely on LLM to
produce solutions directly, the proposed method focuses on discovering a
mathematically compatible formulation that can be efficiently solved by
off-the-shelf optimization solvers. Directly using LLMs to produce solutions
often leads to infeasible or suboptimal results, as these models lack the
numerical precision and constraint-handling capabilities of established
optimization solvers. The pipeline integrates a domain-aware prompt and schema
with an LLM, enforces feasibility through systematic validation and iterative
repair, and returns both solver-ready models and user-facing results. Using the
unit commitment problem as a representative case study, the agent produces
optimal or near-optimal schedules along with the associated objective costs.
Results demonstrate that coupling the solver with task-specific validation
significantly enhances solution reliability. This work shows that combining AI
with established optimization frameworks bridges high-level problem
descriptions and executable mathematical models, enabling more efficient
decision-making in energy systems

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [382] [Self-Organizing Survival Manifolds: A Theory for Unsupervised Discovery of Prognostic Structures in Biological Systems](https://arxiv.org/abs/2508.06539)
*Atahan Karagoz*

Main category: cs.LG

TL;DR: 提出了一种无需外部标注的新理论，自组织生存流形(SOSM)，通过几何曲率和流场解释生存动力学。


<details>
  <summary>Details</summary>
Motivation: 挑战传统依赖标签和固定变量的监督学习方法，尝试从几何和生物性质出发重新定义生存问题。

Method: 引入生存能量泛函，通过最小化测地曲率建立一种低曲率流形，推导离散和连续形式的目标，证明在生物学条件下的轨迹生成理论。

Result: 验证了在真实生物约束条件下，SOSM模型可以自发生成与生存有关的动力学轨迹，还揭示了与物理定律的深层关联。

Conclusion: 为生存建模提供了一种普适且不依赖标注的几何基础，将疾病与衰老等现象重新定义为流形结构的几何相变。

Abstract: Survival is traditionally modeled as a supervised learning task, reliant on
curated outcome labels and fixed covariates. This work rejects that premise. It
proposes that survival is not an externally annotated target but a geometric
consequence: an emergent property of the curvature and flow inherent in
biological state space. We develop a theory of Self-Organizing Survival
Manifolds (SOSM), in which survival-relevant dynamics arise from low-curvature
geodesic flows on latent manifolds shaped by internal biological constraints. A
survival energy functional based on geodesic curvature minimization is
introduced and shown to induce structures where prognosis aligns with geometric
flow stability. We derive discrete and continuous formulations of the objective
and prove theoretical results demonstrating the emergence and convergence of
survival-aligned trajectories under biologically plausible conditions. The
framework draws connections to thermodynamic efficiency, entropy flow, Ricci
curvature, and optimal transport, grounding survival modeling in physical law.
Health, disease, aging, and death are reframed as geometric phase transitions
in the manifold's structure. This theory offers a universal, label-free
foundation for modeling survival as a property of form, not annotation-bridging
machine learning, biophysics, and the geometry of life itself.

</details>


### [383] [Semi-Supervised Supply Chain Fraud Detection with Unsupervised Pre-Filtering](https://arxiv.org/abs/2508.06574)
*Fatemeh Moradi,Mehran Tarif,Mohammadhossein Homaei*

Main category: cs.LG

TL;DR: 本文提出一种两阶段学习框架，用于解决供应链欺诈检测中的数据复杂性和标注数据稀缺问题，在实验证明中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决全球供应链欺诈检测中的类别失衡和有限监督问题，提高方法在现实应用中的有效性。

Method: 第一阶段使用Isolation Forest进行无监督异常检测，减少数据分析范围；第二阶段则利用自训练SVM进行半监督学习，结合标注数据和高置信度伪标注数据进行预测优化。

Result: 在DataCo智能供应链数据集上，提出方法实现了F1得分0.817，假阳性率低于3.0%。

Conclusion: 该方法通过结合无监督预过滤和半监督优化，在现实供应链欺诈检测中实现了高效性与有效性，但仍需改进以应对概念漂移与与深度学习方法的比较。

Abstract: Detecting fraud in modern supply chains is a growing challenge, driven by the
complexity of global networks and the scarcity of labeled data. Traditional
detection methods often struggle with class imbalance and limited supervision,
reducing their effectiveness in real-world applications. This paper proposes a
novel two-phase learning framework to address these challenges. In the first
phase, the Isolation Forest algorithm performs unsupervised anomaly detection
to identify potential fraud cases and reduce the volume of data requiring
further analysis. In the second phase, a self-training Support Vector Machine
(SVM) refines the predictions using both labeled and high-confidence
pseudo-labeled samples, enabling robust semi-supervised learning. The proposed
method is evaluated on the DataCo Smart Supply Chain Dataset, a comprehensive
real-world supply chain dataset with fraud indicators. It achieves an F1-score
of 0.817 while maintaining a false positive rate below 3.0%. These results
demonstrate the effectiveness and efficiency of combining unsupervised
pre-filtering with semi-supervised refinement for supply chain fraud detection
under real-world constraints, though we acknowledge limitations regarding
concept drift and the need for comparison with deep learning approaches.

</details>


### [384] [GFlowNets for Learning Better Drug-Drug Interaction Representations](https://arxiv.org/abs/2508.06576)
*Azmine Toushik Wasi*

Main category: cs.LG

TL;DR: 本文提出一种结合生成流网络（GFlowNet）和变分图自动编码器（VGAE）的框架，以生成稀有类别的合成样本，改善药物之间交互的预测效果。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于药物相互作用中出现的类别间不平衡，尤其是数据中稀有但关键的交互被低估，限制了预测模型的效果。

Method: 使用生成流网络（GFlowNet）与变分图自动编码器（VGAE）的结合框架，为稀有类别生成合成样本，并生成有效的新药物对。

Result: 该方法改善了各类药物交互的预测表现，提高了模型对不同类别的可靠性。

Conclusion: 该框架能够有效解决类别失衡问题，为更有效的药物交互预测奠定基础，同时具备较好的临床应用前景。

Abstract: Drug-drug interactions pose a significant challenge in clinical pharmacology,
with severe class imbalance among interaction types limiting the effectiveness
of predictive models. Common interactions dominate datasets, while rare but
critical interactions remain underrepresented, leading to poor model
performance on infrequent cases. Existing methods often treat DDI prediction as
a binary problem, ignoring class-specific nuances and exacerbating bias toward
frequent interactions. To address this, we propose a framework combining
Generative Flow Networks (GFlowNet) with Variational Graph Autoencoders (VGAE)
to generate synthetic samples for rare classes, improving model balance and
generate effective and novel DDI pairs. Our approach enhances predictive
performance across interaction types, ensuring better clinical reliability.

</details>


### [385] [Hypergraph Neural Network with State Space Models for Node Classification](https://arxiv.org/abs/2508.06587)
*A. Quadir,M. Tanveer*

Main category: cs.LG

TL;DR: 本文提出了一种结合角色感知表示和状态空间模型的超图神经网络（HGMN），用于提升图神经网络（GNN）在节点分类任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 传统GNN主要关注节点之间的邻接关系，忽视了节点角色特征，这限制了模型的表达能力。现有的角色特征提取方法多为无监督，性能欠佳。因此需要一个新的方法来整合角色特征与邻接信息。

Method: 提出HGMN模型，利用超图构建技术加强相似角色节点之间的联系，并通过可学习的mamba transformer机制结合角色感知和邻接表示，结合残差网络减少过平滑问题，采用超图卷积层建模复杂依赖，同时提出两种基于节点度和邻域层次的超图构建方法。

Result: HGMN在一个新引入的数据集和四个基准数据集的节点分类任务中表现优越，相较现有最优GNN方法有显著性能提升。

Conclusion: HGMN能有效嵌入角色特征与邻接信息，显著增强节点表示能力，是一种强大且通用的图学习工具。

Abstract: In recent years, graph neural networks (GNNs) have gained significant
attention for node classification tasks on graph-structured data. However,
traditional GNNs primarily focus on adjacency relationships between nodes,
often overlooking the rich role-based characteristics that are crucial for
learning more expressive node representations. Existing methods for capturing
role-based features are largely unsupervised and fail to achieve optimal
performance in downstream tasks. To address these limitations, we propose a
novel hypergraph neural network with state space model (HGMN) that effectively
integrates role-aware representations into GNNs and the state space model. HGMN
utilizes hypergraph construction techniques to model higher-order relationships
and combines role-based and adjacency-based representations through a learnable
mamba transformer mechanism. By leveraging two distinct hypergraph construction
methods-based on node degree and neighborhood levels, it strengthens the
connections among nodes with similar roles, enhancing the model's
representational power. Additionally, the inclusion of hypergraph convolution
layers enables the model to capture complex dependencies within hypergraph
structures. To mitigate the over-smoothing problem inherent in deep GNNs, we
incorporate a residual network, ensuring improved stability and better feature
propagation across layers. Extensive experiments conducted on one newly
introduced dataset and four benchmark datasets demonstrate the superiority of
HGMN. The model achieves significant performance improvements on node
classification tasks compared to state-of-the-art GNN methods. These results
highlight HGMN's ability to provide enriched node representations by
effectively embedding role-based features alongside adjacency information,
making it a versatile and powerful tool for a variety of graph-based learning
applications.

</details>


### [386] [Symbolic Quantile Regression for the Interpretable Prediction of Conditional Quantiles](https://arxiv.org/abs/2508.08080)
*Cas Oude Hoekstra,Floris den Hengst*

Main category: cs.LG

TL;DR: 本文提出了符号分位回归（SQR）方法，以通过符号回归（SR）预测条件分位数，证明其具有透明性且性能优异。


<details>
  <summary>Details</summary>
Motivation: 当前符号回归方法可以生成可解释的平均值预测模型，但对如何用于目标变量分布中的其它点尚不明确。在高风险、关键安全领域，需要更全面地了解预测变量如何影响结果。

Method: 提出了符号分位回归（SQR）方法，通过符号回归预测条件分位数，并进行了广泛的评估和案例研究。

Result: SQR优于透明模型，与强黑箱基线表现相当，同时保持透明性，成功用于解释目标分布差异。

Conclusion: SQR适合用于预测条件分位数，同时有助于理解不同分位数下的特征影响。

Abstract: Symbolic Regression (SR) is a well-established framework for generating
interpretable or white-box predictive models. Although SR has been successfully
applied to create interpretable estimates of the average of the outcome, it is
currently not well understood how it can be used to estimate the relationship
between variables at other points in the distribution of the target variable.
Such estimates of e.g. the median or an extreme value provide a fuller picture
of how predictive variables affect the outcome and are necessary in
high-stakes, safety-critical application domains. This study introduces
Symbolic Quantile Regression (SQR), an approach to predict conditional
quantiles with SR. In an extensive evaluation, we find that SQR outperforms
transparent models and performs comparably to a strong black-box baseline
without compromising transparency. We also show how SQR can be used to explain
differences in the target distribution by comparing models that predict extreme
and central outcomes in an airline fuel usage case study. We conclude that SQR
is suitable for predicting conditional quantiles and understanding interesting
feature influences at varying quantiles.

</details>


### [387] [Graph is a Natural Regularization: Revisiting Vector Quantization for Graph Representation Learning](https://arxiv.org/abs/2508.06588)
*Zian Zhai,Fan Li,Xingyu Tan,Xiaoyang Wang,Wenjie Zhang*

Main category: cs.LG

TL;DR: 研究发现代码簿坍塌是图数据向量量化的一个常见问题，并提出RGVQ框架解决此问题。


<details>
  <summary>Details</summary>
Motivation: 探讨代码簿坍塌对图数据离散表示的负面影响并提出改进方案。

Method: 提出RGVQ框架，利用图拓扑和特征相似性作为正则化信号，结合Gumbel-Softmax重参数化和结构对比损失，提升代码簿利用率和标记多样性。

Result: 实验表明，RGVQ提升了代码簿的利用率，同时在多个下游任务中显著提高了性能。

Conclusion: RGVQ能够有效解决代码簿坍塌问题，增强图标记表示的表现力和可迁移性。

Abstract: Vector Quantization (VQ) has recently emerged as a promising approach for
learning discrete representations of graph-structured data. However, a
fundamental challenge, i.e., codebook collapse, remains underexplored in the
graph domain, significantly limiting the expressiveness and generalization of
graph tokens.In this paper, we present the first empirical study showing that
codebook collapse consistently occurs when applying VQ to graph data, even with
mitigation strategies proposed in vision or language domains. To understand why
graph VQ is particularly vulnerable to collapse, we provide a theoretical
analysis and identify two key factors: early assignment imbalances caused by
redundancy in graph features and structural patterns, and self-reinforcing
optimization loops in deterministic VQ. To address these issues, we propose
RGVQ, a novel framework that integrates graph topology and feature similarity
as explicit regularization signals to enhance codebook utilization and promote
token diversity. RGVQ introduces soft assignments via Gumbel-Softmax
reparameterization, ensuring that all codewords receive gradient updates. In
addition, RGVQ incorporates a structure-aware contrastive regularization to
penalize the token co-assignments among similar node pairs. Extensive
experiments demonstrate that RGVQ substantially improves codebook utilization
and consistently boosts the performance of state-of-the-art graph VQ backbones
across multiple downstream tasks, enabling more expressive and transferable
graph token representations.

</details>


### [388] [A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis](https://arxiv.org/abs/2508.06589)
*Xinglin Zhao,Yanwen Wang,Xiaobo Liu,Yanrong Hao,Rui Cao,Xin Wen*

Main category: cs.LG

TL;DR: 提出一种针对神经影像CAD系统的联邦学习框架，解决数据异质性和亚型混杂问题，显著提升诊断准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决小样本研究再现性低和大规模数据集中多亚型分类导致的异质性问题。

Method: 设计一个包含动态导航模块和元整合模块的联邦学习框架，用于路由和整合诊断信息。

Result: 经过超1300名MDD患者和1100名健康对照者的大型数据集测试，框架平均准确率达到74.06%，验证了其处理亚型异质性和增强泛化性能的有效性。

Conclusion: 通过应对数据异质性和亚型混杂，该框架为神经学和精神病学个性化医疗及临床决策提供了可靠工具。

Abstract: Computer-aided diagnosis (CAD) systems play a crucial role in analyzing
neuroimaging data for neurological and psychiatric disorders. However,
small-sample studies suffer from low reproducibility, while large-scale
datasets introduce confounding heterogeneity due to multiple disease subtypes
being labeled under a single category. To address these challenges, we propose
a novel federated learning framework tailored for neuroimaging CAD systems. Our
approach includes a dynamic navigation module that routes samples to the most
suitable local models based on latent subtype representations, and a
meta-integration module that combines predictions from heterogeneous local
models into a unified diagnostic output. We evaluated our framework using a
comprehensive dataset comprising fMRI data from over 1300 MDD patients and 1100
healthy controls across multiple study cohorts. Experimental results
demonstrate significant improvements in diagnostic accuracy and robustness
compared to traditional methods. Specifically, our framework achieved an
average accuracy of 74.06\% across all tested sites, showcasing its
effectiveness in handling subtype heterogeneity and enhancing model
generalizability. Ablation studies further confirmed the importance of both the
dynamic navigation and meta-integration modules in improving performance. By
addressing data heterogeneity and subtype confounding, our framework advances
reliable and reproducible neuroimaging CAD systems, offering significant
potential for personalized medicine and clinical decision-making in neurology
and psychiatry.

</details>


### [389] [Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials](https://arxiv.org/abs/2508.06591)
*Rachel K. Luu,Jingyu Deng,Mohammed Shahrudin Ibrahim,Nam-Joon Cho,Ming Dao,Subra Suresh,Markus J. Buehler*

Main category: cs.LG

TL;DR: 这篇论文介绍了一个将生成式AI与多学科文献结合的新框架，用于材料科学的实验设计，并成功验证了这一方法在开发新型生物启发材料上的可行性。


<details>
  <summary>Details</summary>
Motivation: 探讨将大型语言模型用于复杂多学科领域实验科学的新方法，通过结合不同领域知识推动材料科学的创新应用。

Method: 采用生成式AI工具（包括一个微调模型BioinspiredLLM、检索增强生成RAG、代理系统及分层采样策略）整合文献数据，从植物科学、生物仿生学和材料工程中提取结构-性能关系，生成并评价大批假设，并通过实验验证。

Result: 实验验证了通过LLM生成的程序、材料设计和机械预测的效果，最终制造出具有可调形态和抗剪强度的新型基于花粉的粘合剂材料。

Conclusion: 该研究展示了AI辅助的创新如何驱动实际材料设计，并为人机协作探索新材料设计提供了新的可能性。

Abstract: Large language models (LLMs) have reshaped the research landscape by enabling
new approaches to knowledge retrieval and creative ideation. Yet their
application in discipline-specific experimental science, particularly in highly
multi-disciplinary domains like materials science, remains limited. We present
a first-of-its-kind framework that integrates generative AI with literature
from hitherto-unconnected fields such as plant science, biomimetics, and
materials engineering to extract insights and design experiments for materials.
We focus on humidity-responsive systems such as pollen-based materials and
Rhapis excelsa (broadleaf lady palm) leaves, which exhibit self-actuation and
adaptive performance. Using a suite of AI tools, including a fine-tuned model
(BioinspiredLLM), Retrieval-Augmented Generation (RAG), agentic systems, and a
Hierarchical Sampling strategy, we extract structure-property relationships and
translate them into new classes of bioinspired materials. Structured inference
protocols generate and evaluate hundreds of hypotheses from a single query,
surfacing novel and experimentally tractable ideas. We validate our approach
through real-world implementation: LLM-generated procedures, materials designs,
and mechanical predictions were tested in the laboratory, culminating in the
fabrication of a novel pollen-based adhesive with tunable morphology and
measured shear strength, establishing a foundation for future plant-derived
adhesive design. This work demonstrates how AI-assisted ideation can drive
real-world materials design and enable effective human-AI collaboration.

</details>


### [390] [Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs](https://arxiv.org/abs/2508.06601)
*Kyle O'Brien,Stephen Casper,Quentin Anthony,Tomek Korbak,Robert Kirk,Xander Davies,Ishan Mishra,Geoffrey Irving,Yarin Gal,Stella Biderman*

Main category: cs.LG

TL;DR: 这篇论文探讨了通过过滤训练数据中的双重使用话题文本来增强开放权重AI系统的安全性。


<details>
  <summary>Details</summary>
Motivation: 解决开放权重AI系统易受篡改攻击的问题，寻求更有效的风险管理方法。

Method: 提出了一个多阶段的数据过滤管道，将双重用途相关文本从训练数据中筛除，并训练多个模型进行实验。

Result: 所提出的方法使模型对长达10,000步和3亿字节生物威胁文本的对抗性微调攻击有显著的抵抗力，比现有方法优越一倍以上。

Conclusion: 数据过滤是一种有前途的防御层，但必须结合其他方法来全面应对潜在风险。

Abstract: Open-weight AI systems offer unique benefits, including enhanced
transparency, open research, and decentralized access. However, they are
vulnerable to tampering attacks which can efficiently elicit harmful behaviors
by modifying weights or activations. Currently, there is not yet a robust
science of open-weight model risk management. Existing safety fine-tuning
methods and other post-training techniques have struggled to make LLMs
resistant to more than a few dozen steps of adversarial fine-tuning. In this
paper, we investigate whether filtering text about dual-use topics from
training data can prevent unwanted capabilities and serve as a more
tamper-resistant safeguard. We introduce a multi-stage pipeline for scalable
data filtering and show that it offers a tractable and effective method for
minimizing biothreat proxy knowledge in LLMs. We pretrain multiple
6.9B-parameter models from scratch and find that they exhibit substantial
resistance to adversarial fine-tuning attacks on up to 10,000 steps and 300M
tokens of biothreat-related text -- outperforming existing post-training
baselines by over an order of magnitude -- with no observed degradation to
unrelated capabilities. However, while filtered models lack internalized
dangerous knowledge, we find that they can still leverage such information when
it is provided in context (e.g., via search tool augmentation), demonstrating a
need for a defense-in-depth approach. Overall, these findings help to establish
pretraining data curation as a promising layer of defense for open-weight AI
systems.

</details>


### [391] [Local Diffusion Models and Phases of Data Distributions](https://arxiv.org/abs/2508.06614)
*Fangjun Hu,Guangkuo Liu,Yifan Zhang,Xun Gao*

Main category: cs.LG

TL;DR: 该研究提出通过引入数据分布的相位来改进扩散模型，并建议在远离相位转变点时使用本地神经网络，有效降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型忽略了数据的空间局部结构，导致计算代价高。研究者尝试通过分析数据分布的相位特性来优化模型架构。

Method: 定义数据分布相位，通过信息论手段界定相位转变特征，并使用数值实验验证局部去噪器在不同相位阶段的表现。

Result: 证明在远离相位转变点时可使用局部神经网络，高效计算得分函数，而全局网络仅需在相位转变区间短暂使用。

Conclusion: 该研究提出了基于物理启发的神经网络设计新方向，实现更简化及高效的扩散模型，同时为生成型AI研究扩展新领域。

Abstract: As a class of generative artificial intelligence frameworks inspired by
statistical physics, diffusion models have shown extraordinary performance in
synthesizing complicated data distributions through a denoising process
gradually guided by score functions. Real-life data, like images, is often
spatially structured in low-dimensional spaces. However, ordinary diffusion
models ignore this local structure and learn spatially global score functions,
which are often computationally expensive. In this work, we introduce a new
perspective on the phases of data distributions, which provides insight into
constructing local denoisers with reduced computational costs. We define two
distributions as belonging to the same data distribution phase if they can be
mutually connected via spatially local operations such as local denoisers.
Then, we show that the reverse denoising process consists of an early trivial
phase and a late data phase, sandwiching a rapid phase transition where local
denoisers must fail. To diagnose such phase transitions, we prove an
information-theoretic bound on the fidelity of local denoisers based on
conditional mutual information, and conduct numerical experiments in a
real-world dataset. This work suggests simpler and more efficient architectures
of diffusion models: far from the phase transition point, we can use small
local neural networks to compute the score function; global neural networks are
only necessary around the narrow time interval of phase transitions. This
result also opens up new directions for studying phases of data distributions,
the broader science of generative artificial intelligence, and guiding the
design of neural networks inspired by physics concepts.

</details>


### [392] [Generalizing Scaling Laws for Dense and Sparse Large Language Models](https://arxiv.org/abs/2508.06617)
*Md Arafat Hossain,Xingfu Wu,Valerie Taylor,Ali Jannesari*

Main category: cs.LG

TL;DR: 本研究提出了一种通用的扩展定律框架，适用于密集型和稀疏型大语言模型，并通过评估验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型规模和训练成本增长迅速，当前的扩展定律通常为特定架构设计，无法普适应用，研究动机在于解决这一问题。

Method: 重新审视现有扩展定律，提出了一种适用于密集型和稀疏型大语言模型的通用扩展定律，并对其有效性与现有方法进行比较。

Result: 实验结果表明，所提通用扩展定律在适用性和有效性上优于现有扩展定律。

Conclusion: 所提通用扩展定律能够为大语言模型的训练资源分配和规模预测提供更广泛的适用性，具有重要应用价值。

Abstract: Over the past few years, the size of language models has grown exponentially,
as has the computational cost to train these large models. This rapid growth
has motivated researchers to develop new techniques aimed at enhancing the
efficiency of the training process. Despite these advancements, optimally
predicting the model size or allocating optimal resources remains a challenge.
Several efforts have addressed the challenge by proposing different scaling
laws, but almost all of them are architecture-specific (dense or sparse). In
this work we revisit existing scaling laws and propose a generalized scaling
law to provide a unified framework that is applicable to both dense and sparse
large language models. We evaluate and compare our proposed scaling law with
existing scaling laws to demonstrate its effectiveness.

</details>


### [393] [Learning to Forget with Information Divergence Reweighted Objectives for Noisy Labels](https://arxiv.org/abs/2508.06622)
*Jeremiah Birrell,Reza Ebrahimi*

Main category: cs.LG

TL;DR: 我们提出了ANTIDOTE，一种在含噪标签环境下学习的新目标，通过信息散度邻域的松弛定义。


<details>
  <summary>Details</summary>
Motivation: 应对训练数据中标签噪声的问题，尤其是在对抗攻击或人为标注情况下的标签干扰。

Method: 通过凸对偶理论将目标转换为一种与标准交叉熵损失计算开销相当的对抗训练方法，并动态减小含噪标签样本的影响。

Result: 在不同程度的对称、非对称、人为标注和真实世界的标签噪声实验中，ANTIDOTE优于现有主流损失函数并保持接近标准交叉熵的时间复杂度。

Conclusion: ANTIDOTE是一种有效的含噪标签学习方法，其性能和可扩展性优于传统方法。

Abstract: We introduce ANTIDOTE, a new class of objectives for learning under noisy
labels which are defined in terms of a relaxation over an
information-divergence neighborhood. Using convex duality, we provide a
reformulation as an adversarial training method that has similar computational
cost to training with standard cross-entropy loss. We show that our approach
adaptively reduces the influence of the samples with noisy labels during
learning, exhibiting a behavior that is analogous to forgetting those samples.
ANTIDOTE is effective in practical environments where label noise is inherent
in the training data or where an adversary can alter the training labels.
Extensive empirical evaluations on different levels of symmetric, asymmetric,
human annotation, and real-world label noise show that ANTIDOTE outperforms
leading comparable losses in the field and enjoys a time complexity that is
very close to that of the standard cross entropy loss.

</details>


### [394] [Early Detection of Pancreatic Cancer Using Multimodal Learning on Electronic Health Record](https://arxiv.org/abs/2508.06627)
*Mosbah Aouad,Anirudh Choudhary,Awais Farooq,Steven Nevers,Lusine Demirkhanyan,Bhrandon Harris,Suguna Pappu,Christopher Gondi,Ravishankar Iyer*

Main category: cs.LG

TL;DR: 本文提出一种利用电子健康记录中长期诊断代码和实验室测量值的多模态方法，通过神经控制微分方程、预训练语言模型和交叉注意力机制提高PDAC的早期检测效果。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决胰腺导管腺癌（PDAC）因缺乏特异症状和可靠生物标志物而难以早期发现的问题。

Method: 提出一种基于多模态的计算模型，结合神经控制微分方程处理不规则实验室时间序列，利用预训练语言模型和递归网络分析诊断代码，并通过交叉注意力机制捕捉多模态交互信息。

Result: 在一个包括约4700名患者的真实数据集上测试，模型AUC性能比现有方法提高6.5%至15.5%，并识别出与PDAC风险相关的诊断代码和实验室指标，包括已知和新发现的生物标志物。

Conclusion: 该方法显著提升了PDAC的早期检测能力，为基于常规医疗数据的精准医疗提供了新思路。

Abstract: Pancreatic ductal adenocarcinoma (PDAC) is one of the deadliest cancers, and
early detection remains a major clinical challenge due to the absence of
specific symptoms and reliable biomarkers. In this work, we propose a new
multimodal approach that integrates longitudinal diagnosis code histories and
routinely collected laboratory measurements from electronic health records to
detect PDAC up to one year prior to clinical diagnosis. Our method combines
neural controlled differential equations to model irregular lab time series,
pretrained language models and recurrent networks to learn diagnosis code
trajectory representations, and cross-attention mechanisms to capture
interactions between the two modalities. We develop and evaluate our approach
on a real-world dataset of nearly 4,700 patients and achieve significant
improvements in AUC ranging from 6.5% to 15.5% over state-of-the-art methods.
Furthermore, our model identifies diagnosis codes and laboratory panels
associated with elevated PDAC risk, including both established and new
biomarkers. Our code is available at
https://github.com/MosbahAouad/EarlyPDAC-MML.

</details>


### [395] [Using Imperfect Synthetic Data in Downstream Inference Tasks](https://arxiv.org/abs/2508.06635)
*Yewon Byun,Shantanu Gupta,Zachary C. Lipton,Rachel Leah Childers,Bryan Wilder*

Main category: cs.LG

TL;DR: 研究探索如何将大语言模型生成的合成样本与真实数据有效结合并得出统计意义的结论，提出一种基于广义矩估计的新方法。


<details>
  <summary>Details</summary>
Motivation: 目前有很多研究使用大语言模型生成合成样本用于有限数据的场景，但缺乏有效的方法将这些样本与真实数据结合并确保统计有效性。

Method: 提出了一种基于广义矩方法的无超参数估计器，并分析其理论基础，解决数据结合的统计有效性问题。

Result: 发现合成数据和真实数据的矩残差之间的交互可以改善目标参数估计，并通过多种回归任务验证了估计器的优越性。

Conclusion: 该方法为大语言模型和真实数据的结合提供了一种有理论依据且有效的解决方案，并在计算社会科学中的实际应用中展现出显著的性能提升。

Abstract: Predictions and generations from large language models are increasingly being
explored as an aid to computational social science and human subject research
in limited data regimes. While previous technical work has explored the
potential to use model-predicted labels for unlabeled data in a principled
manner, there is increasing interest in using large language models to generate
entirely new synthetic samples (also termed as synthetic simulations), such as
in responses to surveys. However, it is not immediately clear by what means
practitioners can combine such data with real data and yet produce
statistically valid conclusions upon them. In this work, we introduce a new
estimator based on generalized method of moments, providing a
hyperparameter-free solution with strong theoretical guarantees to address the
challenge at hand. Surprisingly, we find that interactions between the moment
residuals of synthetic data and those of real data can improve estimates of the
target parameter. We empirically validate the finite-sample performance of our
estimator across different regression tasks in computational social science
applications, demonstrating large empirical gains.

</details>


### [396] [Segmented Confidence Sequences and Multi-Scale Adaptive Confidence Segments for Anomaly Detection in Nonstationary Time Series](https://arxiv.org/abs/2508.06638)
*Muyan Anna Li,Aditi Gautam*

Main category: cs.LG

TL;DR: 提出了两种新型自适应阈值框架（SCS和MACS），以解决时间序列数据中的异常检测挑战，并在实验中表现出显著改进。


<details>
  <summary>Details</summary>
Motivation: 随着时间序列数据在各领域的普及，传统的静态阈值在非平稳环境中容易失效，因此需要更灵活的检测方法。

Method: 引入了两种自适应阈值框架SCS和MACS，基于统计在线学习和分段原理，并保证在分布变化情况下的误报率控制。

Result: 在Wafer Manufacturing基准数据集实验中，相比传统方法，F1评分显著提高。

Conclusion: 统计学支持的自适应阈值能够可靠地检测各种实际环境中的异常现象，同时具备可解释性和实时性优势。

Abstract: As time series data become increasingly prevalent in domains such as
manufacturing, IT, and infrastructure monitoring, anomaly detection must adapt
to nonstationary environments where statistical properties shift over time.
Traditional static thresholds are easily rendered obsolete by regime shifts,
concept drift, or multi-scale changes. To address these challenges, we
introduce and empirically evaluate two novel adaptive thresholding frameworks:
Segmented Confidence Sequences (SCS) and Multi-Scale Adaptive Confidence
Segments (MACS). Both leverage statistical online learning and segmentation
principles for local, contextually sensitive adaptation, maintaining guarantees
on false alarm rates even under evolving distributions. Our experiments across
Wafer Manufacturing benchmark datasets show significant F1-score improvement
compared to traditional percentile and rolling quantile approaches. This work
demonstrates that robust, statistically principled adaptive thresholds enable
reliable, interpretable, and timely detection of diverse real-world anomalies.

</details>


### [397] [Fractal Language Modelling by Universal Sequence Maps (USM)](https://arxiv.org/abs/2508.06641)
*Jonas S Almeida,Daniel E Russ,Susana Vinga,Ines Duarte,Lee Mason,Praphulla Bhawsar,Aaron Ge,Arlindo Oliveira,Jeya Balaji Balasubramanian*

Main category: cs.LG

TL;DR: 提出了一种改进的通用序列映射 (USM) 方法，通过解析迭代过程中的偏差问题以实现更高效的数值嵌入。


<details>
  <summary>Details</summary>
Motivation: 当前的语言模型需要有效编码符号序列的方法，以保留上下文信息以供非线性建模使用。此研究旨在解决这一编码挑战。

Method: 利用USM结合两种混沌图游戏表示法（前向和后向）的迭代方式，并通过频域投影（FCGR）实现编码；进而计算数值位置信息和k-mer频率。

Result: 1) 完全协调了数值定位与序列身份的一致性；2) 揭示了USM作为一种高效数值处理方案的稳态收敛特性。

Conclusion: 改进后的USM方法为基因组序列等符号序列的嵌入提供了稳健且通用的解决方案，同时证明了其在任意复杂度字母表上的适用性。

Abstract: Motivation: With the advent of Language Models using Transformers,
popularized by ChatGPT, there is a renewed interest in exploring encoding
procedures that numerically represent symbolic sequences at multiple scales and
embedding dimensions. The challenge that encoding addresses is the need for
mechanisms that uniquely retain contextual information about the succession of
individual symbols, which can then be modeled by nonlinear formulations such as
neural networks.
  Context: Universal Sequence Maps(USM) are iterated functions that bijectively
encode symbolic sequences onto embedded numerical spaces. USM is composed of
two Chaos Game Representations (CGR), iterated forwardly and backwardly, that
can be projected into the frequency domain (FCGR). The corresponding USM
coordinates can be used to compute a Chebyshev distance metric as well as k-mer
frequencies, without having to recompute the embedded numeric coordinates, and,
paradoxically, allowing for non-integers values of k.
  Results: This report advances the bijective fractal encoding by Universal
Sequence Maps (USM) by resolving seeding biases affecting the iterated process.
The resolution had two results, the first expected, the second an intriguing
outcome: 1) full reconciliation of numeric positioning with sequence identity;
and 2) uncovering the nature of USM as an efficient numeric process converging
towards a steady state sequence embedding solution. We illustrate these results
for genomic sequences because of the convenience of a planar representation
defined by an alphabet with only 4 tokens (the 4 nucleotides). Nevertheless,
the application to alphabet of arbitrary cardinality was found to be
straightforward.

</details>


### [398] [Privacy-Preserving Tabular Synthetic Data Generation Using TabularARGN](https://arxiv.org/abs/2508.06647)
*Andrey Sidorenko,Paul Tiwald*

Main category: cs.LG

TL;DR: 本研究提出了一种专为生成高质量合成表格数据而设计的神经网络架构TabularARGN，并验证了其在数据相似性、机器学习效用和检测鲁棒性方面的优越性，同时通过详细的隐私评估验证了其隐私保护能力。


<details>
  <summary>Details</summary>
Motivation: 传统匿名化方法往往难以有效保护敏感数据的隐私，因此需要一种新方法生成安全的合成数据，同时保证数据质量。

Method: 提出了TabularARGN架构，采用基于离散化的自动回归方法，生成高质量合成数据，并进行了统计相似性、机器学习效用和隐私攻击等多方面评估。

Result: TabularARGN在数据保真度、隐私保护和计算效率方面表现出色，相比现有方法具有更好的隐私-效用平衡。

Conclusion: TabularARGN为生成高质量合成表格数据提供了一个有效的新方法，同时实现了隐私保护与数据实用性之间的良好平衡。

Abstract: Synthetic data generation has become essential for securely sharing and
analyzing sensitive data sets. Traditional anonymization techniques, however,
often fail to adequately preserve privacy. We introduce the Tabular
Auto-Regressive Generative Network (TabularARGN), a neural network architecture
specifically designed for generating high-quality synthetic tabular data. Using
a discretization-based auto-regressive approach, TabularARGN achieves high data
fidelity while remaining computationally efficient. We evaluate TabularARGN
against existing synthetic data generation methods, showing competitive results
in statistical similarity, machine learning utility, and detection robustness.
We further perform an in-depth privacy evaluation using systematic
membership-inference attacks, highlighting the robustness and effective
privacy-utility balance of our approach.

</details>


### [399] [In-Context Reinforcement Learning via Communicative World Models](https://arxiv.org/abs/2508.06659)
*Fernando Martinez-Lopez,Tao Li,Yingdong Lu,Juntao Chen*

Main category: cs.LG

TL;DR: 本文提出了一种名为CORAL的框架，通过分离潜在表示学习与控制来增强强化学习代理的上下文适应能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习代理通常无法在不更新参数的情况下泛化到新的任务和环境，这是因为它们的表示和策略对训练环境过度拟合。

Method: 本文将上下文强化学习（ICRL）视为一个双代理的通信问题，引入了信息代理（IA）和控制代理（CA）。IA被预训练为一个世界模型，生成简洁消息，而CA通过这些消息学习解决任务。

Result: 利用具有预训练IA的CA实验表明，在全新稀疏奖励环境下，代理提升了采样效率，并成功实现了零样本适应。

Conclusion: 学习一种可迁移的通信表示对于提升强化学习代理的泛化能力和稀疏奖励环境适应性非常有效。

Abstract: Reinforcement learning (RL) agents often struggle to generalize to new tasks
and contexts without updating their parameters, mainly because their learned
representations and policies are overfit to the specifics of their training
environments. To boost agents' in-context RL (ICRL) ability, this work
formulates ICRL as a two-agent emergent communication problem and introduces
CORAL (Communicative Representation for Adaptive RL), a framework that learns a
transferable communicative context by decoupling latent representation learning
from control. In CORAL, an Information Agent (IA) is pre-trained as a world
model on a diverse distribution of tasks. Its objective is not to maximize task
reward, but to build a world model and distill its understanding into concise
messages. The emergent communication protocol is shaped by a novel Causal
Influence Loss, which measures the effect that the message has on the next
action. During deployment, the previously trained IA serves as a fixed
contextualizer for a new Control Agent (CA), which learns to solve tasks by
interpreting the provided communicative context. Our experiments demonstrate
that this approach enables the CA to achieve significant gains in sample
efficiency and successfully perform zero-shot adaptation with the help of
pre-trained IA in entirely unseen sparse-reward environments, validating the
efficacy of learning a transferable communicative representation.

</details>


### [400] [Transferring Social Network Knowledge from Multiple GNN Teachers to Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.06663)
*Yuan-Hung Chao,Chia-Hsun Lu,Chih-Ya Shen*

Main category: cs.LG

TL;DR: 本文提出整合Kolmogorov-Arnold Networks（KANs）到现有的图神经网络（GNN），以提高其可扩展性和效率，并通过知识融合显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统图神经网络由于依赖于图连接性，存在可扩展性和计算效率的限制，为了解决这些问题，本文尝试引入具有非线性表达能力和高效推理能力的KANs。

Method: 将KANs与三种流行的GNN架构（GAT, SGC, APPNP）结合，提出新模型KGAT, KSGC, KAPPNP，并引入多教师知识融合框架，将多个KAN-GNN模型的知识蒸馏到图无关的KAN学生模型中。

Result: 实验结果表明，新模型在标准测试数据集上的节点分类精度有所提高，知识融合显著增强了学生模型的性能。

Conclusion: KANs可以提高GNN的表达能力，同时支持高效的无图推理，为改进GNN设计提供了新方向。

Abstract: Graph Neural Networks (GNNs) have shown strong performance on
graph-structured data, but their reliance on graph connectivity often limits
scalability and efficiency. Kolmogorov-Arnold Networks (KANs), a recent
architecture with learnable univariate functions, offer strong nonlinear
expressiveness and efficient inference. In this work, we integrate KANs into
three popular GNN architectures-GAT, SGC, and APPNP-resulting in three new
models: KGAT, KSGC, and KAPPNP. We further adopt a multi-teacher knowledge
amalgamation framework, where knowledge from multiple KAN-based GNNs is
distilled into a graph-independent KAN student model. Experiments on benchmark
datasets show that the proposed models improve node classification accuracy,
and the knowledge amalgamation approach significantly boosts student model
performance. Our findings highlight the potential of KANs for enhancing GNN
expressiveness and for enabling efficient, graph-free inference.

</details>


### [401] [Watermarking Kolmogorov-Arnold Networks for Emerging Networked Applications via Activation Perturbation](https://arxiv.org/abs/2508.06676)
*Chia-Hsun Lu,Guan-Jhih Wu,Ya-Chi Ho,Chih-Ya Shen*

Main category: cs.LG

TL;DR: 本文关注机器学习知识产权保护，提出基于离散余弦变换的激活水印方法（DCT-AW）用于Kolmogorov-Arnold网络的模型水印嵌入。


<details>
  <summary>Details</summary>
Motivation: 传统水印方法难以适应具有可学习激活函数的新型Kolmogorov-Arnold网络，急需开发适配性的水印技术以保障此种网络的知识产权保护。

Method: 提出了一种新的基于离散余弦变换的激活水印方法（DCT-AW），通过扰动激活函数的输出嵌入水印，以实现任务兼容性与独立性。

Result: 实验结果显示DCT-AW方法对模型性能影响较小，同时在应对微调、剪枝及剪枝后重训练等多种水印移除攻击时表现出高鲁棒性。

Conclusion: 方法有效地实现了针对Kolmogorov-Arnold网络的水印保护，同时对模型性能影响有限，具有较强的实际应用价值。

Abstract: With the increasing importance of protecting intellectual property in machine
learning, watermarking techniques have gained significant attention. As
advanced models are increasingly deployed in domains such as social network
analysis, the need for robust model protection becomes even more critical.
While existing watermarking methods have demonstrated effectiveness for
conventional deep neural networks, they often fail to adapt to the novel
architecture, Kolmogorov-Arnold Networks (KAN), which feature learnable
activation functions. KAN holds strong potential for modeling complex
relationships in network-structured data. However, their unique design also
introduces new challenges for watermarking. Therefore, we propose a novel
watermarking method, Discrete Cosine Transform-based Activation Watermarking
(DCT-AW), tailored for KAN. Leveraging the learnable activation functions of
KAN, our method embeds watermarks by perturbing activation outputs using
discrete cosine transform, ensuring compatibility with diverse tasks and
achieving task independence. Experimental results demonstrate that DCT-AW has a
small impact on model performance and provides superior robustness against
various watermark removal attacks, including fine-tuning, pruning, and
retraining after pruning.

</details>


### [402] [Stabilizing Federated Learning under Extreme Heterogeneity with HeteRo-Select](https://arxiv.org/abs/2508.06692)
*Md. Akmol Masud,Md Abrar Jahin,Mahmud Hasan*

Main category: cs.LG

TL;DR: 提出HeteRo-Select框架以解决联邦学习中因客户端数据多样性导致的训练不稳定问题，并证明其在传播效率和稳定性方面的优势。


<details>
  <summary>Details</summary>
Motivation: 联邦学习经常因为客户端数据的异质性导致训练不稳定，而现有的基于效用的客户端选择方法在训练后期精度下滑明显。

Method: 提出HeteRo-Select框架，通过一个逐步评分系统来综合考虑客户端的效用、公平性、更新速度与数据多样性，理论上证明在异质性较高的情况下聪明的客户端选择可以减少传播开销。

Result: 在CIFAR-10数据集上的实验验证了理论分析结果。HeteRo-Select在显著标签偏斜条件下（$α=0.1$）实现了峰值准确率74.75%，最终准确率72.76%，与Oort相比更加稳定，其最小稳定性下降为1.99%。

Conclusion: HeteRo-Select框架在理论基础和实验表现方面展现了其在处理真实场景异质性联邦学习问题中的可靠性。

Abstract: Federated Learning (FL) is a machine learning technique that often suffers
from training instability due to the diverse nature of client data. Although
utility-based client selection methods like Oort are used to converge by
prioritizing high-loss clients, they frequently experience significant drops in
accuracy during later stages of training. We propose a theoretical
HeteRo-Select framework designed to maintain high performance and ensure
long-term training stability. We provide a theoretical analysis showing that
when client data is very different (high heterogeneity), choosing a smart
subset of client participation can reduce communication more effectively
compared to full participation. Our HeteRo-Select method uses a clear,
step-by-step scoring system that considers client usefulness, fairness, update
speed, and data variety. It also shows convergence guarantees under strong
regularization. Our experimental results on the CIFAR-10 dataset under
significant label skew ($\alpha=0.1$) support the theoretical findings. The
HeteRo-Select method performs better than existing approaches in terms of peak
accuracy, final accuracy, and training stability. Specifically, HeteRo-Select
achieves a peak accuracy of $74.75\%$, a final accuracy of $72.76\%$, and a
minimal stability drop of $1.99\%$. In contrast, Oort records a lower peak
accuracy of $73.98\%$, a final accuracy of $71.25\%$, and a larger stability
drop of $2.73\%$. The theoretical foundations and empirical performance in our
study make HeteRo-Select a reliable solution for real-world heterogeneous FL
problems.

</details>


### [403] [CISO: Species Distribution Modeling Conditioned on Incomplete Species Observations](https://arxiv.org/abs/2508.06704)
*Hager Radi Abdelwahed,Mélisande Teng,Robin Zbinden,Laura Pollock,Hugo Larochelle,Devis Tuia,David Rolnick*

Main category: cs.LG

TL;DR: 文章提出了一种名为CISO的深度学习方法，用于在不完全物种观测条件下预测物种分布，通过融合环境变量和部分生物信息提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前物种分布模型主要基于环境变量，但忽视了生物物种间的相互作用，这种不足影响了预测的准确性。

Method: 提出了CISO方法，通过深度学习结合不完全物种观察数据和环境变量进行灵活预测，并用于植物、鸟类和蝴蝶数据集验证。

Result: 结果表明CISO方法在空间分离的测试集上预测性能优于传统方法，且结合多数据集的观测信息进一步提升性能。

Conclusion: CISO是一种潜力巨大的生态学工具，可利用不完整的生物信息进行多物种预测，并揭示跨种类的潜在相互作用。

Abstract: Species distribution models (SDMs) are widely used to predict species'
geographic distributions, serving as critical tools for ecological research and
conservation planning. Typically, SDMs relate species occurrences to
environmental variables representing abiotic factors, such as temperature,
precipitation, and soil properties. However, species distributions are also
strongly influenced by biotic interactions with other species, which are often
overlooked. While some methods partially address this limitation by
incorporating biotic interactions, they often assume symmetrical pairwise
relationships between species and require consistent co-occurrence data. In
practice, species observations are sparse, and the availability of information
about the presence or absence of other species varies significantly across
locations. To address these challenges, we propose CISO, a deep learning-based
method for species distribution modeling Conditioned on Incomplete Species
Observations. CISO enables predictions to be conditioned on a flexible number
of species observations alongside environmental variables, accommodating the
variability and incompleteness of available biotic data. We demonstrate our
approach using three datasets representing different species groups: sPlotOpen
for plants, SatBird for birds, and a new dataset, SatButterfly, for
butterflies. Our results show that including partial biotic information
improves predictive performance on spatially separate test sets. When
conditioned on a subset of species within the same dataset, CISO outperforms
alternative methods in predicting the distribution of the remaining species.
Furthermore, we show that combining observations from multiple datasets can
improve performance. CISO is a promising ecological tool, capable of
incorporating incomplete biotic information and identifying potential
interactions between species from disparate taxa.

</details>


### [404] [Analysis of Schedule-Free Nonconvex Optimization](https://arxiv.org/abs/2508.06743)
*Connor Brown*

Main category: cs.LG

TL;DR: 本文研究了一种无需预知迭代总步数的全局调度自适应方法（SF方法），提出了新的Lyapunov框架并推导出该方法在非凸优化下的表现界限。


<details>
  <summary>Details</summary>
Motivation: 一阶优化方法在大规模学习中广泛应用，但传统方法需要依赖于预知总步数$T$的步骤调整，而优化任务中这个$T$通常未知。因此需要找到一种独立于$T$的优化方法。

Method: 提出利用Lyapunov框架分析SF方法，并基于$L$-平滑性和下界特性，推导出关键的一步降解不等式，进一步推导出不同步骤设定下的收敛率。

Result: 证明了在非凸环境下SF方法的无视界收敛界（如常数步长+PR平均的$O(1/\log T)$等），并通过PEP实验验证这些收敛率，同时指出可能更严格的收敛界限。

Conclusion: 研究将SF方法的无视界性能保证扩展到平滑非凸优化领域，并为未来研究最优非凸收敛率提供了方向。

Abstract: First-order methods underpin most large-scale learning algorithms, yet their
classical convergence guarantees hinge on carefully scheduled step-sizes that
depend on the total horizon $T$, which is rarely known in advance. The
Schedule-Free (SF) method promises optimal performance with hyperparameters
that are independent of $T$ by interpolating between Polyak--Ruppert averaging
and momentum, but nonconvex analysis of SF has been limited or reliant on
strong global assumptions. We introduce a robust Lyapunov framework that, under
only $L$-smoothness and lower-boundedness, reduces SF analysis to a single-step
descent inequality. This yields horizon-agnostic bounds in the nonconvex
setting: $O(1/\log T)$ for constant step + PR averaging, $O(\log T/T)$ for a
linearly growing step-size, and a continuum of $O(T^{-(1-\alpha)})$ rates for
polynomial averaging. We complement these proofs with Performance Estimation
Problem (PEP) experiments that numerically validate our rates and suggest that
our $O(1/\log T)$ bound on the original nonconvex SF algorithm may tighten to
$O(1/T)$. Our work extends SF's horizon-free guarantees to smooth nonconvex
optimization and charts future directions for optimal nonconvex rates.

</details>


### [405] [Fed MobiLLM: Efficient Federated LLM Fine-Tuning over Heterogeneous Mobile Devices via Server Assisted Side-Tuning](https://arxiv.org/abs/2508.06765)
*Xingke Yang,Liang Li,Sicong Li,Liwei Guan,Hao Wang,Xiaoqi Qi,Jiang Liu,Xin Fu,Miao Pan*

Main category: cs.LG

TL;DR: 提出Fed MobiLLM方法，实现了在异质移动设备上高效的联合大语言模型微调。


<details>
  <summary>Details</summary>
Motivation: 解决现有联邦学习方法在移动设备上面临的计算和内存负担大、同步模型聚合协议慢等问题。

Method: 设计了一种新颖的服务端辅助联合旁路微调范式，并通过自适应层级特征对齐方法解决设备间模型异构性问题。

Result: 实现了95.2%以上的计算开销减小、93.2%的通信费用降低以及5.1倍的收敛速度提升，同时保持了强大的微调性能。

Conclusion: Fed MobiLLM有效适用于异质移动设备环境下的大语言模型微调，显著降低了设备负担。

Abstract: Collaboratively fine-tuning (FT) large language models (LLMs) over
heterogeneous mobile devices fosters immense potential applications of
personalized intelligence. However, such a vision faces critical system
challenges. Conventional federated LLM FT approaches place prohibitive
computational and memory burdens on mobile hardware, and their synchronous
model aggregation protocols stall for slower devices. In this paper, we propose
Fed MobiLLM, a novel design to facilitate efficient federated LLM FT across
mobile devices with diverse computing/communication speeds and local model
architectures. In particular, Fed MobiLLM implements a pioneering
server-assisted federated side-tuning paradigm. Briefly, mobile devices perform
lightweight forward propagation computations on local data using their frozen
pre-scaled backbone LLMs, and then upload selected intermediate activations.
The server trains a shared side-network independently, eliminating client-side
backpropagation and enabling asynchronous updates. To bridge model
heterogeneity across different devices, we introduce an adaptive layer-wise
feature alignment method, which ensures consistent representations for
collaboratively tuning a shared side network. Extensive experimental results
demonstrate that Fed MobiLLM can maintain robust fine-tuning performance while
achieving extremely low on-device memory, with at least 95.2% reduction in
computation overhead, 93.2% reduction in communication costs and 5.1x faster
convergence compared to existing methods, validating its efficacy for practical
LLM adaptation over heterogeneous mobile devices.

</details>


### [406] [PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems](https://arxiv.org/abs/2508.06767)
*Arman Dogru,R. Irem Bor-Yaliniz,Nimal Gamini Senarath*

Main category: cs.LG

TL;DR: 论文介绍了一种名为PANAMA的新算法，用于数字孪生（DT）生态系统中的多智能体路径规划，解决数据处理和网络中的动态问题。


<details>
  <summary>Details</summary>
Motivation: 目标是优化数字孪生生态系统中的数据共享和多智能体协调问题，提升机器人与自动化系统的性能。

Method: 提出一种基于多智能体强化学习(MARL)的算法PANAMA，采用优先级非对称性和联合训练分布式执行框架，为多智能体路径规划提供解决方案。

Result: PANAMA在路径规划的准确性、速度和可扩展性方面优于现有基准，并通过模拟展示了数据共享策略的优化。

Conclusion: PANAMA实现了网络感知决策和多智能体协调之间的结合，推动了数字孪生、无线网络与AI驱动自动化技术的融合。

Abstract: Digital Twins (DTs) are transforming industries through advanced data
processing and analysis, positioning the world of DTs, Digital World, as a
cornerstone of nextgeneration technologies including embodied AI. As robotics
and automated systems scale, efficient data-sharing frameworks and robust
algorithms become critical. We explore the pivotal role of data handling in
next-gen networks, focusing on dynamics between application and network
providers (AP/NP) in DT ecosystems. We introduce PANAMA, a novel algorithm with
Priority Asymmetry for Network Aware Multi-agent Reinforcement Learning (MARL)
based multi-agent path finding (MAPF). By adopting a Centralized Training with
Decentralized Execution (CTDE) framework and asynchronous actor-learner
architectures, PANAMA accelerates training while enabling autonomous task
execution by embodied AI. Our approach demonstrates superior pathfinding
performance in accuracy, speed, and scalability compared to existing
benchmarks. Through simulations, we highlight optimized data-sharing strategies
for scalable, automated systems, ensuring resilience in complex, real-world
environments. PANAMA bridges the gap between network-aware decision-making and
robust multi-agent coordination, advancing the synergy between DTs, wireless
networks, and AI-driven automation.

</details>


### [407] [Zero-Direction Probing: A Linear-Algebraic Framework for Deep Analysis of Large-Language-Model Drift](https://arxiv.org/abs/2508.06776)
*Amit Pandey*

Main category: cs.LG

TL;DR: 本论文提出了一种名为Zero-Direction Probing (ZDP)的理论框架，可在无需任务标签或输出评估的情况下，通过Transformer激活的零方向检测模型漂移。


<details>
  <summary>Details</summary>
Motivation: 当前神经网络的模型漂移问题挑战了其在长期运行中的稳定性，而本研究试图通过理论手段来提供一种无监督的检测方法。

Method: 通过构建零方向探测框架 (ZDP)，提出了关键定理如方差泄露定理、Fisher零方向保持以及SNL度量，并提供了一系列数学证明和非渐近界限。

Result: 研究表明，监控层激活的零空间及其Fisher几何属性，可以提供代表性变化的具体可测试性保证。

Conclusion: 本文为无监督检测模型漂移提供了理论支持，通过SNL度量和相关定理保障，可以帮助理解和监控深度学习模型的表示变化。

Abstract: We present Zero-Direction Probing (ZDP), a theory-only framework for
detecting model drift from null directions of transformer activations without
task labels or output evaluations. Under assumptions A1--A6, we prove: (i) the
Variance--Leak Theorem, (ii) Fisher Null-Conservation, (iii) a Rank--Leak bound
for low-rank updates, and (iv) a logarithmic-regret guarantee for online
null-space trackers. We derive a Spectral Null-Leakage (SNL) metric with
non-asymptotic tail bounds and a concentration inequality, yielding a-priori
thresholds for drift under a Gaussian null model. These results show that
monitoring right/left null spaces of layer activations and their Fisher
geometry provides concrete, testable guarantees on representational change.

</details>


### [408] [PROPS: Progressively Private Self-alignment of Large Language Models](https://arxiv.org/abs/2508.06783)
*Noel Teku,Fengwei Tian,Payel Bhattacharjee,Souradip Chakraborty,Amrit Singh Bedi,Ravi Tandon*

Main category: cs.LG

TL;DR: PROPS 提供了一种新方法，在保持对首选项标签隐私的同时更高效地对齐大型语言模型，更优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决通过人类反馈对语言模型进行对齐时可能泄露标注者个人隐私的问题。

Method: 提出了一种名为 PROPS 的分阶段隐私对齐框架，私密对齐模型在不同阶段以渐进方式补充后续对齐数据。

Result: PROPS 在多个模型和数据集上的性能优于现有方法，同等隐私预算下胜率可达 DP-SGD 的 3 倍，RR 的 2.5 倍。

Conclusion: PROPS 能在提供高隐私的同时显著提升模型对齐效果，为首选项隐私保护提供了新的实践方向。

Abstract: Alignment is a key step in developing Large Language Models (LLMs) using
human feedback to ensure adherence to human values and societal norms.
Dependence on human feedback raises privacy concerns about how much a labeler's
preferences may reveal about their personal values, beliefs, and personality
traits. Existing approaches, such as Differentially Private SGD (DP-SGD),
provide rigorous privacy guarantees by privatizing gradients during fine-tuning
and alignment but can provide more privacy than necessary as human preferences
are tied only to labels of (prompt, response) pairs and can degrade model
utility. This work focuses on LLM alignment with preference-level privacy,
which preserves the privacy of preference labels provided by humans. We propose
PROPS (PROgressively Private Self-alignment), a multi-stage privacy preserving
alignment framework where privately aligned models in previous stages can serve
as labelers for supplementing training data in the subsequent stages of
alignment. We present theoretical guarantees for PROPS as well as comprehensive
validation using multiple models (Pythia and GPT) and datasets (AlpacaEval,
Anthropic HH-RLHF, truthy-dpo-v0.1) to demonstrate the utility of PROPS over
existing methods while still providing high privacy. For the same privacy
budget, alignment via PROPS can achieve up to 3x higher win-rates compared to
DP-SGD, and 2.5x higher win-rates compared to Randomized Response (RR) based
alignment.

</details>


### [409] [Mode-Aware Non-Linear Tucker Autoencoder for Tensor-based Unsupervised Learning](https://arxiv.org/abs/2508.06784)
*Junjing Zheng,Chengliang Song,Weidong Jiang,Xinyu Zhang*

Main category: cs.LG

TL;DR: 提出了一种名为MA-NTAE的非线性Tensor分解模型，能够有效处理高阶高维张量的自监督学习问题，实验表明在压缩与聚类任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有AE模型在处理高维张量时面临的维度灾难、计算开销大以及非线性建模能力弱等问题。

Method: 提出了一种非线性Tucker分解框架MA-NTAE，采用Pick-and-Unfold策略，通过逐层展开、编码和复原的方式实现张量的灵活建模，同时优化计算复杂度。

Result: 在高阶高维张量的压缩和聚类任务中，MA-NTAE展现出优于标准AE和现有张量网络的性能，尤其在更高阶与更高维数据上表现更突出。

Conclusion: MA-NTAE有效结合了张量的结构先验与非线性建模能力，为解决高阶高维张量问题提供了新思路。

Abstract: High-dimensional data, particularly in the form of high-order tensors,
presents a major challenge in self-supervised learning. While MLP-based
autoencoders (AE) are commonly employed, their dependence on flattening
operations exacerbates the curse of dimensionality, leading to excessively
large model sizes, high computational overhead, and challenging optimization
for deep structural feature capture. Although existing tensor networks
alleviate computational burdens through tensor decomposition techniques, most
exhibit limited capability in learning non-linear relationships. To overcome
these limitations, we introduce the Mode-Aware Non-linear Tucker Autoencoder
(MA-NTAE). MA-NTAE generalized classical Tucker decomposition to a non-linear
framework and employs a Pick-and-Unfold strategy, facilitating flexible
per-mode encoding of high-order tensors via recursive unfold-encode-fold
operations, effectively integrating tensor structural priors. Notably, MA-NTAE
exhibits linear growth in computational complexity with tensor order and
proportional growth with mode dimensions. Extensive experiments demonstrate
MA-NTAE's performance advantages over standard AE and current tensor networks
in compression and clustering tasks, which become increasingly pronounced for
higher-order, higher-dimensional tensors.

</details>


### [410] [Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities](https://arxiv.org/abs/2508.06800)
*Rui Liu,Haolin Zuo,Zheng Lian,Hongyu Yuan,Qi Fan*

Main category: cs.LG

TL;DR: 本文提出了一种名为HARDY-MER的新框架，应用于多模态情感识别（MER）中的缺失模态问题。通过动态课程学习和样本难度评估，提高了模型对困难样本的处理能力并提升了整体性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法无法处理样本在模态重建难易程度上的差异，因此表现有限。本文研究如何针对性地处理困难样本以提高MER模型的整体性能。

Method: 提出了HARDY-MER框架，包括两个关键步骤：1. 使用多视角难度评估机制，从直接难度（重建误差）和间接难度（跨模态互信息）量化硬样本；2. 使用基于检索的动态课程学习策略，通过检索语义信息相似的样本，在训练期间平衡易与难样本的学习分配。

Result: 多项实验表明，HARDY-MER在基准数据集上显著优于现有方法，特别是在模态缺失的情况下表现出色。

Conclusion: HARDY-MER通过集成难度感知和动态课程学习，显著提升了MER模型处理困境样本的能力，为处理缺失模态问题提供了新思路。

Abstract: Missing modalities have recently emerged as a critical research direction in
multimodal emotion recognition (MER). Conventional approaches typically address
this issue through missing modality reconstruction. However, these methods fail
to account for variations in reconstruction difficulty across different
samples, consequently limiting the model's ability to handle hard samples
effectively. To overcome this limitation, we propose a novel Hardness-Aware
Dynamic Curriculum Learning framework, termed HARDY-MER. Our framework operates
in two key stages: first, it estimates the hardness level of each sample, and
second, it strategically emphasizes hard samples during training to enhance
model performance on these challenging instances. Specifically, we first
introduce a Multi-view Hardness Evaluation mechanism that quantifies
reconstruction difficulty by considering both Direct Hardness (modality
reconstruction errors) and Indirect Hardness (cross-modal mutual information).
Meanwhile, we introduce a Retrieval-based Dynamic Curriculum Learning strategy
that dynamically adjusts the training curriculum by retrieving samples with
similar semantic information and balancing the learning focus between easy and
hard instances. Extensive experiments on benchmark datasets demonstrate that
HARDY-MER consistently outperforms existing methods in missing-modality
scenarios. Our code will be made publicly available at
https://github.com/HARDY-MER/HARDY-MER.

</details>


### [411] [Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation](https://arxiv.org/abs/2508.06806)
*Xiao Huang,Xu Liu,Enze Zhang,Tong Yu,Shuai Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的数据增强方法，名为Classifier-Free Diffusion Generation (CFDG)，通过改进生成数据质量和重新加权策略，提升了离线到在线强化学习的性能。


<details>
  <summary>Details</summary>
Motivation: 离线到在线强化学习需要在线精调离线预训练的策略，但在线数据分布与离线数据间的差距限制了性能，因此需要改进数据分布的统一性。

Method: CFDG方法利用无分类器指导的扩散生成技术提升离线和在线数据的生成质量，同时通过重新加权策略使生成的数据分布更贴近在线数据。

Result: CFDG在多个D4RL基准测试中表现出优越性，在结合当前主流算法（如IQL、PEX、APL）时，实现了15%的平均性能提升。

Conclusion: CFDG方法有效改善了离线到在线强化学习算法的表现，并且可以无缝整合到现有算法中，展现了其通用性强和性能提升显著的优点。

Abstract: Offline-to-online Reinforcement Learning (O2O RL) aims to perform online
fine-tuning on an offline pre-trained policy to minimize costly online
interactions. Existing work used offline datasets to generate data that conform
to the online data distribution for data augmentation. However, generated data
still exhibits a gap with the online data, limiting overall performance. To
address this, we propose a new data augmentation approach, Classifier-Free
Diffusion Generation (CFDG). Without introducing additional classifier training
overhead, CFDG leverages classifier-free guidance diffusion to significantly
enhance the generation quality of offline and online data with different
distributions. Additionally, it employs a reweighting method to enable more
generated data to align with the online data, enhancing performance while
maintaining the agent's stability. Experimental results show that CFDG
outperforms replaying the two data types or using a standard diffusion model to
generate new data. Our method is versatile and can be integrated with existing
offline-to-online RL algorithms. By implementing CFDG to popular methods IQL,
PEX and APL, we achieve a notable 15% average improvement in empirical
performance on the D4RL benchmark such as MuJoCo and AntMaze.

</details>


### [412] [Technical Report: Full-Stack Fine-Tuning for the Q Programming Language](https://arxiv.org/abs/2508.06813)
*Brendan R. Hogan,Will Brown,Adel Boyarsky,Anderson Schneider,Yuriy Nevmyvaka*

Main category: cs.LG

TL;DR: 该论文提出了一种开源方法，将大型语言模型（LLMs）适配至在互联网上相对稀少代表的Q编程语言，并在相关基准测试中显著超越了当前的前沿模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在互联网不常见任务中的表现有限，特别是针对小众编程语言和私有领域的应用。研究试图解决将LLMs应用于Q编程语言的挑战，该语言主要用于量化金融领域，有别于主流编程语言。

Method: 该研究发布了一个新的Q语言基准数据集，并对主要模型进行测试。此外，通过预训练、监督微调和强化学习对Qwen-2.5系列模型进行训练，模型参数从1.5B到32B。

Result: 优化后模型的最优版本在Q基准测试中达到59%的pass@1准确率，比表现最好的前沿模型Claude Opus-4高出29.5%。即便是最小1.5B模型也优于GPT-4.1。

Conclusion: 研究中提出的方法具备通用性，可以扩展到其他任务中，尤其是需要依赖软性或主观信号进行评估的领域。同时公开模型、代码以及数据。

Abstract: Even though large language models are becoming increasingly capable, it is
still unreasonable to expect them to excel at tasks that are under-represented
on the Internet. Leveraging LLMs for specialized applications, particularly in
niche programming languages and private domains, remains challenging and
largely unsolved. In this work, we address this gap by presenting a
comprehensive, open-source approach for adapting LLMs to the Q programming
language, a popular tool in quantitative finance that is much less present on
the Internet compared to Python, C, Java, and other ``mainstream" languages and
is therefore not a strong suit of general-purpose AI models. We introduce a new
Leetcode style evaluation dataset for Q, benchmark major frontier models on the
dataset, then do pretraining, supervised fine tuning, and reinforcement
learning to train a suite of reasoning and non-reasoning models based on the
Qwen-2.5 series, spanning five parameter sizes (1.5B, 3B, 7B, 14B, 32B). Our
best model achieves a pass@1 accuracy of 59 percent on our Q benchmark,
surpassing the best-performing frontier model, Claude Opus-4 by 29.5 percent.
Additionally, all models, even our 1.5B model, outperform GPT-4.1 on this task.
In addition to releasing models, code, and data, we provide a detailed
blueprint for dataset construction, model pretraining, supervised fine-tuning,
and reinforcement learning. Our methodology is broadly applicable, and we
discuss how these techniques can be extended to other tasks, including those
where evaluation may rely on soft or subjective signals.

</details>


### [413] [Who's the Evil Twin? Differential Auditing for Undesired Behavior](https://arxiv.org/abs/2508.06827)
*Ishwar Balappanawar,Venkata Hasith Vattikuti,Greta Kintzley,Ronan Azimi-Mancel,Satvik Golechha*

Main category: cs.LG

TL;DR: 该研究提出一种利用对抗游戏方式检测神经网络中隐藏行为的框架，通过两队模拟对抗来分析检测策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前神经网络中隐藏行为的检测由于缺乏先验知识和潜在的对抗性混淆而面临重大挑战。

Method: 利用对抗游戏框架，由红队训练出一个仅含良性数据的模型和一个含有隐藏有害行为的模型，蓝队则在非常有限的信息下尝试识别出有害模型。实验中采用了多种蓝队策略，包括高斯噪声分析、模型微分、集成梯度和对抗性攻击等方法。

Result: 结果表明，在红队提供提示的情况下，对抗性攻击方法可以实现100%的正确检测率，而其他策略的性能则存在较大差异。对于LLM模型的审计，研究发现标准方法需要结合一定的分布提示才能有效揭示偏差行为。

Conclusion: 研究认为，基于提示的审计方法在检测隐藏行为上表现较为出色，且公开了相关审计游戏及模型与数据，希望这些发现能帮助设计更好的审计机制。

Abstract: Detecting hidden behaviors in neural networks poses a significant challenge
due to minimal prior knowledge and potential adversarial obfuscation. We
explore this problem by framing detection as an adversarial game between two
teams: the red team trains two similar models, one trained solely on benign
data and the other trained on data containing hidden harmful behavior, with the
performance of both being nearly indistinguishable on the benign dataset. The
blue team, with limited to no information about the harmful behaviour, tries to
identify the compromised model. We experiment using CNNs and try various blue
team strategies, including Gaussian noise analysis, model diffing, integrated
gradients, and adversarial attacks under different levels of hints provided by
the red team. Results show high accuracy for adversarial-attack-based methods
(100\% correct prediction, using hints), which is very promising, whilst the
other techniques yield more varied performance. During our LLM-focused rounds,
we find that there are not many parallel methods that we could apply from our
study with CNNs. Instead, we find that effective LLM auditing methods require
some hints about the undesired distribution, which can then used in standard
black-box and open-weight methods to probe the models further and reveal their
misalignment. We open-source our auditing games (with the model and data) and
hope that our findings contribute to designing better audits.

</details>


### [414] [Sparsity-Driven Plasticity in Multi-Task Reinforcement Learning](https://arxiv.org/abs/2508.06871)
*Aleksandar Todorov,Juan Cardenas-Cartagena,Rafael F. Cunha,Marco Zullich,Matthia Sabatelli*

Main category: cs.LG

TL;DR: 该论文探讨了多任务强化学习（MTRL）中因训练的适应性降低（即可塑性丧失）所带来的挑战，提出了通过稀疏化方法，如逐渐幅度剪枝（GMP）和稀疏进化训练（SET）来增强可塑性的解决方案，并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 在多任务强化学习中，由于任务的多样性和潜在冲突，模型需要更高的表示灵活性，但可塑性丧失阻碍了这一目标。这促使研究如何提升可塑性以改进模型表现。

Method: 研究使用了两种稀疏化方法，即逐渐幅度剪枝（GMP）与稀疏进化训练（SET），并将其应用于共享骨干网络、专家混合模型、正交专家混合模型等MTRL架构上进行评估，同时与密集基线和其他正则化方法对比。

Result: 结果表明，使用GMP和SET可以有效缓解可塑性退化的关键指标（如神经元休眠和表示崩溃），通常能提高多任务表现，在一些情况下甚至优于密集模型和明确的可塑性干预方法。

Conclusion: 动态稀疏化是一种强大但需视情境而定的工具，能在提升多任务强化学习系统适应性方面发挥作用。

Abstract: Plasticity loss, a diminishing capacity to adapt as training progresses, is a
critical challenge in deep reinforcement learning. We examine this issue in
multi-task reinforcement learning (MTRL), where higher representational
flexibility is crucial for managing diverse and potentially conflicting task
demands. We systematically explore how sparsification methods, particularly
Gradual Magnitude Pruning (GMP) and Sparse Evolutionary Training (SET), enhance
plasticity and consequently improve performance in MTRL agents. We evaluate
these approaches across distinct MTRL architectures (shared backbone, Mixture
of Experts, Mixture of Orthogonal Experts) on standardized MTRL benchmarks,
comparing against dense baselines, and a comprehensive range of alternative
plasticity-inducing or regularization methods. Our results demonstrate that
both GMP and SET effectively mitigate key indicators of plasticity degradation,
such as neuron dormancy and representational collapse. These plasticity
improvements often correlate with enhanced multi-task performance, with sparse
agents frequently outperforming dense counterparts and achieving competitive
results against explicit plasticity interventions. Our findings offer insights
into the interplay between plasticity, network sparsity, and MTRL designs,
highlighting dynamic sparsification as a robust but context-sensitive tool for
developing more adaptable MTRL systems.

</details>


### [415] [Conformal Prediction and Trustworthy AI](https://arxiv.org/abs/2508.06885)
*Anthony Bellotti,Xindi Zhao*

Main category: cs.LG

TL;DR: 讨论保形预测在可信AI中的潜力，特别是在AI治理和偏差减缓方面。


<details>
  <summary>Details</summary>
Motivation: 探索保形预测在促进可信AI（Trustworthy AI）发展中的作用，尤其是能否解决广义风险和相关治理问题。

Method: 对保形预测的应用进行回顾与实验，评估其在偏差识别与减轻和校准预测方面的表现。

Result: 展示保形预测不仅可以提供有效验证，还能在偏差管理和治理中具有重要作用。

Conclusion: 保形预测在可信AI领域具有很大潜力，尤其是在提高可校准性及解决偏差等挑战中的应用。

Abstract: Conformal predictors are machine learning algorithms developed in the 1990's
by Gammerman, Vovk, and their research team, to provide set predictions with
guaranteed confidence level. Over recent years, they have grown in popularity
and have become a mainstream methodology for uncertainty quantification in the
machine learning community. From its beginning, there was an understanding that
they enable reliable machine learning with well-calibrated uncertainty
quantification. This makes them extremely beneficial for developing trustworthy
AI, a topic that has also risen in interest over the past few years, in both
the AI community and society more widely. In this article, we review the
potential for conformal prediction to contribute to trustworthy AI beyond its
marginal validity property, addressing problems such as generalization risk and
AI governance. Experiments and examples are also provided to demonstrate its
use as a well-calibrated predictor and for bias identification and mitigation.

</details>


### [416] [QuiZSF: An efficient data-model interaction framework for zero-shot time-series forecasting](https://arxiv.org/abs/2508.06915)
*Shichao Ma,Zhengyang Zhou,Qihe Huang,Binwu Wang,Kuo Yang,Huan Li,Yang Wang*

Main category: cs.LG

TL;DR: 提出了一种名为QuiZSF的框架，通过引入RAG技术增强时间序列预训练模型的零样本预测能力，在多种预测场景中表现出众。


<details>
  <summary>Details</summary>
Motivation: 当前的时间序列预测模型在数据稀缺环境（如跨领域或极端条件下的预测）中效果有限，而RAG技术则提供了一种动态注入外部知识的潜力，可助力解决这一问题。

Method: 提出一种轻量级和模块化的框架QuiZSF，包括：构建层次化的时间序列存储和检索树结构ChronoRAG Base（CRB），开发多粒度系列交互学习器（MSIL），以及设计双分支模型协作器（MCC），用于对非LLM和LLM两种时间序列预训练模型的调整和知识对齐。

Result: 实验表明，与现有方法相比，使用非LLM及LLM为基模型的QuiZSF分别在75%和87.5%的预测场景下达到Top1性能，同时具备高效的存储及推理特性。

Conclusion: QuiZSF成功整合了RAG技术与时间序列预测模型，在零样本时间序列预测任务中取得了显著的性能提升，并体现了实际应用价值。

Abstract: Time series forecasting has become increasingly important to empower diverse
applications with streaming data. Zero-shot time-series forecasting (ZSF),
particularly valuable in data-scarce scenarios, such as domain transfer or
forecasting under extreme conditions, is difficult for traditional models to
deal with. While time series pre-trained models (TSPMs) have demonstrated
strong performance in ZSF, they often lack mechanisms to dynamically
incorporate external knowledge. Fortunately, emerging retrieval-augmented
generation (RAG) offers a promising path for injecting such knowledge on
demand, yet they are rarely integrated with TSPMs. To leverage the strengths of
both worlds, we introduce RAG into TSPMs to enhance zero-shot time series
forecasting. In this paper, we propose QuiZSF (Quick Zero-Shot Time Series
Forecaster), a lightweight and modular framework that couples efficient
retrieval with representation learning and model adaptation for ZSF.
Specifically, we construct a hierarchical tree-structured ChronoRAG Base (CRB)
for scalable time-series storage and domain-aware retrieval, introduce a
Multi-grained Series Interaction Learner (MSIL) to extract fine- and
coarse-grained relational features, and develop a dual-branch Model Cooperation
Coherer (MCC) that aligns retrieved knowledge with two kinds of TSPMs: Non-LLM
based and LLM based. Compared with contemporary baselines, QuiZSF, with Non-LLM
based and LLM based TSPMs as base model, respectively, ranks Top1 in 75% and
87.5% of prediction settings, while maintaining high efficiency in memory and
inference time.

</details>


### [417] [Class Unbiasing for Generalization in Medical Diagnosis](https://arxiv.org/abs/2508.06943)
*Lishi Zuo,Man-Wai Mak,Lu Yi,Youzhi Tu*

Main category: cs.LG

TL;DR: 本文提出了一种方法来缓解医疗诊断中因类别和特征偏差引起的问题，同时解决类别不平衡，改善模型性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 医疗诊断模型可能会出现由于类别和特征偏差导致的泛化问题，这显著影响了某些类别的模型表现。

Method: 提出一种‘类别无偏’方法，包括类别不平等损失和类别分组分布鲁棒优化目标，从而平衡正负类别样本损失并加权表现不佳的类别。

Result: 通过合成及真实世界数据集实验，证明了类别与特征偏差会削弱模型性能，而所提方法有效缓解这些偏差并提升泛化能力。

Conclusion: 提出的方法能够同时缓解类别不平衡和类别特征偏差，显著改善模型性能，具有实际应用价值。

Abstract: Medical diagnosis might fail due to bias. In this work, we identified
class-feature bias, which refers to models' potential reliance on features that
are strongly correlated with only a subset of classes, leading to biased
performance and poor generalization on other classes. We aim to train a
class-unbiased model (Cls-unbias) that mitigates both class imbalance and
class-feature bias simultaneously. Specifically, we propose a class-wise
inequality loss which promotes equal contributions of classification loss from
positive-class and negative-class samples. We propose to optimize a class-wise
group distributionally robust optimization objective-a class-weighted training
objective that upweights underperforming classes-to enhance the effectiveness
of the inequality loss under class imbalance. Through synthetic and real-world
datasets, we empirically demonstrate that class-feature bias can negatively
impact model performance. Our proposed method effectively mitigates both
class-feature bias and class imbalance, thereby improving the model's
generalization ability.

</details>


### [418] [AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance](https://arxiv.org/abs/2508.06944)
*Lixuan He,Jie Feng,Yong Li*

Main category: cs.LG

TL;DR: 该论文提出了一种单阶段算法AMFT，解决了现有语言模型在监督微调(SFT)和强化学习(RL)中的平衡问题，并在多项任务中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的微调方式存在灾难性遗忘以及模仿与探索之间的权衡不足，作者希望通过引入更统一的方法优化SFT与RL的结合。

Method: 本研究提出了AMFT算法，利用隐式奖励的理论，将SFT和RL视为互补的奖励信号，并通过元梯度控制器来动态优化两者的平衡，最大化长远任务性能。

Result: AMFT在数学推理、抽象视觉推理和视觉语言导航等任务中表现优异，超越了现有方法的效果，并在OOD任务上展示了出色的泛化能力。

Conclusion: AMFT通过动态学习SFT与RL之间的平衡，建立了LLM微调的更为有效的范式，相关代码已开源。

Abstract: Large Language Models (LLMs) are typically fine-tuned for reasoning tasks
through a two-stage pipeline of Supervised Fine-Tuning (SFT) followed by
Reinforcement Learning (RL), a process fraught with catastrophic forgetting and
suboptimal trade-offs between imitation and exploration. Recent single-stage
methods attempt to unify SFT and RL using heuristics, but lack a principled
mechanism for dynamically balancing the two paradigms. In this paper, we
reframe this challenge through the theoretical lens of \textbf{implicit
rewards}, viewing SFT and RL not as distinct methods but as complementary
reward signals. We introduce \textbf{Adaptive Meta Fine-Tuning (AMFT)}, a novel
single-stage algorithm that learns the optimal balance between SFT's implicit,
path-level reward and RL's explicit, outcome-based reward. The core of AMFT is
a \textbf{meta-gradient adaptive weight controller} that treats the SFT-RL
balance as a learnable parameter, dynamically optimizing it to maximize
long-term task performance. This forward-looking approach, regularized by
policy entropy for stability, autonomously discovers an effective training
curriculum. We conduct a comprehensive evaluation on challenging benchmarks
spanning mathematical reasoning, abstract visual reasoning (General Points),
and vision-language navigation (V-IRL). AMFT consistently establishes a new
state-of-the-art and demonstrats superior generalization on out-of-distribution
(OOD) tasks. Ablation studies and training dynamic analysis confirm that the
meta-learning controller is crucial for AMFT's stability, sample efficiency,
and performance, offering a more principled and effective paradigm for LLM
alignment.Our codes are open-sourced via https://github.com/hlxtsyj/AMFT.

</details>


### [419] [BoRA: Towards More Expressive Low-Rank Adaptation with Block Diversity](https://arxiv.org/abs/2508.06953)
*Shiwei Li,Xiandi Luo,Haozhao Wang,Xing Tang,Ziqiang Cui,Dugang Liu,Yuhua Li,Xiuqiang He,Ruixuan Li*

Main category: cs.LG

TL;DR: 本文提出了Block Diversified Low-Rank Adaptation (BoRA)，一种改进LoRA模型的方法，通过分块处理和引入对角矩阵提高了模型的表现，同时只增加了少量的参数。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型的微调存在高效参数化需求，LoRA通过低秩矩阵降维的方法较好地解决这一问题，但提升LoRA权重秩时需要显著增加可训练参数。

Method: BoRA通过将LoRA的低秩矩阵更新分块，将矩阵设为多个子矩阵，并对每个块引入独特的对角矩阵，从而提高LoRA权重的秩，只需增加少量额外参数。

Result: 实验结果表明，BoRA在多个数据集和模型上均表现优越，并通过消融实验验证了其扩展性。

Conclusion: 在优化LoRA的基础上，BoRA提供了一种高效、参数友好的方法，能在保持参数增量较少的情况下提升模型性能，显示出良好的实际应用价值。

Abstract: Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method
widely used in large language models (LLMs). It approximates the update of a
pretrained weight matrix $W\in\mathbb{R}^{m\times n}$ by the product of two
low-rank matrices, $BA$, where $A \in\mathbb{R}^{r\times n}$ and
$B\in\mathbb{R}^{m\times r} (r\ll\min\{m,n\})$. Increasing the dimension $r$
can raise the rank of LoRA weights (i.e., $BA$), which typically improves
fine-tuning performance but also significantly increases the number of
trainable parameters. In this paper, we propose Block Diversified Low-Rank
Adaptation (BoRA), which improves the rank of LoRA weights with a small number
of additional parameters. Specifically, BoRA treats the product $BA$ as a block
matrix multiplication, where $A$ and $B$ are partitioned into $b$ blocks along
the columns and rows, respectively (i.e., $A=[A_1,\dots,A_b]$ and
$B=[B_1,\dots,B_b]^\top$). Consequently, the product $BA$ becomes the
concatenation of the block products $B_iA_j$ for $i,j\in[b]$. To enhance the
diversity of different block products, BoRA introduces a unique diagonal matrix
$\Sigma_{i,j} \in \mathbb{R}^{r\times r}$ for each block multiplication,
resulting in $B_i \Sigma_{i,j} A_j$. By leveraging these block-wise diagonal
matrices, BoRA increases the rank of LoRA weights by a factor of $b$ while only
requiring $b^2r$ additional parameters. Extensive experiments across multiple
datasets and models demonstrate the superiority of BoRA, and ablation studies
further validate its scalability.

</details>


### [420] [Can Multitask Learning Enhance Model Explainability?](https://arxiv.org/abs/2508.06966)
*Hiba Najjar,Bushra Alshbib,Andreas Dengel*

Main category: cs.LG

TL;DR: 本文研究了通过多任务学习利用卫星数据的多样性，同时提高模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 探讨如何通过多模态数据提升模型性能的同时增强模型行为的解释性，特别是在卫星数据中。

Method: 使用多任务学习，将某些模态作为额外的预测目标，而非输入模态，从而利用多模态数据提高模型性能及解释性。

Result: 模型不需要在部署时额外收集数据，性能与多模态基线模型相当甚至更好，并且主要任务预测误差可以通过辅助任务行为解释。

Conclusion: 所提出的方法在三种数据集任务中验证了其效率，并提供代码供社区使用。

Abstract: Remote sensing provides satellite data in diverse types and formats. The
usage of multimodal learning networks exploits this diversity to improve model
performance, except that the complexity of such networks comes at the expense
of their interpretability. In this study, we explore how modalities can be
leveraged through multitask learning to intrinsically explain model behavior.
In particular, instead of additional inputs, we use certain modalities as
additional targets to be predicted along with the main task. The success of
this approach relies on the rich information content of satellite data, which
remains as input modalities. We show how this modeling context provides
numerous benefits: (1) in case of data scarcity, the additional modalities do
not need to be collected for model inference at deployment, (2) the model
performance remains comparable to the multimodal baseline performance, and in
some cases achieves better scores, (3) prediction errors in the main task can
be explained via the model behavior in the auxiliary task(s). We demonstrate
the efficiency of our approach on three datasets, including segmentation,
classification, and regression tasks. Code available at
git.opendfki.de/hiba.najjar/mtl_explainability/.

</details>


### [421] [Structure-Preserving Digital Twins via Conditional Neural Whitney Forms](https://arxiv.org/abs/2508.06981)
*Brooks Kinch,Benjamin Shaffer,Elizabeth Armstrong,Michael Meehan,John Hewson,Nathaniel Trask*

Main category: cs.LG

TL;DR: 框架基于保结构的有限元模型，通过条件注意力机制实现数值良性、守恒量精确保留，并支持复杂几何真实时间推断和校准。


<details>
  <summary>Details</summary>
Motivation: 为了在稀疏数据和复杂几何条件下，实现能保留守恒量的快速、准确实时数字孪生建模。

Method: 采用条件注意力机制学习有限元基础及非线性守恒定律，集成传统有限元工具及外代数体系，保证数值良性和守恒量精确。

Result: 模型可在复杂几何和稀疏数据下实现准确预测，约0.1秒实时推断相较于LES提升3.1x10^8倍，涵盖多种物理问题的基准测试。

Conclusion: 框架能够高效、非侵入集成传统有限元工具，支持复杂问题的实时准确数字孪生建模，代码已开源。

Abstract: We present a framework for constructing real-time digital twins based on
structure-preserving reduced finite element models conditioned on a latent
variable Z. The approach uses conditional attention mechanisms to learn both a
reduced finite element basis and a nonlinear conservation law within the
framework of finite element exterior calculus (FEEC). This guarantees numerical
well-posedness and exact preservation of conserved quantities, regardless of
data sparsity or optimization error. The conditioning mechanism supports
real-time calibration to parametric variables, allowing the construction of
digital twins which support closed loop inference and calibration to sensor
data. The framework interfaces with conventional finite element machinery in a
non-invasive manner, allowing treatment of complex geometries and integration
of learned models with conventional finite element techniques.
  Benchmarks include advection diffusion, shock hydrodynamics, electrostatics,
and a complex battery thermal runaway problem. The method achieves accurate
predictions on complex geometries with sparse data (25 LES simulations),
including capturing the transition to turbulence and achieving real-time
inference ~0.1s with a speedup of 3.1x10^8 relative to LES. An open-source
implementation is available on GitHub.

</details>


### [422] [Discovery Learning accelerates battery design evaluation](https://arxiv.org/abs/2508.06985)
*Jiawei Zhang,Yifei Zhang,Baozhao Yi,Yao Ren,Qi Jiao,Hanyu Bai,Weiran Jiang,Ziyou Song*

Main category: cs.LG

TL;DR: 该研究提出了一种新的科学机器学习范式DL，用以加速锂电池设计和开发，通过历史数据学习实现高效的寿命预测，显著降低时间和能源成本。


<details>
  <summary>Details</summary>
Motivation: 锂电池设计与开发受到原型设计和寿命测试高成本的限制，现有数据驱动的寿命预测方法效率不足，难以满足快速反馈的需求。

Method: 引入Discovery Learning (DL) 范式，结合主动学习、物理指导学习和零样本学习，从历史设计中学习并减少对原型的需求，能够对新材料设计组合进行快速寿命评估。

Result: DL仅利用小容量圆柱电池的公开数据集训练，就实现了平均7.2%的预测误差，并相比工业实践节省了98%的时间及95%的能源。

Conclusion: DL证明了从历史设计中洞察新方法的重要性，对下一代电池技术的开发具有极大潜力，推进了数据驱动建模效率，以及机器学习在科学发现及工程创新中的应用。

Abstract: Fast and reliable validation of novel designs in complex physical systems
such as batteries is critical to accelerating technological innovation.
However, battery research and development remain bottlenecked by the
prohibitively high time and energy costs required to evaluate numerous new
design candidates, particularly in battery prototyping and life testing.
Despite recent progress in data-driven battery lifetime prediction, existing
methods require labeled data of target designs to improve accuracy and cannot
make reliable predictions until after prototyping, thus falling far short of
the efficiency needed to enable rapid feedback for battery design. Here, we
introduce Discovery Learning (DL), a scientific machine-learning paradigm that
integrates active learning, physics-guided learning, and zero-shot learning
into a human-like reasoning loop, drawing inspiration from learning theories in
educational psychology. DL can learn from historical battery designs and
actively reduce the need for prototyping, thus enabling rapid lifetime
evaluation for unobserved material-design combinations without requiring
additional data labeling. To test DL, we present 123 industrial-grade
large-format lithium-ion pouch cells, spanning eight material-design
combinations and diverse cycling protocols. Trained solely on public datasets
of small-capacity cylindrical cells, DL achieves 7.2% test error in predicting
the average cycle life under unknown device variability. This results in
savings of 98% in time and 95% in energy compared to industrial practices. This
work highlights the potential of uncovering insights from historical designs to
inform and accelerate the development of next-generation battery technologies.
DL represents a key advance toward efficient data-driven modeling and helps
realize the promise of machine learning for accelerating scientific discovery
and engineering innovation.

</details>


### [423] [UniMove: A Unified Model for Multi-city Human Mobility Prediction](https://arxiv.org/abs/2508.06986)
*Chonghua Han,Yuan Yuan,Yukun Liu,Jingtao Ding,Jie Feng,Yong Li*

Main category: cs.LG

TL;DR: UniMove是一个统一的多城市人类移动预测模型，可提升10.2%以上预测准确率。


<details>
  <summary>Details</summary>
Motivation: 解决城市异质性和复杂人类移动行为难以建模的问题，为城市规划、交通优化等提供支持。

Method: 提出了轨迹-位置双塔架构及专家选择机制，以实现通用的空间编码和多样移动模式的建模。

Result: 实验表明，UniMove在多城市联合训练中显著提高了移动预测准确率，超过10.2%的改进。

Conclusion: UniMove作为一个统一架构的核心模型，为多城市人类移动预测提供了有效解决方案，具有重要意义。

Abstract: Human mobility prediction is vital for urban planning, transportation
optimization, and personalized services. However, the inherent randomness,
non-uniform time intervals, and complex patterns of human mobility, compounded
by the heterogeneity introduced by varying city structures, infrastructure, and
population densities, present significant challenges in modeling. Existing
solutions often require training separate models for each city due to distinct
spatial representations and geographic coverage. In this paper, we propose
UniMove, a unified model for multi-city human mobility prediction, addressing
two challenges: (1) constructing universal spatial representations for
effective token sharing across cities, and (2) modeling heterogeneous mobility
patterns from varying city characteristics. We propose a trajectory-location
dual-tower architecture, with a location tower for universal spatial encoding
and a trajectory tower for sequential mobility modeling. We also design MoE
Transformer blocks to adaptively select experts to handle diverse movement
patterns. Extensive experiments across multiple datasets from diverse cities
demonstrate that UniMove truly embodies the essence of a unified model. By
enabling joint training on multi-city data with mutual data enhancement, it
significantly improves mobility prediction accuracy by over 10.2\%. UniMove
represents a key advancement toward realizing a true foundational model with a
unified architecture for human mobility. We release the implementation at
https://github.com/tsinghua-fib-lab/UniMove/.

</details>


### [424] [A Comparative Study of Feature Selection in Tsetlin Machines](https://arxiv.org/abs/2508.06991)
*Vojtech Halenka,Ole-Christoffer Granmo,Lei Jiao,Per-Arne Andersen*

Main category: cs.LG

TL;DR: 本文提出多种特征选择技术用于Tsetlin机器，并在12个数据集上进行了评估，展示TM内部评分器的竞争性能及低计算开销。


<details>
  <summary>Details</summary>
Motivation: Tsetlin机器虽然具有可解释性，但缺乏特征重要性测量工具，因此需要设计适用的特征选择方法。

Method: 结合经典的过滤及嵌入式方法、后验解释工具（如SHAP和LIME）以及基于TM条款权重和Tsetlin自动机的嵌入式评分器，对特征选择技术进行适配与评估。

Result: 通过多种基准测试发现，TM内部评分器具有竞争性能，并能利用条款的可解释性揭示特征交互模式，且某些评分器在低计算成本下取得了相似的准确性。

Conclusion: 本文首次为TM建立了完整的特征选择基准，推动了特定TM解释性技术的进一步发展。

Abstract: Feature Selection (FS) is crucial for improving model interpretability,
reducing complexity, and sometimes for enhancing accuracy. The recently
introduced Tsetlin machine (TM) offers interpretable clause-based learning, but
lacks established tools for estimating feature importance. In this paper, we
adapt and evaluate a range of FS techniques for TMs, including classical filter
and embedded methods as well as post-hoc explanation methods originally
developed for neural networks (e.g., SHAP and LIME) and a novel family of
embedded scorers derived from TM clause weights and Tsetlin automaton (TA)
states. We benchmark all methods across 12 datasets, using evaluation
protocols, like Remove and Retrain (ROAR) strategy and Remove and Debias
(ROAD), to assess causal impact. Our results show that TM-internal scorers not
only perform competitively but also exploit the interpretability of clauses to
reveal interacting feature patterns. Simpler TM-specific scorers achieve
similar accuracy retention at a fraction of the computational cost. This study
establishes the first comprehensive baseline for FS in TM and paves the way for
developing specialized TM-specific interpretability techniques.

</details>


### [425] [Conformal Set-based Human-AI Complementarity with Multiple Experts](https://arxiv.org/abs/2508.06997)
*Helbert Paat,Guohao Shen*

Main category: cs.LG

TL;DR: 利用基于预训练模型的保形预测集，研究了从多个专家中选择实例特定专家的问题，并提出了一种用于子集选择的贪婪算法，提升了多专家协作的分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于单一专家场景，而未深入探讨如何在多专家协作中选取适合每个实例的专家子集，以进一步提升分类任务中的人机协作能力。

Method: 提出了一种基于保形预测集的贪婪算法，该算法选择适合每个实例的专家子集以优化分类预测，采用真实的专家预测集CIFAR-10H和ImageNet-16H数据进行了模拟研究。

Result: 贪婪算法能够接近最优地选择专家子集，显著提升了多专家分类的整体性能。

Conclusion: 在多专家协作场景中，贪婪算法为实例特定的专家选取提供了一种有效方法，验证了其在提升分类性能方面的有效性。

Abstract: Decision support systems are designed to assist human experts in
classification tasks by providing conformal prediction sets derived from a
pre-trained model. This human-AI collaboration has demonstrated enhanced
classification performance compared to using either the model or the expert
independently. In this study, we focus on the selection of instance-specific
experts from a pool of multiple human experts, contrasting it with existing
research that typically focuses on single-expert scenarios. We characterize the
conditions under which multiple experts can benefit from the conformal sets.
With the insight that only certain experts may be relevant for each instance,
we explore the problem of subset selection and introduce a greedy algorithm
that utilizes conformal sets to identify the subset of expert predictions that
will be used in classifying an instance. This approach is shown to yield better
performance compared to naive methods for human subset selection. Based on real
expert predictions from the CIFAR-10H and ImageNet-16H datasets, our simulation
study indicates that our proposed greedy algorithm achieves near-optimal
subsets, resulting in improved classification performance among multiple
experts.

</details>


### [426] [TLCCSP: A Scalable Framework for Enhancing Time Series Forecasting with Time-Lagged Cross-Correlations](https://arxiv.org/abs/2508.07016)
*Jianfei Wu,Wenmian Yang,Bingning Liu,Weijia Jia*

Main category: cs.LG

TL;DR: 本文提出了一种名为时间滞后交叉相关序列预测框架（TLCCSP）的新方法，利用时间滞后交叉相关性提升时间序列预测的准确性，并在多个领域取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型对时间序列预测的能力有所提升，但通常忽略了相关序列之间的重要时间滞后交叉相关性，导致无法全面捕捉复杂的时间关系。为解决这一问题，提出了TLCCSP框架。

Method: TLCCSP框架通过序列移位动态时间规整算法（SSDTW）捕捉滞后相关性，同时结合对比学习的编码器高效逼近SSDTW距离。

Result: 在天气、金融和房地产数据集中，SSDTW减少了16.01%到21.29%的均方误差（MSE）；结合对比学习的编码器（CLE）进一步减少6.13%到17.88%的MSE，并将SSDTW计算时间减少约99%。

Conclusion: TLCCSP框架通过有效结合滞后相关性和对比学习，实现高效、准确的时间序列预测，在多个应用领域具有很好的实践价值。

Abstract: Time series forecasting is critical across various domains, such as weather,
finance and real estate forecasting, as accurate forecasts support informed
decision-making and risk mitigation. While recent deep learning models have
improved predictive capabilities, they often overlook time-lagged
cross-correlations between related sequences, which are crucial for capturing
complex temporal relationships. To address this, we propose the Time-Lagged
Cross-Correlations-based Sequence Prediction framework (TLCCSP), which enhances
forecasting accuracy by effectively integrating time-lagged cross-correlated
sequences. TLCCSP employs the Sequence Shifted Dynamic Time Warping (SSDTW)
algorithm to capture lagged correlations and a contrastive learning-based
encoder to efficiently approximate SSDTW distances.
  Experimental results on weather, finance and real estate time series datasets
demonstrate the effectiveness of our framework. On the weather dataset, SSDTW
reduces mean squared error (MSE) by 16.01% compared with single-sequence
methods, while the contrastive learning encoder (CLE) further decreases MSE by
17.88%. On the stock dataset, SSDTW achieves a 9.95% MSE reduction, and CLE
reduces it by 6.13%. For the real estate dataset, SSDTW and CLE reduce MSE by
21.29% and 8.62%, respectively. Additionally, the contrastive learning approach
decreases SSDTW computational time by approximately 99%, ensuring scalability
and real-time applicability across multiple time series forecasting tasks.

</details>


### [427] [From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving](https://arxiv.org/abs/2508.07029)
*Antonio Guillen-Perez*

Main category: cs.LG

TL;DR: 该研究通过改进行为克隆(BC)和结合离线强化学习(CQL)，提出一种更稳健的自动驾驶策略学习方法，显著提高了驾驶绩效和安全性。


<details>
  <summary>Details</summary>
Motivation: 传统行为克隆方法在闭环执行时容易出错，而在线数据收集又不安全，因此研究旨在探索离线学习方法，克服这些限制并提高稳健性。

Method: 提出一套BC基线模型，并尝试将CQL引入到同一个数据与架构中，通过设计精细的奖励函数，使CQL有效避免分布偏移并提高鲁棒性。

Result: 经过在Waymo Open Motion Dataset的1000个情景中测试，CQL策略相比最强BC基线成功率提高3.2倍，碰撞率降低7.4倍。

Conclusion: 离线强化学习方法（如CQL）相比传统行为克隆更能学到稳健、长时间视距的驾驶策略，尤其适用于静态专家数据训练的场景。

Abstract: Learning robust driving policies from large-scale, real-world datasets is a
central challenge in autonomous driving, as online data collection is often
unsafe and impractical. While Behavioral Cloning (BC) offers a straightforward
approach to imitation learning, policies trained with BC are notoriously
brittle and suffer from compounding errors in closed-loop execution. This work
presents a comprehensive pipeline and a comparative study to address this
limitation. We first develop a series of increasingly sophisticated BC
baselines, culminating in a Transformer-based model that operates on a
structured, entity-centric state representation. While this model achieves low
imitation loss, we show that it still fails in long-horizon simulations. We
then demonstrate that by applying a state-of-the-art Offline Reinforcement
Learning algorithm, Conservative Q-Learning (CQL), to the same data and
architecture, we can learn a significantly more robust policy. Using a
carefully engineered reward function, the CQL agent learns a conservative value
function that enables it to recover from minor errors and avoid
out-of-distribution states. In a large-scale evaluation on 1,000 unseen
scenarios from the Waymo Open Motion Dataset, our final CQL agent achieves a
3.2x higher success rate and a 7.4x lower collision rate than the strongest BC
baseline, proving that an offline RL approach is critical for learning robust,
long-horizon driving policies from static expert data.

</details>


### [428] [A Stage-Aware Mixture of Experts Framework for Neurodegenerative Disease Progression Modelling](https://arxiv.org/abs/2508.07032)
*Tiantian He,Keyue Jiang,An Zhao,Anna Schroder,Elinor Thompson,Sonja Soskic,Frederik Barkhof,Daniel C. Alexander*

Main category: cs.LG

TL;DR: 提出了一种新型以阶段为中心的专家混合模型（MoE），用于模拟神经退行性疾病的进程，结合了时间依赖的专家加权和不均匀图神经扩散模型（IGND）。


<details>
  <summary>Details</summary>
Motivation: 传统模型难以处理神经退行性疾病中的复杂机制和数据稀缺问题。

Method: 提出了一种阶段感知的专家混合框架（MoE）和不均匀图神经扩散模型（IGND），采用迭代双优化方法来构建队列级进程轨迹，并用局部神经反应模块捕获复杂动态。

Result: 构建了一个能够动态整合时间状态和阶段特定机制的模型，提供了临床洞察，表明早期以图相关过程为主，晚期其他机制占主导地位。

Conclusion: 模型为理解疾病进程中阶段特定的病理机制提供了规范化方式，并与目前的文献一致。

Abstract: The long-term progression of neurodegenerative diseases is commonly
conceptualized as a spatiotemporal diffusion process that consists of a graph
diffusion process across the structural brain connectome and a localized
reaction process within brain regions. However, modeling this progression
remains challenging due to 1) the scarcity of longitudinal data obtained
through irregular and infrequent subject visits and 2) the complex interplay of
pathological mechanisms across brain regions and disease stages, where
traditional models assume fixed mechanisms throughout disease progression. To
address these limitations, we propose a novel stage-aware Mixture of Experts
(MoE) framework that explicitly models how different contributing mechanisms
dominate at different disease stages through time-dependent expert
weighting.Data-wise, we utilize an iterative dual optimization method to
properly estimate the temporal position of individual observations,
constructing a co hort-level progression trajectory from irregular snapshots.
Model-wise, we enhance the spatial component with an inhomogeneous graph neural
diffusion model (IGND) that allows diffusivity to vary based on node states and
time, providing more flexible representations of brain networks. We also
introduce a localized neural reaction module to capture complex dynamics beyond
standard processes.The resulting IGND-MoE model dynamically integrates these
components across temporal states, offering a principled way to understand how
stage-specific pathological mechanisms contribute to progression. The
stage-wise weights yield novel clinical insights that align with literature,
suggesting that graph-related processes are more influential at early stages,
while other unknown physical processes become dominant later on.

</details>


### [429] [Differentiable Adaptive Kalman Filtering via Optimal Transport](https://arxiv.org/abs/2508.07037)
*Yangguang He,Wenhao Li,Minzhe Li,Juan Zhang,Xiangfeng Wang,Bo Jin*

Main category: cs.LG

TL;DR: 本论文提出了OTAKNet，一种基于学习的自适应卡尔曼滤波器，能够在线适应噪声统计漂移，而无需重新训练或真实标签。


<details>
  <summary>Details</summary>
Motivation: 现有学习型滤波器在非线性动态系统中表现优异，但在实际应用中因环境变化导致的噪声统计漂移会显著降低性能，需开发能在线适应漂移的解决方案。

Method: 提出OTAKNet，通过预测测量似然与漂移建立联系，并利用最优传输的几何感知成本和稳定梯度，实现无需真实标签的完全在线适应能力。

Result: OTAKNet在合成和实际NCLT数据集上，尤其是有限训练数据条件下，性能优于经典基于模型的自适应卡尔曼滤波和离线学习型滤波。

Conclusion: OTAKNet能够显著提升学习型滤波器在环境变化下的稳健性，通过完全在线的方式解决噪声统计漂移难题。

Abstract: Learning-based filtering has demonstrated strong performance in non-linear
dynamical systems, particularly when the statistics of noise are unknown.
However, in real-world deployments, environmental factors, such as changing
wind conditions or electromagnetic interference, can induce unobserved
noise-statistics drift, leading to substantial degradation of learning-based
methods. To address this challenge, we propose OTAKNet, the first online
solution to noise-statistics drift within learning-based adaptive Kalman
filtering. Unlike existing learning-based methods that perform offline
fine-tuning using batch pointwise matching over entire trajectories, OTAKNet
establishes a connection between the state estimate and the drift via one-step
predictive measurement likelihood, and addresses it using optimal transport.
This leverages OT's geometry - aware cost and stable gradients to enable fully
online adaptation without ground truth labels or retraining. We compare OTAKNet
against classical model-based adaptive Kalman filtering and offline
learning-based filtering. The performance is demonstrated on both synthetic and
real-world NCLT datasets, particularly under limited training data.

</details>


### [430] [Membership and Memorization in LLM Knowledge Distillation](https://arxiv.org/abs/2508.07054)
*Ziqi Zhang,Ali Shahin Shamsabadi,Hanxiao Lu,Yifeng Cai,Hamed Haddadi*

Main category: cs.LG

TL;DR: 本论文研究了知识蒸馏(KD)技术在大语言模型(LLMs)中可能引发的隐私风险，发现所有现有技术都会将教师模型的隐私风险传递给学生模型，但程度因技术方法而异。


<details>
  <summary>Details</summary>
Motivation: 探讨知识蒸馏技术在从大语言模型向小模型传递知识的过程中对隐私的影响，尤其是继承隐私风险的问题。

Method: 分析了六种LLM知识蒸馏技术，在七个NLP任务、三种教师模型(GPT-2、LLAMA-2、OPT)和不同大小的学生模型下，系统评估其隐私风险。

Result: 证明现有的LLM KD技术会导致记忆泄露和成员隐私风险，并分析了不同KD组成部分对这些风险的影响。

Conclusion: 发现了隐私风险随蒸馏技术变化显著，同时识别了模型块中隐私风险分布差异，为未来改进蒸馏技术提供依据。

Abstract: Recent advances in Knowledge Distillation (KD) aim to mitigate the high
computational demands of Large Language Models (LLMs) by transferring knowledge
from a large ''teacher'' to a smaller ''student'' model. However, students may
inherit the teacher's privacy when the teacher is trained on private data. In
this work, we systematically characterize and investigate membership and
memorization privacy risks inherent in six LLM KD techniques. Using
instruction-tuning settings that span seven NLP tasks, together with three
teacher model families (GPT-2, LLAMA-2, and OPT), and various size student
models, we demonstrate that all existing LLM KD approaches carry membership and
memorization privacy risks from the teacher to its students. However, the
extent of privacy risks varies across different KD techniques. We
systematically analyse how key LLM KD components (KD objective functions,
student training data and NLP tasks) impact such privacy risks. We also
demonstrate a significant disagreement between memorization and membership
privacy risks of LLM KD techniques. Finally, we characterize per-block privacy
risk and demonstrate that the privacy risk varies across different blocks by a
large margin.

</details>


### [431] [Surgical Knowledge Rewrite in Compact LLMs: An 'Unlearn-then-Learn' Strategy with ($IA^3$) for Localized Factual Modulation and Catastrophic Forgetting Mitigation](https://arxiv.org/abs/2508.07075)
*Stanley Ngugi*

Main category: cs.LG

TL;DR: 本文提出了一种创新的“先遗忘再学习”的策略，通过准确定位并编辑涉及冲突知识的内部组件，以高效地实现大型语言模型的知识更新，显著降低遗忘无关知识的概率。


<details>
  <summary>Details</summary>
Motivation: 传统大型语言模型在面对新知识（尤其是与现有知识冲突的情况）时，难以有效更新，同时容易出现严重的遗忘无关知识问题，这限制了模型的知识动态调整能力。

Method: 采用两阶段策略：首先，通过电路定位阶段精确识别嵌入冲突知识的内部组件；其次，利用基于IA^3的参数高效微调技术（Infused Adapter by Inhibiting and Amplifying Inner Activations）进行知识“取消”与“更新”。

Result: 在实验中，提出的策略在microsoft/Phi-3-mini-4k-instruct模型上实现了近乎完美的新知识正确率（98.50%）及冲突知识抑制率（96.00%忘记率）。同时，与直接微调相比，显著缓解了灾难性遗忘问题（定位准确率提高到72.00%）。

Conclusion: 此研究展示了精准、安全且本地化的大型语言模型知识管理新方法，有助于更高效地处理知识更新与冲突问题，同时提升了模型的安全性与控制能力。

Abstract: Large Language Models (LLMs) struggle with dynamic knowledge updates,
especially when new information conflicts with deeply embedded facts. Such
conflicting factual edits often lead to two critical issues: resistance to
adopting the new fact and severe catastrophic forgetting of unrelated
knowledge. This paper introduces and evaluates a novel "unlearn-then-learn"
strategy for precise knowledge editing in LLMs, leveraging the
parameter-efficient fine-tuning (PEFT) technique, Infused Adapter by Inhibiting
and Amplifying Inner Activations ($IA^3$). Crucially, this two-stage approach
is powered by an initial circuit localization phase that identifies and targets
the specific internal components responsible for encoding the conflicting fact.
Through a rigorous experimental methodology on
microsoft/Phi-3-mini-4k-instruct, we demonstrate that this mechanistically
informed two-stage approach achieves near-perfect accuracy (98.50%) for the
new, modulated fact while simultaneously effectively suppressing the original
conflicting fact (96.00% forget rate). Critically, our strategy exhibits
unprecedented localization (72.00% F_control accuracy), dramatically mitigating
catastrophic forgetting observed in direct fine-tuning approaches (which showed
as low as ~20% F_control accuracy), a direct benefit of our targeted
interpretability-guided intervention. Furthermore, qualitative analysis reveals
a nuanced mechanism of "soft forgetting," where original knowledge is
suppressed from default retrieval but remains latent and conditionally
accessible, enhancing model safety and control. These findings represent a
significant advancement towards precise, localized, and safe knowledge
management in compact LLMs.

</details>


### [432] [Improving Real-Time Concept Drift Detection using a Hybrid Transformer-Autoencoder Framework](https://arxiv.org/abs/2508.07085)
*N Harshit,K Mounvik*

Main category: cs.LG

TL;DR: 本文提出了一种结合Transformer和Autoencoder的混合框架，用于实时概念漂移检测，能更早、更准确地识别数据分布的变化。


<details>
  <summary>Details</summary>
Motivation: 现有概念漂移检测方法往往是被动的，对早期检测不敏感。为了改进模型性能，文章提出了一种更高效的检测方法。

Method: 采用混合框架结合了Transformer和Autoencoder，还引入了Trust Score评价方法，结合多种统计和重构度量指标进行实时漂移检测。

Result: 在航空乘客时间序列数据上进行实验，显示新方法比现有模型能更早、更灵敏地检测到漂移，并改善了模型错误率和逻辑违规率的检测能力。

Conclusion: 提出的框架可靠有效，可用于实际机器学习场景下的概念漂移监测。

Abstract: In applied machine learning, concept drift, which is either gradual or abrupt
changes in data distribution, can significantly reduce model performance.
Typical detection methods,such as statistical tests or reconstruction-based
models,are generally reactive and not very sensitive to early detection. Our
study proposes a hybrid framework consisting of Transformers and Autoencoders
to model complex temporal dynamics and provide online drift detection. We
create a distinct Trust Score methodology, which includes signals on (1)
statistical and reconstruction-based drift metrics, more specifically, PSI,
JSD, Transformer-AE error, (2) prediction uncertainty, (3) rules violations,
and (4) trend of classifier error aligned with the combined metrics defined by
the Trust Score. Using a time sequenced airline passenger data set with
synthetic drift, our proposed model allows for a better detection of drift
using as a whole and at different detection thresholds for both sensitivity and
interpretability compared to baseline methods and provides a strong pipeline
for drift detection in real time for applied machine learning. We evaluated
performance using a time-sequenced airline passenger dataset having the
gradually injected stimulus of drift in expectations,e.g. permuted ticket
prices in later batches, broken into 10 time segments [1].In the data, our
results support that the Transformation-Autoencoder detected drift earlier and
with more sensitivity than the autoencoders commonly used in the literature,
and provided improved modeling over more error rates and logical violations.
Therefore, a robust framework was developed to reliably monitor concept drift.

</details>


### [433] [Towards High-Order Mean Flow Generative Models: Feasibility, Expressivity, and Provably Efficient Criteria](https://arxiv.org/abs/2508.07102)
*Yang Cao,Yubin Chen,Zhao Song,Jiahao Zhang*

Main category: cs.LG

TL;DR: 本文提出了Second-Order MeanFlow，一种整合平均加速度场的新生成建模方法，具有高效单步采样能力和稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前生成建模中的MeanFlow框架虽高效，但仅局限于一阶动态。本研究旨在通过引入二阶平均加速度场以增强MeanFlow的表达能力并保持采样效率。

Method: 通过理论推导证明二阶平均加速度场满足广义一致性条件，并采用电路复杂性分析来评估其可表达性。同时，通过快速近似注意力计算推导出可扩展实现的高效条件。

Result: 提出的Second-Order MeanFlow方法在理论分析中表现出高效可行性，能够通过快速近似注意力实现$n^{2+o(1)}$级复杂度的采样操作。

Conclusion: Second-Order MeanFlow为高阶流匹配模型奠定了理论基础，兼具复杂动态表达能力和实用采样效率。

Abstract: Generative modelling has seen significant advances through simulation-free
paradigms such as Flow Matching, and in particular, the MeanFlow framework,
which replaces instantaneous velocity fields with average velocities to enable
efficient single-step sampling. In this work, we introduce a theoretical study
on Second-Order MeanFlow, a novel extension that incorporates average
acceleration fields into the MeanFlow objective. We first establish the
feasibility of our approach by proving that the average acceleration satisfies
a generalized consistency condition analogous to first-order MeanFlow, thereby
supporting stable, one-step sampling and tractable loss functions. We then
characterize its expressivity via circuit complexity analysis, showing that
under mild assumptions, the Second-Order MeanFlow sampling process can be
implemented by uniform threshold circuits within the $\mathsf{TC}^0$ class.
Finally, we derive provably efficient criteria for scalable implementation by
leveraging fast approximate attention computations: we prove that attention
operations within the Second-Order MeanFlow architecture can be approximated to
within $1/\mathrm{poly}(n)$ error in time $n^{2+o(1)}$. Together, these results
lay the theoretical foundation for high-order flow matching models that combine
rich dynamics with practical sampling efficiency.

</details>


### [434] [BrainATCL: Adaptive Temporal Brain Connectivity Learning for Functional Link Prediction and Age Estimation](https://arxiv.org/abs/2508.07106)
*Yiran Huang,Amirhossein Nouranizadeh,Christine Ahrends,Mengjia Xu*

Main category: cs.LG

TL;DR: 本文提出了一种名为BrainATCL的新框架，用于动态功能连接学习，能够预测功能链接和估计年龄，表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的图神经网络无法很好地捕捉动态fMRI数据中的长时依赖性，因此需要新的方法来建模大脑连接的时空动态。

Method: 提出了BrainATCL框架，通过动态调整时间窗口并结合GINE-Mamba2骨干网络来编码动态功能连接图序列，同时加入左右脑和子网络等结构功能信息。

Result: BrainATCL在功能链接预测和年龄估计任务上的表现优于现有方法，展示了出色的泛化能力，包括跨时段预测的场景。

Conclusion: BrainATCL框架能够捕获动态fMRI数据中的生物学意义的拓扑模式，显著提升任务表现，为脑功能动态研究提供了有力工具。

Abstract: Functional Magnetic Resonance Imaging (fMRI) is an imaging technique widely
used to study human brain activity. fMRI signals in areas across the brain
transiently synchronise and desynchronise their activity in a highly structured
manner, even when an individual is at rest. These functional connectivity
dynamics may be related to behaviour and neuropsychiatric disease. To model
these dynamics, temporal brain connectivity representations are essential, as
they reflect evolving interactions between brain regions and provide insight
into transient neural states and network reconfigurations. However,
conventional graph neural networks (GNNs) often struggle to capture long-range
temporal dependencies in dynamic fMRI data. To address this challenge, we
propose BrainATCL, an unsupervised, nonparametric framework for adaptive
temporal brain connectivity learning, enabling functional link prediction and
age estimation. Our method dynamically adjusts the lookback window for each
snapshot based on the rate of newly added edges. Graph sequences are
subsequently encoded using a GINE-Mamba2 backbone to learn spatial-temporal
representations of dynamic functional connectivity in resting-state fMRI data
of 1,000 participants from the Human Connectome Project. To further improve
spatial modeling, we incorporate brain structure and function-informed edge
attributes, i.e., the left/right hemispheric identity and subnetwork membership
of brain regions, enabling the model to capture biologically meaningful
topological patterns. We evaluate our BrainATCL on two tasks: functional link
prediction and age estimation. The experimental results demonstrate superior
performance and strong generalization, including in cross-session prediction
scenarios.

</details>


### [435] [Approaching Maximal Information Extraction in Low-Signal Regimes via Multiple Instance Learning](https://arxiv.org/abs/2508.07114)
*Atakan Azakli,Bernd Stelzer*

Main category: cs.LG

TL;DR: 本文提出了一种新的机器学习方法，以改进假设检验问题中某些参数的预测精度，特别是在现有分类器难以准确预测的情况下提高其判别能力。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习模型在某些复杂问题上的判别和预测能力受限，因此需要一种新的方法来改进其能力并系统性降低预测误差。

Method: 通过提供数学动机解释为何多实例学习（MIL）的预测能力优于单实例方法，同时研究了MIL模型预测实例数量扩展时的行为，并结合实际应用进行了验证。

Result: 在标准模型有效场论(SMEFT)的应用中，利用粒子对撞事件数据，证明了在某些情况下可以提取数据集中潜在的理论最大Fisher信息。

Conclusion: 该研究在理论上和实验上证明了多实例学习在提高预测能力方面的优势，并展现了该方法在实际科学应用中的潜力。

Abstract: In this work, we propose a new machine learning (ML) methodology to obtain
more precise predictions for some parameters of interest in a given hypotheses
testing problem. Our proposed method also allows ML models to have more
discriminative power in cases where it is extremely challenging for
state-of-the-art classifiers to have any level of accurate predictions. This
method can also allow us to systematically decrease the error from ML models in
their predictions. In this paper, we provide a mathematical motivation why
Multiple Instance Learning (MIL) would have more predictive power over their
single-instance counterparts. We support our theoretical claims by analyzing
the behavior of the MIL models through their scaling behaviors with respect to
the number of instances on which the model makes predictions. As a concrete
application, we constrain Wilson coefficients of the Standard Model Effective
Field Theory (SMEFT) using kinematic information from subatomic particle
collision events at the Large Hadron Collider (LHC). We show that under certain
circumstances, it might be possible to extract the theoretical maximum Fisher
Information latent in a dataset.

</details>


### [436] [From Nodes to Narratives: Explaining Graph Neural Networks with LLMs and Graph Context](https://arxiv.org/abs/2508.07117)
*Peyman Baghershahi,Gregoire Fournier,Pranav Nyati,Sourav Medya*

Main category: cs.LG

TL;DR: LOGIC是一种轻量级的后处理框架，运用大型语言模型(LLMs)为图神经网络(GNN)预测生成忠实且可解释的解释。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络解释方法难以为包含丰富自然语言节点属性的图生成细粒度、可解释的推理。

Method: 提出的LOGIC方法利用LLMs，将GNN节点嵌入投射到LLM嵌入空间，并通过混合提示（软提示+图结构文本）生成解释。

Result: 在四个实际文本属性图(TAG)数据集上的实验显示，LOGIC在忠实性和稀疏性之间实现了良好平衡，并在可读性、直观性等人类指标上显著提升。

Conclusion: LOGIC为基于LLM的图学习可解释性开辟了新方向，通过对齐GNN内部表示与人类推理方式，生成细粒度的自然语言解释和简洁的子图。

Abstract: Graph Neural Networks (GNNs) have emerged as powerful tools for learning over
structured data, including text-attributed graphs, which are common in domains
such as citation networks, social platforms, and knowledge graphs. GNNs are not
inherently interpretable and thus, many explanation methods have been proposed.
However, existing explanation methods often struggle to generate interpretable,
fine-grained rationales, especially when node attributes include rich natural
language. In this work, we introduce LOGIC, a lightweight, post-hoc framework
that uses large language models (LLMs) to generate faithful and interpretable
explanations for GNN predictions. LOGIC projects GNN node embeddings into the
LLM embedding space and constructs hybrid prompts that interleave soft prompts
with textual inputs from the graph structure. This enables the LLM to reason
about GNN internal representations and produce natural language explanations
along with concise explanation subgraphs. Our experiments across four
real-world TAG datasets demonstrate that LOGIC achieves a favorable trade-off
between fidelity and sparsity, while significantly improving human-centric
metrics such as insightfulness. LOGIC sets a new direction for LLM-based
explainability in graph learning by aligning GNN internals with human
reasoning.

</details>


### [437] [Multi-Level Service Performance Forecasting via Spatiotemporal Graph Neural Networks](https://arxiv.org/abs/2508.07122)
*Zhihao Xue,Yun Zi,Nia Qi,Ming Gong,Yujun Zou*

Main category: cs.LG

TL;DR: 提出一种基于时空图神经网络的性能预测算法，用于分布式后端系统性能波动预测，在多个基准指标上超越现有方法，表现出强鲁棒性和应用潜力。


<details>
  <summary>Details</summary>
Motivation: 解决多层服务调用结构的分布式后端系统中预测性能波动的难题。

Method: 利用图卷积网络提取服务拓扑结构的高阶依赖信息，结合门控循环网络捕捉性能指标的动态演变，并引入时间编码机制增强非平稳时间序列表示能力。使用端到端的训练方式优化模型，进行高精度性能指标预测。

Result: 实验结果显示，该模型在MAE、RMSE和R2等关键指标上的表现优于现有方法，并且在不同负载强度和结构复杂性条件下仍表现出强鲁棒性。

Conclusion: 该方法在后端服务性能管理任务中具有实际应用潜力，证明了其在高精度预测任务中的优越性和稳定性。

Abstract: This paper proposes a spatiotemporal graph neural network-based performance
prediction algorithm to address the challenge of forecasting performance
fluctuations in distributed backend systems with multi-level service call
structures. The method abstracts system states at different time slices into a
sequence of graph structures. It integrates the runtime features of service
nodes with the invocation relationships among services to construct a unified
spatiotemporal modeling framework. The model first applies a graph
convolutional network to extract high-order dependency information from the
service topology. Then it uses a gated recurrent network to capture the dynamic
evolution of performance metrics over time. A time encoding mechanism is also
introduced to enhance the model's ability to represent non-stationary temporal
sequences. The architecture is trained in an end-to-end manner, optimizing the
multi-layer nested structure to achieve high-precision regression of future
service performance metrics. To validate the effectiveness of the proposed
method, a large-scale public cluster dataset is used. A series of
multi-dimensional experiments are designed, including variations in time
windows and concurrent load levels. These experiments comprehensively evaluate
the model's predictive performance and stability. The experimental results show
that the proposed model outperforms existing representative methods across key
metrics such as MAE, RMSE, and R2. It maintains strong robustness under varying
load intensities and structural complexities. These results demonstrate the
model's practical potential for backend service performance management tasks.

</details>


### [438] [Pref-GUIDE: Continual Policy Learning from Real-Time Human Feedback via Preference-Based Learning](https://arxiv.org/abs/2508.07126)
*Zhengran Ji,Boyuan Chen*

Main category: cs.LG

TL;DR: Pref-GUIDE 将实时的标量反馈转化为偏好数据，用于增强在线强化学习中的奖励模型，对提高学习效果有显著优势。


<details>
  <summary>Details</summary>
Motivation: 当任务目标难以通过密集奖励函数定义时，使用人类反馈来训练强化学习代理尤为关键，现有方法难以在在线学习场景中使用。

Method: 提出Pref-GUIDE框架，将实时标量反馈转化为偏好数据，通过Pref-GUIDE Individual短窗对比和模糊反馈过滤，以及Pref-GUIDE Voting的用户群体反馈共识，解决现有反馈的噪声与不一致问题。

Result: 在三个具有挑战性的环境中，Pref-GUIDE显著优于标量反馈的基线方法，投票版本甚至超过了专家设计的密集奖励。

Conclusion: Pref-GUIDE通过将标量反馈重构为结构化偏好数据，并结合用户群体反馈提供扩展性和有效性，为在线强化学习中的人类输入利用提供了创新途径。

Abstract: Training reinforcement learning agents with human feedback is crucial when
task objectives are difficult to specify through dense reward functions. While
prior methods rely on offline trajectory comparisons to elicit human
preferences, such data is unavailable in online learning scenarios where agents
must adapt on the fly. Recent approaches address this by collecting real-time
scalar feedback to guide agent behavior and train reward models for continued
learning after human feedback becomes unavailable. However, scalar feedback is
often noisy and inconsistent, limiting the accuracy and generalization of
learned rewards. We propose Pref-GUIDE, a framework that transforms real-time
scalar feedback into preference-based data to improve reward model learning for
continual policy training. Pref-GUIDE Individual mitigates temporal
inconsistency by comparing agent behaviors within short windows and filtering
ambiguous feedback. Pref-GUIDE Voting further enhances robustness by
aggregating reward models across a population of users to form consensus
preferences. Across three challenging environments, Pref-GUIDE significantly
outperforms scalar-feedback baselines, with the voting variant exceeding even
expert-designed dense rewards. By reframing scalar feedback as structured
preferences with population feedback, Pref-GUIDE offers a scalable and
principled approach for harnessing human input in online reinforcement
learning.

</details>


### [439] [How Effectively Can Large Language Models Connect SNP Variants and ECG Phenotypes for Cardiovascular Risk Prediction?](https://arxiv.org/abs/2508.07127)
*Niranjana Arun Menon,Iqra Farooq,Yulong Li,Sara Ahmed,Yutong Xie,Muhammad Awais,Imran Razzak*

Main category: cs.LG

TL;DR: 研究表明，通过微调的大型语言模型（LLMs）可以识别导致心血管疾病（CVD）风险的基因标记，并进行早期预测。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病因其多因素病因及高发病率和死亡率对全球构成重大挑战，目前可用的基因组和电生理学数据虽多，但因数据维度高且噪声多，分析难度大。

Method: 通过将问题框定为“链式思考推理”任务（CoT），利用来自高通量基因组分析的基因标记，探索微调LLMs如何预测心血管疾病和可能导致心血管疾病风险的单核苷酸多态性（SNPs）。

Result: 研究发现LLMs能够从结构化与半结构化的基因组数据中学习潜在生物关系，并生成疾病标签及相关临床推论。

Conclusion: 研究证明，LLMs有潜力助力心血管疾病的早期检测、风险评估，促进个性化医疗的发展。

Abstract: Cardiovascular disease (CVD) prediction remains a tremendous challenge due to
its multifactorial etiology and global burden of morbidity and mortality.
Despite the growing availability of genomic and electrophysiological data,
extracting biologically meaningful insights from such high-dimensional, noisy,
and sparsely annotated datasets remains a non-trivial task. Recently, LLMs has
been applied effectively to predict structural variations in biological
sequences. In this work, we explore the potential of fine-tuned LLMs to predict
cardiac diseases and SNPs potentially leading to CVD risk using genetic markers
derived from high-throughput genomic profiling. We investigate the effect of
genetic patterns associated with cardiac conditions and evaluate how LLMs can
learn latent biological relationships from structured and semi-structured
genomic data obtained by mapping genetic aspects that are inherited from the
family tree. By framing the problem as a Chain of Thought (CoT) reasoning task,
the models are prompted to generate disease labels and articulate informed
clinical deductions across diverse patient profiles and phenotypes. The
findings highlight the promise of LLMs in contributing to early detection, risk
assessment, and ultimately, the advancement of personalized medicine in cardiac
care.

</details>


### [440] [A Globally Optimal Analytic Solution for Semi-Nonnegative Matrix Factorization with Nonnegative or Mixed Inputs](https://arxiv.org/abs/2508.07134)
*Lu Chenggang*

Main category: cs.LG

TL;DR: 本文提出了一种新的方法，通过输入数据的散射矩阵的正交分解，在 Frobenius 范数下对半非负矩阵分解（semi-NMF）问题提供全局最优解。


<details>
  <summary>Details</summary>
Motivation: 现有的半非负矩阵分解方法多为迭代性、非凸且易陷入局部最小值，因此需要一种能够确保全局最优的解决方案。

Method: 通过输入数据的散射矩阵的正交分解，推导出一种新的方案，在 Frobenius 范数下找到半非负矩阵分解的全局最优解，并证明其在重构误差上达到全局最小值。

Result: 验证表明，在合成数据以及 UCI Wine 数据集上，该方法在重构精度上优于现有的 NMF 和半NMF方法，特别是在低秩情况下能够完全恢复 NMF 结构。

Conclusion: 本文提供了一种具有理论保证和实验优势的全新非迭代半非负矩阵分解方法，为矩阵分解的优化和数据分析提供了新视角。

Abstract: Semi-Nonnegative Matrix Factorization (semi-NMF) extends classical
Nonnegative Matrix Factorization (NMF) by allowing the basis matrix to contain
both positive and negative entries, making it suitable for decomposing data
with mixed signs. However, most existing semi-NMF algorithms are iterative,
non-convex, and prone to local minima. In this paper, we propose a novel method
that yields a globally optimal solution to the semi-NMF problem under the
Frobenius norm, through an orthogonal decomposition derived from the scatter
matrix of the input data. We rigorously prove that our solution attains the
global minimum of the reconstruction error. Furthermore, we demonstrate that
when the input matrix is nonnegative, our method often achieves lower
reconstruction error than standard NMF algorithms, although unfortunately the
basis matrix may not satisfy nonnegativity. In particular, in low-rank cases
such as rank 1 or 2, our solution reduces exactly to a nonnegative
factorization, recovering the NMF structure. We validate our approach through
experiments on both synthetic data and the UCI Wine dataset, showing that our
method consistently outperforms existing NMF and semi-NMF methods in terms of
reconstruction accuracy. These results confirm that our globally optimal,
non-iterative formulation offers both theoretical guarantees and empirical
advantages, providing a new perspective on matrix factorization in optimization
and data analysis.

</details>


### [441] [A Stable and Principled Loss Function for Direct Language Model Alignment](https://arxiv.org/abs/2508.07137)
*Yuandong Tan*

Main category: cs.LG

TL;DR: 提出一种基于RLHF的新型损失函数，避免了DPO的不稳定性与奖励失误问题，同时提升模型生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决DPO法中因损失函数设计产生的不稳定与奖励劫持问题，提升大语言模型与人类偏好对齐效果。

Method: 设计了一种直接源于RLHF最优性条件的损失函数，限制logits差异到具体有限值，理论上避免了过大梯度产生的不稳定性。

Result: 通过在Qwen2.5-7B模型上验证，新方法显著提升了与人类偏好的对齐效果，胜率高于DPO，并在某些场景中媲美更大模型。

Conclusion: 新损失函数解决了DPO的理论不一致及实例问题，提升了语言模型的学习效率和实际表现，展示了该方法的潜在广泛应用价值。

Abstract: The alignment of large language models (LLMs) with human preferences is
commonly achieved through Reinforcement Learning from Human Feedback (RLHF).
Direct Preference Optimization (DPO) simplified this paradigm by establishing a
direct mapping between the optimal policy and a reward function, eliminating
the need for an explicit reward model. However, we argue that the DPO loss
function is theoretically misaligned with its own derivation, as it promotes
the indefinite maximization of a logits difference, which can lead to training
instability and reward hacking. In this paper, we propose a novel loss function
derived directly from the RLHF optimality condition. Our proposed loss targets
a specific, finite value for the logits difference, which is dictated by the
underlying reward, rather than its maximization. We provide a theoretical
analysis, including a gradient-based comparison, to demonstrate that our method
avoids the large gradients that plague DPO when the probability of dispreferred
responses approaches zero. This inherent stability prevents reward hacking and
leads to more effective alignment. We validate our approach by fine-tuning a
Qwen2.5-7B model, showing significant win-rate improvements over a standard DPO
baseline and achieving competitive performance against larger models like
Llama-3.1-8B.

</details>


### [442] [Strategic Incentivization for Locally Differentially Private Federated Learning](https://arxiv.org/abs/2508.07138)
*Yashwant Krishna Pagoti,Arunesh Sinha,Shamik Sural*

Main category: cs.LG

TL;DR: 本文提出了一种基于游戏论的联邦学习隐私-准确性权衡模型，结合代币激励机制，研究如何在保证隐私的前提下提高全局模型精度。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，仅共享梯度信息而不是原始数据也可能导致信息泄露。因此，作者引入局部差分隐私（LDP）来保护隐私，同时希望解决加入噪声导致全局模型准确性下降的问题。

Method: 作者将隐私-准确性权衡问题建模为一个博弈，其中服务器通过代币机制激励客户减少梯度噪声来提高模型准确性，而客户则寻求在隐私和准确性之间找到平衡。并进行策略分析和实验验证。

Result: 实验分析了不同参数对隐私与准确性权衡的影响，并验证了提出机制的有效性。

Conclusion: 所提代币激励机制在兼顾客户隐私保护和全局模型准确性方面表现出较好效果，为联邦学习带来了新的思路。

Abstract: In Federated Learning (FL), multiple clients jointly train a machine learning
model by sharing gradient information, instead of raw data, with a server over
multiple rounds. To address the possibility of information leakage in spite of
sharing only the gradients, Local Differential Privacy (LDP) is often used. In
LDP, clients add a selective amount of noise to the gradients before sending
the same to the server. Although such noise addition protects the privacy of
clients, it leads to a degradation in global model accuracy. In this paper, we
model this privacy-accuracy trade-off as a game, where the sever incentivizes
the clients to add a lower degree of noise for achieving higher accuracy, while
the clients attempt to preserve their privacy at the cost of a potential loss
in accuracy. A token based incentivization mechanism is introduced in which the
quantum of tokens credited to a client in an FL round is a function of the
degree of perturbation of its gradients. The client can later access a newly
updated global model only after acquiring enough tokens, which are to be
deducted from its balance. We identify the players, their actions and payoff,
and perform a strategic analysis of the game. Extensive experiments were
carried out to study the impact of different parameters.

</details>


### [443] [SGD Convergence under Stepsize Shrinkage in Low-Precision Training](https://arxiv.org/abs/2508.07142)
*Vincent-Daniel Yun*

Main category: cs.LG

TL;DR: 本文研究了低精度训练中的随机梯度下降（SGD）收敛特性，并提出了一种梯度收缩模型来分析收敛速度及其影响。


<details>
  <summary>Details</summary>
Motivation: 低精度训练在提高大规模深度学习计算效率和降低内存开销中非常重要，但量化梯度引入了大小缩减和噪声的问题，可能影响SGD的收敛行为。

Method: 本文提出了一个梯度收缩模型，在此模型中每个随机梯度被缩放为一个范围在（0,1]的因子，并受到零均值量化噪声干扰。通过将收缩看作是步长调整，理论分析了低精度下收敛速度的变化和误差下界。

Result: 研究表明低精度量化的SGD仍然能够收敛，但会以一个由收缩因子q_min决定的较低速率进行，同时因量化噪声带来的误差下界会增加。

Conclusion: 通过量化分析，低精度的SGD在理论上能够实现收敛，但会受梯度缩减与噪声影响，导致收敛速度变慢且最终误差升高。

Abstract: Low-precision training has become essential for reducing the computational
and memory costs of large-scale deep learning. However, quantization of
gradients introduces both magnitude shrinkage and additive noise, which can
alter the convergence behavior of stochastic gradient descent (SGD). In this
work, we study the convergence of SGD under a gradient shrinkage model, where
each stochastic gradient is scaled by a factor $q_k \in (0,1]$ and perturbed by
zero-mean quantization noise. We show that this shrinkage is equivalent to
replacing the nominal stepsize $\mu_k$ with an effective stepsize $\mu_k q_k$,
which slows convergence when $q_{\min} < 1$. Under standard smoothness and
bounded-variance assumptions, we prove that low-precision SGD still converges,
but at a reduced rate determined by $q_{\min}$, and with an increased
asymptotic error floor due to quantization noise. We theoretically analyze how
reduced numerical precision slows down training by modeling it as gradient
shrinkage in the standard SGD convergence framework.

</details>


### [444] [What One Cannot, Two Can: Two-Layer Transformers Provably Represent Induction Heads on Any-Order Markov Chains](https://arxiv.org/abs/2508.07208)
*Chanakya Ekbote,Marco Bondaschi,Nived Rajaraman,Jason D. Lee,Michael Gastpar,Ashok Vardhan Makkuva,Paul Pu Liang*

Main category: cs.LG

TL;DR: 本文探讨了两层单头Transformer是否可以表示任意k阶马尔科夫过程，提供了理论证明，并进一步分析了其学习动力学，深化了对Transformer基于上下文学习的理解。


<details>
  <summary>Details</summary>
Motivation: 通过揭示Transformer深度与马尔科夫过程之间的关系，从理论上验证浅层Transformer的能力，并探索其学习行为。

Method: 提出理论证明，两层单头Transformer可以表示任意条件k-gram，并研究其学习动力学，尤其是简化的低阶马尔科夫链。

Result: 证明了两层单头Transformer的表示能力，同时分析了其学习过程，特别针对结构化序列建模任务的内部表示生成。

Conclusion: 即使浅层Transformer架构，依然可在特定条件下展现强大的上下文学习能力，这为进一步理解Transformer在结构化任务中的表现提供了新思路。

Abstract: In-context learning (ICL) is a hallmark capability of transformers, through
which trained models learn to adapt to new tasks by leveraging information from
the input context. Prior work has shown that ICL emerges in transformers due to
the presence of special circuits called induction heads. Given the equivalence
between induction heads and conditional k-grams, a recent line of work modeling
sequential inputs as Markov processes has revealed the fundamental impact of
model depth on its ICL capabilities: while a two-layer transformer can
efficiently represent a conditional 1-gram model, its single-layer counterpart
cannot solve the task unless it is exponentially large. However, for higher
order Markov sources, the best known constructions require at least three
layers (each with a single attention head) - leaving open the question: can a
two-layer single-head transformer represent any kth-order Markov process? In
this paper, we precisely address this and theoretically show that a two-layer
transformer with one head per layer can indeed represent any conditional
k-gram. Thus, our result provides the tightest known characterization of the
interplay between transformer depth and Markov order for ICL. Building on this,
we further analyze the learning dynamics of our two-layer construction,
focusing on a simplified variant for first-order Markov chains, illustrating
how effective in-context representations emerge during training. Together,
these results deepen our current understanding of transformer-based ICL and
illustrate how even shallow architectures can surprisingly exhibit strong ICL
capabilities on structured sequence modeling tasks.

</details>


### [445] [Neural Bridge Processes](https://arxiv.org/abs/2508.07220)
*Jian Xu,Yican Liu,Qibin Zhao,John Paisley,Delu Zeng*

Main category: cs.LG

TL;DR: 提出了神经桥过程（NBPs），通过动态锚点强化扩散路径，解决了传统模型在刻画复杂目标分布时的不足，实验结果表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的高斯过程因其可扩展性和假设高斯性受限，神经过程（NPs）虽更灵活但难以捕捉复杂的多模态目标分布。

Method: 提出了一种新的方法（NBPs），通过将输入x作为动态锚点，重新定义了前向核，使得扩散路径严格终止于监督目标，提供了更强的梯度信号，且保证了终点一致性。

Result: NBPs在合成数据、EEG信号回归和图像回归任务中均表现出显著优于基线的方法的性能。

Conclusion: DDPM风格的桥采样方法有效提升了结构化预测任务的表现和理论一致性。

Abstract: Learning stochastic functions from partially observed context-target pairs is
a fundamental problem in probabilistic modeling. Traditional models like
Gaussian Processes (GPs) face scalability issues with large datasets and assume
Gaussianity, limiting their applicability. While Neural Processes (NPs) offer
more flexibility, they struggle with capturing complex, multi-modal target
distributions. Neural Diffusion Processes (NDPs) enhance expressivity through a
learned diffusion process but rely solely on conditional signals in the
denoising network, resulting in weak input coupling from an unconditional
forward process and semantic mismatch at the diffusion endpoint. In this work,
we propose Neural Bridge Processes (NBPs), a novel method for modeling
stochastic functions where inputs x act as dynamic anchors for the entire
diffusion trajectory. By reformulating the forward kernel to explicitly depend
on x, NBP enforces a constrained path that strictly terminates at the
supervised target. This approach not only provides stronger gradient signals
but also guarantees endpoint coherence. We validate NBPs on synthetic data, EEG
signal regression and image regression tasks, achieving substantial
improvements over baselines. These results underscore the effectiveness of
DDPM-style bridge sampling in enhancing both performance and theoretical
consistency for structured prediction tasks.

</details>


### [446] [LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference](https://arxiv.org/abs/2508.07221)
*Po-Han Lee,Yu-Cheng Lin,Chan-Tung Ku,Chan Hsu,Pei-Cing Huang,Ping-Hsun Wu,Yihuang Kang*

Main category: cs.LG

TL;DR: 本文提出使用基于大语言模型的代理来加强因果机器学习方法应对现实环境的复杂性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理未测量混杂和复杂现实环境（如潜在混杂因素或非结构化格式的数据）时表现有限。此外，目前流程对领域专家的依赖提高了标注成本并限制了可扩展性。

Method: 提出了一种基于大语言模型的因果机器学习框架，利用LLM代理实现自动化混杂因素发现与亚组分析，以降低对领域专家的依赖。

Result: 实验表明该方法在实际医学数据上表现优异，不仅强化了治疗效果估计的稳健性，还缩小了置信区间并揭示了未识别的混杂偏差。

Conclusion: 基于LLM的代理为实现可扩展、可信且具有语义意识的因果推断提供了新途径。

Abstract: Estimating individualized treatment effects from observational data presents
a persistent challenge due to unmeasured confounding and structural bias.
Causal Machine Learning (causal ML) methods, such as causal trees and doubly
robust estimators, provide tools for estimating conditional average treatment
effects. These methods have limited effectiveness in complex real-world
environments due to the presence of latent confounders or those described in
unstructured formats. Moreover, reliance on domain experts for confounder
identification and rule interpretation introduces high annotation cost and
scalability concerns. In this work, we proposed Large Language Model-based
agents for automated confounder discovery and subgroup analysis that integrate
agents into the causal ML pipeline to simulate domain expertise. Our framework
systematically performs subgroup identification and confounding structure
discovery by leveraging the reasoning capabilities of LLM-based agents, which
reduces human dependency while preserving interpretability. Experiments on
real-world medical datasets show that our proposed approach enhances treatment
effect estimation robustness by narrowing confidence intervals and uncovering
unrecognized confounding biases. Our findings suggest that LLM-based agents
offer a promising path toward scalable, trustworthy, and semantically aware
causal inference.

</details>


### [447] [EDGE: A Theoretical Framework for Misconception-Aware Adaptive Learning](https://arxiv.org/abs/2508.07224)
*Ananda Prakash Verma*

Main category: cs.LG

TL;DR: EDGE是一个结合心理测量学、认知诊断、对比生成和调度的学习框架，提供误解发现和矫正的综合方法。


<details>
  <summary>Details</summary>
Motivation: 这个研究的动机是解决学生学习中的误解问题，通过提供一种自适应的框架提高纠正效率。

Method: 该框架有四阶段：1）能力和状态评估，2）误解诊断，3）生成对抗性问题，4）基于索引的检索调度。同时，提出了EdgeScore度量指标，并证明其理论属性。

Result: 证明了该框架的理论可行性及其在减少目标误解的效率上的优势，但尚未进行实证研究。

Conclusion: EDGE框架通过与心理测量、误解诊断和对抗性生成的结合，提供了一种系统的方法解决学习中的误解问题。

Abstract: We present EDGE, a general-purpose, misconception-aware adaptive learning
framework composed of four stages: Evaluate (ability and state estimation),
Diagnose (posterior infer-ence of misconceptions), Generate (counterfactual
item synthesis), and Exercise (index-based retrieval scheduling). EDGE unifies
psychometrics (IRT/Bayesian state space models), cog-nitive diagnostics
(misconception discovery from distractor patterns and response latencies),
contrastive item generation (minimal perturbations that invalidate learner
shortcuts while pre-serving psychometric validity), and principled scheduling
(a restless bandit approximation to spaced retrieval). We formalize a composite
readiness metric, EdgeScore, prove its monotonicity and Lipschitz continuity,
and derive an index policy that is near-optimal under mild assumptions on
forgetting and learning gains. We further establish conditions under which
counterfactual items provably reduce the posterior probability of a targeted
misconception faster than standard practice. The paper focuses on theory and
implementable pseudocode; empirical study is left to future work.

</details>


### [448] [Causal Negative Sampling via Diffusion Model for Out-of-Distribution Recommendation](https://arxiv.org/abs/2508.07243)
*Chu Zhao,Eneng Yang,Yizhou Dang,Jianzhe Zhao,Guibing Guo,Xingwei Wang*

Main category: cs.LG

TL;DR: CNSDiff通过在潜在空间中合成负样本，避免传统负采样的偏差问题并提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在推荐系统中，传统的负采样方法可能引入伪难负样本（FHNS），导致模型学习到环境混杂因子引起的伪相关性，从而降低模型的泛化能力。

Method: 提出CNSDiff方法，通过条件扩散过程合成潜在空间中的负样本，同时引入因果正则化项以减少环境混杂因子的影响，从而改进分布变化情况下的泛化能力。

Result: 在四种典型分布变化场景下，CNSDiff在所有评价指标上平均提升13.96%，相比于现有最先进的基线方法展现出更高效和更强的鲁棒性。

Conclusion: CNSDiff有效解决了传统负采样方法引入的偏差问题，并显著提升了分布变化下推荐任务的表现能力。

Abstract: Heuristic negative sampling enhances recommendation performance by selecting
negative samples of varying hardness levels from predefined candidate pools to
guide the model toward learning more accurate decision boundaries. However, our
empirical and theoretical analyses reveal that unobserved environmental
confounders (e.g., exposure or popularity biases) in candidate pools may cause
heuristic sampling methods to introduce false hard negatives (FHNS). These
misleading samples can encourage the model to learn spurious correlations
induced by such confounders, ultimately compromising its generalization ability
under distribution shifts. To address this issue, we propose a novel method
named Causal Negative Sampling via Diffusion (CNSDiff). By synthesizing
negative samples in the latent space via a conditional diffusion process,
CNSDiff avoids the bias introduced by predefined candidate pools and thus
reduces the likelihood of generating FHNS. Moreover, it incorporates a causal
regularization term to explicitly mitigate the influence of environmental
confounders during the negative sampling process, leading to robust negatives
that promote out-of-distribution (OOD) generalization. Comprehensive
experiments under four representative distribution shift scenarios demonstrate
that CNSDiff achieves an average improvement of 13.96% across all evaluation
metrics compared to state-of-the-art baselines, verifying its effectiveness and
robustness in OOD recommendation tasks.

</details>


### [449] [Policy Newton methods for Distortion Riskmetrics](https://arxiv.org/abs/2508.07249)
*Soumen Pachal,Mizhaan Prajit Maniyar,Prashanth L. A*

Main category: cs.LG

TL;DR: 本文探讨了强化学习框架中的风险敏感控制问题，提出了一个基于DRM的风险最优策略求解算法，并证明其能够收敛至二阶平稳点。


<details>
  <summary>Details</summary>
Motivation: 在强化学习的场景中，研究能够更有效评估风险的策略，以提高决策质量。

Method: 利用DRM描述折扣奖励风险度量，结合DRM梯度和Hessian估计，提出三次正则化策略牛顿算法，保证算法收敛到二阶平稳点，同时避免鞍点。

Result: 算法收敛的样本复杂度为$\mathcal{O}(\epsilon^{-3.5})$，实验验证了理论结果。

Conclusion: 该工作首次实现了风险敏感目标的$\epsilon$-二阶平稳点收敛，为风险敏感的强化学习问题提供了新理论与方法。

Abstract: We consider the problem of risk-sensitive control in a reinforcement learning
(RL) framework. In particular, we aim to find a risk-optimal policy by
maximizing the distortion riskmetric (DRM) of the discounted reward in a finite
horizon Markov decision process (MDP). DRMs are a rich class of risk measures
that include several well-known risk measures as special cases. We derive a
policy Hessian theorem for the DRM objective using the likelihood ratio method.
Using this result, we propose a natural DRM Hessian estimator from sample
trajectories of the underlying MDP. Next, we present a cubic-regularized policy
Newton algorithm for solving this problem in an on-policy RL setting using
estimates of the DRM gradient and Hessian. Our proposed algorithm is shown to
converge to an $\epsilon$-second-order stationary point ($\epsilon$-SOSP) of
the DRM objective, and this guarantee ensures the escaping of saddle points.
The sample complexity of our algorithms to find an $ \epsilon$-SOSP is
$\mathcal{O}(\epsilon^{-3.5})$. Our experiments validate the theoretical
findings. To the best of our knowledge, our is the first work to present
convergence to an $\epsilon$-SOSP of a risk-sensitive objective, while existing
works in the literature have either shown convergence to a first-order
stationary point of a risk-sensitive objective, or a SOSP of a risk-neutral
one.

</details>


### [450] [PySeizure: A single machine learning classifier framework to detect seizures in diverse datasets](https://arxiv.org/abs/2508.07253)
*Bartlomiej Chybowski,Shima Abdullateef,Hollan Haule,Alfredo Gonzalez-Sulser,Javier Escudero*

Main category: cs.LG

TL;DR: 本文提出了一种开源的机器学习框架，用于跨多种临床数据集实现鲁棒且具有普适性的癫痫发作检测，显著减少手动EEG解读的时间需求。


<details>
  <summary>Details</summary>
Motivation: 目前癫痫检测依赖于耗时的EEG手动解读，而现有机器学习方法因数据集特定优化受限，因此需要一种能在不同数据集间通用的解决方案。

Method: 设计了一种包含自动预处理管道和多数投票机制的开源机器学习框架，并在两个临床EEG公开数据集上进行训练、调试及评估，验证其跨数据集迁移性。

Result: 在数据集内部和跨数据集间测试中，该框架均表现出较高的性能（AUC最高达0.913和0.867，跨数据集AUC也有显著水平）。轻度后处理进一步提升了性能。

Conclusion: 本文提出的框架在真实临床环境中展现了优秀的推广能力，为实现通用且可复现的癫痫检测提供了基础，同时可作为专家判断的补充，加速临床整合。

Abstract: Reliable seizure detection is critical for diagnosing and managing epilepsy,
yet clinical workflows remain dependent on time-consuming manual EEG
interpretation. While machine learning has shown promise, existing approaches
often rely on dataset-specific optimisations, limiting their real-world
applicability and reproducibility. Here, we introduce an innovative,
open-source machine-learning framework that enables robust and generalisable
seizure detection across varied clinical datasets. We evaluate our approach on
two publicly available EEG datasets that differ in patient populations and
electrode configurations. To enhance robustness, the framework incorporates an
automated pre-processing pipeline to standardise data and a majority voting
mechanism, in which multiple models independently assess each second of EEG
before reaching a final decision. We train, tune, and evaluate models within
each dataset, assessing their cross-dataset transferability. Our models achieve
high within-dataset performance (AUC 0.904+/-0.059 for CHB-MIT and
0.864+/-0.060 for TUSZ) and demonstrate strong generalisation across datasets
despite differences in EEG setups and populations (AUC 0.615+/-0.039 for models
trained on CHB-MIT and tested on TUSZ and 0.762+/-0.175 in the reverse case)
without any post-processing. Furthermore, a mild post-processing improved the
within-dataset results to 0.913+/-0.064 and 0.867+/-0.058 and cross-dataset
results to 0.619+/-0.036 and 0.768+/-0.172. These results underscore the
potential of, and essential considerations for, deploying our framework in
diverse clinical settings. By making our methodology fully reproducible, we
provide a foundation for advancing clinically viable, dataset-agnostic seizure
detection systems. This approach has the potential for widespread adoption,
complementing rather than replacing expert interpretation, and accelerating
clinical integration.

</details>


### [451] [Revisiting Data Attribution for Influence Functions](https://arxiv.org/abs/2508.07297)
*Hongbo Zhu,Angelo Cangelosi*

Main category: cs.LG

TL;DR: 本文全面评估了影响函数在深度学习中的数据归因能力，探讨了理论基础、算法改进及其在数据归因和错误标签检测中的效果，并展望了未来的挑战和方向。


<details>
  <summary>Details</summary>
Motivation: 致力于追溯模型预测至训练数据，从而理解模型的行为和决策过程，并解决机器学习中的可解释性、数据调试和模型责任等关键问题。

Method: 利用影响函数，通过高效的逆Hessian-向量积估计，提供一种一阶近似方法，评估对模型参数及预测的边际权重调整影响，无需昂贵的重新训练。

Result: 分析了影响函数的理论基础，算法改进和其在数据归因及错误标签检测的实际效果，同时提出了影响函数在大规模深度学习场景中的潜力和挑战。

Conclusion: 影响函数是利用统计方法进行数据归因的重要工具，尽管具有挑战性，但是在大型深度学习系统中应用潜力巨大。

Abstract: The goal of data attribution is to trace the model's predictions through the
learning algorithm and back to its training data. thereby identifying the most
influential training samples and understanding how the model's behavior leads
to particular predictions. Understanding how individual training examples
influence a model's predictions is fundamental for machine learning
interpretability, data debugging, and model accountability. Influence
functions, originating from robust statistics, offer an efficient, first-order
approximation to estimate the impact of marginally upweighting or removing a
data point on a model's learned parameters and its subsequent predictions,
without the need for expensive retraining. This paper comprehensively reviews
the data attribution capability of influence functions in deep learning. We
discuss their theoretical foundations, recent algorithmic advances for
efficient inverse-Hessian-vector product estimation, and evaluate their
effectiveness for data attribution and mislabel detection. Finally,
highlighting current challenges and promising directions for unleashing the
huge potential of influence functions in large-scale, real-world deep learning
scenarios.

</details>


### [452] [When Is Prior Knowledge Helpful? Exploring the Evaluation and Selection of Unsupervised Pretext Tasks from a Neuro-Symbolic Perspective](https://arxiv.org/abs/2508.07299)
*Lin-Han Jia,Si-Yu Han,Wen-Chao Hu,Jie-Jing Shao,Wen-Da Wei,Zhi Zhou,Lan-Zhe Guo,Yu-Feng Li*

Main category: cs.LG

TL;DR: 本文提出了一种统一的理论框架，将神经符号学习(Nesy)和半/自监督学习(SSL)相结合，能够预测无监督任务的效果，并用实验验证了这个理论的有效性。


<details>
  <summary>Details</summary>
Motivation: 目前无监督任务的选择通常是基于启发式的，而缺乏理论支持，该研究旨在改变这一现状，通过统一框架预测无监督任务的有效性。

Method: 通过严格理论分析，结合知识的可学习性、可靠性和完备性，提出了可操作化的指标体系来预测无监督任务的有效性。

Result: 通过实验验证，所提出的方法可以使用少量数据预测目标任务之后的表现，验证了理论和方法的有效性。

Conclusion: 通过理论与实验，证明了预测无监督任务效果的可能性，开发了一种从理论上选择和评估无监督任务的新方法，为实际应用中任务选择提供了方向。

Abstract: Neuro-symbolic (Nesy) learning improves the target task performance of models
by enabling them to satisfy knowledge, while semi/self-supervised learning
(SSL) improves the target task performance by designing unsupervised pretext
tasks for unlabeled data to make models satisfy corresponding assumptions. We
extend the Nesy theory based on reliable knowledge to the scenario of
unreliable knowledge (i.e., assumptions), thereby unifying the theoretical
frameworks of SSL and Nesy. Through rigorous theoretical analysis, we
demonstrate that, in theory, the impact of pretext tasks on target performance
hinges on three factors: knowledge learnability with respect to the model,
knowledge reliability with respect to the data, and knowledge completeness with
respect to the target. We further propose schemes to operationalize these
theoretical metrics, and thereby develop a method that can predict the
effectiveness of pretext tasks in advance. This will change the current status
quo in practical applications, where the selections of unsupervised tasks are
heuristic-based rather than theory-based, and it is difficult to evaluate the
rationality of unsupervised pretext task selection before testing the model on
the target task. In experiments, we verify a high correlation between the
predicted performance-estimated using minimal data-and the actual performance
achieved after large-scale semi-supervised or self-supervised learning, thus
confirming the validity of the theory and the effectiveness of the evaluation
method.

</details>


### [453] [Efficient Edge LLMs Deployment via HessianAware Quantization and CPU GPU Collaborative](https://arxiv.org/abs/2508.07329)
*Tuo Zhang,Ning Li,Xin Yuan,Wenchao Xu,Quan Chen,Song Guo,Haijun Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种基于Hessian-Aware Quantization (HAQ) 和 CPU-GPU协同推断的高效MoE边缘部署方案，解决了大语言模型在资源受限设备上的量化准确性下降和推理效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）在自然语言处理与多模态任务中的突破性进展，如何在资源受限的边缘设备上高效部署这些模型成为了迫切需要解决的问题。

Method: 本文提出两大方法：(1) 利用平滑Hessian矩阵量化实现激活和权重的联合8位量化，从而解决量化准确性因出liers问题导致的下降；(2) 设计基于专家级别的协同卸载与推断机制，结合激活路径统计，优化专家模块在CPU和GPU间的部署与调度。

Result: 通过在主流大模型(如OPT系列和Mixtral 8*7B)上的实验，方法显著降低了GPU内存使用(约60%)，推理延迟大幅改善，并且量化模型的推理精度接近全精度模型在Wikitext2和C4数据集上的表现。

Conclusion: 提出的MoE边缘部署方法显著提高了在资源受限设备上推理的准确性及效率，为大语言模型边缘计算的实际部署提供了可行的解决方案。

Abstract: With the breakthrough progress of large language models (LLMs) in natural
language processing and multimodal tasks, efficiently deploying them on
resource-constrained edge devices has become a critical challenge. The Mixture
of Experts (MoE) architecture enhances model capacity through sparse
activation, but faces two major difficulties in practical deployment: (1) The
presence of numerous outliers in activation distributions leads to severe
degradation in quantization accuracy for both activations and weights,
significantly impairing inference performance; (2) Under limited memory,
efficient offloading and collaborative inference of expert modules struggle to
balance latency and throughput. To address these issues, this paper proposes an
efficient MoE edge deployment scheme based on Hessian-Aware Quantization (HAQ)
and CPU-GPU collaborative inference. First, by introducing smoothed Hessian
matrix quantization, we achieve joint 8-bit quantization of activations and
weights, which significantly alleviates the accuracy loss caused by outliers
while ensuring efficient implementation on mainstream hardware. Second, we
design an expert-level collaborative offloading and inference mechanism, which,
combined with expert activation path statistics, enables efficient deployment
and scheduling of expert modules between CPU and GPU, greatly reducing memory
footprint and inference latency. Extensive experiments validate the
effectiveness of our method on mainstream large models such as the OPT series
and Mixtral 8*7B: on datasets like Wikitext2 and C4, the inference accuracy of
the low-bit quantized model approaches that of the full-precision model, while
GPU memory usage is reduced by about 60%, and inference latency is
significantly improved.

</details>


### [454] [Finite-Time Convergence Analysis of ODE-based Generative Models for Stochastic Interpolants](https://arxiv.org/abs/2508.07333)
*Yuhao Liu,Rui Hu,Yu Chen,Longbo Huang*

Main category: cs.LG

TL;DR: 论文研究了基于随机插值的常微分方程（ODE）数值求解的有限时间收敛性，特别是对前向欧拉法和二阶Heun方法进行了误差边界分析。


<details>
  <summary>Details</summary>
Motivation: 随机插值可以实现样本在任意数据分布间的连续变换，是生成模型的有力工具。然而，其数值方案的有限时间收敛性保障尚待深入研究。

Method: 提出了对两种数值积分方法（前向欧拉法与二阶Heun法）的误差边界进行分析，并研究了特定随机插值构建的迭代复杂性，为计算效率提供优化调度方案。

Result: 通过理论分析得出了误差边界与优化调度方法，数值实验验证了这些结果的有效性。

Conclusion: 本文为基于随机插值的数值求解提供了严格的理论支撑，并通过优化调度提升了计算效率，验证结果显示该方法在实践中具有可行性。

Abstract: Stochastic interpolants offer a robust framework for continuously
transforming samples between arbitrary data distributions, holding significant
promise for generative modeling. Despite their potential, rigorous finite-time
convergence guarantees for practical numerical schemes remain largely
unexplored. In this work, we address the finite-time convergence analysis of
numerical implementations for ordinary differential equations (ODEs) derived
from stochastic interpolants. Specifically, we establish novel finite-time
error bounds in total variation distance for two widely used numerical
integrators: the first-order forward Euler method and the second-order Heun's
method. Furthermore, our analysis on the iteration complexity of specific
stochastic interpolant constructions provides optimized schedules to enhance
computational efficiency. Our theoretical findings are corroborated by
numerical experiments, which validate the derived error bounds and complexity
analyses.

</details>


### [455] [ProteoKnight: Convolution-based phage virion protein classification and uncertainty analysis](https://arxiv.org/abs/2508.07345)
*Samiha Afaf Neha,Abir Ahammed Bhuiyan,Md. Ishrak Khan*

Main category: cs.LG

TL;DR: 提出了ProteoKnight，一种基于图像的新编码方法，提高了噬菌体蛋白质分类的性能，并利用蒙特卡罗Dropout进行预测不确定性评估。


<details>
  <summary>Details</summary>
Motivation: 当前用于噬菌体蛋白质序列注释的计算工具需要更专业的序列编码来提高预测性能。

Method: 设计了ProteoKnight，通过改进的DNA-Walk算法为蛋白质序列创建图像编码，并使用预训练卷积神经网络进行分类；同时采用蒙特卡罗Dropout评估预测不确定性。

Result: 二分类准确率达到90.8%，与先进方法相当；多分类准确率仍需改进；揭示了分类信心受蛋白质类别及序列长度的影响。

Conclusion: ProteoKnight通过改进编码策略有效缓解了空间信息损失问题，在提供准确预测的同时识别低置信度分类结果，优于传统方法。

Abstract: \textbf{Introduction:} Accurate prediction of Phage Virion Proteins (PVP) is
essential for genomic studies due to their crucial role as structural elements
in bacteriophages. Computational tools, particularly machine learning, have
emerged for annotating phage protein sequences from high-throughput sequencing.
However, effective annotation requires specialized sequence encodings. Our
paper introduces ProteoKnight, a new image-based encoding method that addresses
spatial constraints in existing techniques, yielding competitive performance in
PVP classification using pre-trained convolutional neural networks.
Additionally, our study evaluates prediction uncertainty in binary PVP
classification through Monte Carlo Dropout (MCD). \textbf{Methods:}
ProteoKnight adapts the classical DNA-Walk algorithm for protein sequences,
incorporating pixel colors and adjusting walk distances to capture intricate
protein features. Encoded sequences were classified using multiple pre-trained
CNNs. Variance and entropy measures assessed prediction uncertainty across
proteins of various classes and lengths. \textbf{Results:} Our experiments
achieved 90.8% accuracy in binary classification, comparable to
state-of-the-art methods. Multi-class classification accuracy remains
suboptimal. Our uncertainty analysis unveils variability in prediction
confidence influenced by protein class and sequence length.
\textbf{Conclusions:} Our study surpasses frequency chaos game representation
(FCGR) by introducing novel image encoding that mitigates spatial information
loss limitations. Our classification technique yields accurate and robust PVP
predictions while identifying low-confidence predictions.

</details>


### [456] [Intrinsic training dynamics of deep neural networks](https://arxiv.org/abs/2508.07370)
*Sibylle Marcotte,Gabriel Peyré,Rémi Gribonval*

Main category: cs.LG

TL;DR: 研究高维梯度流动如何简化为低维梯度流动，为理解深度学习中的隐式偏差提供理论支持。


<details>
  <summary>Details</summary>
Motivation: 探索深度学习中高维参数空间的梯度流动是否可以由低维结构表达，从而揭示隐式偏差。

Method: 通过定义隐式动态属性并引入内在梯度流动，分析用函数φ将高维梯度流映射到低维；应用于ReLU网络和线性网络，研究了初始化条件对维度简化的影响。

Result: 针对ReLU网络提出了基于路径提升的内在梯度流动理论，并推广了线性网络的平衡初始化结论，发现宽松平衡初始化在某些条件下是保障内在动态的唯一选择。

Conclusion: 证明在特定初始化情况下，高维梯度的维度简化是可能的，为理解深度学习的隐式偏差提供了新的理论工具。

Abstract: A fundamental challenge in the theory of deep learning is to understand
whether gradient-based training in high-dimensional parameter spaces can be
captured by simpler, lower-dimensional structures, leading to so-called
implicit bias. As a stepping stone, we study when a gradient flow on a
high-dimensional variable $\theta$ implies an intrinsic gradient flow on a
lower-dimensional variable $z = \phi(\theta)$, for an architecture-related
function $\phi$. We express a so-called intrinsic dynamic property and show how
it is related to the study of conservation laws associated with the
factorization $\phi$. This leads to a simple criterion based on the inclusion
of kernels of linear maps which yields a necessary condition for this property
to hold. We then apply our theory to general ReLU networks of arbitrary depth
and show that, for any initialization, it is possible to rewrite the flow as an
intrinsic dynamic in a lower dimension that depends only on $z$ and the
initialization, when $\phi$ is the so-called path-lifting. In the case of
linear networks with $\phi$ the product of weight matrices, so-called balanced
initializations are also known to enable such a dimensionality reduction; we
generalize this result to a broader class of {\em relaxed balanced}
initializations, showing that, in certain configurations, these are the
\emph{only} initializations that ensure the intrinsic dynamic property.
Finally, for the linear neural ODE associated with the limit of infinitely deep
linear networks, with relaxed balanced initialization, we explicitly express
the corresponding intrinsic dynamics.

</details>


### [457] [Tight Bounds for Schrödinger Potential Estimation in Unpaired Image-to-Image Translation Problems](https://arxiv.org/abs/2508.07392)
*Nikita Puchkin,Denis Suchkov,Alexey Naumov,Denis Belomestny*

Main category: cs.LG

TL;DR: 本文研究了基于薛定谔桥和随机最优控制理论的生成建模和无监督图像到图像转换方法，提出了鲁棒的生成方法并分析了其误差边界。


<details>
  <summary>Details</summary>
Motivation: 现代的生成建模和无监督图像翻译需求将一种初始分布高效地转换为目标分布，而数据往往仅以初始和目标分布的样本形式出现，这驱动了当前方法的提出。

Method: 本文采用随机最优控制方法，选择Ornstein-Uhlenbeck过程作为参考过程，估算薛定谔势能；通过KL散度定义风险函数，推导出了泛化能力的误差界。

Result: 结果表明，该框架在某些情况下几乎达到了快速收敛率，实验验证了其性能的有效性。

Conclusion: 这一方法为生成建模和图像翻译提供了一种高效、理论严密的解决方案。

Abstract: Modern methods of generative modelling and unpaired image-to-image
translation based on Schr\"odinger bridges and stochastic optimal control
theory aim to transform an initial density to a target one in an optimal way.
In the present paper, we assume that we only have access to i.i.d. samples from
initial and final distributions. This makes our setup suitable for both
generative modelling and unpaired image-to-image translation. Relying on the
stochastic optimal control approach, we choose an Ornstein-Uhlenbeck process as
the reference one and estimate the corresponding Schr\"odinger potential.
Introducing a risk function as the Kullback-Leibler divergence between
couplings, we derive tight bounds on generalization ability of an empirical
risk minimizer in a class of Schr\"odinger potentials including Gaussian
mixtures. Thanks to the mixing properties of the Ornstein-Uhlenbeck process, we
almost achieve fast rates of convergence up to some logarithmic factors in
favourable scenarios. We also illustrate performance of the suggested approach
with numerical experiments.

</details>


### [458] [Parity Requires Unified Input Dependence and Negative Eigenvalues in SSMs](https://arxiv.org/abs/2508.07395)
*Behnoush Khavari,Mehran Shakerinava,Jayesh Khullar,Jerry Huang,François Rivest,Siamak Ravanbakhsh,Sarath Chandar*

Main category: cs.LG

TL;DR: 本文探讨了传统LRNN模型（如S4D、Mamba和DeltaNet）在状态跟踪任务中的缺陷，并验证了引入输入依赖的、包含负特征值的循环层的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有LRNN模型在状态跟踪任务中性能受限，需探索增强模型状态跟踪能力的设计思路。

Method: 通过理论分析和实验，验证了输入依赖的传递矩阵和负特征值对解决状态跟踪任务（如Parity问题）的关键作用。

Result: 确定了即使是多层SSM（对角传递矩阵）的组合，仍然无法解决Parity任务，证明需引入输入相关性与负特征值。

Conclusion: 研究表明，状态跟踪任务需要循环层具备输入依赖性及负特征值，这为高效SSM模型的设计提供了方向。

Abstract: Recent work has shown that LRNN models such as S4D, Mamba, and DeltaNet lack
state-tracking capability due to either time-invariant transition matrices or
restricted eigenvalue ranges. To address this, input-dependent transition
matrices, particularly those that are complex or non-triangular, have been
proposed to enhance SSM performance on such tasks. While existing theorems
demonstrate that both input-independent and non-negative SSMs are incapable of
solving simple state-tracking tasks, such as parity, regardless of depth, they
do not explore whether combining these two types in a multilayer SSM could
help. We investigate this question for efficient SSMs with diagonal transition
matrices and show that such combinations still fail to solve parity. This
implies that a recurrence layer must both be input-dependent and include
negative eigenvalues. Our experiments support this conclusion by analyzing an
SSM model that combines S4D and Mamba layers.

</details>


### [459] [Efficient Reward Identification In Max Entropy Reinforcement Learning with Sparsity and Rank Priors](https://arxiv.org/abs/2508.07400)
*Mohamad Louai Shehab,Alperen Tercan,Necmiye Ozay*

Main category: cs.LG

TL;DR: 本文研究了如何从最优策略或演示中恢复时变奖励函数，提出了两种假设并基于此设计了有效的优化算法。


<details>
  <summary>Details</summary>
Motivation: 当前从最优策略或演示中推导奖励函数的问题在没有额外假设的情况下是不适定的。然而，许多应用场景中奖励函数具有稀疏性或可以通过少量特征函数线性组合表示。

Method: 提出了两种奖励假设：(1) 奖励函数大部分不变且变动少；(2) 奖励可以通过少量特征函数的线性组合表示。基于此，通过将奖励函数的恢复问题转化为稀疏化或秩最小化问题，设计了多项式时间优化算法来解决。

Result: 所提出的两种方法均通过优化来有效恢复奖励函数，并通过实验展示了高准确性和广泛的泛化能力。

Conclusion: 引入了两种有效的假设和相应的算法，可精确且高效地恢复时变奖励函数，为解决奖励恢复问题提供了新思路。

Abstract: In this paper, we consider the problem of recovering time-varying reward
functions from either optimal policies or demonstrations coming from a max
entropy reinforcement learning problem. This problem is highly ill-posed
without additional assumptions on the underlying rewards. However, in many
applications, the rewards are indeed parsimonious, and some prior information
is available. We consider two such priors on the rewards: 1) rewards are mostly
constant and they change infrequently, 2) rewards can be represented by a
linear combination of a small number of feature functions. We first show that
the reward identification problem with the former prior can be recast as a
sparsification problem subject to linear constraints. Moreover, we give a
polynomial-time algorithm that solves this sparsification problem exactly.
Then, we show that identifying rewards representable with the minimum number of
features can be recast as a rank minimization problem subject to linear
constraints, for which convex relaxations of rank can be invoked. In both
cases, these observations lead to efficient optimization-based reward
identification algorithms. Several examples are given to demonstrate the
accuracy of the recovered rewards as well as their generalizability.

</details>


### [460] [Lightning Prediction under Uncertainty: DeepLight with Hazy Loss](https://arxiv.org/abs/2508.07428)
*Md Sultanul Arifin,Abu Nowshed Sakib,Yeasir Rayhan,Tanzima Hashem*

Main category: cs.LG

TL;DR: 本研究提出了一种名为DeepLight的深度学习架构，专注于改进雷电预测准确性，通过多源气象数据与特定损失函数实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 雷电对人类生命财产和经济安全构成威胁，特别在气候变化加剧的背景下，提出更先进的预测方法有重要意义。

Method: 使用名为DeepLight的深度学习模型，整合多源气象数据（例如雷达反射率、云层特性和历史雷电记录），采用双编码器架构和多分支卷积技术捕捉动态空间相关性，同时设计Hazy Loss函数处理时空不确定性。

Result: DeepLight模型相比其他最先进方法提升了18%-30%的ETS值，并在雷电预测上表现出强大的优越性能。

Conclusion: DeepLight为雷电预测提供了一种高效而精确的解决方案，能够有效降低雷电相关风险，可作为雷电预测领域的重要技术。

Abstract: Lightning, a common feature of severe meteorological conditions, poses
significant risks, from direct human injuries to substantial economic losses.
These risks are further exacerbated by climate change. Early and accurate
prediction of lightning would enable preventive measures to safeguard people,
protect property, and minimize economic losses. In this paper, we present
DeepLight, a novel deep learning architecture for predicting lightning
occurrences. Existing prediction models face several critical limitations: they
often struggle to capture the dynamic spatial context and inherent uncertainty
of lightning events, underutilize key observational data, such as radar
reflectivity and cloud properties, and rely heavily on Numerical Weather
Prediction (NWP) systems, which are both computationally expensive and highly
sensitive to parameter settings. To overcome these challenges, DeepLight
leverages multi-source meteorological data, including radar reflectivity, cloud
properties, and historical lightning occurrences through a dual-encoder
architecture. By employing multi-branch convolution techniques, it dynamically
captures spatial correlations across varying extents. Furthermore, its novel
Hazy Loss function explicitly addresses the spatio-temporal uncertainty of
lightning by penalizing deviations based on proximity to true events, enabling
the model to better learn patterns amidst randomness. Extensive experiments
show that DeepLight improves the Equitable Threat Score (ETS) by 18%-30% over
state-of-the-art methods, establishing it as a robust solution for lightning
prediction.

</details>


### [461] [Unsupervised operator learning approach for dissipative equations via Onsager principle](https://arxiv.org/abs/2508.07440)
*Zhipeng Chang,Zhenye Wen,Xiaofei Zhao*

Main category: cs.LG

TL;DR: 提出了一种无需高精度标记数据的无监督解法：深度Onsager算子学习（DOOL）方法，用于解决耗散方程，在数值实验中表现优秀。


<details>
  <summary>Details</summary>
Motivation: 现有算子学习依赖高成本的高精度模拟数据，研究试图提出一种更高效的方法。

Method: 方法基于Onsager变分原理，通过直接最小化由OVP定义的Rayleigh函数，无需标记数据；并采用空间和时间解耦策略提升效率，同时利用外部时间步长进行时间外推。

Result: 该方法在典型耗散方程上的数值实验验证其效果，并与监督式方法（DeepONet和MIONet）对比表现更优。

Conclusion: DOOL方法无需高精度监督数据，在处理耗散方程中具有高效性，并扩展适用于不直接遵循OVP的模型。

Abstract: Existing operator learning methods rely on supervised training with
high-fidelity simulation data, introducing significant computational cost. In
this work, we propose the deep Onsager operator learning (DOOL) method, a novel
unsupervised framework for solving dissipative equations. Rooted in the Onsager
variational principle (OVP), DOOL trains a deep operator network by directly
minimizing the OVP-defined Rayleighian functional, requiring no labeled data,
and then proceeds in time explicitly through conservation/change laws for the
solution. Another key innovation here lies in the spatiotemporal decoupling
strategy: the operator's trunk network processes spatial coordinates
exclusively, thereby enhancing training efficiency, while integrated external
time stepping enables temporal extrapolation. Numerical experiments on typical
dissipative equations validate the effectiveness of the DOOL method, and
systematic comparisons with supervised DeepONet and MIONet demonstrate its
enhanced performance. Extensions are made to cover the second-order wave models
with dissipation that do not directly follow OVP.

</details>


### [462] [Stackelberg Coupling of Online Representation Learning and Reinforcement Learning](https://arxiv.org/abs/2508.07452)
*Fernando Martinez,Tao Li,Yingdong Lu,Juntao Chen*

Main category: cs.LG

TL;DR: 本文提出了一种名为SCORER的框架，通过引入Stackelberg博弈的方法优化感知网络和控制网络的交互，以提升深度强化学习性能。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在学习稀疏奖励信号的特征时面临挑战，现有方法由于目标复杂或过程解耦，增加了设计复杂度，因此需要新的解决方案。

Method: 作者通过将感知网络和控制网络的交互建模为Stackelberg博弈，提出了SCORER框架，其中感知网络作为领导者优化特征，使控制网络（跟随者）能够最小化自身的Bellman误差，并通过双时间尺度算法逼近博弈的均衡解。

Result: SCORER在标准DQN变体及基准任务中提高了样本效率和最终性能。

Conclusion: 通过对感知-控制动态的原则性算法设计，无需复杂的辅助目标或架构即可提升强化学习的性能。

Abstract: Integrated, end-to-end learning of representations and policies remains a
cornerstone of deep reinforcement learning (RL). However, to address the
challenge of learning effective features from a sparse reward signal, recent
trends have shifted towards adding complex auxiliary objectives or fully
decoupling the two processes, often at the cost of increased design complexity.
This work proposes an alternative to both decoupling and naive end-to-end
learning, arguing that performance can be significantly improved by structuring
the interaction between distinct perception and control networks with a
principled, game-theoretic dynamic. We formalize this dynamic by introducing
the Stackelberg Coupled Representation and Reinforcement Learning (SCORER)
framework, which models the interaction between perception and control as a
Stackelberg game. The perception network (leader) strategically learns features
to benefit the control network (follower), whose own objective is to minimize
its Bellman error. We approximate the game's equilibrium with a practical
two-timescale algorithm. Applied to standard DQN variants on benchmark tasks,
SCORER improves sample efficiency and final performance. Our results show that
performance gains can be achieved through principled algorithmic design of the
perception-control dynamic, without requiring complex auxiliary objectives or
architectures.

</details>


### [463] [Towards Unveiling Predictive Uncertainty Vulnerabilities in the Context of the Right to Be Forgotten](https://arxiv.org/abs/2508.07458)
*Wei Qian,Chenxu Zhao,Yangyi Li,Wenqian Ye,Mengdi Huai*

Main category: cs.LG

TL;DR: 本文探讨了深度学习模型中预测不确定性的脆弱性，提出了一种新型的恶意遗忘攻击，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 探讨预测不确定性在恶意遗忘攻击下的脆弱性，填补现有研究空白。

Method: 提出恶意遗忘攻击，设计优化框架，进行包括黑盒场景在内的大量实验分析。

Result: 实验表明：相较于传统的标签误分类攻击，新攻击方法在操控预测不确定性方面更为有效，且现有防御方法无法有效抵御。

Conclusion: 研究揭示了预测不确定性在恶意遗忘攻击下的潜在风险，并凸显了改进防御措施的紧迫性。

Abstract: Currently, various uncertainty quantification methods have been proposed to
provide certainty and probability estimates for deep learning models' label
predictions. Meanwhile, with the growing demand for the right to be forgotten,
machine unlearning has been extensively studied as a means to remove the impact
of requested sensitive data from a pre-trained model without retraining the
model from scratch. However, the vulnerabilities of such generated predictive
uncertainties with regard to dedicated malicious unlearning attacks remain
unexplored. To bridge this gap, for the first time, we propose a new class of
malicious unlearning attacks against predictive uncertainties, where the
adversary aims to cause the desired manipulations of specific predictive
uncertainty results. We also design novel optimization frameworks for our
attacks and conduct extensive experiments, including black-box scenarios.
Notably, our extensive experiments show that our attacks are more effective in
manipulating predictive uncertainties than traditional attacks that focus on
label misclassifications, and existing defenses against conventional attacks
are ineffective against our attacks.

</details>


### [464] [MOTGNN: Interpretable Graph Neural Networks for Multi-Omics Disease Classification](https://arxiv.org/abs/2508.07465)
*Tiantian Yang,Zhiqian Chen*

Main category: cs.LG

TL;DR: 提出MOTGNN，一个结合多组学数据进行二元疾病分类的新框架，性能和可解释性显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多组学数据的高维度和复杂交互对预测建模的挑战，尤其在疾病分类任务中。

Method: 利用XGBoost构造组学特异性的稀疏图，再应用组学特定的GNN进行分层表征学习，最终通过深度前馈网络实现跨组学的整合预测。

Result: 在三个真实数据集上，MOTGNN较现有方法在准确率、ROC-AUC和F1评分上提高5-10%，并在不平衡分类任务中表现出强鲁棒性。

Conclusion: MOTGNN在提高多组学疾病预测的准确性和可解释性方面表现出巨大潜力，同时具备较高计算效率和良好的生物学可解释性。

Abstract: Integrating multi-omics data, such as DNA methylation, mRNA expression, and
microRNA (miRNA) expression, offers a comprehensive view of the biological
mechanisms underlying disease. However, the high dimensionality and complex
interactions among omics layers present major challenges for predictive
modeling. We propose Multi-Omics integration with Tree-generated Graph Neural
Network (MOTGNN), a novel and interpretable framework for binary disease
classification. MOTGNN employs eXtreme Gradient Boosting (XGBoost) to perform
omics-specific supervised graph construction, followed by modality-specific
Graph Neural Networks (GNNs) for hierarchical representation learning, and a
deep feedforward network for cross-omics integration. On three real-world
disease datasets, MOTGNN outperforms state-of-the-art baselines by 5-10% in
accuracy, ROC-AUC, and F1-score, and remains robust to severe class imbalance
(e.g., 87.2% vs. 33.4% F1 on imbalanced data). The model maintains
computational efficiency through sparse graphs (2.1-2.8 edges per node) and
provides built-in interpretability, revealing both top-ranked biomarkers and
the relative contributions of each omics modality. These results highlight
MOTGNN's potential to improve both predictive accuracy and interpretability in
multi-omics disease modeling.

</details>


### [465] [Online Convex Optimization with Heavy Tails: Old Algorithms, New Regrets, and Applications](https://arxiv.org/abs/2508.07473)
*Zijian Liu*

Main category: cs.LG

TL;DR: 本文研究了在重尾噪声条件下的在线凸优化问题（OCO），提出了在不修改经典算法的情况下，解决该问题的有效方法，并证明了其最优的遗憾界限。


<details>
  <summary>Details</summary>
Motivation: 在OCO中，当随机梯度具有有限方差时，已有算法可以确保次线性的遗憾。然而，对于仅具有有限$p$阶中心矩（$p\in(1,2]$）的梯度估计研究较少。本文旨在解决这一重尾梯度问题。

Method: 本文在经典方法（如在线梯度下降）下，提出并分析了在标准有界域假设下的重尾条件下的遗憾，并未对算法进行修改。同时，扩展了这一结果到更广泛的场景，如平滑OCO及乐观算法。

Result: 本文得出了经典算法在重尾噪声下的全参数最优遗憾界限，同时首次证明了在无梯度裁剪情况下非光滑非凸优化问题的收敛性。

Conclusion: 在OCO问题中，即使面对重尾噪声条件，经典算法也可以高效运作，并在参数未知的情况下达到最优性能。此外，这些方法在更多场景和算法中具有普适性。

Abstract: In Online Convex Optimization (OCO), when the stochastic gradient has a
finite variance, many algorithms provably work and guarantee a sublinear
regret. However, limited results are known if the gradient estimate has a heavy
tail, i.e., the stochastic gradient only admits a finite $\mathsf{p}$-th
central moment for some $\mathsf{p}\in\left(1,2\right]$. Motivated by it, this
work examines different old algorithms for OCO (e.g., Online Gradient Descent)
in the more challenging heavy-tailed setting. Under the standard bounded domain
assumption, we establish new regrets for these classical methods without any
algorithmic modification. Remarkably, these regret bounds are fully optimal in
all parameters (can be achieved even without knowing $\mathsf{p}$), suggesting
that OCO with heavy tails can be solved effectively without any extra operation
(e.g., gradient clipping). Our new results have several applications. A
particularly interesting one is the first provable convergence result for
nonsmooth nonconvex optimization under heavy-tailed noise without gradient
clipping. Furthermore, we explore broader settings (e.g., smooth OCO) and
extend our ideas to optimistic algorithms to handle different cases
simultaneously.

</details>


### [466] [N-BEATS-MOE: N-BEATS with a Mixture-of-Experts Layer for Heterogeneous Time Series Forecasting](https://arxiv.org/abs/2508.07490)
*Ricardo Matos,Luis Roque,Vitor Cerqueira*

Main category: cs.LG

TL;DR: 本文提出了一种名为N-BEATS-MOE的时间序列预测模型，通过引入专家混合(MoE)层改进了传统的N-BEATS方法。


<details>
  <summary>Details</summary>
Motivation: 提出更好适应时间序列特点且能提高预测解释性的模型，并改进当前时间序列预测的性能。

Method: 通过在N-BEATS模型中引入专家混合层(MoE)和动态权重分配策略，利用门控网络实现更灵活的特征适配能力。

Result: 在12个基准数据集上进行验证，相较于多种方法，在多样性较强的数据集上表现出了一致的改进。

Conclusion: N-BEATS-MOE模型不仅提升了时间序列预测的性能，还通过门控机制增强了预测的解释性。

Abstract: Deep learning approaches are increasingly relevant for time series
forecasting tasks. Methods such as N-BEATS, which is built on stacks of
multilayer perceptrons (MLPs) blocks, have achieved state-of-the-art results on
benchmark datasets and competitions. N-BEATS is also more interpretable
relative to other deep learning approaches, as it decomposes forecasts into
different time series components, such as trend and seasonality. In this work,
we present N-BEATS-MOE, an extension of N-BEATS based on a Mixture-of-Experts
(MoE) layer. N-BEATS-MOE employs a dynamic block weighting strategy based on a
gating network which allows the model to better adapt to the characteristics of
each time series. We also hypothesize that the gating mechanism provides
additional interpretability by identifying which expert is most relevant for
each series. We evaluate our method across 12 benchmark datasets against
several approaches, achieving consistent improvements on several datasets,
especially those composed of heterogeneous time series.

</details>


### [467] [Enhancing Privacy in Decentralized Min-Max Optimization: A Differentially Private Approach](https://arxiv.org/abs/2508.07505)
*Yueyang Quan,Chang Wang,Shengjie Zhai,Minghong Fang,Zhuqing Liu*

Main category: cs.LG

TL;DR: 文中提出了DPMixSGD算法，一种用于非凸分布式极小极大优化问题的隐私保护方法，旨在解决引入差分隐私噪声可能影响收敛的问题，并通过理论分析和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决在分布式极小极大优化中，由于差分隐私噪声导致的收敛性能受损问题，尤其是在复杂非凸场景下。

Method: 提出了一种新的DPMixSGD算法，基于最先进的分布式极小极大优化算法STORM，并为加入差分隐私算法提供了理论收敛分析和隐私保证。

Result: 通过理论证明和广泛实验，验证了在各类任务和模型中，DPMixSGD算法的有效性和隐私保护能力。

Conclusion: DPMixSGD能在有效保护数据隐私的同时，保持良好的优化收敛特性，为非凸分布式极小极大优化提供了可行的解决方案。

Abstract: Decentralized min-max optimization allows multi-agent systems to
collaboratively solve global min-max optimization problems by facilitating the
exchange of model updates among neighboring agents, eliminating the need for a
central server. However, sharing model updates in such systems carry a risk of
exposing sensitive data to inference attacks, raising significant privacy
concerns. To mitigate these privacy risks, differential privacy (DP) has become
a widely adopted technique for safeguarding individual data. Despite its
advantages, implementing DP in decentralized min-max optimization poses
challenges, as the added noise can hinder convergence, particularly in
non-convex scenarios with complex agent interactions in min-max optimization
problems. In this work, we propose an algorithm called DPMixSGD (Differential
Private Minmax Hybrid Stochastic Gradient Descent), a novel privacy-preserving
algorithm specifically designed for non-convex decentralized min-max
optimization. Our method builds on the state-of-the-art STORM-based algorithm,
one of the fastest decentralized min-max solutions. We rigorously prove that
the noise added to local gradients does not significantly compromise
convergence performance, and we provide theoretical bounds to ensure privacy
guarantees. To validate our theoretical findings, we conduct extensive
experiments across various tasks and models, demonstrating the effectiveness of
our approach.

</details>


### [468] [FairDRL-ST: Disentangled Representation Learning for Fair Spatio-Temporal Mobility Prediction](https://arxiv.org/abs/2508.07518)
*Sichen Zhao,Wei Shao,Jeffrey Chan,Ziqi Xu,Flora Salim*

Main category: cs.LG

TL;DR: 本文提出了一个名为FairDRL-ST的新框架，以解决时空预测中的公平性问题，该框架通过无监督学习实现敏感信息去关联，同时保证预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前大多时空方法关注于提高准确性，但忽视了公平性，造成了某些群体在资源分配上的不公平，尤其在关键的城市基础设施中可能加剧社会经济不平等。

Method: 本文提出了基于去关联表示学习的框架FairDRL-ST，采用对抗学习分离敏感信息，通过无监督而非监督学习确保公平性，避免性能过度补偿的挑战。

Result: 实验结果表明，与现有的公平性方法相比，该框架能够在维持竞争性预测性能的同时，降低公平性差距。

Conclusion: FairDRL-ST框架通过创新的研究方法实现了在时空预测中兼顾公平性与性能，为AI在公共服务中的道德部署提供了新途径。

Abstract: As deep spatio-temporal neural networks are increasingly utilised in urban
computing contexts, the deployment of such methods can have a direct impact on
users of critical urban infrastructure, such as public transport, emergency
services, and traffic management systems. While many spatio-temporal methods
focus on improving accuracy, fairness has recently gained attention due to
growing evidence that biased predictions in spatio-temporal applications can
disproportionately disadvantage certain demographic or geographic groups,
thereby reinforcing existing socioeconomic inequalities and undermining the
ethical deployment of AI in public services. In this paper, we propose a novel
framework, FairDRL-ST, based on disentangled representation learning, to
address fairness concerns in spatio-temporal prediction, with a particular
focus on mobility demand forecasting. By leveraging adversarial learning and
disentangled representation learning, our framework learns to separate
attributes that contain sensitive information. Unlike existing methods that
enforce fairness through supervised learning, which may lead to
overcompensation and degraded performance, our framework achieves fairness in
an unsupervised manner with minimal performance loss. We apply our framework to
real-world urban mobility datasets and demonstrate its ability to close
fairness gaps while delivering competitive predictive performance compared to
state-of-the-art fairness-aware methods.

</details>


### [469] [Physics-Informed Multimodal Bearing Fault Classification under Variable Operating Conditions using Transfer Learning](https://arxiv.org/abs/2508.07536)
*Tasfiq E. Alam,Md Manjurul Ahsan,Shivakumar Raman*

Main category: cs.LG

TL;DR: 本文研究了一种带有物理启发的多模态卷积神经网络，通过结合振动和电机电流信号以及物理特征提取分支，改进了轴承故障分类模型的性能。并引入了一种新的损失函数来惩罚不符合物理规律的预测，验证了模型在不同数据集及操作条件下的稳定性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在变工况条件下域迁移性差的问题，为实现鲁棒、可解释且通用的轴承故障诊断提供改进方案。

Method: 提出了一个新型物理启发的多模态CNN网络，整合了多种信号和基于物理的特征提取分支，同时设计了一种基于特定轴承故障频率的物理启发型损失函数，并在三种迁移学习策略上对模型进行了进一步优化。

Result: 实验表明，该方法在Paderborn和KAIST数据集上表现优异，并通过统计假设验证了显著改进的分类性能。

Conclusion: 本框架展示了将领域知识与数据驱动学习融合的潜力，为实际工业环境下轴承故障诊断提供了一种鲁棒、可解释、且可推广的方法。

Abstract: Accurate and interpretable bearing fault classification is critical for
ensuring the reliability of rotating machinery, particularly under variable
operating conditions where domain shifts can significantly degrade model
performance. This study proposes a physics-informed multimodal convolutional
neural network (CNN) with a late fusion architecture, integrating vibration and
motor current signals alongside a dedicated physics-based feature extraction
branch. The model incorporates a novel physics-informed loss function that
penalizes physically implausible predictions based on characteristic bearing
fault frequencies - Ball Pass Frequency Outer (BPFO) and Ball Pass Frequency
Inner (BPFI) - derived from bearing geometry and shaft speed. Comprehensive
experiments on the Paderborn University dataset demonstrate that the proposed
physics-informed approach consistently outperforms a non-physics-informed
baseline, achieving higher accuracy, reduced false classifications, and
improved robustness across multiple data splits. To address performance
degradation under unseen operating conditions, three transfer learning (TL)
strategies - Target-Specific Fine-Tuning (TSFT), Layer-Wise Adaptation Strategy
(LAS), and Hybrid Feature Reuse (HFR) - are evaluated. Results show that LAS
yields the best generalization, with additional performance gains when combined
with physics-informed modeling. Validation on the KAIST bearing dataset
confirms the framework's cross-dataset applicability, achieving up to 98
percent accuracy. Statistical hypothesis testing further verifies significant
improvements (p < 0.01) in classification performance. The proposed framework
demonstrates the potential of integrating domain knowledge with data-driven
learning to achieve robust, interpretable, and generalizable fault diagnosis
for real-world industrial applications.

</details>


### [470] [Multimodal Remote Inference](https://arxiv.org/abs/2508.07555)
*Keyuan Zhang,Yin Sun,Bo Ji*

Main category: cs.LG

TL;DR: 研究远程推理系统中的多模态调度，提出了基于指数的阈值策略实现推理误差最小化。实验表明，提出的策略可比传统策略减少高达55%的推理误差。


<details>
  <summary>Details</summary>
Motivation: 由于远程传感器动态变化及网络资源限制，实时获取新鲜特征对于提高推理精度至关重要，需要针对传输调度问题提出优化方案。

Method: 研究两模态调度问题，提出一种基于指数的阈值策略，通过切换模式减少推理误差，并证明了该策略的最优性。

Result: 实验表明，与传统轮询与随机调度策略相比，新方法将推理误差降低了最多55%。

Conclusion: 提出的任务导向AoI优化方法显著提升了远程推理系统的推理精度。

Abstract: We consider a remote inference system with multiple modalities, where a
multimodal machine learning (ML) model performs real-time inference using
features collected from remote sensors. As sensor observations may change
dynamically over time, fresh features are critical for inference tasks.
However, timely delivering features from all modalities is often infeasible due
to limited network resources. To this end, we study a two-modality scheduling
problem to minimize the ML model's inference error, which is expressed as a
penalty function of AoI for both modalities. We develop an index-based
threshold policy and prove its optimality. Specifically, the scheduler switches
modalities when the current modality's index function exceeds a threshold. We
show that the two modalities share the same threshold, and both the index
functions and the threshold can be computed efficiently. The optimality of our
policy holds for (i) general AoI functions that are \emph{non-monotonic} and
\emph{non-additive} and (ii) \emph{heterogeneous} transmission times. Numerical
results show that our policy reduces inference error by up to 55% compared to
round-robin and uniform random policies, which are oblivious to the AoI-based
inference error function. Our results shed light on how to improve remote
inference accuracy by optimizing task-oriented AoI functions.

</details>


### [471] [Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning](https://arxiv.org/abs/2508.07556)
*Stephan Rabanser*

Main category: cs.LG

TL;DR: 机器学习系统用于高风险领域时，论文研究通过不确定性估计提升其安全性，重点在于选择性预测（模型在低置信度时选择拒绝预测）。


<details>
  <summary>Details</summary>
Motivation: 在高风险应用中保证ML系统的可靠性至关重要，但当前模型在不确定性处理上仍存在不足。

Method: 通过模型训练轨迹中的不确定性信号，提出了一种轻量的后处理方法，不需改变模型架构，同时适用于差分隐私环境。还开发了选择性分类程度误差的细分框架，分析误差来源，并设计了防御机制对抗不确定性信号的对抗性操纵。

Result: 文章展示了新方法在选择性预测和不确定性估计下的优越性能，方法在差分隐私情况下表现依旧稳健，并能有效分析解决选择性分类的误差问题。

Conclusion: 这些研究成果提升了ML中不确定性估计的可靠性与安全性，使得模型不仅能准确预测，还能在合适的时候选择“不知道”。

Abstract: Machine learning (ML) systems are increasingly deployed in high-stakes
domains where reliability is paramount. This thesis investigates how
uncertainty estimation can enhance the safety and trustworthiness of ML,
focusing on selective prediction -- where models abstain when confidence is
low.
  We first show that a model's training trajectory contains rich uncertainty
signals that can be exploited without altering its architecture or loss. By
ensembling predictions from intermediate checkpoints, we propose a lightweight,
post-hoc abstention method that works across tasks, avoids the cost of deep
ensembles, and achieves state-of-the-art selective prediction performance.
Crucially, this approach is fully compatible with differential privacy (DP),
allowing us to study how privacy noise affects uncertainty quality. We find
that while many methods degrade under DP, our trajectory-based approach remains
robust, and we introduce a framework for isolating the privacy-uncertainty
trade-off. Next, we then develop a finite-sample decomposition of the selective
classification gap -- the deviation from the oracle accuracy-coverage curve --
identifying five interpretable error sources and clarifying which interventions
can close the gap. This explains why calibration alone cannot fix ranking
errors, motivating methods that improve uncertainty ordering. Finally, we show
that uncertainty signals can be adversarially manipulated to hide errors or
deny service while maintaining high accuracy, and we design defenses combining
calibration audits with verifiable inference.
  Together, these contributions advance reliable ML by improving, evaluating,
and safeguarding uncertainty estimation, enabling models that not only make
accurate predictions -- but also know when to say "I do not know".

</details>


### [472] [Towards Theoretical Understanding of Transformer Test-Time Computing: Investigation on In-Context Linear Regression](https://arxiv.org/abs/2508.07571)
*Xingwu Chen,Miao Lu,Beining Wu,Difan Zou*

Main category: cs.LG

TL;DR: 本文研究在语言模型推理时利用多种中间计算和答案采样，提高模型性能的效果，并首次尝试将随机性与采样引入推理分析。


<details>
  <summary>Details</summary>
Motivation: 旨在通过引入随机性和探索多样化推理方式，缩小实践语言模型推理与理论分析之间的差距。

Method: 利用一种模拟语言模型解码的框架，加入噪声注入与二进制系数采样，主要研究上下文线性回归的推理行为。

Result: 通过实证与理论分析，证明了引入的新推理机制优化的潜力，并深入理解实际语言模型的推理行为。

Conclusion: 研究表明改变推理方式（如噪声注入和多样性采样）可以提供模型性能提升与理论新见解的有效方法。

Abstract: Using more test-time computation during language model inference, such as
generating more intermediate thoughts or sampling multiple candidate answers,
has proven effective in significantly improving model performance. This paper
takes an initial step toward bridging the gap between practical language model
inference and theoretical transformer analysis by incorporating randomness and
sampling. We focus on in-context linear regression with continuous/binary
coefficients, where our framework simulates language model decoding through
noise injection and binary coefficient sampling. Through this framework, we
provide detailed analyses of widely adopted inference techniques. Supported by
empirical results, our theoretical framework and analysis demonstrate the
potential for offering new insights into understanding inference behaviors in
real-world language models.

</details>


### [473] [When and how can inexact generative models still sample from the data manifold?](https://arxiv.org/abs/2508.07581)
*Nisha Chandramoorthy,Adriaan de Clercq*

Main category: cs.LG

TL;DR: 研究了生成模型中支持集的鲁棒性，发现学习误差仅在数据流形上影响密度分布，并提出相关条件以实现支持集的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 观察到生成模型中尽管存在学习误差，生成样本仍沿着而非远离数据分布的支持迁移，激发对这种现象背后机制的好奇心。

Method: 通过对生成过程的概率流进行扰动分析以及有限时间线性扰动分析，研究生成模型中支持集鲁棒性的动态机制，并提出拓扑向量与切空间对齐的条件。

Result: 发现导致支持集鲁棒性的动态机制是拓扑向量与数据流形边界的切空间对齐，并提出一种计算高效的对齐条件，验证其对流形切丛估计的准确性。

Conclusion: 该研究从随机分析、统计学习等角度扩展生成模型的理论保证，并适用于多种目标分布及生成模型，如条件流匹配和基于分数的生成模型。

Abstract: A curious phenomenon observed in some dynamical generative models is the
following: despite learning errors in the score function or the drift vector
field, the generated samples appear to shift \emph{along} the support of the
data distribution but not \emph{away} from it. In this work, we investigate
this phenomenon of \emph{robustness of the support} by taking a dynamical
systems approach on the generating stochastic/deterministic process. Our
perturbation analysis of the probability flow reveals that infinitesimal
learning errors cause the predicted density to be different from the target
density only on the data manifold for a wide class of generative models.
Further, what is the dynamical mechanism that leads to the robustness of the
support? We show that the alignment of the top Lyapunov vectors (most sensitive
infinitesimal perturbation directions) with the tangent spaces along the
boundary of the data manifold leads to robustness and prove a sufficient
condition on the dynamics of the generating process to achieve this alignment.
Moreover, the alignment condition is efficient to compute and, in practice, for
robust generative models, automatically leads to accurate estimates of the
tangent bundle of the data manifold. Using a finite-time linear perturbation
analysis on samples paths as well as probability flows, our work complements
and extends existing works on obtaining theoretical guarantees for generative
models from a stochastic analysis, statistical learning and uncertainty
quantification points of view. Our results apply across different dynamical
generative models, such as conditional flow-matching and score-based generative
models, and for different target distributions that may or may not satisfy the
manifold hypothesis.

</details>


### [474] [Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization](https://arxiv.org/abs/2508.07629)
*Zhenpeng Su,Leiyu Pan,Xue Bai,Dening Liu,Guanting Dong,Jiaming Huang,Wenping Hu,Guorui Zhou*

Main category: cs.LG

TL;DR: 本文介绍了一种名为Klear-Reasoner的长推理模型，通过长链式推理训练与强化学习策略优化，展示了在数学和编程领域的卓越推理能力，并在多个基准测试中取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 当前推理模型的研究较多，但由于训练细节未全面公开，高性能推理模型的复现仍存挑战，推动了该工作的开展。

Method: 采用包含数据准备、长链式推理监督微调（CoT SFT）和强化学习（RL）的后训练策略，并提出了一种名为GPPO（Gradient-Preserving Clipping Policy Optimization）的新机制来改善探索能力和效率。

Result: 在AIME 2024中得分90.5%、AIME 2025中得分83.2%、LiveCodeBench V5中得分66.0%以及LiveCodeBench V6中得分58.1%。

Conclusion: Klear-Reasoner通过创新的训练方法和优化策略展示了其在数学和编程推理上的强大能力，为推理模型领域的进一步发展提供了重要参考。

Abstract: We present Klear-Reasoner, a model with long reasoning capabilities that
demonstrates careful deliberation during problem solving, achieving outstanding
performance across multiple benchmarks. Although there are already many
excellent works related to inference models in the current community, there are
still many problems with reproducing high-performance inference models due to
incomplete disclosure of training details. This report provides an in-depth
analysis of the reasoning model, covering the entire post-training workflow
from data preparation and long Chain-of-Thought supervised fine-tuning (long
CoT SFT) to reinforcement learning (RL), along with detailed ablation studies
for each experimental component. For SFT data, our experiments show that a
small number of high-quality data sources are more effective than a large
number of diverse data sources, and that difficult samples can achieve better
results without accuracy filtering. In addition, we investigate two key issues
with current clipping mechanisms in RL: Clipping suppresses critical
exploration signals and ignores suboptimal trajectories. To address these
challenges, we propose Gradient-Preserving clipping Policy Optimization (GPPO)
that gently backpropagates gradients from clipped tokens. GPPO not only
enhances the model's exploration capacity but also improves its efficiency in
learning from negative samples. Klear-Reasoner exhibits exceptional reasoning
abilities in mathematics and programming, scoring 90.5\% on AIME 2024, 83.2\%
on AIME 2025, 66.0\% on LiveCodeBench V5 and 58.1\% on LiveCodeBench V6.

</details>


### [475] [Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo](https://arxiv.org/abs/2508.07631)
*Advait Parulekar,Litu Rout,Karthikeyan Shanmugam,Sanjay Shakkottai*

Main category: cs.LG

TL;DR: 本文研究通过分数网络实现后验采样的问题，并提出在KL散度和Fisher散度下同时近似后验分布的新方法。


<details>
  <summary>Details</summary>
Motivation: 尽管现有方法在图像超分辨率、风格化和重建任务中效果良好，但后验采样问题在KL意义下被认为不可解，因此需要一个新的理论框架。

Method: 提出了一种基于分数网络的倾斜方法以生成同时在KL散度与Fisher散度下接近后验分布的采样点。

Result: 在近似范围内实现了与真实后验分布一致的采样，并首次证明了多项式时间内（近似）后验采样的可行性。

Conclusion: 该方法在理论上为基于分数网络的后验采样提供了新方法，并在实际应用中显示了潜在的改进空间。

Abstract: We study the problem of posterior sampling in the context of score based
generative models. We have a trained score network for a prior $p(x)$, a
measurement model $p(y|x)$, and are tasked with sampling from the posterior
$p(x|y)$. Prior work has shown this to be intractable in KL (in the worst case)
under well-accepted computational hardness assumptions. Despite this, popular
algorithms for tasks such as image super-resolution, stylization, and
reconstruction enjoy empirical success. Rather than establishing distributional
assumptions or restricted settings under which exact posterior sampling is
tractable, we view this as a more general "tilting" problem of biasing a
distribution towards a measurement. Under minimal assumptions, we show that one
can tractably sample from a distribution that is simultaneously close to the
posterior of a noised prior in KL divergence and the true posterior in Fisher
divergence. Intuitively, this combination ensures that the resulting sample is
consistent with both the measurement and the prior. To the best of our
knowledge these are the first formal results for (approximate) posterior
sampling in polynomial time.

</details>


### [476] [Attribution Explanations for Deep Neural Networks: A Theoretical Perspective](https://arxiv.org/abs/2508.07636)
*Huiqi Deng,Hongbin Pei,Quanshi Zhang,Mengnan Du*

Main category: cs.LG

TL;DR: 本文探讨了归因解释在解释深度神经网络中的作用，以及其在忠实反映输入变量对决策过程的影响时面临的核心挑战，并总结了近期理论的进展。


<details>
  <summary>Details</summary>
Motivation: 随着深度神经网络的复杂性增加，人们越来越需要可解释性方法。例如，归因方法通过为每个输入变量分配重要性得分来说明其对最终输出的贡献。然而，现有方法的可信度受限，其是否忠实反映实际贡献仍是未解决的问题。

Method: 总结近期理论发展，包括理论统一化（解析方法间的共性和差异）、理论基础（澄清已有方法的根基）及理论评价（验证方法是否满足忠实性原则）。

Result: 通过对近期理论工作的综述和总结，提出了三大关键方向，并指出这些研究为相关领域的深入理论理解和新方法开发提供了支持。

Conclusion: 本文通过系统综述总结现有归因方法的理论进展及三大核心方向，并讨论了未来的开放性问题以启发后续研究。

Abstract: Attribution explanation is a typical approach for explaining deep neural
networks (DNNs), inferring an importance or contribution score for each input
variable to the final output. In recent years, numerous attribution methods
have been developed to explain DNNs. However, a persistent concern remains
unresolved, i.e., whether and which attribution methods faithfully reflect the
actual contribution of input variables to the decision-making process. The
faithfulness issue undermines the reliability and practical utility of
attribution explanations. We argue that these concerns stem from three core
challenges. First, difficulties arise in comparing attribution methods due to
their unstructured heterogeneity, differences in heuristics, formulations, and
implementations that lack a unified organization. Second, most methods lack
solid theoretical underpinnings, with their rationales remaining absent,
ambiguous, or unverified. Third, empirically evaluating faithfulness is
challenging without ground truth. Recent theoretical advances provide a
promising way to tackle these challenges, attracting increasing attention. We
summarize these developments, with emphasis on three key directions: (i)
Theoretical unification, which uncovers commonalities and differences among
methods, enabling systematic comparisons; (ii) Theoretical rationale,
clarifying the foundations of existing methods; (iii) Theoretical evaluation,
rigorously proving whether methods satisfy faithfulness principles. Beyond a
comprehensive review, we provide insights into how these studies help deepen
theoretical understanding, inform method selection, and inspire new attribution
methods. We conclude with a discussion of promising open problems for further
work.

</details>


### [477] [Extracting Complex Topology from Multivariate Functional Approximation: Contours, Jacobi Sets, and Ridge-Valley Graphs](https://arxiv.org/abs/2508.07637)
*Guanqun Ma,David Lenz,Hanqi Guo,Tom Peterka,Bei Wang*

Main category: cs.LG

TL;DR: 文章提出一种方法直接从多变量函数近似（MFA）模型中提取复杂拓扑特征，为隐式连续模型的拓扑分析和可视化奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 在科学数据分析中，隐式连续模型因其高阶、可微分的特点为数据存储、传输和分析提供了新视角，但直接从这些模型中提取复杂拓扑特征仍是挑战。

Method: 提出了一种从多变量函数近似（MFA）模型中直接提取复杂拓扑特征（如等值线、Jacobi集和脊谷图）的方法，无需将模型转换为离散表示。

Result: 方法成功将在MFA模型中以连续的方式直接实现复杂拓扑特征的提取，且可推广到支持函数值和高阶导数查询的其他隐式模型。

Conclusion: 该工作为在隐式连续模型上进行拓扑数据分析和可视化提供了基础框架，并展示了其潜在的通用性。

Abstract: Implicit continuous models, such as functional models and implicit neural
networks, are an increasingly popular method for replacing discrete data
representations with continuous, high-order, and differentiable surrogates.
These models offer new perspectives on the storage, transfer, and analysis of
scientific data. In this paper, we introduce the first framework to directly
extract complex topological features -- contours, Jacobi sets, and ridge-valley
graphs -- from a type of continuous implicit model known as multivariate
functional approximation (MFA). MFA replaces discrete data with continuous
piecewise smooth functions. Given an MFA model as the input, our approach
enables direct extraction of complex topological features from the model,
without reverting to a discrete representation of the model. Our work is easily
generalizable to any continuous implicit model that supports the queries of
function values and high-order derivatives. Our work establishes the building
blocks for performing topological data analysis and visualization on implicit
continuous models.

</details>


### [478] [Beyond Single: A Data Selection Principle for LLM Alignment via Fine-Grained Preference Signals](https://arxiv.org/abs/2508.07638)
*Jia Zhang,Yao Liu,Chen-Xi Zhang,Yi Liu,Yi-Xuan Jin,Lan-Zhe Guo,Yu-Feng Li*

Main category: cs.LG

TL;DR: 本文提出了一种新方法解决在多细节、偏好细粒度的数据上训练大型语言模型的问题，使用了名为‘偏好发散（PD）’的一种概念，并通过选择高共识数据来优化训练效率。


<details>
  <summary>Details</summary>
Motivation: 为了使大型语言模型能够适配多样化的人类价值观，需要细粒度的偏好数据。但现有方法在对抗噪音和冲突时表现不佳，因此需要新的策略。

Method: 本文推导了直接多偏好优化（DMPO）目标函数，提出‘偏好发散（PD）’概念，并据此制定了一种高共识数据选择原则，最终通过实用化方法实现优化。

Result: 在UltraFeedback数据集不同冲突水平下的验证中，提出的方法相较于传统整体偏好及更强的集成偏好信号模型，表现出10%以上的相对提高，同时提升了训练效率。

Conclusion: 该研究表明，通过选择高共识偏好数据，可以显著提升大型语言模型在细粒度偏好信号上的对齐能力，开启了基于此类偏好数据实现鲁棒对齐的新可能性。

Abstract: Aligning Large Language Models (LLMs) with diverse human values requires
moving beyond a single holistic "better-than" preference criterion. While
collecting fine-grained, aspect-specific preference data is more reliable and
scalable, existing methods like Direct Preference Optimization (DPO) struggle
with the severe noise and conflicts inherent in such aggregated datasets. In
this paper, we tackle this challenge from a data-centric perspective. We first
derive the Direct Multi-Preference Optimization (DMPO) objective, and uncover a
key Preference Divergence (PD) term that quantifies inter-aspect preference
conflicts. Instead of using this term for direct optimization, we leverage it
to formulate a novel, theoretically-grounded data selection principle. Our
principle advocates for selecting a subset of high-consensus data-identified by
the most negative PD values-for efficient DPO training. We prove the optimality
of this strategy by analyzing the loss bounds of the DMPO objective in the
selection problem. To operationalize our approach, we introduce practical
methods of PD term estimation and length bias mitigation, thereby proposing our
PD selection method. Evaluation on the UltraFeedback dataset with three varying
conflict levels shows that our simple yet effective strategy achieves over 10%
relative improvement against both the standard holistic preference and a
stronger oracle using aggregated preference signals, all while boosting
training efficiency and obviating the need for intractable holistic preference
annotating, unlocking the potential of robust LLM alignment via fine-grained
preference signals.

</details>


### [479] [Multi-Turn Jailbreaks Are Simpler Than They Seem](https://arxiv.org/abs/2508.07646)
*Xiaoxue Yang,Jaeha Lee,Anna-Katharina Dick,Jasper Timm,Fei Xie,Diogo Cruz*

Main category: cs.LG

TL;DR: 本文研究了多回合对抗攻击在先进LLM（如GPT-4、Claude和Gemini变体）中的影响，发现多回合攻击与重复单回合攻击的效果相当，并且发现推理强度高的模型可能更容易被攻击。


<details>
  <summary>Details</summary>
Motivation: 虽然单回合对抗已显著改善，但多回合对抗依然是LLMs的显著漏洞，因此需要针对其中的机制和成效进行深入分析。

Method: 通过StrongREJECT基准，研究多回合攻击在多个先进LLM上的表现，并分析模型推理强度与攻击成功率之间的相关性。

Result: 多回合攻击与重复单回合攻击的效果相当；相似模型间的成功攻击相关性较高；推理强度高的模型反而更易被成功攻击。

Conclusion: 多回合攻击并不如预想复杂，现有的单回合防御优化也可能在一定程度有效应对多回合对抗。

Abstract: While defenses against single-turn jailbreak attacks on Large Language Models
(LLMs) have improved significantly, multi-turn jailbreaks remain a persistent
vulnerability, often achieving success rates exceeding 70% against models
optimized for single-turn protection. This work presents an empirical analysis
of automated multi-turn jailbreak attacks across state-of-the-art models
including GPT-4, Claude, and Gemini variants, using the StrongREJECT benchmark.
Our findings challenge the perceived sophistication of multi-turn attacks: when
accounting for the attacker's ability to learn from how models refuse harmful
requests, multi-turn jailbreaking approaches are approximately equivalent to
simply resampling single-turn attacks multiple times. Moreover, attack success
is correlated among similar models, making it easier to jailbreak newly
released ones. Additionally, for reasoning models, we find surprisingly that
higher reasoning effort often leads to higher attack success rates. Our results
have important implications for AI safety evaluation and the design of
jailbreak-resistant systems. We release the source code at
https://github.com/diogo-cruz/multi_turn_simpler

</details>


### [480] [Discovering Spatial Correlations between Earth Observations in Global Atmospheric State Estimation by using Adaptive Graph Structure Learning](https://arxiv.org/abs/2508.07659)
*Hyeon-Ju Jeon,Jeon-Ho Kang,In-Hyuk Kwon,O-Joun Lee*

Main category: cs.LG

TL;DR: 本研究提出了一种基于时空图神经网络（STGNN）和结构学习的方法，以改善全球气象态势预测的准确性，尤其针对高大气变异区域的表现显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 旨在发现地球观测与大气状态之间的空间相关性，通过改进数值天气预报（NWP）系统来提升全球气象状态估计的预测准确性。

Method: 使用时空图神经网络（STGNN）与结构学习相结合的方式，应对动态变化的复杂空间相关性，同时通过自适应控制节点度数和考虑NWP网格点与观测点的空间距离，解决边过多引发的信息丢失和过平滑问题。

Result: 在使用东亚的真实大气数据实验中，该方法在高大气变异区域中表现优于现有STGNN模型，证明其有效性。

Conclusion: 提出的STGNN与结构学习相结合的新方法能够更好地捕捉时空相关性，对全球气象态预测具有优异性能，特别是在复杂的气象条件下。

Abstract: This study aims to discover spatial correlations between Earth observations
and atmospheric states to improve the forecasting accuracy of global
atmospheric state estimation, which are usually conducted using conventional
numerical weather prediction (NWP) systems and is the beginning of weather
forecasting. NWP systems predict future atmospheric states at fixed locations,
which are called NWP grid points, by analyzing previous atmospheric states and
newly acquired Earth observations without fixed locations. Thus, surrounding
meteorological context and the changing locations of the observations make
spatial correlations between atmospheric states and observations over time. To
handle complicated spatial correlations, which change dynamically, we employ
spatiotemporal graph neural networks (STGNNs) with structure learning. However,
structure learning has an inherent limitation that this can cause structural
information loss and over-smoothing problem by generating excessive edges. To
solve this problem, we regulate edge sampling by adaptively determining node
degrees and considering the spatial distances between NWP grid points and
observations. We validated the effectiveness of the proposed method by using
real-world atmospheric state and observation data from East Asia. Even in areas
with high atmospheric variability, the proposed method outperformed existing
STGNN models with and without structure learning.

</details>


### [481] [GLiClass: Generalist Lightweight Model for Sequence Classification Tasks](https://arxiv.org/abs/2508.07662)
*Ihor Stepanov,Mykhailo Shtopko,Dmytro Vodianytskyi,Oleksandr Lukashov,Alexander Yavorskyi,Mykyta Yaroshenko*

Main category: cs.LG

TL;DR: 论文提出了一种适用于序列分类的新方法GLiClass，结合了高效性和准确性，同时适应零样本和少样本场景。


<details>
  <summary>Details</summary>
Motivation: 现有AI分类方法在处理大规模输入数据时效率和准确性受限，且不具备足够的动态适应能力。

Method: 研究提出了一种基于GLiNER架构的分类方法GLiClass，并结合PPO优化多标签文本分类。

Result: 新方法GLiClass在准确性和效率上表现优异，同时支持灵活的零样本和少样本学习场景。

Conclusion: GLiClass能够更高效且准确地执行分类任务，是传统方法的改进选择。

Abstract: Classification is one of the most widespread tasks in AI applications,
serving often as the first step in filtering, sorting, and categorizing data.
Since modern AI systems must handle large volumes of input data and early
pipeline stages can propagate errors downstream, achieving high efficiency and
accuracy is critical. Moreover, classification requirements can change
dynamically based on user needs, necessitating models with strong zero-shot
capabilities. While generative LLMs have become mainstream for zero-shot
classification due to their versatility, they suffer from inconsistent
instruction following and computational inefficiency. Cross-encoders, commonly
used as rerankers in RAG pipelines, face a different bottleneck: they must
process text-label pairs sequentially, significantly reducing efficiency with
large label sets. Embedding-based approaches offer good efficiency but struggle
with complex scenarios involving logical and semantic constraints. We propose
GLiClass, a novel method that adapts the GLiNER architecture for sequence
classification tasks. Our approach achieves strong accuracy and efficiency
comparable to embedding-based methods, while maintaining the flexibility needed
for zero-shot and few-shot learning scenarios. Additionally, we adapted
proximal policy optimization (PPO) for multi-label text classification,
enabling training classifiers in data-sparse conditions or from human feedback.

</details>


### [482] [AIS-LLM: A Unified Framework for Maritime Trajectory Prediction, Anomaly Detection, and Collision Risk Assessment with Explainable Forecasting](https://arxiv.org/abs/2508.07668)
*Hyobin Park,Jinwook Jung,Minseok Seo,Hyunsoo Choi,Deukjae Cho,Sekil Park,Dong-Geol Choi*

Main category: cs.LG

TL;DR: 提出AIS-LLM框架结合AIS数据和大型语言模型，实现对船舶轨迹预测、异常检测和碰撞风险评估三大任务的同时处理，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法逐一处理任务，难以全面分析复杂海事状况，因此需一种能够整合多任务分析的新方法。

Method: 提出AIS-LLM框架，由时间序列编码器、基于LLM的提示编码器、跨模态对齐模块及多任务解码器组成，用于同时执行三项海事数据任务。

Result: AIS-LLM在轨迹预测、异常检测和碰撞风险评估等任务上表现优于现有方法。

Conclusion: AIS-LLM方法验证了其在处理复杂海事状况任务的有效性，同时展示了提升海事交通管理效率的潜力。

Abstract: With the increase in maritime traffic and the mandatory implementation of the
Automatic Identification System (AIS), the importance and diversity of maritime
traffic analysis tasks based on AIS data, such as vessel trajectory prediction,
anomaly detection, and collision risk assessment, is rapidly growing. However,
existing approaches tend to address these tasks individually, making it
difficult to holistically consider complex maritime situations. To address this
limitation, we propose a novel framework, AIS-LLM, which integrates time-series
AIS data with a large language model (LLM). AIS-LLM consists of a Time-Series
Encoder for processing AIS sequences, an LLM-based Prompt Encoder, a
Cross-Modality Alignment Module for semantic alignment between time-series data
and textual prompts, and an LLM-based Multi-Task Decoder. This architecture
enables the simultaneous execution of three key tasks: trajectory prediction,
anomaly detection, and risk assessment of vessel collisions within a single
end-to-end system. Experimental results demonstrate that AIS-LLM outperforms
existing methods across individual tasks, validating its effectiveness.
Furthermore, by integratively analyzing task outputs to generate situation
summaries and briefings, AIS-LLM presents the potential for more intelligent
and efficient maritime traffic management.

</details>


### [483] [Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation](https://arxiv.org/abs/2508.07675)
*Xutong Liu,Baran Atalar,Xiangxiang Dai,Jinhang Zuo,Siwei Wang,John C. S. Lui,Wei Chen,Carlee Joe-Wong*

Main category: cs.LG

TL;DR: 这篇文章提出了一种通过语义缓存优化大型语言模型推理响应的新方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型推理成本高，限制了其可扩展性和可持续性。本研究旨在解决这一问题，通过更高效的语义缓存技术减少冗余计算。

Method: 提出了一个基于学习的语义缓存清除框架，包含离线优化和在线学习两种模型，并开发了具有理论保证的高效算法。

Result: 实验验证表明，所提出的算法在性能上优于或匹敌现有基线方法。

Conclusion: 利用学习型算法处理语义缓存清除问题是一种有效方案，可改善大型语言模型的可扩展性并应对查询和成本不确定性。

Abstract: Large Language Models (LLMs) are revolutionizing how users interact with
information systems, yet their high inference cost poses serious scalability
and sustainability challenges. Caching inference responses, allowing them to be
retrieved without another forward pass through the LLM, has emerged as one
possible solution. Traditional exact-match caching, however, overlooks the
semantic similarity between queries, leading to unnecessary recomputation.
Semantic caching addresses this by retrieving responses based on semantic
similarity, but introduces a fundamentally different cache eviction problem:
one must account for mismatch costs between incoming queries and cached
responses. Moreover, key system parameters, such as query arrival probabilities
and serving costs, are often unknown and must be learned over time. Existing
semantic caching methods are largely ad-hoc, lacking theoretical foundations
and unable to adapt to real-world uncertainty. In this paper, we present a
principled, learning-based framework for semantic cache eviction under unknown
query and cost distributions. We formulate both offline optimization and online
learning variants of the problem, and develop provably efficient algorithms
with state-of-the-art guarantees. We also evaluate our framework on a synthetic
dataset, showing that our proposed algorithms perform matching or superior
performance compared with baselines.

</details>


### [484] [Multi-Hop Privacy Propagation for Differentially Private Federated Learning in Social Networks](https://arxiv.org/abs/2508.07676)
*Chenchen Lin,Xuehe Wang*

Main category: cs.LG

TL;DR: 这篇文章提出了一种考虑社交网络隐私外部性的新型联邦学习方法，改善了隐私保护机制并优化了服务器和客户端的成本收益。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习方法未充分考虑社交网络中隐私外部性的问题，因此需要设计能够量化多跳隐私泄露风险的机制。

Method: 采用两阶段Stackelberg博弈建模服务器和客户端的交互，在机制中引入了均值场估计器以缓解网络隐私估算的信息不对称。

Result: 所提出的方法在实验中显著提升了客户端效用、降低了服务器成本并保持了模型性能，超过了现有基线方法。

Conclusion: 所设计的机制在考虑客户端隐私保护的同时也实现了接近最优的社会福利效果，证明了其实用性和有效性。

Abstract: Federated learning (FL) enables collaborative model training across
decentralized clients without sharing local data, thereby enhancing privacy and
facilitating collaboration among clients connected via social networks.
However, these social connections introduce privacy externalities: a client's
privacy loss depends not only on its privacy protection strategy but also on
the privacy decisions of others, propagated through the network via multi-hop
interactions. In this work, we propose a socially-aware privacy-preserving FL
mechanism that systematically quantifies indirect privacy leakage through a
multi-hop propagation model. We formulate the server-client interaction as a
two-stage Stackelberg game, where the server, as the leader, optimizes
incentive policies, and clients, as followers, strategically select their
privacy budgets, which determine their privacy-preserving levels by controlling
the magnitude of added noise. To mitigate information asymmetry in networked
privacy estimation, we introduce a mean-field estimator to approximate the
average external privacy risk. We theoretically prove the existence and
convergence of the fixed point of the mean-field estimator and derive
closed-form expressions for the Stackelberg Nash Equilibrium. Despite being
designed from a client-centric incentive perspective, our mechanism achieves
approximately-optimal social welfare, as revealed by Price of Anarchy (PoA)
analysis. Experiments on diverse datasets demonstrate that our approach
significantly improves client utilities and reduces server costs while
maintaining model performance, outperforming both Social-Agnostic (SA)
baselines and methods that account for social externalities.

</details>


### [485] [MORE-CLEAR: Multimodal Offline Reinforcement learning for Clinical notes Leveraged Enhanced State Representation](https://arxiv.org/abs/2508.07681)
*Yooseok Lim,ByoungJun Jeon,Seong-A Park,Jisoo Lee,Sae Won Choi,Chang Wook Jeong,Ho-Geol Ryu,Hongyeol Lee,Hyun-Lim Yang*

Main category: cs.LG

TL;DR: 提出了一种名为MORE-CLEAR的多模态离线强化学习框架，通过大规模预训练语言模型从临床笔记中提取语义表示，以改进败血症患者的状态表征，并显著提高治疗性能。


<details>
  <summary>Details</summary>
Motivation: 目前针对败血症的强化学习方法主要依赖于结构化数据，缺乏对患者状态的全面理解，因此需要一种更全面的状态表征方法来优化治疗。

Method: 利用预训练的大规模语言模型从临床笔记中提取语义信息，结合门控融合与跨模态注意机制，动态调整时间上下文权重，并整合多模态数据，形成多模态离线强化学习框架MORE-CLEAR。

Result: 通过MIMIC-III、MIMIC-IV等公共和私有数据集验证，MORE-CLEAR提高了患者的生存率估计和策略性能，相较于单模态方法有显著改善。

Conclusion: MORE-CLEAR框架首次在医疗应用中结合了大规模语言模型和多模态离线强化学习，为败血症的管理和治疗提供了一种潜在的新型解决方案，有助于增强对患者状态的全面理解并优化干预决策。

Abstract: Sepsis, a life-threatening inflammatory response to infection, causes organ
dysfunction, making early detection and optimal management critical. Previous
reinforcement learning (RL) approaches to sepsis management rely primarily on
structured data, such as lab results or vital signs, and on a dearth of a
comprehensive understanding of the patient's condition. In this work, we
propose a Multimodal Offline REinforcement learning for Clinical notes
Leveraged Enhanced stAte Representation (MORE-CLEAR) framework for sepsis
control in intensive care units. MORE-CLEAR employs pre-trained large-scale
language models (LLMs) to facilitate the extraction of rich semantic
representations from clinical notes, preserving clinical context and improving
patient state representation. Gated fusion and cross-modal attention allow
dynamic weight adjustment in the context of time and the effective integration
of multimodal data. Extensive cross-validation using two public (MIMIC-III and
MIMIC-IV) and one private dataset demonstrates that MORE-CLEAR significantly
improves estimated survival rate and policy performance compared to
single-modal RL approaches. To our knowledge, this is the first to leverage LLM
capabilities within a multimodal offline RL for better state representation in
medical applications. This approach can potentially expedite the treatment and
management of sepsis by enabling reinforcement learning models to propose
enhanced actions based on a more comprehensive understanding of patient
conditions.

</details>


### [486] [Semantic-Enhanced Time-Series Forecasting via Large Language Models](https://arxiv.org/abs/2508.07697)
*Hao Liu,Chun Yang,Zhang xiaoxing,Xiaobin Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种名为SE-LLM的新模型，通过探索时间序列的周期性和异常特征嵌入语义空间，并嵌入插件模块改进自注意力机制，解决LLMs在时间序列预测中的问题并显著降低计算成本，实验结果优于SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究的重点是令语言模型适用于时间序列预测，但大多只关注表面对准而忽视语言知识结构和时间序列数据模式的内在差异，导致语义表达能力有限。

Method: 本文提出一种语义增强的SE-LLM方法，挖掘时间序列的周期性和异常特征嵌入语义空间，同时通过插件模块改进自注意力机制，支持长短期依赖建模。此外，冻结语言模型并降低序列维度以减少计算开销。

Result: 实验表明，SE-LLM在时间序列分析上优于当前的最先进方法（SOTA）。

Conclusion: SE-LLM有效改善了语言模型在时间序列分析中的表现，既提升了语义表示的合理性，又显著降低了计算消耗，展示了其在长期和短期依赖建模中的潜力。

Abstract: Time series forecasting plays a significant role in finance, energy,
meteorology, and IoT applications. Recent studies have leveraged the
generalization capabilities of large language models (LLMs) to adapt to time
series forecasting, achieving promising performance. However, existing studies
focus on token-level modal alignment, instead of bridging the intrinsic
modality gap between linguistic knowledge structures and time series data
patterns, greatly limiting the semantic representation. To address this issue,
we propose a novel Semantic-Enhanced LLM (SE-LLM) that explores the inherent
periodicity and anomalous characteristics of time series to embed into the
semantic space to enhance the token embedding. This process enhances the
interpretability of tokens for LLMs, thereby activating the potential of LLMs
for temporal sequence analysis. Moreover, existing Transformer-based LLMs excel
at capturing long-range dependencies but are weak at modeling short-term
anomalies in time-series data. Hence, we propose a plugin module embedded
within self-attention that models long-term and short-term dependencies to
effectively adapt LLMs to time-series analysis. Our approach freezes the LLM
and reduces the sequence dimensionality of tokens, greatly reducing
computational consumption. Experiments demonstrate the superiority performance
of our SE-LLM against the state-of-the-art (SOTA) methods.

</details>


### [487] [Energy Consumption in Parallel Neural Network Training](https://arxiv.org/abs/2508.07706)
*Philipp Huber,David Li,Juan Pedro Gutiérrez Hermosillo Muriedas,Deifilia Kieckhefen,Markus Götz,Achim Streit,Charlotte Debus*

Main category: cs.LG

TL;DR: 本研究通过数据并行训练实验，分析了参数对神经网络训练性能、时间和能耗的影响，强调了能耗与使用资源的线性关系。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络训练对计算资源需求的增加，能耗激增成为一个令人担忧的问题。而在并行化加速训练的背景下，能耗的影响往往被忽略，需要研究填补这方面的空白。

Method: 通过数据并行训练实验，评估ResNet50和FourCastNet模型在GPU数量、全局批量大小和本地批量大小等参数对性能、训练时间和能耗的影响。

Result: 能耗与GPU使用时间呈线性增长关系，但其增幅因模型、硬件以及每小时GPU样本和梯度更新数量的不同而有显著差异。

Conclusion: 研究揭示了扩展神经网络训练时的复杂关系，为未来实现可持续AI研究提供了参考。

Abstract: The increasing demand for computational resources of training neural networks
leads to a concerning growth in energy consumption. While parallelization has
enabled upscaling model and dataset sizes and accelerated training, its impact
on energy consumption is often overlooked. To close this research gap, we
conducted scaling experiments for data-parallel training of two models,
ResNet50 and FourCastNet, and evaluated the impact of parallelization
parameters, i.e., GPU count, global batch size, and local batch size, on
predictive performance, training time, and energy consumption. We show that
energy consumption scales approximately linearly with the consumed resources,
i.e., GPU hours; however, the respective scaling factor differs substantially
between distinct model trainings and hardware, and is systematically influenced
by the number of samples and gradient updates per GPU hour. Our results shed
light on the complex interplay of scaling up neural network training and can
inform future developments towards more sustainable AI research.

</details>


### [488] [Training-Free ANN-to-SNN Conversion for High-Performance Spiking Transformer](https://arxiv.org/abs/2508.07710)
*Jingya Wang,Xin Deng,Wenjie Wei,Dehao Zhang,Shuai Wang,Qian Sun,Jieyuan Zhang,Hanwen Liu,Ning Xie,Malu Zhang*

Main category: cs.LG

TL;DR: 这篇论文提出了一种针对Transformer架构的高性能、无训练的ANN-to-SNN转换框架，通过引入多基指数衰减神经元（MBE），实现在不修改预训练ANN权重的情况下，高效处理非线性操作，并在各种任务和架构中表现出接近无损的转换精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在Transformer中的非线性操作处理上表现不足，同时需要对预训练的ANN进行额外的微调，这限制了其实际应用的效率与范围。

Method: 作者设计了一种多基指数衰减神经元（MBE），通过指数衰减策略和多基编码方法来高效近似非线性操作，避免对预训练ANN权重的修改。

Result: 实验表明，该方法在CV、NLU、NLG任务以及主流Transformer架构下（如ViT、RoBERTa、GPT-2），实现了接近无损的转换精度且显著降低了延迟。

Conclusion: 该框架为Spiking Transformers的高效、可扩展部署提供了一条可行的路径，解决了现有方法的局限性，拓宽了其在真实应用中的可能性。

Abstract: Leveraging the event-driven paradigm, Spiking Neural Networks (SNNs) offer a
promising approach for constructing energy-efficient Transformer architectures.
Compared to directly trained Spiking Transformers, ANN-to-SNN conversion
methods bypass the high training costs. However, existing methods still suffer
from notable limitations, failing to effectively handle nonlinear operations in
Transformer architectures and requiring additional fine-tuning processes for
pre-trained ANNs. To address these issues, we propose a high-performance and
training-free ANN-to-SNN conversion framework tailored for Transformer
architectures. Specifically, we introduce a Multi-basis Exponential Decay (MBE)
neuron, which employs an exponential decay strategy and multi-basis encoding
method to efficiently approximate various nonlinear operations. It removes the
requirement for weight modifications in pre-trained ANNs. Extensive experiments
across diverse tasks (CV, NLU, NLG) and mainstream Transformer architectures
(ViT, RoBERTa, GPT-2) demonstrate that our method achieves near-lossless
conversion accuracy with significantly lower latency. This provides a promising
pathway for the efficient and scalable deployment of Spiking Transformers in
real-world applications.

</details>


### [489] [Detecting Mislabeled and Corrupted Data via Pointwise Mutual Information](https://arxiv.org/abs/2508.07713)
*Jinghan Yang,Jiayu Weng*

Main category: cs.LG

TL;DR: 本文提出一种基于互信息的数据选择框架，可有效应对混合噪声场景，通过量化输入与标签之间的统计依赖，识别并筛除低质量样本，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络容易记住存在噪声的标签，而现实世界数据常受到标签噪声和输入噪声的共同影响，因此需要一种能够在混合噪声场景下识别并去除低质量数据的方法。

Method: 提出了一种基于互信息的方法，通过计算每个样本对整体互信息的点贡献，判断其质量，识别低贡献样本为噪声或错误标记，并筛除这些低质量数据。

Result: 在MNIST数据集上的实验表明该方法能有效过滤低质量样本，在标签混乱场景下可将分类准确率提高最多约15%。此外，该方法对轻微的输入修改具有鲁鲁性，仅去除真正损坏的样本而保留语义上有效的数据。

Conclusion: 利用互信息框架进行高质量样本筛选是应对混合噪声问题的有效方式，可显著提高模型的分类性能，同时保持对输入修改的鲁棒性。

Abstract: Deep neural networks can memorize corrupted labels, making data quality
critical for model performance, yet real-world datasets are frequently
compromised by both label noise and input noise. This paper proposes a mutual
information-based framework for data selection under hybrid noise scenarios
that quantifies statistical dependencies between inputs and labels. We compute
each sample's pointwise contribution to the overall mutual information and find
that lower contributions indicate noisy or mislabeled instances. Empirical
validation on MNIST with different synthetic noise settings demonstrates that
the method effectively filters low-quality samples. Under label corruption,
training on high-MI samples improves classification accuracy by up to 15\%
compared to random sampling. Furthermore, the method exhibits robustness to
benign input modifications, preserving semantically valid data while filtering
truly corrupted samples.

</details>


### [490] [Robust Reinforcement Learning over Wireless Networks with Homomorphic State Representations](https://arxiv.org/abs/2508.07722)
*Pietro Talli,Federico Mason,Federico Chiariotti,Andrea Zanella*

Main category: cs.LG

TL;DR: 提出了一种新的强化学习架构HR3L，解决通信网络中信息丢包和延迟问题，显著提高效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在处理通信网络中存在的丢包与延迟问题时效率低下，计算复杂度高，因此需要一种更高效的解决方案。

Method: 提出了一种新架构HR3L，包括发射端和接收端。发射端负责对环境编码，接收端负责解码信息并采取行动，同时省略了梯度信息的传输，降低了计算与通信开销。

Result: 实验表明HR3L在采样效率上显著优于基线方法，并能适应丢包、延迟和带宽受限等多种通信情景。

Conclusion: HR3L架构为远程强化学习在非理想无线环境中的训练提供了高效解决方案，并展现了较强的鲁棒性和适应性。

Abstract: In this work, we address the problem of training Reinforcement Learning (RL)
agents over communication networks. The RL paradigm requires the agent to
instantaneously perceive the state evolution to infer the effects of its
actions on the environment. This is impossible if the agent receives state
updates over lossy or delayed wireless systems and thus operates with partial
and intermittent information. In recent years, numerous frameworks have been
proposed to manage RL with imperfect feedback; however, they often offer
specific solutions with a substantial computational burden. To address these
limits, we propose a novel architecture, named Homomorphic Robust Remote
Reinforcement Learning (HR3L), that enables the training of remote RL agents
exchanging observations across a non-ideal wireless channel. HR3L considers two
units: the transmitter, which encodes meaningful representations of the
environment, and the receiver, which decodes these messages and performs
actions to maximize a reward signal. Importantly, HR3L does not require the
exchange of gradient information across the wireless channel, allowing for
quicker training and a lower communication overhead than state-of-the-art
solutions. Experimental results demonstrate that HR3L significantly outperforms
baseline methods in terms of sample efficiency and adapts to different
communication scenarios, including packet losses, delayed transmissions, and
capacity limitations.

</details>


### [491] [Separation and Collaboration: Two-Level Routing Grouped Mixture-of-Experts for Multi-Domain Continual Learning](https://arxiv.org/abs/2508.07738)
*Jialu Zhou,Dianxi Shi,Shaowu Yang,Xinyu Wei,Mingyue Yang,Leqian Li,Mengzhu Wang,Chunping Qiu*

Main category: cs.LG

TL;DR: 提出了一种解决多域连续学习中遗忘问题的新方法。


<details>
  <summary>Details</summary>
Motivation: 解决多域连续学习中的双重异质性问题并减少遗忘现象。

Method: 通过提出一种两级路由分组的专家混合方法(TRGE)，实现模块动态扩展及任务标识识别以缓解遗忘问题。

Result: 实验表明该方法在多种条件下优于其他先进方法，同时具有更少的可训练参数。

Conclusion: TRGE方法有效解决遗忘问题并增强任务间协作，是多域连续学习中的一个重要进展。

Abstract: Multi-Domain Continual Learning (MDCL) acquires knowledge from sequential
tasks with shifting class sets and distribution. Despite the
Parameter-Efficient Fine-Tuning (PEFT) methods can adapt for this dual
heterogeneity, they still suffer from catastrophic forgetting and forward
forgetting. To address these challenges, we propose a Two-Level Routing Grouped
Mixture-of-Experts (TRGE) method. Firstly, TRGE dynamically expands the
pre-trained CLIP model, assigning specific expert group for each task to
mitigate catastrophic forgetting. With the number of experts continually grows
in this process, TRGE maintains the static experts count within the group and
introduces the intra-group router to alleviate routing overfitting caused by
the increasing routing complexity. Meanwhile, we design an inter-group routing
policy based on task identifiers and task prototype distance, which dynamically
selects relevant expert groups and combines their outputs to enhance inter-task
collaboration. Secondly, to get the correct task identifiers, we leverage
Multimodal Large Language Models (MLLMs) which own powerful multimodal
comprehension capabilities to generate semantic task descriptions and recognize
the correct task identifier. Finally, to mitigate forward forgetting, we
dynamically fuse outputs for unseen samples from the frozen CLIP model and TRGE
adapter based on training progress, leveraging both pre-trained and learned
knowledge. Through extensive experiments across various settings, our method
outperforms other advanced methods with fewer trainable parameters.

</details>


### [492] [A Tutorial: An Intuitive Explanation of Offline Reinforcement Learning Theory](https://arxiv.org/abs/2508.07746)
*Fengdi Che*

Main category: cs.LG

TL;DR: 本文是一篇关于离线强化学习的综述，讨论了理论和实际算法设计之间的联系与差距。


<details>
  <summary>Details</summary>
Motivation: 旨在探索理论研究中的关键直觉及其对算法设计的启发，助力解决离线强化学习中的基础挑战。

Method: 从理论出发，分析函数表示和数据覆盖假设，探讨无法解决的离线强化学习情境，同时讨论可行条件及其应用。

Result: 指出了当前离线强化学习算法的不足和挑战，并提出寻找在不满足理论假设条件下的新解决方案的必要性。

Conclusion: 研究为设计高效的离线强化学习算法提供了理论支持，同时强调条件限制下的新方法探索的重要性。

Abstract: Offline reinforcement learning (RL) aims to optimize the return given a fixed
dataset of agent trajectories without additional interactions with the
environment. While algorithm development has progressed rapidly, significant
theoretical advances have also been made in understanding the fundamental
challenges of offline RL. However, bridging these theoretical insights with
practical algorithm design remains an ongoing challenge. In this survey, we
explore key intuitions derived from theoretical work and their implications for
offline RL algorithms.
  We begin by listing the conditions needed for the proofs, including function
representation and data coverage assumptions. Function representation
conditions tell us what to expect for generalization, and data coverage
assumptions describe the quality requirement of the data. We then examine
counterexamples, where offline RL is not solvable without an impractically
large amount of data. These cases highlight what cannot be achieved for all
algorithms and the inherent hardness of offline RL. Building on techniques to
mitigate these challenges, we discuss the conditions that are sufficient for
offline RL. These conditions are not merely assumptions for theoretical proofs,
but they also reveal the limitations of these algorithms and remind us to
search for novel solutions when the conditions cannot be satisfied.

</details>


### [493] [Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment](https://arxiv.org/abs/2508.07750)
*Haowen Wang,Yun Yue,Zhiling Ye,Shuowen Zhang,Lei Fan,Jiaxin Liang,Jiadi Jiang,Cheng Wei,Jingyuan Deng,Xudong Han,Ji Li,Chunxiao Guo,Peng Wei,Jian Wang,Jinjie Gu*

Main category: cs.LG

TL;DR: 提出了GRAO框架，结合了SFT和RL的优点，用以优化语言模型对齐能力，同时克服了现有方法的效率与模型依赖性问题。


<details>
  <summary>Details</summary>
Motivation: 当前SFT和RL在提升语言模型对齐能力方面各有优劣，但存在效率和依赖性不足的问题，因此需要一种既能发挥两者优点，又能克服其缺点的新方法。

Method: 提出了名为GRAO的框架，通过三项关键创新结合SFT与RL的优点，包括多样本生成策略、组内直接对齐损失公式及参考感知的参数更新。

Result: 在复杂的人类对齐任务中，GRAO相比于SFT、DPO、PPO和GRPO基线分别取得了57.70%、17.65%、7.95%和5.18%的相对性能提升。

Conclusion: GRAO框架在理论和实证上均展现出对齐效率的提升，为语言模型能力演进提供了依据。

Abstract: Alignment methodologies have emerged as a critical pathway for enhancing
language model alignment capabilities. While SFT (supervised fine-tuning)
accelerates convergence through direct token-level loss intervention, its
efficacy is constrained by offline policy trajectory. In contrast,
RL(reinforcement learning) facilitates exploratory policy optimization, but
suffers from low sample efficiency and stringent dependency on high-quality
base models. To address these dual challenges, we propose GRAO (Group Relative
Alignment Optimization), a unified framework that synergizes the respective
strengths of SFT and RL through three key innovations: 1) A multi-sample
generation strategy enabling comparative quality assessment via reward
feedback; 2) A novel Group Direct Alignment Loss formulation leveraging
intra-group relative advantage weighting; 3) Reference-aware parameter updates
guided by pairwise preference dynamics. Our theoretical analysis establishes
GRAO's convergence guarantees and sample efficiency advantages over
conventional approaches. Comprehensive evaluations across complex human
alignment tasks demonstrate GRAO's superior performance, achieving
57.70\%,17.65\% 7.95\% and 5.18\% relative improvements over SFT, DPO, PPO and
GRPO baselines respectively. This work provides both a theoretically grounded
alignment framework and empirical evidence for efficient capability evolution
in language models.

</details>


### [494] [Sparse Probabilistic Graph Circuits](https://arxiv.org/abs/2508.07763)
*Martin Rektoris,Milan Papež,Václav Šmídl,Tomáš Pevný*

Main category: cs.LG

TL;DR: 提出一种新的稀疏概率图电路（Sparse PGCs），计算复杂度从 O(n^2) 降低至 O(n + m)，并保持可解性，同时在药物设计中表现优秀。


<details>
  <summary>Details</summary>
Motivation: 解决深度生成模型在图上推断问题的不可解性问题，同时提升计算效率。

Method: 提出稀疏概率图电路（Sparse PGCs），直接在稀疏图表示上进行操作，将推断的时间复杂度从 O(n^2) 降低到 O(n + m)。

Result: 稀疏概率图电路在药物设计中表现出内存效率和推断速度的提升，同时在关键指标上匹敌不可解的深度生成模型。

Conclusion: Sparse PGCs 保持了可解性，显著提高了效率，适用于稀疏图场景，如药物设计等。

Abstract: Deep generative models (DGMs) for graphs achieve impressively high expressive
power thanks to very efficient and scalable neural networks. However, these
networks contain non-linearities that prevent analytical computation of many
standard probabilistic inference queries, i.e., these DGMs are considered
\emph{intractable}. While recently proposed Probabilistic Graph Circuits (PGCs)
address this issue by enabling \emph{tractable} probabilistic inference, they
operate on dense graph representations with $\mathcal{O}(n^2)$ complexity for
graphs with $n$ nodes and \emph{$m$ edges}. To address this scalability issue,
we introduce Sparse PGCs, a new class of tractable generative models that
operate directly on sparse graph representation, reducing the complexity to
$\mathcal{O}(n + m)$, which is particularly beneficial for $m \ll n^2$. In the
context of de novo drug design, we empirically demonstrate that SPGCs retain
exact inference capabilities, improve memory efficiency and inference speed,
and match the performance of intractable DGMs in key metrics.

</details>


### [495] [Pareto Multi-Objective Alignment for Language Models](https://arxiv.org/abs/2508.07768)
*Qiang He,Setareh Maghsudi*

Main category: cs.LG

TL;DR: 这篇文章提出PAMA算法，以解决大型语言模型（LLMs）多目标对齐问题，同时显著提升计算效率和理论可保证性。


<details>
  <summary>Details</summary>
Motivation: 当前的LLMs对齐方法如RLHF主要基于单一奖励函数，难以捕捉人类偏好的复杂性和多样性，从而限制了模型在实际应用中同时满足多个相互冲突的目标的能力。

Method: 文中提出Pareto多目标对齐算法（PAMA），将多目标RLHF转换为凸优化问题，其闭式解方法显著减少计算复杂度，从传统的O(n^2*d)降至O(n)。

Result: 通过在参数范围从125M到7B的语言模型上进行实验，证明了PAMA在多目标对齐方面的有效性和理论优势。

Conclusion: PAMA算法为解决此前被认为难以处理的多目标对齐问题提供了高效、实用且有理论依据的方法，推动LLMs在多样化、适应性强的实际AI部署中的进一步发展。

Abstract: Large language models (LLMs) are increasingly deployed in real-world
applications that require careful balancing of multiple, often conflicting,
objectives, such as informativeness versus conciseness, or helpfulness versus
creativity. However, current alignment methods, primarily based on RLHF,
optimize LLMs toward a single reward function, resulting in rigid behavior that
fails to capture the complexity and diversity of human preferences. This
limitation hinders the adaptability of LLMs to practical scenarios, making
multi-objective alignment (MOA) a critical yet underexplored area. To bridge
this gap, we propose Pareto Multi-Objective Alignment (PAMA), a principled and
computationally efficient algorithm designed explicitly for MOA in LLMs. In
contrast to computationally prohibitive multi-objective optimization (MOO)
methods, PAMA transforms multi-objective RLHF into a convex optimization with a
closed-form solution, significantly enhancing scalability. Traditional MOO
approaches suffer from prohibitive O(n^2*d) complexity, where d represents the
number of model parameters, typically in the billions for LLMs, rendering
direct optimization infeasible. PAMA reduces this complexity to O(n) where n is
the number of objectives, enabling optimization to be completed within
milliseconds. We provide theoretical guarantees that PAMA converges to a Pareto
stationary point, where no objective can be improved without degrading at least
one other. Extensive experiments across language models ranging from 125M to 7B
parameters demonstrate PAMA's robust and effective MOA capabilities, aligning
with its theoretical advantages. PAMA provides a highly efficient solution to
the MOA problem that was previously considered intractable, offering a
practical and theoretically grounded approach to aligning LLMs with diverse
human values, paving the way for versatile and adaptable real-world AI
deployments.

</details>


### [496] [From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations](https://arxiv.org/abs/2508.08061)
*Sven Weinzierl,Sandra Zilker,Annina Liessmann,Martin Käppel,Weixin Wang,Martin Matzner*

Main category: cs.LG

TL;DR: 本文提出了一种基于迁移学习的预测流程监控（PPM）技术，用于在缺乏足够事件数据的情况下实现组织间或组织内的有效决策支持。


<details>
  <summary>Details</summary>
Motivation: 现有的PPM技术需要大量事件数据或其他相关资源，而这些资源有时并不容易获得，限制了一些组织利用PPM的能力。

Method: 提出了一种利用迁移学习的PPM技术，使得无合适事件数据或资源的组织也能够实施PPM，具体通过两个实际用例中的事件日志数据验证其可用性。

Result: 实验表明，不同组织或类似业务流程之间的知识可以有效转移，从而在目标情境中实现高效的PPM。

Conclusion: 所提技术通过在组织内外转移预训练模型等资源，使组织能够在资源有限的情况下应用PPM技术，实现流程监控中的预测价值。

Abstract: Event logs reflect the behavior of business processes that are mapped in
organizational information systems. Predictive process monitoring (PPM)
transforms these data into value by creating process-related predictions that
provide the insights required for proactive interventions at process runtime.
Existing PPM techniques require sufficient amounts of event data or other
relevant resources that might not be readily available, preventing some
organizations from utilizing PPM. The transfer learning-based PPM technique
presented in this paper allows organizations without suitable event data or
other relevant resources to implement PPM for effective decision support. The
technique is instantiated in two real-life use cases, based on which numerical
experiments are performed using event logs for IT service management processes
in an intra- and inter-organizational setting. The results of the experiments
suggest that knowledge of one business process can be transferred to a similar
business process in the same or a different organization to enable effective
PPM in the target context. With the proposed technique, organizations can
benefit from transfer learning in an intra- and inter-organizational setting,
where resources like pre-trained models are transferred within and across
organizational boundaries.

</details>


### [497] [Topological Feature Compression for Molecular Graph Neural Networks](https://arxiv.org/abs/2508.07807)
*Rahul Khorana*

Main category: cs.LG

TL;DR: 本文提出了一种结合了压缩的高阶拓扑信号与标准分子特征的图神经网络（GNN）架构，并证明其在多个基准测试中的优越表现。


<details>
  <summary>Details</summary>
Motivation: 分子表示学习虽然在许多化学信息学和生物信息学任务中取得了成功，但在预测准确性、可解释性和计算效率之间找到平衡仍是一个重大挑战。

Method: 设计了一种新颖的GNN架构，结合了压缩的高阶拓扑信号和传统的分子特征，既能捕捉全局几何信息，又保持可解释性和计算高效性。

Result: 在包括小分子数据集到复杂材料数据集的多个基准测试中，该模型在准确性和鲁棒性上几乎全部获得最佳性能，且参数利用率高。

Conclusion: 这种创新的GNN架构不仅在性能上表现优越，还保持了良好的可解释性和计算效率，对分子表示学习和相关任务有重要推动作用。

Abstract: Recent advances in molecular representation learning have produced highly
effective encodings of molecules for numerous cheminformatics and
bioinformatics tasks. However, extracting general chemical insight while
balancing predictive accuracy, interpretability, and computational efficiency
remains a major challenge. In this work, we introduce a novel Graph Neural
Network (GNN) architecture that combines compressed higher-order topological
signals with standard molecular features. Our approach captures global
geometric information while preserving computational tractability and
human-interpretable structure. We evaluate our model across a range of
benchmarks, from small-molecule datasets to complex material datasets, and
demonstrate superior performance using a parameter-efficient architecture. We
achieve the best performing results in both accuracy and robustness across
almost all benchmarks. We open source all code \footnote{All code and results
can be found on Github https://github.com/rahulkhorana/TFC-PACT-Net}.

</details>


### [498] [EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning](https://arxiv.org/abs/2508.07809)
*Huanyu Liu,Jia Li,Chang Yu,Taozhi Chen,Yihong Dong,Lecheng Wang,Hu XiaoLong,Ge Li*

Main category: cs.LG

TL;DR: 提出了一种名为EvoCoT的自我进化课程学习框架，通过两阶段链式推理优化来克服稀疏奖励问题，提升了LLM在复杂问题上的推理能力。


<details>
  <summary>Details</summary>
Motivation: 旨在解决强化学习中在低准确情况下稀疏奖励导致学习效率低和探索受限的问题，为了改善LLM在推理方面的性能。

Method: 提出EvoCoT框架，通过自我生成和验证链式推理轨迹约束探索空间，逐步扩展空间，从而使模型能够在稀疏奖励下解决难题并提升推理能力。

Result: 实验表明，EvoCoT框架可以让LLM解决之前未解决的问题，在没有外部链式推理监督的情况下提升推理能力，并兼容多种强化学习微调方法。

Conclusion: EvoCoT为LLM推理能力提升提供了一个有效的、自适应性强的解决方案，并对未来研究具有重要意义。

Abstract: Reinforcement learning with verifiable reward (RLVR) has become a promising
paradigm for post-training large language models (LLMs) to improve their
reasoning capability. However, when the rollout accuracy is low on hard
problems, the reward becomes sparse, limiting learning efficiency and causing
exploration bottlenecks. Existing approaches either rely on stronger LLMs for
distillation or filter out difficult problems, which limits scalability or
restricts reasoning improvement through exploration.
  We propose EvoCoT, a self-evolving curriculum learning framework based on
two-stage chain-of-thought (CoT) reasoning optimization. EvoCoT constrains the
exploration space by self-generating and verifying CoT trajectories, then
gradually shortens them to expand the space in a controlled way. This enables
LLMs to stably learn from initially unsolved hard problems under sparse
rewards. We apply EvoCoT to multiple LLM families, including Qwen, DeepSeek,
and Llama. Experiments show that EvoCoT enables LLMs to solve previously
unsolved problems, improves reasoning capability without external CoT
supervision, and is compatible with various RL fine-tuning methods. We release
the source code to support future research.

</details>


### [499] [Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning](https://arxiv.org/abs/2508.08221)
*Zihe Liu,Jiashun Liu,Yancheng He,Weixun Wang,Jiaheng Liu,Ling Pan,Xinyu Hu,Shaopan Xiong,Ju Huang,Jian Hu,Shengyi Huang,Siran Yang,Jiamang Wang,Wenbo Su,Bo Zheng*

Main category: cs.LG

TL;DR: 本文综述了强化学习（RL）在大语言模型（LLM）推理中的应用，揭示了现存的挑战，并提出了统一的框架和实践指南。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在LLM推理中的应用缺乏标准化指南和全面的理解，实验设置不一致导致了混乱。

Method: 通过统一的开源框架，系统复现并分析了常用RL技术的机制、适用场景和核心原则，进行了多维度的精细实验并提出了具体实践指南。

Result: 提出了一种简单的两技术组合方法，在无评论家策略下显著提升性能，超越了例如GRPO和DAPO的策略。

Conclusion: 对于RL在LLM中的应用，本文提供了清晰的技术选择指南和可靠的探索路径，同时证明了简单技术组合的优越性。

Abstract: Reinforcement learning for LLM reasoning has rapidly emerged as a prominent
research area, marked by a significant surge in related studies on both
algorithmic innovations and practical applications. Despite this progress,
several critical challenges remain, including the absence of standardized
guidelines for employing RL techniques and a fragmented understanding of their
underlying mechanisms. Additionally, inconsistent experimental settings,
variations in training data, and differences in model initialization have led
to conflicting conclusions, obscuring the key characteristics of these
techniques and creating confusion among practitioners when selecting
appropriate techniques. This paper systematically reviews widely adopted RL
techniques through rigorous reproductions and isolated evaluations within a
unified open-source framework. We analyze the internal mechanisms, applicable
scenarios, and core principles of each technique through fine-grained
experiments, including datasets of varying difficulty, model sizes, and
architectures. Based on these insights, we present clear guidelines for
selecting RL techniques tailored to specific setups, and provide a reliable
roadmap for practitioners navigating the RL for the LLM domain. Finally, we
reveal that a minimalist combination of two techniques can unlock the learning
capability of critic-free policies using vanilla PPO loss. The results
demonstrate that our simple combination consistently improves performance,
surpassing strategies like GRPO and DAPO.

</details>


### [500] [Learning Satellite Attitude Dynamics with Physics-Informed Normalising Flow](https://arxiv.org/abs/2508.07841)
*Carlo Cena,Mauro Martini,Marcello Chiaberge*

Main category: cs.LG

TL;DR: 本研究提出通过引入物理知识神经网络（PINNs）来优化航天器姿态控制的模型预测控制（MPC），相比纯数据驱动方法，在控制精度和鲁棒性方面取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的纯数据驱动方法模型在处理航天器输入超出训练域时面临泛化和稳定性问题，需要一种更鲁棒的控制方法。

Method: 将物理知识神经网络（PINNs）嵌入航天器姿态控制的学习中，结合了含自注意力机制的Real NVP神经网络架构，对比纯数据驱动方法与物理增强方法的性能，分析其对性能的影响。

Result: 物理增强模型相较于纯数据驱动模型，减小了27.08%的相对误差，并在控制性能稳定性上提升了42.86%，明显改善了MPC框架下的控制精度及抗噪性能。

Conclusion: 引入物理知识显著增强了模型在MPC框架下的性能和稳定性，对航天器的姿态控制具有重大意义。

Abstract: Attitude control is a fundamental aspect of spacecraft operations. Model
Predictive Control (MPC) has emerged as a powerful strategy for these tasks,
relying on accurate models of the system dynamics to optimize control actions
over a prediction horizon. In scenarios where physics models are incomplete,
difficult to derive, or computationally expensive, machine learning offers a
flexible alternative by learning the system behavior directly from data.
However, purely data-driven models often struggle with generalization and
stability, especially when applied to inputs outside their training domain. To
address these limitations, we investigate the benefits of incorporating
Physics-Informed Neural Networks (PINNs) into the learning of spacecraft
attitude dynamics, comparing their performance with that of purely data-driven
approaches. Using a Real-valued Non-Volume Preserving (Real NVP) neural network
architecture with a self-attention mechanism, we trained several models on
simulated data generated with the Basilisk simulator. Two training strategies
were considered: a purely data-driven baseline and a physics-informed variant
to improve robustness and stability. Our results demonstrate that the inclusion
of physics-based information significantly enhances the performance in terms of
the mean relative error of the best architectures found by 27.08%. These
advantages are particularly evident when the learned models are integrated into
an MPC framework, where PINN-based models consistently outperform their purely
data-driven counterparts in terms of control accuracy and robustness, yielding
improvements of up to 42.86% in performance stability error and increased
robustness-to-noise.

</details>


### [501] [Not Yet AlphaFold for the Mind: Evaluating Centaur as a Synthetic Participant](https://arxiv.org/abs/2508.07887)
*Sabrina Namazova,Alessandra Brondetta,Younes Strittmatter,Matthew Nassar,Sebastian Musslick*

Main category: cs.LG

TL;DR: 研究对Centaur这个模拟人在行为科学中的应用进行了评估，指出模型虽然预测准确性较高，但生成行为与人类数据存在显著偏差，尚不足以成为可靠的参与者模拟器或认知模型。


<details>
  <summary>Details</summary>
Motivation: 旨在探索类似于AlphaFold在自然科学中的突破，行为科学领域是否也能通过开发可靠的参与者模拟器来实现实验加速和优化。

Method: 评估了Centaur的各种核心标准如预测准确性和生成行为，并以人类数据为基准进行对比分析。

Result: 结果显示，虽然Centaur在预测准确性方面表现优秀，但其生成行为偏离人类数据，无法达到理想的可靠性标准。

Conclusion: Centaur尽管是推动预测人类行为的一大进步，但离成为一个合格的参与者模拟器或精确的认知模型还有一定距离。

Abstract: Simulators have revolutionized scientific practice across the natural
sciences. By generating data that reliably approximate real-world phenomena,
they enable scientists to accelerate hypothesis testing and optimize
experimental designs. This is perhaps best illustrated by AlphaFold, a
Nobel-prize winning simulator in chemistry that predicts protein structures
from amino acid sequences, enabling rapid prototyping of molecular
interactions, drug targets, and protein functions. In the behavioral sciences,
a reliable participant simulator - a system capable of producing human-like
behavior across cognitive tasks - would represent a similarly transformative
advance. Recently, Binz et al. introduced Centaur, a large language model (LLM)
fine-tuned on human data from 160 experiments, proposing its use not only as a
model of cognition but also as a participant simulator for "in silico
prototyping of experimental studies", e.g., to advance automated cognitive
science. Here, we review the core criteria for a participant simulator and
assess how well Centaur meets them. Although Centaur demonstrates strong
predictive accuracy, its generative behavior - a critical criterion for a
participant simulator - systematically diverges from human data. This suggests
that, while Centaur is a significant step toward predicting human behavior, it
does not yet meet the standards of a reliable participant simulator or an
accurate model of cognition.

</details>


### [502] [Score Augmentation for Diffusion Models](https://arxiv.org/abs/2508.07926)
*Liang Hou,Yuan Gao,Boyuan Jiang,Xin Tao,Qi Yan,Renjie Liao,Pengfei Wan,Di Zhang,Kun Gai*

Main category: cs.LG

TL;DR: 研究提出了一种称为ScoreAug的新框架，用于解决扩散模型在数据有限条件下的过拟合问题，通过在噪声数据上实施变换并引入新的学习目标，提高了模型性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 针对扩散模型在数据有限情况下容易出现过拟合的问题，提出一种创新的解决方案，以提高模型在多个基准数据集上的表现。

Method: 提出ScoreAug框架，通过在噪声数据上实施变换，并要求去噪器预测原始目标的变换，从而实现一种等变学习目标。该方法还通过理论分析不同空间下分数的关系。

Result: 在多个基准上进行测试，包括CIFAR-10、FFHQ、AFHQv2和ImageNet，实验结果表明ScoreAug显著提升了性能，成功缓解了过拟合问题，同时具备稳定的收敛特性，并与传统数据增强技术结合可进一步提高表现。

Conclusion: ScoreAug框架有效解决了扩散模型的过拟合问题，并在多种数据规模和模型条件下表现出色，且具有稳定性和易于与现有方法结合的优点。

Abstract: Diffusion models have achieved remarkable success in generative modeling.
However, this study confirms the existence of overfitting in diffusion model
training, particularly in data-limited regimes. To address this challenge, we
propose Score Augmentation (ScoreAug), a novel data augmentation framework
specifically designed for diffusion models. Unlike conventional augmentation
approaches that operate on clean data, ScoreAug applies transformations to
noisy data, aligning with the inherent denoising mechanism of diffusion.
Crucially, ScoreAug further requires the denoiser to predict the augmentation
of the original target. This design establishes an equivariant learning
objective, enabling the denoiser to learn scores across varied denoising
spaces, thereby realizing what we term score augmentation. We also
theoretically analyze the relationship between scores in different spaces under
general transformations. In experiments, we extensively validate ScoreAug on
multiple benchmarks including CIFAR-10, FFHQ, AFHQv2, and ImageNet, with
results demonstrating significant performance improvements over baselines.
Notably, ScoreAug effectively mitigates overfitting across diverse scenarios,
such as varying data scales and model capacities, while exhibiting stable
convergence properties. Another advantage of ScoreAug over standard data
augmentation lies in its ability to circumvent data leakage issues under
certain conditions. Furthermore, we show that ScoreAug can be synergistically
combined with traditional data augmentation techniques to achieve additional
performance gains.

</details>


### [503] [Adaptive Fine-Tuning via Pattern Specialization for Deep Time Series Forecasting](https://arxiv.org/abs/2508.07927)
*Amal Saadallah,Abdulaziz Al-Ademi*

Main category: cs.LG

TL;DR: 本文提出一种结合模型适配和选择的新型框架，用于提升深度神经网络（DNN）在非平稳时间序列环境中的预测性能。


<details>
  <summary>Details</summary>
Motivation: 应对时间序列中的非平稳环境问题，捕捉底层模式随时间变化的特点并提升模型预测性能。

Method: 首先离线训练一个基础DNN；然后针对验证数据中的主要模式进行聚类并识别不同的模式状态；进一步通过微调基础模型，生成能够捕捉特定模式特征的专版DNN；最后依据输入与聚类中心的相似性选择对应的专版DNN进行推断，集成概念漂移检测机制以适应新兴模式的变化。

Result: 提出的方法在多种DNN架构（包括传统与最新的GluonTS库架构）上取得了显著的性能提升。

Conclusion: 该框架方法能有效解决非平稳时间序列中的预测挑战，具有广泛的应用性和较好的性能提升效果。

Abstract: Time series forecasting poses significant challenges in non-stationary
environments where underlying patterns evolve over time. In this work, we
propose a novel framework that enhances deep neural network (DNN) performance
by leveraging specialized model adaptation and selection. Initially, a base DNN
is trained offline on historical time series data. A reserved validation subset
is then segmented to extract and cluster the most dominant patterns within the
series, thereby identifying distinct regimes. For each identified cluster, the
base DNN is fine-tuned to produce a specialized version that captures unique
pattern characteristics. At inference, the most recent input is matched against
the cluster centroids, and the corresponding fine-tuned version is deployed
based on the closest similarity measure. Additionally, our approach integrates
a concept drift detection mechanism to identify and adapt to emerging patterns
caused by non-stationary behavior. The proposed framework is generalizable
across various DNN architectures and has demonstrated significant performance
gains on both traditional DNNs and recent advanced architectures implemented in
the GluonTS library.

</details>


### [504] [Shapley-Inspired Feature Weighting in $k$-means with No Additional Hyperparameters](https://arxiv.org/abs/2508.07952)
*Richard J. Fawley,Renato Cordeiro de Amorim*

Main category: cs.LG

TL;DR: 提出了一种名为SHARK的新型聚类算法，通过Shapley值为特征赋权，从而提高了聚类算法在高维和噪声环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有聚类算法假设所有特征对数据结构的贡献相等，这一假设在高维或噪声数据中不合理。需要一种自动且无需额外参数调节的特征加权方法。

Method: 使用Shapley值量化特征重要性，将k-means目标函数分解为每个特征的Shapley值，并且通过迭代过程根据Shapley值重权特征，强调重要特征并弱化无关特征。

Result: SHARK在合成和真实数据集上的实验中均表现优异，在存在噪声场景下表现出更高的鲁棒性和准确性，优于现有方法。

Conclusion: SHARK通过结合Shapley值和k-means，提供了一种无需额外参数的高效聚类解决方案，特别适用于高噪声环境。

Abstract: Clustering algorithms often assume all features contribute equally to the
data structure, an assumption that usually fails in high-dimensional or noisy
settings. Feature weighting methods can address this, but most require
additional parameter tuning. We propose SHARK (Shapley Reweighted $k$-means), a
feature-weighted clustering algorithm motivated by the use of Shapley values
from cooperative game theory to quantify feature relevance, which requires no
additional parameters beyond those in $k$-means. We prove that the $k$-means
objective can be decomposed into a sum of per-feature Shapley values, providing
an axiomatic foundation for unsupervised feature relevance and reducing Shapley
computation from exponential to polynomial time. SHARK iteratively re-weights
features by the inverse of their Shapley contribution, emphasising informative
dimensions and down-weighting irrelevant ones. Experiments on synthetic and
real-world data sets show that SHARK consistently matches or outperforms
existing methods, achieving superior robustness and accuracy, particularly in
scenarios where noise may be present. Software:
https://github.com/rickfawley/shark.

</details>


### [505] [WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer](https://arxiv.org/abs/2508.07970)
*Junyu Wu,Weiming Chang,Xiaotao Liu,Guanyou He,Tingfeng Xian,Haoqiang Hong,Boqi Chen,Haotao Tian,Tao Yang,Yunsheng Shi,Feng Lin,Ting Yao*

Main category: cs.LG

TL;DR: 本文提出了一种新的RLHF（基于人类反馈的强化学习）训练框架WeChat-YATT，该框架旨在解决现有训练体系在扩展复杂多模态工作流和动态工作负载方面的不足。


<details>
  <summary>Details</summary>
Motivation: RLHF虽然在大语言模型和多模态系统的训练中展现出巨大的潜力，但在应对动态采样与资源分配时仍存在控制器扩展性和管道协调效率低等问题。

Method: 提出了一种并行控制器编程模型并设计了动态放置方案，用于优化复杂训练过程中的资源分配与任务调度，从而改善硬件利用率和扩展能力。

Result: 实验结果表明，WeChat-YATT相较于现有的RLHF框架在吞吐量上有显著提升并成功应用于大规模用户相关的微信产品功能。

Conclusion: WeChat-YATT提供了一种高效、可扩展且实践验证有效的RLHF训练框架，为应对大型复杂数据环境中的挑战提供了解决方案。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has emerged as a prominent
paradigm for training large language models and multimodal systems. Despite
notable advances enabled by existing RLHF training frameworks, significant
challenges remain in scaling to complex multimodal workflows and adapting to
dynamic workloads. In particular, current systems often encounter limitations
related to controller scalability when managing large models, as well as
inefficiencies in orchestrating intricate RLHF pipelines, especially in
scenarios that require dynamic sampling and resource allocation. In this paper,
we introduce WeChat-YATT (Yet Another Transformer Trainer in WeChat), a simple,
scalable, and balanced RLHF training framework specifically designed to address
these challenges. WeChat-YATT features a parallel controller programming model
that enables flexible and efficient orchestration of complex RLHF workflows,
effectively mitigating the bottlenecks associated with centralized controller
architectures and facilitating scalability in large-scale data scenarios. In
addition, we propose a dynamic placement schema that adaptively partitions
computational resources and schedules workloads, thereby significantly reducing
hardware idle time and improving GPU utilization under variable training
conditions. We evaluate WeChat-YATT across a range of experimental scenarios,
demonstrating that it achieves substantial improvements in throughput compared
to state-of-the-art RLHF training frameworks. Furthermore, WeChat-YATT has been
successfully deployed to train models supporting WeChat product features for a
large-scale user base, underscoring its effectiveness and robustness in
real-world applications.

</details>


### [506] [A Physics-informed Deep Operator for Real-Time Freeway Traffic State Estimation](https://arxiv.org/abs/2508.08002)
*Hongxin Yu,Yibing Wang,Fengyue Jin,Meng Zhang,Anni Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于物理信息的深度算子网络（PI-DeepONet）的实时高速交通状态估计方法，并在宽大的城市快速路和NGSIM数据集中验证了其高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有交通状态估计方法分为模型驱动、数据驱动和模型-数据双驱动三类，亟需结合这些方法优点的高效估计算法。

Method: 本文提出了一种扩展的基于PI-DeepONet的架构，包括：支持2D数据输入的CNN计算、非线性扩展层、注意力机制、MIMO机制；同时设计了自适应流量模型参数识别的神经网络。

Result: 通过在NGSIM和中国某城市快速路数据集的验证，证明本文方法优于四种基线方法，在流量和平均速度估计中表现出高精度。

Conclusion: 该方法结合物理模型和深度学习架构，提高了交通状态估计的准确性，为交通流建模提供了一种新思路。

Abstract: Traffic state estimation (TSE) falls methodologically into three categories:
model-driven, data-driven, and model-data dual-driven. Model-driven TSE relies
on macroscopic traffic flow models originated from hydrodynamics. Data-driven
TSE leverages historical sensing data and employs statistical models or machine
learning methods to infer traffic state. Model-data dual-driven traffic state
estimation attempts to harness the strengths of both aspects to achieve more
accurate TSE. From the perspective of mathematical operator theory, TSE can be
viewed as a type of operator that maps available measurements of inerested
traffic state into unmeasured traffic state variables in real time. For the
first time this paper proposes to study real-time freeway TSE in the idea of
physics-informed deep operator network (PI-DeepONet), which is an
operator-oriented architecture embedding traffic flow models based on deep
neural networks. The paper has developed an extended architecture from the
original PI-DeepONet. The extended architecture is featured with: (1) the
acceptance of 2-D data input so as to support CNN-based computations; (2) the
introduction of a nonlinear expansion layer, an attention mechanism, and a MIMO
mechanism; (3) dedicated neural network design for adaptive identification of
traffic flow model parameters. A traffic state estimator built on the basis of
this extended PI-DeepONet architecture was evaluated with respect to a short
freeway stretch of NGSIM and a large-scale urban expressway in China, along
with other four baseline TSE methods. The evaluation results demonstrated that
this novel TSE method outperformed the baseline methods with high-precision
estimation results of flow and mean speed.

</details>


### [507] [Learning to Select MCP Algorithms: From Traditional ML to Dual-Channel GAT-MLP](https://arxiv.org/abs/2508.08005)
*Xiang Li,Shanshan Wang,Chenglong Xiao*

Main category: cs.LG

TL;DR: 该研究提出了一种基于机器学习和图神经网络的框架，通过构建数据集和实验分析，实现针对最大团问题的算法选择。


<details>
  <summary>Details</summary>
Motivation: 算法在最大团问题上的表现不一致，需要通过特定实例特征选择合适的算法，各研究中算法选择领域存在空缺。

Method: 利用机器学习技术与图神经网络，构建标注数据集，提取图的结构和统计特征，评估多种分类器性能并提出双通道模型GAT-MLP。

Result: 实验表明，随机森林分类器具有稳定性能。双通道模型GAT-MLP在多项指标上表现出色，揭示了图神经网络在组合算法选择中的潜力。

Conclusion: 双通道架构和图神经网络可以有效提升算法选择效率，推动相关问题的研究发展。

Abstract: Extensive experiments and prior studies show that no single maximum clique
algorithm consistently performs best across all instances, highlighting the
importance of selecting suitable algorithms based on instance features. Through
an extensive analysis of relevant studies, it is found that there is a lack of
research work concerning algorithm selection oriented toward the Maximum Clique
Problem (MCP). In this work, we propose a learning-based framework that
integrates both traditional machine learning and graph neural networks to
address this gap. We construct a labeled dataset by running four exact MCP
algorithms on a diverse collection of graph instances, accompanied by
structural and global statistical features extracted from each graph. We first
evaluate four conventional classifiers: Support Vector Machine (SVM), Random
Forest (RF), Decision Tree (DT), and K-Nearest Neighbors (KNN), across multiple
dataset variants. Experimental results show that RF consistently shows strong
performance across metrics and dataset variants, making it a reliable baseline.
In addition, feature importance analysis indicates that connectivity and
topological structure are strong predictors of algorithm performance. Building
on these findings, we develop a dual-channel model named GAT-MLP, which
combines a Graph Attention Network (GAT) for local structural encoding with a
Multilayer Perceptron (MLP) for global feature modeling. The GAT-MLP model
shows strong and consistent performance across all metrics. Our results
highlight the effectiveness of dual-channel architectures and the promise of
graph neural networks in combinatorial algorithm selection.

</details>


### [508] [Communication-Efficient Zero-Order and First-Order Federated Learning Methods over Wireless Networks](https://arxiv.org/abs/2508.08013)
*Mohamad Assaad,Zeinab Nehme,Merouane Debbah*

Main category: cs.LG

TL;DR: 论文探讨了在联邦学习中，通过减少通信开销和利用信道信息来提高效率的方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中，设备与聚合器之间的信息交换量巨大，超出无线系统容量，因此需要开发更高效的通信方法。

Method: 提出了两种通信高效的联邦学习方法：1. 使用零阶优化技术与两点梯度估计器；2. 使用一阶梯度计算策略，同时利用信道信息来减少资源需求，并考虑异步设备环境。

Result: 为两种方法提供严谨的分析框架，证明收敛性并建立性能界限。

Conclusion: 通过减少通信开销、充分利用信道信息以及支持异步设备，论文提出的方法提高了联邦学习的效率且具备理论保障。

Abstract: Federated Learning (FL) is an emerging learning framework that enables edge
devices to collaboratively train ML models without sharing their local data. FL
faces, however, a significant challenge due to the high amount of information
that must be exchanged between the devices and the aggregator in the training
phase, which can exceed the limited capacity of wireless systems. In this
paper, two communication-efficient FL methods are considered where
communication overhead is reduced by communicating scalar values instead of
long vectors and by allowing high number of users to send information
simultaneously. The first approach employs a zero-order optimization technique
with two-point gradient estimator, while the second involves a first-order
gradient computation strategy. The novelty lies in leveraging channel
information in the learning algorithms, eliminating hence the need for
additional resources to acquire channel state information (CSI) and to remove
its impact, as well as in considering asynchronous devices. We provide a
rigorous analytical framework for the two methods, deriving convergence
guarantees and establishing appropriate performance bounds.

</details>


### [509] [Deep Learning-Based Analysis of Power Consumption in Gasoline, Electric, and Hybrid Vehicles](https://arxiv.org/abs/2508.08034)
*Roksana Yahyaabadi,Ghazal Farhani,Taufiq Rahman,Soodeh Nikan,Abdullah Jirjees,Fadi Araji*

Main category: cs.LG

TL;DR: 本研究提出了一种基于动力总成动态特征集和机器学习及深度神经网络的数据驱动方法，可准确预测内燃机、电动车和混合动力车的即时时间和累计功耗。


<details>
  <summary>Details</summary>
Motivation: 现有依赖于专用仪器或僵化物理模型的功耗预测方法存在规模化实施困难，从而提出一种实用且可扩展的功耗预测方法。

Method: 采用动力总成动态特征集，结合传统机器学习与深度神经网络模型，构建了功耗预测方法，同时对内燃机、电动车和混合动力汽车进行了性能验证。

Result: 内燃机模型实现平均绝对误差和均方根误差约为$10^{-3}$，累计误差不到3%；变压器和长短期记忆网络对电动车和混合动力车表现最佳，累计误差分别低于4.1%和2.1%。

Conclusion: 提出的功耗预测方法在不同车辆和模型中表现出高效性，同时揭示了复杂动力管理导致的电动车和混合动力车数据集较大变量性，进一步展示了开发稳健模型的重要性。

Abstract: Accurate power consumption prediction is crucial for improving efficiency and
reducing environmental impact, yet traditional methods relying on specialized
instruments or rigid physical models are impractical for large-scale,
real-world deployment. This study introduces a scalable data-driven method
using powertrain dynamic feature sets and both traditional machine learning and
deep neural networks to estimate instantaneous and cumulative power consumption
in internal combustion engine (ICE), electric vehicle (EV), and hybrid electric
vehicle (HEV) platforms. ICE models achieved high instantaneous accuracy with
mean absolute error and root mean squared error on the order of $10^{-3}$, and
cumulative errors under 3%. Transformer and long short-term memory models
performed best for EVs and HEVs, with cumulative errors below 4.1% and 2.1%,
respectively. Results confirm the approach's effectiveness across vehicles and
models. Uncertainty analysis revealed greater variability in EV and HEV
datasets than ICE, due to complex power management, emphasizing the need for
robust models for advanced powertrains.

</details>


### [510] [BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models](https://arxiv.org/abs/2508.08040)
*Maozhen Zhang,Mengnan Zhao,Bo Wang*

Main category: cs.LG

TL;DR: 本文提出了BadPromptFL，一种针对提示词驱动的多模态联邦学习的后门攻击方法，以削弱协作模型的安全性。


<details>
  <summary>Details</summary>
Motivation: 在多模态联邦学习中，提示词驱动的学习在隐私保护下有效训练模型，但其潜在安全隐患尚未研究。

Method: 设计了一种攻击方法，恶意客户端通过共同优化局部后门触发器和提示嵌入，向全局聚合过程注入有毒提示。

Result: 实验表明，该方法在多个数据集和聚合协议下都能以较低参与度和高隐身性实现超过90%的攻击成功率。

Conclusion: 提示驱动的联邦学习在真实环境中的安全性需要进一步关注，其易受后门攻击威胁。

Abstract: Prompt-based tuning has emerged as a lightweight alternative to full
fine-tuning in large vision-language models, enabling efficient adaptation via
learned contextual prompts. This paradigm has recently been extended to
federated learning settings (e.g., PromptFL), where clients collaboratively
train prompts under data privacy constraints. However, the security
implications of prompt-based aggregation in federated multimodal learning
remain largely unexplored, leaving a critical attack surface unaddressed. In
this paper, we introduce \textbf{BadPromptFL}, the first backdoor attack
targeting prompt-based federated learning in multimodal contrastive models. In
BadPromptFL, compromised clients jointly optimize local backdoor triggers and
prompt embeddings, injecting poisoned prompts into the global aggregation
process. These prompts are then propagated to benign clients, enabling
universal backdoor activation at inference without modifying model parameters.
Leveraging the contextual learning behavior of CLIP-style architectures,
BadPromptFL achieves high attack success rates (e.g., \(>90\%\)) with minimal
visibility and limited client participation. Extensive experiments across
multiple datasets and aggregation protocols validate the effectiveness,
stealth, and generalizability of our attack, raising critical concerns about
the robustness of prompt-based federated learning in real-world deployments.

</details>


### [511] [On Understanding of the Dynamics of Model Capacity in Continual Learning](https://arxiv.org/abs/2508.08052)
*Supriyo Chakraborty,Krishnan Raghavan*

Main category: cs.LG

TL;DR: 本文提出了一个新的概念CLEMC，用于表征连续学习中神经网络的稳定性与可塑性平衡的动态变化，并通过实验验证了理论发现。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络在连续学习中稳定性与可塑性之间的矛盾，特别是当任务分布随时间变化时的表现问题。

Method: 引入CLEMC概念，开发差分方程来建模神经网络与任务数据及优化过程之间的动态关系，并通过理论分析和实验验证这一模型。

Result: 发现神经网络的有效容量（即稳定性与可塑性平衡点）本质上是非静态的，当新任务的分布与先前任务显著不同时，神经网络对新任务的表示能力降低。

Conclusion: 无论是神经网络的架构还是优化方法，新任务的分布显著变化都会导致网络的表现能力降低。本文通过实验在多种架构上验证了理论发现，强调了CLEMC的重要性。

Abstract: The stability-plasticity dilemma, closely related to a neural network's (NN)
capacity-its ability to represent tasks-is a fundamental challenge in continual
learning (CL). Within this context, we introduce CL's effective model capacity
(CLEMC) that characterizes the dynamic behavior of the stability-plasticity
balance point. We develop a difference equation to model the evolution of the
interplay between the NN, task data, and optimization procedure. We then
leverage CLEMC to demonstrate that the effective capacity-and, by extension,
the stability-plasticity balance point is inherently non-stationary. We show
that regardless of the NN architecture or optimization method, a NN's ability
to represent new tasks diminishes when incoming task distributions differ from
previous ones. We conduct extensive experiments to support our theoretical
findings, spanning a range of architectures-from small feedforward network and
convolutional networks to medium-sized graph neural networks and
transformer-based large language models with millions of parameters.

</details>


### [512] [C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction](https://arxiv.org/abs/2508.08071)
*Yunqing Li,Zixiang Tang,Jiaying Zhuang,Zhenyu Yang,Farhad Ameri,Jianbang Zhang*

Main category: cs.LG

TL;DR: 该论文提出了PMGraph，一个面向供应链的公开基准数据集，以及Cascade Multimodal Attributed Graph (C-MAG) 方法，用于增强链接预测精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统方法无法有效捕捉制造商档案中复杂属性（如认证地理限制和多模态数据）的问题，以改善全球供应链的韧性和效率。

Method: 提出了一个两阶段的C-MAG架构，首先对文本和视觉属性进行对齐与聚合以生成中间嵌入，然后通过制造商与产品的异构图进行多尺度信息传播，提升链接预测性能。

Result: C-MAG提升了多模态数据环境下链接预测的性能，并提供了应对噪声挑战的融合指南。

Conclusion: 通过利用异构多模态图和先进的属性融合方法，C-MAG在复杂供应链数据中表现出较高的实际应用价值。

Abstract: Connecting an ever-expanding catalogue of products with suitable
manufacturers and suppliers is critical for resilient, efficient global supply
chains, yet traditional methods struggle to capture complex capabilities,
certifications, geographic constraints, and rich multimodal data of real-world
manufacturer profiles. To address these gaps, we introduce PMGraph, a public
benchmark of bipartite and heterogeneous multimodal supply-chain graphs linking
8,888 manufacturers, over 70k products, more than 110k manufacturer-product
edges, and over 29k product images. Building on this benchmark, we propose the
Cascade Multimodal Attributed Graph C-MAG, a two-stage architecture that first
aligns and aggregates textual and visual attributes into intermediate group
embeddings, then propagates them through a manufacturer-product hetero-graph
via multiscale message passing to enhance link prediction accuracy. C-MAG also
provides practical guidelines for modality-aware fusion, preserving predictive
performance in noisy, real-world settings.

</details>


### [513] [ELF: Efficient Logic Synthesis by Pruning Redundancy in Refactoring](https://arxiv.org/abs/2508.08073)
*Dimitris Tsaras,Xing Li,Lei Chen,Zhiyao Xie,Mingxuan Yuan*

Main category: cs.LG

TL;DR: 论文提出利用分类器预先修剪无效的迭代切割，减少重综合操作，从而加速逻辑优化过程。


<details>
  <summary>Details</summary>
Motivation: 现有逻辑优化操作需要高计算成本并且成功率低，促使研究者寻求更高效的解决方案。

Method: 提出了一种使用分类器对逻辑切割进行预筛选的方法，避免对失败的切割进行不必要的重综合操作。

Result: 在EPFL基准测试套件和10个大型工业设计上的实验表明，与最先进的ABC实现相比，该方法使逻辑优化平均加速3.9倍。

Conclusion: 通过引入分类器预筛选无效操作的机制，显著提升了逻辑优化的效率，可作为电子设计自动化领域的有效优化手段。

Abstract: In electronic design automation, logic optimization operators play a crucial
role in minimizing the gate count of logic circuits. However, their computation
demands are high. Operators such as refactor conventionally form iterative cuts
for each node, striving for a more compact representation - a task which often
fails 98% on average. Prior research has sought to mitigate computational cost
through parallelization. In contrast, our approach leverages a classifier to
prune unsuccessful cuts preemptively, thus eliminating unnecessary resynthesis
operations. Experiments on the refactor operator using the EPFL benchmark suite
and 10 large industrial designs demonstrate that this technique can speedup
logic optimization by 3.9x on average compared with the state-of-the-art ABC
implementation.

</details>


### [514] [Fast and Generalizable parameter-embedded Neural Operators for Lithium-Ion Battery Simulation](https://arxiv.org/abs/2508.08087)
*Amir Ali Panahi,Daniel Luder,Billy Wu,Gregory Offer,Dirk Uwe Sauer,Weihan Li*

Main category: cs.LG

TL;DR: 本研究比较了三种操作学习代理（DeepONet、FNO和PE-FNO）在锂电池单颗粒模型仿真中的性能，结果显示PE-FNO在精度、速度和参数弹性方面表现出出色的能力。


<details>
  <summary>Details</summary>
Motivation: 开发速度快、精度高且具有参数灵活性的数字孪生技术，用于锂电池的实时管理和实验设计需求。

Method: 使用三种操作学习代理模型（DeepONet、FNO和PE-FNO）对单颗粒模型（SPM）进行逼近，模拟和分析多种电流类型下的锂电池行为，同时引入参数嵌入以提升模型在变量条件下的表现。

Result: FNO在所有负载类型下浓度错误低于1%，电压均方误差小于1.7 mV。PE-FNO尽管略增加了误差，但其速度快200倍，支持不同半径和扩散率的泛化，在参数估计任务中表现优异。

Conclusion: PE-FNO在精度、速度及参数灵活性方面超越传统神经网络代理，为高效高保真电化学数字孪生提供了实际解决方案。

Abstract: Reliable digital twins of lithium-ion batteries must achieve high physical
fidelity with sub-millisecond speed. In this work, we benchmark three
operator-learning surrogates for the Single Particle Model (SPM): Deep Operator
Networks (DeepONets), Fourier Neural Operators (FNOs) and a newly proposed
parameter-embedded Fourier Neural Operator (PE-FNO), which conditions each
spectral layer on particle radius and solid-phase diffusivity. Models are
trained on simulated trajectories spanning four current families (constant,
triangular, pulse-train, and Gaussian-random-field) and a full range of
State-of-Charge (SOC) (0 % to 100 %). DeepONet accurately replicates
constant-current behaviour but struggles with more dynamic loads. The basic FNO
maintains mesh invariance and keeps concentration errors below 1 %, with
voltage mean-absolute errors under 1.7 mV across all load types. Introducing
parameter embedding marginally increases error, but enables generalisation to
varying radii and diffusivities. PE-FNO executes approximately 200 times faster
than a 16-thread SPM solver. Consequently, PE-FNO's capabilities in inverse
tasks are explored in a parameter estimation task with Bayesian optimisation,
recovering anode and cathode diffusivities with 1.14 % and 8.4 % mean absolute
percentage error, respectively, and 0.5918 percentage points higher error in
comparison with classical methods. These results pave the way for neural
operators to meet the accuracy, speed and parametric flexibility demands of
real-time battery management, design-of-experiments and large-scale inference.
PE-FNO outperforms conventional neural surrogates, offering a practical path
towards high-speed and high-fidelity electrochemical digital twins.

</details>


### [515] [Grid2Guide: A* Enabled Small Language Model for Indoor Navigation](https://arxiv.org/abs/2508.08100)
*Md. Wasiul Haque,Sagar Dasgupta,Mizanur Rahman*

Main category: cs.LG

TL;DR: 该研究提出了Grid2Guide，一个结合A*算法与小型语言模型的导航框架，用于生成清晰的室内路径指引。


<details>
  <summary>Details</summary>
Motivation: 目前室内导航在外界定位信号或基础设施缺乏的复杂环境中存在挑战，需开发一种无需基础设施的可靠导航方法。

Method: 通过A*算法在二值化占用矩阵上计算最优路径生成文本导航，再用小型语言模型转化为自然语言指南。

Result: 实验表明，该方法在多种室内场景下效果良好，可准确及时地生成导航指引。

Conclusion: 提出的方法是一种轻量级、无需基础设施的可靠室内实时导航解决方案。

Abstract: Reliable indoor navigation remains a significant challenge in complex
environments, particularly where external positioning signals and dedicated
infrastructures are unavailable. This research presents Grid2Guide, a hybrid
navigation framework that combines the A* search algorithm with a Small
Language Model (SLM) to generate clear, human-readable route instructions. The
framework first conducts a binary occupancy matrix from a given indoor map.
Using this matrix, the A* algorithm computes the optimal path between origin
and destination, producing concise textual navigation steps. These steps are
then transformed into natural language instructions by the SLM, enhancing
interpretability for end users. Experimental evaluations across various indoor
scenarios demonstrate the method's effectiveness in producing accurate and
timely navigation guidance. The results validate the proposed approach as a
lightweight, infrastructure-free solution for real-time indoor navigation
support.

</details>


### [516] [Vision-Based Localization and LLM-based Navigation for Indoor Environments](https://arxiv.org/abs/2508.08120)
*Keyan Rahimi,Md. Wasiul Haque,Sagar Dasgupta,Mizanur Rahman*

Main category: cs.LG

TL;DR: 研究提出了一种室内导航方法，将基于视觉的定位与大语言模型（LLM）导航相结合，实现无需基础设施的室内导航。


<details>
  <summary>Details</summary>
Motivation: 旨在解决室内导航中因缺少GPS信号和建筑环境复杂性带来的挑战，开发一种适用于资源受限场景的可扩展导航方案。

Method: 定位模块采用ResNet-50卷积神经网络，通过两阶段微调识别用户位置，导航模块借助LLM（如ChatGPT），解析楼层平面图并生成逐步导航指令。

Result: 实验表明，定位系统在所有测试点的准确率高达96%，导航模块指令准确率平均为75%。

Conclusion: 研究验证了使用智能手机摄像头和公开楼层图即能实现室内导航的潜力，尤其适用于医院、机场等资源受限环境。

Abstract: Indoor navigation remains a complex challenge due to the absence of reliable
GPS signals and the architectural intricacies of large enclosed environments.
This study presents an indoor localization and navigation approach that
integrates vision-based localization with large language model (LLM)-based
navigation. The localization system utilizes a ResNet-50 convolutional neural
network fine-tuned through a two-stage process to identify the user's position
using smartphone camera input. To complement localization, the navigation
module employs an LLM, guided by a carefully crafted system prompt, to
interpret preprocessed floor plan images and generate step-by-step directions.
Experimental evaluation was conducted in a realistic office corridor with
repetitive features and limited visibility to test localization robustness. The
model achieved high confidence and an accuracy of 96% across all tested
waypoints, even under constrained viewing conditions and short-duration
queries. Navigation tests using ChatGPT on real building floor maps yielded an
average instruction accuracy of 75%, with observed limitations in zero-shot
reasoning and inference time. This research demonstrates the potential for
scalable, infrastructure-free indoor navigation using off-the-shelf cameras and
publicly available floor plans, particularly in resource-constrained settings
like hospitals, airports, and educational institutions.

</details>


### [517] [MemoryKT: An Integrative Memory-and-Forgetting Method for Knowledge Tracing](https://arxiv.org/abs/2508.08122)
*Mingrong Lin,Ke Deng,Zhengyang Wu,Zetao Zheng,Jie Li*

Main category: cs.LG

TL;DR: 本文提出memoryKT模型，通过模拟学生记忆动态过程提升知识追踪的性能和解释性，在四个公共数据集上的实验表现显著优于最新基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究在知识追踪中忽略了记忆过程的细节及个性化遗忘模式。

Method: 基于时间变分自编码器（temporal variational autoencoder），通过三阶段流程（学习记忆分布、重构反馈及嵌入个性化遗忘模块）模拟记忆动态过程。

Result: 模型显著优于最先进基线方法，证明其有效性。

Conclusion: memoryKT模型全面模拟记忆过程，提高了个体差异的感知能力，显著提升知识追踪的性能和解释性。

Abstract: Knowledge Tracing (KT) is committed to capturing students' knowledge mastery
from their historical interactions. Simulating students' memory states is a
promising approach to enhance both the performance and interpretability of
knowledge tracing models. Memory consists of three fundamental processes:
encoding, storage, and retrieval. Although forgetting primarily manifests
during the storage stage, most existing studies rely on a single,
undifferentiated forgetting mechanism, overlooking other memory processes as
well as personalized forgetting patterns. To address this, this paper proposes
memoryKT, a knowledge tracing model based on a novel temporal variational
autoencoder. The model simulates memory dynamics through a three-stage process:
(i) Learning the distribution of students' knowledge memory features, (ii)
Reconstructing their exercise feedback, while (iii) Embedding a personalized
forgetting module within the temporal workflow to dynamically modulate memory
storage strength. This jointly models the complete encoding-storage-retrieval
cycle, significantly enhancing the model's perception capability for individual
differences. Extensive experiments on four public datasets demonstrate that our
proposed approach significantly outperforms state-of-the-art baselines.

</details>


### [518] [NeuroDx-LM: A Clinical Large-Scale Model for EEG-based Neurological Disorder Detection](https://arxiv.org/abs/2508.08124)
*Guanghao Jin,Yuan Liang,Yihan Ma,Jingpei Wu,Guoyang Liu*

Main category: cs.LG

TL;DR: 本文提出了专注于EEG为基础的神经疾病检测的大规模模型NeuroDx-LM，该模型通过创新的时间-频率嵌入和分阶段特征训练策略，实现了在CHB-MIT和精神分裂症数据集上的表现超越当前水平。


<details>
  <summary>Details</summary>
Motivation: 目前EEG的大规模预训练模型在临床中应用受限于数据标注少以及模型性能不理想的问题，亟需设计一个能够在临床场景中表现优越的新模型。

Method: 引入了一种选择性时间-频率嵌入机制以适应EEG信号的复杂时间和频谱模式，以及一种分阶段特征优化训练方法。第一阶段提取基础判别特征，第二阶段进一步提取精细特征以提升诊断能力。

Result: 在CHB-MIT与精神分裂症数据集上，NeuroDx-LM 在EEG基础的癫痫与精神分裂症检测中表现出了领先的性能。

Conclusion: NeuroDx-LM 展现了EEG大规模模型在临床应用中的巨大潜力，为未来的神经疾病检测提供了新的解决方案。

Abstract: Large-scale models pre-trained on Electroencephalography (EEG) have shown
promise in clinical applications such as neurological disorder detection.
However, the practical deployment of EEG-based large-scale models faces
critical challenges such as limited labeled EEG data and suboptimal performance
in clinical scenarios. To address these issues, we propose NeuroDx-LM, a novel
large-scale model specifically designed for detecting EEG-based neurological
disorders. Our key contributions include (i) a Selective Temporal-Frequency
Embedding mechanism that adaptively captures complex temporal and spectral
patterns in EEG signals; and (ii) a Progressive Feature-Aware Training strategy
that refines feature representation in a two-stage process. In the first stage,
our model learns the fundamental discriminative features of EEG activities; in
the second stage, the model further extracts more specialized fine-grained
features for accurate diagnostic performance. We evaluated NeuroDx-LM on the
CHB-MIT and Schizophrenia datasets, achieving state-of-the-art performance in
EEG-based seizure and schizophrenia detection, respectively. These results
demonstrate the great potential of EEG-based large-scale models to advance
clinical applicability. Our code is available at
https://github.com/LetItBe12345/NeuroDx-LM.

</details>


### [519] [OFAL: An Oracle-Free Active Learning Framework](https://arxiv.org/abs/2508.08126)
*Hadi Khorsand,Vahid Pourahmadi*

Main category: cs.LG

TL;DR: 提出了一种不依赖Oracle的主动学习方法（OFAL），通过神经网络的不确定性生成新样本，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 在面对大量无标签数据时，传统基于Oracle的标签标注过程复杂且成本高，需要一种减少对Oracle依赖的方式以提高效率。

Method: 使用Monte Carlo Dropouts对不确定性进行分解和量化，引入变分自编码器生成不确定样本，并结合已有主动学习方法进行对比研究。

Result: 通过生成具有信息量的新样本，证实了该方法能够提升模型的准确性。

Conclusion: Oracle-free的主动学习方法能够有效减少对Oracle的依赖，同时提升学习效率和模型性能。

Abstract: In the active learning paradigm, using an oracle to label data has always
been a complex and expensive task, and with the emersion of large unlabeled
data pools, it would be highly beneficial If we could achieve better results
without relying on an oracle. This research introduces OFAL, an oracle-free
active learning scheme that utilizes neural network uncertainty. OFAL uses the
model's own uncertainty to transform highly confident unlabeled samples into
informative uncertain samples. First, we start with separating and quantifying
different parts of uncertainty and introduce Monte Carlo Dropouts as an
approximation of the Bayesian Neural Network model. Secondly, by adding a
variational autoencoder, we go on to generate new uncertain samples by stepping
toward the uncertain part of latent space starting from a confidence seed
sample. By generating these new informative samples, we can perform active
learning and enhance the model's accuracy. Lastly, we try to compare and
integrate our method with other widely used active learning sampling methods.

</details>


### [520] [MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation](https://arxiv.org/abs/2508.08137)
*Pravallika Abbineni,Saoud Aldowaish,Colin Liechty,Soroosh Noorzad,Ali Ghazizadeh,Morteza Fayazi*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为MuaLLM的开源多模态大型语言模型，用于电路设计辅助，能够高效处理文本与视觉数据，性能优越，成本低且速度快。


<details>
  <summary>Details</summary>
Motivation: 当前电路设计领域文献综述工作因研究快速发展、不一致的数据表示及复杂的优化目标而面临挑战。

Method: 提出MuaLLM，一种结合混合型检索增强生成框架与自适应矢量数据库的多模态LLM，采用Reason + Act (ReAct) 工作流程以及动态检索和实时数据库更新技术。

Result: MuaLLM在检索任务RAG-250中达到90.1%的召回率，在推理任务Reas-100中获得86.8%的准确率。此外，相较标准LLM，该模型成本降低至1/10，速度提升1.6倍，同时保持相同精度。

Conclusion: MuaLLM能够有效克服现有方法的局限性，支持大规模数据推理，在电路设计文献分析与综述领域具有显著优势。

Abstract: Conducting a comprehensive literature review is crucial for advancing circuit
design methodologies. However, the rapid influx of state-of-the-art research,
inconsistent data representation, and the complexity of optimizing circuit
design objectives make this task significantly challenging. In this paper, we
propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for
circuit design assistance that integrates a hybrid Retrieval-Augmented
Generation (RAG) framework with an adaptive vector database of circuit design
research papers. Unlike conventional LLMs, the MuaLLM agent employs a Reason +
Act (ReAct) workflow for iterative reasoning, goal-setting, and multi-step
information retrieval. It functions as a question-answering design assistant,
capable of interpreting complex queries and providing reasoned responses
grounded in circuit literature. Its multimodal capabilities enable processing
of both textual and visual data, facilitating more efficient and comprehensive
analysis. The system dynamically adapts using intelligent search tools,
automated document retrieval from the internet, and real-time database updates.
Unlike conventional approaches constrained by model context limits, MuaLLM
decouples retrieval from inference, enabling scalable reasoning over
arbitrarily large corpora. At the maximum context length supported by standard
LLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining
the same accuracy. This allows rapid, no-human-in-the-loop database generation,
overcoming the bottleneck of simulation-based dataset creation for circuits. To
evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval
and citation performance, and Reasoning-100 (Reas-100), focused on multistep
reasoning in circuit design. MuaLLM achieves 90.1% recall on RAG-250, and 86.8%
accuracy on Reas-100.

</details>


### [521] [FairFLRep: Fairness aware fault localization and repair of Deep Neural Networks](https://arxiv.org/abs/2508.08151)
*Moses Openja,Paolo Arcaini,Foutse Khomh,Fuyuki Ishikawa*

Main category: cs.LG

TL;DR: 本文介绍了一种名为FairFLRep的技术，用于在深度神经网络中自动定位和修复偏见，提升公平性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在高风险决策场景中可能反映和放大数据中的偏见，导致不公平和错误决策，亟需一种有效的方法来发现并纠正这些问题。

Method: 提出FairFLRep方法，通过分析网络输入输出关系，调整与敏感属性相关的神经元的权重，从而修复导致决策不公的神经元。

Result: 在四个图像分类数据集和四个表格数据集上的实验结果表明，FairFLRep在改善公平性和保持准确性方面均优于现有方法。

Conclusion: FairFLRep不仅提高了决策公平性，还在定位和修复效率上表现优越，验证了其作为一种有效方法的价值。

Abstract: Deep neural networks (DNNs) are being utilized in various aspects of our
daily lives, including high-stakes decision-making applications that impact
individuals. However, these systems reflect and amplify bias from the data used
during training and testing, potentially resulting in biased behavior and
inaccurate decisions. For instance, having different misclassification rates
between white and black sub-populations. However, effectively and efficiently
identifying and correcting biased behavior in DNNs is a challenge. This paper
introduces FairFLRep, an automated fairness-aware fault localization and repair
technique that identifies and corrects potentially bias-inducing neurons in DNN
classifiers. FairFLRep focuses on adjusting neuron weights associated with
sensitive attributes, such as race or gender, that contribute to unfair
decisions. By analyzing the input-output relationships within the network,
FairFLRep corrects neurons responsible for disparities in predictive quality
parity. We evaluate FairFLRep on four image classification datasets using two
DNN classifiers, and four tabular datasets with a DNN model. The results show
that FairFLRep consistently outperforms existing methods in improving fairness
while preserving accuracy. An ablation study confirms the importance of
considering fairness during both fault localization and repair stages. Our
findings also show that FairFLRep is more efficient than the baseline
approaches in repairing the network.

</details>


### [522] [Federated Learning for Epileptic Seizure Prediction Across Heterogeneous EEG Datasets](https://arxiv.org/abs/2508.08159)
*Cem Ata Baykara,Saurav Raj Pandey,Ali Burak Ünal,Harlin Lee,Mete Akgün*

Main category: cs.LG

TL;DR: 这篇论文提出了一个利用联邦学习改进癫痫发作预测的策略，通过在四个多样化公共数据集上，实现了自动化和公平的模型性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决癫痫发作预测模型因隐私规定和数据异质性（非独立同分布特性）带来的困难。

Method: 提出隐私保护的全局归一化和随机子集聚合策略，每轮让每个客户端仅训练其数据的固定随机子集，以确保聚合时的平等贡献。

Result: 随机子集聚合显著提升了相对弱势客户端的性能，提高了整体和宏观平均准确率，展示了更稳健公平的全球模型表现。

Conclusion: 在多院设置中，平衡的联邦学习方法有潜力构建高效、可推广的癫痫预测系统，同时尊重数据隐私。

Abstract: Developing accurate and generalizable epileptic seizure prediction models
from electroencephalography (EEG) data across multiple clinical sites is
hindered by patient privacy regulations and significant data heterogeneity
(non-IID characteristics). Federated Learning (FL) offers a privacy-preserving
framework for collaborative training, but standard aggregation methods like
Federated Averaging (FedAvg) can be biased by dominant datasets in
heterogeneous settings. This paper investigates FL for seizure prediction using
a single EEG channel across four diverse public datasets (Siena, CHB-MIT,
Helsinki, NCH), representing distinct patient populations (adult, pediatric,
neonate) and recording conditions. We implement privacy-preserving global
normalization and propose a Random Subset Aggregation strategy, where each
client trains on a fixed-size random subset of its data per round, ensuring
equal contribution during aggregation. Our results show that locally trained
models fail to generalize across sites, and standard weighted FedAvg yields
highly skewed performance (e.g., 89.0% accuracy on CHB-MIT but only 50.8% on
Helsinki and 50.6% on NCH). In contrast, Random Subset Aggregation
significantly improves performance on under-represented clients (accuracy
increases to 81.7% on Helsinki and 68.7% on NCH) and achieves a superior
macro-average accuracy of 77.1% and pooled accuracy of 80.0% across all sites,
demonstrating a more robust and fair global model. This work highlights the
potential of balanced FL approaches for building effective and generalizable
seizure prediction systems in realistic, heterogeneous multi-hospital
environments while respecting data privacy.

</details>


### [523] [Neural Logic Networks for Interpretable Classification](https://arxiv.org/abs/2508.08172)
*Vincent Perreault,Katsumi Inoue,Richard Labib,Alain Hertz*

Main category: cs.LG

TL;DR: 提出了一种扩展的神经逻辑网络，结合了NOT运算和偏置，用于提升逻辑和概率建模能力，并在布尔网络发现与可解释性分类任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络尽管分类性能出色，但缺乏可解释性，而神经逻辑网络虽具可解释性结构，但存在局限性，需进一步扩展其表达能力。

Method: 通过加入NOT操作和偏置，发展出一种新的逻辑与概率建模框架，同时提出了因子化的IF-THEN规则结构及一种改进的学习算法。

Result: 改进了布尔网络发现的最优表现，并能够在分类任务中学习到相关性高且可解释的规则，特别是在医疗领域展示了其显著价值。

Conclusion: 扩展的神经逻辑网络框架具备更强的建模能力和分类性能，尤其在需要可解释性的领域具有巨大潜力。

Abstract: Traditional neural networks have an impressive classification performance,
but what they learn cannot be inspected, verified or extracted. Neural Logic
Networks on the other hand have an interpretable structure that enables them to
learn a logical mechanism relating the inputs and outputs with AND and OR
operations. We generalize these networks with NOT operations and biases that
take into account unobserved data and develop a rigorous logical and
probabilistic modeling in terms of concept combinations to motivate their use.
We also propose a novel factorized IF-THEN rule structure for the model as well
as a modified learning algorithm. Our method improves the state-of-the-art in
Boolean networks discovery and is able to learn relevant, interpretable rules
in tabular classification, notably on an example from the medical field where
interpretability has tangible value.

</details>


### [524] [Cross-Subject and Cross-Montage EEG Transfer Learning via Individual Tangent Space Alignment and Spatial-Riemannian Feature Fusion](https://arxiv.org/abs/2508.08216)
*Nicole Lai-Tan,Xiao Gu,Marios G. Philiastides,Fani Deligianni*

Main category: cs.LG

TL;DR: 该研究提出了一种名为ITSA的新方法，通过个体化调节音乐干预以支持运动康复，展示了其在跨个体泛化性方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有脑-机接口面临跨个体EEG信号的泛化性问题，尤其是在运动引起的伪影和个体运动规划差异的影响下。

Method: 提出了个体切线空间对齐（ITSA）策略，包括个体化重心调整、分布匹配和监督旋转对齐，并采用融合正则化共同空间模式和黎曼几何的混合架构。

Result: 通过跨个体交叉验证，ITSA在不同实验条件和电极配置下表现出显著的性能提升，尤其平行融合方法优于序列融合方法。

Conclusion: ITSA提高了脑-机接口的跨个体泛化性，为个性化音乐干预和运动康复提供了一种可行的方法。

Abstract: Personalised music-based interventions offer a powerful means of supporting
motor rehabilitation by dynamically tailoring auditory stimuli to provide
external timekeeping cues, modulate affective states, and stabilise gait
patterns. Generalisable Brain-Computer Interfaces (BCIs) thus hold promise for
adapting these interventions across individuals. However, inter-subject
variability in EEG signals, further compounded by movement-induced artefacts
and motor planning differences, hinders the generalisability of BCIs and
results in lengthy calibration processes. We propose Individual Tangent Space
Alignment (ITSA), a novel pre-alignment strategy incorporating subject-specific
recentering, distribution matching, and supervised rotational alignment to
enhance cross-subject generalisation. Our hybrid architecture fuses Regularised
Common Spatial Patterns (RCSP) with Riemannian geometry in parallel and
sequential configurations, improving class separability while maintaining the
geometric structure of covariance matrices for robust statistical computation.
Using leave-one-subject-out cross-validation, `ITSA' demonstrates significant
performance improvements across subjects and conditions. The parallel fusion
approach shows the greatest enhancement over its sequential counterpart, with
robust performance maintained across varying data conditions and electrode
configurations. The code will be made publicly available at the time of
publication.

</details>


### [525] [Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent](https://arxiv.org/abs/2508.08222)
*Tong Yang,Yu Huang,Yingbin Liang,Yuejie Chi*

Main category: cs.LG

TL;DR: 研究了Transformer如何通过训练获得解决多步推理任务的能力，理论分析表明，即使是简单的一层Transformer也可以学习解决复杂的路径搜索问题，并提供了模型学习的机制性解释。


<details>
  <summary>Details</summary>
Motivation: 理解Transformer在多步推理任务中的学习原理，尤其是在符号化推理问题中的具体表现方式。

Method: 通过结合理论分析和梯度下降动力学，研究了Transformer对树图路径查找问题的学习过程，并对任务分解及不同注意力头的协调机制展开探索。

Result: 结果表明，一层的Transformer可以通过训练解决复杂的路径推理问题，并能推广到不可见的树图，同时解释了其多阶段的解决路径。

Conclusion: Transformer在任务结构化为中间逻辑步骤时，即使是浅层模型也能够高效解决复杂问题，为其推理能力的形成机制提供了一种理论依据。

Abstract: Transformers have demonstrated remarkable capabilities in multi-step
reasoning tasks. However, understandings of the underlying mechanisms by which
they acquire these abilities through training remain limited, particularly from
a theoretical standpoint. This work investigates how transformers learn to
solve symbolic multi-step reasoning problems through chain-of-thought
processes, focusing on path-finding in trees. We analyze two intertwined tasks:
a backward reasoning task, where the model outputs a path from a goal node to
the root, and a more complex forward reasoning task, where the model implements
two-stage reasoning by first identifying the goal-to-root path and then
reversing it to produce the root-to-goal path. Our theoretical analysis,
grounded in the dynamics of gradient descent, shows that trained one-layer
transformers can provably solve both tasks with generalization guarantees to
unseen trees. In particular, our multi-phase training dynamics for forward
reasoning elucidate how different attention heads learn to specialize and
coordinate autonomously to solve the two subtasks in a single autoregressive
path. These results provide a mechanistic explanation of how trained
transformers can implement sequential algorithmic procedures. Moreover, they
offer insights into the emergence of reasoning abilities, suggesting that when
tasks are structured to take intermediate chain-of-thought steps, even shallow
multi-head transformers can effectively solve problems that would otherwise
require deeper architectures.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [526] [Reservoir computing with large valid prediction time for the Lorenz system](https://arxiv.org/abs/2508.06730)
*Lauren A Hurley,Sean E Shaheen*

Main category: cs.NE

TL;DR: 本文研究了储备计算器的有效预测时间（VPT）与其超参数的关系，并得出了在特定情况下VPT可达高性能的条件。


<details>
  <summary>Details</summary>
Motivation: 试图探索如何通过优化储备计算器的设置来提高对系统行为的预测时间，尤其在无噪声系统中。

Method: 研究超参数如正则化系数、储备大小和谱半径对VPT的影响；提出用Lyapunov指数预测VPT的方法；定义有效的地面真值时间（VGTT），来判断超出此时间的VPT是否有意义。

Result: 在特定条件下，储备计算器能达到基准性能的70%，并在无噪声系统中实现超过30个Lyapunov时间的高VPT值；确立了两种谱半径状态下的大VPT表现：接近零的小半径和处于“混沌边缘”的大半径。

Conclusion: 优化储备计算器的超参数可显著提高其预测能力；本文提出的方法在无噪声系统中适用性强，亦可能对有限噪声的实际应用有帮助。

Abstract: We study the dependence of the Valid Prediction Time (VPT) of Reservoir
Computers (RCs) on hyperparameters including the regularization coefficient,
reservoir size, and spectral radius. Under carefully chosen conditions, the RC
can achieve approximately 70% of a benchmark performance, based on the output
of a single prediction step used as initial conditions for the Lorenz
equations. We report high VPT values (>30 Lyapunov times), as we are predicting
a noiseless system where overfitting can be beneficial. While these conditions
may not hold for noisy systems, they could still be useful for real-world
applications with limited noise. Furthermore, utilizing knowledge of the
Lyapunov exponent, we find that the VPT can be predicted by the error in the
first few prediction steps, offering a computationally efficient evaluation
method. We emphasize the importance of the numerical solver used to generate
the Lorenz dataset and define a Valid Ground Truth Time (VGTT), during which
the outputs of several common solvers agree. A VPT exceeding the VGTT is not
meaningful, as a different solver could produce a different result. Lastly, we
identify two spectral radius regimes that achieve large VPT: a small radius
near zero, resulting in simple but stable operation, and a larger radius
operating at the "edge of chaos."

</details>


### [527] [Geometry-Aware Spiking Graph Neural Network](https://arxiv.org/abs/2508.06793)
*Bowen Zhang,Genan Dai,Hu Huang,Long Lan*

Main category: cs.NE

TL;DR: 提出了一种名为Geometry-Aware Spiking Graph Neural Network (GSG)的新方法，将尖峰神经网络的能效与黎曼流形上的自适应表示学习相结合，提升对复杂图结构的建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有的尖峰图神经网络(SNNs)主要局限于欧几里得空间，无法有效建模复杂的图结构如层次或循环，提出此研究以解决该问题。

Method: GSG包括三个核心模块：1.黎曼嵌入层，将节点特征投影到恒曲率流形中；2.流形尖峰层，在曲面空间中实现潜在变化和尖峰行为的模型；3.流形学习目标，通过与分类和链接预测联合优化的几何适配机制，适应实例几何。

Result: 实验表明，与欧几里得尖峰神经网络(SNNs)和基于流形的图神经网络(GNNs)相比，GSG在准确性、鲁棒性和能效上具有显著提升。

Conclusion: GSG建立了一个曲率感知和能效图学习的新范式，适用于复杂的图结构建模。

Abstract: Graph Neural Networks (GNNs) have demonstrated impressive capabilities in
modeling graph-structured data, while Spiking Neural Networks (SNNs) offer high
energy efficiency through sparse, event-driven computation. However, existing
spiking GNNs predominantly operate in Euclidean space and rely on fixed
geometric assumptions, limiting their capacity to model complex graph
structures such as hierarchies and cycles. To overcome these limitations, we
propose \method{}, a novel Geometry-Aware Spiking Graph Neural Network that
unifies spike-based neural dynamics with adaptive representation learning on
Riemannian manifolds. \method{} features three key components: a Riemannian
Embedding Layer that projects node features into a pool of constant-curvature
manifolds, capturing non-Euclidean structures; a Manifold Spiking Layer that
models membrane potential evolution and spiking behavior in curved spaces via
geometry-consistent neighbor aggregation and curvature-based attention; and a
Manifold Learning Objective that enables instance-wise geometry adaptation
through jointly optimized classification and link prediction losses defined
over geodesic distances. All modules are trained using Riemannian SGD,
eliminating the need for backpropagation through time. Extensive experiments on
multiple benchmarks show that GSG achieves superior accuracy, robustness, and
energy efficiency compared to both Euclidean SNNs and manifold-based GNNs,
establishing a new paradigm for curvature-aware, energy-efficient graph
learning.

</details>


### [528] [Memory Enhanced Fractional-Order Dung Beetle Optimization for Photovoltaic Parameter Identification](https://arxiv.org/abs/2508.06841)
*Yiwei Li,Zhihua Allen-Zhao,Yuncheng Xu,Sanyang Liu*

Main category: cs.NE

TL;DR: 为解决光伏模型中非线性、多模态、高维问题，该研究提出了记忆增强分数阶Dung Beetle优化算法（MFO-DBO），显著提升了参数识别的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 光伏模型的参数识别因其复杂的特性依然是一个挑战，现有的Dung Beetle优化方法容易出现早熟收敛问题，需要一种更稳定且高效的改进算法。

Method: 通过整合三种策略提出MFO-DBO算法：分数阶（FO）计算引入记忆性改善收敛稳定性，分数阶混沌映射增强种群多样性以及混沌扰动机制帮助精英解跳出局部最优。

Result: 在CEC2017基准测试集和PV参数识别任务中的试验结果表明，MFO-DBO在准确性、鲁棒性、收敛速度等方面优于各类DBO改进方法和其他优化算法，并达到了探索与开发之间的优秀平衡。

Conclusion: MFO-DBO算法有效克服了传统DBO的局限性，为光伏模型参数识别提供了一种更高效的工具。

Abstract: Accurate parameter identification in photovoltaic (PV) models is crucial for
performance evaluation but remains challenging due to their nonlinear,
multimodal, and high-dimensional nature. Although the Dung Beetle Optimization
(DBO) algorithm has shown potential in addressing such problems, it often
suffers from premature convergence. To overcome these issues, this paper
proposes a Memory Enhanced Fractional-Order Dung Beetle Optimization (MFO-DBO)
algorithm that integrates three coordinated strategies. Firstly,
fractional-order (FO) calculus introduces memory into the search process,
enhancing convergence stability and solution quality. Secondly, a
fractional-order logistic chaotic map improves population diversity during
initialization. Thirdly, a chaotic perturbation mechanism helps elite solutions
escape local optima. Numerical results on the CEC2017 benchmark suite and the
PV parameter identification problem demonstrate that MFO-DBO consistently
outperforms advanced DBO variants, CEC competition winners, FO-based
optimizers, enhanced classical algorithms, and recent metaheuristics in terms
of accuracy, robustness, convergence speed, while also maintaining an excellent
balance between exploration and exploitation compared to the standard DBO
algorithm.

</details>


### [529] [Enhancing Decision Space Diversity in Multi-Objective Evolutionary Optimization for the Diet Problem](https://arxiv.org/abs/2508.07077)
*Gustavo V. Nascimento,Ivan R. Meneghini,Valéria Santos,Eduardo Luz,Gladston Moreira*

Main category: cs.NE

TL;DR: 本文提出通过在多目标进化算法（MOEA）中引入基于汉明距离的均匀性度量以增强决策空间多样性的方法，并通过实验验证了其在饮食问题中的有效性。


<details>
  <summary>Details</summary>
Motivation: 目前大多数MOEAs主要关注优化目标空间的解，而忽略了决策空间的多样性，然而决策空间的多样性对于为决策者提供多种选择至关重要。

Method: 将基于汉明距离的均匀性度量直接整合到MOEA的选择机制中，以增强决策空间的多样性。

Result: 在饮食问题的多目标实验中，相较于NSGA-II，提出的方法显著提高了决策空间的多样性，同时保持了相当的目标空间性能。

Conclusion: 该方法提供了一种将决策空间意识整合到MOEA中的可推广策略，用于解决多目标优化问题。

Abstract: Multi-objective evolutionary algorithms (MOEAs) are essential for solving
complex optimization problems, such as the diet problem, where balancing
conflicting objectives, like cost and nutritional content, is crucial. However,
most MOEAs focus on optimizing solutions in the objective space, often
neglecting the diversity of solutions in the decision space, which is critical
for providing decision-makers with a wide range of choices. This paper
introduces an approach that directly integrates a Hamming distance-based
measure of uniformity into the selection mechanism of a MOEA to enhance
decision space diversity. Experiments on a multi-objective formulation of the
diet problem demonstrate that our approach significantly improves decision
space diversity compared to NSGA-II, while maintaining comparable objective
space performance. The proposed method offers a generalizable strategy for
integrating decision space awareness into MOEAs.

</details>


### [530] [Evolutionary Optimization of Deep Learning Agents for Sparrow Mahjong](https://arxiv.org/abs/2508.07522)
*Jim O'Connor,Derin Gezgin,Gary B. Parker*

Main category: cs.NE

TL;DR: 本文提出了Evo-Sparrow，一种深度学习方法与进化优化结合的AI决策代理模型，用于非确定性、部分可观察环境的雀麻将游戏。该模型性能接近PPO基线，同时优于随机和规则代理。


<details>
  <summary>Details</summary>
Motivation: 探索在复杂的非确定性环境中优化AI决策的策略，通过结合深度学习和进化优化，提供比传统强化学习更高效的替代方案。

Method: 采用Long Short-Term Memory (LSTM)网络进行决策优化，并结合协方差矩阵自适应进化策略（CMA-ES），在雀麻将游戏环境中训练和评估代理性能。

Result: 模型在大量模拟中表现优异，性能超过随机和基于规则的代理，且达到接近PPO的性能水准。

Conclusion: 该研究验证了进化优化结合深度学习方法在复杂随机游戏中的有效性，为游戏AI决策及广泛的自适应决策AI发展提供了新的解决方案及方向。

Abstract: We present Evo-Sparrow, a deep learning-based agent for AI decision-making in
Sparrow Mahjong, trained by optimizing Long Short-Term Memory (LSTM) networks
using Covariance Matrix Adaptation Evolution Strategy (CMA-ES). Our model
evaluates board states and optimizes decision policies in a non-deterministic,
partially observable game environment. Empirical analysis conducted over a
significant number of simulations demonstrates that our model outperforms both
random and rule-based agents, and achieves performance comparable to a Proximal
Policy Optimization (PPO) baseline, indicating strong strategic play and robust
policy quality. By combining deep learning with evolutionary optimization, our
approach provides a computationally effective alternative to traditional
reinforcement learning and gradient-based optimization methods. This research
contributes to the broader field of AI game playing, demonstrating the
viability of hybrid learning strategies for complex stochastic games. These
findings also offer potential applications in adaptive decision-making and
strategic AI development beyond Sparrow Mahjong.

</details>


### [531] [Energy and Quality of Surrogate-Assisted Search Algorithms: a First Analysis](https://arxiv.org/abs/2508.07691)
*Tomohiro Harada,Enrique Alba,Gabriel Luque*

Main category: cs.NE

TL;DR: 本文探讨了利用代理模型优化粒子群算法的能量特性及其对优化效率的影响，并对代理模型的准确性进行研究。


<details>
  <summary>Details</summary>
Motivation: 研究代理模型在帮助元启发式算法提高效率的同时，对能量消耗和总体性能的影响，以弥补能量视角下的研究空白。

Method: 分析多种版本的粒子群优化算法，包括使用预训练和再训练的神经网络代理模型，研究其能量消耗特性（处理器和内存）及代理模型精度对搜索过程的影响。

Result: 对代理模型的能量消耗和准确性进行了深入分析，提出了对代理辅助算法评估的新视角。

Conclusion: 该研究为代理辅助算法的全面评估提供了基础，不仅考虑时间和数值效率，还涵盖能量消耗和代理准确性，提出了优化技术的新方法论方向。

Abstract: Solving complex real problems often demands advanced algorithms, and then
continuous improvements in the internal operations of a search technique are
needed. Hybrid algorithms, parallel techniques, theoretical advances, and much
more are needed to transform a general search algorithm into an efficient,
useful one in practice. In this paper, we study how surrogates are helping
metaheuristics from an important and understudied point of view: their energy
profile. Even if surrogates are a great idea for substituting a time-demanding
complex fitness function, the energy profile, general efficiency, and accuracy
of the resulting surrogate-assisted metaheuristic still need considerable
research. In this work, we make a first step in analyzing particle swarm
optimization in different versions (including pre-trained and retrained neural
networks as surrogates) for its energy profile (for both processor and memory),
plus a further study on the surrogate accuracy to properly drive the search
towards an acceptable solution. Our conclusions shed new light on this topic
and could be understood as the first step towards a methodology for assessing
surrogate-assisted algorithms not only accounting for time or numerical
efficiency but also for energy and surrogate accuracy for a better, more
holistic characterization of optimization and learning techniques.

</details>


### [532] [Growing Reservoirs with Developmental Graph Cellular Automata](https://arxiv.org/abs/2508.08091)
*Matias Barandiaran,James Stovold*

Main category: cs.NE

TL;DR: 提出一种名为发育图形细胞自动机（DGCA）的新模型，能够从单节点种子发展成有向图结构，并可用于训练解决特定任务的储备器。


<details>
  <summary>Details</summary>
Motivation: 探索一种新的方法，通过模拟发育过程构建复杂的图形结构，以增强解决任务的能力。

Method: 通过训练DGCA，以两种导向——任务导向（基于NARMA任务）和非任务导向（基于储备器指标）——生成可用的储备器结构，测试其解决基准任务的性能。

Result: 实验表明，DGCA生成的储备器能够以高效且多样的生命化结构解决特定任务，在统计上优于基准储备器。

Conclusion: DGCA为开发具有可塑性与适应性的储备器及模拟功能性发育模型奠定了基础。

Abstract: Developmental Graph Cellular Automata (DGCA) are a novel model for
morphogenesis, capable of growing directed graphs from single-node seeds. In
this paper, we show that DGCAs can be trained to grow reservoirs. Reservoirs
are grown with two types of targets: task-driven (using the NARMA family of
tasks) and task-independent (using reservoir metrics).
  Results show that DGCAs are able to grow into a variety of specialized,
life-like structures capable of effectively solving benchmark tasks,
statistically outperforming `typical' reservoirs on the same task. Overall,
these lay the foundation for the development of DGCA systems that produce
plastic reservoirs and for modeling functional, adaptive morphogenesis.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [533] [Transfer Learning with EfficientNet for Accurate Leukemia Cell Classification](https://arxiv.org/abs/2508.06535)
*Faisal Ahmed*

Main category: eess.IV

TL;DR: 本研究探索使用预训练卷积神经网络（CNN）的迁移学习和数据增强技术，来改进急性淋巴细胞白血病（ALL）的分类诊断性能。


<details>
  <summary>Details</summary>
Motivation: 准确诊断急性淋巴细胞白血病（ALL）能促成早期干预和有效治疗，因此亟需可靠的自动诊断工具。

Method: 通过使用预训练的卷积神经网络（ResNet50、ResNet101、EfficientNet等）结合数据增强技术，平衡数据集并改进分类性能。

Result: EfficientNet-B3模型取得了最佳结果，F1分数为94.30%，准确率为92.02%，AUC为94.79%。

Conclusion: 结合数据增强和EfficientNet-B3模型的迁移学习方法在血液恶性检测中表现出色，可用于开发更精确的诊断工具。

Abstract: Accurate classification of Acute Lymphoblastic Leukemia (ALL) from peripheral
blood smear images is essential for early diagnosis and effective treatment
planning. This study investigates the use of transfer learning with pretrained
convolutional neural networks (CNNs) to improve diagnostic performance. To
address the class imbalance in the dataset of 3,631 Hematologic and 7,644 ALL
images, we applied extensive data augmentation techniques to create a balanced
training set of 10,000 images per class. We evaluated several models, including
ResNet50, ResNet101, and EfficientNet variants B0, B1, and B3. EfficientNet-B3
achieved the best results, with an F1-score of 94.30%, accuracy of 92.02%,
andAUCof94.79%,outperformingpreviouslyreported methods in the C-NMCChallenge.
Thesefindings demonstrate the effectiveness of combining data augmentation with
advanced transfer learning models, particularly EfficientNet-B3, in developing
accurate and robust diagnostic tools for hematologic malignancy detection.

</details>


### [534] [LWT-ARTERY-LABEL: A Lightweight Framework for Automated Coronary Artery Identification](https://arxiv.org/abs/2508.06874)
*Shisheng Zhang,Ramtin Gharleghi,Sonit Singh,Daniel Moses,Dona Adikari,Arcot Sowmya,Susann Beier*

Main category: eess.IV

TL;DR: 提出了一种轻量化方法，将解剖学知识与基于规则的拓扑约束相结合，用于冠状动脉自动标记，取得了目前最优的性能。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉疾病是全球死亡的主要原因，但当前的冠状动脉计算分析需要大量的人力和时间，而传统和深度学习方法存在各自缺陷。

Method: 提出了一种结合解剖知识和基于规则的拓扑约束的轻量化冠状动脉自动标记方法。

Result: 该方法在基准数据集上达到了目前最好的性能。

Conclusion: 新方法为冠状动脉自动标记提供了有效的解决方案，具有临床可行性。

Abstract: Coronary artery disease (CAD) remains the leading cause of death globally,
with computed tomography coronary angiography (CTCA) serving as a key
diagnostic tool. However, coronary arterial analysis using CTCA, such as
identifying artery-specific features from computational modelling, is
labour-intensive and time-consuming. Automated anatomical labelling of coronary
arteries offers a potential solution, yet the inherent anatomical variability
of coronary trees presents a significant challenge. Traditional knowledge-based
labelling methods fall short in leveraging data-driven insights, while recent
deep-learning approaches often demand substantial computational resources and
overlook critical clinical knowledge. To address these limitations, we propose
a lightweight method that integrates anatomical knowledge with rule-based
topology constraints for effective coronary artery labelling. Our approach
achieves state-of-the-art performance on benchmark datasets, providing a
promising alternative for automated coronary artery labelling.

</details>


### [535] [Fusion-Based Brain Tumor Classification Using Deep Learning and Explainable AI, and Rule-Based Reasoning](https://arxiv.org/abs/2508.06891)
*Melika Filvantorkaman,Mohsen Piri,Maral Filvan Torkaman,Ashkan Zabihi,Hamidreza Moradi*

Main category: eess.IV

TL;DR: 研究提出了一个结合MobileNetV2和DenseNet121的深度学习框架，通过软投票策略对胶质瘤、脑膜瘤和垂体腺瘤三种常见脑肿瘤进行分类，并集成了可解释的人工智能模块和临床决策规则覆盖，实现了91.7%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 为了实现脑肿瘤的精准和可解释性分类，提升诊断和治疗规划的有效性。

Method: 采用MobileNetV2和DenseNet121的深度学习框架，通过软投票策略进行分类，并结合Grad-CAM++进行模型注意力可视化，同时集成符号化临床决策规则覆盖进行验证。

Result: 框架分类准确率达到91.7%，并通过人类放射学评估在可解释性和热图对应度上获得了高评分，显示了模型的临床相关性。

Conclusion: 提出了一种鲁棒、可解释且具有广泛适用性的脑肿瘤分类方法，推动了深度学习在临床神经诊断中的应用。

Abstract: Accurate and interpretable classification of brain tumors from magnetic
resonance imaging (MRI) is critical for effective diagnosis and treatment
planning. This study presents an ensemble-based deep learning framework that
combines MobileNetV2 and DenseNet121 convolutional neural networks (CNNs) using
a soft voting strategy to classify three common brain tumor types: glioma,
meningioma, and pituitary adenoma. The models were trained and evaluated on the
Figshare dataset using a stratified 5-fold cross-validation protocol. To
enhance transparency and clinical trust, the framework integrates an
Explainable AI (XAI) module employing Grad-CAM++ for class-specific saliency
visualization, alongside a symbolic Clinical Decision Rule Overlay (CDRO) that
maps predictions to established radiological heuristics. The ensemble
classifier achieved superior performance compared to individual CNNs, with an
accuracy of 91.7%, precision of 91.9%, recall of 91.7%, and F1-score of 91.6%.
Grad-CAM++ visualizations revealed strong spatial alignment between model
attention and expert-annotated tumor regions, supported by Dice coefficients up
to 0.88 and IoU scores up to 0.78. Clinical rule activation further validated
model predictions in cases with distinct morphological features. A
human-centered interpretability assessment involving five board-certified
radiologists yielded high Likert-scale scores for both explanation usefulness
(mean = 4.4) and heatmap-region correspondence (mean = 4.0), reinforcing the
framework's clinical relevance. Overall, the proposed approach offers a robust,
interpretable, and generalizable solution for automated brain tumor
classification, advancing the integration of deep learning into clinical
neurodiagnostics.

</details>


### [536] [Spatio-Temporal Conditional Diffusion Models for Forecasting Future Multiple Sclerosis Lesion Masks Conditioned on Treatments](https://arxiv.org/abs/2508.07006)
*Gian Mario Favero,Ge Ya Luo,Nima Fathi,Justin Szeto,Douglas L. Arnold,Brennan Nichyporuk,Chris Pal,Tal Arbel*

Main category: eess.IV

TL;DR: 本文提出了一种结合多模态数据的生成模型，用于预测多发性硬化症患者的病灶演变。


<details>
  <summary>Details</summary>
Motivation: 通过图像生成模型，提高对具有进展异质性的疾病的预测能力，特别是对多发性硬化症患者的治疗反应预测。

Method: 提出基于体素空间的时空扩散模型，结合MRI和治疗相关数据预测未来病灶变化；进行了多中心数据集实验，验证模型的泛化能力。

Result: 模型在六种不同治疗条件下准确预测了NET2病灶演变；证明了在病灶计数、位置预测及分类等下游任务中的有效性。

Conclusion: 此模型展示了因果生成模型在推进多发性硬化症数据驱动诊断与治疗中的潜力，对临床应用具有重要意义。

Abstract: Image-based personalized medicine has the potential to transform healthcare,
particularly for diseases that exhibit heterogeneous progression such as
Multiple Sclerosis (MS). In this work, we introduce the first treatment-aware
spatio-temporal diffusion model that is able to generate future masks
demonstrating lesion evolution in MS. Our voxel-space approach incorporates
multi-modal patient data, including MRI and treatment information, to forecast
new and enlarging T2 (NET2) lesion masks at a future time point. Extensive
experiments on a multi-centre dataset of 2131 patient 3D MRIs from randomized
clinical trials for relapsing-remitting MS demonstrate that our generative
model is able to accurately predict NET2 lesion masks for patients across six
different treatments. Moreover, we demonstrate our model has the potential for
real-world clinical applications through downstream tasks such as future lesion
count and location estimation, binary lesion activity classification, and
generating counterfactual future NET2 masks for several treatments with
different efficacies. This work highlights the potential of causal, image-based
generative models as powerful tools for advancing data-driven prognostics in
MS.

</details>


### [537] [Trustworthy Medical Imaging with Large Language Models: A Study of Hallucinations Across Modalities](https://arxiv.org/abs/2508.07031)
*Anindya Bijoy Das,Shahnewaz Karim Sakib,Shibbir Ahmed*

Main category: eess.IV

TL;DR: 这篇论文研究了大型语言模型（LLMs）在医疗影像任务中的幻觉现象，包括图像到文本和文本到图像的应用。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在医疗影像生成和解读中的幻觉问题，了解其对临床决策的潜在误导性。

Method: 通过专家标准评估LLMs在X光、CT、MRI等影像模式下的输出，分析事实错误和解剖学不准确性。

Result: 发现LLMs在解读和生成任务中存在幻觉的常见模式，并探讨失败的影响因素。

Conclusion: 旨在通过研究影像理解和生成的系统性问题，提高LLM驱动的医疗影像系统的安全性与可信度。

Abstract: Large Language Models (LLMs) are increasingly applied to medical imaging
tasks, including image interpretation and synthetic image generation. However,
these models often produce hallucinations, which are confident but incorrect
outputs that can mislead clinical decisions. This study examines hallucinations
in two directions: image to text, where LLMs generate reports from X-ray, CT,
or MRI scans, and text to image, where models create medical images from
clinical prompts. We analyze errors such as factual inconsistencies and
anatomical inaccuracies, evaluating outputs using expert informed criteria
across imaging modalities. Our findings reveal common patterns of hallucination
in both interpretive and generative tasks, with implications for clinical
reliability. We also discuss factors contributing to these failures, including
model architecture and training data. By systematically studying both image
understanding and generation, this work provides insights into improving the
safety and trustworthiness of LLM driven medical imaging systems.

</details>


### [538] [3DGS-VBench: A Comprehensive Video Quality Evaluation Benchmark for 3DGS Compression](https://arxiv.org/abs/2508.07038)
*Yuke Xing,William Gordon,Qi Yang,Kaifa Yang,Jiarui Wang,Yiling Xu*

Main category: eess.IV

TL;DR: 研究通过建立3DGS-VBench数据集和基准以评价3DGS图像压缩方法的视觉质量和存储效率，为后续模型训练和研究提供基础。


<details>
  <summary>Details</summary>
Motivation: 现有的3DGS方法存在存储需求大的问题，尽管压缩模块可以缓解这一问题，但会引入独特的压缩失真，缺乏系统的质量评估研究。

Method: 创建了包含660个3DGS数据模型和视频序列的大规模数据集和基准，并对其进行了主观评分与验证。同时比较了6种压缩算法在存储效率和视觉质量上的表现，并评估了15种质量评估指标。

Result: 提出了一个新数据集3DGS-VBench，并证明其在3DGS视觉质量评估中的可靠性。此外，通过对多种压缩算法和评估指标进行基准测试，给出了3DGS压缩性能的综合分析。

Conclusion: 该研究提供了一个能够支持3DGS质量评估的重要工具，有助于促进3DGS压缩和质量评估领域的研究进展。

Abstract: 3D Gaussian Splatting (3DGS) enables real-time novel view synthesis with high
visual fidelity, but its substantial storage requirements hinder practical
deployment, prompting state-of-the-art (SOTA) 3DGS methods to incorporate
compression modules. However, these 3DGS generative compression techniques
introduce unique distortions lacking systematic quality assessment research. To
this end, we establish 3DGS-VBench, a large-scale Video Quality Assessment
(VQA) Dataset and Benchmark with 660 compressed 3DGS models and video sequences
generated from 11 scenes across 6 SOTA 3DGS compression algorithms with
systematically designed parameter levels. With annotations from 50
participants, we obtained MOS scores with outlier removal and validated dataset
reliability. We benchmark 6 3DGS compression algorithms on storage efficiency
and visual quality, and evaluate 15 quality assessment metrics across multiple
paradigms. Our work enables specialized VQA model training for 3DGS, serving as
a catalyst for compression and quality assessment research. The dataset is
available at https://github.com/YukeXing/3DGS-VBench.

</details>


### [539] [SAGCNet: Spatial-Aware Graph Completion Network for Missing Slice Imputation in Population CMR Imaging](https://arxiv.org/abs/2508.07041)
*Junkai Liu,Nay Aung,Theodoros N. Arvanitis,Stefan K. Piechnik,Joao A C Lima,Steffen E. Petersen,Le Zhang*

Main category: eess.IV

TL;DR: 本文提出了Spatial-Aware Graph Completion Network (SAGCNet)，一种用于补全缺失MRI切片的模型，在心脏磁共振成像数据集上的实验显示出该方法的定量和定性优越性。


<details>
  <summary>Details</summary>
Motivation: 针对传统缺失切片补全方法在处理MRI三维数据时局限于建模局部的切片间相关性及对3D空间信息和全局上下文探索不足的问题。

Method: 提出了Spatial-Aware Graph Completion Network (SAGCNet)，包括两大创新：1）将切片间关系通过图结构建模的体积切片图补全模块；2）用于捕获和利用多样三维空间上下文的体积空间适配器组件。

Result: 在心脏MRI数据上SAGCNet成功合成了缺失的CMR切片，且性能优于当前先进方法，包括在数据切片有限情况下的表现。

Conclusion: SAGCNet显著提升了缺失MRI切片补全的效果，为解决MRI三维数据补全问题提供了新方法。

Abstract: Magnetic resonance imaging (MRI) provides detailed soft-tissue
characteristics that assist in disease diagnosis and screening. However, the
accuracy of clinical practice is often hindered by missing or unusable slices
due to various factors. Volumetric MRI synthesis methods have been developed to
address this issue by imputing missing slices from available ones. The inherent
3D nature of volumetric MRI data, such as cardiac magnetic resonance (CMR),
poses significant challenges for missing slice imputation approaches, including
(1) the difficulty of modeling local inter-slice correlations and dependencies
of volumetric slices, and (2) the limited exploration of crucial 3D spatial
information and global context. In this study, to mitigate these issues, we
present Spatial-Aware Graph Completion Network (SAGCNet) to overcome the
dependency on complete volumetric data, featuring two main innovations: (1) a
volumetric slice graph completion module that incorporates the inter-slice
relationships into a graph structure, and (2) a volumetric spatial adapter
component that enables our model to effectively capture and utilize various
forms of 3D spatial context. Extensive experiments on cardiac MRI datasets
demonstrate that SAGCNet is capable of synthesizing absent CMR slices,
outperforming competitive state-of-the-art MRI synthesis methods both
quantitatively and qualitatively. Notably, our model maintains superior
performance even with limited slice data.

</details>


### [540] [Large-scale Multi-sequence Pretraining for Generalizable MRI Analysis in Versatile Clinical Applications](https://arxiv.org/abs/2508.07165)
*Zelin Qiu,Xi Wang,Zhuoyao Xie,Juan Zhou,Yu Wang,Lingjie Yang,Xinrui Jiang,Juyoung Bae,Moo Hyun Son,Qiang Ye,Dexuan Chen,Rui Zhang,Tao Li,Neeraj Ramesh Mahboobani,Varut Vardhanabhuti,Xiaohui Duan,Yinghua Zhao,Hao Chen*

Main category: eess.IV

TL;DR: 本文介绍了PRISM，一个预训练多序列MRI的基础模型，能够显著提高模型在不同MRI协议下的泛化能力，为放射学中的AI应用提供了可扩展框架。


<details>
  <summary>Details</summary>
Motivation: MRI序列之间的异质性给深度学习模型的泛化能力带来了挑战，限制了其临床应用效果。

Method: 研究提出了一种新的预训练范式，构建具有336,476个体积MRI扫描的最大多器官多序列MRI预训练数据集，同时实现了解耦解剖不变特征与序列特异性变量的目的。

Result: PRISM在44个下游任务基准中39个中表现优异，有统计学显著改进，展示了其在广泛MRI协议下学习强健与可泛化表示的能力。

Conclusion: PRISM提供了一种可扩展的多序列MRI分析框架，增强了AI在放射学中的临床应用潜力，并在不同成像协议下保持一致性能。

Abstract: Multi-sequence Magnetic Resonance Imaging (MRI) offers remarkable
versatility, enabling the distinct visualization of different tissue types.
Nevertheless, the inherent heterogeneity among MRI sequences poses significant
challenges to the generalization capability of deep learning models. These
challenges undermine model performance when faced with varying acquisition
parameters, thereby severely restricting their clinical utility. In this study,
we present PRISM, a foundation model PRe-trained with large-scale
multI-Sequence MRI. We collected a total of 64 datasets from both public and
private sources, encompassing a wide range of whole-body anatomical structures,
with scans spanning diverse MRI sequences. Among them, 336,476 volumetric MRI
scans from 34 datasets (8 public and 26 private) were curated to construct the
largest multi-organ multi-sequence MRI pretraining corpus to date. We propose a
novel pretraining paradigm that disentangles anatomically invariant features
from sequence-specific variations in MRI, while preserving high-level semantic
representations. We established a benchmark comprising 44 downstream tasks,
including disease diagnosis, image segmentation, registration, progression
prediction, and report generation. These tasks were evaluated on 32 public
datasets and 5 private cohorts. PRISM consistently outperformed both
non-pretrained models and existing foundation models, achieving first-rank
results in 39 out of 44 downstream benchmarks with statistical significance
improvements. These results underscore its ability to learn robust and
generalizable representations across unseen data acquired under diverse MRI
protocols. PRISM provides a scalable framework for multi-sequence MRI analysis,
thereby enhancing the translational potential of AI in radiology. It delivers
consistent performance across diverse imaging protocols, reinforcing its
clinical applicability.

</details>


### [541] [HaDM-ST: Histology-Assisted Differential Modeling for Spatial Transcriptomics Generation](https://arxiv.org/abs/2508.07225)
*Xuepeng Liu,Zheng Jiang,Pinan Zhu,Hanyu Liu,Chao Li*

Main category: eess.IV

TL;DR: 提出HaDM-ST框架，通过结合H&E图像和低分辨率ST，生成高分辨率空间转录组数据，全面提升了空间精准度和基因层面的细节捕捉。


<details>
  <summary>Details</summary>
Motivation: 现有空间转录组技术受分辨率限制，多模态方法虽有所改进但面对复杂组织图像分析、精确空间配准和基因特异性建模仍存在挑战。提出HaDM-ST以对应这些问题。

Method: 框架核心包括三个模块：语义蒸馏网络提取H&E图片预测特征；空间配准模块进行像素级精确对齐；通道感知对抗网络精细建模基因特异性变化。

Result: 实验在多种组织和物种的200个基因上验证，HaDM-ST相较于已有方法，在高分辨率空间转录组生成中具有更高的空间准确性和基因一致性。

Conclusion: HaDM-ST为提升空间转录组解析度提供了一个有效方法，在生物样本多样性和基因建模精度方面展现出显著优势。

Abstract: Spatial transcriptomics (ST) reveals spatial heterogeneity of gene
expression, yet its resolution is limited by current platforms. Recent methods
enhance resolution via H&E-stained histology, but three major challenges
persist: (1) isolating expression-relevant features from visually complex H&E
images; (2) achieving spatially precise multimodal alignment in diffusion-based
frameworks; and (3) modeling gene-specific variation across expression
channels. We propose HaDM-ST (Histology-assisted Differential Modeling for ST
Generation), a high-resolution ST generation framework conditioned on H&E
images and low-resolution ST. HaDM-ST includes: (i) a semantic distillation
network to extract predictive cues from H&E; (ii) a spatial alignment module
enforcing pixel-wise correspondence with low-resolution ST; and (iii) a
channel-aware adversarial learner for fine-grained gene-level modeling.
Experiments on 200 genes across diverse tissues and species show HaDM-ST
consistently outperforms prior methods, enhancing spatial fidelity and
gene-level coherence in high-resolution ST predictions.

</details>


### [542] [DiffVC-OSD: One-Step Diffusion-based Perceptual Neural Video Compression Framework](https://arxiv.org/abs/2508.07682)
*Wenzhuo Ma,Zhenzhong Chen*

Main category: eess.IV

TL;DR: 提出了一种名为DiffVC-OSD的单步扩散感知视频压缩框架，实现更高效率和优秀的感知性能。


<details>
  <summary>Details</summary>
Motivation: 针对传统多步扩散算法在感知视频压缩中存在效率低下的问题，提出更快速的单步扩散替代方法。

Method: 设计了单步扩散感知模型DiffVC-OSD，引入时间上下文自适应器来编码条件输入，并采用端到端微调策略优化性能。

Result: 实验显示，与多步扩散法对比，该方法在解码速度上提升约20倍，码率减少86.92%，感知压缩性能达到最先进水平。

Conclusion: DiffVC-OSD能够显著提升视频压缩的感知质量与效率，为相关领域提供了一套高效解决方案。

Abstract: In this work, we first propose DiffVC-OSD, a One-Step Diffusion-based
Perceptual Neural Video Compression framework. Unlike conventional multi-step
diffusion-based methods, DiffVC-OSD feeds the reconstructed latent
representation directly into a One-Step Diffusion Model, enhancing perceptual
quality through a single diffusion step guided by both temporal context and the
latent itself. To better leverage temporal dependencies, we design a Temporal
Context Adapter that encodes conditional inputs into multi-level features,
offering more fine-grained guidance for the Denoising Unet. Additionally, we
employ an End-to-End Finetuning strategy to improve overall compression
performance. Extensive experiments demonstrate that DiffVC-OSD achieves
state-of-the-art perceptual compression performance, offers about 20$\times$
faster decoding and a 86.92\% bitrate reduction compared to the corresponding
multi-step diffusion-based variant.

</details>


### [543] [Anatomy-Aware Low-Dose CT Denoising via Pretrained Vision Models and Semantic-Guided Contrastive Learning](https://arxiv.org/abs/2508.07788)
*Runze Wang,Zeli Chen,Zhiyun Song,Wei Fang,Jiajin Zhang,Danyang Tu,Yuxing Tang,Minfeng Xu,Xianghua Ye,Le Lu,Dakai Jin*

Main category: eess.IV

TL;DR: 为了提高低剂量CT(LDCT)的诊断效果并减少辐射暴露，提出一种结合预训练视觉模型(PVM)的语义特征、对抗学习和对比学习的解剖学感知去噪方法——ALDEN。


<details>
  <summary>Details</summary>
Motivation: 目前的低剂量CT去噪方法普遍忽略了人体组织的解剖学语义信息，这可能导致去噪效果不理想。本文旨在解决这一问题。

Method: 本文引入了解剖学感知判别器，利用交叉注意力机制动态融合来自参考正常剂量CT(NDCT)的分层语义特征；还提出了语义引导的对比学习模块，通过构造正负样本对强制保持解剖一致性。

Result: 大量实验表明，ALDEN在两个LDCT去噪数据集上实现了最新的性能，具有出色的解剖学保留能力并显著减少过度平滑问题。此外，在多器官分割任务的验证中，模型展现了其解剖学意识维持能力。

Conclusion: ALDEN综合了解剖学语义特征、对抗学习与对比学习，提供了卓越的低剂量CT去噪效果，同时有效保留了解剖学信息，具有完善的实际应用潜力。

Abstract: To reduce radiation exposure and improve the diagnostic efficacy of low-dose
computed tomography (LDCT), numerous deep learning-based denoising methods have
been developed to mitigate noise and artifacts. However, most of these
approaches ignore the anatomical semantics of human tissues, which may
potentially result in suboptimal denoising outcomes. To address this problem,
we propose ALDEN, an anatomy-aware LDCT denoising method that integrates
semantic features of pretrained vision models (PVMs) with adversarial and
contrastive learning. Specifically, we introduce an anatomy-aware discriminator
that dynamically fuses hierarchical semantic features from reference
normal-dose CT (NDCT) via cross-attention mechanisms, enabling tissue-specific
realism evaluation in the discriminator. In addition, we propose a
semantic-guided contrastive learning module that enforces anatomical
consistency by contrasting PVM-derived features from LDCT, denoised CT and
NDCT, preserving tissue-specific patterns through positive pairs and
suppressing artifacts via dual negative pairs. Extensive experiments conducted
on two LDCT denoising datasets reveal that ALDEN achieves the state-of-the-art
performance, offering superior anatomy preservation and substantially reducing
over-smoothing issue of previous work. Further validation on a downstream
multi-organ segmentation task (encompassing 117 anatomical structures) affirms
the model's ability to maintain anatomical awareness.

</details>


### [544] [Towards Human-AI Collaboration System for the Detection of Invasive Ductal Carcinoma in Histopathology Images](https://arxiv.org/abs/2508.07875)
*Shuo Han,Ahmed Karam Eldaly,Solomon Sunday Oyelere*

Main category: eess.IV

TL;DR: 该论文提出了一种结合AI和人类专家进行IDC检测的深度学习系统。


<details>
  <summary>Details</summary>
Motivation: 通过人工智能与医学专家的合作，提高乳腺癌IDC检测的准确性和效率。

Method: 使用EfficientNetV2S模型进行初步检测，人类专家纠正误分类，并将修正后的数据反馈给模型，构成一个人类在环的循环过程。

Result: EfficientNetV2S模型取得了93.65%的准确率，在加入人类在环反馈后，精度得到进一步提升。

Conclusion: 证明了人类与AI协作在医学诊断中的潜力，为未来AI辅助医学诊断提供了重要方向。

Abstract: Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer,
and early, accurate diagnosis is critical to improving patient survival rates
by guiding treatment decisions. Combining medical expertise with artificial
intelligence (AI) holds significant promise for enhancing the precision and
efficiency of IDC detection. In this work, we propose a human-in-the-loop
(HITL) deep learning system designed to detect IDC in histopathology images.
The system begins with an initial diagnosis provided by a high-performance
EfficientNetV2S model, offering feedback from AI to the human expert. Medical
professionals then review the AI-generated results, correct any misclassified
images, and integrate the revised labels into the training dataset, forming a
feedback loop from the human back to the AI. This iterative process refines the
model's performance over time. The EfficientNetV2S model itself achieves
state-of-the-art performance compared to existing methods in the literature,
with an overall accuracy of 93.65\%. Incorporating the human-in-the-loop system
further improves the model's accuracy using four experimental groups with
misclassified images. These results demonstrate the potential of this
collaborative approach to enhance AI performance in diagnostic systems. This
work contributes to advancing automated, efficient, and highly accurate methods
for IDC detection through human-AI collaboration, offering a promising
direction for future AI-assisted medical diagnostics.

</details>


### [545] [Diffusing the Blind Spot: Uterine MRI Synthesis with Diffusion Models](https://arxiv.org/abs/2508.07903)
*Johanna P. Müller,Anika Knupfer,Pedro Blöss,Edoardo Berardi Vittur,Bernhard Kainz,Jana Hutter*

Main category: eess.IV

TL;DR: 提出了一种基于扩散模型的框架，用于合成高保真度子宫MRI图像，推动妇科影像学中的公平AI研究。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型难以生成解剖学精确的女性骨盆图像，而妇科影像学因数据稀缺和患者隐私问题受到限制，亟需精准的图像生成技术。

Method: 通过整合无条件与条件的Denoising Diffusion Probabilistic Models (DDPMs)和Latent Diffusion Models (LDMs)，构建了用于合成子宫MRI图像的2D和3D扩散框架。

Result: 模型生成高保真度、解剖学一致的图像，在关键分类任务中显著提高诊断准确率，并通过专家盲审验证了图像的临床现实性。

Conclusion: 提供了具有隐私保护的合成子宫MRI数据集及模型，为妇科影像诊断和AI研究提供了突破性的资源支持。

Abstract: Despite significant progress in generative modelling, existing diffusion
models often struggle to produce anatomically precise female pelvic images,
limiting their application in gynaecological imaging, where data scarcity and
patient privacy concerns are critical. To overcome these barriers, we introduce
a novel diffusion-based framework for uterine MRI synthesis, integrating both
unconditional and conditioned Denoising Diffusion Probabilistic Models (DDPMs)
and Latent Diffusion Models (LDMs) in 2D and 3D. Our approach generates
anatomically coherent, high fidelity synthetic images that closely mimic real
scans and provide valuable resources for training robust diagnostic models. We
evaluate generative quality using advanced perceptual and distributional
metrics, benchmarking against standard reconstruction methods, and demonstrate
substantial gains in diagnostic accuracy on a key classification task. A
blinded expert evaluation further validates the clinical realism of our
synthetic images. We release our models with privacy safeguards and a
comprehensive synthetic uterine MRI dataset to support reproducible research
and advance equitable AI in gynaecology.

</details>


### [546] [RedDino: A foundation model for red blood cell analysis](https://arxiv.org/abs/2508.08180)
*Luca Zedda,Andrea Loddo,Cecilia Di Ruberto,Carsten Marr*

Main category: eess.IV

TL;DR: 提出了一种名为RedDino的自监督基础模型，用于红细胞（RBC）图像分析，在形状分类上表现优异，具备强特征表达与广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 针对当前医疗诊断中基础模型的不足，设计专为分析RBC形态的AI解决方案，为血液学的诊断工具提供创新方法。

Method: 基于DINOv2自监督学习框架，利用1.25百万RBC多样化图像数据训练模型，并进行形状分类及广泛的性能评估。

Result: RedDino在RBC形状分类任务上优于现有的最先进模型，具备出色的特征表达和泛化能力。

Conclusion: RedDino通过处理复杂的形态学特征，解决了计算血液学的主要困难，为开发更可靠的诊断工具提供了基础。

Abstract: Red blood cells (RBCs) are essential to human health, and their precise
morphological analysis is important for diagnosing hematological disorders.
Despite the promise of foundation models in medical diagnostics, comprehensive
AI solutions for RBC analysis remain scarce. We present RedDino, a
self-supervised foundation model designed for RBC image analysis. RedDino uses
an RBC-specific adaptation of the DINOv2 self-supervised learning framework and
is trained on a curated dataset of 1.25 million RBC images from diverse
acquisition modalities and sources. Extensive evaluations show that RedDino
outperforms existing state-of-the-art models on RBC shape classification.
Through assessments including linear probing and nearest neighbor
classification, we confirm its strong feature representations and
generalization ability. Our main contributions are: (1) a foundation model
tailored for RBC analysis, (2) ablation studies exploring DINOv2 configurations
for RBC modeling, and (3) a detailed evaluation of generalization performance.
RedDino addresses key challenges in computational hematology by capturing
nuanced morphological features, advancing the development of reliable
diagnostic tools. The source code and pretrained models for RedDino are
available at https://github.com/Snarci/RedDino, and the pretrained models can
be downloaded from our Hugging Face collection at
https://huggingface.co/collections/Snarcy/reddino-689a13e29241d2e5690202fc

</details>


### [547] [A Physics-Driven Neural Network with Parameter Embedding for Generating Quantitative MR Maps from Weighted Images](https://arxiv.org/abs/2508.08123)
*Lingjing Chen,Chengxiu Zhang,Yinqiao Yi,Yida Wang,Yang Song,Xu Yan,Shengfang Xu,Dalin Zhu,Mengqiu Cao,Yan Zhou,Chenglong Wang,Guang Yang*

Main category: eess.IV

TL;DR: 提出一种深度学习方法，通过引入MRI序列参数显著提高临床加权MRI图像定量合成的精确性和推广性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有深度学习方法在MRI定量成像中对物理信号建模不足的问题，从而改进合成精度和对新病理结构的泛化能力。

Method: 设计了一个嵌入MRI序列参数的深度学习模型，利用T1、T2加权和T2-FLAIR图像合成T1、T2和PD定量图。通过物理驱动的参数嵌入方法，使模型学习MRI信号形成的物理原理。

Result: 模型在内外部数据集测试中表现出高性能，PSNR高于34 dB，SSIM超过0.92，在未知脑结构和病变的合成中表现尤为突出。

Conclusion: 通过将MRI序列参数嵌入神经网络，不仅提高定量MRI合成的准确性和鲁棒性，还展示出加速qMRI并提升临床应用潜力的可能性。

Abstract: We propose a deep learning-based approach that integrates MRI sequence
parameters to improve the accuracy and generalizability of quantitative image
synthesis from clinical weighted MRI. Our physics-driven neural network embeds
MRI sequence parameters -- repetition time (TR), echo time (TE), and inversion
time (TI) -- directly into the model via parameter embedding, enabling the
network to learn the underlying physical principles of MRI signal formation.
The model takes conventional T1-weighted, T2-weighted, and T2-FLAIR images as
input and synthesizes T1, T2, and proton density (PD) quantitative maps.
Trained on healthy brain MR images, it was evaluated on both internal and
external test datasets. The proposed method achieved high performance with PSNR
values exceeding 34 dB and SSIM values above 0.92 for all synthesized parameter
maps. It outperformed conventional deep learning models in accuracy and
robustness, including data with previously unseen brain structures and lesions.
Notably, our model accurately synthesized quantitative maps for these unseen
pathological regions, highlighting its superior generalization capability.
Incorporating MRI sequence parameters via parameter embedding allows the neural
network to better learn the physical characteristics of MR signals,
significantly enhancing the performance and reliability of quantitative MRI
synthesis. This method shows great potential for accelerating qMRI and
improving its clinical utility.

</details>
