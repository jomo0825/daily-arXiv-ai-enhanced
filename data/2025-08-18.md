<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 94]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.AI](#cs.AI) [Total: 11]
- [cs.LG](#cs.LG) [Total: 59]
- [cs.NE](#cs.NE) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Privacy Enhancement for Gaze Data Using a Noise-Infused Autoencoder](https://arxiv.org/abs/2508.10918)
*Samantha Aziz,Oleg Komogortsev*

Main category: cs.CV

TL;DR: 提出了一种用于凝视数据隐私保护的潜在噪声自动编码器机制，减少用户在使用视线相关系统时的可识别性，同时保留数据的实用性。


<details>
  <summary>Details</summary>
Motivation: 解决凝视数据中用户隐私泄露的问题，既要保护隐私又需保持数据在合法任务中的可用性。

Method: 采用潜在噪声自动编码器，通过在不妨碍凝视信号生理可信性的情况下，削弱用户的生物特征辨识性，来实现隐私保护。

Result: 在保护隐私的同时，能实现凝视数据在生物特征识别和凝视预测任务上最小程度的实用性损失。

Conclusion: 该方法在保护敏感凝视数据隐私的同时，确保其在下游任务中的可用性，有效推进了凝视数据隐私保护技术的发展。

Abstract: We present a privacy-enhancing mechanism for gaze signals using a
latent-noise autoencoder that prevents users from being re-identified across
play sessions without their consent, while retaining the usability of the data
for benign tasks. We evaluate privacy-utility trade-offs across biometric
identification and gaze prediction tasks, showing that our approach
significantly reduces biometric identifiability with minimal utility
degradation. Unlike prior methods in this direction, our framework retains
physiologically plausible gaze patterns suitable for downstream use, which
produces favorable privacy-utility trade-off. This work advances privacy in
gaze-based systems by providing a usable and effective mechanism for protecting
sensitive gaze data.

</details>


### [2] [A Survey on Video Temporal Grounding with Multimodal Large Language Model](https://arxiv.org/abs/2508.10922)
*Jianlong Wu,Wei Liu,Ye Liu,Meng Liu,Liqiang Nie,Zhouchen Lin,Chang Wen Chen*

Main category: cs.CV

TL;DR: 本文系统调查了基于多模态大语言模型（MLLMs）的视频时间定位（VTG）研究，通过三维分类方法分析其功能角色、训练范式和视频特征处理技术，同时总结了基准数据集、评估协议及实证结果，并提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 针对当前关于视频时间定位和多模态语言模型研究的综述不足，本文提出系统性调查以填补这一空白。

Method: 采用三维分类方法，通过分析MLLM的架构重要性、时序推理及任务适应的训练策略以及时空表示效果的视频特征处理技术，全面综述VTG-MLLM研究。

Result: 总结了当前VTG-MLLM研究的基准数据、评估协议和实证结果，并讨论现有研究的局限性和潜在研究方向。

Conclusion: 基于MLLM的VTG方法表现出了在零样本、多任务及多领域设置中的优异性能，其未来研究方向包括强化时序推理和任务适应的能力。

Abstract: The recent advancement in video temporal grounding (VTG) has significantly
enhanced fine-grained video understanding, primarily driven by multimodal large
language models (MLLMs). With superior multimodal comprehension and reasoning
abilities, VTG approaches based on MLLMs (VTG-MLLMs) are gradually surpassing
traditional fine-tuned methods. They not only achieve competitive performance
but also excel in generalization across zero-shot, multi-task, and multi-domain
settings. Despite extensive surveys on general video-language understanding,
comprehensive reviews specifically addressing VTG-MLLMs remain scarce. To fill
this gap, this survey systematically examines current research on VTG-MLLMs
through a three-dimensional taxonomy: 1) the functional roles of MLLMs,
highlighting their architectural significance; 2) training paradigms, analyzing
strategies for temporal reasoning and task adaptation; and 3) video feature
processing techniques, which determine spatiotemporal representation
effectiveness. We further discuss benchmark datasets, evaluation protocols, and
summarize empirical findings. Finally, we identify existing limitations and
propose promising research directions. For additional resources and details,
readers are encouraged to visit our repository at
https://github.com/ki-lw/Awesome-MLLMs-for-Video-Temporal-Grounding.

</details>


### [3] [VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step Image Generation Models By \underline{V}alue \underline{S}ign \underline{F}lip](https://arxiv.org/abs/2508.10931)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: 提出了一种名为Value Sign Flip (VSF)的新方法，用于改进少步扩散和流匹配图像生成模型的负向提示引导，能够动态抑制不需要的内容。


<details>
  <summary>Details</summary>
Motivation: 目前的负向提示引导方法如CFG存在限制，无法有效处理复杂的提示对，希望通过改进解决这些问题。

Method: VSF通过对来自负向提示的注意力值取反，动态抑制不需要的内容，集成于MMDiT和交叉注意力模型中，计算开销较小。

Result: 在包含复杂提示对的数据集上进行了验证，VSF在静态图像和视频生成任务中表现出色，相较之前的方法显著提高了负向提示的依从性，同时保持了竞争性的图像质量。

Conclusion: VSF是一种简单高效的负向提示引导方法，超越了现有一些方法的表现，并有实际应用代码提供。

Abstract: We introduce Value Sign Flip (VSF), a simple and efficient method for
incorporating negative prompt guidance in few-step diffusion and flow-matching
image generation models. Unlike existing approaches such as classifier-free
guidance (CFG), NASA, and NAG, VSF dynamically suppresses undesired content by
flipping the sign of attention values from negative prompts. Our method
requires only small computational overhead and integrates effectively with
MMDiT-style architectures such as Stable Diffusion 3.5 Turbo, as well as
cross-attention-based models like Wan. We validate VSF on challenging datasets
with complex prompt pairs and demonstrate superior performance in both static
image and video generation tasks. Experimental results show that VSF
significantly improves negative prompt adherence compared to prior methods in
few-step models, and even CFG in non-few-step models, while maintaining
competitive image quality. Code and ComfyUI node are available in
https://github.com/weathon/VSF/tree/main.

</details>


### [4] [Relative Pose Regression with Pose Auto-Encoders: Enhancing Accuracy and Data Efficiency for Retail Applications](https://arxiv.org/abs/2508.10933)
*Yoli Shavit,Yosi Keller*

Main category: cs.CV

TL;DR: 本文提出了一种基于PAE（Camera Pose Auto-Encoders）的相对位姿回归（RPR）方法，并通过新的重新定位策略改进了APR（Absolute Pose Regression）的精度，不需要额外的图像或位姿数据存储。


<details>
  <summary>Details</summary>
Motivation: 精准的相机定位能够提高零售环境中的客户体验、库存管理和自动化操作效率。现有解决方案中结合视觉与场景先验的信息可以提升精度，而PAE方法被引入以嵌入这些先验信息。

Method: 将Camera Pose Auto-Encoders扩展到相对位姿回归任务，并提出了一种基于RPR的APR预测优化方法。在没有额外数据存储的情况下，通过PAE-based RPR改进APR结果。

Result: 实验数据表明，与等架构的图像RPR模型相比，PAE-based RPR更有效。而且其APR优化策略在室内基准测试上提升了定位精度，即便仅用30%的训练数据，其效果仍然具有竞争力.

Conclusion: 本方法提升了APR的定位精度，减少数据收集成本，对于零售环境中的实际部署更加友好。所有代码和预训练模型已开源。

Abstract: Accurate camera localization is crucial for modern retail environments,
enabling enhanced customer experiences, streamlined inventory management, and
autonomous operations. While Absolute Pose Regression (APR) from a single image
offers a promising solution, approaches that incorporate visual and spatial
scene priors tend to achieve higher accuracy. Camera Pose Auto-Encoders (PAEs)
have recently been introduced to embed such priors into APR. In this work, we
extend PAEs to the task of Relative Pose Regression (RPR) and propose a novel
re-localization scheme that refines APR predictions using PAE-based RPR,
without requiring additional storage of images or pose data. We first introduce
PAE-based RPR and establish its effectiveness by comparing it with image-based
RPR models of equivalent architectures. We then demonstrate that our refinement
strategy, driven by a PAE-based RPR, enhances APR localization accuracy on
indoor benchmarks. Notably, our method is shown to achieve competitive
performance even when trained with only 30% of the data, substantially reducing
the data collection burden for retail deployment. Our code and pre-trained
models are available at: https://github.com/yolish/camera-pose-auto-encoders

</details>


### [5] [ViPE: Video Pose Engine for 3D Geometric Perception](https://arxiv.org/abs/2508.10934)
*Jiahui Huang,Qunjie Zhou,Hesam Rabeti,Aleksandr Korovko,Huan Ling,Xuanchi Ren,Tianchang Shen,Jun Gao,Dmitry Slepichev,Chen-Hsuan Lin,Jiawei Ren,Kevin Xie,Joydeep Biswas,Laura Leal-Taixe,Sanja Fidler*

Main category: cs.CV

TL;DR: ViPE 是一种视频处理引擎，能够从不受约束的原始视频中高效估算相机参数及高精度的深度图，并应用于大规模视频的标注，支持多种场景和相机类型。


<details>
  <summary>Details</summary>
Motivation: 当前空间AI系统依赖于精确的3D几何感知，但从原始视频中获取一致且精确的3D标注依然是一个关键挑战。

Method: 提出 ViPE 视频处理引擎，能够从动态、复杂的非约束场景中，估算相机内参、运动参数以及稠密深度图，同时支持多种相机模型，并提供高效运行性能。

Result: 在多个基准测试中，ViPE 比现有无标定位姿估计方法提升显著，TUM/KITTI 上性能分别提升 18% 和 50%，单GPU下运行速度达到 3-5FPS。

Conclusion: ViPE 在多种场景下表现出强鲁棒性并能用于大规模标注任务，开源了工具和数据集，可加速空间AI系统的发展。

Abstract: Accurate 3D geometric perception is an important prerequisite for a wide
range of spatial AI systems. While state-of-the-art methods depend on
large-scale training data, acquiring consistent and precise 3D annotations from
in-the-wild videos remains a key challenge. In this work, we introduce ViPE, a
handy and versatile video processing engine designed to bridge this gap. ViPE
efficiently estimates camera intrinsics, camera motion, and dense, near-metric
depth maps from unconstrained raw videos. It is robust to diverse scenarios,
including dynamic selfie videos, cinematic shots, or dashcams, and supports
various camera models such as pinhole, wide-angle, and 360{\deg} panoramas. We
have benchmarked ViPE on multiple benchmarks. Notably, it outperforms existing
uncalibrated pose estimation baselines by 18%/50% on TUM/KITTI sequences, and
runs at 3-5FPS on a single GPU for standard input resolutions. We use ViPE to
annotate a large-scale collection of videos. This collection includes around
100K real-world internet videos, 1M high-quality AI-generated videos, and 2K
panoramic videos, totaling approximately 96M frames -- all annotated with
accurate camera poses and dense depth maps. We open-source ViPE and the
annotated dataset with the hope of accelerating the development of spatial AI
systems.

</details>


### [6] [HQ-OV3D: A High Box Quality Open-World 3D Detection Framework based on Diffision Model](https://arxiv.org/abs/2508.10935)
*Qi Liu,Yabei Li,Hongsong Wang,Lei He*

Main category: cs.CV

TL;DR: 提出HQ-OV3D框架，专注于生成和优化开放词汇类别的高质量伪标签，以提升开放世界3D检测性能，特别是在边界框精度上显著改善。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇3D检测方法在生成伪标签时对语义准确性有所提升，但通常忽视了几何质量和边界框精度问题。需要提出一种方法解决这一挑战，以适应自动驾驶等开放世界应用场景。

Method: 提出HQ-OV3D框架，包括两个关键组件：跨模态几何一致性的IMCV提案生成器用于生成初始高质量3D提案；基于已标注类别几何先验的ACA去噪器，通过DDIM去噪机制逐步优化3D提案。

Result: 使用HQ-OV3D生成的伪标签进行训练，在新类别上的mAP提升了7.37%，证明了伪标签的高质量。

Conclusion: HQ-OV3D框架不仅能够成为一个强大的开放词汇3D检测器，同时也可以作为生成高质量伪标签的插件，适用于现有检测或标注流程。

Abstract: Traditional closed-set 3D detection frameworks fail to meet the demands of
open-world applications like autonomous driving. Existing open-vocabulary 3D
detection methods typically adopt a two-stage pipeline consisting of
pseudo-label generation followed by semantic alignment. While vision-language
models (VLMs) recently have dramatically improved the semantic accuracy of
pseudo-labels, their geometric quality, particularly bounding box precision,
remains commonly neglected.To address this issue, we propose a High Box Quality
Open-Vocabulary 3D Detection (HQ-OV3D) framework, dedicated to generate and
refine high-quality pseudo-labels for open-vocabulary classes. The framework
comprises two key components: an Intra-Modality Cross-Validated (IMCV) Proposal
Generator that utilizes cross-modality geometric consistency to generate
high-quality initial 3D proposals, and an Annotated-Class Assisted (ACA)
Denoiser that progressively refines 3D proposals by leveraging geometric priors
from annotated categories through a DDIM-based denoising mechanism.Compared to
the state-of-the-art method, training with pseudo-labels generated by our
approach achieves a 7.37% improvement in mAP on novel classes, demonstrating
the superior quality of the pseudo-labels produced by our framework. HQ-OV3D
can serve not only as a strong standalone open-vocabulary 3D detector but also
as a plug-in high-quality pseudo-label generator for existing open-vocabulary
detection or annotation pipelines.

</details>


### [7] [Vision-Only Gaussian Splatting for Collaborative Semantic Occupancy Prediction](https://arxiv.org/abs/2508.10936)
*Cheng Chen,Hao Huang,Saurabh Bagchi*

Main category: cs.CV

TL;DR: 本文提出了一种基于稀疏3D语义高斯分布的协同3D语义占用预测方法，用来解决现有方法通信成本高或易受深度估计限制的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉方法在3D语义占用预测中通信成本高或依赖准确深度估计，这限制了其在协同场景中的应用。

Method: 作者利用稀疏3D高斯分布提出了一种新方法，通过中间高斯原语的分享与融合，实现去重、减少噪声融合，同时使几何与语义编码结合，减少深度监督需求，并通过稀疏消息减小通信量。

Result: 实验结果表明，该方法在mIoU和IoU上分别比单车感知和基线协作方法有显著提升，同时在减少通信量的情况下，性能依然表现出色。

Conclusion: 该方法有效提高了协同感知的性能，特别是在通信预算有限的场景下，展现了其适用性与鲁棒性。

Abstract: Collaborative perception enables connected vehicles to share information,
overcoming occlusions and extending the limited sensing range inherent in
single-agent (non-collaborative) systems. Existing vision-only methods for 3D
semantic occupancy prediction commonly rely on dense 3D voxels, which incur
high communication costs, or 2D planar features, which require accurate depth
estimation or additional supervision, limiting their applicability to
collaborative scenarios. To address these challenges, we propose the first
approach leveraging sparse 3D semantic Gaussian splatting for collaborative 3D
semantic occupancy prediction. By sharing and fusing intermediate Gaussian
primitives, our method provides three benefits: a neighborhood-based
cross-agent fusion that removes duplicates and suppresses noisy or inconsistent
Gaussians; a joint encoding of geometry and semantics in each primitive, which
reduces reliance on depth supervision and allows simple rigid alignment; and
sparse, object-centric messages that preserve structural information while
reducing communication volume. Extensive experiments demonstrate that our
approach outperforms single-agent perception and baseline collaborative methods
by +8.42 and +3.28 points in mIoU, and +5.11 and +22.41 points in IoU,
respectively. When further reducing the number of transmitted Gaussians, our
method still achieves a +1.9 improvement in mIoU, using only 34.6%
communication volume, highlighting robust performance under limited
communication budgets.

</details>


### [8] [Personalized Face Super-Resolution with Identity Decoupling and Fitting](https://arxiv.org/abs/2508.10937)
*Jiarui Yang,Hang Guo,Wen Huang,Tao Dai,Shutao Xia*

Main category: cs.CV

TL;DR: 本文提出了一种名为IDFSR的面部超分辨率方法，特别针对极端降解条件下的ID信息恢复问题，显著提升了重建图像的ID一致性和感知质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在面临极端降解场景（如放大倍数 > 8x）时，无法重建具有真实ID约束的面孔，并易生成虚假脸部图像，导致ID一致性丧失。

Method: 提出了IDFSR方法，包括三个关键设计：1)通过屏蔽低分辨率图像的面部区域去除不可靠的ID线索；2)通过对齐参考图像提供风格引导；3)利用从真实图像提取的ID嵌入进行细粒度ID建模和个性化调整。方法采用基于扩散的模型进行预训练以解耦风格和ID，然后对ID嵌入进行轻量化微调。

Result: 实验表明，IDFSR在极端降解条件下显著优于现有方法，特别是在ID一致性方面表现突出。

Conclusion: IDFSR有效解决了极端降解场景中的面部超分辨率问题，兼具真实ID约束和自然视觉感知效果，在视觉和量化评估中均表现优异。

Abstract: In recent years, face super-resolution (FSR) methods have achieved remarkable
progress, generally maintaining high image fidelity and identity (ID)
consistency under standard settings. However, in extreme degradation scenarios
(e.g., scale $> 8\times$), critical attributes and ID information are often
severely lost in the input image, making it difficult for conventional models
to reconstruct realistic and ID-consistent faces. Existing methods tend to
generate hallucinated faces under such conditions, producing restored images
lacking authentic ID constraints. To address this challenge, we propose a novel
FSR method with Identity Decoupling and Fitting (IDFSR), designed to enhance ID
restoration under large scaling factors while mitigating hallucination effects.
Our approach involves three key designs: 1) \textbf{Masking} the facial region
in the low-resolution (LR) image to eliminate unreliable ID cues; 2)
\textbf{Warping} a reference image to align with the LR input, providing style
guidance; 3) Leveraging \textbf{ID embeddings} extracted from ground truth (GT)
images for fine-grained ID modeling and personalized adaptation. We first
pretrain a diffusion-based model to explicitly decouple style and ID by forcing
it to reconstruct masked LR face regions using both style and identity
embeddings. Subsequently, we freeze most network parameters and perform
lightweight fine-tuning of the ID embedding using a small set of target ID
images. This embedding encodes fine-grained facial attributes and precise ID
information, significantly improving both ID consistency and perceptual
quality. Extensive quantitative evaluations and visual comparisons demonstrate
that the proposed IDFSR substantially outperforms existing approaches under
extreme degradation, particularly achieving superior performance on ID
consistency.

</details>


### [9] [Deep Learning for Automated Identification of Vietnamese Timber Species: A Tool for Ecological Monitoring and Conservation](https://arxiv.org/abs/2508.10938)
*Tianyu Song,Van-Doan Duong,Thi-Phuong Le,Ton Viet Ta*

Main category: cs.CV

TL;DR: 该研究提出使用轻量级深度学习模型自动分类越南常见的十种木材种类，实现高精度和高效率的分类。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过自动化的方式解决传统木材种类鉴定方法依赖专家知识且耗时的痛点，助力生态监测和生物多样性保护。

Method: 构建了一个定制图像数据集，并评估了五种先进的卷积神经网络架构，包括ResNet50、EfficientNet、MobileViT、MobileNetV3和ShuffleNetV2。

Result: ShuffleNetV2模型在分类性能和计算效率之间达成最佳平衡，平均分类精度达99.29%，F1值达99.35%。

Conclusion: 轻量级深度学习模型能够在资源受限的环境中实现实时、高精度的木材种类识别，为生态信息学的发展提供了新的解决方案。

Abstract: Accurate identification of wood species plays a critical role in ecological
monitoring, biodiversity conservation, and sustainable forest management.
Traditional classification approaches relying on macroscopic and microscopic
inspection are labor-intensive and require expert knowledge. In this study, we
explore the application of deep learning to automate the classification of ten
wood species commonly found in Vietnam. A custom image dataset was constructed
from field-collected wood samples, and five state-of-the-art convolutional
neural network architectures--ResNet50, EfficientNet, MobileViT, MobileNetV3,
and ShuffleNetV2--were evaluated. Among these, ShuffleNetV2 achieved the best
balance between classification performance and computational efficiency, with
an average accuracy of 99.29\% and F1-score of 99.35\% over 20 independent
runs. These results demonstrate the potential of lightweight deep learning
models for real-time, high-accuracy species identification in
resource-constrained environments. Our work contributes to the growing field of
ecological informatics by providing scalable, image-based solutions for
automated wood classification and forest biodiversity assessment.

</details>


### [10] [NIRMAL Pooling: An Adaptive Max Pooling Approach with Non-linear Activation for Enhanced Image Classification](https://arxiv.org/abs/2508.10940)
*Nirmal Gaud,Krishna Kumar Jha,Jhimli Adhikari,Adhini Nasarin P S,Joydeep Das,Samarth S Deshpande,Nitasha Barara,Vaduguru Venkata Ramya,Santu Saha,Mehmet Tarik Baran,Sarangi Venkateshwarlu,Anusha M D,Surej Mouli,Preeti Katiyar,Vipin Kumar Chaudhary*

Main category: cs.CV

TL;DR: 本文介绍了NIRMAL池层，一种新型的CNN池化层，通过自适应最大池化和非线性激活函数，用于提升图像分类任务性能。


<details>
  <summary>Details</summary>
Motivation: 研究解决传统最大池化方法在特征表现力和鲁棒性上的局限性，提出改进方案。

Method: 提出了一种名为NIRMAL的池化方法，结合了非线性激活、中间聚合、自适应最大池化和局部特性。

Result: NIRMAL池化在MNIST Digits上达到了99.25%的测试准确率（对比Max Pooling的99.12%），MNIST Fashion上91.59%（对比91.44%），CIFAR-10上70.49%（对比68.87%）。

Conclusion: NIRMAL池化在提升CNN性能方面表现出潜力，尤其在复杂数据集上。

Abstract: This paper presents NIRMAL Pooling, a novel pooling layer for Convolutional
Neural Networks (CNNs) that integrates adaptive max pooling with non-linear
activation function for image classification tasks. The acronym NIRMAL stands
for Non-linear Activation, Intermediate Aggregation, Reduction, Maximum,
Adaptive, and Localized. By dynamically adjusting pooling parameters based on
desired output dimensions and applying a Rectified Linear Unit (ReLU)
activation post-pooling, NIRMAL Pooling improves robustness and feature
expressiveness. We evaluated its performance against standard Max Pooling on
three benchmark datasets: MNIST Digits, MNIST Fashion, and CIFAR-10. NIRMAL
Pooling achieves test accuracies of 99.25% (vs. 99.12% for Max Pooling) on
MNIST Digits, 91.59% (vs. 91.44%) on MNIST Fashion, and 70.49% (vs. 68.87%) on
CIFAR-10, demonstrating consistent improvements, particularly on complex
datasets. This work highlights the potential of NIRMAL Pooling to enhance CNN
performance in diverse image recognition tasks, offering a flexible and
reliable alternative to traditional pooling methods.

</details>


### [11] [Topological Structure Description for Artcode Detection Using the Shape of Orientation Histogram](https://arxiv.org/abs/2508.10942)
*Liming Xu,Dave Towey,Andrew P. French,Steve Benford*

Main category: cs.CV

TL;DR: 本研究探讨了一种特殊类型的物件——Artcodes，一种融合虚拟元素的装饰性标记，提出了一种新的特征描述符用于检测这些物件的存在。实验结果验证了其检测系统的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着智能手机的普及和VR/AR技术的复兴，研究目标是开发能够检测高效识别现实环境中与虚拟元素连接的装饰性物件的方法。

Method: 本文提出了一种新的特征描述符——方向直方图的形状（shape of orientation histogram），用于描述Artcodes的拓扑结构，并基于此设计了Artcode检测系统。

Result: 实验结果显示，提出的特征描述符能够有效地表示Artcode的拓扑结构，其检测系统能够准确识别Artcodes的存在。

Conclusion: 该研究首次尝试针对拓扑对象提出基于特征的检测系统，为开拓全新互动机会及拓扑对象检测的潜在应用奠定了基础。

Abstract: The increasing ubiquity of smartphones and resurgence of VR/AR techniques, it
is expected that our everyday environment may soon be decorating with objects
connecting with virtual elements. Alerting to the presence of these objects is
therefore the first step for motivating follow-up further inspection and
triggering digital material attached to the objects. This work studies a
special kind of these objects -- Artcodes -- a human-meaningful and
machine-readable decorative markers that camouflage themselves with freeform
appearance by encoding information into their topology. We formulate this
problem of recongising the presence of Artcodes as Artcode proposal detection,
a distinct computer vision task that classifies topologically similar but
geometrically and semantically different objects as a same class. To deal with
this problem, we propose a new feature descriptor, called the shape of
orientation histogram, to describe the generic topological structure of an
Artcode. We collect datasets and conduct comprehensive experiments to evaluate
the performance of the Artcode detection proposer built upon this new feature
vector. Our experimental results show the feasibility of the proposed feature
vector for representing topological structures and the effectiveness of the
system for detecting Artcode proposals. Although this work is an initial
attempt to develop a feature-based system for detecting topological objects
like Artcodes, it would open up new interaction opportunities and spark
potential applications of topological object detection.

</details>


### [12] [Analysis of the Compaction Behavior of Textile Reinforcements in Low-Resolution In-Situ CT Scans via Machine-Learning and Descriptor-Based Methods](https://arxiv.org/abs/2508.10943)
*Christian Düreth,Jan Condé-Wolter,Marek Danczak,Karsten Tittmann,Jörn Jaschinski,Andreas Hornig,Maik Gude*

Main category: cs.CV

TL;DR: 该研究提出了一种利用低分辨率CT扫描来分析干纺织增强材料在压缩下嵌套行为的方法，结合3D-UNet语义分割和空间结构分析，获得了坚实的验证结果。


<details>
  <summary>Details</summary>
Motivation: 纺织增强复合材料的机械性能与多尺度材料结构密切相关，而嵌套行为对材料的弹性、渗透性和损伤容限有重要影响。因此，需要一种高效的方法定量分析嵌套行为。

Method: 研究利用原位压缩实验和分辨率为20.22 μm每体素的低分辨率CT扫描，结合改进的3D-UNet模型对压缩阶段的矩阵、经线和纬线进行语义分割，并通过两点相关函数分析空间结构。

Result: 模型分割性能表现优异，最低的平均IOU为0.822，F1得分为0.902。通过两点相关函数计算，验证结果与显微图像分析吻合良好。

Conclusion: 该方法为从工业CT数据中提取关键几何特征提供了强有力的工具，为复合材料的反向建模及结构分析提供了基础。

Abstract: A detailed understanding of material structure across multiple scales is
essential for predictive modeling of textile-reinforced composites. Nesting --
characterized by the interlocking of adjacent fabric layers through local
interpenetration and misalignment of yarns -- plays a critical role in defining
mechanical properties such as stiffness, permeability, and damage tolerance.
This study presents a framework to quantify nesting behavior in dry textile
reinforcements under compaction using low-resolution computed tomography (CT).
In-situ compaction experiments were conducted on various stacking
configurations, with CT scans acquired at 20.22 $\mu$m per voxel resolution. A
tailored 3D{-}UNet enabled semantic segmentation of matrix, weft, and fill
phases across compaction stages corresponding to fiber volume contents of
50--60 %. The model achieved a minimum mean Intersection-over-Union of 0.822
and an $F1$ score of 0.902. Spatial structure was subsequently analyzed using
the two-point correlation function $S_2$, allowing for probabilistic extraction
of average layer thickness and nesting degree. The results show strong
agreement with micrograph-based validation. This methodology provides a robust
approach for extracting key geometrical features from industrially relevant CT
data and establishes a foundation for reverse modeling and descriptor-based
structural analysis of composite preforms.

</details>


### [13] [iWatchRoad: Scalable Detection and Geospatial Visualization of Potholes for Smart Cities](https://arxiv.org/abs/2508.10945)
*Rishi Raj Sahoo,Surbhi Saswati Mohanty,Subhankar Mishra*

Main category: cs.CV

TL;DR: 该研究开发了一个名为iWatchRoad的系统，利用YOLO模型通过行车记录仪检测路面坑洞，并结合GPS进行实时标记和可视化。


<details>
  <summary>Details</summary>
Motivation: 为了提高路面安全性并减轻道路维护负担，特别是在印度复杂且维护不足的道路上。

Method: 使用超过7,000帧的自建数据集，通过微调YOLO模型进行实时检测，同时结合OCR提取时间戳并与GPS日志同步，实现坑洞的精确地理标注和信息存储、可视化。

Result: 该系统成功提高了坑洞检测的准确性，并生成可供政府使用的道路评估和维护规划数据输出。

Conclusion: iWatchRoad是一种具有成本效益的硬件高效解决方案，适用于发展中地区的城市和农村道路管理。

Abstract: Potholes on the roads are a serious hazard and maintenance burden. This poses
a significant threat to road safety and vehicle longevity, especially on the
diverse and under-maintained roads of India. In this paper, we present a
complete end-to-end system called iWatchRoad for automated pothole detection,
Global Positioning System (GPS) tagging, and real time mapping using
OpenStreetMap (OSM). We curated a large, self-annotated dataset of over 7,000
frames captured across various road types, lighting conditions, and weather
scenarios unique to Indian environments, leveraging dashcam footage. This
dataset is used to fine-tune, Ultralytics You Only Look Once (YOLO) model to
perform real time pothole detection, while a custom Optical Character
Recognition (OCR) module was employed to extract timestamps directly from video
frames. The timestamps are synchronized with GPS logs to geotag each detected
potholes accurately. The processed data includes the potholes' details and
frames as metadata is stored in a database and visualized via a user friendly
web interface using OSM. iWatchRoad not only improves detection accuracy under
challenging conditions but also provides government compatible outputs for road
assessment and maintenance planning through the metadata visible on the
website. Our solution is cost effective, hardware efficient, and scalable,
offering a practical tool for urban and rural road management in developing
regions, making the system automated. iWatchRoad is available at
https://smlab.niser.ac.in/project/iwatchroad

</details>


### [14] [IPG: Incremental Patch Generation for Generalized Adversarial Patch Training](https://arxiv.org/abs/2508.10946)
*Wonho Lee,Hyunsik Na,Jisu Lee,Daeseon Choi*

Main category: cs.CV

TL;DR: 本文提出了一种名为增量式补丁生成（IPG）的方法，其生成对抗补丁的效率比现有方法高达11.1倍，同时保持了可比的攻击效果。


<details>
  <summary>Details</summary>
Motivation: 对抗补丁是对AI模型鲁棒性的一大挑战，尤其是在目标检测等计算机视觉任务中。本文旨在提高对抗补丁生成的效率以及对模型漏洞的广泛覆盖能力。

Method: 利用增量式补丁生成（IPG）方法，通过实验和消融研究及特征分布可视化等验证了其有效性，同时提出该方法生成的数据集可用于增强模型的鲁棒性。

Result: IPG以更高效的方式生成通用化对抗补丁，并覆盖更广泛的模型漏洞；实验表明，其生成的数据集可构建更加鲁棒的AI模型。

Conclusion: IPG不仅在对抗补丁防御中具有潜力，同时也可扩展应用于自动驾驶、安全系统和医疗成像等需要实时鲁棒性保障的领域。

Abstract: The advent of adversarial patches poses a significant challenge to the
robustness of AI models, particularly in the domain of computer vision tasks
such as object detection. In contradistinction to traditional adversarial
examples, these patches target specific regions of an image, resulting in the
malfunction of AI models. This paper proposes Incremental Patch Generation
(IPG), a method that generates adversarial patches up to 11.1 times more
efficiently than existing approaches while maintaining comparable attack
performance. The efficacy of IPG is demonstrated by experiments and ablation
studies including YOLO's feature distribution visualization and adversarial
training results, which show that it produces well-generalized patches that
effectively cover a broader range of model vulnerabilities. Furthermore,
IPG-generated datasets can serve as a robust knowledge foundation for
constructing a robust model, enabling structured representation, advanced
reasoning, and proactive defenses in AI security ecosystems. The findings of
this study suggest that IPG has considerable potential for future utilization
not only in adversarial patch defense but also in real-world applications such
as autonomous vehicles, security systems, and medical imaging, where AI models
must remain resilient to adversarial attacks in dynamic and high-stakes
environments.

</details>


### [15] [MedAtlas: Evaluating LLMs for Multi-Round, Multi-Task Medical Reasoning Across Diverse Imaging Modalities and Clinical Text](https://arxiv.org/abs/2508.10947)
*Ronghao Xu,Zhen Huang,Yangbo Wei,Xiaoqian Zhou,Zikang Xu,Ting Liu,Zihang Jiang,S. Kevin Zhou*

Main category: cs.CV

TL;DR: MedAtlas是一种新的基准框架，用于评估大语言模型在医疗推理任务中的表现，其特点包括多轮对话、多模态医疗图像交互、多任务整合和高度临床真实性，并引入了两种新评估指标。


<details>
  <summary>Details</summary>
Motivation: 当前的医疗多模态基准存在局限性，主要表现为任务单一，缺乏多模态图像整合及难以反映临床实际需求，因此需要更先进的基准框架。

Method: 作者设计了MedAtlas框架，可处理包括多轮问答、多模态医疗图像整合、多任务评估等医疗推理任务。任务结合实际诊断工作流，整合时间互动、文本病史、多模态影像等多种信息来源。

Result: 通过测试现有的多模态模型，结果显示在多阶段临床推理任务中表现存在显著差距，验证了该基准的挑战性。

Conclusion: MedAtlas提供了一个评估平台，旨在推进稳健且可信赖的医疗AI的发展。

Abstract: Artificial intelligence has demonstrated significant potential in clinical
decision-making; however, developing models capable of adapting to diverse
real-world scenarios and performing complex diagnostic reasoning remains a
major challenge. Existing medical multi-modal benchmarks are typically limited
to single-image, single-turn tasks, lacking multi-modal medical image
integration and failing to capture the longitudinal and multi-modal interactive
nature inherent to clinical practice. To address this gap, we introduce
MedAtlas, a novel benchmark framework designed to evaluate large language
models on realistic medical reasoning tasks. MedAtlas is characterized by four
key features: multi-turn dialogue, multi-modal medical image interaction,
multi-task integration, and high clinical fidelity. It supports four core
tasks: open-ended multi-turn question answering, closed-ended multi-turn
question answering, multi-image joint reasoning, and comprehensive disease
diagnosis. Each case is derived from real diagnostic workflows and incorporates
temporal interactions between textual medical histories and multiple imaging
modalities, including CT, MRI, PET, ultrasound, and X-ray, requiring models to
perform deep integrative reasoning across images and clinical texts. MedAtlas
provides expert-annotated gold standards for all tasks. Furthermore, we propose
two novel evaluation metrics: Round Chain Accuracy and Error Propagation
Resistance. Benchmark results with existing multi-modal models reveal
substantial performance gaps in multi-stage clinical reasoning. MedAtlas
establishes a challenging evaluation platform to advance the development of
robust and trustworthy medical AI.

</details>


### [16] [ORBIT: An Object Property Reasoning Benchmark for Visual Inference Tasks](https://arxiv.org/abs/2508.10956)
*Abhishek Kolari,Mohammadhossein Khojasteh,Yifan Jiang,Floris den Hengst,Filip Ilievski*

Main category: cs.CV

TL;DR: 本文提出了一个系统化的评估框架ORBIT，旨在测试视觉语言模型(VLMs)在处理物体属性推理上的能力，并揭示现有VLMs在复杂场景中的显著局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在主流视觉问答(VQA)基准上取得了很大进展，但其是否能够抽象并推理图像中的物体仍不清楚。现有的VQA基准通常忽视对物体属性推理的全面考察，且缺乏不同图像类型和逻辑层级的代表性评价。

Method: 提出了一个多层次的VQA基准测试框架，以三类典型图像、三种推理复杂度水平和基于常识推理的四类物体属性作为核心维度，并开发了一个名为ORBIT的评估基准，包含360张图像和1080个计数型问题，用于系统性评估VLMs的推理能力。

Result: 在零样本测试中，12个现有模型表现出显著局限性，其中最优模型的准确率仅为40%。尤其是在处理复杂的真实图像、反事实物理和功能属性推理、高数量计数等场景下表现较差。

Conclusion: ORBIT揭示了当前VLMs在物体属性推理上的不足，强调了开发适合扩展的评估方法、改进标注规范以及研究新型推理模型的必要性。

Abstract: While vision-language models (VLMs) have made remarkable progress on many
popular visual question answering (VQA) benchmarks, it remains unclear whether
they abstract and reason over depicted objects. Inspired by human object
categorisation, object property reasoning involves identifying and recognising
low-level details and higher-level abstractions. While current VQA benchmarks
consider a limited set of object property attributes like size, they typically
blend perception and reasoning, and lack representativeness in terms of
reasoning and image categories. To this end, we introduce a systematic
evaluation framework with images of three representative types, three reasoning
levels of increasing complexity, and four object property dimensions driven by
prior work on commonsense reasoning. We develop a procedure to instantiate this
benchmark into ORBIT, a multi-level reasoning VQA benchmark for object
properties comprising 360 images paired with a total of 1,080 count-based
questions. Experiments with 12 state-of-the-art VLMs in zero-shot settings
reveal significant limitations compared to humans, with the best-performing
model only reaching 40\% accuracy. VLMs struggle particularly with realistic
(photographic) images, counterfactual reasoning about physical and functional
properties, and higher counts. ORBIT points to the need to develop methods for
scalable benchmarking, generalize annotation guidelines, and explore additional
reasoning VLMs. We make the ORBIT benchmark and the experimental code available
to support such endeavors.

</details>


### [17] [From Promise to Practical Reality: Transforming Diffusion MRI Analysis with Fast Deep Learning Enhancement](https://arxiv.org/abs/2508.10950)
*Xinyi Wang,Michael Barnett,Frederique Boonstra,Yael Barnett,Mariano Cabezas,Arkiev D'Souza,Matthew C. Kiernan,Kain Kyle,Meng Law,Lynette Masters,Zihao Tang,Stephen Tisch,Sicong Tu,Anneke Van Der Walt,Dongang Wang,Fernando Calamante,Weidong Cai,Chenyu Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为FastFOD-Net的新型深度学习框架，用于从单壳、低角度分辨率MRI数据中增强纤维方向分布（FODs），提高了FODs的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 针对现存FODs增强方法在临床数据、尤其是病理学样本上评估不足的问题，研发了一种新型深度学习框架以解决这一限制。

Method: 设计并优化了一个名为FastFOD-Net的端到端深度学习框架，以提高FODs的质量效率，能够在有限的MRI数据条件下进行增强学习。

Result: 通过对健康个体及六种神经疾病患者的全面临床评估，证明FastFOD-Net在提升分析精度、降低错误和加快计算速度上表现卓越，其训练/推断速度为前代的60倍。

Conclusion: FastFOD-Net具备加强临床神经科学研究、改善疾病区分分析以及推动基于深度学习的MRI增强方法在临床上的广泛应用的潜力。

Abstract: Fiber orientation distribution (FOD) is an advanced diffusion MRI modeling
technique that represents complex white matter fiber configurations, and a key
step for subsequent brain tractography and connectome analysis. Its reliability
and accuracy, however, heavily rely on the quality of the MRI acquisition and
the subsequent estimation of the FODs at each voxel. Generating reliable FODs
from widely available clinical protocols with single-shell and
low-angular-resolution acquisitions remains challenging but could potentially
be addressed with recent advances in deep learning-based enhancement
techniques. Despite advancements, existing methods have predominantly been
assessed on healthy subjects, which have proved to be a major hurdle for their
clinical adoption. In this work, we validate a newly optimized enhancement
framework, FastFOD-Net, across healthy controls and six neurological disorders.
This accelerated end-to-end deep learning framework enhancing FODs with
superior performance and delivering training/inference efficiency for clinical
use ($60\times$ faster comparing to its predecessor). With the most
comprehensive clinical evaluation to date, our work demonstrates the potential
of FastFOD-Net in accelerating clinical neuroscience research, empowering
diffusion MRI analysis for disease differentiation, improving interpretability
in connectome applications, and reducing measurement errors to lower sample
size requirements. Critically, this work will facilitate the more widespread
adoption of, and build clinical trust in, deep learning based methods for
diffusion MRI enhancement. Specifically, FastFOD-Net enables robust analysis of
real-world, clinical diffusion MRI data, comparable to that achievable with
high-quality research acquisitions.

</details>


### [18] [Empowering Multimodal LLMs with External Tools: A Comprehensive Survey](https://arxiv.org/abs/2508.10955)
*Wenbin An,Jiahao Nie,Yaqiang Wu,Feng Tian,Shijian Lu,Qinghua Zheng*

Main category: cs.CV

TL;DR: 本文综述了通过结合外部工具提高多模态大语言模型(MLLM)性能的策略，揭示了外部工具在提升数据质量、任务表现和评估能力方面的重要作用。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLLMs）在多模任务中展示了潜力，但其发展受限于数据质量有限、复杂任务表现较差以及评估方法不足等问题，因此需探索通过外部工具来增强其推理与解决问题的能力。

Method: 本研究针对外部工具所能提升的四个方向展开综述：高质量数据的获取与标注、多模态任务性能的改进、综合精准的模型评估，以及现有局限性与未来发展。

Result: 论文指出外部工具能够在多个关键维度增强MLLM的能力，例如以工具支持提升标注质量、强化复杂任务表现并改进评估方法。

Conclusion: 外部工具具有显著潜力，可推动多模态大语言模型的进步，并为其未来发展提供了重要方向建议。

Abstract: By integrating the perception capabilities of multimodal encoders with the
generative power of Large Language Models (LLMs), Multimodal Large Language
Models (MLLMs), exemplified by GPT-4V, have achieved great success in various
multimodal tasks, pointing toward a promising pathway to artificial general
intelligence. Despite this progress, the limited quality of multimodal data,
poor performance on many complex downstream tasks, and inadequate evaluation
protocols continue to hinder the reliability and broader applicability of MLLMs
across diverse domains. Inspired by the human ability to leverage external
tools for enhanced reasoning and problem-solving, augmenting MLLMs with
external tools (e.g., APIs, expert models, and knowledge bases) offers a
promising strategy to overcome these challenges. In this paper, we present a
comprehensive survey on leveraging external tools to enhance MLLM performance.
Our discussion is structured along four key dimensions about external tools:
(1) how they can facilitate the acquisition and annotation of high-quality
multimodal data; (2) how they can assist in improving MLLM performance on
challenging downstream tasks; (3) how they enable comprehensive and accurate
evaluation of MLLMs; (4) the current limitations and future directions of
tool-augmented MLLMs. Through this survey, we aim to underscore the
transformative potential of external tools in advancing MLLM capabilities,
offering a forward-looking perspective on their development and applications.
The project page of this paper is publicly available
athttps://github.com/Lackel/Awesome-Tools-for-MLLMs.

</details>


### [19] [Not There Yet: Evaluating Vision Language Models in Simulating the Visual Perception of People with Low Vision](https://arxiv.org/abs/2508.10972)
*Rosiana Natalie,Wenqian Xu,Ruei-Che Chang,Rada Mihalcea,Anhong Guo*

Main category: cs.CV

TL;DR: 本文评估了视觉语言模型 (VLMs) 模拟低视力个体看图感知能力的效果，使用了40名参与者的调查数据进行实验，并发现结合详细视觉信息和示例响应显著提升模型与人类的响应一致性（从0.59提升至0.70）。


<details>
  <summary>Details</summary>
Motivation: 探究视觉语言模型是否能够有效模拟低视力人群的图像感知能力，从而填补在无障碍领域研究的空白。

Method: 通过40位低视力参与者的调研，收集图像感知相关数据并构建数据集；然后设计基于这些数据构建的提示，用 GPT-4 模拟每个参与者的行为，测试模型与实际参与者回答的一致性。

Result: 当只给出最小提示时，VLM的表现一致性较低（0.59）；提供全面视觉信息和示例响应后，一致性显著提高至0.70；单个结合开式与选择式的响应示例，效果明显优于单独提供任一种（p < 0.0001）。

Conclusion: 视觉语言模型通过结合全面信息，可以显著改善视觉感知模拟能力，但额外增加的示例响应效果有限。

Abstract: Advances in vision language models (VLMs) have enabled the simulation of
general human behavior through their reasoning and problem solving
capabilities. However, prior research has not investigated such simulation
capabilities in the accessibility domain. In this paper, we evaluate the extent
to which VLMs can simulate the vision perception of low vision individuals when
interpreting images. We first compile a benchmark dataset through a survey
study with 40 low vision participants, collecting their brief and detailed
vision information and both open-ended and multiple-choice image perception and
recognition responses to up to 25 images. Using these responses, we construct
prompts for VLMs (GPT-4o) to create simulated agents of each participant,
varying the included information on vision information and example image
responses. We evaluate the agreement between VLM-generated responses and
participants' original answers. Our results indicate that VLMs tend to infer
beyond the specified vision ability when given minimal prompts, resulting in
low agreement (0.59). The agreement between the agent' and participants'
responses remains low when only either the vision information (0.59) or example
image responses (0.59) are provided, whereas a combination of both
significantly increase the agreement (0.70, p < 0.0001). Notably, a single
example combining both open-ended and multiple-choice responses, offers
significant performance improvements over either alone (p < 0.0001), while
additional examples provided minimal benefits (p > 0.05).

</details>


### [20] [CSNR and JMIM Based Spectral Band Selection for Reducing Metamerism in Urban Driving](https://arxiv.org/abs/2508.10962)
*Jiarong Li,Imad Ali Shah,Diarmaid Geever,Fiachra Collins,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 该研究探讨利用高光谱成像（HSI）技术解决RGB图像中伪同色异谱现象的问题，以提高对易受伤害道路使用者（VRU）的识别能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于RGB图像的感知系统在识别VRU时容易受到伪同色异谱现象影响，造成视觉歧义，亟需突破这一限制以提高道路安全。

Method: 提出一种结合信息理论技术（联合互信息最大化、相关性分析）与图像质量指标（对比信噪比）的波段选择策略，通过高光谱成像技术提取光谱信息，选择最具区分能力的光谱波段，并生成伪彩图像用于对比分析。

Result: 利用Hyperspectral City V2（H-City）数据集，选取三个关键波段（497 nm、607 nm、895 nm ±27 nm），结果显示这些波段显著提高了VRU与背景的区分度，定量指标的改进分别达70.24%、528.46%、1206.83%和246.62%。

Conclusion: 通过提供光谱优化的输入数据，方法显著减少伪同色异谱问题，提升了VRU的辨识度，为ADAS与自动驾驶中的感知任务提供了坚实基础，从而助力于道路安全的改善。

Abstract: Protecting Vulnerable Road Users (VRU) is a critical safety challenge for
automotive perception systems, particularly under visual ambiguity caused by
metamerism, a phenomenon where distinct materials appear similar in RGB
imagery. This work investigates hyperspectral imaging (HSI) to overcome this
limitation by capturing unique material signatures beyond the visible spectrum,
especially in the Near-Infrared (NIR). To manage the inherent
high-dimensionality of HSI data, we propose a band selection strategy that
integrates information theory techniques (joint mutual information
maximization, correlation analysis) with a novel application of an image
quality metric (contrast signal-to-noise ratio) to identify the most spectrally
informative bands. Using the Hyperspectral City V2 (H-City) dataset, we
identify three informative bands (497 nm, 607 nm, and 895 nm, $\pm$27 nm) and
reconstruct pseudo-color images for comparison with co-registered RGB.
Quantitative results demonstrate increased dissimilarity and perceptual
separability of VRU from the background. The selected HSI bands yield
improvements of 70.24%, 528.46%, 1206.83%, and 246.62% for dissimilarity
(Euclidean, SAM, $T^2$) and perception (CIE $\Delta E$) metrics, consistently
outperforming RGB and confirming a marked reduction in metameric confusion. By
providing a spectrally optimized input, our method enhances VRU separability,
establishing a robust foundation for downstream perception tasks in Advanced
Driver Assistance Systems (ADAS) and Autonomous Driving (AD), ultimately
contributing to improved road safety.

</details>


### [21] [EVCtrl: Efficient Control Adapter for Visual Generation](https://arxiv.org/abs/2508.10963)
*Zixiang Yang,Yue Ma,Yinhan Zhang,Shanhui Mo,Dongrui Liu,Linfeng Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为EVCtrl的新方法，通过轻量化、可插拔的控制适配器高效地进行图像和视频生成控制，同时大幅减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型在控制精度和计算效率之间存在矛盾，尤其是视频生成中冗余计算问题迫切需解决。

Method: 提出了一种时空双缓存策略，通过分析网络对精细控制信号的响应，将网络分为全局和局部功能区，并制定局部缓存策略以降低空间冗余，还通过跳过不必要的去噪步骤以减少时间冗余。

Result: 在CogVideo-Controlnet、Wan2.1-Controlnet及Flux上的实验显示，该方法无需重新训练模型，能有效实现图像与视频的高效生成控制，速度提升超2倍，基本无质量损失。

Conclusion: EVCtrl显著提升了生成控制效率，是一种无需模型重训即可应用的高效解决方案。

Abstract: Visual generation includes both image and video generation, training
probabilistic models to create coherent, diverse, and semantically faithful
content from scratch. While early research focused on unconditional sampling,
practitioners now demand controllable generation that allows precise
specification of layout, pose, motion, or style. While ControlNet grants
precise spatial-temporal control, its auxiliary branch markedly increases
latency and introduces redundant computation in both uncontrolled regions and
denoising steps, especially for video. To address this problem, we introduce
EVCtrl, a lightweight, plug-and-play control adapter that slashes overhead
without retraining the model. Specifically, we propose a spatio-temporal dual
caching strategy for sparse control information. For spatial redundancy, we
first profile how each layer of DiT-ControlNet responds to fine-grained
control, then partition the network into global and local functional zones. A
locality-aware cache focuses computation on the local zones that truly need the
control signal, skipping the bulk of redundant computation in global regions.
For temporal redundancy, we selectively omit unnecessary denoising steps to
improve efficiency. Extensive experiments on CogVideo-Controlnet,
Wan2.1-Controlnet, and Flux demonstrate that our method is effective in image
and video control generation without the need for training. For example, it
achieves 2.16 and 2.05 times speedups on CogVideo-Controlnet and
Wan2.1-Controlnet, respectively, with almost no degradation in generation
quality.Codes are available in the supplementary materials.

</details>


### [22] [Are Large Pre-trained Vision Language Models Effective Construction Safety Inspectors?](https://arxiv.org/abs/2508.11011)
*Xuezheng Chen,Zhengbo Zou*

Main category: cs.CV

TL;DR: 本文提出ConstructionSite 10k数据集，包含1万张施工现场图片及相关注释，用于图像描述、安全规则违规视觉问答及施工元素视觉定位三个任务。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）在施工安全检查任务中缺乏大规模、开放的数据集，限制了其广泛应用及进一步的调整优化。

Method: 构建包含1万张施工现场图片的ConstructionSite 10k数据集，注释包含图像描述、视觉问答与视觉定位任务，并评估了当前先进的预训练模型在不同训练设定下的性能。

Result: 预训练的VLM模型在零样本和少样本设定下表现出一定的泛化能力，但实际施工场景应用仍需额外训练。

Conclusion: 所提出的数据集为新模型架构与技术在施工安全检查领域的训练与评估，提供了重要的基准工具。

Abstract: Construction safety inspections typically involve a human inspector
identifying safety concerns on-site. With the rise of powerful Vision Language
Models (VLMs), researchers are exploring their use for tasks such as detecting
safety rule violations from on-site images. However, there is a lack of open
datasets to comprehensively evaluate and further fine-tune VLMs in construction
safety inspection. Current applications of VLMs use small, supervised datasets,
limiting their applicability in tasks they are not directly trained for. In
this paper, we propose the ConstructionSite 10k, featuring 10,000 construction
site images with annotations for three inter-connected tasks, including image
captioning, safety rule violation visual question answering (VQA), and
construction element visual grounding. Our subsequent evaluation of current
state-of-the-art large pre-trained VLMs shows notable generalization abilities
in zero-shot and few-shot settings, while additional training is needed to make
them applicable to actual construction sites. This dataset allows researchers
to train and evaluate their own VLMs with new architectures and techniques,
providing a valuable benchmark for construction safety inspection.

</details>


### [23] [Can Multi-modal (reasoning) LLMs detect document manipulation?](https://arxiv.org/abs/2508.11021)
*Zisheng Liang,Kidus Zewde,Rudra Pratap Singh,Disha Patil,Zexi Chen,Jiayu Xue,Yao Yao,Yifei Chen,Qinzhe Liu,Simiao Ren*

Main category: cs.CV

TL;DR: 研究探索多模态大型语言模型(LLMs)在文档欺诈检测中的效果，证明其在零样本泛化能力上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 文档欺诈对依赖安全可验证文档的行业构成重大威胁，需要强有力的检测机制。

Method: 通过优化提示和详细分析模型推理过程，使用标准数据集对多种多模态LLMs模型进行比较和评估，包括OpenAI、Gemini Flash等系列模型。

Result: 顶级多模态LLMs在零样本泛化中表现优异，超越了传统方法。而部分视觉LLMs则表现不一致或较差，模型大小和推理能力与检测精确度相关性有限。

Conclusion: 研究表明，多模态LLMs在文档欺诈检测中有很大潜力，未来需要针对任务的细微调整来提高效果。这为解释性和可扩展的欺诈缓解策略研究奠定了基础。

Abstract: Document fraud poses a significant threat to industries reliant on secure and
verifiable documentation, necessitating robust detection mechanisms. This study
investigates the efficacy of state-of-the-art multi-modal large language models
(LLMs)-including OpenAI O1, OpenAI 4o, Gemini Flash (thinking), Deepseek Janus,
Grok, Llama 3.2 and 4, Qwen 2 and 2.5 VL, Mistral Pixtral, and Claude 3.5 and
3.7 Sonnet-in detecting fraudulent documents. We benchmark these models against
each other and prior work on document fraud detection techniques using a
standard dataset with real transactional documents. Through prompt optimization
and detailed analysis of the models' reasoning processes, we evaluate their
ability to identify subtle indicators of fraud, such as tampered text,
misaligned formatting, and inconsistent transactional sums. Our results reveal
that top-performing multi-modal LLMs demonstrate superior zero-shot
generalization, outperforming conventional methods on out-of-distribution
datasets, while several vision LLMs exhibit inconsistent or subpar performance.
Notably, model size and advanced reasoning capabilities show limited
correlation with detection accuracy, suggesting task-specific fine-tuning is
critical. This study underscores the potential of multi-modal LLMs in enhancing
document fraud detection systems and provides a foundation for future research
into interpretable and scalable fraud mitigation strategies.

</details>


### [24] [MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation](https://arxiv.org/abs/2508.11032)
*Yanwu Yang,Guinan Su,Jiesi Hu,Francesco Sammarco,Jonas Geiping,Thomas Wolfers*

Main category: cs.CV

TL;DR: 本文提出了MedSAMix，一种无需训练的模型合并方法，通过结合通用模型和专业模型的优势，解决了现有医学图像分割模型的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 目前的医学图像分割模型存在数据异质性、注释稀缺和分布偏移等问题，限制了其在多任务中的泛化能力，需要发展更强大灵活的解决方案。

Method: 提出MedSAMix，这是一种基于零阶优化方法的模型合并技术，能自动发现层次合并的最优解决方案，并提供单任务优化和多目标优化两种模式以适应不同的临床需求。

Result: 在25个医学分割任务上的评估结果表明，MedSAMix能够减轻模型偏差，提高单任务的准确率6.67%和多任务的泛化性能4.37%。

Conclusion: MedSAMix有效提升了医学图像分割任务中模型的特定领域准确性和广泛场景的泛化能力。

Abstract: Universal medical image segmentation models have emerged as a promising
paradigm due to their strong generalizability across diverse tasks, showing
great potential for a wide range of clinical applications. This potential has
been partly driven by the success of general-purpose vision models such as the
Segment Anything Model (SAM), which has inspired the development of various
fine-tuned variants for medical segmentation tasks. However, fine-tuned
variants like MedSAM are trained on comparatively limited medical imaging data
that often suffers from heterogeneity, scarce annotations, and distributional
shifts. These challenges limit their ability to generalize across a wide range
of medical segmentation tasks. In this regard, we propose MedSAMix, a
training-free model merging method that integrates the strengths of both
generalist models (e.g., SAM) and specialist models (e.g., MedSAM) for medical
image segmentation. In contrast to traditional model merging approaches that
rely on manual configuration and often result in suboptimal outcomes, we
propose a zero-order optimization method to automatically discover optimal
layer-wise merging solutions. Furthermore, for clinical applications, we
develop two regimes to meet the demand of domain-specificity and
generalizability in different scenarios by single-task optimization and
multi-objective optimization respectively. Extensive evaluations on 25 medical
segmentation tasks demonstrate that MedSAMix effectively mitigates model bias
and consistently improves performance in both domain-specific accuracy and
generalization, achieving improvements of 6.67% on specialized tasks and 4.37%
on multi-task evaluations.

</details>


### [25] [Advancing 3D Scene Understanding with MV-ScanQA Multi-View Reasoning Evaluation and TripAlign Pre-training Dataset](https://arxiv.org/abs/2508.11058)
*Wentao Mo,Qingchao Chen,Yuxin Peng,Siyuan Huang,Yang Liu*

Main category: cs.CV

TL;DR: 本文提出了MV-ScanQA，一个主要用于测试多视图3D场景理解和推理能力的数据集，以及TripAlign，一个低成本大规模的2D-3D-语言预训练数据集。此外，还开发了LEGO，一个新的基线方法，在3D领域实现了多项任务的最新性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉-语言数据集在处理复杂场景理解和多视图推理时存在局限，如过于局限于单视角物体和单一对象的注释，缺乏多对象和多视图的上下文对齐能力。

Method: 提出MV-ScanQA数据集，68%的问题需要多视图信息整合；提出TripAlign预训练数据集，通过1M个2D-3D-语言三元组实现更丰富的多模态对齐信号；并开发LEGO基线方法，将2D语言视觉模型的知识传递到3D领域。

Result: LEGO在MV-ScanQA和现有3D密集描述与问答基准上均达到最新性能。

Conclusion: 本文通过提出新的数据集和方法，推动了3D多视图场景理解和推理能力的发展，同时提供了高效的模型预训练方案，提升了各类任务的模型性能。

Abstract: The advancement of 3D vision-language (3D VL) learning is hindered by several
limitations in existing 3D VL datasets: they rarely necessitate reasoning
beyond a close range of objects in single viewpoint, and annotations often link
instructions to single objects, missing richer contextual alignments between
multiple objects. This significantly curtails the development of models capable
of deep, multi-view 3D scene understanding over distant objects. To address
these challenges, we introduce MV-ScanQA, a novel 3D question answering dataset
where 68% of questions explicitly require integrating information from multiple
views (compared to less than 7% in existing datasets), thereby rigorously
testing multi-view compositional reasoning. To facilitate the training of
models for such demanding scenarios, we present TripAlign dataset, a
large-scale and low-cost 2D-3D-language pre-training corpus containing 1M <2D
view, set of 3D objects, text> triplets that explicitly aligns groups of
contextually related objects with text, providing richer, view-grounded
multi-object multimodal alignment signals than previous single-object
annotations. We further develop LEGO, a baseline method for the multi-view
reasoning challenge in MV-ScanQA, transferring knowledge from pre-trained 2D
LVLMs to 3D domain with TripAlign. Empirically, LEGO pre-trained on TripAlign
achieves state-of-the-art performance not only on the proposed MV-ScanQA, but
also on existing benchmarks for 3D dense captioning and question answering.
Datasets and code are available at
https://matthewdm0816.github.io/tripalign-mvscanqa.

</details>


### [26] [Data-Driven Abdominal Phenotypes of Type 2 Diabetes in Lean, Overweight, and Obese Cohorts](https://arxiv.org/abs/2508.11063)
*Lucas W. Remedios,Chloe Choe,Trent M. Schwartz,Dingjie Su,Gaurav Rudravaram,Chenyu Gao,Aravind R. Krishnan,Adam M. Saunders,Michael E. Kim,Shunxing Bao,Alvin C. Powers,Bennett A. Landman,John Virostko*

Main category: cs.CV

TL;DR: 使用人工智能处理3D临床影像数据，发现不同BMI组别中2型糖尿病患者的腹部成分特征，发现腹部生理指标与糖尿病风险的一致性。


<details>
  <summary>Details</summary>
Motivation: 探讨为何有些瘦人会患2型糖尿病，而有些肥胖者却不会，通过详细的腹部成分分析，尝试识别出与2型糖尿病风险或保护有关的体成分标志。

Method: 利用AI从3D影像提取腹部成分数据，通过随机森林和SHAP分析评估这些特征对糖尿病的风险贡献，分群分析BMI与腹部成分特征的关系。

Result: 随机森林模型在不同组别中平均AUC为0.72-0.74，确认了各组别中共有的糖尿病特征如脂肪骨骼肌、年长、内脏脂肪增加和脂肪负荷胰腺等。

Conclusion: 各BMI类别中腹部的糖尿病驱动因素可能具有一致性，研究展现了通过影像与AI技术揭示糖尿病体成分特征的潜力。

Abstract: Purpose: Although elevated BMI is a well-known risk factor for type 2
diabetes, the disease's presence in some lean adults and absence in others with
obesity suggests that detailed body composition may uncover abdominal
phenotypes of type 2 diabetes. With AI, we can now extract detailed
measurements of size, shape, and fat content from abdominal structures in 3D
clinical imaging at scale. This creates an opportunity to empirically define
body composition signatures linked to type 2 diabetes risk and protection using
large-scale clinical data. Approach: To uncover BMI-specific diabetic abdominal
patterns from clinical CT, we applied our design four times: once on the full
cohort (n = 1,728) and once on lean (n = 497), overweight (n = 611), and obese
(n = 620) subgroups separately. Briefly, our experimental design transforms
abdominal scans into collections of explainable measurements through
segmentation, classifies type 2 diabetes through a cross-validated random
forest, measures how features contribute to model-estimated risk or protection
through SHAP analysis, groups scans by shared model decision patterns
(clustering from SHAP) and links back to anatomical differences
(classification). Results: The random-forests achieved mean AUCs of 0.72-0.74.
There were shared type 2 diabetes signatures in each group; fatty skeletal
muscle, older age, greater visceral and subcutaneous fat, and a smaller or
fat-laden pancreas. Univariate logistic regression confirmed the direction of
14-18 of the top 20 predictors within each subgroup (p < 0.05). Conclusions:
Our findings suggest that abdominal drivers of type 2 diabetes may be
consistent across weight classes.

</details>


### [27] [HierOctFusion: Multi-scale Octree-based 3D Shape Generation via Part-Whole-Hierarchy Message Passing](https://arxiv.org/abs/2508.11106)
*Xinjie Gao,Bi'an Du,Wei Hu*

Main category: cs.CV

TL;DR: 本文提出了一个名为HierOctFusion的3D生成模型，基于部分和多尺度的八叉树扩散方法以改进生成精度和效率，并引入了交叉注意力机制提升语义传播能力。实验证明其在形状质量与效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的三维生成方法忽略了对象的语义部分层次性，同时高分辨率建模计算开销大，因此提出一种基于部分信息的层次化生成方法，以改进生成的细节和计算效率。

Method: 提出了HierOctFusion模型，通过多尺度八叉树扩散技术与交叉注意力条件机制，有效整合各层次部分信息并注入语义特征，同时构建了带有部分类别注释的数据集用于训练和评估。

Result: HierOctFusion在实验中表现出优异的三维形状质量和生成效率，优于以往的方法。

Conclusion: HierOctFusion通过结合语义部分信息与层次化生成策略，实现了对细粒度稀疏物体结构的高效生成，为三维内容的高质量生成提供了新方向。

Abstract: 3D content generation remains a fundamental yet challenging task due to the
inherent structural complexity of 3D data. While recent octree-based diffusion
models offer a promising balance between efficiency and quality through
hierarchical generation, they often overlook two key insights: 1) existing
methods typically model 3D objects as holistic entities, ignoring their
semantic part hierarchies and limiting generalization; and 2) holistic
high-resolution modeling is computationally expensive, whereas real-world
objects are inherently sparse and hierarchical, making them well-suited for
layered generation. Motivated by these observations, we propose HierOctFusion,
a part-aware multi-scale octree diffusion model that enhances hierarchical
feature interaction for generating fine-grained and sparse object structures.
Furthermore, we introduce a cross-attention conditioning mechanism that injects
part-level information into the generation process, enabling semantic features
to propagate effectively across hierarchical levels from parts to the whole.
Additionally, we construct a 3D dataset with part category annotations using a
pre-trained segmentation model to facilitate training and evaluation.
Experiments demonstrate that HierOctFusion achieves superior shape quality and
efficiency compared to prior methods.

</details>


### [28] [UWB-PostureGuard: A Privacy-Preserving RF Sensing System for Continuous Ergonomic Sitting Posture Monitoring](https://arxiv.org/abs/2508.11115)
*Haotang Li,Zhenyu Qi,Sen He,Kebin Peng,Sheng Tan,Yili Ren,Tomas Cerny,Jiyue Zhao,Zi Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种基于超宽带(UWB)的隐私保护坐姿监测系统，用于连续和非接触地监测计算机使用中的人体坐姿。


<details>
  <summary>Details</summary>
Motivation: 传统坐姿监测方法由于摄像头隐私问题或穿戴传感器的不适感，致使用户体验不佳，亟需一种更高效且保护隐私的解决方案。

Method: 利用商用UWB设备，结合全面的特征工程提取功能，开发PoseGBDT模型捕获坐姿模式的时间依赖性，并通过实际评价验证系统性能。

Result: 系统在10名参与者19种坐姿中展现99.11%的检测准确性，同时对环境变量（如衣服厚度、设备或家具）具有良好的鲁棒性。

Conclusion: UWB-PostureGuard提供了一种可扩展的、基于现有平台的隐私保护健康管理解决方案，在低成本条件下显著改善生活质量。

Abstract: Improper sitting posture during prolonged computer use has become a
significant public health concern. Traditional posture monitoring solutions
face substantial barriers, including privacy concerns with camera-based systems
and user discomfort with wearable sensors. This paper presents
UWB-PostureGuard, a privacy-preserving ultra-wideband (UWB) sensing system that
advances mobile technologies for preventive health management through
continuous, contactless monitoring of ergonomic sitting posture. Our system
leverages commercial UWB devices, utilizing comprehensive feature engineering
to extract multiple ergonomic sitting posture features. We develop PoseGBDT to
effectively capture temporal dependencies in posture patterns, addressing
limitations of traditional frame-wise classification approaches. Extensive
real-world evaluation across 10 participants and 19 distinct postures
demonstrates exceptional performance, achieving 99.11% accuracy while
maintaining robustness against environmental variables such as clothing
thickness, additional devices, and furniture configurations. Our system
provides a scalable, privacy-preserving mobile health solution on existing
platforms for proactive ergonomic management, improving quality of life at low
costs.

</details>


### [29] [A Cross-Modal Rumor Detection Scheme via Contrastive Learning by Exploring Text and Image internal Correlations](https://arxiv.org/abs/2508.11141)
*Bin Ma,Yifei Zhang,Yongjin Xian,Qi Li,Linna Zhou,Gongxun Miao*

Main category: cs.CV

TL;DR: 提出了一种名为MICC的跨模态谣言检测算法，结合对比学习、图文语义关联以及多尺度融合技术，在实验证明中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有谣言检测方法忽视了图像内容及其与上下文间的多尺度关系，导致关键信息的遗漏。

Method: 设计一个SCLIP编码器生成文本与多尺度图像的统一语义嵌入，通过交叉模态相关矩阵和Top-K选择机制提取相关图像区域，并通过多尺度融合网络整合语义高度相关的图像和文本特征。

Result: 在两个真实世界数据集上进行评估，结果表明该方法在谣言检测上的表现明显优于现有方法。

Conclusion: 该方法展现了在谣言检测领域的有效性和实际应用潜力，提供了改进技术的可能方向。

Abstract: Existing rumor detection methods often neglect the content within images as
well as the inherent relationships between contexts and images across different
visual scales, thereby resulting in the loss of critical information pertinent
to rumor identification. To address these issues, this paper presents a novel
cross-modal rumor detection scheme based on contrastive learning, namely the
Multi-scale Image and Context Correlation exploration algorithm (MICC).
Specifically, we design an SCLIP encoder to generate unified semantic
embeddings for text and multi-scale image patches through contrastive
pretraining, enabling their relevance to be measured via dot-product
similarity. Building upon this, a Cross-Modal Multi-Scale Alignment module is
introduced to identify image regions most relevant to the textual semantics,
guided by mutual information maximization and the information bottleneck
principle, through a Top-K selection strategy based on a cross-modal relevance
matrix constructed between the text and multi-scale image patches. Moreover, a
scale-aware fusion network is designed to integrate the highly correlated
multi-scale image features with global text features by assigning adaptive
weights to image regions based on their semantic importance and cross-modal
relevance. The proposed methodology has been extensively evaluated on two
real-world datasets. The experimental results demonstrate that it achieves a
substantial performance improvement over existing state-of-the-art approaches
in rumor detection, highlighting its effectiveness and potential for practical
applications.

</details>


### [30] [Residual-based Efficient Bidirectional Diffusion Model for Image Dehazing and Haze Generation](https://arxiv.org/abs/2508.11134)
*Bing Liu,Le Wang,Hao Liu,Mingming Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于残差的高效双向扩散模型（RBDM），旨在实现去雾和生成雾图像之间的双向转换。


<details>
  <summary>Details</summary>
Motivation: 当前深度去雾方法只注重从有雾图像中去雾，缺乏在有雾和无雾图像之间转换的能力。

Method: 提出了残差双向扩散模型，包括：设计双Markov链以促进残差平滑转换；通过在独立时刻扰动图像并预测噪声以学习条件分布；通过图像块而非整图学习，提升小数据集性能并降低计算成本。

Result: RBDM在只需15次采样步骤下，实现了尺寸无关的双向转换，在合成和真实数据集上表现出色或达到最新方法水平。

Conclusion: 该方法显著提升了去雾和雾生成的双向任务性能并优化了小数据集的适用性和计算效率。

Abstract: Current deep dehazing methods only focus on removing haze from hazy images,
lacking the capability to translate between hazy and haze-free images. To
address this issue, we propose a residual-based efficient bidirectional
diffusion model (RBDM) that can model the conditional distributions for both
dehazing and haze generation. Firstly, we devise dual Markov chains that can
effectively shift the residuals and facilitate bidirectional smooth transitions
between them. Secondly, the RBDM perturbs the hazy and haze-free images at
individual timesteps and predicts the noise in the perturbed data to
simultaneously learn the conditional distributions. Finally, to enhance
performance on relatively small datasets and reduce computational costs, our
method introduces a unified score function learned on image patches instead of
entire images. Our RBDM successfully implements size-agnostic bidirectional
transitions between haze-free and hazy images with only 15 sampling steps.
Extensive experiments demonstrate that the proposed method achieves superior or
at least comparable performance to state-of-the-art methods on both synthetic
and real-world datasets.

</details>


### [31] [Better Supervised Fine-tuning for VQA: Integer-Only Loss](https://arxiv.org/abs/2508.11170)
*Baihong Qian,Haotian Fan,Wenjie Liao,Yunqiu Wang,Tao Li,Junhui Cui*

Main category: cs.CV

TL;DR: 提出了一种名为IOVQA的整数仅视频质量评估方法，通过限定模型输出为整数标签并优化损失计算，提升了视觉语言模型在视频质量评估任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视频主题一致性评估和视觉质量评分上表现仍受限于不够精确的结果及低效的损失计算。

Method: 提出一种名为IOVQA的微调方法，通过限制模型输出为[10,50]范围内的整数标签，并采用目标遮罩策略，仅在损失计算中对标签前两位数字进行学习。

Result: 微调后的Qwen2.5-VL模型在VQA任务中显著提高了准确性与一致性，并在2025 VQualA挑战赛中获得第三名。

Conclusion: 证明了在微调过程中仅使用整数标签的有效性，为优化视觉语言模型的定量评估场景提供了有效思路。

Abstract: With the rapid advancement of vision language models(VLM), their ability to
assess visual content based on specific criteria and dimensions has become
increasingly critical for applications such as video-theme consistency
assessment and visual quality scoring. However, existing methods often suffer
from imprecise results and inefficient loss calculation, which limit the focus
of the model on key evaluation indicators. To address this, we propose
IOVQA(Integer-only VQA), a novel fine-tuning approach tailored for VLMs to
enhance their performance in video quality assessment tasks. The key innovation
of IOVQA lies in its label construction and its targeted loss calculation
mechanism. Specifically, during dataset curation, we constrain the model's
output to integers within the range of [10,50], ensuring numerical stability,
and convert decimal Overall_MOS to integer before using them as labels. We also
introduce a target-mask strategy: when computing the loss, only the first
two-digit-integer of the label is unmasked, forcing the model to learn the
critical components of the numerical evaluation. After fine-tuning the
Qwen2.5-VL model using the constructed dataset, experimental results
demonstrate that the proposed method significantly improves the model's
accuracy and consistency in the VQA task, ranking 3rd in VQualA 2025
GenAI-Bench AIGC Video Quality Assessment Challenge -- Track I. Our work
highlights the effectiveness of merely leaving integer labels during
fine-tuning, providing an effective idea for optimizing VLMs in quantitative
evaluation scenarios.

</details>


### [32] [LEARN: A Story-Driven Layout-to-Image Generation Framework for STEM Instruction](https://arxiv.org/abs/2508.11153)
*Maoquan Zhang,Bisser Raytchev,Xiujuan Sun*

Main category: cs.CV

TL;DR: LEARN是一种生成框架，用于生成与STEM教育相符的插图，通过布局感知和结构视觉线索，实现语义对齐的科学概念可视化。


<details>
  <summary>Details</summary>
Motivation: 当前教育领域缺少适合生成连贯教育插图的工具，尤其是将叙事布局与高级语义对齐的框架。

Method: 利用精心策划的BookCover数据集，结合布局控制生成、对比视觉-语义训练及提示调节的方法生成插图。

Result: 生成支持中高层次推理的连贯视觉序列，并减轻认知负担，促进概念专注。

Conclusion: LEARN是第一个结合布局叙事、语义结构学习和认知支架的生成方法，为教育领域的生成式AI开创了新的方向。

Abstract: LEARN is a layout-aware diffusion framework designed to generate
pedagogically aligned illustrations for STEM education. It leverages a curated
BookCover dataset that provides narrative layouts and structured visual cues,
enabling the model to depict abstract and sequential scientific concepts with
strong semantic alignment. Through layout-conditioned generation, contrastive
visual-semantic training, and prompt modulation, LEARN produces coherent visual
sequences that support mid-to-high-level reasoning in line with Bloom's
taxonomy while reducing extraneous cognitive load as emphasized by Cognitive
Load Theory. By fostering spatially organized and story-driven narratives, the
framework counters fragmented attention often induced by short-form media and
promotes sustained conceptual focus. Beyond static diagrams, LEARN demonstrates
potential for integration with multimodal systems and curriculum-linked
knowledge graphs to create adaptive, exploratory educational content. As the
first generative approach to unify layout-based storytelling, semantic
structure learning, and cognitive scaffolding, LEARN represents a novel
direction for generative AI in education. The code and dataset will be released
to facilitate future research and practical deployment.

</details>


### [33] [Semi-supervised Image Dehazing via Expectation-Maximization and Bidirectional Brownian Bridge Diffusion Models](https://arxiv.org/abs/2508.11165)
*Bing Liu,Le Wang,Mingming Liu,Hao Liu,Rui Yao,Yong Zhou,Peng Liu,Tongqiang Xia*

Main category: cs.CV

TL;DR: 提出了一种基于期望最大化和双向布朗桥扩散模型的半监督图像去雾方法EM-B3DM，以解决浓雾图像去雾问题，在合成和真实数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决因缺乏真实配对数据和稳健先验导致的实际浓雾场景图像去雾困难的问题。

Method: 通过EM算法解耦成对的雾和无雾图像分布，引入双向布朗桥扩散模型学习雾图与清晰图像间的相关性，并利用大规模未配对图像与预训练模型提升性能，同时提出了一种新的残差差分卷积块捕捉梯度级信息。

Result: 该方法在合成数据集和真实世界数据集上实现了优于或至少与现有最先进方法相当的性能。

Conclusion: EM-B3DM方法有效解决了浓雾图像去雾的挑战，展现出强大的表现能力，可用于优化图像处理的应用场景。

Abstract: Existing dehazing methods deal with real-world haze images with difficulty,
especially scenes with thick haze. One of the main reasons is the lack of
real-world paired data and robust priors. To avoid the costly collection of
paired hazy and clear images, we propose an efficient semi-supervised image
dehazing method via Expectation-Maximization and Bidirectional Brownian Bridge
Diffusion Models (EM-B3DM) with a two-stage learning scheme. In the first
stage, we employ the EM algorithm to decouple the joint distribution of paired
hazy and clear images into two conditional distributions, which are then
modeled using a unified Brownian Bridge diffusion model to directly capture the
structural and content-related correlations between hazy and clear images. In
the second stage, we leverage the pre-trained model and large-scale unpaired
hazy and clear images to further improve the performance of image dehazing.
Additionally, we introduce a detail-enhanced Residual Difference Convolution
block (RDC) to capture gradient-level information, significantly enhancing the
model's representation capability. Extensive experiments demonstrate that our
EM-B3DM achieves superior or at least comparable performance to
state-of-the-art methods on both synthetic and real-world datasets.

</details>


### [34] [VFM-Guided Semi-Supervised Detection Transformer for Source-Free Object Detection in Remote Sensing Images](https://arxiv.org/abs/2508.11167)
*Jianhong Han,Yupei Wang,Liang Chen*

Main category: cs.CV

TL;DR: 提出了一种名为VG-DETR的方法，在无源域数据的情况下通过利用Vision Foundation Model (VFM)和少量目标域标记数据，改善伪标签质量并加强特征抽取能力，最终提升目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统的无监督领域自适应方法在隐私限制和数据传输受限的情况下缺乏实用性，尤其是在遥感图像分析中，需要针对无源域数据的环境提出一种适用的方法。

Method: 提出了VG-DETR，将Vision Foundation Model (VFM)整合进训练流程，结合VFM引导的伪标签挖掘策略和双层级VFM对齐方法，通过对伪标签质量的校正及特征表示的增强，来提升性能。

Result: 实验结果表明，VG-DETR在无源域遥感目标检测任务中表现出显著的性能改进。

Conclusion: VG-DETR证明了引入VFM和半监督策略可以有效缓解伪标签噪声问题，并在跨域遥感目标检测中提供了一种高效的解决方案。

Abstract: Unsupervised domain adaptation methods have been widely explored to bridge
domain gaps. However, in real-world remote-sensing scenarios, privacy and
transmission constraints often preclude access to source domain data, which
limits their practical applicability. Recently, Source-Free Object Detection
(SFOD) has emerged as a promising alternative, aiming at cross-domain
adaptation without relying on source data, primarily through a self-training
paradigm. Despite its potential, SFOD frequently suffers from training collapse
caused by noisy pseudo-labels, especially in remote sensing imagery with dense
objects and complex backgrounds. Considering that limited target domain
annotations are often feasible in practice, we propose a Vision
foundation-Guided DEtection TRansformer (VG-DETR), built upon a semi-supervised
framework for SFOD in remote sensing images. VG-DETR integrates a Vision
Foundation Model (VFM) into the training pipeline in a "free lunch" manner,
leveraging a small amount of labeled target data to mitigate pseudo-label noise
while improving the detector's feature-extraction capability. Specifically, we
introduce a VFM-guided pseudo-label mining strategy that leverages the VFM's
semantic priors to further assess the reliability of the generated
pseudo-labels. By recovering potentially correct predictions from
low-confidence outputs, our strategy improves pseudo-label quality and
quantity. In addition, a dual-level VFM-guided alignment method is proposed,
which aligns detector features with VFM embeddings at both the instance and
image levels. Through contrastive learning among fine-grained prototypes and
similarity matching between feature maps, this dual-level alignment further
enhances the robustness of feature representations against domain gaps.
Extensive experiments demonstrate that VG-DETR achieves superior performance in
source-free remote sensing detection tasks.

</details>


### [35] [Exploring the Tradeoff Between Diversity and Discrimination for Continuous Category Discovery](https://arxiv.org/abs/2508.11173)
*Ruobing Jiang,Yang Liu,Haobing Liu,Yanwei Yu,Chunyang Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为IDOD的方法，解决了连续类别发现中分类与新类别发现的矛盾，同时减少了错误累积和遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 目前的大多数连续类别发现方法无法有效兼顾新类别发现和分类任务，并且容易在逐步发现新类别的过程中累积错误。此外，现有方法通常依赖知识蒸馏和数据重放来防止遗忘，占用了较大的存储空间。

Method: 提出了一个名为IDOD的框架，包括独立完善的多样性模块、联合发现新颖性模块和通过正交性连续增量模块，用以减轻分类与新类别发现的冲突，减少错误，并通过代表性重放降低存储需求。

Result: 在具有挑战性的细粒度数据集上的实验结果表明，IDOD方法的性能优于目前的最先进方法。

Conclusion: IDOD方法成功解决了连续类别发现中的关键挑战，显著提升了精度，同时降低了存储需求，是解决此问题的有效方法。

Abstract: Continuous category discovery (CCD) aims to automatically discover novel
categories in continuously arriving unlabeled data. This is a challenging
problem considering that there is no number of categories and labels in the
newly arrived data, while also needing to mitigate catastrophic forgetting.
Most CCD methods cannot handle the contradiction between novel class discovery
and classification well. They are also prone to accumulate errors in the
process of gradually discovering novel classes. Moreover, most of them use
knowledge distillation and data replay to prevent forgetting, occupying more
storage space. To address these limitations, we propose Independence-based
Diversity and Orthogonality-based Discrimination (IDOD). IDOD mainly includes
independent enrichment of diversity module, joint discovery of novelty module,
and continuous increment by orthogonality module. In independent enrichment,
the backbone is trained separately using contrastive loss to avoid it focusing
only on features for classification. Joint discovery transforms multi-stage
novel class discovery into single-stage, reducing error accumulation impact.
Continuous increment by orthogonality module generates mutually orthogonal
prototypes for classification and prevents forgetting with lower space overhead
via representative representation replay. Experimental results show that on
challenging fine-grained datasets, our method outperforms the state-of-the-art
methods.

</details>


### [36] [Fine-Grained VLM Fine-tuning via Latent Hierarchical Adapter Learning](https://arxiv.org/abs/2508.11176)
*Yumiao Zhao,Bo Jiang,Yuhe Ding,Xiao Wang,Jin Tang,Bin Luo*

Main category: cs.CV

TL;DR: 本文提出了一种名为LatHAdapter的新型适配器，用于在预训练视觉语言模型（VLMs）进行少样本分类任务的微调。LatHAdapter通过hyperbolic space来建模分类与图像之间的语义层次，从而提升模型的适应与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的适配器方法在对视觉和文本表示进行对齐时，未能有效捕捉类别与图像样本之间的一对多关系，且在未知类别和图像之间的关联建立上存在不足。

Method: 本文提出LatHAdapter，通过引入可学习的‘属性’提示作为桥梁，并利用双曲空间（hyperbolic space）投影类别、属性提示和图像样本，同时使用分层正则化学习语义层次。

Result: 在四个挑战性的少样本任务中，LatHAdapter在已知类别的适配与未知类别的泛化上，均显著优于其他微调方法。

Conclusion: LatHAdapter通过挖掘下游训练数据的语义层次，并将其整合到适配器学习过程，解决了适配器方法中对类别和图像关联建模不足的问题，为少样本分类任务中的预训练模型微调提供了新的方向。

Abstract: Adapter-based approaches have garnered attention for fine-tuning pre-trained
Vision-Language Models (VLMs) on few-shot classification tasks. These methods
strive to develop a lightweight module that better aligns visual and (category)
textual representations, thereby enhancing performance on downstream few-shot
learning tasks. However, existing adapters generally learn/align (category)
textual-visual modalities via explicit spatial proximity in the underlying
embedding space, which i) fails to capture the inherent one-to-many
associations between categories and image samples and ii) struggles to
establish accurate associations between the unknown categories and images. To
address these issues, inspired by recent works on hyperbolic learning, we
develop a novel Latent Hierarchical Adapter (LatHAdapter) for fine-tuning VLMs
on downstream few-shot classification tasks. The core of LatHAdapter is to
exploit the latent semantic hierarchy of downstream training data and employ it
to provide richer, fine-grained guidance for the adapter learning process.
Specifically, LatHAdapter first introduces some learnable `attribute' prompts
as the bridge to align categories and images. Then, it projects the categories,
attribute prompts, and images within each batch in a hyperbolic space, and
employs hierarchical regularization to learn the latent semantic hierarchy of
them, thereby fully modeling the inherent one-to-many associations among
categories, learnable attributes, and image samples. Extensive experiments on
four challenging few-shot tasks show that the proposed LatHAdapter consistently
outperforms many other fine-tuning approaches, particularly in adapting known
classes and generalizing to unknown classes.

</details>


### [37] [Generalized Decoupled Learning for Enhancing Open-Vocabulary Dense Perception](https://arxiv.org/abs/2508.11256)
*Junjie Wang,Keyu Chen,Yulin Li,Bin Chen,Hengshuang Zhao,Xiaojuan Qi,Zhuotao Tian*

Main category: cs.CV

TL;DR: DeCLIP通过增强CLIP的局部特性，提升其在开放词汇密集感知任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前密集视觉感知任务依赖于预定义类别，难以适应现实中无限制的视觉概念；而现有VLMs在这类任务中表现受限。

Method: 提出DeCLIP，分离CLIP的自注意力模块，分别获取“内容”和“上下文”特征，通过语义关联和目标完整性提升空间一致性，同时对“内容”特征进行区域语义对齐以提升局部区分能力。

Result: DeCLIP在多个任务上取得了SOTA表现，如2D检测和分割、3D实例分割等。

Conclusion: DeCLIP为开放词汇密集感知提供了一个强大的基础，扩展了CLIP在实际中的应用边界。

Abstract: Dense visual perception tasks have been constrained by their reliance on
predefined categories, limiting their applicability in real-world scenarios
where visual concepts are unbounded. While Vision-Language Models (VLMs) like
CLIP have shown promise in open-vocabulary tasks, their direct application to
dense perception often leads to suboptimal performance due to limitations in
local feature representation. In this work, we present our observation that
CLIP's image tokens struggle to effectively aggregate information from
spatially or semantically related regions, resulting in features that lack
local discriminability and spatial consistency. To address this issue, we
propose DeCLIP, a novel framework that enhances CLIP by decoupling the
self-attention module to obtain ``content'' and ``context'' features
respectively. \revise{The context features are enhanced by jointly distilling
semantic correlations from Vision Foundation Models (VFMs) and object integrity
cues from diffusion models, thereby enhancing spatial consistency. In parallel,
the content features are aligned with image crop representations and
constrained by region correlations from VFMs to improve local discriminability.
Extensive experiments demonstrate that DeCLIP establishes a solid foundation
for open-vocabulary dense perception, consistently achieving state-of-the-art
performance across a broad spectrum of tasks, including 2D detection and
segmentation, 3D instance segmentation, video instance segmentation, and 6D
object pose estimation.} Code is available at
https://github.com/xiaomoguhz/DeCLIP

</details>


### [38] [Versatile Video Tokenization with Generative 2D Gaussian Splatting](https://arxiv.org/abs/2508.11183)
*Zhenghao Chen,Zicong Chen,Lei Liu,Yiming Wu,Dong Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于生成性2D高斯点方法的通用视频标记器，即Gaussian Video Transformer (GVT)，通过改进空间适应性和时间通用性，实现了视频重建、动作识别和压缩的良好表现。


<details>
  <summary>Details</summary>
Motivation: 目前的视频标记方法在空间和时间的多样性和适应性方面存在局限性，特别是在如何减少低信息区域的过度编码和动态与静态内容的有效区分方面。

Method: 提出GVT，利用生成性2D高斯点及其空间-时间嵌入机制，将视频内容表示为一组2D高斯。通过高斯集划分，明确区分静态和动态内容，从而提高模型通用性和表示能力。

Result: GVT在多项任务中表现出色：其视频重建质量达到SOTA水平，在动作识别任务中超越MAGVIT-v2，同时在压缩任务中表现与基线系统相当甚至更好。

Conclusion: 基于GVT的框架为视频处理提供了一种高效且灵活的标记方法，其通过改进空间和时间建模能力，显著提升了视频相关任务的表现。

Abstract: Video tokenization procedure is critical for a wide range of video processing
tasks. Most existing approaches directly transform video into fixed-grid and
patch-wise tokens, which exhibit limited versatility. Spatially, uniformly
allocating a fixed number of tokens often leads to over-encoding in
low-information regions. Temporally, reducing redundancy remains challenging
without explicitly distinguishing between static and dynamic content. In this
work, we propose the Gaussian Video Transformer (GVT), a versatile video
tokenizer built upon a generative 2D Gaussian Splatting (2DGS) strategy. We
first extract latent rigid features from a video clip and represent them with a
set of 2D Gaussians generated by our proposed Spatio-Temporal Gaussian
Embedding (STGE) mechanism in a feed-forward manner. Such generative 2D
Gaussians not only enhance spatial adaptability by assigning higher (resp.,
lower) rendering weights to regions with higher (resp., lower) information
content during rasterization, but also improve generalization by avoiding
per-video optimization.To enhance the temporal versatility, we introduce a
Gaussian Set Partitioning (GSP) strategy that separates the 2D Gaussians into
static and dynamic sets, which explicitly model static content shared across
different time-steps and dynamic content specific to each time-step, enabling a
compact representation.We primarily evaluate GVT on the video reconstruction,
while also assessing its performance on action recognition and compression
using the UCF101, Kinetics, and DAVIS datasets. Extensive experiments
demonstrate that GVT achieves a state-of-the-art video reconstruction quality,
outperforms the baseline MAGVIT-v2 in action recognition, and delivers
comparable compression performance.

</details>


### [39] [Vision-Language Models display a strong gender bias](https://arxiv.org/abs/2508.11262)
*Aiswarya Konavoor,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.CV

TL;DR: 本文研究了对比视觉语言编码器是否基于性别呈现偏好，并提出了一种评估此类性别关联的方法。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型中的性别偏见是否存在及其具体表现方式，因其可能通过图像和文本的共同表征空间对社会偏见进行编码和强化。

Method: 构建了由220张面部照片和150个陈述组成的数据集，基于性别计算每组文本和图像的余弦相似度，结合自举置信区间和标签交换模型解析性别关联。

Result: 生成了基于单句及类别的视觉语言性别偏见关联图，并提出了带有不确定性分析的偏见评估框架。

Conclusion: 该方法以定量方式揭示对比视觉语言空间中的性别关联，并能为未来研究和算法改进提供科学依据。

Abstract: Vision-language models (VLM) align images and text in a shared representation
space that is useful for retrieval and zero-shot transfer. Yet, this alignment
can encode and amplify social stereotypes in subtle ways that are not obvious
from standard accuracy metrics. In this study, we test whether the contrastive
vision-language encoder exhibits gender-linked associations when it places
embeddings of face images near embeddings of short phrases that describe
occupations and activities. We assemble a dataset of 220 face photographs split
by perceived binary gender and a set of 150 unique statements distributed
across six categories covering emotional labor, cognitive labor, domestic
labor, technical labor, professional roles, and physical labor. We compute
unit-norm image embeddings for every face and unit-norm text embeddings for
every statement, then define a statement-level association score as the
difference between the mean cosine similarity to the male set and the mean
cosine similarity to the female set, where positive values indicate stronger
association with the male set and negative values indicate stronger association
with the female set. We attach bootstrap confidence intervals by resampling
images within each gender group, aggregate by category with a separate
bootstrap over statements, and run a label-swap null model that estimates the
level of mean absolute association we would expect if no gender structure were
present. The outcome is a statement-wise and category-wise map of gender
associations in a contrastive vision-language space, accompanied by
uncertainty, simple sanity checks, and a robust gender bias evaluation
framework.

</details>


### [40] [CHARM3R: Towards Unseen Camera Height Robust Monocular 3D Detector](https://arxiv.org/abs/2508.11185)
*Abhinav Kumar,Yuliang Guo,Zhihao Zhang,Xinyu Huang,Liu Ren,Xiaoming Liu*

Main category: cs.CV

TL;DR: 本文通过分析Mono3D模型在不同相机高度下的性能表现，提出了一种名为CHARM3R的单目3D检测器，能够有效提高对未见相机高度的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 目前单目3D检测器在未见或分布外的相机高度数据中表现较差，本文旨在探索并解决这一问题。

Method: 本文分析了深度估计在相机高度变化对性能的影响，并提出一种结合两种深度估计的检测方法CHARM3R。

Result: CHARM3R在CARLA数据集上对未见相机高度的泛化能力提升超过45%，并达到SOTA性能。

Conclusion: 通过平均深度估计的方式，CHARM3R能有效解决相机高度变化带来的性能下降问题，增强模型的鲁棒性。

Abstract: Monocular 3D object detectors, while effective on data from one ego camera
height, struggle with unseen or out-of-distribution camera heights. Existing
methods often rely on Plucker embeddings, image transformations or data
augmentation. This paper takes a step towards this understudied problem by
first investigating the impact of camera height variations on state-of-the-art
(SoTA) Mono3D models. With a systematic analysis on the extended CARLA dataset
with multiple camera heights, we observe that depth estimation is a primary
factor influencing performance under height variations. We mathematically prove
and also empirically observe consistent negative and positive trends in mean
depth error of regressed and ground-based depth models, respectively, under
camera height changes. To mitigate this, we propose Camera Height Robust
Monocular 3D Detector (CHARM3R), which averages both depth estimates within the
model. CHARM3R improves generalization to unseen camera heights by more than
$45\%$, achieving SoTA performance on the CARLA dataset. Codes and Models at
https://github.com/abhi1kumar/CHARM3R

</details>


### [41] [Enhancing Supervised Composed Image Retrieval via Reasoning-Augmented Representation Engineering](https://arxiv.org/abs/2508.11272)
*Jun Li,Kai Li,Shaoguo Liu,Tingting Gao*

Main category: cs.CV

TL;DR: 该研究提出了一种新的框架（PMTFR），通过Pyramid Patcher模块改善了视觉信息理解，从而在无需训练的优化范式下提高了CIR任务性能。


<details>
  <summary>Details</summary>
Motivation: 旨在应对CIR（组合图像检索）任务中对参考图像和文本修改指令的联合理解挑战，解决现有方法中需要额外训练模型且效率不高的问题。

Method: 提出了Pyramid Matching Model with Training-Free Refinement (PMTFR)框架，通过Pyramid Patcher模块增强模型对不同粒度视觉信息的理解，并通过表示工程将COT数据表示注入LVLMs，实现无需显式文本推理的评分优化。

Result: 在多个CIR基准测试中，PMTFR框架在监督CIR任务中超越了现有最先进的方法，表现出显著性能提升。

Conclusion: PMTFR框架在无需额外训练的优化范式下，通过增强模型的视觉和表征能力，有效解决了CIR任务中的挑战，将推动相关领域的发展。

Abstract: Composed Image Retrieval (CIR) presents a significant challenge as it
requires jointly understanding a reference image and a modified textual
instruction to find relevant target images. Some existing methods attempt to
use a two-stage approach to further refine retrieval results. However, this
often requires additional training of a ranking model. Despite the success of
Chain-of-Thought (CoT) techniques in reducing training costs for language
models, their application in CIR tasks remains limited -- compressing visual
information into text or relying on elaborate prompt designs. Besides, existing
works only utilize it for zero-shot CIR, as it is challenging to achieve
satisfactory results in supervised CIR with a well-trained model. In this work,
we proposed a framework that includes the Pyramid Matching Model with
Training-Free Refinement (PMTFR) to address these challenges. Through a simple
but effective module called Pyramid Patcher, we enhanced the Pyramid Matching
Model's understanding of visual information at different granularities.
Inspired by representation engineering, we extracted representations from COT
data and injected them into the LVLMs. This approach allowed us to obtain
refined retrieval scores in the Training-Free Refinement paradigm without
relying on explicit textual reasoning, further enhancing performance. Extensive
experiments on CIR benchmarks demonstrate that PMTFR surpasses state-of-the-art
methods in supervised CIR tasks. The code will be made public.

</details>


### [42] [Generating Dialogues from Egocentric Instructional Videos for Task Assistance: Dataset, Method and Benchmark](https://arxiv.org/abs/2508.11192)
*Lavisha Aggarwal,Vikas Bahirwani,Lin Li,Andrea Colaco*

Main category: cs.CV

TL;DR: 本文提出了一种方法，通过自动化方式将单人教学视频转化为与逐步细化步骤和视频片段对齐的双人对话，并构建了一个名为HowToDIV的大规模对话视频数据集，适用于复杂多步骤任务的对话研究。


<details>
  <summary>Details</summary>
Motivation: 日常任务往往需要专家知识，但是缺乏面向实际任务辅助手段的对话视频数据集。本研究希望通过一种高效的方法提供对复杂任务的对话支持。

Method: 利用大型语言模型，自动将单人任务指导视频转化为双人对话，以模拟专家与学习者的互动，生成对话数据集HowToDIV，包括多轮对话和与任务步骤对齐的视频片段。

Result: 构建了HowToDIV数据集，包含507对话、6636个问答对以及24小时的视频片段，覆盖厨艺、机械与种植等多种任务范畴。此外，使用Gemma-3模型在该数据集上建立了基准性能表现。

Conclusion: 本研究为实际任务辅助手段的对话视频数据集创建提供了一种高效的替代方案，并推动了在程序性任务对话辅助领域的研究进展。

Abstract: Many everyday tasks ranging from fixing appliances, cooking recipes to car
maintenance require expert knowledge, especially when tasks are complex and
multi-step. Despite growing interest in AI agents, there is a scarcity of
dialogue-video datasets grounded for real world task assistance. In this paper,
we propose a simple yet effective approach that transforms single-person
instructional videos into task-guidance two-person dialogues, aligned with fine
grained steps and video-clips. Our fully automatic approach, powered by large
language models, offers an efficient alternative to the substantial cost and
effort required for human-assisted data collection. Using this technique, we
build HowToDIV, a large-scale dataset containing 507 conversations, 6636
question-answer pairs and 24 hours of videoclips across diverse tasks in
cooking, mechanics, and planting. Each session includes multi-turn conversation
where an expert teaches a novice user how to perform a task step by step, while
observing user's surrounding through a camera and microphone equipped wearable
device. We establish the baseline benchmark performance on HowToDIV dataset
through Gemma-3 model for future research on this new task of dialogues for
procedural-task assistance.

</details>


### [43] [UAV-VL-R1: Generalizing Vision-Language Models via Supervised Fine-Tuning and Multi-Stage GRPO for UAV Visual Reasoning](https://arxiv.org/abs/2508.11196)
*Jiajin Guan,Haibo Mei,Bonan Zhang,Dan Liu,Yuanshuang Fu,Yue Zhang*

Main category: cs.CV

TL;DR: 文章提出了一种轻量级视觉语言模型UAV-VL-R1，用于无人机领域的高分辨率图像视觉推理。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在无人机数据上表现欠佳，受限于其高分辨率、复杂时空语义及实时性需求，需开发适配性更强的模型。

Method: 通过结合监督微调和基于GRPO算法的多阶段强化学习训练UAV-VL-R1，同时引入HRVQA-VL数据集促进模型训练。

Result: 模型在多个任务上超越Qwen2-VL-2B-Instruct基线，零样本准确率提升48.17%，甚至优于其36倍规模的变体模型，同时模型部署存储需求较低。

Conclusion: UAV-VL-R1在推理灵活性、语义对齐性和资源约束下的应用潜能表现优异，适合无人机实时推理任务。

Abstract: Recent advances in vision-language models (VLMs) have demonstrated strong
generalization in natural image tasks. However, their performance often
degrades on unmanned aerial vehicle (UAV)-based aerial imagery, which features
high resolution, complex spatial semantics, and strict real-time constraints.
These challenges limit the applicability of general-purpose VLMs to structured
aerial reasoning tasks. To address these challenges, we propose UAV-VL-R1, a
lightweight VLM explicitly designed for aerial visual reasoning. It is trained
using a hybrid method that combines supervised fine-tuning (SFT) and
multi-stage reinforcement learning (RL). We leverage the group relative policy
optimization (GRPO) algorithm to promote structured and interpretable reasoning
through rule-guided rewards and intra-group policy alignment. To support model
training and evaluation, we introduce a high-resolution visual question
answering dataset named HRVQA-VL, which consists of 50,019 annotated samples
covering eight UAV-relevant reasoning tasks, including object counting,
transportation recognition, and spatial scene inference. Experimental results
show that UAV-VL-R1 achieves a 48.17% higher zero-shot accuracy than the
Qwen2-VL-2B-Instruct baseline and even outperforms its 72B-scale variant, which
is 36x larger, on multiple tasks. Ablation studies reveal that while SFT
improves semantic alignment, it may reduce reasoning diversity in mathematical
tasks. GRPO-based RL compensates for this limitation by enhancing logical
flexibility and the robustness of inference. Additionally, UAV-VL-R1 requires
only 3.9GB of memory under FP16 inference and can be quantized to 2.5GB with
INT8, supporting real-time deployment on resource-constrained UAV platforms.

</details>


### [44] [A Coarse-to-Fine Human Pose Estimation Method based on Two-stage Distillation and Progressive Graph Neural Network](https://arxiv.org/abs/2508.11212)
*Zhangjian Ji,Wenjin Zhang,Shaotong Qiao,Kai Feng,Yuhua Qian*

Main category: cs.CV

TL;DR: 本文介绍了一种新颖的两阶段知识蒸馏框架，用于轻量级且高效的人体姿态估计并在复杂数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有最佳的人体姿态估计方法需要大量计算资源，而本文旨在通过知识蒸馏，以实现准确、鲁棒但轻量化的人体姿态估计。

Method: 提出了一个粗到细的两阶段知识蒸馏框架：第一阶段引入关节结构损失以传递语义知识；第二阶段通过图卷积网络（IGP-GCN）进一步优化姿态估计。

Result: 在COCO和CrowdPose数据集上的实验表明，该方法在性能上优于许多现有方法，特别是在更复杂的CrowdPose数据集上提升显著。

Conclusion: 提出的两阶段框架能有效在减少参数的同时提高姿态估计精度，表现出优异的性能，具有广泛的应用前景。

Abstract: Human pose estimation has been widely applied in the human-centric
understanding and generation, but most existing state-of-the-art human pose
estimation methods require heavy computational resources for accurate
predictions. In order to obtain an accurate, robust yet lightweight human pose
estimator, one feasible way is to transfer pose knowledge from a powerful
teacher model to a less-parameterized student model by knowledge distillation.
However, the traditional knowledge distillation framework does not fully
explore the contextual information among human joints. Thus, in this paper, we
propose a novel coarse-to-fine two-stage knowledge distillation framework for
human pose estimation. In the first-stage distillation, we introduce the human
joints structure loss to mine the structural information among human joints so
as to transfer high-level semantic knowledge from the teacher model to the
student model. In the second-stage distillation, we utilize an Image-Guided
Progressive Graph Convolutional Network (IGP-GCN) to refine the initial human
pose obtained from the first-stage distillation and supervise the training of
the IGP-GCN in the progressive way by the final output pose of teacher model.
The extensive experiments on the benchmark dataset: COCO keypoint and CrowdPose
datasets, show that our proposed method performs favorably against lots of the
existing state-of-the-art human pose estimation methods, especially for the
more complex CrowdPose dataset, the performance improvement of our model is
more significant.

</details>


### [45] [A CLIP-based Uncertainty Modal Modeling (UMM) Framework for Pedestrian Re-Identification in Autonomous Driving](https://arxiv.org/abs/2508.11218)
*Jialin Li,Shuqi Wu,Ning Wang*

Main category: cs.CV

TL;DR: 提出轻量级的UMM框架，通过综合多模态映射器、合成模态增强策略和跨模态交互学习，解决自主驾驶ReID中的模态不确定性挑战，表现出强鲁棒性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决自主驾驶中的行人再识别问题，特别是面对RGB、红外等输入模态不确定性带来的挑战。

Method: 提出UMM框架，包含多模态token映射器、模态增强策略和跨模态交互学习，结合CLIP模型的视觉语言对齐能力，提升多模态数据处理能力。

Result: 实验表明UMM框架在模态不确定性环境下表现出强鲁棒性、泛化性和计算效率。

Conclusion: UMM是一个可扩展、实用的解决方案，适用于资源受限的自主驾驶场景中的行人再识别问题。

Abstract: Re-Identification (ReID) is a critical technology in intelligent perception
systems, especially within autonomous driving, where onboard cameras must
identify pedestrians across views and time in real-time to support safe
navigation and trajectory prediction. However, the presence of uncertain or
missing input modalities--such as RGB, infrared, sketches, or textual
descriptions--poses significant challenges to conventional ReID approaches.
While large-scale pre-trained models offer strong multimodal semantic modeling
capabilities, their computational overhead limits practical deployment in
resource-constrained environments. To address these challenges, we propose a
lightweight Uncertainty Modal Modeling (UMM) framework, which integrates a
multimodal token mapper, synthetic modality augmentation strategy, and
cross-modal cue interactive learner. Together, these components enable unified
feature representation, mitigate the impact of missing modalities, and extract
complementary information across different data types. Additionally, UMM
leverages CLIP's vision-language alignment ability to fuse multimodal inputs
efficiently without extensive finetuning. Experimental results demonstrate that
UMM achieves strong robustness, generalization, and computational efficiency
under uncertain modality conditions, offering a scalable and practical solution
for pedestrian re-identification in autonomous driving scenarios.

</details>


### [46] [FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation](https://arxiv.org/abs/2508.11255)
*MengChao Wang,Qiang Wang,Fan Jiang,Mu Xu*

Main category: cs.CV

TL;DR: 本文提出了一种新方法来优化基于音频驱动的肖像动画，解决了现有方法在多维偏好对齐上的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的音频驱动肖像动画方法无法在如运动自然度、口型同步和视觉质量等多维偏好上实现良好对齐，这部分是由于目标间的冲突性以及缺乏高质量、多维度偏好数据集。

Method: 作者引入了Talking-Critic，一个多模态奖励模型，用于学习人类对视频表现的多维奖励函数；同时提出了TLPO框架，通过逐时间步和网络层对专家模块偏好进行解耦和融合，从而协调整个动画模型的优化。

Result: 实验表明，Talking-Critic在与人类偏好对齐上远超现有方法，同时TLPO显著提升了模型在口型同步、运动自然度及视觉质量上的表现。

Conclusion: 本文提出的方法可实现肖像动画领域在多维偏好上的精细对齐，实验验证了其在主观与客观评估中的优越性。

Abstract: Recent advances in audio-driven portrait animation have demonstrated
impressive capabilities. However, existing methods struggle to align with
fine-grained human preferences across multiple dimensions, such as motion
naturalness, lip-sync accuracy, and visual quality. This is due to the
difficulty of optimizing among competing preference objectives, which often
conflict with one another, and the scarcity of large-scale, high-quality
datasets with multidimensional preference annotations. To address these, we
first introduce Talking-Critic, a multimodal reward model that learns
human-aligned reward functions to quantify how well generated videos satisfy
multidimensional expectations. Leveraging this model, we curate Talking-NSQ, a
large-scale multidimensional human preference dataset containing 410K
preference pairs. Finally, we propose Timestep-Layer adaptive multi-expert
Preference Optimization (TLPO), a novel framework for aligning diffusion-based
portrait animation models with fine-grained, multidimensional preferences. TLPO
decouples preferences into specialized expert modules, which are then fused
across timesteps and network layers, enabling comprehensive, fine-grained
enhancement across all dimensions without mutual interference. Experiments
demonstrate that Talking-Critic significantly outperforms existing methods in
aligning with human preference ratings. Meanwhile, TLPO achieves substantial
improvements over baseline models in lip-sync accuracy, motion naturalness, and
visual quality, exhibiting superior performance in both qualitative and
quantitative evaluations. Ours project page:
https://fantasy-amap.github.io/fantasy-talking2/

</details>


### [47] [Leveraging the RETFound foundation model for optic disc segmentation in retinal images](https://arxiv.org/abs/2508.11354)
*Zhenyi Zhao,Muthu Rama Krishnan Mookiah,Emanuele Trucco*

Main category: cs.CV

TL;DR: RETFound 模型首次被适配用于视盘分割任务，并在多个数据集上展示了超越最先进基线模型的性能，代码将于论文接受后公布。


<details>
  <summary>Details</summary>
Motivation: 探索 RETFound 模型在诊断疾病之外的新应用领域，将其适配于视盘分割任务，并验证其在内部验证、领域泛化和领域适配中的性能表现。

Method: 采用 RETFound 模型作为基础，针对视盘分割任务训练了特定头部，并通过少量任务特定样本在五个公开及私有数据集上评估其性能。

Result: 在 IDRID、Drishti-GS、RIM-ONE-r3、REFUGE 和 GoDARTS 数据集上，模型在 Dice 分数指标上稳定达到 96%，超越了大多数现有的最先进基线系统。

Conclusion: 经过适配的 RETFound 模型不仅性能优秀，还为未来基础模型是否可以替代任务特定架构提供了有价值的讨论方向。

Abstract: RETFound is a well-known foundation model (FM) developed for fundus camera
and optical coherence tomography images. It has shown promising performance
across multiple datasets in diagnosing diseases, both eye-specific and
systemic, from retinal images. However, to our best knowledge, it has not been
used for other tasks. We present the first adaptation of RETFound for optic
disc segmentation, a ubiquitous and foundational task in retinal image
analysis. The resulting segmentation system outperforms state-of-the-art,
segmentation-specific baseline networks after training a head with only a very
modest number of task-specific examples. We report and discuss results with
four public datasets, IDRID, Drishti-GS, RIM-ONE-r3, and REFUGE, and a private
dataset, GoDARTS, achieving about 96% Dice consistently across all datasets.
Overall, our method obtains excellent performance in internal verification,
domain generalization and domain adaptation, and exceeds most of the
state-of-the-art baseline results. We discuss the results in the framework of
the debate about FMs as alternatives to task-specific architectures. The code
is available at: [link to be added after the paper is accepted]

</details>


### [48] [Domain-aware Category-level Geometry Learning Segmentation for 3D Point Clouds](https://arxiv.org/abs/2508.11265)
*Pei He,Lingling Li,Licheng Jiao,Ronghua Shang,Fang Liu,Shuang Wang,Xu Liu,Wenping Ma*

Main category: cs.CV

TL;DR: 提出了一种用于3D语义分割的类别级几何学习框架，应对领域泛化问题。通过类别级几何嵌入（CGE）和几何一致性学习（GCL），模型能够提取领域不变的几何特征，提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前方法未充分利用类别级几何分布和对齐，导致模型难以泛化到新域。

Method: 提出类别级几何嵌入（CGE）和几何一致性学习（GCL），CGE感知类别的细粒度几何特性，GCL对类别级几何嵌入进行对齐和领域分布模拟。

Result: 实验结果证明，该方法在领域泛化3D分割任务中表现非常优异，与当前最先进方法相比具有竞争力。

Conclusion: 该方法能有效捕捉领域不变的几何信息，提高模型在未见领域的3D语义分割性能。

Abstract: Domain generalization in 3D segmentation is a critical challenge in deploying
models to unseen environments. Current methods mitigate the domain shift by
augmenting the data distribution of point clouds. However, the model learns
global geometric patterns in point clouds while ignoring the category-level
distribution and alignment. In this paper, a category-level geometry learning
framework is proposed to explore the domain-invariant geometric features for
domain generalized 3D semantic segmentation. Specifically, Category-level
Geometry Embedding (CGE) is proposed to perceive the fine-grained geometric
properties of point cloud features, which constructs the geometric properties
of each class and couples geometric embedding to semantic learning. Secondly,
Geometric Consistent Learning (GCL) is proposed to simulate the latent 3D
distribution and align the category-level geometric embeddings, allowing the
model to focus on the geometric invariant information to improve
generalization. Experimental results verify the effectiveness of the proposed
method, which has very competitive segmentation accuracy compared with the
state-of-the-art domain generalized point cloud methods.

</details>


### [49] [Probing the Representational Power of Sparse Autoencoders in Vision Models](https://arxiv.org/abs/2508.11277)
*Matthew Lyle Olson,Musashi Hinck,Neale Ratzlaff,Changbai Li,Phillip Howard,Vasudev Lal,Shao-Yen Tseng*

Main category: cs.CV

TL;DR: 本文研究稀疏自编码器（SAEs）在视觉模型中的表现，证明其在视觉任务中具有语义解释性、提升分布外泛化能力、并支持可控生成。


<details>
  <summary>Details</summary>
Motivation: 尽管SAEs在语言模型中表现出色，但在视觉领域的应用和理解仍然不足，作者希望填补这一研究空白。

Method: 在不同的视觉模型架构（包括视觉嵌入模型、多模态语言-视觉模型和扩散模型）中使用SAEs进行实验，评估其在多种图像任务中的效果。

Result: SAE特征在重要的视觉任务上表现出语义意义，能够提升分布外检测性能，还可用于扩散模型的语义操控与多模态模型中揭示跨模态的共享表示。

Conclusion: 本文为SAEs在视觉领域的应用奠定了基础，展示了其在解释性、泛化能力及操控性上的强大潜力。

Abstract: Sparse Autoencoders (SAEs) have emerged as a popular tool for interpreting
the hidden states of large language models (LLMs). By learning to reconstruct
activations from a sparse bottleneck layer, SAEs discover interpretable
features from the high-dimensional internal representations of LLMs. Despite
their popularity with language models, SAEs remain understudied in the visual
domain. In this work, we provide an extensive evaluation the representational
power of SAEs for vision models using a broad range of image-based tasks. Our
experimental results demonstrate that SAE features are semantically meaningful,
improve out-of-distribution generalization, and enable controllable generation
across three vision model architectures: vision embedding models, multi-modal
LMMs and diffusion models. In vision embedding models, we find that learned SAE
features can be used for OOD detection and provide evidence that they recover
the ontological structure of the underlying model. For diffusion models, we
demonstrate that SAEs enable semantic steering through text encoder
manipulation and develop an automated pipeline for discovering
human-interpretable attributes. Finally, we conduct exploratory experiments on
multi-modal LLMs, finding evidence that SAE features reveal shared
representations across vision and language modalities. Our study provides a
foundation for SAE evaluation in vision models, highlighting their strong
potential improving interpretability, generalization, and steerability in the
visual domain.

</details>


### [50] [Does the Skeleton-Recall Loss Really Work?](https://arxiv.org/abs/2508.11374)
*Devansh Arora,Nitin Kumar,Sukrit Gupta*

Main category: cs.CV

TL;DR: 该论文分析了用于细管状结构分割的拓扑保留损失函数的效果，特别是Skeleton Recall Loss (SRL)的表现，发现其效果并未优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 研究用于分割细管状结构的专用模型及其损失函数，特别是拓扑保留损失函数的潜力和性能。

Method: 对SRL损失函数的梯度进行理论分析，并在多个管状数据集上对其性能进行比较评估，兼具理论解释与实证分析。

Result: 研究发现，基于SRL的分割模型在实验数据集上的性能未超越传统基线模型。

Conclusion: 该研究揭示了拓扑保留损失函数的局限性，为开发更高效的复杂管状结构分割模型提供了重要见解。

Abstract: Image segmentation is an important and widely performed task in computer
vision. Accomplishing effective image segmentation in diverse settings often
requires custom model architectures and loss functions. A set of models that
specialize in segmenting thin tubular structures are topology
preservation-based loss functions. These models often utilize a pixel
skeletonization process claimed to generate more precise segmentation masks of
thin tubes and better capture the structures that other models often miss. One
such model, Skeleton Recall Loss (SRL) proposed by Kirchhoff et al.~\cite
{kirchhoff2024srl}, was stated to produce state-of-the-art results on benchmark
tubular datasets. In this work, we performed a theoretical analysis of the
gradients for the SRL loss. Upon comparing the performance of the proposed
method on some of the tubular datasets (used in the original work, along with
some additional datasets), we found that the performance of SRL-based
segmentation models did not exceed traditional baseline models. By providing
both a theoretical explanation and empirical evidence, this work critically
evaluates the limitations of topology-based loss functions, offering valuable
insights for researchers aiming to develop more effective segmentation models
for complex tubular structures.

</details>


### [51] [Unifying Scale-Aware Depth Prediction and Perceptual Priors for Monocular Endoscope Pose Estimation and Tissue Reconstruction](https://arxiv.org/abs/2508.11282)
*Muzammil Khan,Enzo Kerkhof,Matteo Fusaglia,Koert Kuhlmann,Theo Ruers,Françoise J. Siepel*

Main category: cs.CV

TL;DR: 提出了一种整合了尺度感知深度预测和时间约束感知细化的单目内镜组织重建统一框架，有效提升了内窥镜位姿估计和组织表面3D重建的精度。


<details>
  <summary>Details</summary>
Motivation: 解决单目内镜位姿估计和组织3D重建过程中深度模糊、生理组织变形、不一致内镜运动等挑战。

Method: 引入MAPIS-Depth模块进行伪度量深度估计，并通过RAFT计算像素对应关系和LPIPS感知相似性调整，结合WEMA-RTDL模块优化旋转、平移，实现高精度的RGBD帧注册，最后通过体积融合和Marching Cubes生成3D表面网格。

Result: 在HEVD和SCARED数据集上，实验结果和消融分析表明，该框架在鲁棒性和性能上优于最先进的方法。

Conclusion: 所提框架有效整合了状态最前沿的深度预测与时间细化技术，在单目内镜组织重建领域表现出显著优势。

Abstract: Accurate endoscope pose estimation and 3D tissue surface reconstruction
significantly enhances monocular minimally invasive surgical procedures by
enabling accurate navigation and improved spatial awareness. However, monocular
endoscope pose estimation and tissue reconstruction face persistent challenges,
including depth ambiguity, physiological tissue deformation, inconsistent
endoscope motion, limited texture fidelity, and a restricted field of view. To
overcome these limitations, a unified framework for monocular endoscopic tissue
reconstruction that integrates scale-aware depth prediction with
temporally-constrained perceptual refinement is presented. This framework
incorporates a novel MAPIS-Depth module, which leverages Depth Pro for robust
initialisation and Depth Anything for efficient per-frame depth prediction, in
conjunction with L-BFGS-B optimisation, to generate pseudo-metric depth
estimates. These estimates are temporally refined by computing pixel
correspondences using RAFT and adaptively blending flow-warped frames based on
LPIPS perceptual similarity, thereby reducing artefacts arising from
physiological tissue deformation and motion. To ensure accurate registration of
the synthesised pseudo-RGBD frames from MAPIS-Depth, a novel WEMA-RTDL module
is integrated, optimising both rotation and translation. Finally, truncated
signed distance function-based volumetric fusion and marching cubes are applied
to extract a comprehensive 3D surface mesh. Evaluations on HEVD and SCARED,
with ablation and comparative analyses, demonstrate the framework's robustness
and superiority over state-of-the-art methods.

</details>


### [52] [G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration](https://arxiv.org/abs/2508.11379)
*Ramil Khafizov,Artem Komarichev,Ruslan Rakhimov,Peter Wonka,Evgeny Burnaev*

Main category: cs.CV

TL;DR: 本文提出了一种改进的3D场景重建方法G-CUT3R，通过整合先验信息增强了CUT3R模型的性能。


<details>
  <summary>Details</summary>
Motivation: 目前的前馈方法通常仅依赖输入图像，而忽略了现实场景中可获得的辅助信息如深度图、相机校准和位置。

Method: 通过对CUT3R进行轻量化改进，为每种数据模态设计了专用编码器并通过零卷积与RGB图像融合。

Result: 在多个基准测试中表现出显著性能提升，能够有效利用现有先验并支持不同的输入模态。

Conclusion: 所提出的方法展示了在使用额外的先验信息进行3D重建时的重要潜力，同时保证了输入模态的灵活性和广泛适应性。

Abstract: We introduce G-CUT3R, a novel feed-forward approach for guided 3D scene
reconstruction that enhances the CUT3R model by integrating prior information.
Unlike existing feed-forward methods that rely solely on input images, our
method leverages auxiliary data, such as depth, camera calibrations, or camera
positions, commonly available in real-world scenarios. We propose a lightweight
modification to CUT3R, incorporating a dedicated encoder for each modality to
extract features, which are fused with RGB image tokens via zero convolution.
This flexible design enables seamless integration of any combination of prior
information during inference. Evaluated across multiple benchmarks, including
3D reconstruction and other multi-view tasks, our approach demonstrates
significant performance improvements, showing its ability to effectively
utilize available priors while maintaining compatibility with varying input
modalities.

</details>


### [53] [TimeMachine: Fine-Grained Facial Age Editing with Identity Preservation](https://arxiv.org/abs/2508.11284)
*Yilin Mi,Qixin Yan,Zheng-Peng Duan,Chunle Guo,Hubery Yin,Hao Liu,Chen Li,Chongyi Li*

Main category: cs.CV

TL;DR: 提出了一个名为TimeMachine的新框架，通过多种创新设计实现精细的人脸年龄编辑，并同时保持身份特征不变。


<details>
  <summary>Details</summary>
Motivation: 解决当前人脸年龄编辑中难以同时实现精细化编辑与身份保持的问题。

Method: 通过引入高精度年龄信息注入多跨注意力模块和Age Classifier Guidance模块，并构建HFFA高质量数据集来增强训练性能。

Result: TimeMachine在精细化年龄编辑和身份一致性保持上取得了业界领先的效果。

Conclusion: TimeMachine证明在精细年龄编辑领域具有良好的应用潜力，并为未来研究提供了有效工具。

Abstract: With the advancement of generative models, facial image editing has made
significant progress. However, achieving fine-grained age editing while
preserving personal identity remains a challenging task.In this paper, we
propose TimeMachine, a novel diffusion-based framework that achieves accurate
age editing while keeping identity features unchanged. To enable fine-grained
age editing, we inject high-precision age information into the multi-cross
attention module, which explicitly separates age-related and identity-related
features. This design facilitates more accurate disentanglement of age
attributes, thereby allowing precise and controllable manipulation of facial
aging.Furthermore, we propose an Age Classifier Guidance (ACG) module that
predicts age directly in the latent space, instead of performing denoising
image reconstruction during training. By employing a lightweight module to
incorporate age constraints, this design enhances age editing accuracy by
modest increasing training cost. Additionally, to address the lack of
large-scale, high-quality facial age datasets, we construct a HFFA dataset
(High-quality Fine-grained Facial-Age dataset) which contains one million
high-resolution images labeled with identity and facial attributes.
Experimental results demonstrate that TimeMachine achieves state-of-the-art
performance in fine-grained age editing while preserving identity consistency.

</details>


### [54] [Hyperspectral vs. RGB for Pedestrian Segmentation in Urban Driving Scenes: A Comparative Study](https://arxiv.org/abs/2508.11301)
*Jiarong Li,Imad Ali Shah,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 该研究探讨了使用超光谱成像（HSI）在城市驾驶场景中改进行人分割的潜力，特别是评估了两种将128通道HSI数据转为三通道表示的方法（PCA和CSNR-JMIM）相较于标准RGB的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决RGB成像中的同形异色现象，提高汽车中的行人检测能力以增强安全性。

Method: 使用Hyperspectral City v2数据集，比较RGB与两种降维方法（PCA与CSNR-JMIM）的性能，并测试三种分割模型（U-Net, DeepLabV3+, SegFormer）。

Result: CSNR-JMIM在行人分割平均IoU提高1.44%，F1分数提高2.18%；骑车人分割IoU提升1.43%，F1分数提升2.25%。

Conclusion: 通过优化选择HSI波段实现显著性能改善，有潜力在汽车安全相关场景中应用。

Abstract: Pedestrian segmentation in automotive perception systems faces critical
safety challenges due to metamerism in RGB imaging, where pedestrians and
backgrounds appear visually indistinguishable.. This study investigates the
potential of hyperspectral imaging (HSI) for enhanced pedestrian segmentation
in urban driving scenarios using the Hyperspectral City v2 (H-City) dataset. We
compared standard RGB against two dimensionality-reduction approaches by
converting 128-channel HSI data into three-channel representations: Principal
Component Analysis (PCA) and optimal band selection using Contrast
Signal-to-Noise Ratio with Joint Mutual Information Maximization (CSNR-JMIM).
Three semantic segmentation models were evaluated: U-Net, DeepLabV3+, and
SegFormer. CSNR-JMIM consistently outperformed RGB with an average improvements
of 1.44% in Intersection over Union (IoU) and 2.18% in F1-score for pedestrian
segmentation. Rider segmentation showed similar gains with 1.43% IoU and 2.25%
F1-score improvements. These improved performance results from enhanced
spectral discrimination of optimally selected HSI bands effectively reducing
false positives. This study demonstrates robust pedestrian segmentation through
optimal HSI band selection, showing significant potential for safety-critical
automotive applications.

</details>


### [55] [Denoise-then-Retrieve: Text-Conditioned Video Denoising for Video Moment Retrieval](https://arxiv.org/abs/2508.11313)
*Weijia Liu,Jiuxin Cao,Bo Miao,Zhiheng Fu,Xuelin Zhu,Jiawei Ge,Bo Liu,Mehwish Nasim,Ajmal Mian*

Main category: cs.CV

TL;DR: 本文提出了一种称为"降噪-后检索"的新方法用于视频片段检索，通过去除与文本无关的片段来优化多模态对齐及检索效果，显著提升了现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的视频时刻检索方法存在优化问题，即所有的片段都会参与编码，导致无关片段的干扰，对多模态对齐及检索产生不良影响。

Method: 提出了Denoise-then-Retrieve Network (DRNet)网络, 包括文本驱动的降噪(Text-Conditioned Denoising, TCD)和文本重构反馈(Text-Reconstruction Feedback, TRF)模块，分别用来过滤噪声片段和强化文本与视频表征对齐的监督。

Result: 在Charades-STA和QVHighlights数据集上的实验表明，该方法在所有指标上均优于当前最先进的方法。

Conclusion: 降噪-后检索范式提高了视频时刻检索性能，并具有良好的适应性，可以无缝集成到其他先进模型中进一步增强效果。

Abstract: Current text-driven Video Moment Retrieval (VMR) methods encode all video
clips, including irrelevant ones, disrupting multimodal alignment and hindering
optimization. To this end, we propose a denoise-then-retrieve paradigm that
explicitly filters text-irrelevant clips from videos and then retrieves the
target moment using purified multimodal representations. Following this
paradigm, we introduce the Denoise-then-Retrieve Network (DRNet), comprising
Text-Conditioned Denoising (TCD) and Text-Reconstruction Feedback (TRF)
modules. TCD integrates cross-attention and structured state space blocks to
dynamically identify noisy clips and produce a noise mask to purify multimodal
video representations. TRF further distills a single query embedding from
purified video representations and aligns it with the text embedding, serving
as auxiliary supervision for denoising during training. Finally, we perform
conditional retrieval using text embeddings on purified video representations
for accurate VMR. Experiments on Charades-STA and QVHighlights demonstrate that
our approach surpasses state-of-the-art methods on all metrics. Furthermore,
our denoise-then-retrieve paradigm is adaptable and can be seamlessly
integrated into advanced VMR models to boost performance.

</details>


### [56] [Logic Unseen: Revealing the Logical Blindspots of Vision-Language Models](https://arxiv.org/abs/2508.11317)
*Yuchen Zhou,Jiayu Tang,Shuo Yang,Xiaoyan Xiao,Yuqin Dai,Wenhao Yang,Chao Gou,Xiaobo Xia,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本文探讨了视觉语言模型（VLM）在逻辑理解能力上的不足，并提出LogicCLIP框架，通过逻辑敏感数据生成和目标优化提升逻辑理解能力，并针对LogicBench基准测试表现出显著进步。


<details>
  <summary>Details</summary>
Motivation: VLM在多模态智能中发挥基础性作用，但在实际应用中逻辑理解能力存在显著盲点，亟需系统性诊断与改进。

Method: 提出LogicCLIP，一个通过逻辑敏感数据生成及优化目标（粗粒度对齐、细粒度选择、多逻辑结构目标）增强的训练框架。

Result: LogicCLIP在LogicBench上显著提升了逻辑理解能力，同时在通用多模态基准上表现优异，较基线模型有显著进步。

Conclusion: LogicCLIP验证了逻辑能力的增强不会影响一般性能，为提升VLM逻辑能力提供关键资源并促进行业发展。

Abstract: Vision-Language Models (VLMs), exemplified by CLIP, have emerged as
foundational for multimodal intelligence. However, their capacity for logical
understanding remains significantly underexplored, resulting in critical
''logical blindspots'' that limit their reliability in practical applications.
To systematically diagnose this, we introduce LogicBench, a comprehensive
benchmark with over 50,000 vision-language pairs across 9 logical categories
and 4 diverse scenarios: images, videos, anomaly detection, and medical
diagnostics. Our evaluation reveals that existing VLMs, even the
state-of-the-art ones, fall at over 40 accuracy points below human performance,
particularly in challenging tasks like Causality and Conditionality,
highlighting their reliance on surface semantics over critical logical
structures. To bridge this gap, we propose LogicCLIP, a novel training
framework designed to boost VLMs' logical sensitivity through advancements in
both data generation and optimization objectives. LogicCLIP utilizes
logic-aware data generation and a contrastive learning strategy that combines
coarse-grained alignment, a fine-grained multiple-choice objective, and a novel
logical structure-aware objective. Extensive experiments demonstrate
LogicCLIP's substantial improvements in logical comprehension across all
LogicBench domains, significantly outperforming baselines. Moreover, LogicCLIP
retains, and often surpasses, competitive performance on general
vision-language benchmarks, demonstrating that the enhanced logical
understanding does not come at the expense of general alignment. We believe
that LogicBench and LogicCLIP will be important resources for advancing VLM
logical capabilities.

</details>


### [57] [Delving into Dynamic Scene Cue-Consistency for Robust 3D Multi-Object Tracking](https://arxiv.org/abs/2508.11323)
*Haonan Zhang,Xinyao Wang,Boxi Wu,Tu Zheng,Wang Yunhua,Zheng Yang*

Main category: cs.CV

TL;DR: 本文介绍了一种用于3D多目标跟踪的新方法——动态场景一致性跟踪器（DSC-Track），通过时间上的轨迹一致性来提高跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有的方法中，即使已存在几何感知方法，也容易受到无关对象的干扰，从而导致特征模糊和错误匹配。因此需要一种能够利用几何关系并抑制干扰的稳健方法。

Method: 设计了一个空间时间编码器以学习区分性轨迹嵌入，并通过一致性变换模块结合历史轨迹与当前检测数据。此外，提出了一种动态更新机制以保留显著的时空信息，辅以点对特征（PPF）实现几何一致性。

Result: 在nuScenes与Waymo Open Datasets上的实验表明该方法具有效性与鲁棒性，其中nuScenes验证集和测试集上的AMOTA分别达到了73.2%与70.3%。

Conclusion: DSC-Track基于轨迹一致性实现了稳定在线跟踪，尤其是在多目标密集环境中表现出色，突破了传统方法的局限性。

Abstract: 3D multi-object tracking is a critical and challenging task in the field of
autonomous driving. A common paradigm relies on modeling individual object
motion, e.g., Kalman filters, to predict trajectories. While effective in
simple scenarios, this approach often struggles in crowded environments or with
inaccurate detections, as it overlooks the rich geometric relationships between
objects. This highlights the need to leverage spatial cues. However, existing
geometry-aware methods can be susceptible to interference from irrelevant
objects, leading to ambiguous features and incorrect associations. To address
this, we propose focusing on cue-consistency: identifying and matching stable
spatial patterns over time. We introduce the Dynamic Scene Cue-Consistency
Tracker (DSC-Track) to implement this principle. Firstly, we design a unified
spatiotemporal encoder using Point Pair Features (PPF) to learn discriminative
trajectory embeddings while suppressing interference. Secondly, our
cue-consistency transformer module explicitly aligns consistent feature
representations between historical tracks and current detections. Finally, a
dynamic update mechanism preserves salient spatiotemporal information for
stable online tracking. Extensive experiments on the nuScenes and Waymo Open
Datasets validate the effectiveness and robustness of our approach. On the
nuScenes benchmark, for instance, our method achieves state-of-the-art
performance, reaching 73.2% and 70.3% AMOTA on the validation and test sets,
respectively.

</details>


### [58] [Inside Knowledge: Graph-based Path Generation with Explainable Data Augmentation and Curriculum Learning for Visual Indoor Navigation](https://arxiv.org/abs/2508.11446)
*Daniel Airinei,Elena Burceanu,Marius Leordeanu*

Main category: cs.CV

TL;DR: 提出基于视觉输入的实时深度学习室内导航方法，解决传统方法复杂性与需求过高问题。


<details>
  <summary>Details</summary>
Motivation: 室内导航因GPS信号差需用其他信息源，当前解决方案复杂且要求多，难以实际应用，需要更高效、简便的替代方案。

Method: 引入基于视觉输入的深度学习方法，结合图结构路径生成、可解释性数据增强、课程学习等技术，实现高效的自动数据收集、标注与训练。

Result: 提出的模型可根据移动设备拍摄的图像预测目标方向，免去特殊传感器、路径标记、场景地图或网络接入的需求。此外，构建了一个大型购物中心视频数据集，并开发了一款安卓应用。

Conclusion: 新方案高效、可部署且仅需视觉输入操作，随附数据集、代码与演示计划公开，适用于实际应用。

Abstract: Indoor navigation is a difficult task, as it generally comes with poor GPS
access, forcing solutions to rely on other sources of information. While
significant progress continues to be made in this area, deployment to
production applications is still lacking, given the complexity and additional
requirements of current solutions. Here, we introduce an efficient, real-time
and easily deployable deep learning approach, based on visual input only, that
can predict the direction towards a target from images captured by a mobile
device. Our technical approach, based on a novel graph-based path generation
method, combined with explainable data augmentation and curriculum learning,
includes contributions that make the process of data collection, annotation and
training, as automatic as possible, efficient and robust. On the practical
side, we introduce a novel largescale dataset, with video footage inside a
relatively large shopping mall, in which each frame is annotated with the
correct next direction towards different specific target destinations.
Different from current methods, ours relies solely on vision, avoiding the need
of special sensors, additional markers placed along the path, knowledge of the
scene map or internet access. We also created an easy to use application for
Android, which we plan to make publicly available. We make all our data and
code available along with visual demos on our project site

</details>


### [59] [Controlling Multimodal LLMs via Reward-guided Decoding](https://arxiv.org/abs/2508.11616)
*Oscar Mañas,Pierluca D'Oro,Koustuv Sinha,Adriana Romero-Soriano,Michal Drozdzal,Aishwarya Agrawal*

Main category: cs.CV

TL;DR: 提出了一种通过受控解码来适配多模态大语言模型（MLLMs)的新方法，该方法通过构建视觉指向奖励模型，改进了模型的视觉语义能力。


<details>
  <summary>Details</summary>
Motivation: 随着MLLMs的广泛应用，如何满足多样化用户需求成为关键，本研究旨在通过受控解码实现适配性。

Method: 构建视觉指向的奖励模型，独立控制对象精准度和召回率，通过解码过程中动态调整权重实现受控解码。

Result: 实验表明，方法在标准对象幻觉基准测试中显著提高了可控性，并优于现有的幻觉缓解方法。

Conclusion: 该方法为模型推理过程提供了动态对视觉指向性和计算复杂度的控制能力，提升了可用性与性能平衡。

Abstract: As Multimodal Large Language Models (MLLMs) gain widespread applicability, it
is becoming increasingly desirable to adapt them for diverse user needs. In
this paper, we study the adaptation of MLLMs through controlled decoding. To
achieve this, we introduce the first method for reward-guided decoding of MLLMs
and demonstrate its application in improving their visual grounding. Our method
involves building reward models for visual grounding and using them to guide
the MLLM's decoding process. Concretely, we build two separate reward models to
independently control the degree of object precision and recall in the model's
output. Our approach enables on-the-fly controllability of an MLLM's inference
process in two ways: first, by giving control over the relative importance of
each reward function during decoding, allowing a user to dynamically trade off
object precision for recall in image captioning tasks; second, by giving
control over the breadth of the search during decoding, allowing the user to
control the trade-off between the amount of test-time compute and the degree of
visual grounding. We evaluate our method on standard object hallucination
benchmarks, showing that it provides significant controllability over MLLM
inference, while consistently outperforming existing hallucination mitigation
methods.

</details>


### [60] [Noise Matters: Optimizing Matching Noise for Diffusion Classifiers](https://arxiv.org/abs/2508.11330)
*Yanghao Wang,Long Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为NoOp的新方法，通过优化数据集特定的噪声和图像特定的噪声偏移，从而改进基于扩散模型的分类系统的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有扩散分类器存在噪声不稳定性的问题，导致分类性能波动大，为了提高分类的稳定性，研究者提出探讨噪声的作用并设计优化方法。

Method: 提出了NoOp方法，基于两个原则：频率匹配和空间匹配，通过优化数据集特定的噪声和训练一个元网络生成图像特定的噪声偏移，最终用优化后的噪声取代随机噪声。

Result: 实验表明，新方法NoOp在多个数据集上的效果显著优于现有扩散分类器，其分类稳定性和效率都得到显著提高。

Conclusion: 通过优化噪声选择，NoOp方法有效解决了扩散分类器中的噪声不稳定性，兼顾了分类性能和效率，为进一步研究扩散模型的高效应用提供了参考。

Abstract: Although today's pretrained discriminative vision-language models (e.g.,
CLIP) have demonstrated strong perception abilities, such as zero-shot image
classification, they also suffer from the bag-of-words problem and spurious
bias. To mitigate these problems, some pioneering studies leverage powerful
generative models (e.g., pretrained diffusion models) to realize generalizable
image classification, dubbed Diffusion Classifier (DC). Specifically, by
randomly sampling a Gaussian noise, DC utilizes the differences of denoising
effects with different category conditions to classify categories.
Unfortunately, an inherent and notorious weakness of existing DCs is noise
instability: different random sampled noises lead to significant performance
changes. To achieve stable classification performance, existing DCs always
ensemble the results of hundreds of sampled noises, which significantly reduces
the classification speed. To this end, we firstly explore the role of noise in
DC, and conclude that: there are some ``good noises'' that can relieve the
instability. Meanwhile, we argue that these good noises should meet two
principles: Frequency Matching and Spatial Matching. Regarding both principles,
we propose a novel Noise Optimization method to learn matching (i.e., good)
noise for DCs: NoOp. For frequency matching, NoOp first optimizes a
dataset-specific noise: Given a dataset and a timestep t, optimize one randomly
initialized parameterized noise. For Spatial Matching, NoOp trains a
Meta-Network that adopts an image as input and outputs image-specific noise
offset. The sum of optimized noise and noise offset will be used in DC to
replace random noise. Extensive ablations on various datasets demonstrated the
effectiveness of NoOp.

</details>


### [61] [GANDiff FR: Hybrid GAN Diffusion Synthesis for Causal Bias Attribution in Face Recognition](https://arxiv.org/abs/2508.11334)
*Md Asgor Hossain Reaj,Rajan Das Gupta,Md Yeasin Rahat,Nafiz Fahad,Md Jawadul Hasan,Tze Hui Liew*

Main category: cs.CV

TL;DR: 本文引入了GANDiff FR，这是一个精确控制人口统计学和环境因素的合成框架，用于测量、解释和减少偏差。


<details>
  <summary>Details</summary>
Motivation: 在机器学习模型中，减少与人口统计和环境因素相关的偏见，并提供一种标准化方法来评估和提高公正性。

Method: 结合StyleGAN3的身份保真生成和基于扩散的属性控制，能够对姿势、光照和表情等进行细粒度操控，同时在合成环境中生成10,000张具有现实主义的人脸图片。

Result: 通过基准测试发现AdaFace的组间TPR不均减少了60%，并验证了该方法在真实数据集上的强传递性（相关性达到0.85）。尽管相比传统GANs多了20%的计算开销，但GANDiff FR能够生成三倍的属性条件变体。

Conclusion: GANDiff FR定义了一种可重复、符合监管要求的公平性审计标准，为机器学习模型的透明和大规模偏差评估做出了贡献，并公布了代码和数据以支持进一步研究。

Abstract: We introduce GANDiff FR, the first synthetic framework that precisely
controls demographic and environmental factors to measure, explain, and reduce
bias with reproducible rigor. GANDiff FR unifies StyleGAN3-based
identity-preserving generation with diffusion-based attribute control, enabling
fine-grained manipulation of pose around 30 degrees, illumination (four
directions), and expression (five levels) under ceteris paribus conditions. We
synthesize 10,000 demographically balanced faces across five cohorts validated
for realism via automated detection (98.2%) and human review (89%) to isolate
and quantify bias drivers. Benchmarking ArcFace, CosFace, and AdaFace under
matched operating points shows AdaFace reduces inter-group TPR disparity by 60%
(2.5% vs. 6.3%), with illumination accounting for 42% of residual bias.
Cross-dataset evaluation on RFW, BUPT, and CASIA WebFace confirms strong
synthetic-to-real transfer (r 0.85). Despite around 20% computational overhead
relative to pure GANs, GANDiff FR yields three times more attribute-conditioned
variants, establishing a reproducible, regulation-aligned (EU AI Act) standard
for fairness auditing. Code and data are released to support transparent,
scalable bias evaluation.

</details>


### [62] [Handwritten Text Recognition of Historical Manuscripts Using Transformer-Based Models](https://arxiv.org/abs/2508.11499)
*Erez Meoded*

Main category: cs.CV

TL;DR: 本文改进了TrOCR模型，利用图像预处理、数据增强等方法提升了对16世纪拉丁手稿的识别性能。


<details>
  <summary>Details</summary>
Motivation: 研究针对历史手稿识别面临的稀缺转录文本、语言变体及多样化书法风格问题，寻找解决方案。

Method: 采用TrOCR模型，结合图像预处理、数据增强技术，并提出了四种新颖的数据增强方法。同时尝试集成学习策略优化结果。

Result: 单一模型增强（Elastic）实现了1.86的CER，Top-5投票集成模型则达到1.60的CER，相较以往最佳结果分别提升了50%和42%。

Conclusion: 领域特定的数据增强和集成学习策略显著提高了对历史手稿的识别性能，为其他历史文本识别提供参考。

Abstract: Historical handwritten text recognition (HTR) is essential for unlocking the
cultural and scholarly value of archival documents, yet digitization is often
hindered by scarce transcriptions, linguistic variation, and highly diverse
handwriting styles. In this study, we apply TrOCR, a state-of-the-art
transformer-based HTR model, to 16th-century Latin manuscripts authored by
Rudolf Gwalther. We investigate targeted image preprocessing and a broad suite
of data augmentation techniques, introducing four novel augmentation methods
designed specifically for historical handwriting characteristics. We also
evaluate ensemble learning approaches to leverage the complementary strengths
of augmentation-trained models. On the Gwalther dataset, our best single-model
augmentation (Elastic) achieves a Character Error Rate (CER) of 1.86, while a
top-5 voting ensemble achieves a CER of 1.60 - representing a 50% relative
improvement over the best reported TrOCR_BASE result and a 42% improvement over
the previous state of the art. These results highlight the impact of
domain-specific augmentations and ensemble strategies in advancing HTR
performance for historical manuscripts.

</details>


### [63] [Index-Aligned Query Distillation for Transformer-based Incremental Object Detection](https://arxiv.org/abs/2508.11339)
*Mingxiao Ma,Shunyao Zhu,Guoliang Kang*

Main category: cs.CV

TL;DR: 提出了一种新型蒸馏方法IAQD，有效缓解知识遗忘问题，在基准测试上实现了新状态下的最优性能。


<details>
  <summary>Details</summary>
Motivation: 当前变换器的增量目标检测模型存在知识遗忘问题，而基于匈牙利匹配的方法在此任务中不理想，需要一个更精准的蒸馏方法。

Method: 提出Index-Aligned Query Distillation(IAQD)，通过索引对齐查询进行蒸馏，并仅对与旧类别检测相关的部分查询进行蒸馏，从而保留语义和空间编码能力。

Result: 大量实验表明IAQD显著缓解了知识遗忘问题，并在多个基准测试上取得了优异性能。

Conclusion: IAQD通过改进蒸馏方法，优化了转移学习中的知识保留与新知识学习平衡，为增量目标检测领域提供了重要的方法创新。

Abstract: Incremental object detection (IOD) aims to continuously expand the capability
of a model to detect novel categories while preserving its performance on
previously learned ones. When adopting a transformer-based detection model to
perform IOD, catastrophic knowledge forgetting may inevitably occur, meaning
the detection performance on previously learned categories may severely
degenerate. Previous typical methods mainly rely on knowledge distillation (KD)
to mitigate the catastrophic knowledge forgetting of transformer-based
detection models. Specifically, they utilize Hungarian Matching to build a
correspondence between the queries of the last-phase and current-phase
detection models and align the classifier and regressor outputs between matched
queries to avoid knowledge forgetting. However, we observe that in IOD task,
Hungarian Matching is not a good choice. With Hungarian Matching, the query of
the current-phase model may match different queries of the last-phase model at
different iterations during KD. As a result, the knowledge encoded in each
query may be reshaped towards new categories, leading to the forgetting of
previously encoded knowledge of old categories. Based on our observations, we
propose a new distillation approach named Index-Aligned Query Distillation
(IAQD) for transformer-based IOD. Beyond using Hungarian Matching, IAQD
establishes a correspondence between queries of the previous and current phase
models that have the same index. Moreover, we perform index-aligned
distillation only on partial queries which are critical for the detection of
previous categories. In this way, IAQD largely preserves the previous semantic
and spatial encoding capabilities without interfering with the learning of new
categories. Extensive experiments on representative benchmarks demonstrate that
IAQD effectively mitigates knowledge forgetting, achieving new state-of-the-art
performance.

</details>


### [64] [Cost-Effective Active Labeling for Data-Efficient Cervical Cell Classification](https://arxiv.org/abs/2508.11340)
*Yuanlin Liu,Zhihan Zhou,Mingqiang Wei,Youyi Song*

Main category: cs.CV

TL;DR: 本研究提出一种活跃标注方法，用较少人力成本构建代表性训练数据集，提高宫颈细胞分类效率。


<details>
  <summary>Details</summary>
Motivation: 现有分类方法需要大量且昂贵的人工成本来构建代表性的训练数据集，研究动机是通过减少人力成本提升数据效率。

Method: 提出一种活跃标注算法，通过评估分类器对未标注图像的不确定性，选择最有益于标注的图像，从而快速构建高效的训练数据集。

Result: 实验结果显示，该算法提升了训练数据集的代表性和数据效率，并有效优化了人工成本的使用。

Conclusion: 该方法为构建数据高效的宫颈细胞分类框架提供了新的方向，具有实际应用潜力。

Abstract: Information on the number and category of cervical cells is crucial for the
diagnosis of cervical cancer. However, existing classification methods capable
of automatically measuring this information require the training dataset to be
representative, which consumes an expensive or even unaffordable human cost. We
herein propose active labeling that enables us to construct a representative
training dataset using a much smaller human cost for data-efficient cervical
cell classification. This cost-effective method efficiently leverages the
classifier's uncertainty on the unlabeled cervical cell images to accurately
select images that are most beneficial to label. With a fast estimation of the
uncertainty, this new algorithm exhibits its validity and effectiveness in
enhancing the representative ability of the constructed training dataset. The
extensive empirical results confirm its efficacy again in navigating the usage
of human cost, opening the avenue for data-efficient cervical cell
classification.

</details>


### [65] [Semantically Guided Adversarial Testing of Vision Models Using Language Models](https://arxiv.org/abs/2508.11341)
*Katarzyna Filus,Jorge M. Cruz-Duarte*

Main category: cs.CV

TL;DR: 提出了一种语义引导框架，通过跨模态知识迁移，优化目标标签选择以提升对视觉模型的对抗性攻击效果。


<details>
  <summary>Details</summary>
Motivation: 现有对抗性攻击中目标标签选择依赖随机性、模型预测或静态语义资源，缺乏可解释性和灵活性。

Method: 使用预训练语言和视觉语言模型（如BERT、TinyLLAMA、CLIP）进行语义相似性计算，从而选择与真实标签最相关或最不相关的目标标签，形成最佳和最差对抗性场景。

Result: 在实验中，对三种视觉模型和五种攻击方法来说，新方法相比传统语义资源（如WordNet）表现更优，特别是对于语义关系较远的类别。

Conclusion: 预训练模型适用于构建可解释、标准化且可扩展的对抗性基准，有利于不同架构和数据集的一致性评估。

Abstract: In targeted adversarial attacks on vision models, the selection of the target
label is a critical yet often overlooked determinant of attack success. This
target label corresponds to the class that the attacker aims to force the model
to predict. Now, existing strategies typically rely on randomness, model
predictions, or static semantic resources, limiting interpretability,
reproducibility, or flexibility. This paper then proposes a semantics-guided
framework for adversarial target selection using the cross-modal knowledge
transfer from pretrained language and vision-language models. We evaluate
several state-of-the-art models (BERT, TinyLLAMA, and CLIP) as similarity
sources to select the most and least semantically related labels with respect
to the ground truth, forming best- and worst-case adversarial scenarios. Our
experiments on three vision models and five attack methods reveal that these
models consistently render practical adversarial targets and surpass static
lexical databases, such as WordNet, particularly for distant class
relationships. We also observe that static testing of target labels offers a
preliminary assessment of the effectiveness of similarity sources, \textit{a
priori} testing. Our results corroborate the suitability of pretrained models
for constructing interpretable, standardized, and scalable adversarial
benchmarks across architectures and datasets.

</details>


### [66] [HOID-R1: Reinforcement Learning for Open-World Human-Object Interaction Detection Reasoning with Multimodal Large Language Model](https://arxiv.org/abs/2508.11350)
*Zhenhao Zhang,Hanqing Wang,Xiangyu Zeng,Ziyu Cheng,Jiaxin Liu,Haoyu Yan,Zhirui Liu,Kaiyang Ji,Tianxiang Gui,Ke Hu,Kangyi Chen,Yahao Fan,Mokai Pan*

Main category: cs.CV

TL;DR: 本文提出了HOID-R1框架，集成了链式思维(CoT)引导的监督微调(SFT)和群组相对策略优化(GRPO)，用于提升人类-物体交互(HOI)检测，展现了在基准测试中卓越的性能和广泛适应性。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇的HOI检测方法仅依赖大语言模型生成文本提示，忽略其内在的3D空间理解能力。作者提出一种新的方法，弥补该不足。

Method: 提出了HOID-R1框架，先通过CoT引导的SFT赋予模型推理能力，再运用GRPO结合多重奖励信号优化策略，同时引入“MLLM-as-a-judge”机制改善生成推理的准确性。

Result: 在多种HOI检测基准上实验，HOID-R1实现了最新的性能，并在开放世界的全新场景中表现出较优的泛化能力。

Conclusion: HOID-R1框架开创性地结合了CoT和强化学习方法，提升了HOI检测的准确性与泛化性能，为该领域的研究提供了新的思路。

Abstract: Understanding and recognizing human-object interaction (HOI) is a pivotal
application in AR/VR and robotics. Recent open-vocabulary HOI detection
approaches depend exclusively on large language models for richer textual
prompts, neglecting their inherent 3D spatial understanding capabilities. To
address this shortcoming, we introduce HOID-R1, the first HOI detection
framework that integrates chain-of-thought (CoT) guided supervised fine-tuning
(SFT) with group relative policy optimization (GRPO) within a reinforcement
learning (RL) paradigm. Specifically, we initially apply SFT to imbue the model
with essential reasoning capabilities, forcing the model to articulate its
thought process in the output. Subsequently, we integrate GRPO to leverage
multi-reward signals for policy optimization, thereby enhancing alignment
across diverse modalities. To mitigate hallucinations in the CoT reasoning, we
introduce an "MLLM-as-a-judge" mechanism that supervises the CoT outputs,
further improving generalization. Extensive experiments show that HOID-R1
achieves state-of-the-art performance on HOI detection benchmarks and
outperforms existing methods in open-world generalization to novel scenarios.

</details>


### [67] [Is ChatGPT-5 Ready for Mammogram VQA?](https://arxiv.org/abs/2508.11628)
*Qiang Li,Shansong Wang,Mingzhe Hu,Mojtaba Safari,Zachary Eidex,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 本研究评估了GPT-5家族及GPT-4o模型在四个乳腺X光公共数据集上的表现，包括BI-RADS评估、异常检测和恶性分类任务。GPT-5表现优于其他GPT版本，但低于人类专家和特定领域的微调模型。尽管有提升，其在高风险临床影像应用中仍需改进。


<details>
  <summary>Details</summary>
Motivation: 分析大规模语言模型在乳腺X光视觉问答任务中的潜力，为未来乳腺癌筛查提供辅助。

Method: 使用四个公开乳腺X光数据集（EMBED, InBreast, CMMD, CBIS-DDSM），结合BI-RADS评估、异常检测和恶性分类等评价任务，比较GPT-5家族和GPT-4o的性能。

Result: GPT-5在所有任务中表现优于其他GPT模型，但在敏感性(63.5%)和特异性(52.3%)等关键指标上落后于人类专家和领域专用模型。

Conclusion: 尽管GPT-5在助力乳腺癌筛查任务中表现出潜力，但在高风险临床应用中仍需进一步的领域适配和优化。

Abstract: Mammogram visual question answering (VQA) integrates image interpretation
with clinical reasoning and has potential to support breast cancer screening.
We systematically evaluated the GPT-5 family and GPT-4o model on four public
mammography datasets (EMBED, InBreast, CMMD, CBIS-DDSM) for BI-RADS assessment,
abnormality detection, and malignancy classification tasks. GPT-5 consistently
was the best performing model but lagged behind both human experts and
domain-specific fine-tuned models. On EMBED, GPT-5 achieved the highest scores
among GPT variants in density (56.8%), distortion (52.5%), mass (64.5%),
calcification (63.5%), and malignancy (52.8%) classification. On InBreast, it
attained 36.9% BI-RADS accuracy, 45.9% abnormality detection, and 35.0%
malignancy classification. On CMMD, GPT-5 reached 32.3% abnormality detection
and 55.0% malignancy accuracy. On CBIS-DDSM, it achieved 69.3% BI-RADS
accuracy, 66.0% abnormality detection, and 58.2% malignancy accuracy. Compared
with human expert estimations, GPT-5 exhibited lower sensitivity (63.5%) and
specificity (52.3%). While GPT-5 exhibits promising capabilities for screening
tasks, its performance remains insufficient for high-stakes clinical imaging
applications without targeted domain adaptation and optimization. However, the
tremendous improvements in performance from GPT-4o to GPT-5 show a promising
trend in the potential for general large language models (LLMs) to assist with
mammography VQA tasks.

</details>


### [68] [Unified Knowledge Distillation Framework: Fine-Grained Alignment and Geometric Relationship Preservation for Deep Face Recognition](https://arxiv.org/abs/2508.11376)
*Durgesh Mishra,Rishabh Uikey*

Main category: cs.CV

TL;DR: 提出一种通过两个新颖的损失函数来改进面部识别模型知识蒸馏的方法，包括实例级嵌入蒸馏和基于关系的成对相似度蒸馏，显著提升了蒸馏效果和学生模型的性能。


<details>
  <summary>Details</summary>
Motivation: 优化面部识别模型在计算能力有限环境（如边缘设备）上的性能，解决传统知识蒸馏方法无法捕捉细粒度实例细节和复杂关系结构的问题。

Method: 引入两个新型损失函数：实例级嵌入蒸馏和基于关系的成对相似度蒸馏。前者通过动态困难样本挖掘对齐特征嵌入，后者通过内存库机制和样本挖掘捕获样本间的关系信息。

Result: 提出的框架在多个基准面部识别数据集上优于最先进的蒸馏方法。在某些情况下，学生模型甚至能超越教师模型的精度。

Conclusion: 该方法成功整合实例级对齐和几何关系的保持，提供了更全面的知识蒸馏过程，显著提升了面部识别模型的性能，适用于带宽较低的设备部署。

Abstract: Knowledge Distillation is crucial for optimizing face recognition models for
deployment in computationally limited settings, such as edge devices.
Traditional KD methods, such as Raw L2 Feature Distillation or Feature
Consistency loss, often fail to capture both fine-grained instance-level
details and complex relational structures, leading to suboptimal performance.
We propose a unified approach that integrates two novel loss functions,
Instance-Level Embedding Distillation and Relation-Based Pairwise Similarity
Distillation. Instance-Level Embedding Distillation focuses on aligning
individual feature embeddings by leveraging a dynamic hard mining strategy,
thereby enhancing learning from challenging examples. Relation-Based Pairwise
Similarity Distillation captures relational information through pairwise
similarity relationships, employing a memory bank mechanism and a sample mining
strategy. This unified framework ensures both effective instance-level
alignment and preservation of geometric relationships between samples, leading
to a more comprehensive distillation process. Our unified framework outperforms
state-of-the-art distillation methods across multiple benchmark face
recognition datasets, as demonstrated by extensive experimental evaluations.
Interestingly, when using strong teacher networks compared to the student, our
unified KD enables the student to even surpass the teacher's accuracy.

</details>


### [69] [RMFAT: Recurrent Multi-scale Feature Atmospheric Turbulence Mitigator](https://arxiv.org/abs/2508.11409)
*Zhiming Liu,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: 该论文提出了RMFAT模型，用于高效地减轻大气湍流对视频质量的影响。该模型在实验中表现优异，达到了更高的清晰度恢复以及更快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理大气湍流引起的视频失真时过于依赖多帧输入且计算与存储成本高，不利于实时部署，亟需一种轻量化、高效的解决方案。

Method: 提出了一种轻量级的递归多尺度特征模型RMFAT，利用仅两帧输入进行视频帧恢复，整合了多尺度特征编码解码和时序配准模块，实现高效计算和时序一致性。

Result: 在合成和真实大气湍流数据集上，RMFAT在视频清晰度恢复（SSIM提升近9%）以及推理速度（运行时间减少四倍以上）方面均优于现有方法。

Conclusion: RMFAT模型在性能和实时性之间达成了良好平衡，为大气湍流视频恢复任务提供了一种高效、实时的解决方案。

Abstract: Atmospheric turbulence severely degrades video quality by introducing
distortions such as geometric warping, blur, and temporal flickering, posing
significant challenges to both visual clarity and temporal consistency. Current
state-of-the-art methods are based on transformer and 3D architectures and
require multi-frame input, but their large computational cost and memory usage
limit real-time deployment, especially in resource-constrained scenarios. In
this work, we propose RMFAT: Recurrent Multi-scale Feature Atmospheric
Turbulence Mitigator, designed for efficient and temporally consistent video
restoration under AT conditions. RMFAT adopts a lightweight recurrent framework
that restores each frame using only two inputs at a time, significantly
reducing temporal window size and computational burden. It further integrates
multi-scale feature encoding and decoding with temporal warping modules at both
encoder and decoder stages to enhance spatial detail and temporal coherence.
Extensive experiments on synthetic and real-world atmospheric turbulence
datasets demonstrate that RMFAT not only outperforms existing methods in terms
of clarity restoration (with nearly a 9\% improvement in SSIM) but also
achieves significantly improved inference speed (more than a fourfold reduction
in runtime), making it particularly suitable for real-time atmospheric
turbulence suppression tasks.

</details>


### [70] [SelfAdapt: Unsupervised Domain Adaptation of Cell Segmentation Models](https://arxiv.org/abs/2508.11411)
*Fabian H. Reith,Jannik Franzen,Dinesh R. Palli,J. Lorenz Rumberger,Dagmar Kainmueller*

Main category: cs.CV

TL;DR: SelfAdapt方法通过自监督的方式，使得预训练的细胞分割模型能够在不同数据域上适应，无需标签，提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 当前主流的通用细胞分割模型（如Cellpose）在跨域测试时性能下降，而监督微调需要标注数据，成本较高。

Method: 提出了一种基于学生-教师增强一致性训练的方法，引入L2-SP正则化和无标签终止准则，达到自适应分割效果。

Result: 在LiveCell和TissueNet数据集上测试，与基础模型（Cellpose）相比，AP0.5指标最高提升29.64%；并证明该方法可进一步提升已通过监督方式微调的模型性能。

Conclusion: SelfAdapt在无需标注数据的情况下提升了预训练分割模型的跨域适应性，是一种高效的无监督细胞分割增强方法，其代码已开源。

Abstract: Deep neural networks have become the go-to method for biomedical instance
segmentation. Generalist models like Cellpose demonstrate state-of-the-art
performance across diverse cellular data, though their effectiveness often
degrades on domains that differ from their training data. While supervised
fine-tuning can address this limitation, it requires annotated data that may
not be readily available. We propose SelfAdapt, a method that enables the
adaptation of pre-trained cell segmentation models without the need for labels.
Our approach builds upon student-teacher augmentation consistency training,
introducing L2-SP regularization and label-free stopping criteria. We evaluate
our method on the LiveCell and TissueNet datasets, demonstrating relative
improvements in AP0.5 of up to 29.64% over baseline Cellpose. Additionally, we
show that our unsupervised adaptation can further improve models that were
previously fine-tuned with supervision. We release SelfAdapt as an easy-to-use
extension of the Cellpose framework. The code for our method is publicly
available at https: //github.com/Kainmueller-Lab/self_adapt.

</details>


### [71] [Training-free Dimensionality Reduction via Feature Truncation: Enhancing Efficiency in Privacy-preserving Multi-Biometric Systems](https://arxiv.org/abs/2508.11419)
*Florian Bayer,Maximilian Russo,Christian Rathgeb*

Main category: cs.CV

TL;DR: 本文探讨了如何通过结合多模态生物特征实现模板压缩，用同态加密提高处理效率的同时，确保生物识别的准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 研究如何在不影响生物特征识别准确性和安全性的前提下，优化多模态生物模板的效率和大小。

Method: 利用深度神经网络提取人脸、指纹和虹膜特征，构建多模态模板，并通过同态加密减少计算量，同时保持高效加密处理。

Result: 实现了模板尺寸减少67%，且性能与单模态最佳结果相当，在错误率(EER)上无任何损失。

Conclusion: 多模态生物特征融合可以有效减少模板尺寸，同时在同态加密中更高效地处理加密数据，确保高水平的准确性和安全性。

Abstract: Biometric recognition is widely used, making the privacy and security of
extracted templates a critical concern. Biometric Template Protection schemes,
especially those utilizing Homomorphic Encryption, introduce significant
computational challenges due to increased workload. Recent advances in deep
neural networks have enabled state-of-the-art feature extraction for face,
fingerprint, and iris modalities. The ubiquity and affordability of biometric
sensors further facilitate multi-modal fusion, which can enhance security by
combining features from different modalities. This work investigates the
biometric performance of reduced multi-biometric template sizes. Experiments
are conducted on an in-house virtual multi-biometric database, derived from
DNN-extracted features for face, fingerprint, and iris, using the FRGC, MCYT,
and CASIA databases. The evaluated approaches are (i) explainable and
straightforward to implement under encryption, (ii) training-free, and (iii)
capable of generalization. Dimensionality reduction of feature vectors leads to
fewer operations in the Homomorphic Encryption (HE) domain, enabling more
efficient encrypted processing while maintaining biometric accuracy and
security at a level equivalent to or exceeding single-biometric recognition.
Our results demonstrate that, by fusing feature vectors from multiple
modalities, template size can be reduced by 67 % with no loss in Equal Error
Rate (EER) compared to the best-performing single modality.

</details>


### [72] [ImagiDrive: A Unified Imagination-and-Planning Framework for Autonomous Driving](https://arxiv.org/abs/2508.11428)
*Jingyu Li,Bozhou Zhang,Xin Jin,Jiankang Deng,Xiatian Zhu,Li Zhang*

Main category: cs.CV

TL;DR: 提出了一个名为ImagiDrive的框架，将视觉语言模型(VLM)与驾驶世界模型(DWM)相结合，用于自动驾驶的场景预测和规划，实验验证结果优越。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要结合丰富的上下文理解与精准预测，当前VLM和DWM各自有所长，但结合两者的潜力未被充分研究。

Method: 提出一个端到端的框架ImagiDrive，将基于VLM的驾驶代理与基于DWM的场景生成器结合，通过‘想象与规划’协作改进驾驶决策，并引入了提前停止机制和轨迹选择策略。

Result: 在nuScenes和NAVSIM数据集上的实验结果表明，ImagiDrive在开放和闭环条件下表现优于现有方法。

Conclusion: 将多模态上下文理解与未来场景的细致生成有机结合，ImagiDrive在效率和预测精度方面取得了良好效果，是自动驾驶领域的一种有前景解决方案。

Abstract: Autonomous driving requires rich contextual comprehension and precise
predictive reasoning to navigate dynamic and complex environments safely.
Vision-Language Models (VLMs) and Driving World Models (DWMs) have
independently emerged as powerful recipes addressing different aspects of this
challenge. VLMs provide interpretability and robust action prediction through
their ability to understand multi-modal context, while DWMs excel in generating
detailed and plausible future driving scenarios essential for proactive
planning. Integrating VLMs with DWMs is an intuitive, promising, yet
understudied strategy to exploit the complementary strengths of accurate
behavioral prediction and realistic scene generation. Nevertheless, this
integration presents notable challenges, particularly in effectively connecting
action-level decisions with high-fidelity pixel-level predictions and
maintaining computational efficiency. In this paper, we propose ImagiDrive, a
novel end-to-end autonomous driving framework that integrates a VLM-based
driving agent with a DWM-based scene imaginer to form a unified
imagination-and-planning loop. The driving agent predicts initial driving
trajectories based on multi-modal inputs, guiding the scene imaginer to
generate corresponding future scenarios. These imagined scenarios are
subsequently utilized to iteratively refine the driving agent's planning
decisions. To address efficiency and predictive accuracy challenges inherent in
this integration, we introduce an early stopping mechanism and a trajectory
selection strategy. Extensive experimental validation on the nuScenes and
NAVSIM datasets demonstrates the robustness and superiority of ImagiDrive over
previous alternatives under both open-loop and closed-loop conditions.

</details>


### [73] [Remove360: Benchmarking Residuals After Object Removal in 3D Gaussian Splatting](https://arxiv.org/abs/2508.11431)
*Simona Kocour,Assia Benbihi,Torsten Sattler*

Main category: cs.CV

TL;DR: 论文探讨从3D场景中移除物体后的语义残留问题，通过一种新的评估框架检测当前方法的局限性，并提出Remove360数据集。


<details>
  <summary>Details</summary>
Motivation: 研究从3D场景中移除物体后是否仍然存在语义痕迹，以促进隐私保护的3D重建和可编辑场景表示。

Method: 提出一个评估框架，用于测量移除物体后的语义痕迹，同时发布了Remove360数据集，包括移除前后的RGB图像和物体掩码。

Result: 实验表明，当前方法即使在移除3D物体的视觉几何后，仍然保存了语义信息，体现出一定局限性。

Conclusion: 需要开发更强大的解决方案，以应对真实环境中移除物体后的语义残留问题。

Abstract: Understanding what semantic information persists after object removal is
critical for privacy-preserving 3D reconstruction and editable scene
representations. In this work, we introduce a novel benchmark and evaluation
framework to measure semantic residuals, the unintended semantic traces left
behind, after object removal in 3D Gaussian Splatting. We conduct experiments
across a diverse set of indoor and outdoor scenes, showing that current methods
can preserve semantic information despite the absence of visual geometry. We
also release Remove360, a dataset of pre/post-removal RGB images and
object-level masks captured in real-world environments. While prior datasets
have focused on isolated object instances, Remove360 covers a broader and more
complex range of indoor and outdoor scenes, enabling evaluation of object
removal in the context of full-scene representations. Given ground truth images
of a scene before and after object removal, we assess whether we can truly
eliminate semantic presence, and if downstream models can still infer what was
removed. Our findings reveal critical limitations in current 3D object removal
techniques and underscore the need for more robust solutions capable of
handling real-world complexity. The evaluation framework is available at
github.com/spatial-intelligence-ai/Remove360.git. Data are available at
huggingface.co/datasets/simkoc/Remove360.

</details>


### [74] [MM-R1: Unleashing the Power of Unified Multimodal Large Language Models for Personalized Image Generation](https://arxiv.org/abs/2508.11433)
*Qian Liang,Yujia Wu,Kuncheng Li,Jiwei Wei,Shiyuan He,Jinyu Guo,Ning Xie*

Main category: cs.CV

TL;DR: 本文提出了MM-R1框架，通过结合跨模态链式推理（X-CoT）策略，实现多模态大语言模型（MLLMs）在零样本条件下的个性化图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs方法在个性化图像生成中存在可扩展性差的问题，需要大量数据和频繁的微调，而MM-R1旨在解决这一困难。

Method: 引入了跨模态链式推理（X-CoT）策略，将个性化构建为图像理解与生成的整合过程，并通过分组奖励近端策略优化（GRPO）改进推理能力。

Result: 实验表明，MM-R1能够在保持主体一致性和文本对齐的情况下，实现高质量的个性化图像生成，且无需额外数据的零样本学习。

Conclusion: MM-R1框架成功解锁了统一MLLMs的个性化图像生成潜能，具有创新性与实用性。

Abstract: Multimodal Large Language Models (MLLMs) with unified architectures excel
across a wide range of vision-language tasks, yet aligning them with
personalized image generation remains a significant challenge. Existing methods
for MLLMs are frequently subject-specific, demanding a data-intensive
fine-tuning process for every new subject, which limits their scalability. In
this paper, we introduce MM-R1, a framework that integrates a cross-modal
Chain-of-Thought (X-CoT) reasoning strategy to unlock the inherent potential of
unified MLLMs for personalized image generation. Specifically, we structure
personalization as an integrated visual reasoning and generation process: (1)
grounding subject concepts by interpreting and understanding user-provided
images and contextual cues, and (2) generating personalized images conditioned
on both the extracted subject representations and user prompts. To further
enhance the reasoning capability, we adopt Grouped Reward Proximal Policy
Optimization (GRPO) to explicitly align the generation. Experiments demonstrate
that MM-R1 unleashes the personalization capability of unified MLLMs to
generate images with high subject fidelity and strong text alignment in a
zero-shot manner.

</details>


### [75] [Data-Driven Deepfake Image Detection Method -- The 2024 Global Deepfake Image Detection Challenge](https://arxiv.org/abs/2508.11464)
*Xiaoya Zhu,Yibing Nan,Shiguo Lian*

Main category: cs.CV

TL;DR: 本文主要针对Deepfake技术的图像检测任务，提出一种基于Swin Transformer V2-B分类网络的解决方案，并采用数据增强与样本生成方法提升模型表现。最终获得竞赛优秀奖。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的发展，Deepfake技术在生成内容与数字安全领域引发挑战，本文旨在应对其中的图像检测任务。

Method: 采用基于Swin Transformer V2-B的分类网络，并结合在线数据增强及离线样本生成方法提高训练数据多样性与模型泛化能力。

Result: 通过上述方法，成功在Deepfake图像检测比赛中获得优秀奖。

Conclusion: 本文方法在提升Deepfake图像检测中表现出色，展示了模型设计与数据策略的有效性。

Abstract: With the rapid development of technology in the field of AI, deepfake
technology has emerged as a double-edged sword. It has not only created a large
amount of AI-generated content but also posed unprecedented challenges to
digital security. The task of the competition is to determine whether a face
image is a Deepfake image and output its probability score of being a Deepfake
image. In the image track competition, our approach is based on the Swin
Transformer V2-B classification network. And online data augmentation and
offline sample generation methods are employed to enrich the diversity of
training samples and increase the generalization ability of the model. Finally,
we got the award of excellence in Deepfake image detection.

</details>


### [76] [CoFi: A Fast Coarse-to-Fine Few-Shot Pipeline for Glomerular Basement Membrane Segmentation](https://arxiv.org/abs/2508.11469)
*Hongjin Fang,Daniel Reisenbüchler,Kenji Ikemura,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: 该研究提出了一种名为CoFi的粗到细少样本分割管道，用于EM图像中肾小球基底膜（GBM）的自动分割。


<details>
  <summary>Details</summary>
Motivation: 现有监督学习方法可以达到高分割精度，但需要大量像素级标注，不适用于临床工作。而少样本学习方法难以捕捉GBM分析所需的细微结构。

Method: CoFi通过轻量级神经网络从少量（3幅）注释图像生成粗略分割掩膜，然后自动生成高质量点提示，结合形态感知修剪技术，指导SAM完成精细分割。

Result: 该方法达到了74.54%的Dice分数，推理速度为1.9 FPS，展现出卓越的GBM分割性能。

Conclusion: CoFi极大减少了传统方法的标注和计算负担，同时实现了精确可靠的分割结果，适合研究且在肾脏病理学临床应用中具有潜力。

Abstract: Accurate segmentation of the glomerular basement membrane (GBM) in electron
microscopy (EM) images is fundamental for quantifying membrane thickness and
supporting the diagnosis of various kidney diseases. While supervised deep
learning approaches achieve high segmentation accuracy, their reliance on
extensive pixel-level annotation renders them impractical for clinical
workflows. Few-shot learning can reduce this annotation burden but often
struggles to capture the fine structural details necessary for GBM analysis. In
this study, we introduce CoFi, a fast and efficient coarse-to-fine few-shot
segmentation pipeline designed for GBM delineation in EM images. CoFi first
trains a lightweight neural network using only three annotated images to
produce an initial coarse segmentation mask. This mask is then automatically
processed to generate high-quality point prompts with morphology-aware pruning,
which are subsequently used to guide SAM in refining the segmentation. The
proposed method achieved exceptional GBM segmentation performance, with a Dice
coefficient of 74.54% and an inference speed of 1.9 FPS. We demonstrate that
CoFi not only alleviates the annotation and computational burdens associated
with conventional methods, but also achieves accurate and reliable segmentation
results. The pipeline's speed and annotation efficiency make it well-suited for
research and hold strong potential for clinical applications in renal
pathology. The pipeline is publicly available at:
https://github.com/ddrrnn123/CoFi.

</details>


### [77] [TACR-YOLO: A Real-time Detection Framework for Abnormal Human Behaviors Enhanced with Coordinate and Task-Aware Representations](https://arxiv.org/abs/2508.11478)
*Xinyi Yin,Wenbo Yuan,Xuecheng Wu,Liangyu Fu,Danlei Huang*

Main category: cs.CV

TL;DR: 提出了TACR-YOLO，一个用于异常人类行为检测（AHBD）的实时框架，改进了对小目标检测、分类与回归冲突处理及多尺度融合能力，且在自建的PABD数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 针对现有YOLO检测在处理小目标、任务冲突及多尺度融合等问题上的不足，提出优化方案提升异常行为检测能力。

Method: 引入坐标注意力模块、任务感知注意力模块及强化颈部网络进行改进，同时优化锚框尺寸采用K-means聚类算法，并引入DIoU-Loss改进回归损失。

Result: 在包含8529个样本的PABD数据集上取得了91.92%的mAP，展示了其速度和鲁棒性优势。同时，通过消融实验验证了每个改进模块的贡献。

Conclusion: TACR-YOLO为特殊场景下的异常行为检测提供了新的见解，显著推进了相关研究的进展。

Abstract: Abnormal Human Behavior Detection (AHBD) under special scenarios is becoming
increasingly crucial. While YOLO-based detection methods excel in real-time
tasks, they remain hindered by challenges including small objects, task
conflicts, and multi-scale fusion in AHBD. To tackle them, we propose
TACR-YOLO, a new real-time framework for AHBD. We introduce a Coordinate
Attention Module to enhance small object detection, a Task-Aware Attention
Module to deal with classification-regression conflicts, and a Strengthen Neck
Network for refined multi-scale fusion, respectively. In addition, we optimize
Anchor Box sizes using K-means clustering and deploy DIoU-Loss to improve
bounding box regression. The Personnel Anomalous Behavior Detection (PABD)
dataset, which includes 8,529 samples across four behavior categories, is also
presented. Extensive experimental results indicate that TACR-YOLO achieves
91.92% mAP on PABD, with competitive speed and robustness. Ablation studies
highlight the contribution of each improvement. This work provides new insights
for abnormal behavior detection under special scenarios, advancing its
progress.

</details>


### [78] [OpenConstruction: A Systematic Synthesis of Open Visual Datasets for Data-Centric Artificial Intelligence in Construction Monitoring](https://arxiv.org/abs/2508.11482)
*Ruoxin Xiong,Yanyu Wang,Jiannan Cai,Kaijian Liu,Yuansheng Zhu,Pingbo Tang,Nora El-Gohary*

Main category: cs.CV

TL;DR: 本文系统审视了2005-2024年间公开的51个施工视觉数据集，创建了一个开源目录OpenConstruction，并制定未来数据基础设施战略。


<details>
  <summary>Details</summary>
Motivation: 目前施工领域的AI应用需要高质量视觉数据集，但现有数据集存在质量参差不齐、领域代表性不足的问题，急需系统梳理与分类以指导未来发展。

Method: 研究通过广泛搜索学术数据库和开放数据平台，归纳了51个公开的视觉数据集，并使用结构化模式分类数据的基本特征、模式、注释框架及应用领域，最终合成为一个开源目录。

Result: 生成了一个开放目录(OpenConstruction)，总结了施工视觉数据集现状，并揭示了当前施工数据资源的多项关键局限性。

Conclusion: 本文通过全面审视施工领域现有视觉数据集，提出基于FAIR原则的未来数据基础设施路线图，有助于推动施工行业数据驱动解决方案的发展。

Abstract: The construction industry increasingly relies on visual data to support
Artificial Intelligence (AI) and Machine Learning (ML) applications for site
monitoring. High-quality, domain-specific datasets, comprising images, videos,
and point clouds, capture site geometry and spatiotemporal dynamics, including
the location and interaction of objects, workers, and materials. However,
despite growing interest in leveraging visual datasets, existing resources vary
widely in sizes, data modalities, annotation quality, and representativeness of
real-world construction conditions. A systematic review to categorize their
data characteristics and application contexts is still lacking, limiting the
community's ability to fully understand the dataset landscape, identify
critical gaps, and guide future directions toward more effective, reliable, and
scalable AI applications in construction. To address this gap, this study
conducts an extensive search of academic databases and open-data platforms,
yielding 51 publicly available visual datasets that span the 2005-2024 period.
These datasets are categorized using a structured data schema covering (i) data
fundamentals (e.g., size and license), (ii) data modalities (e.g., RGB and
point cloud), (iii) annotation frameworks (e.g., bounding boxes), and (iv)
downstream application domains (e.g., progress tracking). This study
synthesizes these findings into an open-source catalog, OpenConstruction,
supporting data-driven method development. Furthermore, the study discusses
several critical limitations in the existing construction dataset landscape and
presents a roadmap for future data infrastructure anchored in the Findability,
Accessibility, Interoperability, and Reusability (FAIR) principles. By
reviewing the current landscape and outlining strategic priorities, this study
supports the advancement of data-centric solutions in the construction sector.

</details>


### [79] [CineTrans: Learning to Generate Videos with Cinematic Transitions via Masked Diffusion Models](https://arxiv.org/abs/2508.11484)
*Xiaoxue Wu,Bingjie Gao,Yu Qiao,Yaohui Wang,Xinyuan Chen*

Main category: cs.CV

TL;DR: 提出CineTrans框架，解决多镜头视频生成问题，通过电影化渐变生成连贯视频，超越现有基线。


<details>
  <summary>Details</summary>
Motivation: 多镜头视频生成研究仍处于初期阶段，现有方法在过渡处理方面不稳定且受限，亟需改进以实现更复杂和连贯的视频生成。

Method: 研发了一种名为CineTrans的新框架，构建了具有镜头注释的Cine250K多镜头视频-文本数据集，分析扩散模型注意力地图与镜头分界的关联，并通过掩膜控制机制实现无训练情况下的渐变过渡，随后对数据集进行微调以生成电影化风格视频。

Result: CineTrans框架生成了连贯、多镜头且具备电影编辑风格的视频，避免了传统不稳定过渡和简单拼接问题，并在过渡控制、时间一致性和整体质量等特定评估指标上显著优于现有基线模型。

Conclusion: CineTrans成功实现电影化多镜头视频生成，为多镜头视频合成提供了新方法，并提升了视频质量和过渡效果。

Abstract: Despite significant advances in video synthesis, research into multi-shot
video generation remains in its infancy. Even with scaled-up models and massive
datasets, the shot transition capabilities remain rudimentary and unstable,
largely confining generated videos to single-shot sequences. In this work, we
introduce CineTrans, a novel framework for generating coherent multi-shot
videos with cinematic, film-style transitions. To facilitate insights into the
film editing style, we construct a multi-shot video-text dataset Cine250K with
detailed shot annotations. Furthermore, our analysis of existing video
diffusion models uncovers a correspondence between attention maps in the
diffusion model and shot boundaries, which we leverage to design a mask-based
control mechanism that enables transitions at arbitrary positions and transfers
effectively in a training-free setting. After fine-tuning on our dataset with
the mask mechanism, CineTrans produces cinematic multi-shot sequences while
adhering to the film editing style, avoiding unstable transitions or naive
concatenations. Finally, we propose specialized evaluation metrics for
transition control, temporal consistency and overall quality, and demonstrate
through extensive experiments that CineTrans significantly outperforms existing
baselines across all criteria.

</details>


### [80] [Automated Building Heritage Assessment Using Street-Level Imagery](https://arxiv.org/abs/2508.11486)
*Kristina Dabrock,Tim Johansson,Anna Donarelli,Mikael Mangold,Noah Pflugradt,Jann Michael Weinand,Jochen Linßen*

Main category: cs.CV

TL;DR: 使用GPT模型分析建筑物文化遗产价值的外立面图像，结合登记数据，通过机器学习分类建筑类型，并验证其准确性。


<details>
  <summary>Details</summary>
Motivation: 能源节约措施需要细致数据，同时避免破坏文化遗产；AI工具可能更高效地识别建筑遗产价值。

Method: 使用GPT分析建筑外立面图像文化遗产价值，结合登记数据，通过机器学习模型分类建筑，并用专家数据验证准确性。

Result: 验证结果显示，结合登记和GPT提取特征的模型F1分数为0.71，仅用GPT特征的模型为0.60。

Conclusion: 该方法能提高数据库质量，支持大规模建筑节能与遗产价值综合考量的改造方案。

Abstract: Detailed data is required to quantify energy conservation measures in
buildings, such as envelop retrofits, without compromising cultural heritage.
Novel artificial intelligence tools may improve efficiency in identifying
heritage values in buildings compared to costly and time-consuming traditional
inventories. In this study, the large language model GPT was used to detect
various aspects of cultural heritage value in fa\c{c}ade images. Using this
data and building register data as features, machine learning models were
trained to classify multi-family and non-residential buildings in Stockholm,
Sweden. Validation against an expert-created inventory shows a macro F1-score
of 0.71 using a combination of register data and features retrieved from GPT,
and a score of 0.60 using only GPT-derived data. The presented methodology can
contribute to a higher-quality database and thus support careful energy
efficiency measures and integrated consideration of heritage value in
large-scale energetic refurbishment scenarios.

</details>


### [81] [An Efficient Medical Image Classification Method Based on a Lightweight Improved ConvNeXt-Tiny Architecture](https://arxiv.org/abs/2508.11532)
*Jingsong Xia,Yue Yin,Xiuhan Li*

Main category: cs.CV

TL;DR: 本文提出了一种基于改进型ConvNeXt-Tiny架构的医学图像分类方法，通过结构优化、特征融合及损失函数设计提高分类性能并降低计算复杂度，在CPU环境下实现了89.10%的分类精度。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的计算环境中，如何高效且高精度地对医学图像进行分类是一个重要且具有挑战性的问题。

Method: 通过改进ConvNeXt-Tiny架构，引入了双全局池化（全局平均池化和全局最大池化）特征融合策略，以及一种轻量级通道注意力模块SEVector，同时设计了特征平滑损失函数来提高特征一致性和抑制类内差异。

Result: 实验表明，在仅使用CPU的环境下，方法在测试集达到89.10%的分类准确率，仅需10个训练周期，并表现出稳定的收敛趋势。

Conclusion: 该方法有效提升了医学图像分类在资源有限场景下的性能，提供了一种可行且高效的医学图像分析模型部署方案。

Abstract: Intelligent analysis of medical imaging plays a crucial role in assisting
clinical diagnosis. However, achieving efficient and high-accuracy image
classification in resource-constrained computational environments remains
challenging. This study proposes a medical image classification method based on
an improved ConvNeXt-Tiny architecture. Through structural optimization and
loss function design, the proposed method enhances feature extraction
capability and classification performance while reducing computational
complexity. Specifically, the method introduces a dual global pooling (Global
Average Pooling and Global Max Pooling) feature fusion strategy into the
ConvNeXt-Tiny backbone to simultaneously preserve global statistical features
and salient response information. A lightweight channel attention module,
termed Squeeze-and-Excitation Vector (SEVector), is designed to improve the
adaptive allocation of channel weights while minimizing parameter overhead.
Additionally, a Feature Smoothing Loss is incorporated into the loss function
to enhance intra-class feature consistency and suppress intra-class variance.
Under CPU-only conditions (8 threads), the method achieves a maximum
classification accuracy of 89.10% on the test set within 10 training epochs,
exhibiting a stable convergence trend in loss values. Experimental results
demonstrate that the proposed method effectively improves medical image
classification performance in resource-limited settings, providing a feasible
and efficient solution for the deployment and promotion of medical imaging
analysis models.

</details>


### [82] [Perception in Plan: Coupled Perception and Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.11488)
*Bozhou Zhang,Jingyu Li,Nan Song,Li Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种新的端到端自动驾驶框架VeteranAD，在感知和规划的结合上进行了创新设计，显著提升了规划性能，并在NAVSIM和Bench2Drive数据集上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的感知-规划框架虽然为端到端自动驾驶提供了一种优化的途径，但其独立的感知和规划过程对性能的提升存在一定的限制。作者旨在通过结合感知与规划的方式突破这一局限，提高自动驾驶的决策能力。

Method: 提出VeteranAD框架，通过引入多模式的锚定轨迹作为规划先验，使感知模块有针对性地集中于规划轨迹上的交通要素；采用自回归策略动态预测未来轨迹，并对相关区域进行精准感知。

Result: VeteranAD通过感知和规划的深度结合展现出了优越的驾驶行为性能，并在NAVSIM和Bench2Drive数据集上的实验中达到了目前最优的效果。

Conclusion: 这种感知与规划相结合的创新框架有效地释放了端到端自动驾驶方法的潜力，显著提高了系统的准确性和可靠性，这对自动驾驶技术的发展具有重要意义。

Abstract: End-to-end autonomous driving has achieved remarkable advancements in recent
years. Existing methods primarily follow a perception-planning paradigm, where
perception and planning are executed sequentially within a fully differentiable
framework for planning-oriented optimization. We further advance this paradigm
through a perception-in-plan framework design, which integrates perception into
the planning process. This design facilitates targeted perception guided by
evolving planning objectives over time, ultimately enhancing planning
performance. Building on this insight, we introduce VeteranAD, a coupled
perception and planning framework for end-to-end autonomous driving. By
incorporating multi-mode anchored trajectories as planning priors, the
perception module is specifically designed to gather traffic elements along
these trajectories, enabling comprehensive and targeted perception. Planning
trajectories are then generated based on both the perception results and the
planning priors. To make perception fully serve planning, we adopt an
autoregressive strategy that progressively predicts future trajectories while
focusing on relevant regions for targeted perception at each step. With this
simple yet effective design, VeteranAD fully unleashes the potential of
planning-oriented end-to-end methods, leading to more accurate and reliable
driving behavior. Extensive experiments on the NAVSIM and Bench2Drive datasets
demonstrate that our VeteranAD achieves state-of-the-art performance.

</details>


### [83] [Hierarchical Graph Feature Enhancement with Adaptive Frequency Modulation for Visual Recognition](https://arxiv.org/abs/2508.11497)
*Feiyue Zhao,Zhichao Zhang*

Main category: cs.CV

TL;DR: 论文提出一种新的方法，通过将图算法融入CNN，增强其对复杂拓扑关系和非局部语义的建模能力。


<details>
  <summary>Details</summary>
Motivation: 克服CNN依赖规则网格结构难以有效建模图像中复杂拓扑关系和全局语义的局限性。

Method: 提出一种分层图特征增强（HGFE）框架，结合局部和全局的图结构，同时引入自适应频率调制模块以优化信号传播并减轻过度平滑问题。

Result: 在分类（CIFAR-100）、检测（PASCAL VOC、VisDrone）和分割（CrackSeg、CarParts）任务中，验证该方法有效提升了CNN的结构表示能力和识别性能。

Conclusion: HGFE是一种轻量化、端到端可训练，并可无缝嵌入标准CNN主干网络的增强方法，为CNN在复杂图像处理任务中的应用提供了新的可能性。

Abstract: Convolutional neural networks (CNNs) have
  demonstrated strong performance in visual recognition tasks,
  but their inherent reliance on regular grid structures limits
  their capacity to model complex topological relationships and
  non-local semantics within images. To address this limita tion, we propose
the hierarchical graph feature enhancement
  (HGFE), a novel framework that integrates graph-based rea soning into CNNs to
enhance both structural awareness and
  feature representation. HGFE builds two complementary levels
  of graph structures: intra-window graph convolution to cap ture local spatial
dependencies and inter-window supernode
  interactions to model global semantic relationships. Moreover,
  we introduce an adaptive frequency modulation module that
  dynamically balances low-frequency and high-frequency signal
  propagation, preserving critical edge and texture information
  while mitigating over-smoothing. The proposed HGFE module
  is lightweight, end-to-end trainable, and can be seamlessly
  integrated into standard CNN backbone networks. Extensive
  experiments on CIFAR-100 (classification), PASCAL VOC,
  and VisDrone (detection), as well as CrackSeg and CarParts
  (segmentation), validated the effectiveness of the HGFE in
  improving structural representation and enhancing overall
  recognition performance.

</details>


### [84] [AIM: Amending Inherent Interpretability via Self-Supervised Masking](https://arxiv.org/abs/2508.11502)
*Eyad Alshami,Shashank Agnihotri,Bernt Schiele,Margret Keuper*

Main category: cs.CV

TL;DR: AIM通过自监督特征掩码技术提升神经网络解释性和性能，无需额外标注。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络过度依赖伪特征的问题，提升模型的泛化能力和解释性。

Method: 提出AIM方法，利用多阶段编码特征指导自监督、样本特定的特征掩码过程。

Result: AIM在多个数据集上取得了解释性和准确性上的显著改善，例如提高了EPG分数和基准测试模型的性能。

Conclusion: AIM促进了对真实而有意义特征的使用，从而提高了模型的泛化能力和对人类的可解释性对齐。

Abstract: It has been observed that deep neural networks (DNNs) often use both genuine
as well as spurious features. In this work, we propose "Amending Inherent
Interpretability via Self-Supervised Masking" (AIM), a simple yet interestingly
effective method that promotes the network's utilization of genuine features
over spurious alternatives without requiring additional annotations. In
particular, AIM uses features at multiple encoding stages to guide a
self-supervised, sample-specific feature-masking process. As a result, AIM
enables the training of well-performing and inherently interpretable models
that faithfully summarize the decision process. We validate AIM across a
diverse range of challenging datasets that test both out-of-distribution
generalization and fine-grained visual understanding. These include
general-purpose classification benchmarks such as ImageNet100, HardImageNet,
and ImageWoof, as well as fine-grained classification datasets such as
Waterbirds, TravelingBirds, and CUB-200. AIM demonstrates significant dual
benefits: interpretability improvements, as measured by the Energy Pointing
Game (EPG) score, and accuracy gains over strong baselines. These consistent
gains across domains and architectures provide compelling evidence that AIM
promotes the use of genuine and meaningful features that directly contribute to
improved generalization and human-aligned interpretability.

</details>


### [85] [A Real-time Concrete Crack Detection and Segmentation Model Based on YOLOv11](https://arxiv.org/abs/2508.11517)
*Shaoze Huang,Qi Liu,Chao Chen,Yuhang Chen*

Main category: cs.CV

TL;DR: 该论文提出一种高效的混凝土裂缝检测与分割模型YOLOv11-KW-TA-FP，解决复杂背景下小目标裂缝检测的难题。


<details>
  <summary>Details</summary>
Motivation: 快速发展的长三角地区交通基础设施老化亟需高效的混凝土裂缝检测方法，以保障结构完整性和经济发展。现有人工检测效率低下、深度学习模型表现不足，尤其在复杂背景下的小目标裂缝检测任务中面临挑战。

Method: 基于YOLOv11n架构，本文提出了一种三阶段优化框架：1. 在主干网络中嵌入动态KernelWarehouse卷积（KWConv）以增强特征表现；2. 在特征金字塔中加入三重注意力机制（TA）以加强通道和空间的交互建模；3. 设计FP-IoU损失函数以实现自适应边界框回归惩罚。

Result: 实验验证表明，该模型相比基线性能显著提高，达到91.3%精准率、76.6%召回率和86.4%的mAP@50。消融研究证实模块的协同效果，且在数据稀缺和噪声干扰下表现稳定。

Conclusion: 本研究提供了一种高效的计算机视觉自动化基础设施检测解决方案，具有重要的工程实践价值。

Abstract: Accelerated aging of transportation infrastructure in the rapidly developing
Yangtze River Delta region necessitates efficient concrete crack detection, as
crack deterioration critically compromises structural integrity and regional
economic growth. To overcome the limitations of inefficient manual inspection
and the suboptimal performance of existing deep learning models, particularly
for small-target crack detection within complex backgrounds, this paper
proposes YOLOv11-KW-TA-FP, a multi-task concrete crack detection and
segmentation model based on the YOLOv11n architecture. The proposed model
integrates a three-stage optimization framework: (1) Embedding dynamic
KernelWarehouse convolution (KWConv) within the backbone network to enhance
feature representation through a dynamic kernel sharing mechanism; (2)
Incorporating a triple attention mechanism (TA) into the feature pyramid to
strengthen channel-spatial interaction modeling; and (3) Designing an FP-IoU
loss function to facilitate adaptive bounding box regression penalization.
Experimental validation demonstrates that the enhanced model achieves
significant performance improvements over the baseline, attaining 91.3%
precision, 76.6% recall, and 86.4% mAP@50. Ablation studies confirm the
synergistic efficacy of the proposed modules. Furthermore, robustness tests
indicate stable performance under conditions of data scarcity and noise
interference. This research delivers an efficient computer vision solution for
automated infrastructure inspection, exhibiting substantial practical
engineering value.

</details>


### [86] [Multi-State Tracker: Enhancing Efficient Object Tracking via Multi-State Specialization and Interaction](https://arxiv.org/abs/2508.11531)
*Shilei Wang,Gong Cheng,Pujian Lai,Dong Gao,Junwei Han*

Main category: cs.CV

TL;DR: 本文提出了一种高效的跟踪器Multi-State Tracker (MST)，通过多状态生成(MSG)与状态特定增强(SSE)的交互设计，增强特征表示能力，并保持计算开销低。


<details>
  <summary>Details</summary>
Motivation: 当前高效跟踪器由于减少模型参数而降低了特征表示能力，限制了对目标状态的准确捕捉能力。

Method: MST使用轻量化的状态特定增强(SSE)和跨状态交互(CSI)来增强多状态特征，并采用隐藏状态适配的状态空间二元性设计，仅增加小量计算开销。

Result: 实验表明MST在多个数据集上超越了现有高效跟踪器，在GOT-10K数据集上比之前最佳效率跟踪器提升4.5%的AO分数，且运行速度优异。

Conclusion: MST在跟踪准确性、鲁棒性和运行效率方面具有显著提升，是一种高效的多状态跟踪解决方案。

Abstract: Efficient trackers achieve faster runtime by reducing computational
complexity and model parameters. However, this efficiency often compromises the
expense of weakened feature representation capacity, thus limiting their
ability to accurately capture target states using single-layer features. To
overcome this limitation, we propose Multi-State Tracker (MST), which utilizes
highly lightweight state-specific enhancement (SSE) to perform specialized
enhancement on multi-state features produced by multi-state generation (MSG)
and aggregates them in an interactive and adaptive manner using cross-state
interaction (CSI). This design greatly enhances feature representation while
incurring minimal computational overhead, leading to improved tracking
robustness in complex environments. Specifically, the MSG generates multiple
state representations at multiple stages during feature extraction, while SSE
refines them to highlight target-specific features. The CSI module facilitates
information exchange between these states and ensures the integration of
complementary features. Notably, the introduced SSE and CSI modules adopt a
highly lightweight hidden state adaptation-based state space duality (HSA-SSD)
design, incurring only 0.1 GFLOPs in computation and 0.66 M in parameters.
Experimental results demonstrate that MST outperforms all previous efficient
trackers across multiple datasets, significantly improving tracking accuracy
and robustness. In particular, it shows excellent runtime performance, with an
AO score improvement of 4.5\% over the previous SOTA efficient tracker HCAT on
the GOT-10K dataset. The code is available at https://github.com/wsumel/MST.

</details>


### [87] [Reinforcing Video Reasoning Segmentation to Think Before It Segments](https://arxiv.org/abs/2508.11538)
*Sitong Gong,Lu Zhang,Yunzhi Zhuge,Xu Jia,Pingping Zhang,Huchuan Lu*

Main category: cs.CV

TL;DR: 本论文提出了Veason-R1，用于提升视频推理分割任务的性能，其基于结构化的推理方法，并通过新的训练和优化策略实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在进行视频推理分割任务时，因为缺乏空间和时间逻辑的推理能力，表现相对欠佳，且模型的推理过程缺乏可解释性。

Method: 引入了Veason-R1，这是一种专为VRS任务设计的LVLM，通过高质量的链式思维（CoT）初始化和群相对策略优化（GRPO）进行训练，结合整体奖励机制，将视频语义和空间定位更好地结合起来。

Result: Veason-R1在多个基准上实现了最先进表现，例如ReVOS上提高1.3 J&F，ReasonVOS上提高10.0 J&F，同时在抗幻觉性上表现出色，增加了8.8 R。

Conclusion: Veason-R1成功通过创新的训练和推理策略显著提升了视频推理分割的性能，并展现了更强的空间和时间逻辑推理能力。

Abstract: Video reasoning segmentation (VRS) endeavors to delineate referred objects in
videos guided by implicit instructions that encapsulate human intent and
temporal logic. Previous approaches leverage large vision language models
(LVLMs) to encode object semantics into <SEG> tokens for mask prediction.
However, this paradigm suffers from limited interpretability during inference
and suboptimal performance due to inadequate spatiotemporal reasoning. Drawing
inspiration from seminal breakthroughs in reinforcement learning, we introduce
Veason-R1, a specialized LVLM for VRS that emphasizes structured reasoning in
segmentation. Veason-R1 is trained through Group Relative Policy Optimization
(GRPO) augmented with Chain-of-Thought (CoT) initialization. To begin with, we
curate high-quality CoT training data to instill structured reasoning
trajectories, bridging video-level semantics and frame-level spatial grounding,
yielding the supervised fine-tuned model Veason-SFT. Subsequently, GRPO
fine-tuning encourages efficient exploration of the reasoning space by
optimizing reasoning chains. To this end, we incorporate a holistic reward
mechanism that synergistically enhances spatial alignment and temporal
consistency, bolstering keyframe localization and fine-grained grounding.
Comprehensive empirical evaluations demonstrate that Veason-R1 achieves
state-of-the-art performance on multiple benchmarks, surpassing prior art by
significant margins (e.g., +1.3 J &F in ReVOS and +10.0 J &F in ReasonVOS),
while exhibiting robustness to hallucinations (+8.8 R). Our code and model
weights will be available at Veason-R1.

</details>


### [88] [Training-Free Anomaly Generation via Dual-Attention Enhancement in Diffusion Model](https://arxiv.org/abs/2508.11550)
*Zuo Zuo,Jiahao Dong,Yanyun Qu,Zongze Wu*

Main category: cs.CV

TL;DR: 本文提出了基于Stable Diffusion的训练自由异常生成框架AAG，用于工业异常检测中的数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 解决工业异常检测中因异常数据不足而面临的挑战，通过引入一种无需额外训练数据的异常生成方法。

Method: 利用Stable Diffusion的生成能力，基于普通图像、掩膜和简单文本提示生成异常区域，并提出了交叉注意力增强（CAE）和自注意力增强（SAE）机制提升生成效果。

Result: 在MVTec AD和VisA数据集上的实验表明，AAG在异常生成和支持异常检查任务方面表现出色。

Conclusion: AAG框架不仅生成了自然且符合语义的异常，还提升了后续异常检测任务的性能，具有广泛应用价值。

Abstract: Industrial anomaly detection (AD) plays a significant role in manufacturing
where a long-standing challenge is data scarcity. A growing body of works have
emerged to address insufficient anomaly data via anomaly generation. However,
these anomaly generation methods suffer from lack of fidelity or need to be
trained with extra data. To this end, we propose a training-free anomaly
generation framework dubbed AAG, which is based on Stable Diffusion (SD)'s
strong generation ability for effective anomaly image generation. Given a
normal image, mask and a simple text prompt, AAG can generate realistic and
natural anomalies in the specific regions and simultaneously keep contents in
other regions unchanged. In particular, we propose Cross-Attention Enhancement
(CAE) to re-engineer the cross-attention mechanism within Stable Diffusion
based on the given mask. CAE increases the similarity between visual tokens in
specific regions and text embeddings, which guides these generated visual
tokens in accordance with the text description. Besides, generated anomalies
need to be more natural and plausible with object in given image. We propose
Self-Attention Enhancement (SAE) which improves similarity between each normal
visual token and anomaly visual tokens. SAE ensures that generated anomalies
are coherent with original pattern. Extensive experiments on MVTec AD and VisA
datasets demonstrate effectiveness of AAG in anomaly generation and its
utility. Furthermore, anomaly images generated by AAG can bolster performance
of various downstream anomaly inspection tasks.

</details>


### [89] [TrajSV: A Trajectory-based Model for Sports Video Representations and Applications](https://arxiv.org/abs/2508.11569)
*Zheng Wang,Shihao Xu,Wei Shi*

Main category: cs.CV

TL;DR: 本文提出了一个基于轨迹数据的框架TrajSV，通过三部分模块优化体育视频分析，达到了顶尖效果。


<details>
  <summary>Details</summary>
Motivation: 当前体育分析领域存在数据不可用、缺乏有效框架、监督标签需求高等问题。

Method: TrajSV框架由数据预处理、轨迹增强的Transformer模块（CRNet）和编码解码结构的VRNet组成，通过无监督的三重对比损失优化视频和片段表示。

Result: 在足球、篮球、排球的三个任务中（视频检索、动作检测、视频描述），TrajSV表现优异，其中视频检索效果提升近70%、动作检测中9/17类达到顶尖水平、视频描述改进近20%。

Conclusion: TrajSV为体育视频分析提供了先进的方法，并推出了基于此框架的部署系统。

Abstract: Sports analytics has received significant attention from both academia and
industry in recent years. Despite the growing interest and efforts in this
field, several issues remain unresolved, including (1) data unavailability, (2)
lack of an effective trajectory-based framework, and (3) requirement for
sufficient supervision labels. In this paper, we present TrajSV, a
trajectory-based framework that addresses various issues in existing studies.
TrajSV comprises three components: data preprocessing, Clip Representation
Network (CRNet), and Video Representation Network (VRNet). The data
preprocessing module extracts player and ball trajectories from sports
broadcast videos. CRNet utilizes a trajectory-enhanced Transformer module to
learn clip representations based on these trajectories. Additionally, VRNet
learns video representations by aggregating clip representations and visual
features with an encoder-decoder architecture. Finally, a triple contrastive
loss is introduced to optimize both video and clip representations in an
unsupervised manner. The experiments are conducted on three broadcast video
datasets to verify the effectiveness of TrajSV for three types of sports (i.e.,
soccer, basketball, and volleyball) with three downstream applications (i.e.,
sports video retrieval, action spotting, and video captioning). The results
demonstrate that TrajSV achieves state-of-the-art performance in sports video
retrieval, showcasing a nearly 70% improvement. It outperforms baselines in
action spotting, achieving state-of-the-art results in 9 out of 17 action
categories, and demonstrates a nearly 20% improvement in video captioning.
Additionally, we introduce a deployed system along with the three applications
based on TrajSV.

</details>


### [90] [Causality Matters: How Temporal Information Emerges in Video Language Models](https://arxiv.org/abs/2508.11576)
*Yumeng Shi,Quanyu Long,Yin Wu,Wenya Wang*

Main category: cs.CV

TL;DR: 本研究探讨了视频语言模型(VideoLMs)在时间理解方面的挑战，发现时间信息通过因果信息路径在注意力机制中隐式编码，并提出两种提高效率的策略。


<details>
  <summary>Details</summary>
Motivation: 视频语言模型在多模态理解中取得了进展，但其在时间理解(如事件顺序、持续时间和关系)上仍存在挑战。本研究旨在揭示时间信息是如何在模型中整合的，以寻求改进方向。

Method: 通过分析实验，追踪时间信息在模型中的整合路径，发现时间线索通过因果注意力机制逐步整合。基于此洞察，提出阶段性交叉模态注意力和早期标记截断的时间退出机制两种提高效率的策略。

Result: 实验表明，提出的两种策略在两个基准数据集上的表现有效，展示了其在时间理解方面的应用潜力。

Conclusion: 研究首次系统性地探讨了视频语言模型中的时间理解，并提出了高效的解决方案，为未来模型的改进提供了重要的实践指导。

Abstract: Video language models (VideoLMs) have made significant progress in multimodal
understanding. However, temporal understanding, which involves identifying
event order, duration, and relationships across time, still remains a core
challenge. Prior works emphasize positional encodings (PEs) as a key mechanism
for encoding temporal structure. Surprisingly, we find that removing or
modifying PEs in video inputs yields minimal degradation in the performance of
temporal understanding. In contrast, reversing the frame sequence while
preserving the original PEs causes a substantial drop. To explain this
behavior, we conduct substantial analysis experiments to trace how temporal
information is integrated within the model. We uncover a causal information
pathway: temporal cues are progressively synthesized through inter-frame
attention, aggregated in the final frame, and subsequently integrated into the
query tokens. This emergent mechanism shows that temporal reasoning emerges
from inter-visual token interactions under the constraints of causal attention,
which implicitly encodes temporal structure. Based on these insights, we
propose two efficiency-oriented strategies: staged cross-modal attention and a
temporal exit mechanism for early token truncation. Experiments on two
benchmarks validate the effectiveness of both approaches. To the best of our
knowledge, this is the first work to systematically investigate video temporal
understanding in VideoLMs, offering insights for future model improvement.

</details>


### [91] [DashCam Video: A complementary low-cost data stream for on-demand forest-infrastructure system monitoring](https://arxiv.org/abs/2508.11591)
*Durga Joshi,Chandi Witharana,Robert Fahey,Thomas Worthley,Zhe Zhu,Diego Cerrai*

Main category: cs.CV

TL;DR: 本文提出一个新颖、低成本的实时道路旁植被和基础设施结构评估与定位框架，利用常见行车记录仪视频数据，通过单目深度估算、深度误差校正和几何三角测量生成准确的空间与结构数据。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一种低成本、快速且可扩展的解决方案，用于动态城市环境中植被风险和基础设施暴露的实时监测。

Method: 开发了一套端到端管道，包括单目深度模型估算、梯度增强回归框架的深度校正以及基于GPS的三角定位与针孔摄像几何进行结构评估。

Result: 深度校正模型的预测性能较高（R2=0.92，MAE=0.31），定位误差为2.83m，高度估算误差为树木2.09m，杆件0.88m。

Conclusion: 首次结合单目深度建模、三角GPS定位与消费者级视频数据进行城市植被和基础设施结构评估，可补充传统方法如LiDAR，适用于快速、低成本的监测场景。

Abstract: Our study introduces a novel, low-cost, and reproducible framework for
real-time, object-level structural assessment and geolocation of roadside
vegetation and infrastructure with commonly available but underutilized
dashboard camera (dashcam) video data. We developed an end-to-end pipeline that
combines monocular depth estimation, depth error correction, and geometric
triangulation to generate accurate spatial and structural data from
street-level video streams from vehicle-mounted dashcams. Depth maps were first
estimated using a state-of-the-art monocular depth model, then refined via a
gradient-boosted regression framework to correct underestimations, particularly
for distant objects. The depth correction model achieved strong predictive
performance (R2 = 0.92, MAE = 0.31 on transformed scale), significantly
reducing bias beyond 15 m. Further, object locations were estimated using
GPS-based triangulation, while object heights were calculated using pin hole
camera geometry. Our method was evaluated under varying conditions of camera
placement and vehicle speed. Low-speed vehicle with inside camera gave the
highest accuracy, with mean geolocation error of 2.83 m, and mean absolute
error (MAE) in height estimation of 2.09 m for trees and 0.88 m for poles. To
the best of our knowledge, it is the first framework to combine monocular depth
modeling, triangulated GPS-based geolocation, and real-time structural
assessment for urban vegetation and infrastructure using consumer-grade video
data. Our approach complements conventional RS methods, such as LiDAR and image
by offering a fast, real-time, and cost-effective solution for object-level
monitoring of vegetation risks and infrastructure exposure, making it
especially valuable for utility companies, and urban planners aiming for
scalable and frequent assessments in dynamic urban environments.

</details>


### [92] [CoreEditor: Consistent 3D Editing via Correspondence-constrained Diffusion](https://arxiv.org/abs/2508.11603)
*Zhe Zhu,Honghua Chen,Peng Li,Mingqiang Wei*

Main category: cs.CV

TL;DR: 本文提出了一种新的框架-CoreEditor，用于实现一致性的文本驱动3D编辑。其核心创新在于一种约束对应的注意力机制，从而增强跨视图一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本驱动3D编辑方法难以保持视点一致性，导致编辑效果不足且细节模糊。

Method: 提出了一种基于对应约束的注意力机制，同时融合几何对齐与语义相似性，确保更可靠的多视图编辑。另外设计了一个选择性编辑流程，用户可以从多个候选结果中选择最满意的结果。

Result: 实验结果表明，CoreEditor生成的编辑效果更高质量，视图一致性更好，细节更清晰，显著优于现有方法。

Conclusion: CoreEditor通过结合几何与语义信息，以及灵活的用户控制机制，为文本驱动3D编辑提供了全新、更优性能的解决方案。

Abstract: Text-driven 3D editing seeks to modify 3D scenes according to textual
descriptions, and most existing approaches tackle this by adapting pre-trained
2D image editors to multi-view inputs. However, without explicit control over
multi-view information exchange, they often fail to maintain cross-view
consistency, leading to insufficient edits and blurry details. We introduce
CoreEditor, a novel framework for consistent text-to-3D editing. The key
innovation is a correspondence-constrained attention mechanism that enforces
precise interactions between pixels expected to remain consistent throughout
the diffusion denoising process. Beyond relying solely on geometric alignment,
we further incorporate semantic similarity estimated during denoising, enabling
more reliable correspondence modeling and robust multi-view editing. In
addition, we design a selective editing pipeline that allows users to choose
preferred results from multiple candidates, offering greater flexibility and
user control. Extensive experiments show that CoreEditor produces high-quality,
3D-consistent edits with sharper details, significantly outperforming prior
methods.

</details>


### [93] [LoRAtorio: An intrinsic approach to LoRA Skill Composition](https://arxiv.org/abs/2508.11624)
*Niki Foteinopoulou,Ignas Budvytis,Stephan Liwicki*

Main category: cs.CV

TL;DR: 提出了一种新的无训练框架LoRAtorio，用于多LoRA组合，通过利用模型的内在行为实现表现优化，展示了其在多种领域中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA方法难以在开放场景中有效组合多个LoRA适配器，因此需要一种方法来解决这些问题。

Method: 提出LoRAtorio框架，通过在潜在空间分割成空间patch并计算余弦相似性构造加权矩阵，从而解决域漂移问题并优化LoRA组合性能。

Result: 实验表明LoRAtorio达到了先进水平，ClipScore提高1.3%，在GPT-4V评价中具有72.43%的胜率，并且可扩展到多个潜在扩散模型。

Conclusion: LoRAtorio提供了一种有效的多LoRA组合方法，为动态模块选择和领域转换提供了新的可能性。

Abstract: Low-Rank Adaptation (LoRA) has become a widely adopted technique in
text-to-image diffusion models, enabling the personalisation of visual concepts
such as characters, styles, and objects. However, existing approaches struggle
to effectively compose multiple LoRA adapters, particularly in open-ended
settings where the number and nature of required skills are not known in
advance. In this work, we present LoRAtorio, a novel train-free framework for
multi-LoRA composition that leverages intrinsic model behaviour. Our method is
motivated by two key observations: (1) LoRA adapters trained on narrow domains
produce denoised outputs that diverge from the base model, and (2) when
operating out-of-distribution, LoRA outputs show behaviour closer to the base
model than when conditioned in distribution. The balance between these two
observations allows for exceptional performance in the single LoRA scenario,
which nevertheless deteriorates when multiple LoRAs are loaded. Our method
operates in the latent space by dividing it into spatial patches and computing
cosine similarity between each patch's predicted noise and that of the base
model. These similarities are used to construct a spatially-aware weight
matrix, which guides a weighted aggregation of LoRA outputs. To address domain
drift, we further propose a modification to classifier-free guidance that
incorporates the base model's unconditional score into the composition. We
extend this formulation to a dynamic module selection setting, enabling
inference-time selection of relevant LoRA adapters from a large pool. LoRAtorio
achieves state-of-the-art performance, showing up to a 1.3% improvement in
ClipScore and a 72.43% win rate in GPT-4V pairwise evaluations, and generalises
effectively to multiple latent diffusion models.

</details>


### [94] [Thyme: Think Beyond Images](https://arxiv.org/abs/2508.11630)
*Yi-Fan Zhang,Xingyu Lu,Shukang Yin,Chaoyou Fu,Wei Chen,Xiao Hu,Bin Wen,Kaiyu Jiang,Changyi Liu,Tianke Zhang,Haonan Fan,Kaibing Chen,Jiankang Chen,Haojie Ding,Kaiyu Tang,Zhang Zhang,Liang Wang,Fan Yang,Tingting Gao,Guorui Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为Thyme的新范式，使多模态语言模型（MLLMs）通过可执行代码实现丰富的图像处理和计算功能，从而超越现有的“图像思考”方法。


<details>
  <summary>Details</summary>
Motivation: 目前开源模型在视觉信息与逻辑推理结合的能力上不及专有模型，作者旨在填补这一空白，以提升模型在高难度感知和复杂推理任务中的表现。

Method: 本文采用两阶段训练策略：首先使用经过精心策划的50万样本数据集进行代码生成的初始监督微调（SFT），然后通过强化学习阶段提升决策能力。此过程中设计了一个名为GRPO-ATS的算法，对文本和代码生成应用不同的温度采样以实现平衡。

Result: 通过接近20个基准的全面评估，Thyme在高分辨率感知和复杂推理任务中展示了显著且一致的性能提升。

Conclusion: Thyme为多模态模型引入了以代码生成和复杂推理整合为基础的新可能性，展示了丰富的图像处理能力和逻辑推理能力，同时具备在高难度任务中的卓越表现。

Abstract: Following OpenAI's introduction of the ``thinking with images'' concept,
recent efforts have explored stimulating the use of visual information in the
reasoning process to enhance model performance in perception and reasoning
tasks. However, to the best of our knowledge, no open-source work currently
offers a feature set as rich as proprietary models (O3), which can perform
diverse image manipulations and simultaneously enhance logical reasoning
capabilities through code. In this paper, we make a preliminary attempt in this
direction by introducing Thyme (Think Beyond Images), a novel paradigm for
enabling MLLMs to transcend existing ``think with images'' approaches by
autonomously generating and executing diverse image processing and
computational operations via executable code. This approach not only
facilitates a rich, on-the-fly set of image manipulations (e.g., cropping,
rotation, contrast enhancement) but also allows for mathematical computations,
all while maintaining high autonomy in deciding when and how to apply these
operations. We activate this capability through a two-stage training strategy:
an initial SFT on a curated dataset of 500K samples to teach code generation,
followed by a RL phase to refine decision-making. For the RL stage, we manually
collect and design high-resolution question-answer pairs to increase the
learning difficulty, and we propose GRPO-ATS (Group Relative Policy
Optimization with Adaptive Temperature Sampling), an algorithm that applies
distinct temperatures to text and code generation to balance reasoning
exploration with code execution precision. We conduct extensive experimental
analysis and ablation studies. Comprehensive evaluations on nearly 20
benchmarks show that Thyme yields significant and consistent performance gains,
particularly in challenging high-resolution perception and complex reasoning
tasks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [95] [A2HCoder: An LLM-Driven Coding Agent for Hierarchical Algorithm-to-HDL Translation](https://arxiv.org/abs/2508.10904)
*Jie Lei,Ruofan Jia,J. Andrew Zhang,Hao Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为A2HCoder的分层算法到HDL代码生成代理，利用大规模语言模型实现高效的算法到硬件转换。


<details>
  <summary>Details</summary>
Motivation: 当前算法设计与硬件实现之间存在巨大鸿沟，传统方法需要大量领域知识和开发时间来弥合差距。

Method: A2HCoder通过分层框架引入水平和垂直维度的翻译方法：水平分解复杂算法为模块化功能块，简化代码生成；垂直采用逐步、细致翻译和外部工具链调试，减少语言模型代码生成中的错误。

Result: 在5G无线通信领域的实际案例中验证了其实用性、可靠性和高效性。

Conclusion: A2HCoder显著提高了算法到硬件转换的效率和准确性，在无线通信系统等领域具有广泛应用前景。

Abstract: In wireless communication systems, stringent requirements such as ultra-low
latency and power consumption have significantly increased the demand for
efficient algorithm-to-hardware deployment. However, a persistent and
substantial gap remains between algorithm design and hardware implementation.
Bridging this gap traditionally requires extensive domain expertise and
time-consuming manual development, due to fundamental mismatches between
high-level programming languages like MATLAB and hardware description languages
(HDLs) such as Verilog-in terms of memory access patterns, data processing
manners, and datatype representations. To address this challenge, we propose
A2HCoder: a Hierarchical Algorithm-to-HDL Coding Agent, powered by large
language models (LLMs), designed to enable agile and reliable
algorithm-to-hardware translation. A2HCoder introduces a hierarchical framework
that enhances both robustness and interpretability while suppressing common
hallucination issues in LLM-generated code. In the horizontal dimension,
A2HCoder decomposes complex algorithms into modular functional blocks,
simplifying code generation and improving consistency. In the vertical
dimension, instead of relying on end-to-end generation, A2HCoder performs
step-by-step, fine-grained translation, leveraging external toolchains such as
MATLAB and Vitis HLS for debugging and circuit-level synthesis. This structured
process significantly mitigates hallucinations and ensures hardware-level
correctness. We validate A2HCoder through a real-world deployment case in the
5G wireless communication domain, demonstrating its practicality, reliability,
and deployment efficiency.

</details>


### [96] [PersonaTwin: A Multi-Tier Prompt Conditioning Framework for Generating and Evaluating Personalized Digital Twins](https://arxiv.org/abs/2508.10906)
*Sihan Chen,John P. Lalor,Yi Yang,Ahmed Abbasi*

Main category: cs.CL

TL;DR: 本文提出PersonaTwin框架，以基于LLMs的多层提示条件，结合人口统计、行为和心理测量数据，为用户建模以生成高保真度和公平的数字孪生。


<details>
  <summary>Details</summary>
Motivation: LLMs虽然有可能建模用户行为，但很难捕捉用户的多维特性。本研究旨在开发一种框架，以改进LLMs在用户建模中的精度和公平性。

Method: 提出PersonaTwin多层提示框架，结合人口统计、行为和心理测量数据，根据8500+人的医疗数据，对其输出与标准LLM进行全面对比，使用最新文本相似性指标和人口统计公平性评价指标评估模型性能。

Result: 实验结果表明，PersonaTwin的模拟精准度达到专家设定水平，且下游模型的预测和公平性表现接近个人训练模型，适用于GPT-4o与Llama模型。

Conclusion: PersonaTwin框架能够生成公平、准确且情感丰富的用户模拟，为个性化用户建模和行为分析提供了强大的支持。

Abstract: While large language models (LLMs) afford new possibilities for user modeling
and approximation of human behaviors, they often fail to capture the
multidimensional nuances of individual users. In this work, we introduce
PersonaTwin, a multi-tier prompt conditioning framework that builds adaptive
digital twins by integrating demographic, behavioral, and psychometric data.
Using a comprehensive data set in the healthcare context of more than 8,500
individuals, we systematically benchmark PersonaTwin against standard LLM
outputs, and our rigorous evaluation unites state-of-the-art text similarity
metrics with dedicated demographic parity assessments, ensuring that generated
responses remain accurate and unbiased. Experimental results show that our
framework produces simulation fidelity on par with oracle settings. Moreover,
downstream models trained on persona-twins approximate models trained on
individuals in terms of prediction and fairness metrics across both
GPT-4o-based and Llama-based models. Together, these findings underscore the
potential for LLM digital twin-based approaches in producing realistic and
emotionally nuanced user simulations, offering a powerful tool for personalized
digital user modeling and behavior analysis.

</details>


### [97] [gpt-oss-120b & gpt-oss-20b Model Card](https://arxiv.org/abs/2508.10925)
*OpenAI,:,Sandhini Agarwal,Lama Ahmad,Jason Ai,Sam Altman,Andy Applebaum,Edwin Arbus,Rahul K. Arora,Yu Bai,Bowen Baker,Haiming Bao,Boaz Barak,Ally Bennett,Tyler Bertao,Nivedita Brett,Eugene Brevdo,Greg Brockman,Sebastien Bubeck,Che Chang,Kai Chen,Mark Chen,Enoch Cheung,Aidan Clark,Dan Cook,Marat Dukhan,Casey Dvorak,Kevin Fives,Vlad Fomenko,Timur Garipov,Kristian Georgiev,Mia Glaese,Tarun Gogineni,Adam Goucher,Lukas Gross,Katia Gil Guzman,John Hallman,Jackie Hehir,Johannes Heidecke,Alec Helyar,Haitang Hu,Romain Huet,Jacob Huh,Saachi Jain,Zach Johnson,Chris Koch,Irina Kofman,Dominik Kundel,Jason Kwon,Volodymyr Kyrylov,Elaine Ya Le,Guillaume Leclerc,James Park Lennon,Scott Lessans,Mario Lezcano-Casado,Yuanzhi Li,Zhuohan Li,Ji Lin,Jordan Liss,Lily,Liu,Jiancheng Liu,Kevin Lu,Chris Lu,Zoran Martinovic,Lindsay McCallum,Josh McGrath,Scott McKinney,Aidan McLaughlin,Song Mei,Steve Mostovoy,Tong Mu,Gideon Myles,Alexander Neitz,Alex Nichol,Jakub Pachocki,Alex Paino,Dana Palmie,Ashley Pantuliano,Giambattista Parascandolo,Jongsoo Park,Leher Pathak,Carolina Paz,Ludovic Peran,Dmitry Pimenov,Michelle Pokrass,Elizabeth Proehl,Huida Qiu,Gaby Raila,Filippo Raso,Hongyu Ren,Kimmy Richardson,David Robinson,Bob Rotsted,Hadi Salman,Suvansh Sanjeev,Max Schwarzer,D. Sculley,Harshit Sikchi,Kendal Simon,Karan Singhal,Yang Song,Dane Stuckey,Zhiqing Sun,Philippe Tillet,Sam Toizer,Foivos Tsimpourlas,Nikhil Vyas,Eric Wallace,Xin Wang,Miles Wang,Olivia Watkins,Kevin Weil,Amy Wendling,Kevin Whinnery,Cedric Whitney,Hannah Wong,Lin Yang,Yu Yang,Michihiro Yasunaga,Kristen Ying,Wojciech Zaremba,Wenting Zhan,Cyril Zhang,Brian Zhang,Eddie Zhang,Shengjia Zhao*

Main category: cs.CL

TL;DR: 本文介绍了gpt-oss-120b和gpt-oss-20b两个开源的推理模型，使用混合专家架构，支持高效推断，具备开放权重并自由分发。


<details>
  <summary>Details</summary>
Motivation: 开发更加高效和准确的推理模型，特别是在深度研究浏览、编程工具使用等方面表现卓越。

Method: 采用混合专家transformer架构，通过大规模的蒸馏和强化学习训练，支持明确指令和角色分工，以及开发者定义函数。

Result: 模型在数学、编程和安全性等基准上表现优异，同时支持Apache 2.0许可证下的广泛使用和进一步研究。

Conclusion: gpt-oss-120b和gpt-oss-20b展示了性能与推理成本的新高度，为未来的研究和实际应用提供了开放的技术基础。

Abstract: We present gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models
that push the frontier of accuracy and inference cost. The models use an
efficient mixture-of-expert transformer architecture and are trained using
large-scale distillation and reinforcement learning. We optimize the models to
have strong agentic capabilities (deep research browsing, python tool use, and
support for developer-provided functions), all while using a rendered chat
format that enables clear instruction following and role delineation. Both
models achieve strong results on benchmarks ranging from mathematics, coding,
and safety. We release the model weights, inference implementations, tool
environments, and tokenizers under an Apache 2.0 license to enable broad use
and further research.

</details>


### [98] [Modeling and Detecting Company Risks from News: A Case Study in Bloomberg News](https://arxiv.org/abs/2508.10927)
*Jiaxin Pei,Soumya Vadlamannati,Liang-Kang Huang,Daniel Preotiuc-Pietro,Xinyu Hua*

Main category: cs.CL

TL;DR: 本研究提出了一个计算框架，从新闻文章中自动提取公司风险因素，分析了大规模语言模型和微调模型在这一任务上的表现，并应用模型分析了27.7万篇新闻文章。


<details>
  <summary>Details</summary>
Motivation: 帮助投资者和金融市场了解公司的风险因素，从而提高决策信息透明度。

Method: 建立了包含七个方面（如供应链、法规、竞争等）的风险分类体系，采样和标注了744篇新闻文章，比较了多种机器学习模型的表现。

Result: 发现大型语言模型（如LLaMA-2）在零样本和少样本任务上的表现有限，经过微调的预训练语言模型更具优势，同时使用模型分析了27.7万篇彭博新闻文章。

Conclusion: 微调模型在识别新闻中的公司风险因素表现更优，风险识别可为公司和行业运营提供广泛的见解。

Abstract: Identifying risks associated with a company is important to investors and the
well-being of the overall financial market. In this study, we build a
computational framework to automatically extract company risk factors from news
articles. Our newly proposed schema comprises seven distinct aspects, such as
supply chain, regulations, and competitions. We sample and annotate 744 news
articles and benchmark various machine learning models. While large language
models have achieved huge progress in various types of NLP tasks, our
experiment shows that zero-shot and few-shot prompting state-of-the-art LLMs
(e.g. LLaMA-2) can only achieve moderate to low performances in identifying
risk factors. And fine-tuned pre-trained language models are performing better
on most of the risk factors. Using this model, we analyze over 277K Bloomberg
news articles and demonstrate that identifying risk factors from news could
provide extensive insight into the operations of companies and industries.

</details>


### [99] [Rule2Text: A Framework for Generating and Evaluating Natural Language Explanations of Knowledge Graph Rules](https://arxiv.org/abs/2508.10971)
*Nasim Shirvani-Mahdavi,Chengkai Li*

Main category: cs.CL

TL;DR: 提出了Rule2Text框架，利用大语言模型（LLMs）为知识图谱生成自然语言解释，从而提升其可访问性和可用性。


<details>
  <summary>Details</summary>
Motivation: 解决知识图谱中规则复杂性及标签惯例导致的难以解释问题，增强其可读性和实用性。

Method: 通过结合多种数据集、AMIE 3.5.1挖掘规则，采用多种提示策略对LLM进行系统评估，并引入LLM-as-a-judge框架和领域调优模型。

Result: 调优后模型在解释质量上显著提升，并在特定领域数据集中表现尤为突出。

Conclusion: Rule2Text的框架可有效改进知识图谱规则的自然语言解释质量，代码和数据已公开发布。

Abstract: Knowledge graphs (KGs) can be enhanced through rule mining; however, the
resulting logical rules are often difficult for humans to interpret due to
their inherent complexity and the idiosyncratic labeling conventions of
individual KGs. This work presents Rule2Text, a comprehensive framework that
leverages large language models (LLMs) to generate natural language
explanations for mined logical rules, thereby improving KG accessibility and
usability. We conduct extensive experiments using multiple datasets, including
Freebase variants (FB-CVT-REV, FB+CVT-REV, and FB15k-237) as well as the
ogbl-biokg dataset, with rules mined using AMIE 3.5.1. We systematically
evaluate several LLMs across a comprehensive range of prompting strategies,
including zero-shot, few-shot, variable type incorporation, and
Chain-of-Thought reasoning. To systematically assess models' performance, we
conduct a human evaluation of generated explanations on correctness and
clarity. To address evaluation scalability, we develop and validate an
LLM-as-a-judge framework that demonstrates strong agreement with human
evaluators. Leveraging the best-performing model (Gemini 2.0 Flash), LLM judge,
and human-in-the-loop feedback, we construct high-quality ground truth
datasets, which we use to fine-tune the open-source Zephyr model. Our results
demonstrate significant improvements in explanation quality after fine-tuning,
with particularly strong gains in the domain-specific dataset. Additionally, we
integrate a type inference module to support KGs lacking explicit type
information. All code and data are publicly available at
https://github.com/idirlab/KGRule2NL.

</details>


### [100] [Improving Text Style Transfer using Masked Diffusion Language Models with Inference-time Scaling](https://arxiv.org/abs/2508.10995)
*Tejomay Kishor Padole,Suyash P Awate,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 本论文提出了一种基于验证器的推理时间缩放方法，优化了蒙面扩散语言模型 (MDMs) 在文本生成过程中的性能，并验证了其在文本风格转换任务中的优越表现。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在提高生成质量方面展示了潜力，但其在离散数据生成中的应用仍需探索，尤其是如何通过推理时优化进一步提高结果质量。

Method: 引入一种基于软值验证器的推理时间缩放方法，利用预训练嵌入模型，结合现有的无分类器指导生成，提高MDMs生成质量。

Result: 实验表明，所提出的方法在标准文本风格转换任务中显著提升了生成质量，与传统自回归语言模型相比表现优异。

Conclusion: 提议的基于验证器的优化方法，为MDMs提供了一种高效的推理时间增强策略，进一步巩固了其作为非自回归离散数据生成模型的地位。

Abstract: Masked diffusion language models (MDMs) have recently gained traction as a
viable generative framework for natural language. This can be attributed to its
scalability and ease of training compared to other diffusion model paradigms
for discrete data, establishing itself as the state-of-the-art
non-autoregressive generator for discrete data. Diffusion models, in general,
have shown excellent ability to improve the generation quality by leveraging
inference-time scaling either by increasing the number of denoising steps or by
using external verifiers on top of the outputs of each step to guide the
generation. In this work, we propose a verifier-based inference-time scaling
method that aids in finding a better candidate generation during the denoising
process of the MDM. Our experiments demonstrate the application of MDMs for
standard text-style transfer tasks and establish MDMs as a better alternative
to autoregressive language models. Additionally, we show that a simple
soft-value-based verifier setup for MDMs using off-the-shelf pre-trained
embedding models leads to significant gains in generation quality even when
used on top of typical classifier-free guidance setups in the existing
literature.

</details>


### [101] [SproutBench: A Benchmark for Safe and Ethical Large Language Models for Youth](https://arxiv.org/abs/2508.11009)
*Wenpeng Xing,Lanyi Wei,Haixiao Hu,Rongchang Li,Mohan Li,Changting Lin,Meng Han*

Main category: cs.CL

TL;DR: 本文探讨大语言模型（LLMs）在面向儿童和青少年应用时存在的安全问题，提出并研发了SproutBench评价框架，以弥补现有安全性基准的缺陷。


<details>
  <summary>Details</summary>
Motivation: 由于现有AI安全框架主要针对成人用户，忽视了未成年人的认知、情感和社会发展脆弱性，因此需要重新评估以确保儿童和青少年的安全性。

Method: 本文通过开发SproutBench，包括1283个具有发展相关性的对抗性提示，评估大语言模型在应对情感依赖、隐私泄露和危险行为模仿等方面的安全性。

Result: 通过对47种不同模型的实证评估，发现现有模型在安全性方面存在显著漏洞，同时揭示了安全性与风险预防之间的相关性，以及交互性与年龄适宜性之间的反比关系。

Conclusion: 提出了推动以儿童为中心的AI设计和部署的实践指南，并强调在开发LLMs时需要更关注未成年人的独特需求和风险。

Abstract: The rapid proliferation of large language models (LLMs) in applications
targeting children and adolescents necessitates a fundamental reassessment of
prevailing AI safety frameworks, which are largely tailored to adult users and
neglect the distinct developmental vulnerabilities of minors. This paper
highlights key deficiencies in existing LLM safety benchmarks, including their
inadequate coverage of age-specific cognitive, emotional, and social risks
spanning early childhood (ages 0--6), middle childhood (7--12), and adolescence
(13--18). To bridge these gaps, we introduce SproutBench, an innovative
evaluation suite comprising 1,283 developmentally grounded adversarial prompts
designed to probe risks such as emotional dependency, privacy violations, and
imitation of hazardous behaviors. Through rigorous empirical evaluation of 47
diverse LLMs, we uncover substantial safety vulnerabilities, corroborated by
robust inter-dimensional correlations (e.g., between Safety and Risk
Prevention) and a notable inverse relationship between Interactivity and Age
Appropriateness. These insights yield practical guidelines for advancing
child-centric AI design and deployment.

</details>


### [102] [Beyond the Rosetta Stone: Unification Forces in Generalization Dynamics](https://arxiv.org/abs/2508.11017)
*Carter Blum,Katja Filipova,Ann Yuan,Asma Ghandeharioun,Julian Zimmert,Fred Zhang,Jessica Hoffmann,Tal Linzen,Martin Wattenberg,Lucas Dixon,Mor Geva*

Main category: cs.CL

TL;DR: 研究表明，语言模型在跨语言知识转移中会出现错误陈述现象，通过建立受控环境研究这个问题，并提出了改进跨语言转移的方法与度量工具。


<details>
  <summary>Details</summary>
Motivation: 语言模型在跨语言知识转移时表现不佳，存在对不同语言事实偏执不统一的问题。

Method: 通过构建合成多语言数据集，训练小型Transformer模型，从控制变量的角度分析跨语言知识转移，提出数据分布和分词上的改进方法。

Result: 发现模型需要统一跨语言的事实表示，这依赖于事实与语言训练数据之间的信息量。同时引入可视化工具和度量指标来分析这些因素。

Conclusion: 本研究揭示了跨语言知识转移中预训练动态的本质，并为提高这种能力提供了新方向。

Abstract: Large language models (LLMs) struggle with cross-lingual knowledge transfer:
they hallucinate when asked in one language about facts expressed in a
different language during training. This work introduces a controlled setting
to study the causes and dynamics of this phenomenon by training small
Transformer models from scratch on synthetic multilingual datasets. We identify
a learning phase wherein a model develops either separate or unified
representations of the same facts across languages, and show that unification
is essential for cross-lingual transfer. We also show that the degree of
unification depends on mutual information between facts and training data
language, and on how easy it is to extract that language. Based on these
insights, we develop methods to modulate the level of cross-lingual transfer by
manipulating data distribution and tokenization, and we introduce metrics and
visualizations to formally characterize their effects on unification. Our work
shows how controlled settings can shed light on pre-training dynamics and
suggests new directions for improving cross-lingual transfer in LLMs.

</details>


### [103] [Hell or High Water: Evaluating Agentic Recovery from External Failures](https://arxiv.org/abs/2508.11027)
*Andrew Wang,Sophia Hager,Adi Asija,Daniel Khashabi,Nicholas Andrews*

Main category: cs.CL

TL;DR: 论文提出一个针对语言模型代理人进行计划测试的基准，研究其在面对外部失败时的应对能力，发现当前模型难以适应环境反馈并制定备选计划。


<details>
  <summary>Details</summary>
Motivation: 为了解决日益复杂的实际问题，语言模型代理人需要在广阔搜索空间内制定计划，并在执行计划失败时寻找替代方案。研究目前的模型在这种场景中的表现和局限性。

Method: 提出一个特殊的计划基准，其中包括超过4000个函数，模型需要在外部失败（如函数不可用）的情况下，通过环境反馈继续完成任务。

Result: 发现当前的最先进模型在确定正确的函数组合方面表现良好，但在面对环境反馈时难以调整计划并探索替代路线，即使搜索空间已被缩小。

Conclusion: 目前的生成模型在应对外部失败时表现不佳，这揭示了当前模型的关键挑战，同时指出了改进生成模型在复杂任务中适应能力的未来研究方向。

Abstract: As language model agents are applied to real world problems of increasing
complexity, they will be expected to formulate plans across large search
spaces. If those plans fail for reasons beyond their control, how well do
language agents search for alternative ways to achieve their goals? We devise a
specialized agentic planning benchmark to study this question. Each planning
problem is solved via combinations of function calls. The agent searches for
relevant functions from a set of over four thousand possibilities, and observes
environmental feedback in the form of function outputs or error messages. Our
benchmark confronts the agent with external failures in its workflow, such as
functions that suddenly become unavailable. At the same time, even with the
introduction of these failures, we guarantee that the task remains solvable.
Ideally, an agent's performance on the planning task should not be affected by
the presence of external failures. Overall, we find that language agents
struggle to formulate and execute backup plans in response to environment
feedback. While state-of-the-art models are often able to identify the correct
function to use in the right context, they struggle to adapt to feedback from
the environment and often fail to pursue alternate courses of action, even when
the search space is artificially restricted. We provide a systematic analysis
of the failures of both open-source and commercial models, examining the
effects of search space size, as well as the benefits of scaling model size in
our setting. Our analysis identifies key challenges for current generative
models as well as promising directions for future work.

</details>


### [104] [BIPOLAR: Polarization-based granular framework for LLM bias evaluation](https://arxiv.org/abs/2508.11061)
*Martin Pavlíček,Tomáš Filip,Petr Sosík*

Main category: cs.CL

TL;DR: 提出一个可以检测和分析大语言模型在极化相关偏差的框架，并展示其在不同模型和语境下的表现差异。


<details>
  <summary>Details</summary>
Motivation: 深入研究现有大语言模型的偏差问题，为解决极化相关偏见提供更通用和细粒度的评估方法。

Method: 设计一个结合极化敏感情感指标和合成平衡数据集的方法，同时考察用不同语义分类评估的偏差表现。

Result: 基于俄罗斯与乌克兰相关话题的数据集测试了多种LLM，发现总体对乌克兰更为正面，但在不同语义类别之间表现存在显著差异。

Conclusion: 该框架能够自动化数据生成及细粒度偏差评估，适用于多个极化话题，并补充其他偏差评估策略。

Abstract: Large language models (LLMs) are known to exhibit biases in downstream tasks,
especially when dealing with sensitive topics such as political discourse,
gender identity, ethnic relations, or national stereotypes. Although
significant progress has been made in bias detection and mitigation techniques,
certain challenges remain underexplored. This study proposes a reusable,
granular, and topic-agnostic framework to evaluate polarisation-related biases
in LLM (both open-source and closed-source). Our approach combines
polarisation-sensitive sentiment metrics with a synthetically generated
balanced dataset of conflict-related statements, using a predefined set of
semantic categories.
  As a case study, we created a synthetic dataset that focusses on the
Russia-Ukraine war, and we evaluated the bias in several LLMs: Llama-3,
Mistral, GPT-4, Claude 3.5, and Gemini 1.0. Beyond aggregate bias scores, with
a general trend for more positive sentiment toward Ukraine, the framework
allowed fine-grained analysis with considerable variation between semantic
categories, uncovering divergent behavioural patterns among models. Adaptation
to prompt modifications showed further bias towards preconceived language and
citizenship modification.
  Overall, the framework supports automated dataset generation and fine-grained
bias assessment, is applicable to a variety of polarisation-driven scenarios
and topics, and is orthogonal to many other bias-evaluation strategies.

</details>


### [105] [Approaching the Source of Symbol Grounding with Confluent Reductions of Abstract Meaning Representation Directed Graphs](https://arxiv.org/abs/2508.11068)
*Nicolas Goulet,Alexandre Blondin Massé,Moussa Abdendi*

Main category: cs.CL

TL;DR: 本论文提出一种将数字词典嵌入到抽象语义图(AMR)的技术，并通过缩减与符号绑定问题进行讨论。


<details>
  <summary>Details</summary>
Motivation: 探讨如何将真实的数字字典与AMR图结合，以解决符号绑定问题。

Method: 利用预训练的大型语言模型将数字字典嵌入AMR图中，并通过保持电路空间的转换规约这些图。

Result: 得到经过规约的AMR图并分析这些图的特性及其与符号绑定问题的关系。

Conclusion: 展示了嵌入和规约技术如何在AMR图中实现，并进一步推进了对符号绑定问题的理解。

Abstract: Abstract meaning representation (AMR) is a semantic formalism used to
represent the meaning of sentences as directed acyclic graphs. In this paper,
we describe how real digital dictionaries can be embedded into AMR directed
graphs (digraphs), using state-of-the-art pre-trained large language models.
Then, we reduce those graphs in a confluent manner, i.e. with transformations
that preserve their circuit space. Finally, the properties of these reduces
digraphs are analyzed and discussed in relation to the symbol grounding
problem.

</details>


### [106] [Towards Reliable Multi-Agent Systems for Marketing Applications via Reflection, Memory, and Planning](https://arxiv.org/abs/2508.11120)
*Lorenzo Jaime Yu Flores,Junyi Shen,Xiaoyuan Gu*

Main category: cs.CL

TL;DR: 介绍了一种适用于营销任务的多智能体系统RAMP，利用大语言模型进行受众策划，并通过验证、反思等方式提高了准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在复杂任务中的可靠性，特别是对其在真实世界中的应用。

Method: 提出了一种名为RAMP的框架，结合大语言模型的规划和记忆能力，并加入一个客户特定知识库，用于长期存储。采用迭代验证和改进的方式提升系统效果。

Result: 在88个测试查询中准确率提高了28个百分点。在更复杂的任务中，迭代验证反思提高了约20个百分点的召回率，并显著提升了用户满意度。

Conclusion: 通过该研究提供了如何在动态、行业导向环境中部署可靠的大语言模型系统的实用价值。

Abstract: Recent advances in large language models (LLMs) enabled the development of AI
agents that can plan and interact with tools to complete complex tasks.
However, literature on their reliability in real-world applications remains
limited. In this paper, we introduce a multi-agent framework for a marketing
task: audience curation. To solve this, we introduce a framework called RAMP
that iteratively plans, calls tools, verifies the output, and generates
suggestions to improve the quality of the audience generated. Additionally, we
equip the model with a long-term memory store, which is a knowledge base of
client-specific facts and past queries. Overall, we demonstrate the use of LLM
planning and memory, which increases accuracy by 28 percentage points on a set
of 88 evaluation queries. Moreover, we show the impact of iterative
verification and reflection on more ambiguous queries, showing progressively
better recall (roughly +20 percentage points) with more verify/reflect
iterations on a smaller challenge set, and higher user satisfaction. Our
results provide practical insights for deploying reliable LLM-based systems in
dynamic, industry-facing environments.

</details>


### [107] [MoNaCo: More Natural and Complex Questions for Reasoning Across Dozens of Documents](https://arxiv.org/abs/2508.11133)
*Tomer Wolfson,Harsh Trivedi,Mor Geva,Yoav Goldberg,Dan Roth,Tushar Khot,Ashish Sabharwal,Reut Tsarfaty*

Main category: cs.CL

TL;DR: 论文介绍了一个名为MoNaCo的新基准，用于评估复杂且耗时问题的问答能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型基准无法充分评估对复杂和耗时问题的回答能力，MoNaCo填补了这一空白。

Method: 开发了一种分解注释流水线，生成了1,315个复杂问题，并手动回答以构建MoNaCo基准；然后用现有最前沿的语言模型进行评估。

Result: 现有模型在MoNaCo上最多只能达到61.2%的F1值，受限于低召回率和幻觉问题。

Conclusion: MoNaCo基准表明，当前模型需要更好的推理能力来处理真实世界中复杂的查询任务。

Abstract: Large language models (LLMs) are emerging as a go-to tool for querying
information. However, current LLM benchmarks rarely feature natural questions
that are both information-seeking as well as genuinely time-consuming for
humans. To address this gap we introduce MoNaCo, a benchmark of 1,315 natural
and complex questions that require dozens, and at times hundreds, of
intermediate steps to solve -- far more than any existing QA benchmark. To
build MoNaCo, we developed a decomposed annotation pipeline to elicit and
manually answer natural time-consuming questions at scale. Frontier LLMs
evaluated on MoNaCo achieve at most 61.2% F1, hampered by low recall and
hallucinations. Our results underscore the need for reasoning models that
better handle the complexity and sheer breadth of real-world
information-seeking questions -- with MoNaCo providing an effective resource
for tracking such progress. The MONACO benchmark, codebase, prompts and models
predictions are publicly available at: https://tomerwolgithub.github.io/monaco

</details>


### [108] [MobQA: A Benchmark Dataset for Semantic Understanding of Human Mobility Data through Question Answering](https://arxiv.org/abs/2508.11163)
*Hikaru Asano,Hiroki Ouchi,Akira Kasuga,Ryo Yonetani*

Main category: cs.CL

TL;DR: 提出了一种名为MobQA的数据集，用于评估大语言模型处理人类移动数据自然语言问答的能力。


<details>
  <summary>Details</summary>
Motivation: 想要评估大语言模型在理解人的移动数据及其语义意义上的能力，这在现有预测模型中尚无明确答案。

Method: 设计了一个包含5800对高质量问答的评估框架，涉及三种问题类型：事实检索、多选推理和自由解释，涵盖空间、时间及语义推理能力测试。

Result: 主流大语言模型在事实检索问题上表现良好，但在语义推理和解释性问答上表现存在明显不足，轨迹长度对模型效果有较大影响。

Conclusion: 研究揭示了当前最先进的大语言模型在语义移动理解上的能力和局限性，为未来改进提供了参考依据。

Abstract: This paper presents MobQA, a benchmark dataset designed to evaluate the
semantic understanding capabilities of large language models (LLMs) for human
mobility data through natural language question answering.
  While existing models excel at predicting human movement patterns, it remains
unobvious how much they can interpret the underlying reasons or semantic
meaning of those patterns. MobQA provides a comprehensive evaluation framework
for LLMs to answer questions about diverse human GPS trajectories spanning
daily to weekly granularities. It comprises 5,800 high-quality question-answer
pairs across three complementary question types: factual retrieval (precise
data extraction), multiple-choice reasoning (semantic inference), and free-form
explanation (interpretive description), which all require spatial, temporal,
and semantic reasoning. Our evaluation of major LLMs reveals strong performance
on factual retrieval but significant limitations in semantic reasoning and
explanation question answering, with trajectory length substantially impacting
model effectiveness. These findings demonstrate the achievements and
limitations of state-of-the-art LLMs for semantic mobility
understanding.\footnote{MobQA dataset is available at
https://github.com/CyberAgentAILab/mobqa.}

</details>


### [109] [Overcoming Low-Resource Barriers in Tulu: Neural Models and Corpus Creation for OffensiveLanguage Identification](https://arxiv.org/abs/2508.11166)
*Anusha M D,Deepthi Vikram,Bharathi Raja Chakravarthi,Parameshwar R Hegde*

Main category: cs.CL

TL;DR: 该研究构建了一个针对低资源达罗毗荼语系语言Tulu的代码混合社交媒体内容中攻击性语言检测的基准数据集，并对多种深度学习模型进行了评估，发现BiGRU模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 由于Tulu语言计算资源的匮乏和其数字存在的增加，研究旨在为低资源语言Tulu在代码混合环境下的攻击性语言检测提供基准数据集和方法评估。

Method: 收集来自YouTube评论的3,845条Tulu代码混合内容数据，并分为四类（非攻击性、非Tulu、无目标攻击和目标攻击），然后使用多种深度学习模型进行评估，包括GRU、LSTM、CNN及Transformer模型。

Result: BiGRU模型结合自注意力机制的表现最好，准确率达到82%，宏观F1分数为0.81。同时，Transformer模型的效果较弱，表明多语言预训练在代码混合低资源环境中的局限性。

Conclusion: 为Tulu语言及类似低资源代码混合语言的自然语言处理研究奠定了基础，特别是在攻击性语言检测领域。

Abstract: Tulu, a low-resource Dravidian language predominantly spoken in southern
India, has limited computational resources despite its growing digital
presence. This study presents the first benchmark dataset for Offensive
Language Identification (OLI) in code-mixed Tulu social media content,
collected from YouTube comments across various domains. The dataset, annotated
with high inter-annotator agreement (Krippendorff's alpha = 0.984), includes
3,845 comments categorized into four classes: Not Offensive, Not Tulu,
Offensive Untargeted, and Offensive Targeted. We evaluate a suite of deep
learning models, including GRU, LSTM, BiGRU, BiLSTM, CNN, and attention-based
variants, alongside transformer architectures (mBERT, XLM-RoBERTa). The BiGRU
model with self-attention achieves the best performance with 82% accuracy and a
0.81 macro F1-score. Transformer models underperform, highlighting the
limitations of multilingual pretraining in code-mixed, under-resourced
contexts. This work lays the foundation for further NLP research in Tulu and
similar low-resource, code-mixed languages.

</details>


### [110] [Personalized Distractor Generation via MCTS-Guided Reasoning Reconstruction](https://arxiv.org/abs/2508.11184)
*Tao Wu,Jingyuan Chen,Wang Lin,Jian Zhan,Mengze Li,Kun Kuang,Fei Wu*

Main category: cs.CL

TL;DR: 本文提出了一种针对个体学生设计个性化干扰项的方法，以提高多项选择题的诊断效能。


<details>
  <summary>Details</summary>
Motivation: 目前的大语言模型生成的共享干扰项无法有效反映个体学生的多样化推理错误，限制了其诊断效能。

Method: 提出了一种无训练的两阶段框架，首先利用蒙特卡洛树搜索推导学生的错误推理轨迹生成“误解原型”，然后基于该原型生成个性化干扰项。

Result: 实验表明，该方法在为140名学生生成个性化干扰项方面表现最佳，同时在群体级别的场景中也表现出很好的泛化性。

Conclusion: 个性化干扰项生成方法能够更有效地暴露学生的具体推理错误，既具备针对性又具有通用性，提升了教育评估的诊断能力。

Abstract: Distractors, incorrect but plausible answer choices in multiple-choice
questions (MCQs), play a critical role in educational assessment by diagnosing
student misconceptions. Recent work has leveraged large language models (LLMs)
to generate shared, group-level distractors by learning common error patterns
across large student populations. However, such distractors often fail to
capture the diverse reasoning errors of individual students, limiting their
diagnostic effectiveness. To address this limitation, we introduce the task of
personalized distractor generation, which aims to generate tailored distractors
based on individual misconceptions inferred from each student's past
question-answering (QA) records, ensuring every student receives options that
effectively exposes their specific reasoning errors. While promising, this task
is challenging because each student typically has only a few QA records, which
often lack the student's underlying reasoning processes, making training-based
group-level approaches infeasible. To overcome this, we propose a training-free
two-stage framework. In the first stage, we construct a student-specific
misconception prototype by applying Monte Carlo Tree Search (MCTS) to recover
the student's reasoning trajectories from past incorrect answers. In the second
stage, this prototype guides the simulation of the student's reasoning on new
questions, enabling the generation of personalized distractors that align with
the student's recurring misconceptions. Experiments show that our approach
achieves the best performance in generating plausible, personalized distractors
for 140 students, and also effectively generalizes to group-level settings,
highlighting its robustness and adaptability.

</details>


### [111] [Novel Parasitic Dual-Scale Modeling for Efficient and Accurate Multilingual Speech Translation](https://arxiv.org/abs/2508.11189)
*Chenyang Le,Yinfeng Xia,Huiyan Li,Manhong Wang,Yutao Sun,Xingyang Ma,Yanmin Qian*

Main category: cs.CL

TL;DR: 提出一种名为Parasitic Dual-Scale Approach的新方法，通过增强的推测采样方法、模型压缩和知识蒸馏，显著提升了多语言语音翻译的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 解决当前多语言语音翻译模型参数规模大、推理效率与性能难以平衡的问题，特别是在本地部署场景中。

Method: 提出Parasitic Dual-Scale方法，结合增强推测采样、模型压缩和知识蒸馏技术，并在Whisper Medium模型基础上进行优化，集成名为KVSPN的模块。

Result: 实现了六种流行语言中的SOTA性能，KVSPN模块使推理速度提升40%，在不降低BLEU分数的情况下提升了效率，与蒸馏方法结合后比原始模型速度提升2.6倍，并具有更好的翻译性能。

Conclusion: 提出的Parasitic Dual-Scale Approach有效平衡了多语言语音翻译模型的推理效率与性能，具有较高的实际应用价值。

Abstract: Recent advancements in speech-to-text translation have led to the development
of multilingual models capable of handling multiple language pairs
simultaneously. However, these unified models often suffer from large parameter
sizes, making it challenging to balance inference efficiency and performance,
particularly in local deployment scenarios. We propose an innovative Parasitic
Dual-Scale Approach, which combines an enhanced speculative sampling method
with model compression and knowledge distillation techniques. Building on the
Whisper Medium model, we enhance it for multilingual speech translation into
whisperM2M, and integrate our novel KVSPN module, achieving state-of-the-art
(SOTA) performance across six popular languages with improved inference
efficiency. KVSPN enables a 40\% speedup with no BLEU score degradation.
Combined with distillation methods, it represents a 2.6$\times$ speedup over
the original Whisper Medium with superior performance.

</details>


### [112] [E-CaTCH: Event-Centric Cross-Modal Attention with Temporal Consistency and Class-Imbalance Handling for Misinformation Detection](https://arxiv.org/abs/2508.11197)
*Ahmad Mousavi,Yeganeh Abdollahinejad,Roberto Corizzo,Nathalie Japkowicz,Zois Boukouvalas*

Main category: cs.CL

TL;DR: E-CaTCH是一种检测社交媒体多模态虚假信息的框架，注重跨时间和模式的事件级结构，通过结合单事件的文本和图像特征、多模态对齐及时间发展建模，取得了领先的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在检测多模态虚假信息时难以处理时间模式变化、模态间不一致性及类别不平衡问题。作者希望开发一种既解释性强又可扩展的模型来应对这些挑战。

Method: E-CaTCH框架通过聚类生成伪事件，利用自注意力和交叉模态注意力对文本和视觉特征进行提取和对齐，并通过趋势感知LSTM捕捉时间演化特性，同时采用多种策略解决类别不平衡问题。最终的分类在事件级上进行。

Result: E-CaTCH在多个数据集（如Fakeddit、IND和COVID-19 MISINFOGRAPH）上的实验结果显示其性能优于现有最先进的基线模型，并在跨数据集评估中表现出卓越的鲁棒性和通用性。

Conclusion: E-CaTCH框架通过高效的模态对齐和时间建模，提供了优越的检测多模态虚假信息能力，证明了其在实际应用中的潜力和优越性。

Abstract: Detecting multimodal misinformation on social media remains challenging due
to inconsistencies between modalities, changes in temporal patterns, and
substantial class imbalance. Many existing methods treat posts independently
and fail to capture the event-level structure that connects them across time
and modality. We propose E-CaTCH, an interpretable and scalable framework for
robustly detecting misinformation. If needed, E-CaTCH clusters posts into
pseudo-events based on textual similarity and temporal proximity, then
processes each event independently. Within each event, textual and visual
features are extracted using pre-trained BERT and ResNet encoders, refined via
intra-modal self-attention, and aligned through bidirectional cross-modal
attention. A soft gating mechanism fuses these representations to form
contextualized, content-aware embeddings of each post. To model temporal
evolution, E-CaTCH segments events into overlapping time windows and uses a
trend-aware LSTM, enhanced with semantic shift and momentum signals, to encode
narrative progression over time. Classification is performed at the event
level, enabling better alignment with real-world misinformation dynamics. To
address class imbalance and promote stable learning, the model integrates
adaptive class weighting, temporal consistency regularization, and hard-example
mining. The total loss is aggregated across all events. Extensive experiments
on Fakeddit, IND, and COVID-19 MISINFOGRAPH demonstrate that E-CaTCH
consistently outperforms state-of-the-art baselines. Cross-dataset evaluations
further demonstrate its robustness, generalizability, and practical
applicability across diverse misinformation scenarios.

</details>


### [113] [Cross-Granularity Hypergraph Retrieval-Augmented Generation for Multi-hop Question Answering](https://arxiv.org/abs/2508.11247)
*Changjian Wang,Weihong Deng,Weili Guan,Quan Lu,Ning Jiang*

Main category: cs.CL

TL;DR: 本文提出了一种新方法HGRAG，用于通过超图实现结构和语义信息的跨粒度整合，从而提升多跳问答任务的表现和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG方法在多跳问答中缺乏对分散知识的有效整合，图RAG方法虽利用知识图谱克服部分问题，但对文本语义信息的利用不足。

Method: 构建一种实体超图，将精细粒度的实体作为节点，粗粒度的段落作为超边，基于超图扩散方法融合实体和段落的相似性，同时通过检索增强模块优化结果。

Result: 实验结果表明，HGRAG方法在问答性能上优于现有最先进方法，同时在检索效率上提升了6倍。

Conclusion: HGRAG方法通过有效整合结构与语义信息，为多跳问答任务提供了更强的性能和更高的效率。

Abstract: Multi-hop question answering (MHQA) requires integrating knowledge scattered
across multiple passages to derive the correct answer. Traditional
retrieval-augmented generation (RAG) methods primarily focus on coarse-grained
textual semantic similarity and ignore structural associations among dispersed
knowledge, which limits their effectiveness in MHQA tasks. GraphRAG methods
address this by leveraging knowledge graphs (KGs) to capture structural
associations, but they tend to overly rely on structural information and
fine-grained word- or phrase-level retrieval, resulting in an underutilization
of textual semantics. In this paper, we propose a novel RAG approach called
HGRAG for MHQA that achieves cross-granularity integration of structural and
semantic information via hypergraphs. Structurally, we construct an entity
hypergraph where fine-grained entities serve as nodes and coarse-grained
passages as hyperedges, and establish knowledge association through shared
entities. Semantically, we design a hypergraph retrieval method that integrates
fine-grained entity similarity and coarse-grained passage similarity via
hypergraph diffusion. Finally, we employ a retrieval enhancement module, which
further refines the retrieved results both semantically and structurally, to
obtain the most relevant passages as context for answer generation with the
LLM. Experimental results on benchmark datasets demonstrate that our approach
outperforms state-of-the-art methods in QA performance, and achieves a
6$\times$ speedup in retrieval efficiency.

</details>


### [114] [UNVEILING: What Makes Linguistics Olympiad Puzzles Tricky for LLMs?](https://arxiv.org/abs/2508.11260)
*Mukund Choudhary,KV Aditya Srivatsa,Gaurja Aeron,Antara Raaghavi Bhattacharya,Dang Khoa Dang Dinh,Ikhlasul Akmal Hanif,Daria Kotova,Ekaterina Kochmar,Monojit Choudhury*

Main category: cs.CL

TL;DR: LLMs在语言推理任务上表现不佳，通过分析41种低资源语言的语言学谜题揭示其弱点，发现其难以处理形态复杂度高的问题，需改进分词器。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在低资源语言上的语言推理能力，并揭示其弱点和改进方向。

Method: 对41种低资源语言的629个语言学谜题进行分析，标注特征并检验LLMs性能。同时测试拆分词素的预处理步骤对解题能力的影响。

Result: LLMs对英文相关特征的问题表现较好，但在形态复杂度高的问题上表现不佳。拆分词素作为预处理步骤可提升解题能力。

Conclusion: LLMs在处理复杂语言学特征和形态复杂度高的低资源语言上存在挑战，需要更语言特定的分词器以增强其推理能力。

Abstract: Large language models (LLMs) have demonstrated potential in reasoning tasks,
but their performance on linguistics puzzles remains consistently poor. These
puzzles, often derived from Linguistics Olympiad (LO) contests, provide a
minimal contamination environment to assess LLMs' linguistic reasoning
abilities across low-resource languages. This work analyses LLMs' performance
on 629 problems across 41 low-resource languages by labelling each with
linguistically informed features to unveil weaknesses. Our analyses show that
LLMs struggle with puzzles involving higher morphological complexity and
perform better on puzzles involving linguistic features that are also found in
English. We also show that splitting words into morphemes as a pre-processing
step improves solvability, indicating a need for more informed and
language-specific tokenisers. These findings thus offer insights into some
challenges in linguistic reasoning and modelling of low-resource languages.

</details>


### [115] [LETToT: Label-Free Evaluation of Large Language Models On Tourism Using Expert Tree-of-Thought](https://arxiv.org/abs/2508.11280)
*Ruiyan Qi,Congding Wen,Weibo Zhou,Shangsong Liang,Lingbo Li*

Main category: cs.CL

TL;DR: 本文提出了一种无需标注数据的旅游领域大语言模型评价方法--LETToT，通过专家树式推理架构来评估模型表现。


<details>
  <summary>Details</summary>
Motivation: 当前在特定领域（如旅游）中评估大语言模型十分困难，原因在于标注基准成本高昂及模型生成幻觉等问题。

Method: 提出LETToT框架，利用专家衍生的推理结构代替标注数据，经过迭代与专家反馈优化，并用该框架评估不同规模的模型性能。

Result: 实验表明：1. 在特定领域中，模型规模扩大仍表现优异；2. 小模型通过增强推理能力可追平性能差距；3. 基于显式推理的架构在准确性与简洁性上优于其他方法。

Conclusion: LETToT提供了一种标签自由、可扩展的领域特定LLM评估范式，替代传统的标注基准方法。

Abstract: Evaluating large language models (LLMs) in specific domain like tourism
remains challenging due to the prohibitive cost of annotated benchmarks and
persistent issues like hallucinations. We propose $\textbf{L}$able-Free
$\textbf{E}$valuation of LLM on $\textbf{T}$ourism using Expert
$\textbf{T}$ree-$\textbf{o}$f-$\textbf{T}$hought (LETToT), a framework that
leverages expert-derived reasoning structures-instead of labeled data-to access
LLMs in tourism. First, we iteratively refine and validate hierarchical ToT
components through alignment with generic quality dimensions and expert
feedback. Results demonstrate the effectiveness of our systematically optimized
expert ToT with 4.99-14.15\% relative quality gains over baselines. Second, we
apply LETToT's optimized expert ToT to evaluate models of varying scales
(32B-671B parameters), revealing: (1) Scaling laws persist in specialized
domains (DeepSeek-V3 leads), yet reasoning-enhanced smaller models (e.g.,
DeepSeek-R1-Distill-Llama-70B) close this gap; (2) For sub-72B models, explicit
reasoning architectures outperform counterparts in accuracy and conciseness
($p<0.05$). Our work established a scalable, label-free paradigm for
domain-specific LLM evaluation, offering a robust alternative to conventional
annotated benchmarks.

</details>


### [116] [ToxiFrench: Benchmarking and Enhancing Language Models via CoT Fine-Tuning for French Toxicity Detection](https://arxiv.org/abs/2508.11281)
*Axel Delaval,Shujian Yang,Haicheng Wang,Han Qiu,Jialiang Lu*

Main category: cs.CL

TL;DR: 本研究提出TOXIFRENCH，一个包含53,622条法语在线评论的新基准数据集，通过部分自动化标注流水线显著减少人工工作量，并发现小型语言模型在毒性检测任务中的表现优于多数大型模型。此外，提出一种基于动态加权损失的连锁思维微调策略，提升模型性能，最终取得了跨语言的强大能力。


<details>
  <summary>Details</summary>
Motivation: 法语毒性内容检测发展不足，关键在于缺乏大规模与文化相关的数据集。研究动机是解决这一问题，并优化毒性检测模型的性能。

Method: 采用部分自动化标注方式，构建一个法语毒性评论数据集；同时，使用连锁思维微调策略，通过动态加权损失提升模型的最终决策能力。

Result: 训练得到的4B模型在F1分数上比基线提升13%，优于GPT-4.0和Gemini-2.5，展示出跨语言毒性检测的能力。

Conclusion: 提出的数据集及微调策略为法语毒性检测提供了有效解决方案，并具有扩展到其他语言和任务的潜力。

Abstract: Detecting toxic content using language models is crucial yet challenging.
While substantial progress has been made in English, toxicity detection in
French remains underdeveloped, primarily due to the lack of culturally
relevant, large-scale datasets. In this work, we introduce TOXIFRENCH, a new
public benchmark of 53,622 French online comments, constructed via a
semi-automated annotation pipeline that reduces manual labeling to only 10%
through high-confidence LLM-based pre-annotation and human verification. Then,
we benchmark a broad range of models and uncover a counterintuitive insight:
Small Language Models (SLMs) outperform many larger models in robustness and
generalization under the toxicity detection task. Motivated by this finding, we
propose a novel Chain-of-Thought (CoT) fine-tuning strategy using a dynamic
weighted loss that progressively emphasizes the model's final decision,
significantly improving faithfulness. Our fine-tuned 4B model achieves
state-of-the-art performance, improving its F1 score by 13% over its baseline
and outperforming LLMs such as GPT-40 and Gemini-2.5. Further evaluation on a
cross-lingual toxicity benchmark demonstrates strong multilingual ability,
suggesting that our methodology can be effectively extended to other languages
and safety-critical classification tasks.

</details>


### [117] [AI in Mental Health: Emotional and Sentiment Analysis of Large Language Models' Responses to Depression, Anxiety, and Stress Queries](https://arxiv.org/abs/2508.11285)
*Arya VarastehNezhad,Reza Tavasoli,Soroush Elyasi,MohammadHossein LotfiNia,Hamed Farbeh*

Main category: cs.CL

TL;DR: 本文研究了八个大型语言模型（LLMs）在应对与抑郁、焦虑和压力相关的问题时的情感表达模式及其差异。


<details>
  <summary>Details</summary>
Motivation: 探讨特定LLMs在心理健康应用中的表现，尤其是在回答与抑郁、焦虑和压力相关的问题时的情感表达。

Method: 研究分析了八个LLMs在六种用户背景下回答20个心理健康相关问题的2,880个回答，使用情感及情绪分析工具对回答进行评分，分析模型和问题类型对情感表达的影响。

Result: 1. 不同模型的情感表达差异显著；2. 焦虑问题引发高恐惧，抑郁问题以悲伤为主，压力问题更乐观；3. 用户背景对情绪表达影响较小，但模型和问题类型对情感表达的影响显著。

Conclusion: 模型选择对于心理健康应用至关重要，不同LLMs的情感特征可能显著影响用户体验和结果。

Abstract: Depression, anxiety, and stress are widespread mental health concerns that
increasingly drive individuals to seek information from Large Language Models
(LLMs). This study investigates how eight LLMs (Claude Sonnet, Copilot, Gemini
Pro, GPT-4o, GPT-4o mini, Llama, Mixtral, and Perplexity) reply to twenty
pragmatic questions about depression, anxiety, and stress when those questions
are framed for six user profiles (baseline, woman, man, young, old, and
university student). The models generated 2,880 answers, which we scored for
sentiment and emotions using state-of-the-art tools. Our analysis revealed that
optimism, fear, and sadness dominated the emotional landscape across all
outputs, with neutral sentiment maintaining consistently high values.
Gratitude, joy, and trust appeared at moderate levels, while emotions such as
anger, disgust, and love were rarely expressed. The choice of LLM significantly
influenced emotional expression patterns. Mixtral exhibited the highest levels
of negative emotions including disapproval, annoyance, and sadness, while Llama
demonstrated the most optimistic and joyful responses. The type of mental
health condition dramatically shaped emotional responses: anxiety prompts
elicited extraordinarily high fear scores (0.974), depression prompts generated
elevated sadness (0.686) and the highest negative sentiment, while
stress-related queries produced the most optimistic responses (0.755) with
elevated joy and trust. In contrast, demographic framing of queries produced
only marginal variations in emotional tone. Statistical analyses confirmed
significant model-specific and condition-specific differences, while
demographic influences remained minimal. These findings highlight the critical
importance of model selection in mental health applications, as each LLM
exhibits a distinct emotional signature that could significantly impact user
experience and outcomes.

</details>


### [118] [SafeConstellations: Steering LLM Safety to Reduce Over-Refusals Through Task-Specific Trajectory](https://arxiv.org/abs/2508.11290)
*Utsav Maskey,Sumit Yadav,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型（LLMs）过度拒绝（over-refusal）行为，并提出了解决办法。


<details>
  <summary>Details</summary>
Motivation: LLMs经常因安全机制拒绝合法任务的执行，影响实际应用效果，特别是在频繁依赖通用提示或执行特定任务的应用中。

Method: 研究通过机制分析发现LLMs在嵌入空间中具有特定路径模式，并提出SafeConstellations方法，通过引导模型的推理路径减少过度拒绝发生。

Result: 该方法在保留模型整体性能的情况下，将过度拒绝率降低了73%。

Conclusion: SafeConstellations提供了一种有效减少LLMs过度拒绝的原则性方法，有助于提升其在实际生产环境中的实用性。

Abstract: LLMs increasingly exhibit over-refusal behavior, where safety mechanisms
cause models to reject benign instructions that superficially resemble harmful
content. This phenomena diminishes utility in production applications that
repeatedly rely on common prompt templates or applications that frequently rely
on LLMs for specific tasks (e.g. sentiment analysis, language translation).
Through comprehensive evaluation, we demonstrate that LLMs still tend to refuse
responses to harmful instructions when those instructions are reframed to
appear as benign tasks. Our mechanistic analysis reveal that LLMs follow
distinct "constellation" patterns in embedding space as representations
traverse layers, with each task maintaining consistent trajectories that shift
predictably between refusal and non-refusal cases. We introduce
SafeConstellations, an inference-time trajectory-shifting approach that tracks
task-specific trajectory patterns and guides representations toward non-refusal
pathways. By selectively guiding model behavior only on tasks prone to
over-refusal, and by preserving general model behavior, our method reduces
over-refusal rates by up to 73% with minimal impact on utility-offering a
principled approach to mitigating over-refusals.

</details>


### [119] [SGSimEval: A Comprehensive Multifaceted and Similarity-Enhanced Benchmark for Automatic Survey Generation Systems](https://arxiv.org/abs/2508.11310)
*Beichen Guo,Zhiyuan Wen,Yu Yang,Peng Gao,Ruosong Yang,Jiaxing Shen*

Main category: cs.CL

TL;DR: 本文提出了一种名为SGSimEval的新型评估框架，用于自动调研生成任务的综合评估，结合了内容、结构、引用的对比和量化计算，改善现有评估方法的缺陷。


<details>
  <summary>Details</summary>
Motivation: 针对现有的自动调研生成评估方法中存在的偏差指标、缺乏人类偏好数据的表现以及对语言模型作为评估工具过度依赖的问题。

Method: 开发了一个名为SGSimEval的综合评估框架，引入类似度增强评价，从大纲、内容到引用进行全面评估，同时结合多维度人类偏好数据和量化指标评估自动生成系统的性能。

Result: 实验表明，当前的自动调研生成系统在大纲生成方面接近人类水平，但在内容和参考文献生成上仍有明显的改进空间，而SGSimEval框架的评估结果与人类评价高度一致。

Conclusion: SGSimEval为自动调研生成领域提供了系统、全面且接近人类偏好的评估方法，为未来的改进研究奠定了基础，同时展示了现有系统在不同生成方面的效果差异。

Abstract: The growing interest in automatic survey generation (ASG), a task that
traditionally required considerable time and effort, has been spurred by recent
advances in large language models (LLMs). With advancements in
retrieval-augmented generation (RAG) and the rising popularity of multi-agent
systems (MASs), synthesizing academic surveys using LLMs has become a viable
approach, thereby elevating the need for robust evaluation methods in this
domain. However, existing evaluation methods suffer from several limitations,
including biased metrics, a lack of human preference, and an over-reliance on
LLMs-as-judges. To address these challenges, we propose SGSimEval, a
comprehensive benchmark for Survey Generation with Similarity-Enhanced
Evaluation that evaluates automatic survey generation systems by integrating
assessments of the outline, content, and references, and also combines
LLM-based scoring with quantitative metrics to provide a multifaceted
evaluation framework. In SGSimEval, we also introduce human preference metrics
that emphasize both inherent quality and similarity to humans. Extensive
experiments reveal that current ASG systems demonstrate human-comparable
superiority in outline generation, while showing significant room for
improvement in content and reference generation, and our evaluation metrics
maintain strong consistency with human assessments.

</details>


### [120] [LLM Compression: How Far Can We Go in Balancing Size and Performance?](https://arxiv.org/abs/2508.11318)
*Sahil Sk,Debasish Dhal,Sonal Khosla,Sk Shahid,Sambit Shekhar,Akash Dhaka,Shantipriya Parida,Dilip K. Prasad,Ondřej Bojar*

Main category: cs.CL

TL;DR: 本文研究4-bit GSQ和GPTQ量化技术在不同大小语言模型和多任务上的性能影响。


<details>
  <summary>Details</summary>
Motivation: 通过量化技术减少大型语言模型的内存使用和计算成本，同时保持性能。

Method: 对LLaMA 1B、Qwen 0.5B和PHI 1.5B模型应用4-bit GSQ和GPTQ技术，并在MS MARCO、BoolQ和GSM8K数据集上评估其性能和效率。

Result: 结果展示了模型压缩与任务性能之间的权衡，并提供了关键评估指标如准确率、推理延迟和吞吐量。

Conclusion: 低比特量化技术适用于实际部署，同时探讨了GSQ和GPTQ在不同大小模型上的优劣，为后续研究提供基准。

Abstract: Quantization is an essential and popular technique for improving the
accessibility of large language models (LLMs) by reducing memory usage and
computational costs while maintaining performance. In this study, we apply
4-bit Group Scaling Quantization (GSQ) and Generative Pretrained Transformer
Quantization (GPTQ) to LLaMA 1B, Qwen 0.5B, and PHI 1.5B, evaluating their
impact across multiple NLP tasks. We benchmark these models on MS MARCO
(Information Retrieval), BoolQ (Boolean Question Answering), and GSM8K
(Mathematical Reasoning) datasets, assessing both accuracy and efficiency
across various tasks. The study measures the trade-offs between model
compression and task performance, analyzing key evaluation metrics, namely
accuracy, inference latency, and throughput (total output tokens generated per
second), providing insights into the suitability of low-bit quantization for
real-world deployment. Using the results, users can then make suitable
decisions based on the specifications that need to be met. We discuss the pros
and cons of GSQ and GPTQ techniques on models of different sizes, which also
serve as a benchmark for future experiments.

</details>


### [121] [SpecDetect: Simple, Fast, and Training-Free Detection of LLM-Generated Text via Spectral Analysis](https://arxiv.org/abs/2508.11343)
*Haitong Luo,Weiyao Zhang,Suhang Wang,Wenji Zou,Chungang Lin,Xuying Meng,Yujun Zhang*

Main category: cs.CL

TL;DR: 提出一种基于频域分析的检测方法，通过分析文本生成过程中的信号频谱特性来区分人类撰写文本和LLM生成文本。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法依赖于表层统计，忽略生成文本信号性质，因此需要一种更可靠的检测方式。

Method: 将检测问题重新定义为信号处理问题，分析token对数概率的频谱特性，利用全局离散傅立叶变换（DFT）和局部短时傅立叶变换（STFT）来检测信号中的能量特点，并构建基于DFT能量特性的检测器SpecDetect及其改进版SpecDetect++。

Result: 提出的方法在检测性能上优于当前最先进的模型，并且运行耗时减少近一半。

Conclusion: 经典信号处理技术在LLM文本检测中极为有效，为该领域提供了一种高效且可解释的新途径。

Abstract: The proliferation of high-quality text from Large Language Models (LLMs)
demands reliable and efficient detection methods. While existing training-free
approaches show promise, they often rely on surface-level statistics and
overlook fundamental signal properties of the text generation process. In this
work, we reframe detection as a signal processing problem, introducing a novel
paradigm that analyzes the sequence of token log-probabilities in the frequency
domain. By systematically analyzing the signal's spectral properties using the
global Discrete Fourier Transform (DFT) and the local Short-Time Fourier
Transform (STFT), we find that human-written text consistently exhibits
significantly higher spectral energy. This higher energy reflects the
larger-amplitude fluctuations inherent in human writing compared to the
suppressed dynamics of LLM-generated text. Based on this key insight, we
construct SpecDetect, a detector built on a single, robust feature from the
global DFT: DFT total energy. We also propose an enhanced version,
SpecDetect++, which incorporates a sampling discrepancy mechanism to further
boost robustness. Extensive experiments demonstrate that our approach
outperforms the state-of-the-art model while running in nearly half the time.
Our work introduces a new, efficient, and interpretable pathway for
LLM-generated text detection, showing that classical signal processing
techniques offer a surprisingly powerful solution to this modern challenge.

</details>


### [122] [Feedback Indicators: The Alignment between Llama and a Teacher in Language Learning](https://arxiv.org/abs/2508.11364)
*Sylvio Rüdian,Yassin Elsir,Marvin Kretschmer,Sabine Cayrou,Niels Pinkwart*

Main category: cs.CL

TL;DR: 研究分析如何使用大型语言模型LLama 3.1从学生提交的语言学习课程中提取指标，达到自动生成高质量反馈的目的。


<details>
  <summary>Details</summary>
Motivation: 通过自动生成反馈，提升学生学习效率并减轻教师工作负担，为生成高质量反馈需优先提取相关指标。

Method: 采用LLama 3.1模型从学生作业中提取指标，并与教师的人工评分对比评估两者在多种反馈标准上的一致性。

Result: 研究结果显示，模型提取的指标与人工评分具有显著强相关性，即使是一些未预期的指标组合也表现良好。

Conclusion: 所提出的方法奠定了利用LLMs提取指标的基础，这些指标未来可用于生成可解释和透明的形成性反馈。

Abstract: Automated feedback generation has the potential to enhance students' learning
progress by providing timely and targeted feedback. Moreover, it can assist
teachers in optimizing their time, allowing them to focus on more strategic and
personalized aspects of teaching. To generate high-quality, information-rich
formative feedback, it is essential first to extract relevant indicators, as
these serve as the foundation upon which the feedback is constructed. Teachers
often employ feedback criteria grids composed of various indicators that they
evaluate systematically. This study examines the initial phase of extracting
such indicators from students' submissions of a language learning course using
the large language model Llama 3.1. Accordingly, the alignment between
indicators generated by the LLM and human ratings across various feedback
criteria is investigated. The findings demonstrate statistically significant
strong correlations, even in cases involving unanticipated combinations of
indicators and criteria. The methodology employed in this paper offers a
promising foundation for extracting indicators from students' submissions using
LLMs. Such indicators can potentially be utilized to auto-generate explainable
and transparent formative feedback in future research.

</details>


### [123] [When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs](https://arxiv.org/abs/2508.11383)
*Mikhail Seleznyov,Mikhail Chaichuk,Gleb Ershov,Alexander Panchenko,Elena Tutubalina,Oleg Somov*

Main category: cs.CL

TL;DR: 本文系统评估了5种提高大型语言模型（LLMs）提示鲁棒性的方法，并在统一框架下进行测试，分析了多种模型对分布变化的适应性。


<details>
  <summary>Details</summary>
Motivation: LLMs对提示的细微变化高度敏感，难以在不同上下文中保证稳定性。研究的动机是改善LLMs对提示格式扰动的鲁棒性，以提高其在真实世界应用中的可靠性。

Method: 本文基于一个统一实验框架，对包括Llama、Qwen和Gemma系列的8种模型，以及GPT-4.1和DeepSeek V3进行系统评估，并从微调和上下文学习两种视角分析提示鲁棒性方法的效果。

Result: 研究发现不同方法在面对分布变化时的有效性各异，总结了目前提高提示鲁棒性最有效的实践，尤其是对前沿模型的适应性提供了深入洞察。

Conclusion: 本文为如何选择和应用提示鲁棒性方法提供了实际指导，为LLMs在复杂环境中的稳定表现奠定了基础。

Abstract: Large Language Models (LLMs) are highly sensitive to subtle, non-semantic
variations in prompt phrasing and formatting. In this work, we present the
first systematic evaluation of 5 methods for improving prompt robustness within
a unified experimental framework. We benchmark these techniques on 8 models
from Llama, Qwen and Gemma families across 52 tasks from Natural Instructions
dataset. Our evaluation covers robustness methods from both fine-tuned and
in-context learning paradigms, and tests their generalization against multiple
types of distribution shifts. Finally, we extend our analysis to GPT-4.1 and
DeepSeek V3 to assess frontier models' current robustness to format
perturbations. Our findings offer actionable insights into the relative
effectiveness of these robustness methods, enabling practitioners to make
informed decisions when aiming for stable and reliable LLM performance in
real-world applications. Code:
https://github.com/AIRI-Institute/when-punctuation-matters.

</details>


### [124] [Retrieval-augmented reasoning with lean language models](https://arxiv.org/abs/2508.11386)
*Ryan Sze-Yin Chan,Federico Nanni,Tomas Lazauskas,Rosie Wood,Penelope Yong,Lionel Tarassenko,Mark Girolami,James Geddes,Andrew Duncan*

Main category: cs.CL

TL;DR: 本文提出了一种新型的方法，将推理和检索增强生成（RAG）融入到一个精简的语言模型中，用于资源受限或需要隐私保护的环境中部署。


<details>
  <summary>Details</summary>
Motivation: 应对资源受限或安全环境中对高性能、隐私保护解决方案的需求，而非依赖大型模型和外部API。

Method: 开发了一个检索增强的对话代理系统，利用轻量级模型作为基础，通过引入密集式检索器、微调的Qwen2.5-Instruct模型、合成查询生成以及推理痕迹等技术，提升模型对复杂领域特定查询的理解能力。

Result: 和非推理模型及一般精简模型相比，经过领域特定微调后的系统在答案准确性和一致性方面有显著提高，接近前沿性能，同时适合本地部署。

Conclusion: 提出的系统在领域特定任务中表现优异，并通过开源支持可重复性和跨领域适配性。

Abstract: This technical report details a novel approach to combining reasoning and
retrieval augmented generation (RAG) within a single, lean language model
architecture. While existing RAG systems typically rely on large-scale models
and external APIs, our work addresses the increasing demand for performant and
privacy-preserving solutions deployable in resource-constrained or secure
environments. Building on recent developments in test-time scaling and
small-scale reasoning models, we develop a retrieval augmented conversational
agent capable of interpreting complex, domain-specific queries using a
lightweight backbone model. Our system integrates a dense retriever with
fine-tuned Qwen2.5-Instruct models, using synthetic query generation and
reasoning traces derived from frontier models (e.g., DeepSeek-R1) over a
curated corpus, in this case, the NHS A-to-Z condition pages. We explore the
impact of summarisation-based document compression, synthetic data design, and
reasoning-aware fine-tuning on model performance. Evaluation against both
non-reasoning and general-purpose lean models demonstrates that our
domain-specific fine-tuning approach yields substantial gains in answer
accuracy and consistency, approaching frontier-level performance while
remaining feasible for local deployment. All implementation details and code
are publicly released to support reproducibility and adaptation across domains.

</details>


### [125] [Model Interpretability and Rationale Extraction by Input Mask Optimization](https://arxiv.org/abs/2508.11388)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

TL;DR: 为了提高神经网络模型的预测解释性，本文提出了一种基于屏蔽输入部分的提取式解释方法，并在图像与自然语言处理中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络模型在自然语言处理和计算机视觉领域的快速发展，对这些“黑盒”模型预测解释的需求不断增加。

Method: 提出了一种基于梯度优化的遮掩方法，同时结合一种新的正则化机制，确保生成的解释充分性、全面性和紧凑性。

Result: 该方法无需训练专门的模型，仅基于已有分类器即可生成高质量的解释，并适合于自然语言和图像输入。

Conclusion: 这种方法用统一的技术手段跨越了模型可解释性和基础模型之间的鸿沟，展示了其在多种输入类型上的广泛适用性。

Abstract: Concurrent to the rapid progress in the development of neural-network based
models in areas like natural language processing and computer vision, the need
for creating explanations for the predictions of these black-box models has
risen steadily. We propose a new method to generate extractive explanations for
predictions made by neural networks, that is based on masking parts of the
input which the model does not consider to be indicative of the respective
class. The masking is done using gradient-based optimization combined with a
new regularization scheme that enforces sufficiency, comprehensiveness and
compactness of the generated explanation, three properties that are known to be
desirable from the related field of rationale extraction in natural language
processing. In this way, we bridge the gap between model interpretability and
rationale extraction, thereby proving that the latter of which can be performed
without training a specialized model, only on the basis of a trained
classifier. We further apply the same method to image inputs and obtain high
quality explanations for image classifications, which indicates that the
conditions proposed for rationale extraction in natural language processing are
more broadly applicable to different input types.

</details>


### [126] [Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training](https://arxiv.org/abs/2508.11393)
*Marc Brinner,Sina Zarrieß*

Main category: cs.CL

TL;DR: 提出了一种用于稳定训练的端到端可微分训理性化Transformer分类器的方法。


<details>
  <summary>Details</summary>
Motivation: 解决训练理性化模型中的不稳定性和效率问题，同时获得与人类标注对齐的高质量结果。

Method: 通过让单一个模型同时扮演选择器、分类器和补充分类器的角色，简化三方博弈框架；并扩展到生成类别专属的理性化解释，提高模型和人类注释的一致性。

Result: 提升了人类注释对齐率并达到了最新的技术水平，同时减轻了现有方法的训练不稳定性问题。

Conclusion: 简化了架构，提升了效率和稳定性，改进了理性化结果的质量。

Abstract: We propose an end-to-end differentiable training paradigm for stable training
of a rationalized transformer classifier. Our approach results in a single
model that simultaneously classifies a sample and scores input tokens based on
their relevance to the classification. To this end, we build on the widely-used
three-player-game for training rationalized models, which typically relies on
training a rationale selector, a classifier and a complement classifier. We
simplify this approach by making a single model fulfill all three roles,
leading to a more efficient training paradigm that is not susceptible to the
common training instabilities that plague existing approaches. Further, we
extend this paradigm to produce class-wise rationales while incorporating
recent advances in parameterizing and regularizing the resulting rationales,
thus leading to substantially improved and state-of-the-art alignment with
human annotations without any explicit supervision.

</details>


### [127] [Survey-to-Behavior: Downstream Alignment of Human Values in LLMs via Survey Questions](https://arxiv.org/abs/2508.11414)
*Shangrui Nie,Florian Mai,David Kaczér,Charles Welch,Zhixue Zhao,Lucie Flek*

Main category: cs.CL

TL;DR: 研究通过微调回答价值观问卷改变大型语言模型的价值观系统，从而影响其下游行为。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以通过简单的微调方法改变语言模型的价值观系统，以减少需要大量训练数据的难度。

Method: 构建开放源码语言模型的价值观基线；通过微调模型使其回答价值问卷来调整其价值观；评估微调后模型在问卷回答和特定场景中的行为变化。

Result: 简单的微调方法不仅改变了模型在问卷问题上的回答，还在下游任务中产生了显著的价值观对齐效果。

Conclusion: 微调价值观问卷是一种有效且简单的方法，可以改变语言模型的价值观系统并优化其在各种场景中的行为表现。

Abstract: Large language models implicitly encode preferences over human values, yet
steering them often requires large training data. In this work, we investigate
a simple approach: Can we reliably modify a model's value system in downstream
behavior by training it to answer value survey questions accordingly? We first
construct value profiles of several open-source LLMs by asking them to rate a
series of value-related descriptions spanning 20 distinct human values, which
we use as a baseline for subsequent experiments. We then investigate whether
the value system of a model can be governed by fine-tuning on the value
surveys. We evaluate the effect of finetuning on the model's behavior in two
ways; first, we assess how answers change on in-domain, held-out survey
questions. Second, we evaluate whether the model's behavior changes in
out-of-domain settings (situational scenarios). To this end, we construct a
contextualized moral judgment dataset based on Reddit posts and evaluate
changes in the model's behavior in text-based adventure games. We demonstrate
that our simple approach can not only change the model's answers to in-domain
survey questions, but also produces substantial shifts (value alignment) in
implicit downstream task behavior.

</details>


### [128] [HumorPlanSearch: Structured Planning and HuCoT for Contextual AI Humor](https://arxiv.org/abs/2508.11429)
*Shivam Dubey*

Main category: cs.CL

TL;DR: HumorPlanSearch 是一个生成幽默内容的模块化流程，使用计划搜索、文化推理模板、知识图谱等方法，根据听众的背景和情境优化 AI 的幽默生成。


<details>
  <summary>Details</summary>
Motivation: 解决 LLMs 在幽默生成中出现的内容千篇一律或脱离语境的问题，使生成内容更适配听众文化和情境。

Method: 提出 HumorPlanSearch 流程，包括计划搜索、文化推理模板、知识图谱检索、语义新颖性过滤和迭代式修改等模块，并引入 Humor Generation Score（HGS）指标评估幽默质量。

Result: 在九个主题上的实验表明，HumorPlanSearch 流程中的完整实现方案相较于强基线方法将平均 HGS 提高了 15.4%。

Conclusion: 该流程通过关注从策略规划到多信号评估的上下文，推进了 AI 驱动幽默生成的适应性和文化敏感性。

Abstract: Automated humor generation with Large Language Models (LLMs) often yields
jokes that feel generic, repetitive, or tone-deaf because humor is deeply
situated and hinges on the listener's cultural background, mindset, and
immediate context. We introduce HumorPlanSearch, a modular pipeline that
explicitly models context through: (1) Plan-Search for diverse, topic-tailored
strategies; (2) Humor Chain-of-Thought (HuCoT) templates capturing cultural and
stylistic reasoning; (3) a Knowledge Graph to retrieve and adapt
high-performing historical strategies; (4) novelty filtering via semantic
embeddings; and (5) an iterative judge-driven revision loop. To evaluate
context sensitivity and comedic quality, we propose the Humor Generation Score
(HGS), which fuses direct ratings, multi-persona feedback, pairwise win-rates,
and topic relevance. In experiments across nine topics with feedback from 13
human judges, our full pipeline (KG + Revision) boosts mean HGS by 15.4 percent
(p < 0.05) over a strong baseline. By foregrounding context at every stage from
strategy planning to multi-signal evaluation, HumorPlanSearch advances
AI-driven humor toward more coherent, adaptive, and culturally attuned comedy.

</details>


### [129] [Online Anti-sexist Speech: Identifying Resistance to Gender Bias in Political Discourse](https://arxiv.org/abs/2508.11434)
*Aditi Dutta,Susan Banducci*

Main category: cs.CL

TL;DR: 这项研究研究了大型语言模型（LLMs）在区分性别歧视、反性别歧视和中性政治推文时的表现，发现模型经常错误分类，可能抑制反性别歧视言论的表达。


<details>
  <summary>Details</summary>
Motivation: 探讨自动内容审核系统在分辨性别歧视和反性别歧视言论方面的挑战，尤其关注数字政治空间中约束反对性别歧视表达的风险。

Method: 分析五种大型语言模型对英国2022年涉及女性议员的政治推文的分类能力，尤其在政治性事件的高触发时期进行评估。

Result: 研究发现模型会将反性别歧视言论错误分类为有害内容，尤其在表达风格复杂的政治事件中，可能导致边缘化声音被压制。

Conclusion: 呼吁内容审核设计超越简单的有害/无害分类，整合人在环审核，并将反对性别歧视言论纳入训练数据，维护数字政治空间的反抗性表达。

Abstract: Anti-sexist speech, i.e., public expressions that challenge or resist
gendered abuse and sexism, plays a vital role in shaping democratic debate
online. Yet automated content moderation systems, increasingly powered by large
language models (LLMs), may struggle to distinguish such resistance from the
sexism it opposes. This study examines how five LLMs classify sexist,
anti-sexist, and neutral political tweets from the UK, focusing on
high-salience trigger events involving female Members of Parliament in the year
2022. Our analysis show that models frequently misclassify anti-sexist speech
as harmful, particularly during politically charged events where rhetorical
styles of harm and resistance converge. These errors risk silencing those who
challenge sexism, with disproportionate consequences for marginalised voices.
We argue that moderation design must move beyond binary harmful/not-harmful
schemas, integrate human-in-the-loop review during sensitive events, and
explicitly include counter-speech in training data. By linking feminist
scholarship, event-based analysis, and model evaluation, this work highlights
the sociotechnical challenges of safeguarding resistance speech in digital
political spaces.

</details>


### [130] [CoDiEmb: A Collaborative yet Distinct Framework for Unified Representation Learning in Information Retrieval and Semantic Textual Similarity](https://arxiv.org/abs/2508.11442)
*Bowen Zhang,Zixin Song,Chunquan Chen,Qian-Wen Zhang,Di Yin,Xing Sun*

Main category: cs.CL

TL;DR: CoDiEmb为学习统一文本表示的优化结构，通过创新方法解决信息检索和语义文本相似性任务之间的性能权衡问题。


<details>
  <summary>Details</summary>
Motivation: 目标是解决信息检索（IR）和语义文本相似性（STS）联合训练时产生的负迁移问题，这两个任务本质上差异较大，直接联合培训常导致性能权衡。

Method: 引入CoDiEmb框架，包括：1. 任务专用目标结合动态采样器，防止梯度干扰；2. 基于参数偏移分析的模型融合策略；3. 简洁高效的单阶段训练流程。

Result: 在15个IR和STS基准以及3个基础编码器上的实验结果表明，CoDiEmb有效缓解了跨任务权衡并提升嵌入空间的几何属性。

Conclusion: CoDiEmb实现了IR和STS任务联合优化的目标，同时提升了文本表示的性能和空间属性。

Abstract: Learning unified text embeddings that excel across diverse downstream tasks
is a central goal in representation learning, yet negative transfer remains a
persistent obstacle. This challenge is particularly pronounced when jointly
training a single encoder for Information Retrieval (IR) and Semantic Textual
Similarity (STS), two essential but fundamentally disparate tasks for which
naive co-training typically yields steep performance trade-offs. We argue that
resolving this conflict requires systematically decoupling task-specific
learning signals throughout the training pipeline. To this end, we introduce
CoDiEmb, a unified framework that reconciles the divergent requirements of IR
and STS in a collaborative yet distinct manner. CoDiEmb integrates three key
innovations for effective joint optimization: (1) Task-specialized objectives
paired with a dynamic sampler that forms single-task batches and balances
per-task updates, thereby preventing gradient interference. For IR, we employ a
contrastive loss with multiple positives and hard negatives, augmented by
cross-device sampling. For STS, we adopt order-aware objectives that directly
optimize correlation and ranking consistency. (2) A delta-guided model fusion
strategy that computes fine-grained merging weights for checkpoints by
analyzing each parameter's deviation from its pre-trained initialization,
proving more effective than traditional Model Soups. (3) An efficient,
single-stage training pipeline that is simple to implement and converges
stably. Extensive experiments on 15 standard IR and STS benchmarks across three
base encoders validate CoDiEmb. Our results and analysis demonstrate that the
framework not only mitigates cross-task trade-offs but also measurably improves
the geometric properties of the embedding space.

</details>


### [131] [Reference Points in LLM Sentiment Analysis: The Role of Structured Context](https://arxiv.org/abs/2508.11454)
*Junichiro Niimi*

Main category: cs.CL

TL;DR: 这项研究探讨了使用大语言模型（LLMs）进行情感分析时，补充信息内容和形式对结果的影响，并发现结构化提示（如JSON格式）可以显著提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要通过文本分析情感，但消费者评价受体验和参考点等多因素影响，因此需要探索补充信息对情感分析的作用。

Method: 比较自然语言和JSON格式提示词在分析补充信息对情感分析的影响，实验使用参数较小的3B模型进行研究。

Result: 在两类Yelp数据（餐厅和夜生活）上，JSON格式提示显著提升了模型性能，Macro-F1指标提高1.6%和4%，RMSE分别下降16%和9.1%。

Conclusion: 通过结构化提示，小型模型（如3B参数）可取得与大模型媲美的性能，为资源有限设备提供了实用方法。

Abstract: Large language models (LLMs) are now widely used across many fields,
including marketing research. Sentiment analysis, in particular, helps firms
understand consumer preferences. While most NLP studies classify sentiment from
review text alone, marketing theories, such as prospect theory and
expectation--disconfirmation theory, point out that customer evaluations are
shaped not only by the actual experience but also by additional reference
points. This study therefore investigates how the content and format of such
supplementary information affect sentiment analysis using LLMs. We compare
natural language (NL) and JSON-formatted prompts using a lightweight 3B
parameter model suitable for practical marketing applications. Experiments on
two Yelp categories (Restaurant and Nightlife) show that the JSON prompt with
additional information outperforms all baselines without fine-tuning: Macro-F1
rises by 1.6% and 4% while RMSE falls by 16% and 9.1%, respectively, making it
deployable in resource-constrained edge devices. Furthermore, a follow-up
analysis confirms that performance gains stem from genuine contextual reasoning
rather than label proxying. This work demonstrates that structured prompting
can enable smaller models to achieve competitive performance, offering a
practical alternative to large-scale model deployment.

</details>


### [132] [Speciesism in AI: Evaluating Discrimination Against Animals in Large Language Models](https://arxiv.org/abs/2508.11534)
*Monika Jotautaitė,Lucius Caviola,David A. Brewster,Thilo Hagendorff*

Main category: cs.CL

TL;DR: 本文研究大语言模型(LLMs)在物种歧视上的表现，发现它们虽能识别物种歧视言论，却少有谴责，并在道德判断中倾向于遵循人类现有的文化和社会规范。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的广泛应用，研究其内在的伦理趋势变得重要。研究聚焦于LLMs是否存在物种歧视偏见及其对非人类动物的价值判断。

Method: 本文通过三个路径研究此议题：(1)建立包含1003项的SpeciesismBench基准测试评估LLMs对物种歧视言论的认知和道德评估；(2)使用心理学指标将模型的反应与人类对应结果比较；(3)文本生成任务，探究对物种歧视理由的阐述或抵触行为。

Result: 在基准测试中，LLMs能有效识别物种歧视言论，但很少谴责这些言论，通常将其视为道德上可接受。在心理学测试中，LLMs表现出比人类略低的显性物种歧视，但在涉及人类与多种动物的权衡中，更常选择救人。在开放文本生成中，LLMs倾向正常化或合理化针对农场动物的伤害，但对非农场动物有所拒绝。

Conclusion: 本文提出，在LLMs展现的道德视图中，既有进步也有与人类文化主流相一致的部分。然而，其依旧反映了动物剥削的固有文化规范。因此，有必要将AI的公平性和对齐框架扩展到涵盖非人类道德主体，减少这些偏见并防止物种歧视态度的进一步巩固。

Abstract: As large language models (LLMs) become more widely deployed, it is crucial to
examine their ethical tendencies. Building on research on fairness and
discrimination in AI, we investigate whether LLMs exhibit speciesist bias --
discrimination based on species membership -- and how they value non-human
animals. We systematically examine this issue across three paradigms: (1)
SpeciesismBench, a 1,003-item benchmark assessing recognition and moral
evaluation of speciesist statements; (2) established psychological measures
comparing model responses with those of human participants; (3) text-generation
tasks probing elaboration on, or resistance to, speciesist rationalizations. In
our benchmark, LLMs reliably detected speciesist statements but rarely
condemned them, often treating speciesist attitudes as morally acceptable. On
psychological measures, results were mixed: LLMs expressed slightly lower
explicit speciesism than people, yet in direct trade-offs they more often chose
to save one human over multiple animals. A tentative interpretation is that
LLMs may weight cognitive capacity rather than species per se: when capacities
were equal, they showed no species preference, and when an animal was described
as more capable, they tended to prioritize it over a less capable human. In
open-ended text generation tasks, LLMs frequently normalized or rationalized
harm toward farmed animals while refusing to do so for non-farmed animals.
These findings suggest that while LLMs reflect a mixture of progressive and
mainstream human views, they nonetheless reproduce entrenched cultural norms
around animal exploitation. We argue that expanding AI fairness and alignment
frameworks to explicitly include non-human moral patients is essential for
reducing these biases and preventing the entrenchment of speciesist attitudes
in AI systems and the societies they influence.

</details>


### [133] [Language models align with brain regions that represent concepts across modalities](https://arxiv.org/abs/2508.11536)
*Maria Ryskina,Greta Tuckute,Alexander Fung,Ashley Malkin,Evelina Fedorenko*

Main category: cs.CL

TL;DR: 本研究探讨语言模型与大脑活动的关系，发现语言模型更能预测与概念意义一致性高的大脑区域的信号。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型与大脑中语言处理及跨模态概念意义表示的关系。

Method: 通过fMRI数据分析大脑对句子、词云和图像的反应一致性及与语言模型的对齐情况。

Result: 发现语义一致性高的大脑区域的信号由语言模型更好地预测，即便这些区域不敏感于语言处理。

Conclusion: 语言模型可能内部存在跨模态概念意义的表示。

Abstract: Cognitive science and neuroscience have long faced the challenge of
disentangling representations of language from representations of conceptual
meaning. As the same problem arises in today's language models (LMs), we
investigate the relationship between LM--brain alignment and two neural
metrics: (1) the level of brain activation during processing of sentences,
targeting linguistic processing, and (2) a novel measure of meaning consistency
across input modalities, which quantifies how consistently a brain region
responds to the same concept across paradigms (sentence, word cloud, image)
using an fMRI dataset (Pereira et al., 2018). Our experiments show that both
language-only and language-vision models predict the signal better in more
meaning-consistent areas of the brain, even when these areas are not strongly
sensitive to language processing, suggesting that LMs might internally
represent cross-modal conceptual meaning.

</details>


### [134] [AgentMental: An Interactive Multi-Agent Framework for Explainable and Adaptive Mental Health Assessment](https://arxiv.org/abs/2508.11567)
*Jinpeng Hu,Ao Wang,Qianqian Xie,Hui Ma,Zhuo Li,Dan Guo*

Main category: cs.CL

TL;DR: 本文提出了一种多智能体心理健康评估框架，模拟医生-患者对话，动态调整提问策略，并通过实验验证了其性能优越性。


<details>
  <summary>Details</summary>
Motivation: 传统心理健康评估因专业人员短缺受到限制，而现有自动化方法多局限于静态文本分析，无法全面捕捉动态交互中的有效信息。

Method: 作者设计了一个多智能体框架，其中不同智能体负责提问、评价响应充分性、评分及信息更新；引入自适应提问机制，根据用户回复动态生成后续问题，并通过树状记忆结构有效组织和更新信息。

Result: 实验在DAIC-WOZ数据集上表明，该方法优于现有其他方法。

Conclusion: 本文提出的方法能够更全面捕捉和处理用户信息，为自动化心理健康评估提供了一种更具潜力的解决方案。

Abstract: Mental health assessment is crucial for early intervention and effective
treatment, yet traditional clinician-based approaches are limited by the
shortage of qualified professionals. Recent advances in artificial intelligence
have sparked growing interest in automated psychological assessment, yet most
existing approaches are constrained by their reliance on static text analysis,
limiting their ability to capture deeper and more informative insights that
emerge through dynamic interaction and iterative questioning. Therefore, in
this paper, we propose a multi-agent framework for mental health evaluation
that simulates clinical doctor-patient dialogues, with specialized agents
assigned to questioning, adequacy evaluation, scoring, and updating. We
introduce an adaptive questioning mechanism in which an evaluation agent
assesses the adequacy of user responses to determine the necessity of
generating targeted follow-up queries to address ambiguity and missing
information. Additionally, we employ a tree-structured memory in which the root
node encodes the user's basic information, while child nodes (e.g., topic and
statement) organize key information according to distinct symptom categories
and interaction turns. This memory is dynamically updated throughout the
interaction to reduce redundant questioning and further enhance the information
extraction and contextual tracking capabilities. Experimental results on the
DAIC-WOZ dataset illustrate the effectiveness of our proposed method, which
achieves better performance than existing approaches.

</details>


### [135] [Aware First, Think Less: Dynamic Boundary Self-Awareness Drives Extreme Reasoning Efficiency in Large Language Models](https://arxiv.org/abs/2508.11582)
*Qiguang Chen,Dengyun Peng,Jinhao Liu,HuiKang Su,Jiannan Guan,Libo Qin,Wanxiang Che*

Main category: cs.CL

TL;DR: 论文讨论了通过动态调整推理深度，提高大语言模型长链式推理效率的新框架。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在长链式推理中存在冗余，降低了计算效率，本文为解决这一问题提出解决方案。

Method: 提出了动态推理边界自适应框架(DR. SAF)，包括三个核心模块：边界自觉对齐、自适应回报管理和边界保留机制。

Result: 实验表明，DR. SAF在效率和精度之间实现了显著优化，减少约49.27%的响应token，同时提升token效率达6.59倍并缩短训练时间5倍。

Conclusion: DR. SAF在资源受限环境下展现优异性能，甚至在极端训练情况下能超越传统模型，具有较高实践价值。

Abstract: Recent advancements in large language models (LLMs) have greatly improved
their capabilities on complex reasoning tasks through Long Chain-of-Thought
(CoT). However, this approach often results in substantial redundancy,
impairing computational efficiency and causing significant delays in real-time
applications. To improve the efficiency, current methods often rely on
human-defined difficulty priors, which do not align with the LLM's self-awared
difficulty, leading to inefficiencies. In this paper, we introduce the Dynamic
Reasoning-Boundary Self-Awareness Framework (DR. SAF), which enables models to
dynamically assess and adjust their reasoning depth in response to problem
complexity. DR. SAF integrates three key components: Boundary Self-Awareness
Alignment, Adaptive Reward Management, and a Boundary Preservation Mechanism.
These components allow models to optimize their reasoning processes, balancing
efficiency and accuracy without compromising performance. Our experimental
results demonstrate that DR. SAF achieves a 49.27% reduction in total response
tokens with minimal loss in accuracy. The framework also delivers a 6.59x gain
in token efficiency and a 5x reduction in training time, making it well-suited
to resource-limited settings. During extreme training, DR. SAF can even surpass
traditional instruction-based models in token efficiency with more than 16%
accuracy improvement.

</details>


### [136] [Representing Speech Through Autoregressive Prediction of Cochlear Tokens](https://arxiv.org/abs/2508.11598)
*Greta Tuckute,Klemen Kotar,Evelina Fedorenko,Daniel L. K. Yamins*

Main category: cs.CL

TL;DR: 介绍了AuriStream，一个模仿人类听觉处理的语音编码两阶段模型，具有强大的表征能力并能生成连续音频。


<details>
  <summary>Details</summary>
Motivation: 借鉴人类听觉处理机制，开发更高效处理语音任务的模型。

Method: 提出了两阶段框架：第一阶段将音频转换为基于人工耳蜗的时频表示并提取离散耳蜗令牌；第二阶段通过耳蜗令牌进行自回归序列建模。

Result: AuriStream学习了有意义的音素、单词表示以及最先进的词汇语义；在SUPERB语音任务中表现竞争力；提供音频预测及生成功能，用于可视化与解码。

Conclusion: AuriStream推动了更接近人类听觉处理的语音表征学习发展，可高效应对多种语音任务，同时提供独特的生成与分析能力。

Abstract: We introduce AuriStream, a biologically inspired model for encoding speech
via a two-stage framework inspired by the human auditory processing hierarchy.
The first stage transforms raw audio into a time-frequency representation based
on the human cochlea, from which we extract discrete \textbf{cochlear tokens}.
The second stage applies an autoregressive sequence model over the cochlear
tokens. AuriStream learns meaningful phoneme and word representations, and
state-of-the-art lexical semantics. AuriStream shows competitive performance on
diverse downstream SUPERB speech tasks. Complementing AuriStream's strong
representational capabilities, it generates continuations of audio which can be
visualized in a spectrogram space and decoded back into audio, providing
insights into the model's predictions. In summary, we present a two-stage
framework for speech representation learning to advance the development of more
human-like models that efficiently handle a range of speech-based tasks.

</details>


### [137] [Dataset Creation for Visual Entailment using Generative AI](https://arxiv.org/abs/2508.11605)
*Rob Reijtenbach,Suzan Verberne,Gijs Wijnholds*

Main category: cs.CL

TL;DR: 提出并验证了一种新的合成数据集，用于训练视觉蕴含模型，利用SNLI数据集合成图像并进行验证，实验结果表明合成数据集在某些数据稀疏条件下表现良好。


<details>
  <summary>Details</summary>
Motivation: 目前用于视觉蕴含的训练数据集既小又稀疏，手动创建数据集成本高昂，因此需要寻找新的数据生成方法。

Method: 基于文本蕴含的SNLI数据集，将前提文本输入生成式图像模型Stable Diffusion生成图像，替代文本前提；从数据内在特性和外部表现两个方面评估数据集质量。

Result: 在使用合成数据进行训练时，与真实数据相比，SNLI-VE数据集F分数仅稍微下降（从0.703到0.686），在SICK-VTE数据集上也类似（从0.400下降到0.384），表明合成数据在数据稀疏情境下表现出潜力。

Conclusion: 实验表明，合成数据能够在一定程度上代替真实数据用于视觉蕴含模型的训练，对解决数据稀疏问题具有实际价值。

Abstract: In this paper we present and validate a new synthetic dataset for training
visual entailment models. Existing datasets for visual entailment are small and
sparse compared to datasets for textual entailment. Manually creating datasets
is labor-intensive. We base our synthetic dataset on the SNLI dataset for
textual entailment. We take the premise text from SNLI as input prompts in a
generative image model, Stable Diffusion, creating an image to replace each
textual premise. We evaluate our dataset both intrinsically and extrinsically.
For extrinsic evaluation, we evaluate the validity of the generated images by
using them as training data for a visual entailment classifier based on CLIP
feature vectors. We find that synthetic training data only leads to a slight
drop in quality on SNLI-VE, with an F-score 0.686 compared to 0.703 when
trained on real data. We also compare the quality of our generated training
data to original training data on another dataset: SICK-VTE. Again, there is
only a slight drop in F-score: from 0.400 to 0.384. These results indicate that
in settings with data sparsity, synthetic data can be a promising solution for
training visual entailment models.

</details>


### [138] [TinyTim: A Family of Language Models for Divergent Generation](https://arxiv.org/abs/2508.11607)
*Christopher J. Agostino*

Main category: cs.CL

TL;DR: TinyTim是一组基于詹姆斯·乔伊斯的《芬尼根的守灵夜》微调的大语言模型。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用特定文本训练语言模型以提升创意与复杂任务解决能力。

Method: 通过定量评估，与基线模型比较，分析生成模型的词汇多样性与语义连贯性。

Result: TinyTim V1展现出高词汇多样性和低语义连贯性的独特生成特性。

Conclusion: 该模型可作为广泛创意性架构中的发散知识来源，助力多样情境下的自动化发现机制。

Abstract: This work introduces TinyTim, a family of large language models fine-tuned on
James Joyce's `Finnegans Wake'. Through quantitative evaluation against
baseline models, we demonstrate that TinyTim V1 produces a statistically
distinct generative profile characterized by high lexical diversity and low
semantic coherence. These findings are interpreted through theories of
creativity and complex problem-solving, arguing that such specialized models
can function as divergent knowledge sources within more extensive creative
architectures, powering automated discovery mechanisms in diverse settings.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [139] [Grounding Rule-Based Argumentation Using Datalog](https://arxiv.org/abs/2508.10976)
*Martin Diller,Sarah Alice Gaggl,Philipp Hanisch,Giuseppina Monterosso,Fritz Rauschenbach*

Main category: cs.AI

TL;DR: ASPIC+支持规则论证，但目前同类方法多基于命题规则，造成推导输入理论爆炸问题。研究提出智能化第一阶ASPIC+实例的求解方法，利用Datalog完成高效实时展开，保持推导正确性并减少无效规则展开。


<details>
  <summary>Details</summary>
Motivation: 当前ASPIC+需依赖预处理的规则展开才能对第一阶实例进行推理。展开造成理论尺寸指数级增长，对智能化展开方法的需求迫切。

Method: 通过将第一阶ASPIC+实例转化为Datalog程序，调用Datalog引擎获得紧凑的规则实例。此外，针对ASPIC+规则特点设计无影响规则的跳过机制。

Result: 提出的原型系统展现了ASPIC+推理方法的易扩展性和相较传统展开的显著性能优势。

Conclusion: 研究表明，结合Datalog高效处理规则实例的方法，可有效降低ASPIC+框架下的理论推理尺寸复杂度，具备实际应用潜力。

Abstract: ASPIC+ is one of the main general frameworks for rule-based argumentation for
AI. Although first-order rules are commonly used in ASPIC+ examples, most
existing approaches to reason over rule-based argumentation only support
propositional rules. To enable reasoning over first-order instances, a
preliminary grounding step is required. As groundings can lead to an
exponential increase in the size of the input theories, intelligent procedures
are needed. However, there is a lack of dedicated solutions for ASPIC+.
Therefore, we propose an intelligent grounding procedure that keeps the size of
the grounding manageable while preserving the correctness of the reasoning
process. To this end, we translate the first-order ASPIC+ instance into a
Datalog program and query a Datalog engine to obtain ground substitutions to
perform the grounding of rules and contraries. Additionally, we propose
simplifications specific to the ASPIC+ formalism to avoid grounding of rules
that have no influence on the reasoning process. Finally, we performed an
empirical evaluation of a prototypical implementation to show scalability.

</details>


### [140] [From Individual to Multi-Agent Algorithmic Recourse: Minimizing the Welfare Gap via Capacitated Bipartite Matching](https://arxiv.org/abs/2508.11070)
*Zahra Khotanlou,Kate Larson,Amir-Hossein Karimi*

Main category: cs.AI

TL;DR: 此论文提出了一个多代理算法补救框架，解决多个求助者和多个提供者之间的优化问题，通过三层优化框架实现了近乎最优的社会福利，强调了从个体至系统的设计扩展。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单一求助者与单一模型场景，但现实世界中涉及多方互动的复杂系统，需要一个能优化多代理相互作用的解决方案。

Method: 提出一个三层优化框架，包括基本的匹配优化，容量重新分配以缩小福利差距，以及带成本约束的福利最大化。

Result: 通过实验验证，该框架在实现接近最优社会福利的同时，最小化了对系统设置的修改。

Conclusion: 该工作将算法补救从个体建议扩展到系统级别设计，为实现更高的社会福利提供了可行的途径，同时保持了个体操作性。

Abstract: Decision makers are increasingly relying on machine learning in sensitive
situations. In such settings, algorithmic recourse aims to provide individuals
with actionable and minimally costly steps to reverse unfavorable AI-driven
decisions. While existing research predominantly focuses on single-individual
(i.e., seeker) and single-model (i.e., provider) scenarios, real-world
applications often involve multiple interacting stakeholders. Optimizing
outcomes for seekers under an individual welfare approach overlooks the
inherently multi-agent nature of real-world systems, where individuals interact
and compete for limited resources. To address this, we introduce a novel
framework for multi-agent algorithmic recourse that accounts for multiple
recourse seekers and recourse providers. We model this many-to-many interaction
as a capacitated weighted bipartite matching problem, where matches are guided
by both recourse cost and provider capacity. Edge weights, reflecting recourse
costs, are optimized for social welfare while quantifying the welfare gap
between individual welfare and this collectively feasible outcome. We propose a
three-layer optimization framework: (1) basic capacitated matching, (2) optimal
capacity redistribution to minimize the welfare gap, and (3) cost-aware
optimization balancing welfare maximization with capacity adjustment costs.
Experimental validation on synthetic and real-world datasets demonstrates that
our framework enables the many-to-many algorithmic recourse to achieve
near-optimal welfare with minimum modification in system settings. This work
extends algorithmic recourse from individual recommendations to system-level
design, providing a tractable path toward higher social welfare while
maintaining individual actionability.

</details>


### [141] [Learn to optimize for automatic proton PBS treatment planning for H&N cancers](https://arxiv.org/abs/2508.11085)
*Qingqing Wang,Liqiang Xiao,Chang Chang*

Main category: cs.AI

TL;DR: 本文提出了一种基于PPO(近端策略优化)的自动治疗计划框架及数据驱动的逆优化器，用于头颈癌的质子PBS治疗。


<details>
  <summary>Details</summary>
Motivation: 现有头颈癌质子PBS治疗计划方法，因目标冲突复杂而需大量人工调整，同时逆优化依赖理论方法，效率低。

Method: 提出融合L2O(学习优化算法)的逆优化器和PPO框架，将长上下文处理技术集成于Transformer中的L2O方法解决现有方法的可扩展性问题。

Result: 研究收集了97名病例数据，与传统方法相比，逆优化器的效果提高了22.97%，效率提高了36.41%。自动生成的计划在目标覆盖和OAR（正常组织器官）对比人生成计划表现更优或相当。

Conclusion: 该方法显著提升了头颈癌质子治疗计划的自动化水平和临床适用性，减少了人为干预时间，同时达到高质量治疗效果。

Abstract: Proton PBS treatment planning for H&N cancers involves numerous conflicting
objectives, requiring significant effort from human planners to balance and
satisfy multiple clinical goals during planning. To achieve this,
experience-demanding objective parameter adjustment and computationally
expensive inverse optimization are performed iteratively. Extensive efforts
have been made to automatically adjust objective parameters, but the most
time-consuming component, i.e., inverse optimization, still relies heavily on
theory-driven approaches. We propose a data-driven inverse optimizer and
integrate it into a PPO-based automatic treatment planning framework to
automatically generate high-quality plans within a clinical acceptable planning
time. The inverse optimizer is a L2O method that predicts update steps by
learning from the task-specific data distribution. For the first time, we
integrate techniques designed for long-context processing, originally developed
for LLMs, into a Transformer-based L2O framework to address the scalability
issue of existing L2O methods. The PPO framework functions as an outer-loop
virtual planner, autonomously adjusting objective parameters through a policy
network, and the dose predictor is used to initialize objective parameters. The
inner-loop L2O inverse optimizer computes machine-deliverable MU values based
on objectives refined by the PPO policy network. 97 patients are collected in
this study, and compared with L-BFGSB, our L2O-based inverse optimizer improves
the effectiveness and efficiency by 22.97% and 36.41%, respectively. In
conjunction with the PPO-based learned virtual planner, plans generated by our
framework within an average of 2.55 hours show improved or comparable OAR
sparing with superior target coverage for patients with different prescription
dose levels, number of target volumes, beam angles, etc., compared with
human-generated plans.

</details>


### [142] [On Strong and Weak Admissibility in Non-Flat Assumption-Based Argumentation](https://arxiv.org/abs/2508.11182)
*Matti Berthold,Lydia Blümel,Anna Rapberger*

Main category: cs.AI

TL;DR: 本文扩展了假设基础论证 (ABA) 中可采性概念的研究，引入强和弱可采性，定义相关的语义，并讨论它们的特性。


<details>
  <summary>Details</summary>
Motivation: 探讨现有ABA中标准可采性概念的局限性，研究新的可采性概念(强、弱可采性)以解决相关问题。

Method: 使用抽象的两极集合论证框架 (BSAFs)，分析并定义ABA中的强和弱可采性以及相关语义，并延展到一般非“平直”ABA框架下的研究。

Result: 证明多个关键模块化属性在经典、强、弱可采性下均能保持，并分析强、弱可采性语义与标准语义的不足之处。

Conclusion: 强可采性首次被提出并研究；弱可采性拓展到非平直ABA；这两种语义在一定程度上解决了不足，但仍存在某些限制。

Abstract: In this work, we broaden the investigation of admissibility notions in the
context of assumption-based argumentation (ABA). More specifically, we study
two prominent alternatives to the standard notion of admissibility from
abstract argumentation, namely strong and weak admissibility, and introduce the
respective preferred, complete and grounded semantics for general (sometimes
called non-flat) ABA. To do so, we use abstract bipolar set-based argumentation
frameworks (BSAFs) as formal playground since they concisely capture the
relations between assumptions and are expressive enough to represent general
non-flat ABA frameworks, as recently shown. While weak admissibility has been
recently investigated for a restricted fragment of ABA in which assumptions
cannot be derived (flat ABA), strong admissibility has not been investigated
for ABA so far. We introduce strong admissibility for ABA and investigate
desirable properties. We furthermore extend the recent investigations of weak
admissibility in the flat ABA fragment to the non-flat case. We show that the
central modularization property is maintained under classical, strong, and weak
admissibility. We also show that strong and weakly admissible semantics in
non-flat ABA share some of the shortcomings of standard admissible semantics
and discuss ways to address these.

</details>


### [143] [Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information](https://arxiv.org/abs/2508.11252)
*Youcheng Huang,Bowen Qin,Chen Huang,Duanyu Feng,Xi Yang,Wenqiang Lei*

Main category: cs.AI

TL;DR: 研究显示大型推理模型（LRMs）在处理数学问题方面表现出色，但在面对信息不足问题时，无法主动询问信息，本文提出新的数据集和评估方法来弥补此缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有评估仅专注于LRMs在解答明确问题上的能力，但人工智能的真正智能应包括主动获取信息的能力。

Method: 提出一个包含两类上下文丰富的非完整问题的新数据集，并系统化评估LRMs在面对信息不足问题时的表现。

Result: 发现LRMs无法主动询问信息，并揭示其过度思考和幻觉行为，还讨论了监督微调的潜力与挑战。

Conclusion: 研究提供了新的见解，指向开发具备真正智能的大型推理模型，而不仅仅局限于问题求解能力。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable problem-solving
abilities in mathematics, as evaluated by existing benchmarks exclusively on
well-defined problems. However, such evaluation setup constitutes a critical
gap, since a genuine intelligent agent should not only solve problems (as a
math quiz solver), but also be able~to ask for information when the problems
lack sufficient information, enabling proactivity in responding users'
requests. To bridge such gap, we proposes a new dataset consisting of two types
of incomplete problems with diverse contexts. Based on the dataset, our
systematical evaluation of LRMs reveals their inability in proactively asking
for information. In addition, we uncover the behaviors related to overthinking
and hallucination of LRMs, and highlight the potential and challenges of
supervised fine-tuning in learning such ability. We hope to provide new
insights in developing LRMs with genuine intelligence, rather than just solving
problems.

</details>


### [144] [SAGE: Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding](https://arxiv.org/abs/2508.11347)
*Yifei Li,Lingling Zhang,Hang Yan,Tianzhe Zhao,Zihan Ma,Muye Huang,Jun Liu*

Main category: cs.AI

TL;DR: 本论文提出了一种面向可持续知识图谱嵌入（CKGE）的框架SAGE，针对更新规模自适应调整嵌入维度并使用动态蒸馏机制平衡旧知识保留与新知识吸收。


<details>
  <summary>Details</summary>
Motivation: 现有的CKGE方法未能有效考虑真实世界动态知识图谱中更新的不同尺度并缺乏系统性评价。

Method: 提出了SAGE框架：根据更新规模自适应调整嵌入维度，同时引入动态蒸馏机制来平衡知识保留与吸收。

Result: 在七个基准数据集上测试，SAGE在MRR提升1.38%、H@1提升1.25%、H@10提升1.6%，且在所有快照中均达到最佳性能。

Conclusion: SAGE通过可变嵌入维度显著提升CKGE性能，验证了动态维度的重要性。

Abstract: Traditional knowledge graph (KG) embedding methods aim to represent entities
and relations in a low-dimensional space, primarily focusing on static graphs.
However, real-world KGs are dynamically evolving with the constant addition of
entities, relations and facts. To address such dynamic nature of KGs, several
continual knowledge graph embedding (CKGE) methods have been developed to
efficiently update KG embeddings to accommodate new facts while maintaining
learned knowledge. As KGs grow at different rates and scales in real-world
scenarios, existing CKGE methods often fail to consider the varying scales of
updates and lack systematic evaluation throughout the entire update process. In
this paper, we propose SAGE, a scale-aware gradual evolution framework for
CKGE. Specifically, SAGE firstly determine the embedding dimensions based on
the update scales and expand the embedding space accordingly. The Dynamic
Distillation mechanism is further employed to balance the preservation of
learned knowledge and the incorporation of new facts. We conduct extensive
experiments on seven benchmarks, and the results show that SAGE consistently
outperforms existing baselines, with a notable improvement of 1.38% in MRR,
1.25% in H@1 and 1.6% in H@10. Furthermore, experiments comparing SAGE with
methods using fixed embedding dimensions show that SAGE achieves optimal
performance on every snapshot, demonstrating the importance of adaptive
embedding dimensions in CKGE. The codes of SAGE are publicly available at:
https://github.com/lyfxjtu/Dynamic-Embedding.

</details>


### [145] [CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks](https://arxiv.org/abs/2508.11360)
*Songqin Nong,Jingxuan Xu,Sheng Zhou,Jianfeng Chen,Xiaoxuan Tang,Tao Jiang,Wenhao Xu*

Main category: cs.AI

TL;DR: 本研究提出了一种名为CRAFT-GUI的框架，通过集成强化学习和课程学习来有效解决GUI任务的训练难度不均和奖励信号单一的问题，并显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在GUI任务中存在训练数据难度不均和奖励信号单一的问题，影响了模型的学习效率和性能。

Method: 提出了CRAFT-GUI框架，基于组相对策略优化（GRPO）进行课程学习，并设计了一种结合规则信号和模型评估的奖励函数，为模型提供更细粒度的优化反馈。

Result: 实验结果表明，与现有最优方法相比，CRAFT-GUI在公开基准测试（Android Control）中性能提升5.6%，在内部在线基准中提升10.3%。

Conclusion: 实验证明，结合课程学习的强化学习方法能够有效提升在动态交互GUI环境中的任务执行性能。

Abstract: As autonomous agents become adept at understanding and interacting with
graphical user interface (GUI) environments, a new era of automated task
execution is emerging. Recent studies have demonstrated that Reinforcement
Learning (RL) can effectively enhance agents' performance in dynamic
interactive GUI environments. However, these methods face two key limitations:
(1) they overlook the significant variation in difficulty across different GUI
tasks by treating the entire training data as a uniform set, which hampers the
agent's ability to adapt its learning process; and (2) most approaches collapse
task-specific nuances into a single, coarse reward, leaving the agent with a
uniform signal that yields inefficient policy updates. To address these
limitations, we propose CRAFT-GUI, a curriculum learning framework based on
Group Relative Policy Optimization (GRPO) that explicitly accounts for the
varying difficulty across trajectories. To enable more fine-grained policy
optimization, we design a reward function that combines simple rule-based
signals with model-judged evaluation, providing richer and more nuanced
feedback during training. Experimental results demonstrate that our method
achieves significant improvements over previous state-of-the-art approaches,
outperforming them by 5.6% on public benchmarks Android Control and 10.3% on
our internal online benchmarks, respectively. These findings empirically
validate the effectiveness of integrating reinforcement learning with
curriculum learning in GUI interaction tasks.

</details>


### [146] [AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager](https://arxiv.org/abs/2508.11416)
*Xuhua Zhao,Yuxuan Xie,Caihua Chen,Yuxiang Sun*

Main category: cs.AI

TL;DR: 本文提出了AIM-Bench基准，用于评估大型语言模型（LLM）在不确定供应链管理场景中的决策行为。结果表明，不同时LLM模型的决策偏差程度类似于人类的决策偏差。


<details>
  <summary>Details</summary>
Motivation: 旨在探索LLM在不确定背景下进行库存决策的能力，以及其在商业操作中可能存在的决策偏差问题。

Method: 引入了AIM-Bench基准，通过多样化的库存补充实验评估LLM在不确定供应链管理场景下的决策行为。

Result: 不同的LLM模型展现出了不同程度的决策偏差，类似于人类的决策行为。此外，研究了认知反思和信息共享策略以缓解拉中效应和牛鞭效应。

Conclusion: 强调了在库存决策场景中部署LLM时需谨慎考虑其潜在偏差，并期望这些结果能够推动减轻人类决策偏差和开发以人为中心的供应链决策支持系统的发展。

Abstract: Recent advances in mathematical reasoning and the long-term planning
capabilities of large language models (LLMs) have precipitated the development
of agents, which are being increasingly leveraged in business operations
processes. Decision models to optimize inventory levels are one of the core
elements of operations management. However, the capabilities of the LLM agent
in making inventory decisions in uncertain contexts, as well as the
decision-making biases (e.g. framing effect, etc.) of the agent, remain largely
unexplored. This prompts concerns regarding the capacity of LLM agents to
effectively address real-world problems, as well as the potential implications
of biases that may be present. To address this gap, we introduce AIM-Bench, a
novel benchmark designed to assess the decision-making behaviour of LLM agents
in uncertain supply chain management scenarios through a diverse series of
inventory replenishment experiments. Our results reveal that different LLMs
typically exhibit varying degrees of decision bias that are similar to those
observed in human beings. In addition, we explored strategies to mitigate the
pull-to-centre effect and the bullwhip effect, namely cognitive reflection and
implementation of information sharing. These findings underscore the need for
careful consideration of the potential biases in deploying LLMs in Inventory
decision-making scenarios. We hope that these insights will pave the way for
mitigating human decision bias and developing human-centred decision support
systems for supply chains.

</details>


### [147] [Inclusion Arena: An Open Platform for Evaluating Large Foundation Models with Real-World Apps](https://arxiv.org/abs/2508.11452)
*Kangyu Wang,Hongliang He,Lin Liu,Ruiqi Liang,Zhenzhong Lan,Jianguo Li*

Main category: cs.AI

TL;DR: 本文提出了一个名为Inclusion Arena的在线排行榜，通过整合真人反馈的数据进行大模型排名，旨在弥补静态数据集和通用领域提示的不足。


<details>
  <summary>Details</summary>
Motivation: 目前的评测方法大多基于静态数据集或众包提示，无法很好地反映模型在现实世界应用中的表现，本研究旨在填补这一空白。

Method: Inclusion Arena在用户交互过程中收集人类反馈，采用Bradley-Terry模型进行模型排名，并引入了快速评价新模型的Placement Matches机制和优先比较能力相近模型的Proximity Sampling策略。

Result: 分析和仿真实验证明，Inclusion Arena提供了可靠且稳定的排名，比通用众包数据集具有更高的数据传递性，同时有效减轻了恶意操控的风险。

Conclusion: 该平台通过开放的模型与真实应用的协作，加速了面向现实用户部署的大模型优化。

Abstract: Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)
have ushered in a new era of AI capabilities, demonstrating near-human-level
performance across diverse scenarios. While numerous benchmarks (e.g., MMLU)
and leaderboards (e.g., Chatbot Arena) have been proposed to help evolve the
development of LLMs and MLLMs, most rely on static datasets or crowdsourced
general-domain prompts, often falling short of reflecting performance in
real-world applications. To bridge this critical gap, we present Inclusion
Arena, a live leaderboard that ranks models based on human feedback collected
directly from AI-powered applications. Our platform integrates pairwise model
comparisons into natural user interactions, ensuring evaluations reflect
practical usage scenarios. For robust model ranking, we employ the
Bradley-Terry model augmented with two key innovations: (1) Placement Matches,
a cold-start mechanism to quickly estimate initial ratings for newly integrated
models, and (2) Proximity Sampling, an intelligent comparison strategy that
prioritizes battles between models of similar capabilities to maximize
information gain and enhance rating stability. Extensive empirical analyses and
simulations demonstrate that Inclusion Arena yields reliable and stable
rankings, exhibits higher data transitivity compared to general crowdsourced
datasets, and significantly mitigates the risk of malicious manipulation. By
fostering an open alliance between foundation models and real-world
applications, Inclusion Arena aims to accelerate the development of LLMs and
MLLMs truly optimized for practical, user-centric deployments. The platform is
publicly accessible at https://doraemon.alipay.com/model-ranking.

</details>


### [148] [Landmark-Assisted Monte Carlo Planning](https://arxiv.org/abs/2508.11493)
*David H. Chan,Mark Roberts,Dana S. Nau*

Main category: cs.AI

TL;DR: 本文探讨了在随机领域中使用概率地标对MDP的分解优化，并通过UCT算法增强规划效率。


<details>
  <summary>Details</summary>
Motivation: 研究随机领域中如何通过地标分解MDP，提升在线规划性能。

Method: 提出概率地标的形式化定义，并将其融合到UCT算法中，作为子目标进行解问题分解，同时寻求贪婪与终极目标之间的平衡。

Result: 实验表明，通过精心选择的地标，可以显著提高UCT算法在在线概率规划中的性能，但目标之间的最佳平衡取决于具体问题。

Conclusion: 地标可以为求解MDP的即时性算法提供有效指导。

Abstract: Landmarks$\unicode{x2013}$conditions that must be satisfied at some point in
every solution plan$\unicode{x2013}$have contributed to major advancements in
classical planning, but they have seldom been used in stochastic domains. We
formalize probabilistic landmarks and adapt the UCT algorithm to leverage them
as subgoals to decompose MDPs; core to the adaptation is balancing between
greedy landmark achievement and final goal achievement. Our results in
benchmark domains show that well-chosen landmarks can significantly improve the
performance of UCT in online probabilistic planning, while the best balance of
greedy versus long-term goal achievement is problem-dependent. The results
suggest that landmarks can provide helpful guidance for anytime algorithms
solving MDPs.

</details>


### [149] [Inspire or Predict? Exploring New Paradigms in Assisting Classical Planners with Large Language Models](https://arxiv.org/abs/2508.11524)
*Wenkai Yu,Jianhang Tang,Yang Zhang,Shanjiang Tang,Kebing Jin,Hankz Hankui Zhuo*

Main category: cs.AI

TL;DR: 提出了一种结合LLM和问题分解的新型规划方法，有效解决了大规模规划问题中的搜索空间膨胀问题。


<details>
  <summary>Details</summary>
Motivation: 应对因对象和动作增长导致的状态空间爆炸问题，现有研究未充分融合LLM和领域知识以生成有效计划。

Method: 设计了一种LLM辅助的规划器，首先将问题分解为子任务，然后提出LLM4Inspire（提供启发式指导）和LLM4Predict（运用领域知识推断中间条件）两种范式。

Result: 通过实验证明，LLM能够有效缩小搜索空间范围，特别是结合领域知识的LLM4Predict表现更优。

Conclusion: 将LLMs与问题分解以及领域知识整合，是解决大规模规划问题的一种有效方案。

Abstract: Addressing large-scale planning problems has become one of the central
challenges in the planning community, deriving from the state-space explosion
caused by growing objects and actions. Recently, researchers have explored the
effectiveness of leveraging Large Language Models (LLMs) to generate helpful
actions and states to prune the search space. However, prior works have largely
overlooked integrating LLMs with domain-specific knowledge to ensure valid
plans. In this paper, we propose a novel LLM-assisted planner integrated with
problem decomposition, which first decomposes large planning problems into
multiple simpler sub-tasks. Then we explore two novel paradigms to utilize
LLMs, i.e., LLM4Inspire and LLM4Predict, to assist problem decomposition, where
LLM4Inspire provides heuristic guidance according to general knowledge and
LLM4Predict employs domain-specific knowledge to infer intermediate conditions.
We empirically validate the effectiveness of our planner across multiple
domains, demonstrating the ability of search space partition when solving
large-scale planning problems. The experimental results show that LLMs
effectively locate feasible solutions when pruning the search space, where
infusing domain-specific knowledge into LLMs, i.e., LLM4Predict, holds
particular promise compared with LLM4Inspire, which offers general knowledge
within LLMs.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [150] [A Cooperative Game-Based Multi-Criteria Weighted Ensemble Approach for Multi-Class Classification](https://arxiv.org/abs/2508.10926)
*DongSeong-Yoon*

Main category: cs.LG

TL;DR: 提出了一种通过合作博弈在多标准情况下进行决策的新方法，用以提升机器学习中投票集成模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有加权方法只考虑单一评价标准，未能全面反映模型中应考虑的信息，因此提出更全面的方法解决问题。

Method: 通过合作博弈的方法引入多种已知信息，同时为分类器分配适当权重，优化投票集成学习的规则。

Result: 在Open-ML-CC18数据集上的实验结果显示，新方法性能优于现有加权集成学习方法。

Conclusion: 运用合作博弈的多标准集成加权方法有效提升了分类模型的性能，具有显著的改进效果。

Abstract: Since the Fourth Industrial Revolution, AI technology has been widely used in
many fields, but there are several limitations that need to be overcome,
including overfitting/underfitting, class imbalance, and the limitations of
representation (hypothesis space) due to the characteristics of different
models. As a method to overcome these problems, ensemble, commonly known as
model combining, is being extensively used in the field of machine learning.
Among ensemble learning methods, voting ensembles have been studied with
various weighting methods, showing performance improvements. However, the
existing methods that reflect the pre-information of classifiers in weights
consider only one evaluation criterion, which limits the reflection of various
information that should be considered in a model realistically. Therefore, this
paper proposes a method of making decisions considering various information
through cooperative games in multi-criteria situations. Using this method,
various types of information known beforehand in classifiers can be
simultaneously considered and reflected, leading to appropriate weight
distribution and performance improvement. The machine learning algorithms were
applied to the Open-ML-CC18 dataset and compared with existing ensemble
weighting methods. The experimental results showed superior performance
compared to other weighting methods.

</details>


### [151] [Apriel-Nemotron-15B-Thinker](https://arxiv.org/abs/2508.10948)
*Shruthan Radhakrishna,Soham Parikh,Gopal Sarda,Anil Turkkan,Quaizar Vohra,Raymond Li,Dhruv Jhamb,Kelechi Ogueji,Aanjaneya Shukla,Oluwanifemi Bamgbose,Toby Liang,Luke Kumar,Oleksiy Ostapenko,Shiva Krishna Reddy Malay,Aman Tiwari,Tara Bogavelli,Vikas Yadav,Jash Mehta,Saloni Mittal,Akshay Kalkunte,Pulkit Pattnaik,Khalil Slimi,Anirudh Sreeram,Jishnu Nair,Akintunde Oladipo,Shashank Maiya,Khyati Mahajan,Rishabh Maheshwary,Masoud Hashemi,Sai Rajeswar Mudumba,Sathwik Tejaswi Madhusudhan,Torsten Scholak,Sebastien Paquet,Sagar Davasam,Srinivas Sunkara*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种参数量为15亿的语言模型——Apriel-Nemotron-15B-Thinker，其性能与现有更大规模的32亿参数模型相当，但内存占用仅为后者的一半。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在实际企业环境中由于高内存与计算成本而难以应用的问题。

Method: 提出了一个四阶段训练管线：1）基础模型扩展；2）持续预训练；3）监督微调（SFT）；4）基于GRPO的强化学习。

Result: 实验结果显示，Apriel-Nemotron-15B-Thinker在多种基准测试中与32亿参数的模型相比，性能相当或更优，且模型规模和内存占用更低。

Conclusion: 本研究证明，通过优化训练过程，可以在显著减少资源占用的情况下，获得高性能语言模型，适用于实际企业应用场景。

Abstract: While large language models (LLMs) have achieved remarkable reasoning
capabilities across domains like code, math and other enterprise tasks, their
significant memory and computational costs often preclude their use in
practical enterprise settings. To this end, we introduce
Apriel-Nemotron-15B-Thinker, a 15-billion parameter model in the ServiceNow
Apriel SLM series that achieves performance against medium sized
state-of-the-art models such as o1-mini, QWQ32B, and EXAONE-Deep-32B while
maintaining only half the memory footprint of those alternatives.
Apriel-Nemotron-15B-Thinker model is trained in a four stage training pipeline
including 1) Base Model upscaling, 2) Continual Pre-training 3) Supervised
Fine-tuning (SFT) and 4) Reinforcement Learning using GRPO. Comprehensive
evaluations across a diverse suite of benchmarks consistently demonstrate that
our Apriel-Nemotron-15B-Thinker model matches or exceeds the performance of its
32-billion parameter counterparts, despite being less than half their size.

</details>


### [152] [Towards Efficient Prompt-based Continual Learning in Distributed Medical AI](https://arxiv.org/abs/2508.10954)
*Gyutae Oh,Jitae Shin*

Main category: cs.LG

TL;DR: 该论文提出一种基于提示的持续学习（PCL）方法，通过最小化的提示池扩展策略，在保留之前知识的同时适应新的医疗数据分布，从而提高了模型的分类精度和F1得分，同时降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 由于医疗领域的数据分布变化以及数据共享受限，传统训练方法容易过拟合并产生灾难性遗忘，无法很好地应对分布式医疗环境的需求。

Method: 提出一种基于提示的持续学习（PCL）方法，通过扩展和冻结部分提示来减少计算成本，并引入一种新正则化项来平衡知识保留和适应性。

Result: 在三个糖尿病视网膜病变数据集（Aptos2019, LI2019, Diabetic Retinopathy Detection）上进行实验，相比于最先进方法，分类精度提高至少10%，F1得分提高9点，推断成本更低。

Conclusion: 所提方法在医疗领域取得显著效果，有望推动可持续医疗AI的发展，助力实时诊断、病人监测和远程医疗应用，相关代码将在论文接受后公开。

Abstract: Modern AI models achieve state-of-the-art performance with large-scale,
high-quality datasets; however, ethical, social, and institutional constraints
in the medical domain severely restrict data sharing, rendering centralized
learning nearly impossible. Each institution must incrementally update models
using only local data. Traditional training overfits new samples and suffers
from catastrophic forgetting, losing previously acquired knowledge. Medical
data distributions also shift due to varying diagnostic equipment and
demographics. Although continual learning (CL) has advanced, most methods
address natural images, leaving medical-domain-specific CL underexplored. We
propose a prompt-based continual learning (PCL) approach featuring a unified
prompt pool with a minimal expansion strategy: by expanding and freezing a
subset of prompts, our method reduces computational overhead, and a novel
regularization term balances retention and adaptation. Experiments on three
diabetic retinopathy datasets Aptos2019, LI2019, and Diabetic Retinopathy
Detection show our model improves final classification accuracy by at least 10%
and F1-score by 9 points over state-of-the-art approaches while lowering
inference cost. We anticipate this study will drive sustainable medical AI
advances, enabling real-time diagnosis, patient monitoring, and telemedicine
applications in distributed healthcare. Code will be released upon acceptance

</details>


### [153] [Retro-Expert: Collaborative Reasoning for Interpretable Retrosynthesis](https://arxiv.org/abs/2508.10967)
*Xinyi Li,Sai Wang,Yutian Lin,Yu Wu,Yi Yang*

Main category: cs.LG

TL;DR: 本文提出了一个名为Retro-Expert的系统，该系统结合大语言模型(LLM)与专用模型，通过强化学习实现协作推理并解释化学逻辑。


<details>
  <summary>Details</summary>
Motivation: 现有模型基于静态模式匹配的方式，缺乏逻辑决策能力，导致决策过程如同黑箱操作。

Method: 提出Retro-Expert框架，结合大语言模型和专用模型的推理优势，采用强化学习进行决策优化，包含三个组件：专用模型用于建立化学决策空间；大语言模型进行关键推理并生成解释路径；强化学习优化决策策略。

Result: Retro-Expert在各种指标上优于现有基于LLM和专用模型的方法，同时还能提供符合专家逻辑的解释。

Conclusion: 该方法通过增强的解释性和精准的预测能力缩小了AI预测与化学洞察之间的差距，展现了在化学合成领域的潜在优势。

Abstract: Retrosynthesis prediction aims to infer the reactant molecule based on a
given product molecule, which is a fundamental task in chemical synthesis.
However, existing models rely on static pattern-matching paradigm, which limits
their ability to perform effective logic decision-making, leading to black-box
decision-making. Building on this, we propose Retro-Expert, an interpretable
retrosynthesis framework that performs collaborative reasoning by combining the
complementary reasoning strengths of Large Language Models and specialized
models via reinforcement learning. It outputs natural language explanations
grounded in chemical logic through three components: (1) specialized models
perform shallow reasoning to construct high-quality chemical decision space,
(2) LLM-driven critical reasoning to generate predictions and corresponding
interpretable reasoning path, and (3) reinforcement learning optimizing
interpretable decision policy. Experiments show that Retro-Expert not only
surpasses both LLM-based and specialized models across different metrics but
also provides expert-aligned explanations that bridge the gap between AI
predictions and actionable chemical insights.

</details>


### [154] [BeyondWeb: Lessons from Scaling Synthetic Data for Trillion-scale Pretraining](https://arxiv.org/abs/2508.10975)
*Pratyush Maini,Vineeth Dorna,Parth Doshi,Aldo Carranza,Fan Pan,Jack Urbanek,Paul Burstein,Alex Fang,Alvin Deng,Amro Abbas,Brett Larsen,Cody Blakeney,Charvi Bannur,Christina Baek,Darren Teh,David Schwab,Haakon Mongstad,Haoli Yin,Josh Wills,Kaleigh Mentzer,Luke Merrick,Ricardo Monti,Rishabh Adiga,Siddharth Joshi,Spandan Das,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: 本文提出BeyondWeb框架，用于生成高质量合成数据进行预训练，并在14个基准评估上明显超越现有最先进的合成数据集。


<details>
  <summary>Details</summary>
Motivation: 解决大规模语言模型在扩展数据量到一定水平后收益递减的问题，并探索如何生成高质量的合成预训练数据。

Method: 引入BeyondWeb，一个专注于生成高质量合成数据的框架；分析影响合成数据质量的各种因素，并优化多个维度以提升数据质量。

Result: BeyondWeb在多个数据集和评估上表现出显著提升，与现有方法相比提高了多达5.1个百分点，同时训练速度显著加快，且在同等资源下表现优于更大模型。

Conclusion: 生成高质量的合成数据需要多维度的联合优化，简单方法虽有小幅改进，但需要科学与实践结合才能带来显著成效。BeyondWeb就是一个成功实例。

Abstract: Recent advances in large language model (LLM) pretraining have shown that
simply scaling data quantity eventually leads to diminishing returns, hitting a
data wall. In response, the use of synthetic data for pretraining has emerged
as a promising paradigm for pushing the frontier of performance. Despite this,
the factors affecting synthetic data quality remain poorly understood. In this
work, we introduce BeyondWeb, a synthetic data generation framework that
produces high-quality synthetic data for pretraining. BeyondWeb significantly
extends the capabilities of traditional web-scale datasets, outperforming
state-of-the-art synthetic pretraining datasets such as Cosmopedia and
Nemotron-CC's high-quality synthetic subset (Nemotron-Synth) by up to 5.1
percentage points (pp) and 2.6pp, respectively, when averaged across a suite of
14 benchmark evaluations. It delivers up to 7.7x faster training than open web
data and 2.7x faster than Nemotron-Synth. Remarkably, a 3B model trained for
180B tokens on BeyondWeb outperforms an 8B model trained for the same token
budget on Cosmopedia. We also present several insights from BeyondWeb on
synthetic data for pretraining: what drives its benefits, which data to
rephrase and how, and the impact of model size and family on data quality.
Overall, our work shows that there's no silver bullet for generating
high-quality synthetic pretraining data. The best outcomes require jointly
optimizing many factors, a challenging task that requires rigorous science and
practical expertise. Naive approaches can yield modest improvements,
potentially at great cost, while well-executed methods can yield transformative
improvements, as exemplified by BeyondWeb.

</details>


### [155] [Match & Choose: Model Selection Framework for Fine-tuning Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.10993)
*Basile Lewandowski,Robert Birke,Lydia Y. Chen*

Main category: cs.LG

TL;DR: 提出了一个针对文本到图像（T2I）任务的模型选择框架，M&C，使用户能根据目标领域高效选择预训练模型，而无需对所有预训练模型进行微调。


<details>
  <summary>Details</summary>
Motivation: 随着基于扩散和Transformer架构的文本到图像（T2I）模型的快速发展，公开预训练模型的使用逐渐普及。然而，如何根据目标数据领域选择最佳的预训练模型成为了一个挑战。

Method: 提出了一个名为M&C的模型选择框架，它利用匹配图来分析模型与数据的关系，匹配图包括：节点（可用模型和数据集）和边（描述模型-数据的微调性能和数据间的相似性）。基于输入的模型/数据特征提取，以及匹配图的嵌入特征，预测最佳的微调模型。

Result: 在涉及10个T2I模型和32个数据集的实验中，M&C在61.3%的情况下成功预测出最佳微调模型，其余情况下选出了性能接近的模型。

Conclusion: M&C框架能够有效帮助用户在无需全部微调的情况下找到最适合目标领域的预训练T2I模型，为模型使用的高效性和便捷性提供了新方法。

Abstract: Text-to-image (T2I) models based on diffusion and transformer architectures
advance rapidly. They are often pretrained on large corpora, and openly shared
on a model platform, such as HuggingFace. Users can then build up AI
applications, e.g., generating media contents, by adopting pretrained T2I
models and fine-tuning them on the target dataset. While public pretrained T2I
models facilitate the democratization of the models, users face a new
challenge: which model can be best fine-tuned based on the target data domain?
Model selection is well addressed in classification tasks, but little is known
in (pretrained) T2I models and their performance indication on the target
domain. In this paper, we propose the first model selection framework, M&C,
which enables users to efficiently choose a pretrained T2I model from a model
platform without exhaustively fine-tuning them all on the target dataset. The
core of M&C is a matching graph, which consists of: (i) nodes of available
models and profiled datasets, and (ii) edges of model-data and data-data pairs
capturing the fine-tuning performance and data similarity, respectively. We
then build a model that, based on the inputs of model/data feature, and,
critically, the graph embedding feature, extracted from the matching graph,
predicts the model achieving the best quality after fine-tuning for the target
domain. We evaluate M&C on choosing across ten T2I models for 32 datasets
against three baselines. Our results show that M&C successfully predicts the
best model for fine-tuning in 61.3% of the cases and a closely performing model
for the rest.

</details>


### [156] [CURE: Critical-Token-Guided Re-concatenation for Entropy-collapse Prevention](https://arxiv.org/abs/2508.11016)
*Qingbin Li,Rongkun Xue,Jie Wang,Ming Zhou,Zhi Li,Xiaofeng Ji,Yongqi Wang,Miao Liu,Zheming Yang,Minghui Qiu,Jing Yang*

Main category: cs.LG

TL;DR: 这篇论文提出了CURE框架，解决了强化学习奖励验证（RLVR）中由于固定初始状态采样导致的熵崩塌问题，从而提升大型语言模型的推理能力，特别是在数学推理任务上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法中的静态初始状态采样会引发熵崩塌，导致模型行为的多样性降低，阻碍长期训练中的性能提升。

Method: 提出CURE框架，通过两个阶段实现探索与利用的平衡：第一阶段再生高熵关键标记并联合优化原始与分支轨迹，第二阶段引入静态初始状态采样来加强对已熟悉状态的利用。

Result: 在Qwen-2.5-Math-7B模型上的实验显示，CURE相较其他方法在六个数学基准上获得了5%的性能提升，并在熵和准确性上达到了最新水平。

Conclusion: CURE通过防止熵崩塌，在保持探索能力的同时显著增强了数学推理任务的性能，证明其在RLVR中的有效性和广泛适用性。

Abstract: Recent advances in Reinforcement Learning with Verified Reward (RLVR) have
driven the emergence of more sophisticated cognitive behaviors in large
language models (LLMs), thereby enhancing their reasoning capabilities.
However, in prior RLVR pipelines, the repeated use of static initial-state
sampling drawn exactly from the dataset distribution during each sampling phase
produced overly deterministic, low diversity model behavior, which manifested
as rapid entropy collapse and hindered sustained performance gains during
prolonged training. To address this issue, we introduce CURE
(Critical-token-gUided Re concatenation for Entropy-collapse prevention), a
two-stage framework that balances exploration and exploitation. Specifically,
in the first stage, to deliberately steer the model toward novel yet coherent
contexts, we re-generate at high-entropy critical tokens and jointly optimize
the original and the branched trajectories. The further comparison with vanilla
DAPO shows that the regeneration process achieves a better performance on math
reasoning tasks while sustaining a high-level entropy degree for exploration.
In the second stage, we continue training with static initial-state sampling by
DAPO, intentionally placing the model in a familiar state to gradually
strengthen exploitation. Extensive experiments on Qwen-2.5-Math-7B show that,
compared to other RLVR methods, CURE achieves a 5% performance gain across six
math benchmarks, establishing state-of-the-art performance in both entropy and
accuracy. A series of experiments further validate the effectiveness of our
approach. Code is available at https://github.com/CURE-Project/CURE.

</details>


### [157] [Quantization vs Pruning: Insights from the Strong Lottery Ticket Hypothesis](https://arxiv.org/abs/2508.11020)
*Aakash Kumar,Emanuele Natale*

Main category: cs.LG

TL;DR: 该论文研究了量化神经网络的理论基础，扩展了强彩票假设（SLTH）理论到有限精度网络中，并给出了初始网络参数化所需的最优边界。


<details>
  <summary>Details</summary>
Motivation: 目前对于量化神经网络理论理解有限，而低精度网络的构造已被证明可以通过剪枝大规模、随机初始化的网络实现，提出论文旨在扩展现有理论，特别是强彩票假设(SLTH)，以涵盖量化背景。

Method: 通过基于Borgs等人的数分配问题理论构建延伸SLTH到量化环境的新理论，研究了随机子集和问题（Random Subset Sum Problem）在量化设置中的表现。

Result: 在量化设置中，论文证明了目标离散神经网络的等效类可以被完全表示，并给出了所需初始网络过参数化程度的最优绑定。

Conclusion: 此工作将SLTH框架从连续扩展到离散背景下，为有限精度网络在量化中提供了深入理论支持，为未来优化量化网络效率提供基础。

Abstract: Quantization is an essential technique for making neural networks more
efficient, yet our theoretical understanding of it remains limited. Previous
works demonstrated that extremely low-precision networks, such as binary
networks, can be constructed by pruning large, randomly-initialized networks,
and showed that the ratio between the size of the original and the pruned
networks is at most polylogarithmic.
  The specific pruning method they employed inspired a line of theoretical work
known as the Strong Lottery Ticket Hypothesis (SLTH), which leverages insights
from the Random Subset Sum Problem. However, these results primarily address
the continuous setting and cannot be applied to extend SLTH results to the
quantized setting.
  In this work, we build on foundational results by Borgs et al. on the Number
Partitioning Problem to derive new theoretical results for the Random Subset
Sum Problem in a quantized setting.
  Using these results, we then extend the SLTH framework to finite-precision
networks. While prior work on SLTH showed that pruning allows approximation of
a certain class of neural networks, we demonstrate that, in the quantized
setting, the analogous class of target discrete neural networks can be
represented exactly, and we prove optimal bounds on the necessary
overparameterization of the initial network as a function of the precision of
the target network.

</details>


### [158] [Zono-Conformal Prediction: Zonotope-Based Uncertainty Quantification for Regression and Classification Tasks](https://arxiv.org/abs/2508.11025)
*Laura Lützow,Michael Eichelbeck,Mykel J. Kochenderfer,Matthias Althoff*

Main category: cs.LG

TL;DR: 本文引入了zono-conformal预测方法，通过预测zonotope提高多维输出的依赖性捕获能力，并保证概率覆盖，同时提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的保覆盖率预测方法存在计算复杂、数据需求大、以及在多维输出依赖捕获方面的不足。

Method: 提出zono-conformal预测方法，通过将zonotopic不确定性集成到基础模型中，并通过线性规划高效地识别预测zonotope，可应用于非线性基础预测器，主要针对前馈神经网络，并提供分类和回归任务的特殊设计。

Result: 在实验中，与现有方法相比，zono-conformal预测器在保证测试数据类似覆盖率的同时表现出较小的保守性。

Conclusion: zono-conformal预测方法在保覆盖率条件下改善了多维输出的依赖性捕获与计算效率，为不确定性量化预测提供了有效的新方向。

Abstract: Conformal prediction is a popular uncertainty quantification method that
augments a base predictor with prediction sets with statistically valid
coverage guarantees. However, current methods are often computationally
expensive and data-intensive, as they require constructing an uncertainty model
before calibration. Moreover, existing approaches typically represent the
prediction sets with intervals, which limits their ability to capture
dependencies in multi-dimensional outputs. We address these limitations by
introducing zono-conformal prediction, a novel approach inspired by interval
predictor models and reachset-conformant identification that constructs
prediction zonotopes with assured coverage. By placing zonotopic uncertainty
sets directly into the model of the base predictor, zono-conformal predictors
can be identified via a single, data-efficient linear program. While we can
apply zono-conformal prediction to arbitrary nonlinear base predictors, we
focus on feed-forward neural networks in this work. Aside from regression
tasks, we also construct optimal zono-conformal predictors in classification
settings where the output of an uncertain predictor is a set of possible
classes. We provide probabilistic coverage guarantees and present methods for
detecting outliers in the identification data. In extensive numerical
experiments, we show that zono-conformal predictors are less conservative than
interval predictor models and standard conformal prediction methods, while
achieving a similar coverage over the test data.

</details>


### [159] [Learning with Confidence](https://arxiv.org/abs/2508.11037)
*Oliver Ethan Richardson*

Main category: cs.LG

TL;DR: 提出了一种学习信心的概念，定义了其对信念状态的影响，解释其与学习率、训练轮次等相关，并进行了公式化和表示方法的研究。


<details>
  <summary>Details</summary>
Motivation: 探讨在学习或更新信念中信心的作用，区分事件概率与信心的本质差异。

Method: 通过形式化理论定义学习信心，给出两种标准化测量方法，并提出基于矢量场与损失函数的简单表示方法。

Result: 证明了信心可以通过两种方式表示，并推导出基于附加假设的更简化表示，并将其扩展到包括“复合并行”观察的新语言。

Conclusion: 信心可以用作为优化学习框架的一部分进行数学和几何上的形式化表示，贝叶斯法则可视为其一个特例。

Abstract: We characterize a notion of confidence that arises in learning or updating
beliefs: the amount of trust one has in incoming information and its impact on
the belief state. This learner's confidence can be used alongside (and is
easily mistaken for) probability or likelihood, but it is fundamentally a
different concept -- one that captures many familiar concepts in the
literature, including learning rates and number of training epochs, Shafer's
weight of evidence, and Kalman gain. We formally axiomatize what it means to
learn with confidence, give two canonical ways of measuring confidence on a
continuum, and prove that confidence can always be represented in this way.
Under additional assumptions, we derive more compact representations of
confidence-based learning in terms of vector fields and loss functions. These
representations induce an extended language of compound "parallel"
observations. We characterize Bayes Rule as the special case of an optimizing
learner whose loss representation is a linear expectation.

</details>


### [160] [Conditional Independence Estimates for the Generalized Nonparanormal](https://arxiv.org/abs/2508.11050)
*Ujas Shah,Manuel Lladser,Rebecca Morrison*

Main category: cs.LG

TL;DR: 作者提出了一种方法，用于从一般化的非参数数据中推断条件独立性结构，虽然这些数据不满足高斯分布。


<details>
  <summary>Details</summary>
Motivation: 解决非高斯分布中如何通过精度矩阵推断条件独立性结构的挑战。

Method: 引入了一类称为“广义非参数”的分布，结合具体条件，通过精度矩阵推断条件独立性，提出了一种简单高效的算法。

Result: 通过综合实验和实际数据表明所提算法能够有效恢复条件独立性结构。

Conclusion: 即使分布为非高斯，本文算法依然能够在满足特定条件下从广义非参数数据中推断出有用的结构信息。

Abstract: For general non-Gaussian distributions, the covariance and precision matrices
do not encode the independence structure of the variables, as they do for the
multivariate Gaussian. This paper builds on previous work to show that for a
class of non-Gaussian distributions -- those derived from diagonal
transformations of a Gaussian -- information about the conditional independence
structure can still be inferred from the precision matrix, provided the data
meet certain criteria, analogous to the Gaussian case. We call such
transformations of the Gaussian as the generalized nonparanormal. The functions
that define these transformations are, in a broad sense, arbitrary. We also
provide a simple and computationally efficient algorithm that leverages this
theory to recover conditional independence structure from the generalized
nonparanormal data. The effectiveness of the proposed algorithm is demonstrated
via synthetic experiments and applications to real-world data.

</details>


### [161] [SHLIME: Foiling adversarial attacks fooling SHAP and LIME](https://arxiv.org/abs/2508.11053)
*Sam Chauhan,Estelle Duguet,Karthik Ramakrishnan,Hugh Van Deventer,Jack Kruger,Ranjan Subbaraman*

Main category: cs.LG

TL;DR: 论文探讨LIME和SHAP解释方法的脆弱性及对抗偏见的改进方法，提出一种模块化测试框架，验证了某些配置能显著提升偏见检测能力。


<details>
  <summary>Details</summary>
Motivation: LIME和SHAP等后验解释方法常用于评估模型偏见和泛化能力，但其易受对抗性操控，可能掩盖有害的偏见，因此研究其鲁棒性显得重要。

Method: 作者复现与验证了COMPAS实验以建立基准，并提出一个模块化测试框架，用于系统性评估多种增强与集成方法在不同模型上的表现，比较其在抵抗偏见掩盖方面的效果。

Result: 实验发现，某些LIME/SHAP集成方法显著增强了偏见检测能力，优于原始方法，尤其是在处理分布外模型时表现出更强的鲁棒性。

Conclusion: 优化后的解释方法在高风险机器学习部署中能提升透明性，有助于更有效地检测和应对潜在偏见。

Abstract: Post hoc explanation methods, such as LIME and SHAP, provide interpretable
insights into black-box classifiers and are increasingly used to assess model
biases and generalizability. However, these methods are vulnerable to
adversarial manipulation, potentially concealing harmful biases. Building on
the work of Slack et al. (2020), we investigate the susceptibility of LIME and
SHAP to biased models and evaluate strategies for improving robustness. We
first replicate the original COMPAS experiment to validate prior findings and
establish a baseline. We then introduce a modular testing framework enabling
systematic evaluation of augmented and ensemble explanation approaches across
classifiers of varying performance. Using this framework, we assess multiple
LIME/SHAP ensemble configurations on out-of-distribution models, comparing
their resistance to bias concealment against the original methods. Our results
identify configurations that substantially improve bias detection, highlighting
their potential for enhancing transparency in the deployment of high-stakes
machine learning systems.

</details>


### [162] [Abundance-Aware Set Transformer for Microbiome Sample Embedding](https://arxiv.org/abs/2508.11075)
*Hyunwoo Yoo,Gail Rosen*

Main category: cs.LG

TL;DR: 研究提出了一种以丰度为中心的Set Transformer变体，将序列的丰度纳入考虑，以改进微生物组数据的表示和分类。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了丰度的重要性，仅简单平均序列嵌入。研究旨在通过丰度权重的方式改进数据表示，从而更准确地完成下游任务。

Method: 将丰度信息与Set Transformer结合，重复嵌入向量并应用基于自注意力机制的聚合，不改变模型架构的情况下实现丰度敏感表示。

Result: 在实际微生物分类任务中显著优于平均池化及未加权Set Transformer，部分任务达到完美表现。

Conclusion: 证明了丰度敏感的嵌入方法在微生物组表示中的有效性，与现有方法相比更具生物学意义，同时取得优异性能。

Abstract: Microbiome sample representation to input into LLMs is essential for
downstream tasks such as phenotype prediction and environmental classification.
While prior studies have explored embedding-based representations of each
microbiome sample, most rely on simple averaging over sequence embeddings,
often overlooking the biological importance of taxa abundance. In this work, we
propose an abundance-aware variant of the Set Transformer to construct
fixed-size sample-level embeddings by weighting sequence embeddings according
to their relative abundance. Without modifying the model architecture, we
replicate embedding vectors proportional to their abundance and apply
self-attention-based aggregation. Our method outperforms average pooling and
unweighted Set Transformers on real-world microbiome classification tasks,
achieving perfect performance in some cases. These results demonstrate the
utility of abundance-aware aggregation for robust and biologically informed
microbiome representation. To the best of our knowledge, this is one of the
first approaches to integrate sequence-level abundance into Transformer-based
sample embeddings.

</details>


### [163] [A Feasibility Experiment on the Application of Predictive Coding to Instant Messaging Corpora](https://arxiv.org/abs/2508.11084)
*Thanasis Schoinas,Ghulam Qadir*

Main category: cs.LG

TL;DR: 本文探讨了如何在数据为即时消息的情况下，利用机器学习实现法律行业文档分类。提出通过分组、特征选择及逻辑回归模型改善分类效率，并在Instant Bloomberg数据集上进行了性能测试与经济效果评估。


<details>
  <summary>Details</summary>
Motivation: 即时消息的非正式性及数据量小，给法律行业的文档分类带来了额外的挑战，因此需要开发一种经济高效的分类方法。

Method: 通过对即时消息分组为日聊天记录，进行特征选择和逻辑回归分类，并通过降维技术提升模型基础性能。

Result: 利用Rich in quantitative features 的Instant Bloomberg数据集进行测试，验证方法的分类性能和成本节约情况。

Conclusion: 提出的方法可提升通过机器学习对即时消息进行文档分类的效率和经济性。

Abstract: Predictive coding, the term used in the legal industry for document
classification using machine learning, presents additional challenges when the
dataset comprises instant messages, due to their informal nature and smaller
sizes. In this paper, we exploit a data management workflow to group messages
into day chats, followed by feature selection and a logistic regression
classifier to provide an economically feasible predictive coding solution. We
also improve the solution's baseline model performance by dimensionality
reduction, with focus on quantitative features. We test our methodology on an
Instant Bloomberg dataset, rich in quantitative information. In parallel, we
provide an example of the cost savings of our approach.

</details>


### [164] [Relative Advantage Debiasing for Watch-Time Prediction in Short-Video Recommendation](https://arxiv.org/abs/2508.11086)
*Emily Liu,Kuan Han,Minfeng Zhan,Bocheng Zhao,Guanyu Mu,Yang Song*

Main category: cs.LG

TL;DR: 本文提出了一种使用相对优势校正框架，通过比较视频观看时长与基于用户和物品分组的参照分布，以减少推荐系统中的偏差。


<details>
  <summary>Details</summary>
Motivation: 现有视频推荐系统中的观看时长会受视频长度、流行度和用户行为等混杂因素影响，可能导致偏差的偏好信号及推荐模型。

Method: 提出了一个相对优势去偏框架，通过分布估计与偏好学习的两阶段结构校正观看时长，并使用分布嵌入高效参数化观看时长分位数。

Result: 离线和在线实验表明，该方法相比现有基线方法在推荐准确性和鲁棒性上有显著提高。

Conclusion: 通过去除观看时长中的偏差，改进了推荐系统的偏好信号及模型性能。

Abstract: Watch time is widely used as a proxy for user satisfaction in video
recommendation platforms. However, raw watch times are influenced by
confounding factors such as video duration, popularity, and individual user
behaviors, potentially distorting preference signals and resulting in biased
recommendation models. We propose a novel relative advantage debiasing
framework that corrects watch time by comparing it to empirically derived
reference distributions conditioned on user and item groups. This approach
yields a quantile-based preference signal and introduces a two-stage
architecture that explicitly separates distribution estimation from preference
learning. Additionally, we present distributional embeddings to efficiently
parameterize watch-time quantiles without requiring online sampling or storage
of historical data. Both offline and online experiments demonstrate significant
improvements in recommendation accuracy and robustness compared to existing
baseline methods.

</details>


### [165] [Compressive Meta-Learning](https://arxiv.org/abs/2508.11090)
*Daniel Mas Montserrat,David Bonet,Maria Perera,Xavier Giró-i-Nieto,Alexander G. Ioannidis*

Main category: cs.LG

TL;DR: 本文提出了一种通过神经网络元学习来优化压缩学习框架中编码和解码阶段的新方法。


<details>
  <summary>Details</summary>
Motivation: 随着数据集规模的迅速扩大，快速且高效的参数学习技术需求迫切。然而，现有的压缩学习方法未能有效利用数据潜在结构，需要改进。

Method: 设计一个基于神经网络的框架，用于元学习编码和解码阶段，从而提升压缩学习方法的效率与准确性。

Result: 所提的框架在多个应用场景中显著优于现有方法，例如压缩PCA、岭回归、K-means及自动编码器。

Conclusion: 通过将神经网络引入压缩学习，本文展示了一种更快、更准确并满足隐私保护需求的学习体系，对大数据处理具有重要意义。

Abstract: The rapid expansion in the size of new datasets has created a need for fast
and efficient parameter-learning techniques. Compressive learning is a
framework that enables efficient processing by using random, non-linear
features to project large-scale databases onto compact, information-preserving
representations whose dimensionality is independent of the number of samples
and can be easily stored, transferred, and processed. These database-level
summaries are then used to decode parameters of interest from the underlying
data distribution without requiring access to the original samples, offering an
efficient and privacy-friendly learning framework. However, both the encoding
and decoding techniques are typically randomized and data-independent, failing
to exploit the underlying structure of the data. In this work, we propose a
framework that meta-learns both the encoding and decoding stages of compressive
learning methods by using neural networks that provide faster and more accurate
systems than the current state-of-the-art approaches. To demonstrate the
potential of the presented Compressive Meta-Learning framework, we explore
multiple applications -- including neural network-based compressive PCA,
compressive ridge regression, compressive k-means, and autoencoders.

</details>


### [166] [Predictive Multimodal Modeling of Diagnoses and Treatments in EHR](https://arxiv.org/abs/2508.11092)
*Cindy Shih-Ting Huang,Clarence Boon Liang Ng,Marek Rei*

Main category: cs.LG

TL;DR: 该研究提出了一种利用电子健康记录的多模态预测模型以改进早期ICD代码预测。


<details>
  <summary>Details</summary>
Motivation: 在患者住院初期仅有有限信息的情况下，提出预测模型以评估健康风险、优化资源分配等。

Method: 利用预训练编码器、特征池化和跨模态注意机制，融合临床笔记和表格数据，并引入加权时间损失策略。

Result: 实验验证表明所提模型优于当前最先进系统，改进了早期预测准确性。

Conclusion: 多模态学习与创新的时间损失策略可显著提升ICD代码的早期预测能力。

Abstract: While the ICD code assignment problem has been widely studied, most works
have focused on post-discharge document classification. Models for early
forecasting of this information could be used for identifying health risks,
suggesting effective treatments, or optimizing resource allocation. To address
the challenge of predictive modeling using the limited information at the
beginning of a patient stay, we propose a multimodal system to fuse clinical
notes and tabular events captured in electronic health records. The model
integrates pre-trained encoders, feature pooling, and cross-modal attention to
learn optimal representations across modalities and balance their presence at
every temporal point. Moreover, we present a weighted temporal loss that
adjusts its contribution at each point in time. Experiments show that these
strategies enhance the early prediction model, outperforming the current
state-of-the-art systems.

</details>


### [167] [Hybrid-Hierarchical Fashion Graph Attention Network for Compatibility-Oriented and Personalized Outfit Recommendation](https://arxiv.org/abs/2508.11105)
*Sajjad Saed,Babak Teimourpour*

Main category: cs.LG

TL;DR: 本文提出了FGAT框架，进而改进个性化时尚推荐系统的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前时尚推荐系统常未统一考虑商品搭配性与用户个性化需求，导致推荐效果不足。

Method: 引入FGAT框架，结合图神经网络(GNNs)和图注意力机制，构建用户-服装-商品的三级图谱结构，整合视觉与文本特征，动态加权节点重要性。

Result: 在POG数据集上，FGAT模型优于基准模型（如HFGN），在精确率、召回率、HR、NDCG及准确性等指标上均有提升。

Conclusion: 多模态特征结合层次化图结构及注意力机制，有效增强了个性化时尚推荐系统的性能。

Abstract: The rapid expansion of the fashion industry and the growing variety of
products have made it challenging for users to find compatible items on
e-commerce platforms. Effective fashion recommendation systems are crucial for
filtering irrelevant items and suggesting suitable ones. However,
simultaneously addressing outfit compatibility and personalized recommendations
remains a significant challenge, as these aspects are often treated
independently in existing studies, often overlooking the complex interactions
between items and user preferences. This research introduces a new framework
named FGAT, inspired by the HFGN model, which leverages graph neural networks
and graph attention mechanisms to tackle this issue. The proposed framework
constructs a three-tier hierarchical graph of users, outfits, and items,
integrating visual and textual features to simultaneously model outfit
compatibility and user preferences. A graph attention mechanism dynamically
weights node importance during representation propagation, enabling the capture
of key interactions and generating precise representations for both user
preferences and outfit compatibility. Evaluated on the POG dataset, FGAT
outperforms baseline models such as HFGN, achieving improved results in
precision, HR, recall, NDCG, and accuracy.These results demonstrate that
combining multimodal visual-textual features with a hierarchical graph
structure and attention mechanisms significantly enhances the accuracy and
efficiency of personalized fashion recommendation systems.

</details>


### [168] [Quantization through Piecewise-Affine Regularization: Optimization and Statistical Guarantees](https://arxiv.org/abs/2508.11112)
*Jianhao Ma,Lin Xiao*

Main category: cs.LG

TL;DR: 本文研究了使用分段仿射正则化（PAR）处理离散变量优化问题的理论基础。


<details>
  <summary>Details</summary>
Motivation: 优化离散或量化变量的问题由于其组合性质的搜索空间而具有挑战性，论文旨在为量化问题提供基于连续优化的灵活框架并探究其在监督学习中的理论基础。

Method: 1. 在超参数化的情景下分析PAR正则化损失函数的关键点；2. 推导出PAR的闭形式近端映射，提出多种求解方法；3. 探讨PAR在线性回归问题中的统计保障。

Result: 以PAR正则化的优化问题为基础，证明在超参数化情景下的高量化程度，导出不同类型的PAR的公式，并表明PAR可以实现与经典正则化类似的统计保障同时得到量化解。

Conclusion: 本文成功探索了用PAR处理离散变量问题的方法和效果，使得量化问题可以通过连续优化方法得到更灵活和有效的解。

Abstract: Optimization problems over discrete or quantized variables are very
challenging in general due to the combinatorial nature of their search space.
Piecewise-affine regularization (PAR) provides a flexible modeling and
computational framework for quantization based on continuous optimization. In
this work, we focus on the setting of supervised learning and investigate the
theoretical foundations of PAR from optimization and statistical perspectives.
First, we show that in the overparameterized regime, where the number of
parameters exceeds the number of samples, every critical point of the
PAR-regularized loss function exhibits a high degree of quantization. Second,
we derive closed-form proximal mappings for various (convex, quasi-convex, and
non-convex) PARs and show how to solve PAR-regularized problems using the
proximal gradient method, its accelerated variant, and the Alternating
Direction Method of Multipliers. Third, we study statistical guarantees of
PAR-regularized linear regression problems; specifically, we can approximate
classical formulations of $\ell_1$-, squared $\ell_2$-, and nonconvex
regularizations using PAR and obtain similar statistical guarantees with
quantized solutions.

</details>


### [169] [CTRL Your Shift: Clustered Transfer Residual Learning for Many Small Datasets](https://arxiv.org/abs/2508.11144)
*Gauri Jain,Dominik Rothenhäusler,Kirk Bansak,Elisabeth Paulson*

Main category: cs.LG

TL;DR: 本文提出了一个名为CTRL（Clustered Transfer Residual Learning）的元学习方法，用于解决高异质性和分布差异的多源数据问题，并在多个大规模数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 结合机器学习在多个不同数据源（如地理位置或社群）任务中的需求，要求预测结果不仅整体准确，还能在各源数据中维持可靠性和差异性。

Method: 提出CTRL方法，将跨领域残差学习与自适应聚类技术结合，优化整体精度的同时保留各源数据的异质性，并提供理论分析以平衡数据数量与质量的权衡。

Result: 通过5个大规模数据集（包括瑞士国家庇护项目的数据）评估，CTRL在多个指标上优于当前最先进的基准核心方法，且适用于不同的基础学习器。

Conclusion: CTRL方法具有显著提升性能的潜力，在确保大规模数据任务中的准确性与异质性的同时，展现了实际应用价值。

Abstract: Machine learning (ML) tasks often utilize large-scale data that is drawn from
several distinct sources, such as different locations, treatment arms, or
groups. In such settings, practitioners often desire predictions that not only
exhibit good overall accuracy, but also remain reliable within each source and
preserve the differences that matter across sources. For instance, several
asylum and refugee resettlement programs now use ML-based employment
predictions to guide where newly arriving families are placed within a host
country, which requires generating informative and differentiated predictions
for many and often small source locations. However, this task is made
challenging by several common characteristics of the data in these settings:
the presence of numerous distinct data sources, distributional shifts between
them, and substantial variation in sample sizes across sources. This paper
introduces Clustered Transfer Residual Learning (CTRL), a meta-learning method
that combines the strengths of cross-domain residual learning and adaptive
pooling/clustering in order to simultaneously improve overall accuracy and
preserve source-level heterogeneity. We provide theoretical results that
clarify how our objective navigates the trade-off between data quantity and
data quality. We evaluate CTRL alongside other state-of-the-art benchmarks on 5
large-scale datasets. This includes a dataset from the national asylum program
in Switzerland, where the algorithmic geographic assignment of asylum seekers
is currently being piloted. CTRL consistently outperforms the benchmarks across
several key metrics and when using a range of different base learners.

</details>


### [170] [Towards the Next-generation Bayesian Network Classifiers](https://arxiv.org/abs/2508.11145)
*Huan Zhang,Daokun Zhang,Kexin Meng,Geoffrey I. Webb*

Main category: cs.LG

TL;DR: 本文为解决贝叶斯网络分类器面临的参数爆炸和数据稀疏问题，提出一种结合高阶特征依赖模型的分布式表征学习方法。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯网络分类器限制于低阶特征依赖建模，因参数爆炸和数据稀疏性难以处理复杂数据，亟需改进。

Method: 通过借鉴词嵌入和图表征学习，对特征值进行分布式表征学习，并设计了新型神经架构扩展KDB分类器至神经版本（NeuralKDB），结合随机梯度下降算法训练。

Result: 在60个UCI数据集上的分类实验结果表明，NeuralKDB能够有效捕捉高阶特征依赖，分类效果显著优于传统贝叶斯网络分类器及其他竞品分类器。

Conclusion: NeuralKDB通过分布式表征学习提升了高维特征依赖建模能力，为复杂表格数据分类问题提供了更优解决方案。

Abstract: Bayesian network classifiers provide a feasible solution to tabular data
classification, with a number of merits like high time and memory efficiency,
and great explainability. However, due to the parameter explosion and data
sparsity issues, Bayesian network classifiers are restricted to low-order
feature dependency modeling, making them struggle in extrapolating the
occurrence probabilities of complex real-world data. In this paper, we propose
a novel paradigm to design high-order Bayesian network classifiers, by learning
distributional representations for feature values, as what has been done in
word embedding and graph representation learning. The learned distributional
representations are encoded with the semantic relatedness between different
features through their observed co-occurrence patterns in training data, which
then serve as a hallmark to extrapolate the occurrence probabilities of new
test samples. As a classifier design realization, we remake the K-dependence
Bayesian classifier (KDB) by extending it into a neural version, i.e.,
NeuralKDB, where a novel neural network architecture is designed to learn
distributional representations of feature values and parameterize the
conditional probabilities between interdependent features. A stochastic
gradient descent based algorithm is designed to train the NeuralKDB model
efficiently. Extensive classification experiments on 60 UCI datasets
demonstrate that the proposed NeuralKDB classifier excels in capturing
high-order feature dependencies and significantly outperforms the conventional
Bayesian network classifiers, as well as other competitive classifiers,
including two neural network based classifiers without distributional
representation learning.

</details>


### [171] [Mitigating Modality Quantity and Quality Imbalance in Multimodal Online Federated Learning](https://arxiv.org/abs/2508.11159)
*Heqiang Wang,Weihong Yang,Xiaoxiong Zhong,Jia Zhou,Fangming Liu,Weizhe Zhang*

Main category: cs.LG

TL;DR: 本文研究物联网生成的多模态数据在联邦学习中的不平衡问题，提出QQR算法应对质量和数量的不平衡，取得了显著的实验效果。


<details>
  <summary>Details</summary>
Motivation: 物联网设备从简单的数据采集节点向具备计算能力的节点转变，但多模态数据的不平衡性（特别是质量和数量的不平衡）影响了分布式学习性能。

Method: 提出一种称为QQR的算法，通过基于原型学习的方法，在不平衡条件下平衡模式数据的质量和数量，同时并行于训练过程运行。

Result: 在两个真实的多模态数据集上的大量实验显示，QQR算法在存在模态不平衡的条件下表现优越，学习性能显著提升。

Conclusion: QQR算法有效解决了物联网多模态联邦学习中的模态质量和数量不平衡问题，显示出其在实际场景中应用的潜力。

Abstract: The Internet of Things (IoT) ecosystem produces massive volumes of multimodal
data from diverse sources, including sensors, cameras, and microphones. With
advances in edge intelligence, IoT devices have evolved from simple data
acquisition units into computationally capable nodes, enabling localized
processing of heterogeneous multimodal data. This evolution necessitates
distributed learning paradigms that can efficiently handle such data.
Furthermore, the continuous nature of data generation and the limited storage
capacity of edge devices demand an online learning framework. Multimodal Online
Federated Learning (MMO-FL) has emerged as a promising approach to meet these
requirements. However, MMO-FL faces new challenges due to the inherent
instability of IoT devices, which often results in modality quantity and
quality imbalance (QQI) during data collection. In this work, we systematically
investigate the impact of QQI within the MMO-FL framework and present a
comprehensive theoretical analysis quantifying how both types of imbalance
degrade learning performance. To address these challenges, we propose the
Modality Quantity and Quality Rebalanced (QQR) algorithm, a prototype learning
based method designed to operate in parallel with the training process.
Extensive experiments on two real-world multimodal datasets show that the
proposed QQR algorithm consistently outperforms benchmarks under modality
imbalance conditions with promising learning performance.

</details>


### [172] [A Semi-supervised Generative Model for Incomplete Multi-view Data Integration with Missing Labels](https://arxiv.org/abs/2508.11180)
*Yiyang Shen,Weiran Wang*

Main category: cs.LG

TL;DR: 本文提出一种方法处理带有缺失视图和标签的多视图学习数据，其利用半监督生成模型优化预测和插补性能。


<details>
  <summary>Details</summary>
Motivation: 多视图学习在实际数据集中的应用经常受到视图缺失和标签缺失的限制，因此需要一种方法能够兼顾这两类问题。

Method: 提出一种半监督生成模型，结合信息瓶颈（IB）原则和交叉视图互信息最大化，从而同时利用带标签和无标签样本的潜在空间进行学习。

Result: 相比现有方法，本文模型在存在缺失视图和有限标签样本的图像和多组学数据中显示出更好的预测性能和插补能力。

Conclusion: 本文方法有效整合了监督和无监督数据，在缺失信息和多视图融合领域表现出更优越的性能。

Abstract: Multi-view learning is widely applied to real-life datasets, such as multiple
omics biological data, but it often suffers from both missing views and missing
labels. Prior probabilistic approaches addressed the missing view problem by
using a product-of-experts scheme to aggregate representations from present
views and achieved superior performance over deterministic classifiers, using
the information bottleneck (IB) principle. However, the IB framework is
inherently fully supervised and cannot leverage unlabeled data. In this work,
we propose a semi-supervised generative model that utilizes both labeled and
unlabeled samples in a unified framework. Our method maximizes the likelihood
of unlabeled samples to learn a latent space shared with the IB on labeled
data. We also perform cross-view mutual information maximization in the latent
space to enhance the extraction of shared information across views. Compared to
existing approaches, our model achieves better predictive and imputation
performance on both image and multi-omics data with missing views and limited
labeled samples.

</details>


### [173] [Quantum-Boosted High-Fidelity Deep Learning](https://arxiv.org/abs/2508.11190)
*Feng-ao Wang,Shaobo Chen,Yao Xuan,Junwei Liu,Qi Gao,Hongdong Zhu,Junjie Hou,Lixin Yuan,Jinyu Cheng,Chenxin Yi,Hai Wei,Yin Ma,Tao Xu,Kai Wen,Yixue Li*

Main category: cs.LG

TL;DR: 提出了一种称为QBM-VAE的混合量子-经典架构，利用量子处理器中的Boltzmann分布进行高效采样，解决了以往深度学习依赖于高斯先验所存在的局限性，并在生物数据分析等任务中取得了卓越效果。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型依赖高斯先验，难以捕捉复杂的非高斯特性，严重限制了模型在科学探索中的表现。

Method: 提出了一种结合量子处理和变分自编码器的框架QBM-VAE，利用量子处理器高效地从Boltzmann分布采样，将其作为深度生成模型的先验。

Result: 在多个百万级单细胞数据集上，QBM-VAE生成的潜在空间更好地保留了复杂的生物结构，在多项任务上显著优于传统的高斯基深度学习模型。

Conclusion: QBM-VAE展示了量子计算在大规模科学问题上的实际深度学习优势，并为开发混合量子AI模型提供了可转移的蓝图。

Abstract: A fundamental limitation of probabilistic deep learning is its predominant
reliance on Gaussian priors. This simplistic assumption prevents models from
accurately capturing the complex, non-Gaussian landscapes of natural data,
particularly in demanding domains like complex biological data, severely
hindering the fidelity of the model for scientific discovery. The
physically-grounded Boltzmann distribution offers a more expressive
alternative, but it is computationally intractable on classical computers. To
date, quantum approaches have been hampered by the insufficient qubit scale and
operational stability required for the iterative demands of deep learning.
Here, we bridge this gap by introducing the Quantum Boltzmann
Machine-Variational Autoencoder (QBM-VAE), a large-scale and long-time stable
hybrid quantum-classical architecture. Our framework leverages a quantum
processor for efficient sampling from the Boltzmann distribution, enabling its
use as a powerful prior within a deep generative model. Applied to
million-scale single-cell datasets from multiple sources, the QBM-VAE generates
a latent space that better preserves complex biological structures,
consistently outperforming conventional Gaussian-based deep learning models
like VAE and SCVI in essential tasks such as omics data integration, cell-type
classification, and trajectory inference. It also provides a typical example of
introducing a physics priori into deep learning to drive the model to acquire
scientific discovery capabilities that breaks through data limitations. This
work provides the demonstration of a practical quantum advantage in deep
learning on a large-scale scientific problem and offers a transferable
blueprint for developing hybrid quantum AI models.

</details>


### [174] [Meta-learning Structure-Preserving Dynamics](https://arxiv.org/abs/2508.11205)
*Cheng Jing,Uvini Balasuriya Mudiyanselage,Woojin Cho,Minju Jo,Anthony Gruber,Kookjin Lee*

Main category: cs.LG

TL;DR: 本文提出了一种基于调制的元学习框架，用于在保证物理系统动态稳定性的前提下，实现对参数化动态系统的高效建模和泛化。


<details>
  <summary>Details</summary>
Motivation: 基于结构的动力学建模方法虽然能够很好地保持物理系统的动力学特性，但通常需要在定参数设置下训练，且每次参数变化都需要昂贵的重新训练。为解决该问题，元学习被认为是潜在的解决方案，但现有的优化型元学习方法存在训练不稳定或泛化能力限制的问题。

Method: 提出了一种基于调制的元学习框架，该框架将结构保留模型与系统参数的潜在表示相结合，避免了灰盒系统知识及适应期间显式优化的需求，从而提高了可扩展性和泛化性。

Result: 在标准基准问题上的实验表明，该方法在少样本学习场景下实现了高精度预测，同时保持了动力学稳定性和跨参数空间的有效泛化性能。

Conclusion: 本文提出的方法有效解决了参数变化场景下的结构保留动力学模型的训练问题，并在准确性和物理约束条件之间实现了良好平衡。

Abstract: Structure-preserving approaches to dynamics modeling have demonstrated great
potential for modeling physical systems due to their strong inductive biases
that enforce conservation laws and dissipative behavior. However, the resulting
models are typically trained for fixed system configurations, requiring
explicit knowledge of system parameters as well as costly retraining for each
new set of parameters -- a major limitation in many-query or parameter-varying
scenarios. Meta-learning offers a potential solution, but existing approaches
like optimization-based meta-learning often suffer from training instability or
limited generalization capability. Inspired by ideas from computer vision, we
introduce a modulation-based meta-learning framework that directly conditions
structure-preserving models on compact latent representations of potentially
unknown system parameters, avoiding the need for gray-box system knowledge and
explicit optimization during adaptation. Through the application of novel
modulation strategies to parametric energy-conserving and dissipative systems,
we enable scalable and generalizable learning across parametric families of
dynamical systems. Experiments on standard benchmark problems demonstrate that
our approach achieves accurate predictions in few-shot learning settings,
without compromising on the essential physical constraints necessary for
dynamical stability and effective generalization performance across parameter
space.

</details>


### [175] [Borrowing From the Future: Enhancing Early Risk Assessment through Contrastive Learning](https://arxiv.org/abs/2508.11210)
*Minghui Sun,Matthew M. Engelhard,Benjamin A. Goldstein*

Main category: cs.LG

TL;DR: 研究提出一个名为Borrowing From the Future (BFF)的框架来改进儿童群体早期风险评估的预测性能。


<details>
  <summary>Details</summary>
Motivation: 早期风险评估预测的精度较低，但早期评估具有重要的临床意义，因此需要改进早期阶段的预测性能。

Method: 提出的BFF框架将每个时间窗口视为一个独特的模态，通过对整个时间段的数据进行训练，并使用对比学习从后期阶段的信号中学习，以提升早期阶段的风险预测能力。

Result: BFF在两个真实世界的儿科结果预测任务中表现出色，提高了早期风险评估的预测性能。

Conclusion: BFF框架显著改进了早期阶段的预测表现，为临床早期干预提供了支持。

Abstract: Risk assessments for a pediatric population are often conducted across
multiple stages. For example, clinicians may evaluate risks prenatally, at
birth, and during Well-Child visits. Although predictions made at later stages
typically achieve higher precision, it is clinically desirable to make reliable
risk assessments as early as possible. Therefore, this study focuses on
improving prediction performance in early-stage risk assessments. Our solution,
\textbf{Borrowing From the Future (BFF)}, is a contrastive multi-modal
framework that treats each time window as a distinct modality. In BFF, a model
is trained on all available data throughout the time while performing a risk
assessment using up-to-date information. This contrastive framework allows the
model to ``borrow'' informative signals from later stages (e.g., Well-Child
visits) to implicitly supervise the learning at earlier stages (e.g.,
prenatal/birth stages). We validate BFF on two real-world pediatric outcome
prediction tasks, demonstrating consistent improvements in early risk
assessments. The code is available at https://github.com/scotsun/bff.

</details>


### [176] [How Causal Abstraction Underpins Computational Explanation](https://arxiv.org/abs/2508.11214)
*Atticus Geiger,Jacqueline Harding,Thomas Icard*

Main category: cs.LG

TL;DR: 通过因果理论和因果抽象，研究认知行为的计算实现及其推断的角色，解析哲学生计算与现代机器学习的交集。


<details>
  <summary>Details</summary>
Motivation: 探讨认知行为涉及的计算及表示在系统中的实现，以因果抽象为视角增强理解。

Method: 结合因果性理论和因果抽象框架，对哲学计算主题在人工神经网络和深度学习的现代化体现进行分析，探索一般化与预测中的表示作用。

Result: 提出基于因果抽象的计算实现方法，并深入分析表示及其在认知推断中的应用场景。

Conclusion: 因果抽象理论为解释计算和认知中的表示问题提供了扎实基础，尤其在预测和一般性层面提出了新的见解。

Abstract: Explanations of cognitive behavior often appeal to computations over
representations. What does it take for a system to implement a given
computation over suitable representational vehicles within that system? We
argue that the language of causality -- and specifically the theory of causal
abstraction -- provides a fruitful lens on this topic. Drawing on current
discussions in deep learning with artificial neural networks, we illustrate how
classical themes in the philosophy of computation and cognition resurface in
contemporary machine learning. We offer an account of computational
implementation grounded in causal abstraction, and examine the role for
representation in the resulting picture. We argue that these issues are most
profitably explored in connection with generalization and prediction.

</details>


### [177] [Air Quality PM2.5 Index Prediction Model Based on CNN-LSTM](https://arxiv.org/abs/2508.11215)
*Zicheng Guo,Shuqi Wu,Meixing Zhu,He Guandi*

Main category: cs.LG

TL;DR: 研究提出了一种基于混合CNN-LSTM架构的PM2.5浓度预测模型，实验结果优于传统时间序列模型。


<details>
  <summary>Details</summary>
Motivation: 随着气候变化的加剧，准确预测空气质量指标（尤其是PM2.5浓度）在环境保护、公共健康和城市管理中需求日益增加。

Method: 结合了卷积神经网络（CNN）提取局部空间特征和长短期记忆网络（LSTM）建模时间序列数据中的时间依赖性。

Result: 模型在实验中取得了5.236的均方根误差（RMSE），性能优于传统时间序列模型。

Conclusion: 模型在现实中具有较大的应用潜力，但对多变量输入的复杂性处理仍需优化，同时未来将扩展到更复杂的气象预测任务中。

Abstract: With the intensification of global climate change, accurate prediction of air
quality indicators, especially PM2.5 concentration, has become increasingly
important in fields such as environmental protection, public health, and urban
management. To address this, we propose an air quality PM2.5 index prediction
model based on a hybrid CNN-LSTM architecture. The model effectively combines
Convolutional Neural Networks (CNN) for local spatial feature extraction and
Long Short-Term Memory (LSTM) networks for modeling temporal dependencies in
time series data. Using a multivariate dataset collected from an industrial
area in Beijing between 2010 and 2015 -- which includes hourly records of PM2.5
concentration, temperature, dew point, pressure, wind direction, wind speed,
and precipitation -- the model predicts the average PM2.5 concentration over
6-hour intervals. Experimental results show that the model achieves a root mean
square error (RMSE) of 5.236, outperforming traditional time series models in
both accuracy and generalization. This demonstrates its strong potential in
real-world applications such as air pollution early warning systems. However,
due to the complexity of multivariate inputs, the model demands high
computational resources, and its ability to handle diverse atmospheric factors
still requires optimization. Future work will focus on enhancing scalability
and expanding support for more complex multivariate weather prediction tasks.

</details>


### [178] [Enhancing Interactive Voting-Based Map Matching: Improving Efficiency and Robustness for Heterogeneous GPS Trajectories](https://arxiv.org/abs/2508.11235)
*William Alemanni,Arianna Burzacchi,Davide Colombi,Elena Giarratano*

Main category: cs.LG

TL;DR: 提出了一种改进的交互式基于投票的地图匹配算法，专注于高效处理采样率变化的GPS轨迹。


<details>
  <summary>Details</summary>
Motivation: 目标是提高GPS轨迹重建的精度，克服输入数据质量的依赖性，并扩展算法适用范围。

Method: 改进了原算法，新增轨迹补全功能；加入距离约束的交互式投票策略；通过自定义OpenStreetMap资产实现地域通用性。

Result: 改进算法不仅在复杂场景下更高效，而且显著增强对不同地区与数据质量的兼容性。

Conclusion: 保留原有算法优势的基础上，扩展了其应用范围，使其适应更广泛的实际场景。

Abstract: This paper presents an enhanced version of the Interactive Voting-Based Map
Matching algorithm, designed to efficiently process trajectories with varying
sampling rates. The main aim is to reconstruct GPS trajectories with high
accuracy, independent of input data quality. Building upon the original
algorithm, developed exclusively for aligning GPS signals to road networks, we
extend its capabilities by integrating trajectory imputation. Our improvements
also include the implementation of a distance-bounded interactive voting
strategy to reduce computational complexity, as well as modifications to
address missing data in the road network. Furthermore, we incorporate a
custom-built asset derived from OpenStreetMap, enabling this approach to be
smoothly applied in any geographic region covered by OpenStreetMap's road
network. These advancements preserve the core strengths of the original
algorithm while significantly extending its applicability to diverse real-world
scenarios.

</details>


### [179] [Graph Neural Diffusion via Generalized Opinion Dynamics](https://arxiv.org/abs/2508.11249)
*Asela Hevapathige,Asiri Wijesinghe,Ahad N. Zehmakan*

Main category: cs.LG

TL;DR: 提出了一种名为GODNF的框架，通过结合多种舆论动力学模型，与现有方法相比在节点分类和影响估计任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有扩散式GNN方法存在三大问题：适应性不足、深度受限及收敛性理论有限，这促使研究人员探索更灵活高效的扩散机制。

Method: 提出了GODNF框架，通过节点特定行为建模和动态邻域影响机制，捕捉异质扩散模式和时间动态，并提供高效、可解释的深层消息传播。

Result: 理论分析表明GODNF能够建模多样化的收敛配置，实验结果表明其在节点分类和影响估计任务上优于现有方法。

Conclusion: GODNF框架成功解决了现有扩散式GNN的主要局限，展现了卓越的性能和理论基础。

Abstract: There has been a growing interest in developing diffusion-based Graph Neural
Networks (GNNs), building on the connections between message passing mechanisms
in GNNs and physical diffusion processes. However, existing methods suffer from
three critical limitations: (1) they rely on homogeneous diffusion with static
dynamics, limiting adaptability to diverse graph structures; (2) their depth is
constrained by computational overhead and diminishing interpretability; and (3)
theoretical understanding of their convergence behavior remains limited. To
address these challenges, we propose GODNF, a Generalized Opinion Dynamics
Neural Framework, which unifies multiple opinion dynamics models into a
principled, trainable diffusion mechanism. Our framework captures heterogeneous
diffusion patterns and temporal dynamics via node-specific behavior modeling
and dynamic neighborhood influence, while ensuring efficient and interpretable
message propagation even at deep layers. We provide a rigorous theoretical
analysis demonstrating GODNF's ability to model diverse convergence
configurations. Extensive empirical evaluations of node classification and
influence estimation tasks confirm GODNF's superiority over state-of-the-art
GNNs.

</details>


### [180] [Group Fairness Meets the Black Box: Enabling Fair Algorithms on Closed LLMs via Post-Processing](https://arxiv.org/abs/2508.11258)
*Ruicheng Xian,Yuxuan Wan,Han Zhao*

Main category: cs.LG

TL;DR: 本文提出一种方法，通过闭权重大语言模型（LLMs）的提示生成特征，从而在后续步骤中训练一个轻量化的公平分类器，对高风险应用实现组公平性，实验结果表明该方法在多种数据集上均表现出强大的精确性与公平性权衡。


<details>
  <summary>Details</summary>
Motivation: 为了解决在使用闭权重LLMs进行零样本或小样本推理时难以实现组公平性的问题，特别是在高风险领域。

Method: 通过设计满足指定公平性标准的提示，将闭权重LLMs作为特征提取器，获取概率预测特性，并使用公平算法进行后处理训练公平分类器。

Result: 实验在五个数据集上表明，该框架在精确性与公平性权衡方面优于基于LLM嵌入训练或从头使用原始数据特征训练的公平分类器，尤其数据效率更高。

Conclusion: 提出的框架在闭权重LLMs上实现了有效的组公平性，同时充分利用了模型的概率预测能力，可推广至多种应用场景。

Abstract: Instruction fine-tuned large language models (LLMs) enable a simple zero-shot
or few-shot prompting paradigm, also known as in-context learning, for building
prediction models. This convenience, combined with continued advances in LLM
capability, has the potential to drive their adoption across a broad range of
domains, including high-stakes applications where group fairness -- preventing
disparate impacts across demographic groups -- is essential. The majority of
existing approaches to enforcing group fairness on LLM-based classifiers rely
on traditional fair algorithms applied via model fine-tuning or head-tuning on
final-layer embeddings, but they are no longer applicable to closed-weight LLMs
under the in-context learning setting, which include some of the most capable
commercial models today, such as GPT-4, Gemini, and Claude. In this paper, we
propose a framework for deriving fair classifiers from closed-weight LLMs via
prompting: the LLM is treated as a feature extractor, and features are elicited
from its probabilistic predictions (e.g., token log probabilities) using
prompts strategically designed for the specified fairness criterion to obtain
sufficient statistics for fair classification; a fair algorithm is then applied
to these features to train a lightweight fair classifier in a post-hoc manner.
Experiments on five datasets, including three tabular ones, demonstrate strong
accuracy-fairness tradeoffs for the classifiers derived by our framework from
both open-weight and closed-weight LLMs; in particular, our framework is
data-efficient and outperforms fair classifiers trained on LLM embeddings
(i.e., head-tuning) or from scratch on raw tabular features.

</details>


### [181] [Boosting the Robustness-Accuracy Trade-off of SNNs by Robust Temporal Self-Ensemble](https://arxiv.org/abs/2508.11279)
*Jihang Wang,Dongcheng Zhao,Ruolin Chen,Qian Zhang,Yi Zeng*

Main category: cs.LG

TL;DR: 本研究提出了一种新的训练框架RTE，以提高时序脉冲神经网络（SNNs）对抗干扰的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络在节能和类脑计算中表现优越，但在对抗干扰下的脆弱性理解尚不深入。

Method: 通过引入Robust Temporal self-Ensemble (RTE)训练框架，强化单个时序子网络的鲁棒性，并减少对抗干扰在时间上的迁移性，实现高效优化。

Result: 实验显示RTE在多个基准测试中的鲁棒性-精确性平衡优于现有方法。

Conclusion: RTE为构建能更好应对对抗干扰的时序脉冲模型提供了理论依据，并突出了时序结构在对抗学习中的重要性。

Abstract: Spiking Neural Networks (SNNs) offer a promising direction for
energy-efficient and brain-inspired computing, yet their vulnerability to
adversarial perturbations remains poorly understood. In this work, we revisit
the adversarial robustness of SNNs through the lens of temporal ensembling,
treating the network as a collection of evolving sub-networks across discrete
timesteps. This formulation uncovers two critical but underexplored
challenges-the fragility of individual temporal sub-networks and the tendency
for adversarial vulnerabilities to transfer across time. To overcome these
limitations, we propose Robust Temporal self-Ensemble (RTE), a training
framework that improves the robustness of each sub-network while reducing the
temporal transferability of adversarial perturbations. RTE integrates both
objectives into a unified loss and employs a stochastic sampling strategy for
efficient optimization. Extensive experiments across multiple benchmarks
demonstrate that RTE consistently outperforms existing training methods in
robust-accuracy trade-off. Additional analyses reveal that RTE reshapes the
internal robustness landscape of SNNs, leading to more resilient and temporally
diversified decision boundaries. Our study highlights the importance of
temporal structure in adversarial learning and offers a principled foundation
for building robust spiking models.

</details>


### [182] [Generalize across Homophily and Heterophily: Hybrid Spectral Graph Pre-Training and Prompt Tuning](https://arxiv.org/abs/2508.11328)
*Haitong Luo,Suhang Wang,Weiyao Zhang,Ruiqi Meng,Xuying Meng,Yujun Zhang*

Main category: cs.LG

TL;DR: 研究提出了HS-GPPT模型，解决现有图预训练和提示调优方法在频谱知识转移上的不足，改进了在真实世界中频谱多样性图上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖同质性低频知识，无法有效处理具备多种频谱分布的实际图数据，且频谱差距会阻碍有效的知识转移。

Method: 提出HS-GPPT框架，通过使用混合频谱过滤和局部-全局对比学习构建丰富的频谱知识，并设计提示图对频谱分布进行对齐，从而实现知识转移。

Result: 大量实验验证了HS-GPPT模型在透传学习和归纳学习场景下的有效性。

Conclusion: HS-GPPT通过频谱对齐提升了有限监督条件下的知识转移能力，且针对不同同质性情况表现均优秀。

Abstract: Graph ``pre-training and prompt-tuning'' aligns downstream tasks with
pre-trained objectives to enable efficient knowledge transfer under limited
supervision. However, existing methods rely on homophily-based low-frequency
knowledge, failing to handle diverse spectral distributions in real-world
graphs with varying homophily. Our theoretical analysis reveals a spectral
specificity principle: optimal knowledge transfer requires alignment between
pre-trained spectral filters and the intrinsic spectrum of downstream graphs.
Under limited supervision, large spectral gaps between pre-training and
downstream tasks impede effective adaptation. To bridge this gap, we propose
the HS-GPPT model, a novel framework that ensures spectral alignment throughout
both pre-training and prompt-tuning. We utilize a hybrid spectral filter
backbone and local-global contrastive learning to acquire abundant spectral
knowledge. Then we design prompt graphs to align the spectral distribution with
pretexts, facilitating spectral knowledge transfer across homophily and
heterophily. Extensive experiments validate the effectiveness under both
transductive and inductive learning settings. Our code is available at
https://anonymous.4open.science/r/HS-GPPT-62D2/.

</details>


### [183] [RegimeNAS: Regime-Aware Differentiable Architecture Search With Theoretical Guarantees for Financial Trading](https://arxiv.org/abs/2508.11338)
*Prathamesh Devadiga,Yashmitha Shailesh*

Main category: cs.LG

TL;DR: RegimeNAS 是一个专为加密货币交易设计的区分可微架构搜索框架，通过整合市场状态意识显著提升交易表现。


<details>
  <summary>Details</summary>
Motivation: 当前静态深度学习模型在动态金融环境中表现有限，因此需要开发适应性更强的方法。

Method: 提出了 RegimeNAS，包括贝叶斯搜索空间、动态激活神经模块（如波动性、趋势和范围模块），以及包含市场特定惩罚项的多目标损失函数；结合多头注意机制进行市场状态识别。

Result: 在真实加密货币数据中显著优于其他技术，减少了80.3%的平均绝对误差，且收敛速度快。

Conclusion: 通过直接在架构搜索过程中嵌入市场状态等领域知识，本研究成功开发了适应性强且鲁棒的金融应用模型。

Abstract: We introduce RegimeNAS, a novel differentiable architecture search framework
specifically designed to enhance cryptocurrency trading performance by
explicitly integrating market regime awareness. Addressing the limitations of
static deep learning models in highly dynamic financial environments, RegimeNAS
features three core innovations: (1) a theoretically grounded Bayesian search
space optimizing architectures with provable convergence properties; (2)
specialized, dynamically activated neural modules (Volatility, Trend, and Range
blocks) tailored for distinct market conditions; and (3) a multi-objective loss
function incorporating market-specific penalties (e.g., volatility matching,
transition smoothness) alongside mathematically enforced Lipschitz stability
constraints. Regime identification leverages multi-head attention across
multiple timeframes for improved accuracy and uncertainty estimation. Rigorous
empirical evaluation on extensive real-world cryptocurrency data demonstrates
that RegimeNAS significantly outperforms state-of-the-art benchmarks, achieving
an 80.3% Mean Absolute Error reduction compared to the best traditional
recurrent baseline and converging substantially faster (9 vs. 50+ epochs).
Ablation studies and regime-specific analysis confirm the critical contribution
of each component, particularly the regime-aware adaptation mechanism. This
work underscores the imperative of embedding domain-specific knowledge, such as
market regimes, directly within the NAS process to develop robust and adaptive
models for challenging financial applications.

</details>


### [184] [Conformal Prediction Meets Long-tail Classification](https://arxiv.org/abs/2508.11345)
*Shuqi Liu,Jianguo Huang,Luke Ong*

Main category: cs.LG

TL;DR: 本文提出了一种名为Tail-Aware Conformal Prediction (TACP)的新方法，旨在解决长尾分布下类别覆盖率不平衡的问题，并通过sTACP扩展进一步改进覆盖率平衡性。


<details>
  <summary>Details</summary>
Motivation: 现有的CP方法在长尾标签分布中会导致类别覆盖率不平衡，头部类别过度覆盖而尾部类别覆盖不足，严重影响少数类别的预测可靠性。

Method: 提出了TACP方法，利用长尾结构减小头尾覆盖率差距，并引入软TACP (sTACP)通过重加权机制进一步提升覆盖平衡性。

Result: 理论分析表明，TACP在缩小头尾覆盖率差距方面优于标准方法，实验验证了该方法在多个长尾基准数据集上的有效性。

Conclusion: TACP及其扩展方法sTACP在长尾分布下显著改善了类别覆盖率不平衡问题，为少数类别提供了更可靠的置信预测集。

Abstract: Conformal Prediction (CP) is a popular method for uncertainty quantification
that converts a pretrained model's point prediction into a prediction set, with
the set size reflecting the model's confidence. Although existing CP methods
are guaranteed to achieve marginal coverage, they often exhibit imbalanced
coverage across classes under long-tail label distributions, tending to over
cover the head classes at the expense of under covering the remaining tail
classes. This under coverage is particularly concerning, as it undermines the
reliability of the prediction sets for minority classes, even with coverage
ensured on average. In this paper, we propose the Tail-Aware Conformal
Prediction (TACP) method to mitigate the under coverage of the tail classes by
utilizing the long-tail structure and narrowing the head-tail coverage gap.
Theoretical analysis shows that it consistently achieves a smaller head-tail
coverage gap than standard methods. To further improve coverage balance across
all classes, we introduce an extension of TACP: soft TACP (sTACP) via a
reweighting mechanism. The proposed framework can be combined with various
non-conformity scores, and experiments on multiple long-tail benchmark datasets
demonstrate the effectiveness of our methods.

</details>


### [185] [NeMo: A Neuron-Level Modularizing-While-Training Approach for Decomposing DNN Models](https://arxiv.org/abs/2508.11348)
*Xiaohan Bi,Binhang Qi,Hailong Sun,Xiang Gao,Yue Yu,Xiaojun Liang*

Main category: cs.LG

TL;DR: 深度神经网络的模块化训练方法NeMo具有高可扩展性和通用性，在减少模块尺寸的同时提升了分类准确率，适用于Transformer和CNN架构。


<details>
  <summary>Details</summary>
Motivation: 现有的深度神经网络模块化方法在多样化和大规模模型（尤其是Transformer模型）中的表现有限，需要更通用和可扩展的解决方案。

Method: 提出NeMo方法，通过针对神经元层面的对比学习和复合损失函数设计，实现对大型模型的有效模块化训练。

Result: 在两个Transformer模型和四个CNN模型上的实验显示，NeMo平均提升1.72%的分类准确率，并减少58.10%的模块尺寸。

Conclusion: NeMo拥有强大的实用性和潜力，可以在实际应用中为深度学习模型的模块化提供高效解决方案。

Abstract: With the growing incorporation of deep neural network (DNN) models into
modern software systems, the prohibitive construction costs have become a
significant challenge. Model reuse has been widely applied to reduce training
costs, but indiscriminately reusing entire models may incur significant
inference overhead. Consequently, DNN modularization has gained attention,
enabling module reuse by decomposing DNN models. The emerging
modularizing-while-training (MwT) paradigm, which incorporates modularization
into training, outperforms modularizing-after-training approaches. However,
existing MwT methods focus on small-scale CNN models at the convolutional
kernel level and struggle with diverse DNNs and large-scale models,
particularly Transformer-based models. To address these limitations, we propose
NeMo, a scalable and generalizable MwT approach. NeMo operates at the neuron
level fundamental component common to all DNNs-ensuring applicability to
Transformers and various architectures. We design a contrastive learning-based
modular training method with an effective composite loss function, enabling
scalability to large-scale models. Comprehensive experiments on two
Transformer-based models and four CNN models across two classification datasets
demonstrate NeMo's superiority over state-of-the-art MwT methods. Results show
average gains of 1.72% in module classification accuracy and 58.10% reduction
in module size, demonstrating efficacy across both CNN and large-scale
Transformer-based models. A case study on open-source projects shows NeMo's
potential benefits in practical scenarios, offering a promising approach for
scalable and generalizable DNN modularization.

</details>


### [186] [A Global Dataset of Location Data Integrity-Assessed Reforestation Efforts](https://arxiv.org/abs/2508.11349)
*Angela John,Selvyn Allotey,Till Koebe,Alexandra Tyukavina,Ingmar Weber*

Main category: cs.LG

TL;DR: 本文研究了使用数据集验证全球造林和再造林项目效能，发现很多项目缺乏可靠的地理数据。


<details>
  <summary>Details</summary>
Motivation: 应对气候变化，造林和再造林被广泛采用，但对其效能的独立验证不足，亟需解决数据可靠性问题。

Method: 利用时序卫星影像和其他次级数据，构建包含1,289,068个种植地点的全球数据集，并用LDIS（位置数据完整性评分）评估地理位置信息。

Result: 研究发现79%的监测地点在LDIS评分中至少有1项不达标，约15%的项目缺乏机器可读的地理数据。

Conclusion: 提出的标准化数据集能提升自愿碳市场的透明度，同时为计算机视觉等领域提供有价值的训练数据。

Abstract: Afforestation and reforestation are popular strategies for mitigating climate
change by enhancing carbon sequestration. However, the effectiveness of these
efforts is often self-reported by project developers, or certified through
processes with limited external validation. This leads to concerns about data
reliability and project integrity. In response to increasing scrutiny of
voluntary carbon markets, this study presents a dataset on global afforestation
and reforestation efforts compiled from primary (meta-)information and
augmented with time-series satellite imagery and other secondary data. Our
dataset covers 1,289,068 planting sites from 45,628 projects spanning 33 years.
Since any remote sensing-based validation effort relies on the integrity of a
planting site's geographic boundary, this dataset introduces a standardized
assessment of the provided site-level location information, which we summarize
in one easy-to-communicate key indicator: LDIS -- the Location Data Integrity
Score. We find that approximately 79\% of the georeferenced planting sites
monitored fail on at least 1 out of 10 LDIS indicators, while 15\% of the
monitored projects lack machine-readable georeferenced data in the first place.
In addition to enhancing accountability in the voluntary carbon market, the
presented dataset also holds value as training data for e.g. computer
vision-related tasks with millions of linked Sentinel-2 and Planetscope
satellite images.

</details>


### [187] [Harmonized Gradient Descent for Class Imbalanced Data Stream Online Learning](https://arxiv.org/abs/2508.11353)
*Han Zhou,Hongpeng Yin,Xuanhong Deng,Yuyu Huang,Hao Ren*

Main category: cs.LG

TL;DR: 提出了一种名为HGD的算法，通过平衡不同类别的梯度范数来解决数据流不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现实中的数据流通常具有不平衡的类别分布，现有方法无法很好地解决这种问题，尤其是在在线学习场景中。

Method: 通过修改梯度下降算法，引入HGD算法，使不同类别的梯度范数达到平衡，无需数据缓冲或额外参数。

Result: 理论分析表明HGD具有次线性遗憾界，实验结果验证了其在不平衡数据流下的高效性和有效性。

Conclusion: HGD在不平衡数据流的在线学习中具有广泛的适用性和良好的性能。

Abstract: Many real-world data are sequentially collected over time and often exhibit
skewed class distributions, resulting in imbalanced data streams. While
existing approaches have explored several strategies, such as resampling and
reweighting, for imbalanced data stream learning, our work distinguishes itself
by addressing the imbalance problem through training modification, particularly
focusing on gradient descent techniques. We introduce the harmonized gradient
descent (HGD) algorithm, which aims to equalize the norms of gradients across
different classes. By ensuring the gradient norm balance, HGD mitigates
under-fitting for minor classes and achieves balanced online learning. Notably,
HGD operates in a streamlined implementation process, requiring no data-buffer,
extra parameters, or prior knowledge, making it applicable to any learning
models utilizing gradient descent for optimization. Theoretical analysis, based
on a few common and mild assumptions, shows that HGD achieves a satisfied
sub-linear regret bound. The proposed algorithm are compared with the commonly
used online imbalance learning methods under several imbalanced data stream
scenarios. Extensive experimental evaluations demonstrate the efficiency and
effectiveness of HGD in learning imbalanced data streams.

</details>


### [188] [ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism](https://arxiv.org/abs/2508.11356)
*Jia Liu,ChangYi He,YingQiao Lin,MingMin Yang,FeiYang Shen,ShaoGuo Liu,TingTing Gao*

Main category: cs.LG

TL;DR: 提出一种优化大型语言模型在无监督情况下能力的新方法，大幅提升推断效率和性能。


<details>
  <summary>Details</summary>
Motivation: 针对当前大型语言模型依赖标注数据和在无监督场景中适应性差的问题，提出在测试时应用强化学习的优化方法。

Method: 通过引入基于熵的两种策略(ETMR和EAR)，平衡测试时强化学习的探索与利用。

Result: 相比基线模型，Llama3.1-8B在AIME 2024测试中实现了68%的性能提升，同时减少了40%的推理成本。

Conclusion: 该方法有效优化了推理效率、多样性及估计稳健性，为开放领域推理任务提供了新的方向。

Abstract: Recent advancements in Large Language Models have yielded significant
improvements in complex reasoning tasks such as mathematics and programming.
However, these models remain heavily dependent on annotated data and exhibit
limited adaptability in unsupervised scenarios. To address these limitations,
test-time reinforcement learning (TTRL) has been proposed, which enables
self-optimization by leveraging model-generated pseudo-labels. Despite its
promise, TTRL faces several key challenges, including high inference costs due
to parallel rollouts and early-stage estimation bias that fosters
overconfidence, reducing output diversity and causing performance plateaus. To
address these challenges, we introduce an entropy-based mechanism to enhance
the exploration-exploitation balance in test-time reinforcement learning
through two strategies: Entropy-fork Tree Majority Rollout (ETMR) and
Entropy-based Advantage Reshaping (EAR). Compared with the baseline, our
approach enables Llama3.1-8B to achieve a 68 percent relative improvement in
Pass at 1 metric on the AIME 2024 benchmark, while consuming only 60 percent of
the rollout tokens budget. This highlights our method's ability to effectively
optimize the trade-off between inference efficiency, diversity, and estimation
robustness, thereby advancing unsupervised reinforcement learning for
open-domain reasoning tasks.

</details>


### [189] [PTSM: Physiology-aware and Task-invariant Spatio-temporal Modeling for Cross-Subject EEG Decoding](https://arxiv.org/abs/2508.11357)
*Changhong Jing,Yan Liu,Shuqiang Wang,Bruce X. B. Yu,Gong Chen,Zhejing Hu,Zhi Zhang,Yanyan Shen*

Main category: cs.LG

TL;DR: 该论文提出了一个名为PTSM的新框架，通过解耦神经表征，在未见过的受试者上实现了鲁棒的EEG解码，并在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 跨受试者EEG解码具有重大挑战，包括受试者间的显著差异和跨个体不变特征的缺乏。作者希望通过设计一种新方法解决这一问题。

Method: 提出PTSM框架，使用双分支掩膜机制独立学习个性化和共享的时空模式，结合信息论约束将嵌入分解为任务相关和受试者相关的子空间，通过多目标损失端到端训练模型。

Result: 大规模实验显示，PTSM在跨受试者运动意象任务上表现突出，实现了强大的零样本泛化性能并优于现有方法。

Conclusion: 解耦任务相关和个体相关表征对于非平稳神经生理环境中的个性化和通用化解码至关重要，PTSM框架实现了平衡。

Abstract: Cross-subject electroencephalography (EEG) decoding remains a fundamental
challenge in brain-computer interface (BCI) research due to substantial
inter-subject variability and the scarcity of subject-invariant
representations. This paper proposed PTSM (Physiology-aware and Task-invariant
Spatio-temporal Modeling), a novel framework for interpretable and robust EEG
decoding across unseen subjects. PTSM employs a dual-branch masking mechanism
that independently learns personalized and shared spatio-temporal patterns,
enabling the model to preserve individual-specific neural characteristics while
extracting task-relevant, population-shared features. The masks are factorized
across temporal and spatial dimensions, allowing fine-grained modulation of
dynamic EEG patterns with low computational overhead. To further address
representational entanglement, PTSM enforces information-theoretic constraints
that decompose latent embeddings into orthogonal task-related and
subject-related subspaces. The model is trained end-to-end via a
multi-objective loss integrating classification, contrastive, and
disentanglement objectives. Extensive experiments on cross-subject motor
imagery datasets demonstrate that PTSM achieves strong zero-shot
generalization, outperforming state-of-the-art baselines without
subject-specific calibration. Results highlight the efficacy of disentangled
neural representations for achieving both personalized and transferable
decoding in non-stationary neurophysiological settings.

</details>


### [190] [Fusing Rewards and Preferences in Reinforcement Learning](https://arxiv.org/abs/2508.11363)
*Sadegh Khorasani,Saber Salehkaleybar,Negar Kiyavash,Matthias Grossglauser*

Main category: cs.LG

TL;DR: 本文提出了Dual-Feedback Actor (DFA)，一种结合个体奖励和成对偏好用于单一更新规则的强化学习算法。使用生成的偏好数据，DFA在多个控制环境中性能优于SAC，并表现出更稳定的训练过程。同时，它在基于部分合成的偏好数据集下优于基准RLHF方法。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习算法难以高效结合个体奖励信号和人类偏好，且通常需要额外的奖励建模步骤。

Method: 提出DFA算法，通过直接利用策略的对数概率来建模偏好概率，无需单独的奖励建模过程。基于Bradley-Terry模型进行数学推导，同时支持由人类标注、在线合成的偏好数据输入，统一于单一更新规则中。

Result: 实验表明，DFA算法在合成偏好数据上的性能超越SAC，并在GridWorld环境中优于传统基于奖励建模的RLHF方法，接近真实奖励的表现。

Conclusion: DFA算法提供了一种新颖且稳定的强化学习训练方式，将人类偏好有效统一于算法中，以高效实现更优性能。

Abstract: We present Dual-Feedback Actor (DFA), a reinforcement learning algorithm that
fuses both individual rewards and pairwise preferences (if available) into a
single update rule. DFA uses the policy's log-probabilities directly to model
the preference probability, avoiding a separate reward-modeling step.
Preferences can be provided by human-annotators (at state-level or
trajectory-level) or be synthesized online from Q-values stored in an
off-policy replay buffer. Under a Bradley-Terry model, we prove that minimizing
DFA's preference loss recovers the entropy-regularized Soft Actor-Critic (SAC)
policy. Our simulation results show that DFA trained on generated preferences
matches or exceeds SAC on six control environments and demonstrates a more
stable training process. With only a semi-synthetic preference dataset under
Bradley-Terry model, our algorithm outperforms reward-modeling reinforcement
learning from human feedback (RLHF) baselines in a stochastic GridWorld and
approaches the performance of an oracle with true rewards.

</details>


### [191] [Minimizing Surrogate Losses for Decision-Focused Learning using Differentiable Optimization](https://arxiv.org/abs/2508.11365)
*Jayanta Mandi,Ali İrfan Mahmutoğulları,Senne Berden,Tias Guns*

Main category: cs.LG

TL;DR: 本文探讨了决策导向学习(DFL)中的问题，提出通过最小化代理损失来改进可微优化方法，从而减小决策遗憾并提高训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在求解线性规划问题时，因遗憾对预测参数的梯度多为零，使得梯度优化在大部分情况下无效，因此需要改进解决此问题。

Method: 本文提出即便使用了可微优化层，也建议最小化代理损失，尤其通过DYS-Net这一快速的可微优化技术来有效实现梯度计算和近似解。

Result: 实验表明，最小化代理损失可以在决策遗憾方面达到甚至优于现有方法，同时利用DYS-Net显著减少训练时间。

Conclusion: 使用代理损失最小化方法结合快速的可微优化技术如DYS-Net，不仅能够取得更低的遗憾值，还能大幅优化训练效率，证明了其优势。

Abstract: Decision-focused learning (DFL) trains a machine learning (ML) model to
predict parameters of an optimization problem, to directly minimize decision
regret, i.e., maximize decision quality. Gradient-based DFL requires computing
the derivative of the solution to the optimization problem with respect to the
predicted parameters. However, for many optimization problems, such as linear
programs (LPs), the gradient of the regret with respect to the predicted
parameters is zero almost everywhere. Existing gradient-based DFL approaches
for LPs try to circumvent this issue in one of two ways: (a) smoothing the LP
into a differentiable optimization problem by adding a quadratic regularizer
and then minimizing the regret directly or (b) minimizing surrogate losses that
have informative (sub)gradients. In this paper, we show that the former
approach still results in zero gradients, because even after smoothing the
regret remains constant across large regions of the parameter space. To address
this, we propose minimizing surrogate losses -- even when a differentiable
optimization layer is used and regret can be minimized directly. Our
experiments demonstrate that minimizing surrogate losses allows differentiable
optimization layers to achieve regret comparable to or better than
surrogate-loss based DFL methods. Further, we demonstrate that this also holds
for DYS-Net, a recently proposed differentiable optimization technique for LPs,
that computes approximate solutions and gradients through operations that can
be performed using feedforward neural network layers. Because DYS-Net executes
the forward and the backward pass very efficiently, by minimizing surrogate
losses using DYS-Net, we are able to attain regret on par with the
state-of-the-art while reducing training time by a significant margin.

</details>


### [192] [A Remedy for Over-Squashing in Graph Learning via Forman-Ricci Curvature based Graph-to-Hypergraph Structural Lifting](https://arxiv.org/abs/2508.11390)
*Michael Banf,Dominik Filipiak,Max Schattauer,Liliya Imasheva*

Main category: cs.LG

TL;DR: 研究提出了一种使用Forman-Ricci曲率的结构提升策略，以改进图消息传递中的信息失真问题。


<details>
  <summary>Details</summary>
Motivation: 当前图神经网络在处理复杂交互和高阶结构表示上存在局限性，无法有效处理社交网络或生物网络中基于拓扑的复杂互动需求。

Method: 提出通过Forman-Ricci曲率对图结构进行提升，利用这个基于黎曼几何学定义的特征来表示图的局部和全局特性，尤其是改进对远距离信息传递中的失真问题的处理。

Result: 通过使用Forman-Ricci曲率，该方法更好地刻画了图网络中的主干结构，把它们转化为超边形式，从而减轻了信息压缩和失真的问题。

Conclusion: 此方法有效解决了图学习中的长距离信息传递和过度压缩现象，为几何和拓扑深度学习领域提供了新的思路和工具。

Abstract: Graph Neural Networks are highly effective at learning from relational data,
leveraging node and edge features while maintaining the symmetries inherent to
graph structures. However, many real-world systems, such as social or
biological networks, exhibit complex interactions that are more naturally
represented by higher-order topological domains. The emerging field of
Geometric and Topological Deep Learning addresses this challenge by introducing
methods that utilize and benefit from higher-order structures. Central to TDL
is the concept of lifting, which transforms data representations from basic
graph forms to more expressive topologies before the application of GNN models
for learning. In this work, we propose a structural lifting strategy using
Forman-Ricci curvature, which defines an edge-based network characteristic
based on Riemannian geometry. Curvature reveals local and global properties of
a graph, such as a network's backbones, i.e. coarse, structure-preserving graph
geometries that form connections between major communities - most suitably
represented as hyperedges to model information flows between clusters across
large distances in the network. To this end, our approach provides a remedy to
the problem of information distortion in message passing across long distances
and graph bottlenecks - a phenomenon known in graph learning as over-squashing.

</details>


### [193] [On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting](https://arxiv.org/abs/2508.11408)
*Wenhao Zhang,Yuexiang Xie,Yuchang Sun,Yanxi Chen,Guoyin Wang,Yaliang Li,Bolin Ding,Jingren Zhou*

Main category: cs.LG

TL;DR: 提出了CHORD框架，实现了大语言模型（LLMs）中监督微调（SFT）和强化学习（RL）的动态权衡，解决了当前方法中的模型失衡和过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 当前SFT和RL结合的方式容易破坏模型已有模式并导致过拟合，需要一种新方法在二者间取得平衡。

Method: 提出CHORD动态加权框架，通过全局和局部两个层次动态调整离线专家数据和在线探索的融合程度，实现对SFT和RL的统一视角处理。

Result: 实验表明，CHORD在广泛使用的基准测试中实现了稳定且高效的学习过程，性能显著优于基线方法。

Conclusion: CHORD通过有效结合离线专家数据与在线探索，优化了模型调优过程，为进一步研究提供了灵感，并公开了实现代码。

Abstract: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two
prominent post-training paradigms for refining the capabilities and aligning
the behavior of Large Language Models (LLMs). Existing approaches that
integrate SFT and RL often face the risk of disrupting established model
patterns and inducing overfitting to expert data. To address this, we present a
novel investigation into the unified view of SFT and RL through an off-policy
versus on-policy lens. We propose CHORD, a framework for the Controllable
Harmonization of On- and Off-Policy Reinforcement Learning via Dynamic
Weighting, which reframes SFT not as a separate stage but as a dynamically
weighted auxiliary objective within the on-policy RL process. Based on an
analysis of off-policy expert data's influence at both holistic and granular
levels, we incorporate a dual-control mechanism in CHORD. Specifically, the
framework first employs a global coefficient to holistically guide the
transition from off-policy imitation to on-policy exploration, and then applies
a token-wise weighting function that enables granular learning from expert
tokens, which preserves on-policy exploration and mitigates disruption from
off-policy data. We conduct extensive experiments on widely used benchmarks,
providing empirical evidence that CHORD achieves a stable and efficient
learning process. By effectively harmonizing off-policy expert data with
on-policy exploration, CHORD demonstrates significant improvements over
baselines. We release the implementation at
https://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_chord to
inspire further research.

</details>


### [194] [Generative Co-Design of Antibody Sequences and Structures via Black-Box Guidance in a Shared Latent Space](https://arxiv.org/abs/2508.11424)
*Yinghua Yao,Yuangang Pan,Xixian Chen*

Main category: cs.LG

TL;DR: LEAD提出了一种优化CDR性能的新框架，通过在共享潜在空间中共同优化抗体序列和结构，实现了比现有方法更高效和精准的发展能力优化。


<details>
  <summary>Details</summary>
Motivation: 现有的CDR优化方法在原始数据空间中运行，效率较低且评估成本高。

Method: 提出LEAD框架，在潜在空间中优化序列与结构的潜在编码，并设计了适用于非可微评估器的黑箱指导策略。

Result: 实验表明，LEAD在单目标与多目标优化中表现优异，查询消耗减少一半，优于基线方法。

Conclusion: LEAD改进了抗体开发的效率与效果，展示了其在多评估场景中的实用性与优势。

Abstract: Advancements in deep generative models have enabled the joint modeling of
antibody sequence and structure, given the antigen-antibody complex as context.
However, existing approaches for optimizing complementarity-determining regions
(CDRs) to improve developability properties operate in the raw data space,
leading to excessively costly evaluations due to the inefficient search
process. To address this, we propose LatEnt blAck-box Design (LEAD), a
sequence-structure co-design framework that optimizes both sequence and
structure within their shared latent space. Optimizing shared latent codes can
not only break through the limitations of existing methods, but also ensure
synchronization of different modality designs. Particularly, we design a
black-box guidance strategy to accommodate real-world scenarios where many
property evaluators are non-differentiable. Experimental results demonstrate
that our LEAD achieves superior optimization performance for both single and
multi-property objectives. Notably, LEAD reduces query consumption by a half
while surpassing baseline methods in property optimization. The code is
available at https://github.com/EvaFlower/LatEnt-blAck-box-Design.

</details>


### [195] [Robust Convolution Neural ODEs via Contractivity-promoting regularization](https://arxiv.org/abs/2508.11432)
*Muhammad Zakwan,Liang Xu,Giancarlo Ferrari-Trecate*

Main category: cs.LG

TL;DR: 提出利用收缩理论增强卷积神经常微分方程(CNODE)的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 神经网络容易受到输入噪声和对抗攻击的影响。本文意在通过改进网络结构提高其在噪声和攻击下的稳健性。

Method: 通过在训练中引入与系统动力学Jacobian矩阵相关的正则化项来增强收缩性；或者通过应用特殊的权重正则化来实现收缩性。

Result: 在MNIST和FashionMNIST数据集的图像分类任务中，通过噪声和攻击的实验验证了正则化方法的有效性。

Conclusion: 提出的方法能提升卷积神经常微分方程模型的鲁棒性，对抗噪声和攻击有显著改善效果。

Abstract: Neural networks can be fragile to input noise and adversarial attacks.
  In this work, we consider Convolutional Neural Ordinary Differential
Equations (NODEs), a family of continuous-depth neural networks represented by
dynamical systems, and propose to use contraction theory to improve their
robustness.
  For a contractive dynamical system two trajectories starting from different
initial conditions converge to each other exponentially fast.
  Contractive Convolutional NODEs can enjoy increased robustness as slight
perturbations of the features do not cause a significant change in the output.
  Contractivity can be induced during training by using a regularization term
involving the Jacobian of the system dynamics.
  To reduce the computational burden, we show that it can also be promoted
using carefully selected weight regularization terms for a class of NODEs with
slope-restricted activation functions.
  The performance of the proposed regularizers is illustrated through benchmark
image classification tasks on MNIST and FashionMNIST datasets, where images are
corrupted by different kinds of noise and attacks.

</details>


### [196] [Multi-Sensory Cognitive Computing for Learning Population-level Brain Connectivity](https://arxiv.org/abs/2508.11436)
*Mayssa Soussia,Mohamed Ali Mahjoub,Islem Rekik*

Main category: cs.LG

TL;DR: 本文提出了一个名为mCOCO的新框架，用于从BOLD信号中学习功能连接的脑模板（CBT），侧重于提高可解释性、计算效率并捕捉认知特性。


<details>
  <summary>Details</summary>
Motivation: 现有CBT方法存在黑盒性、不具备认知性、高计算复杂度等问题，因此需要一种更高效和认知灵活性的解决方案。

Method: 通过Reservoir Computing (RC)技术从BOLD信号计算个体功能连接后聚合成群体CBT，并通过认知储层整合多感官输入赋予CBT认知功能。

Result: mCOCO在中心性、判别性、拓扑合理性及多感官记忆保留方面优于基于GNN的CBT方法。

Conclusion: mCOCO框架在生成兼具结构性与认知性脑模板中展现出更高性能，未来可广泛用于脑功能连接研究。

Abstract: The generation of connectional brain templates (CBTs) has recently garnered
significant attention for its potential to identify unique connectivity
patterns shared across individuals. However, existing methods for CBT learning
such as conventional machine learning and graph neural networks (GNNs) are
hindered by several limitations. These include: (i) poor interpretability due
to their black-box nature, (ii) high computational cost, and (iii) an exclusive
focus on structure and topology, overlooking the cognitive capacity of the
generated CBT. To address these challenges, we introduce mCOCO (multi-sensory
COgnitive COmputing), a novel framework that leverages Reservoir Computing (RC)
to learn population-level functional CBT from BOLD
(Blood-Oxygen-level-Dependent) signals. RC's dynamic system properties allow
for tracking state changes over time, enhancing interpretability and enabling
the modeling of brain-like dynamics, as demonstrated in prior literature. By
integrating multi-sensory inputs (e.g., text, audio, and visual data), mCOCO
captures not only structure and topology but also how brain regions process
information and adapt to cognitive tasks such as sensory processing, all in a
computationally efficient manner. Our mCOCO framework consists of two phases:
(1) mapping BOLD signals into the reservoir to derive individual functional
connectomes, which are then aggregated into a group-level CBT - an approach, to
the best of our knowledge, not previously explored in functional connectivity
studies - and (2) incorporating multi-sensory inputs through a cognitive
reservoir, endowing the CBT with cognitive traits. Extensive evaluations show
that our mCOCO-based template significantly outperforms GNN-based CBT in terms
of centeredness, discriminativeness, topological soundness, and multi-sensory
memory retention. Our source code is available at
https://github.com/basiralab/mCOCO.

</details>


### [197] [Informative Post-Hoc Explanations Only Exist for Simple Functions](https://arxiv.org/abs/2508.11441)
*Eric Günther,Balázs Szabados,Robi Bhattacharjee,Sebastian Bordt,Ulrike von Luxburg*

Main category: cs.LG

TL;DR: 本文提出了一个基于学习理论的框架来评估解释算法对复杂决策函数的适用性，并发现许多流行的解释算法在复杂模型中并不具备意义。


<details>
  <summary>Details</summary>
Motivation: 当前流行的局部后验解释算法被广泛用于理解复杂机器学习模型，但缺乏理论上的普遍性验证。研究旨在探讨复杂模型下解释算法的理论基础和适用性条件。

Method: 提出了一个基于学习理论的框架，通过复杂决策函数的可解释性与降低函数复杂性的能力关联，分析了不同解释算法在满足特定条件下的可解释性。

Result: 发现许多流行的解释算法在复杂函数上缺乏信息作用，如梯度解释、反事实解释、SHAP以及锚点解释在特定函数空间中均不具备信息性。提出了改进算法使其具备信息性的策略。

Conclusion: 尽管现有的许多解释算法无法对复杂决策函数提供有意义的解释，但通过满足特定条件，算法的可解释性仍能得到改进。这一分析对AI模型的审计、监管及高风险领域应用具有重要意义。

Abstract: Many researchers have suggested that local post-hoc explanation algorithms
can be used to gain insights into the behavior of complex machine learning
models. However, theoretical guarantees about such algorithms only exist for
simple decision functions, and it is unclear whether and under which
assumptions similar results might exist for complex models. In this paper, we
introduce a general, learning-theory-based framework for what it means for an
explanation to provide information about a decision function. We call an
explanation informative if it serves to reduce the complexity of the space of
plausible decision functions. With this approach, we show that many popular
explanation algorithms are not informative when applied to complex decision
functions, providing a rigorous mathematical rejection of the idea that it
should be possible to explain any model. We then derive conditions under which
different explanation algorithms become informative. These are often stronger
than what one might expect. For example, gradient explanations and
counterfactual explanations are non-informative with respect to the space of
differentiable functions, and SHAP and anchor explanations are not informative
with respect to the space of decision trees. Based on these results, we discuss
how explanation algorithms can be modified to become informative. While the
proposed analysis of explanation algorithms is mathematical, we argue that it
holds strong implications for the practical applicability of these algorithms,
particularly for auditing, regulation, and high-risk applications of AI.

</details>


### [198] [Calibrated and uncertain? Evaluating uncertainty estimates in binary classification models](https://arxiv.org/abs/2508.11460)
*Aurora Grefsrud,Nello Blaser,Trygve Buanes*

Main category: cs.LG

TL;DR: 通过对6种概率机器学习算法进行比较研究，评估其对分类概率和不确定性估计的性能，发现深度学习算法在处理分布外数据点的不确定性估计时存在不足。


<details>
  <summary>Details</summary>
Motivation: 研究复杂数据模型（如深度学习）中的不确定性量化挑战，评估现有不确定性估计方法的实际效果。

Method: 采用近似贝叶斯推断框架，基于精心设计的合成分类数据集，评估6种概率机器学习算法的不确定性估计性能。

Result: 6种算法均在校准性上表现良好，但深度学习相关算法在分布外数据点的不确定性估计上不具一致性。

Conclusion: 此研究为科学数据驱动建模中不确定性估计新方法的开发提供了基准与参考。

Abstract: Rigorous statistical methods, including parameter estimation with
accompanying uncertainties, underpin the validity of scientific discovery,
especially in the natural sciences. With increasingly complex data models such
as deep learning techniques, uncertainty quantification has become exceedingly
difficult and a plethora of techniques have been proposed. In this case study,
we use the unifying framework of approximate Bayesian inference combined with
empirical tests on carefully created synthetic classification datasets to
investigate qualitative properties of six different probabilistic machine
learning algorithms for class probability and uncertainty estimation: (i) a
neural network ensemble, (ii) neural network ensemble with conflictual loss,
(iii) evidential deep learning, (iv) a single neural network with Monte Carlo
Dropout, (v) Gaussian process classification and (vi) a Dirichlet process
mixture model. We check if the algorithms produce uncertainty estimates which
reflect commonly desired properties, such as being well calibrated and
exhibiting an increase in uncertainty for out-of-distribution data points. Our
results indicate that all algorithms are well calibrated, but none of the deep
learning based algorithms provide uncertainties that consistently reflect lack
of experimental evidence for out-of-distribution data points. We hope our study
may serve as a clarifying example for researchers developing new methods of
uncertainty estimation for scientific data-driven modeling.

</details>


### [199] [Predicting and Explaining Traffic Crash Severity Through Crash Feature Selection](https://arxiv.org/abs/2508.11504)
*Andrea Castellani,Zacharias Papadovasilakis,Giorgos Papoutsoglou,Mary Cole,Brian Bautsch,Tobias Rodemann,Ioannis Tsamardinos,Angela Harden*

Main category: cs.LG

TL;DR: 数据驱动方法阐明并减轻交通事故严重性，研究结合AutoML和可解释人工智能，构建预测模型并分析关键风险因素。


<details>
  <summary>Details</summary>
Motivation: 交通事故是全球伤亡的重要原因，需要基于数据的方法理解和减少事故严重性。

Method: 使用JADBio AutoML平台构建预测模型结合SHAP分析，量化个体特征对事故严重性的贡献，模型达到较高AUC-ROC评分。

Result: 最终模型识别出17个关键特征，与环境和背景变量相关性更高，传统因素如酒精影响权重较低。

Conclusion: 通过透明的可复制方法，该研究提供了支持“零愿景”（Vision Zero）的可扩展框架，从而改进交通安全政策。

Abstract: Motor vehicle crashes remain a leading cause of injury and death worldwide,
necessitating data-driven approaches to understand and mitigate crash severity.
This study introduces a curated dataset of more than 3 million people involved
in accidents in Ohio over six years (2017-2022), aggregated to more than 2.3
million vehicle-level records for predictive analysis. The primary contribution
is a transparent and reproducible methodology that combines Automated Machine
Learning (AutoML) and explainable artificial intelligence (AI) to identify and
interpret key risk factors associated with severe crashes. Using the JADBio
AutoML platform, predictive models were constructed to distinguish between
severe and non-severe crash outcomes. The models underwent rigorous feature
selection across stratified training subsets, and their outputs were
interpreted using SHapley Additive exPlanations (SHAP) to quantify the
contribution of individual features. A final Ridge Logistic Regression model
achieved an AUC-ROC of 85.6% on the training set and 84.9% on a hold-out test
set, with 17 features consistently identified as the most influential
predictors. Key features spanned demographic, environmental, vehicle, human,
and operational categories, including location type, posted speed, minimum
occupant age, and pre-crash action. Notably, certain traditionally emphasized
factors, such as alcohol or drug impairment, were less influential in the final
model compared to environmental and contextual variables. Emphasizing
methodological rigor and interpretability over mere predictive performance,
this study offers a scalable framework to support Vision Zero with aligned
interventions and advanced data-informed traffic safety policy.

</details>


### [200] [Towards Faithful Class-level Self-explainability in Graph Neural Networks by Subgraph Dependencies](https://arxiv.org/abs/2508.11513)
*Fanzhen Liu,Xiaoxiao Ma,Jian Yang,Alsharif Abuadbba,Kristen Moore,Surya Nepal,Cecile Paris,Quan Z. Sheng,Jia Wu*

Main category: cs.LG

TL;DR: 提出了GraphOracle,一个用于生成和评估图神经网络（GNN）类级别解释的新框架，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自解释GNN模型多关注实例级别解释，对于类级别解释的有效性仍存悬而未决的问题。

Method: 设计一种新的自解释GNN框架GraphOracle，结合分类器和稀疏子图生成器，并通过图-子图-预测关联的整合训练和基于掩码的验证策略进行高效评估。

Result: GraphOracle在保真度、可解释性和可扩展性方面优于现有方法，并且通过新颖的轻量化随机游走和熵正则子图选择避免了传统方法的计算瓶颈。

Conclusion: GraphOracle为实现GNN类级别的自解释性提供了实际可行且有理论依据的解决方案。

Abstract: Enhancing the interpretability of graph neural networks (GNNs) is crucial to
ensure their safe and fair deployment. Recent work has introduced
self-explainable GNNs that generate explanations as part of training, improving
both faithfulness and efficiency. Some of these models, such as ProtGNN and
PGIB, learn class-specific prototypes, offering a potential pathway toward
class-level explanations. However, their evaluations focus solely on
instance-level explanations, leaving open the question of whether these
prototypes meaningfully generalize across instances of the same class. In this
paper, we introduce GraphOracle, a novel self-explainable GNN framework
designed to generate and evaluate class-level explanations for GNNs. Our model
jointly learns a GNN classifier and a set of structured, sparse subgraphs that
are discriminative for each class. We propose a novel integrated training that
captures graph$\unicode{x2013}$subgraph$\unicode{x2013}$prediction dependencies
efficiently and faithfully, validated through a masking-based evaluation
strategy. This strategy enables us to retroactively assess whether prior
methods like ProtGNN and PGIB deliver effective class-level explanations. Our
results show that they do not. In contrast, GraphOracle achieves superior
fidelity, explainability, and scalability across a range of graph
classification tasks. We further demonstrate that GraphOracle avoids the
computational bottlenecks of previous methods$\unicode{x2014}$like Monte Carlo
Tree Search$\unicode{x2014}$by using entropy-regularized subgraph selection and
lightweight random walk extraction, enabling faster and more scalable training.
These findings position GraphOracle as a practical and principled solution for
faithful class-level self-explainability in GNNs.

</details>


### [201] [DiCriTest: Testing Scenario Generation for Decision-Making Agents Considering Diversity and Criticality](https://arxiv.org/abs/2508.11514)
*Qitong Chu,Yufeng Yue,Danya Yao,Huaxin Pei*

Main category: cs.LG

TL;DR: 提出了一种双空间引导测试框架，通过协调场景参数空间与智能体行为空间，在动态环境中生成多样且关键的测试场景。


<details>
  <summary>Details</summary>
Motivation: 现有方法在高维场景空间中容易陷入局部最优，无法有效平衡场景的多样性和关键性，需求迫切。

Method: 提出双空间引导测试框架，场景参数空间中通过分层表示框架和子空间评估来寻找多样和关键子空间，行为空间中利用智能体与环境的交互数据量化行为的多样性和关键性，并基于反馈动态调整生成模式。

Result: 框架相较于现有基线，关键场景生成性能平均提升56.23%，并在多样性指标下表现优越。

Conclusion: 该框架有效改进了动态环境中关键场景的生成能力，并成功平衡了多样性和关键性。

Abstract: The growing deployment of decision-making agents in dynamic environments
increases the demand for safety verification. While critical testing scenario
generation has emerged as an appealing verification methodology, effectively
balancing diversity and criticality remains a key challenge for existing
methods, particularly due to local optima entrapment in high-dimensional
scenario spaces. To address this limitation, we propose a dual-space guided
testing framework that coordinates scenario parameter space and agent behavior
space, aiming to generate testing scenarios considering diversity and
criticality. Specifically, in the scenario parameter space, a hierarchical
representation framework combines dimensionality reduction and
multi-dimensional subspace evaluation to efficiently localize diverse and
critical subspaces. This guides dynamic coordination between two generation
modes: local perturbation and global exploration, optimizing critical scenario
quantity and diversity. Complementarily, in the agent behavior space,
agent-environment interaction data are leveraged to quantify behavioral
criticality/diversity and adaptively support generation mode switching, forming
a closed feedback loop that continuously enhances scenario characterization and
exploration within the parameter space. Experiments show our framework improves
critical scenario generation by an average of 56.23\% and demonstrates greater
diversity under novel parameter-behavior co-driven metrics when tested on five
decision-making agents, outperforming state-of-the-art baselines.

</details>


### [202] [Finite-Width Neural Tangent Kernels from Feynman Diagrams](https://arxiv.org/abs/2508.11522)
*Max Guillen,Philipp Misof,Jan E. Gerken*

Main category: cs.LG

TL;DR: 本文提出了用费曼图来计算有限宽度神经切线核（NTK）修正，以简化必要的代数操作，并预测主要训练动态。


<details>
  <summary>Details</summary>
Motivation: 分析无限宽度限制下的深层非线性神经网络的训练动态，解决特征学习及NTK演化在有限宽度下的缺失问题。

Method: 引入费曼图的计算框架，用于计算有限宽度修正，并建立涉及预激活、NTK及其高阶导数张量的层级递归关系。

Result: 证明了对于像ReLU这样具有尺度不变性的非线性函数，NTK Gram矩阵对角线上的有限宽度修正不存在。通过数值实验验证了结果。

Conclusion: 使用费曼图简化了有限宽度修正的计算，并扩展了深度网络稳定性的分析，验证了研究框架的可行性。

Abstract: Neural tangent kernels (NTKs) are a powerful tool for analyzing deep,
non-linear neural networks. In the infinite-width limit, NTKs can easily be
computed for most common architectures, yielding full analytic control over the
training dynamics. However, at infinite width, important properties of training
such as NTK evolution or feature learning are absent. Nevertheless, finite
width effects can be included by computing corrections to the Gaussian
statistics at infinite width. We introduce Feynman diagrams for computing
finite-width corrections to NTK statistics. These dramatically simplify the
necessary algebraic manipulations and enable the computation of layer-wise
recursive relations for arbitrary statistics involving preactivations, NTKs and
certain higher-derivative tensors (dNTK and ddNTK) required to predict the
training dynamics at leading order. We demonstrate the feasibility of our
framework by extending stability results for deep networks from preactivations
to NTKs and proving the absence of finite-width corrections for scale-invariant
nonlinearities such as ReLU on the diagonal of the Gram matrix of the NTK. We
validate our results with numerical experiments.

</details>


### [203] [Physics-Informed Diffusion Models for Unsupervised Anomaly Detection in Multivariate Time Series](https://arxiv.org/abs/2508.11528)
*Juhi Soni,Markus Lange-Hegermann,Stefan Windmann*

Main category: cs.LG

TL;DR: 提出了一种基于物理启发扩散模型的无监督异常检测方法，适用于多变量时间序列数据。


<details>
  <summary>Details</summary>
Motivation: 基于过去扩散模型在时间序列领域的成功应用，探索如何通过引入物理信息改进异常检测性能。

Method: 在扩散模型训练中引入基于静态权重计划的物理启发型加权损失，以更准确地学习时间序列的物理相关时序分布。

Result: 实验表明，物理启发型训练在异常检测的F1得分、数据多样性和对数似然上均表现更优。

Conclusion: 本文方法在部分数据集上超越了基线方法、之前的物理启发工作及纯数据驱动扩散模型，并在其他数据集上表现亦有竞争力。

Abstract: We propose an unsupervised anomaly detection approach based on a
physics-informed diffusion model for multivariate time series data. Over the
past years, diffusion model has demonstrated its effectiveness in forecasting,
imputation, generation, and anomaly detection in the time series domain. In
this paper, we present a new approach for learning the physics-dependent
temporal distribution of multivariate time series data using a weighted
physics-informed loss during diffusion model training. A weighted
physics-informed loss is constructed using a static weight schedule. This
approach enables a diffusion model to accurately approximate underlying data
distribution, which can influence the unsupervised anomaly detection
performance. Our experiments on synthetic and real-world datasets show that
physics-informed training improves the F1 score in anomaly detection; it
generates better data diversity and log-likelihood. Our model outperforms
baseline approaches, additionally, it surpasses prior physics-informed work and
purely data-driven diffusion models on a synthetic dataset and one real-world
dataset while remaining competitive on others.

</details>


### [204] [A Comprehensive Perspective on Explainable AI across the Machine Learning Workflow](https://arxiv.org/abs/2508.11529)
*George Paterakis,Andrea Castellani,George Papoutsoglou,Tobias Rodemann,Ioannis Tsamardinos*

Main category: cs.LG

TL;DR: 提出了一个名为Holistic Explainable Artificial Intelligence (HXAI)的框架，整合解释性到人工智能的各个阶段，旨在提升透明性和用户信任。


<details>
  <summary>Details</summary>
Motivation: 解决传统可解释人工智能（XAI）只关注单一预测解释、忽视数据分析流程中其他关键环节的问题，增强人工智能的透明性和可信度。

Method: 提出HXAI框架，将数据、分析设置、学习过程等六个部分统一为一个分类体系，并根据行业专家、数据分析师和科学家的需求定制解释，通过引入112项问题库，以及整合从多个学科获得的理论和实践经验，构建具有操作性的系统化方法。

Result: 实现了理论与实践的桥接，构建了一个描述清晰、可操作性强的分类体系，并展示了AI代理如何通过大语言模型协调不同的解释技术，生成符合利益相关者需求的叙述。

Conclusion: 本文提供了一种整合多学科知识与实际经验的新型视角，通过HXAI框架推动了人工智能模型的端到端透明性及可信部署的进展。

Abstract: Artificial intelligence is reshaping science and industry, yet many users
still regard its models as opaque "black boxes". Conventional explainable
artificial-intelligence methods clarify individual predictions but overlook the
upstream decisions and downstream quality checks that determine whether
insights can be trusted. In this work, we present Holistic Explainable
Artificial Intelligence (HXAI), a user-centric framework that embeds
explanation into every stage of the data-analysis workflow and tailors those
explanations to users. HXAI unifies six components (data, analysis set-up,
learning process, model output, model quality, communication channel) into a
single taxonomy and aligns each component with the needs of domain experts,
data analysts and data scientists. A 112-item question bank covers these needs;
our survey of contemporary tools highlights critical coverage gaps. Grounded in
theories of human explanation, principles from human-computer interaction and
findings from empirical user studies, HXAI identifies the characteristics that
make explanations clear, actionable and cognitively manageable. A comprehensive
taxonomy operationalises these insights, reducing terminological ambiguity and
enabling rigorous coverage analysis of existing toolchains. We further
demonstrate how AI agents that embed large-language models can orchestrate
diverse explanation techniques, translating technical artifacts into
stakeholder-specific narratives that bridge the gap between AI developers and
domain experts. Departing from traditional surveys or perspective articles,
this work melds concepts from multiple disciplines, lessons from real-world
projects and a critical synthesis of the literature to advance a novel,
end-to-end viewpoint on transparency, trustworthiness and responsible AI
deployment.

</details>


### [205] [DFed-SST: Building Semantic- and Structure-aware Topologies for Decentralized Federated Graph Learning](https://arxiv.org/abs/2508.11530)
*Lianshuai Guo,Zhongzheng Yuan,Xunkai Li,Yinlin Zhu,Meixia Qu,Wenyu Wang*

Main category: cs.LG

TL;DR: 本文提出了DFed-SST，一种用于图数据的去中心化联邦学习框架，通过动态调整通信拓扑实现更高效的模型聚合，提升了分布式学习的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的去中心化联邦学习方法无法有效处理本地子图的拓扑信息，同时现有的联邦图学习方法依赖中心化架构，未能利用去中心化带来的优点。

Method: 提出了一种双拓扑自适应通信机制，根据每个客户端本地子图的特征动态构建并优化客户端间的通信拓扑，提升模型聚合的效率和应对异质性的能力。

Result: 在八个真实数据集上的实验显示，DFed-SST相比基线方法在平均准确率上提升了3.26%。

Conclusion: DFed-SST证明了去中心化联邦图学习框架的有效性，更好地处理了拓扑异质性和通信效率问题，为分布式学习领域提供了新的视角。

Abstract: Decentralized Federated Learning (DFL) has emerged as a robust distributed
paradigm that circumvents the single-point-of-failure and communication
bottleneck risks of centralized architectures. However, a significant challenge
arises as existing DFL optimization strategies, primarily designed for tasks
such as computer vision, fail to address the unique topological information
inherent in the local subgraph. Notably, while Federated Graph Learning (FGL)
is tailored for graph data, it is predominantly implemented in a centralized
server-client model, failing to leverage the benefits of decentralization.To
bridge this gap, we propose DFed-SST, a decentralized federated graph learning
framework with adaptive communication. The core of our method is a
dual-topology adaptive communication mechanism that leverages the unique
topological features of each client's local subgraph to dynamically construct
and optimize the inter-client communication topology. This allows our framework
to guide model aggregation efficiently in the face of heterogeneity. Extensive
experiments on eight real-world datasets consistently demonstrate the
superiority of DFed-SST, achieving 3.26% improvement in average accuracy over
baseline methods.

</details>


### [206] [Nested Operator Inference for Adaptive Data-Driven Learning of Reduced-order Models](https://arxiv.org/abs/2508.11542)
*Nicole Aretz,Karen Willcox*

Main category: cs.LG

TL;DR: 本文提出了一种数据驱动的嵌套算子推断方法，从高维动力系统的快照数据中学习物理信息的降阶模型。


<details>
  <summary>Details</summary>
Motivation: 当处理高维动力系统时，创建有效的降阶模型是一项挑战，需要找到能够高效逼近系统行为的方法。

Method: 通过利用降阶空间中的固有层次结构，迭代构建初始猜测，从而优先考虑主要模式之间的交互。这种方法还支持动态基础和模型形式更新。

Result: 在一个导热问题中，该方法比标准算子推断的误差减少了四倍，同时应用于格陵兰冰盖时，其误差平均为3%，计算加速因子超过了19,000。

Conclusion: 嵌套算子推断方法在高效降阶建模中表现出显著优势，提供了较高的准确性和显著的计算加速。

Abstract: This paper presents a data-driven, nested Operator Inference (OpInf) approach
for learning physics-informed reduced-order models (ROMs) from snapshot data of
high-dimensional dynamical systems. The approach exploits the inherent
hierarchy within the reduced space to iteratively construct initial guesses for
the OpInf learning problem that prioritize the interactions of the dominant
modes. The initial guess computed for any target reduced dimension corresponds
to a ROM with provably smaller or equal snapshot reconstruction error than with
standard OpInf. Moreover, our nested OpInf algorithm can be warm-started from
previously learned models, enabling versatile application scenarios involving
dynamic basis and model form updates. We demonstrate the performance of our
algorithm on a cubic heat conduction problem, with nested OpInf achieving a
four times smaller error than standard OpInf at a comparable offline time.
Further, we apply nested OpInf to a large-scale, parameterized model of the
Greenland ice sheet where, despite model form approximation errors, it learns a
ROM with, on average, 3% error and computational speed-up factor above 19,000.

</details>


### [207] [SeamlessFlow: A Trainer Agent Isolation RL Framework Achieving Bubble-Free Pipelines via Tag Scheduling](https://arxiv.org/abs/2508.11553)
*Jinghui Wang,Shaojie Wang,Yinghan Cui,Xuxing Chen,Chao Wang,Xiaojiang Zhang,Minglei Zhang,Jiarong Zhang,Wenhao Zhuang,Yuchen Cao,Wankang Bao,Haimo Li,Zheng Lin,Huiming Wang,Haoyang Huang,Zongxian Feng,Zizheng Zhan,Ken Deng,Wen Xiang,Huaixi Tang,Kun Wu,Mengtong Li,Mengfei Xie,Junyi Peng,Haotian Zhang,Bin Chen,Bing Yu*

Main category: cs.LG

TL;DR: SeamlessFlow是一种工业级强化学习框架，解决了训练与执行解耦及GPU利用率最大化的问题，通过数据平面和标签驱动调度抽象优化性能与扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决工业级强化学习中训练和执行流程复杂性、GPU利用率低的问题，适应大规模部署需求。

Method: 引入数据平面实现RL训练与代理执行解耦，采用轨迹管理支持滚动断续与恢复；提出标签驱动调度模式，优化硬件资源使用，通过时空复用动态分配节点。

Result: 实现了强化学习的稳定性与高性能，适用于多智能体、长时间跨度及复杂任务。

Conclusion: SeamlessFlow通过系列创新，提供了稳定且高效的RL解决方案，适应多种复杂工业场景的需求。

Abstract: We introduce SeamlessFlow, a server based reinforcement learning (RL)
framework that addresses two core challenges in industrial scale RL: (1)
decoupling RL training from the complex execution flow of agents; (2)
maximizing GPU utilization with minimal idle time while preserving the
stability and scalability required for large-scale deployments. First,
SeamlessFlow introduces a data plane that decouples the RL trainer from
diverse, complex agent implementations while sustaining high throughput. A
central trajectory manager maintains complete interaction histories and
supports partial rollout, allowing rollout to pause for weight updates and
resume seamlessly, keeping agents unaware of service interruptions. Second, we
propose a tag driven scheduling paradigm that abstracts hardware into
capability tagged resources, unifying colocated and disaggregated
architectures. Based on this, SeamlessFlow introduces a spatiotemporal
multiplexing pipeline that dynamically reassigns idle training nodes to rollout
in a train rollout separated setup, eliminating pipeline bubbles and fully
exploiting heterogeneous cluster resources. By combining these innovations,
SeamlessFlow delivers both stability and high performance, making it well
suited for multi agent, long horizon, and other complex RL tasks.

</details>


### [208] [Optimal CO2 storage management considering safety constraints in multi-stakeholder multi-site CCS projects: a game theoretic perspective](https://arxiv.org/abs/2508.11618)
*Jungang Chen,Seyyed A. Hosseini*

Main category: cs.LG

TL;DR: 提出了一种基于马尔可夫博弈的框架，研究多方协作下的碳捕获和储存（CCS）项目管理，尤其是在地质条件复杂的情况下。


<details>
  <summary>Details</summary>
Motivation: CCS项目涉及多方利益相关者，分布在复杂且长周期的地质结构中，单方面目标优化难以实现，需探索协作或联合的有效性。

Method: 将多方多地点问题建模为具有安全约束的多智能体强化学习问题，采用Embed-to-Control（E2C）框架的代理模型提高计算效率，实现基于马尔可夫博弈的方案。

Result: 展示了该框架能够有效处理多利益相关者共同管理的CO2储存优化问题。

Conclusion: 合作且遵循安全规定的框架对于CCS项目的有效规划和管理至关重要，特别是在多目标多利益冲突的情境中。

Abstract: Carbon capture and storage (CCS) projects typically involve a diverse array
of stakeholders or players from public, private, and regulatory sectors, each
with different objectives and responsibilities. Given the complexity, scale,
and long-term nature of CCS operations, determining whether individual
stakeholders can independently maximize their interests or whether
collaborative coalition agreements are needed remains a central question for
effective CCS project planning and management. CCS projects are often
implemented in geologically connected sites, where shared geological features
such as pressure space and reservoir pore capacity can lead to competitive
behavior among stakeholders. Furthermore, CO2 storage sites are often located
in geologically mature basins that previously served as sites for hydrocarbon
extraction or wastewater disposal in order to leverage existing
infrastructures, which makes unilateral optimization even more complicated and
unrealistic.
  In this work, we propose a paradigm based on Markov games to quantitatively
investigate how different coalition structures affect the goals of
stakeholders. We frame this multi-stakeholder multi-site problem as a
multi-agent reinforcement learning problem with safety constraints. Our
approach enables agents to learn optimal strategies while compliant with safety
regulations. We present an example where multiple operators are injecting CO2
into their respective project areas in a geologically connected basin. To
address the high computational cost of repeated simulations of high-fidelity
models, a previously developed surrogate model based on the Embed-to-Control
(E2C) framework is employed. Our results demonstrate the effectiveness of the
proposed framework in addressing optimal management of CO2 storage when
multiple stakeholders with various objectives and goals are involved.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [209] [SDSNN: A Single-Timestep Spiking Neural Network with Self-Dropping Neuron and Bayesian Optimization](https://arxiv.org/abs/2508.10913)
*Changqing Xu,Buxuan Song,Yi Liu,Xinfang Liao,Wenbin Zheng,Yintang Yang*

Main category: cs.NE

TL;DR: 提出一种单时间步的尖峰神经网络(SNN)，通过优化尖峰生成和时间参数，提高准确率并减少计算能耗。实验验证了所提方法的有效性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统多时间步尖峰神经网络(SNNs)在推理延迟和计算能耗方面存在局限性，特别是在边缘计算场景中。研究旨在通过设计一种新型的单时间步SNN解决此问题。

Method: 提出了一种自降神经元(Self-Dropping Neuron)机制，通过动态阈值调整和选择性尖峰抑制提高信息承载能力，并利用贝叶斯优化探索时间参数以实现高效的单时间步推理模式。

Result: 在Fashion-MNIST, CIFAR-10, CIFAR-100数据集上，该方法在单时间步下的准确率分别为93.72%、92.20%和69.45%，能耗减少56%、21%和22%。

Conclusion: 所提出的单时间步SNN方法能够在保持甚至超过传统多时间步模型准确率的同时，显著降低推理能耗，展示了在高效计算场景中的潜力。

Abstract: Spiking Neural Networks (SNNs), as an emerging biologically inspired
computational model, demonstrate significant energy efficiency advantages due
to their event-driven information processing mechanism. Compared to traditional
Artificial Neural Networks (ANNs), SNNs transmit information through discrete
spike signals, which substantially reduces computational energy consumption
through their sparse encoding approach. However, the multi-timestep computation
model significantly increases inference latency and energy, limiting the
applicability of SNNs in edge computing scenarios. We propose a single-timestep
SNN, which enhances accuracy and reduces computational energy consumption in a
single timestep by optimizing spike generation and temporal parameters. We
design a Self-Dropping Neuron mechanism, which enhances information-carrying
capacity through dynamic threshold adjustment and selective spike suppression.
Furthermore, we employ Bayesian optimization to globally search for time
parameters and obtain an efficient inference mode with a single time step.
Experimental results on the Fashion-MNIST, CIFAR-10, and CIFAR-100 datasets
demonstrate that, compared to traditional multi-timestep SNNs employing the
Leaky Integrate-and-Fire (LIF) model, our method achieves classification
accuracies of 93.72%, 92.20%, and 69.45%, respectively, using only
single-timestep spikes, while maintaining comparable or even superior accuracy.
Additionally, it reduces energy consumption by 56%, 21%, and 22%, respectively.

</details>


### [210] [Insect-Wing Structured Microfluidic System for Reservoir Computing](https://arxiv.org/abs/2508.10915)
*Jacob Clouse,Thomas Ramsey,Samitha Somathilaka,Nicholas Kleinsasser,Sangjin Ryu,Sasitharan Balasubramaniam*

Main category: cs.NE

TL;DR: 该研究提出了一种基于蜻蜓翅膀启发的微流体芯片的混合储备计算系统，可以在非电子环境下实现高效计算。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索在无法使用传统电子设备的环境中，如何实现低功耗、高鲁棒性的计算方法。

Method: 设计一个具有三个染料通道和三个检测区域的微流体芯片，通过液体在微通道网络中的相互作用来编码时序输入模式，并结合易于训练的读出层进行图案分类。

Result: 实验结果显示，无论在低分辨率还是有限训练数据条件下，分类准确率可达到91%。

Conclusion: 微流体储备计算具有可行性，为实现高效、适应性的计算提供了新方向，特别适合于不适合电子设备的环境。

Abstract: As the demand for more efficient and adaptive computing grows,
nature-inspired architectures offer promising alternatives to conventional
electronic designs. Microfluidic platforms, drawing on biological forms and
fluid dynamics, present a compelling foundation for low-power, high-resilience
computing in environments where electronics are unsuitable. This study explores
a hybrid reservoir computing system based on a dragonfly-wing inspired
microfluidic chip, which encodes temporal input patterns as fluid interactions
within the micro channel network.
  The system operates with three dye-based inlet channels and three
camera-monitored detection areas, transforming discrete spatial patterns into
dynamic color output signals. These reservoir output signals are then modified
and passed to a simple and trainable readout layer for pattern classification.
Using a combination of raw reservoir outputs and synthetically generated
outputs, we evaluated system performance, system clarity, and data efficiency.
The results demonstrate consistent classification accuracies up to $91\%$, even
with coarse resolution and limited training data, highlighting the viability of
the microfluidic reservoir computing.

</details>


### [211] [Use of a genetic algorithm to find solutions to introductory physics problems](https://arxiv.org/abs/2508.10920)
*Tom Bensky,Justin Kopcinski*

Main category: cs.NE

TL;DR: 本文展示了一种利用遗传算法（GA）解决基础物理问题的创新方法，通过生成方程序列来完成问题求解。


<details>
  <summary>Details</summary>
Motivation: 目标是帮助学生通过系统搜索方程序列解答物理问题，提升学习效率并增强对问题解法直观理解。

Method: 采用遗传算法，通过优化适应度函数寻找方程序列。适应度基于已知和未知量的差值，GA从问题文本中提取已知量并生成问题序列，不断改进解法。

Result: 证明了该方法可以指导学生解决涉及一维运动学的任何基础物理问题，同时提升了解法的可解释性。

Conclusion: 遗传算法可有效协助学生解决物理问题，并提供直观的解题步骤，具有较大的教学应用潜力。

Abstract: In this work, we show how a genetic algorithm (GA) can be used to find
step-by-step solutions to introductory physics problems. Our perspective is
that the underlying task for this is one of finding a sequence of equations
that will lead to the needed answer. Here a GA is used to find an appropriate
equation sequence by minimizing a fitness function that measures the difference
between the number of unknowns versus knowns in a set of equations. Information
about knowns comes from the GA posing questions to the student about what
quantities exist in the text of their problem. The questions are generated from
enumerations pulled from the chromosomes that drive the GA. Equations with
smaller known vs. unknown differences are considered more fit and are used to
produce intermediate results that feed less fit equations. We show that this
technique can guide a student to an answer to any introductory physics problem
involving one-dimensional kinematics. Interpretability findings are discussed.

</details>


### [212] [SO-PIFRNN: Self-optimization physics-informed Fourier-features randomized neural network for solving partial differential equations](https://arxiv.org/abs/2508.10921)
*Jiale Linghu,Weifeng Gao,Hao Dong,Yufeng Nie*

Main category: cs.NE

TL;DR: 提出了一种可自优化的物理信息傅里叶特征随机神经网络（SO-PIFRNN）框架，通过超参数优化显著提高了偏微分方程（PDEs）的数值求解精度。


<details>
  <summary>Details</summary>
Motivation: 提高偏微分方程数值求解的准确性和效率，并解决传统网络在多频率成分捕捉能力上的不足。

Method: 采用双层优化结构，外层优化通过多策略协作粒子群优化算法（MSC-PSO）优化网络超参数，内层优化通过最小二乘法调整输出层权重；同时引入傅里叶基函数激活机制和新型导数神经网络方法提高计算性能。

Result: 通过大量数值实验验证，SO-PIFRNN在复杂区域多尺度方程、高次方程、高维方程和非线性方程的数值求解中，表现出卓越的逼近精度和频率捕捉能力。

Conclusion: SO-PIFRNN框架提升了偏微分方程的求解能力，在多频率成分的捕捉和全局优化能力上取得显著改进，具有广泛的应用潜力。

Abstract: This study proposes a self-optimization physics-informed Fourier-features
randomized neural network (SO-PIFRNN) framework, which significantly improves
the numerical solving accuracy of PDEs through hyperparameter optimization
mechanism. The framework employs a bi-level optimization architecture: the
outer-level optimization utilizes a multi-strategy collaborated particle swarm
optimization (MSC-PSO) algorithm to search for optimal hyperparameters of
physics-informed Fourier-features randomized neural network, while the
inner-level optimization determines the output layer weights of the neural
network via the least squares method. The core innovation of this study is
embodied in the following three aspects: First, the Fourier basis function
activation mechanism is introduced in the hidden layer of neural network, which
significantly enhances the ability of the network to capture multi-frequency
components of the solution. Secondly, a novel derivative neural network method
is proposed, which improves the calculation accuracy and efficiency of PIFRNN
method. Finally, the MSC-PSO algorithm of the hybrid optimization strategy is
designed to improve the global search ability and convergence accuracy through
the synergistic effect of dynamic parameter adjustment, elitist and mutation
strategies. Through a series of numerical experiments, including multiscale
equations in complex regions, high-order equations, high-dimensional equations
and nonlinear equations, the validity of SO-PIFRNN is verified. The
experimental results affirm that SO-PIFRNN exhibits superior approximation
accuracy and frequency capture capability.

</details>


### [213] [Allee Synaptic Plasticity and Memory](https://arxiv.org/abs/2508.10929)
*Eddy Kwessi*

Main category: cs.NE

TL;DR: 考察基于Allee的非线性可塑性模型相比传统模型的性能，提出改进和解决问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有记忆模型噪声敏感性高与突触权值无限增长的问题。

Method: 研究并扩展基于Allee的非线性突触塑性模型，引入时间依赖性动态机制如资格迹和振荡输入。

Result: 该模型提高了记忆保持、模式检索的容量和可靠性，增强了动态环境下的恢复准确性与稳健性。

Conclusion: 提供了一个与生物学更加一致的框架，有助于推动人工智能和神经科学的发展。

Abstract: Neural plasticity is fundamental to memory storage and retrieval in
biological systems, yet existing models often fall short in addressing noise
sensitivity and unbounded synaptic weight growth. This paper investigates the
Allee-based nonlinear plasticity model, emphasizing its biologically inspired
weight stabilization mechanisms, enhanced noise robustness, and critical
thresholds for synaptic regulation. We analyze its performance in memory
retention and pattern retrieval, demonstrating increased capacity and
reliability compared to classical models like Hebbian and Oja's rules. To
address temporal limitations, we extend the model by integrating time-dependent
dynamics, including eligibility traces and oscillatory inputs, resulting in
improved retrieval accuracy and resilience in dynamic environments. This work
bridges theoretical insights with practical implications, offering a robust
framework for modeling neural adaptation and informing advances in artificial
intelligence and neuroscience.

</details>
