<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.CL](#cs.CL) [Total: 46]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.LG](#cs.LG) [Total: 62]
- [cs.NE](#cs.NE) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Quality-Guided Mixture of Score-Fusion Experts Framework for Human Recognition](https://arxiv.org/abs/2508.00053)
*Jie Zhu,Yiyang Su,Minchul Kim,Anil Jain,Xiaoming Liu*

Main category: cs.CV

TL;DR: 提出了一种新的用于全身生物识别的方法，即质量引导的专家混合得分融合（QME），通过引入伪质量损失和得分三元损失，在多个数据集上显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 克服单一模态系统的局限性，解决传统方法在多模态分数分布变化中提升性能的难题。

Method: 设计了一个新框架，结合专家混合模型（MoE），通过伪质量损失进行质量估计，并通过得分三元损失优化结果。

Result: 在多个全身生物识别数据集上的实验表明，所提方法在各种衡量指标上均优于基线方法，且解决了模型对齐和数据质量变化的关键问题。

Conclusion: QME方法有效提升了全身生物识别性能，对多模态及多模型任务表现出了强大的适配能力，并解决了传统得分融合方式的局限性。

Abstract: Whole-body biometric recognition is a challenging multimodal task that
integrates various biometric modalities, including face, gait, and body. This
integration is essential for overcoming the limitations of unimodal systems.
Traditionally, whole-body recognition involves deploying different models to
process multiple modalities, achieving the final outcome by score-fusion (e.g.,
weighted averaging of similarity matrices from each model). However, these
conventional methods may overlook the variations in score distributions of
individual modalities, making it challenging to improve final performance. In
this work, we present \textbf{Q}uality-guided \textbf{M}ixture of score-fusion
\textbf{E}xperts (QME), a novel framework designed for improving whole-body
biometric recognition performance through a learnable score-fusion strategy
using a Mixture of Experts (MoE). We introduce a novel pseudo-quality loss for
quality estimation with a modality-specific Quality Estimator (QE), and a score
triplet loss to improve the metric performance. Extensive experiments on
multiple whole-body biometric datasets demonstrate the effectiveness of our
proposed approach, achieving state-of-the-art results across various metrics
compared to baseline methods. Our method is effective for multimodal and
multi-model, addressing key challenges such as model misalignment in the
similarity score domain and variability in data quality.

</details>


### [2] [Punching Bag vs. Punching Person: Motion Transferability in Videos](https://arxiv.org/abs/2508.00085)
*Raiyaan Abdullah,Jared Claypoole,Michael Cogswell,Ajay Divakaran,Yogesh Rawat*

Main category: cs.CV

TL;DR: 通过三个数据集评估动作识别模型的运动迁移能力，并发现模型在新情境下的高层动作识别表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 研究动作识别模型是否能在不同情境中有效迁移高层运动概念，如识别“punching”是否能扩展到未见过的情境“punching person”。

Method: 提出运动迁移能力框架，包含三个数据集（Syn-TA、Kinetics400-TA 和 Something-Something-v2-TA），并对13种先进模型在这些基准上的性能进行评估。

Result: 发现模型在识别新情境下的高层动作时表现显著下降，多模态模型在细粒度未知动作上表现更差，较大的模型在依赖时间推理时效果不理想。

Conclusion: 研究建立了一项关键基准，用于评估动作识别中的运动迁移能力，并提出分离粗细粒度运动以提高识别性能。

Abstract: Action recognition models demonstrate strong generalization, but can they
effectively transfer high-level motion concepts across diverse contexts, even
within similar distributions? For example, can a model recognize the broad
action "punching" when presented with an unseen variation such as "punching
person"? To explore this, we introduce a motion transferability framework with
three datasets: (1) Syn-TA, a synthetic dataset with 3D object motions; (2)
Kinetics400-TA; and (3) Something-Something-v2-TA, both adapted from natural
video datasets. We evaluate 13 state-of-the-art models on these benchmarks and
observe a significant drop in performance when recognizing high-level actions
in novel contexts. Our analysis reveals: 1) Multimodal models struggle more
with fine-grained unknown actions than with coarse ones; 2) The bias-free
Syn-TA proves as challenging as real-world datasets, with models showing
greater performance drops in controlled settings; 3) Larger models improve
transferability when spatial cues dominate but struggle with intensive temporal
reasoning, while reliance on object and background cues hinders generalization.
We further explore how disentangling coarse and fine motions can improve
recognition in temporally challenging datasets. We believe this study
establishes a crucial benchmark for assessing motion transferability in action
recognition. Datasets and relevant code:
https://github.com/raiyaan-abdullah/Motion-Transfer.

</details>


### [3] [The Monado SLAM Dataset for Egocentric Visual-Inertial Tracking](https://arxiv.org/abs/2508.00088)
*Mateo de Mayo,Daniel Cremers,Taihú Pire*

Main category: cs.CV

TL;DR: 提出了Monado SLAM数据集，旨在解决头戴式传感器在现实应用中的挑战性问题，并促进VIO/SLAM技术的研究与发展。


<details>
  <summary>Details</summary>
Motivation: 现有的VIO/SLAM系统在头戴式设备应用场景中，如高强度运动、动态遮挡等，仍存在难以处理的挑战，且相关数据集覆盖不足。

Method: 通过从多个VR头戴设备中采集真实数据场景，构建了Monado SLAM数据集，并通过CC BY 4.0许可协议对外发布。

Result: 提供了一个涵盖真实应用挑战的公开SLAM数据集，便于研究者使用。

Conclusion: Monado SLAM数据集有望推动VIO和SLAM技术在真实应用中的发展和改进。

Abstract: Humanoid robots and mixed reality headsets benefit from the use of
head-mounted sensors for tracking. While advancements in visual-inertial
odometry (VIO) and simultaneous localization and mapping (SLAM) have produced
new and high-quality state-of-the-art tracking systems, we show that these are
still unable to gracefully handle many of the challenging settings presented in
the head-mounted use cases. Common scenarios like high-intensity motions,
dynamic occlusions, long tracking sessions, low-textured areas, adverse
lighting conditions, saturation of sensors, to name a few, continue to be
covered poorly by existing datasets in the literature. In this way, systems may
inadvertently overlook these essential real-world issues. To address this, we
present the Monado SLAM dataset, a set of real sequences taken from multiple
virtual reality headsets. We release the dataset under a permissive CC BY 4.0
license, to drive advancements in VIO/SLAM research and development.

</details>


### [4] [Exploring the Feasibility of Deep Learning Techniques for Accurate Gender Classification from Eye Images](https://arxiv.org/abs/2508.00135)
*Basna Mohammed Salih Hasan,Ramadhan J. Mstafa*

Main category: cs.CV

TL;DR: 本论文探讨了使用卷积神经网络（CNN）对眼周区域彩色图像进行性别分类，高效性能展示了模型的卓越效果，特别是在安保和监控领域的潜在应用。


<details>
  <summary>Details</summary>
Motivation: 性别分类在安全、人机交互和广告等领域至关重要，但受到化妆和伪装等因素影响。因此，研究着眼于通过分析眼周区域提升性别分类准确性。

Method: 提出了一种先进的卷积神经网络模型，专注于利用眼周区域彩色图像进行性别分类，并在两个数据集上验证了模型的表现。

Result: 在CVBL数据集上达到了99%的准确率；在(Female and Male)数据集上，以仅7,235,089个可学习参数实现了96%的准确率。

Conclusion: 该模型的高效性在多种指标下得到了验证，与现有方法相比具有明显优势，展示了其在安保和监控等实际应用场景中的巨大潜力。

Abstract: Gender classification has emerged as a crucial aspect in various fields,
including security, human-machine interaction, surveillance, and advertising.
Nonetheless, the accuracy of this classification can be influenced by factors
such as cosmetics and disguise. Consequently, our study is dedicated to
addressing this concern by concentrating on gender classification using color
images of the periocular region. The periocular region refers to the area
surrounding the eye, including the eyelids, eyebrows, and the region between
them. It contains valuable visual cues that can be used to extract key features
for gender classification. This paper introduces a sophisticated Convolutional
Neural Network (CNN) model that utilizes color image databases to evaluate the
effectiveness of the periocular region for gender classification. To validate
the model's performance, we conducted tests on two eye datasets, namely CVBL
and (Female and Male). The recommended architecture achieved an outstanding
accuracy of 99% on the previously unused CVBL dataset while attaining a
commendable accuracy of 96% with a small number of learnable parameters
(7,235,089) on the (Female and Male) dataset. To ascertain the effectiveness of
our proposed model for gender classification using the periocular region, we
evaluated its performance through an extensive range of metrics and compared it
with other state-of-the-art approaches. The results unequivocally demonstrate
the efficacy of our model, thereby suggesting its potential for practical
application in domains such as security and surveillance.

</details>


### [5] [World Consistency Score: A Unified Metric for Video Generation Quality](https://arxiv.org/abs/2508.00144)
*Akshat Rakheja,Aarsh Ashdhir,Aryan Bhattacharjee,Vanshika Sharma*

Main category: cs.CV

TL;DR: 提出了一种新的视频生成模型评估指标WCS，强调视频生成中的内部世界一致性，并整合了四个可解释的子组件，用于量化各种方面的时间和物理一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视频评估指标多集中于视觉保真度或提示对齐性，而忽略了视频内部世界一贯性分析。WCS填补了这一空白。

Method: WCS结合了四个子组件（物体持久性、关系稳定性、因果符合和闪烁惩罚），并通过学习加权公式汇总为一个一致性得分。计算中运用了开源工具并基于人类偏好数据训练权重。

Result: 通过在VBench-2.0、EvalCrafter和LOVE等基准中实验验证，展示了WCS与人类评估匹配的相关性，并在敏感性分析和与现有指标的对比下表现出优势。

Conclusion: WCS提供了一个全面且可解释的框架，用于衡量视频生成模型维持时空上连贯“世界”的能力，有效弥补了现有评估方法的不足。

Abstract: We introduce World Consistency Score (WCS), a novel unified evaluation metric
for generative video models that emphasizes internal world consistency of the
generated videos. WCS integrates four interpretable sub-components - object
permanence, relation stability, causal compliance, and flicker penalty - each
measuring a distinct aspect of temporal and physical coherence in a video.
These submetrics are combined via a learned weighted formula to produce a
single consistency score that aligns with human judgments. We detail the
motivation for WCS in the context of existing video evaluation metrics,
formalize each submetric and how it is computed with open-source tools
(trackers, action recognizers, CLIP embeddings, optical flow), and describe how
the weights of the WCS combination are trained using human preference data. We
also outline an experimental validation blueprint: using benchmarks like
VBench-2.0, EvalCrafter, and LOVE to test WCS's correlation with human
evaluations, performing sensitivity analyses, and comparing WCS against
established metrics (FVD, CLIPScore, VBench, FVMD). The proposed WCS offers a
comprehensive and interpretable framework for evaluating video generation
models on their ability to maintain a coherent "world" over time, addressing
gaps left by prior metrics focused only on visual fidelity or prompt alignment.

</details>


### [6] [GeoExplorer: Active Geo-localization with Curiosity-Driven Exploration](https://arxiv.org/abs/2508.00152)
*Li Mi,Manon Bechaz,Zeming Chen,Antoine Bosselut,Devis Tuia*

Main category: cs.CV

TL;DR: 本文提出了GeoExplorer，一种通过内在奖励实现好奇心驱动探索的主动地理定位新方法。


<details>
  <summary>Details</summary>
Motivation: 目前AGL方法依赖基于距离的奖励，但在复杂场景中鲁棒性和泛化能力较差，需要新的探索策略。

Method: GeoExplorer通过引入好奇心驱动的内在奖励，而非传统的基于距离的奖励，以实现无目标导向的多样性探索。

Result: 通过在四个AGL基准上的实验，证明GeoExplorer在多样环境中定位未知目标的能力及其优越的泛化性。

Conclusion: GeoExplorer实现了更鲁棒的环境建模及探索，为AGL任务提供了新的解决方案，尤其在未知环境中表现卓越。

Abstract: Active Geo-localization (AGL) is the task of localizing a goal, represented
in various modalities (e.g., aerial images, ground-level images, or text),
within a predefined search area. Current methods approach AGL as a
goal-reaching reinforcement learning (RL) problem with a distance-based reward.
They localize the goal by implicitly learning to minimize the relative distance
from it. However, when distance estimation becomes challenging or when
encountering unseen targets and environments, the agent exhibits reduced
robustness and generalization ability due to the less reliable exploration
strategy learned during training. In this paper, we propose GeoExplorer, an AGL
agent that incorporates curiosity-driven exploration through intrinsic rewards.
Unlike distance-based rewards, our curiosity-driven reward is goal-agnostic,
enabling robust, diverse, and contextually relevant exploration based on
effective environment modeling. These capabilities have been proven through
extensive experiments across four AGL benchmarks, demonstrating the
effectiveness and generalization ability of GeoExplorer in diverse settings,
particularly in localizing unfamiliar targets and environments.

</details>


### [7] [Robust 3D Object Detection using Probabilistic Point Clouds from Single-Photon LiDARs](https://arxiv.org/abs/2508.00169)
*Bhavya Goyal,Felipe Gutierrez-Barragan,Wei Lin,Andreas Velten,Yin Li,Mohit Gupta*

Main category: cs.CV

TL;DR: 提出了一种称为Probabilistic Point Clouds (PPC)的新方法，通过为点云中的每个点添加概率属性来捕捉测量不确定性，并改进在稀疏或错误点云下的3D场景理解任务的性能。


<details>
  <summary>Details</summary>
Motivation: 目前的LiDAR在远距离或低反射率物体等场景中生成稀疏或错误点云，导致下游感知模型准确性下降。传统3D处理流程未保留测量不确定性信息，引发对更鲁棒方法的需求。

Method: 深入分析LiDAR测量不确定性，提出PPC表示方法，将概率属性加入原始点云数据中。同时，提出利用这种增强表示的推断方法，将其作为3D推断管道中的轻量模块，提升感知鲁棒性。

Result: PPC方法在挑战性的室内外场景、弱反射物体、小型物体以及强光下的3D对象检测中，显著优于传统LiDAR和摄像头-LiDAR联合建模方法。

Conclusion: 使用PPC方法改进了现有的3D场景理解流程，可普遍适用于不同的3D推断任务。这种包含不确定性的表征方式具有显著的实用性和性能提升。

Abstract: LiDAR-based 3D sensors provide point clouds, a canonical 3D representation
used in various scene understanding tasks. Modern LiDARs face key challenges in
several real-world scenarios, such as long-distance or low-albedo objects,
producing sparse or erroneous point clouds. These errors, which are rooted in
the noisy raw LiDAR measurements, get propagated to downstream perception
models, resulting in potentially severe loss of accuracy. This is because
conventional 3D processing pipelines do not retain any uncertainty information
from the raw measurements when constructing point clouds.
  We propose Probabilistic Point Clouds (PPC), a novel 3D scene representation
where each point is augmented with a probability attribute that encapsulates
the measurement uncertainty (or confidence) in the raw data. We further
introduce inference approaches that leverage PPC for robust 3D object
detection; these methods are versatile and can be used as computationally
lightweight drop-in modules in 3D inference pipelines. We demonstrate, via both
simulations and real captures, that PPC-based 3D inference methods outperform
several baselines using LiDAR as well as camera-LiDAR fusion models, across
challenging indoor and outdoor scenarios involving small, distant, and
low-albedo objects, as well as strong ambient light.
  Our project webpage is at https://bhavyagoyal.github.io/ppc .

</details>


### [8] [On the Risk of Misleading Reports: Diagnosing Textual Biases in Multimodal Clinical AI](https://arxiv.org/abs/2508.00171)
*David Restrepo,Ira Ktena,Maria Vakalopoulou,Stergios Christodoulidis,Enzo Ferrante*

Main category: cs.CV

TL;DR: 本文提出了一种称为选择性模态转换（SMS）的方法，用于量化视觉语言模型在医疗图像与临床报告分析中的模态依赖性，并发现这些模型在多模态任务中表现出对文本输入的显著偏好。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在医疗决策任务中可能更偏重文本信息，忽视关键的视觉线索，需研究其多模态依赖性问题。

Method: 提出选择性模态转换（SMS）方法，系统性交换带有相反标签的样本中的图像或文本，并对模型性能进行评估。同时，通过注意力分析揭示模型对不同模态的依赖。

Result: 通过对六种开源视觉语言模型在两个医疗图像数据集上的实验，发现这些模型在多模态任务中仍主要依赖文本输入，尽管有可用的视觉信息。

Conclusion: 设计和评估能够真正整合视觉和文本线索的多模态医疗模型至关重要，以避免对单一模态的偏倚。

Abstract: Clinical decision-making relies on the integrated analysis of medical images
and the associated clinical reports. While Vision-Language Models (VLMs) can
offer a unified framework for such tasks, they can exhibit strong biases toward
one modality, frequently overlooking critical visual cues in favor of textual
information. In this work, we introduce Selective Modality Shifting (SMS), a
perturbation-based approach to quantify a model's reliance on each modality in
binary classification tasks. By systematically swapping images or text between
samples with opposing labels, we expose modality-specific biases. We assess six
open-source VLMs-four generalist models and two fine-tuned for medical data-on
two medical imaging datasets with distinct modalities: MIMIC-CXR (chest X-ray)
and FairVLMed (scanning laser ophthalmoscopy). By assessing model performance
and the calibration of every model in both unperturbed and perturbed settings,
we reveal a marked dependency on text input, which persists despite the
presence of complementary visual information. We also perform a qualitative
attention-based analysis which further confirms that image content is often
overshadowed by text details. Our findings highlight the importance of
designing and evaluating multimodal medical models that genuinely integrate
visual and textual cues, rather than relying on single-modality signals.

</details>


### [9] [Graph Lineages and Skeletal Graph Products](https://arxiv.org/abs/2508.00197)
*Eric Mjolsness,Cory B. Scott*

Main category: cs.CV

TL;DR: 本文定义了层次化增长的结构化图“传承”，并提出了路径构造新型图操作和类型构造器从而支持广泛应用的算法开发。


<details>
  <summary>Details</summary>
Motivation: 为了解释并推广以图为基础的建模方法，以及探索如何利用分层架构简化模型设计及优化算法开发。

Method: 提出了分层化且结构化的图传承概念，通过定义多种面向图和“层级图系谱”的代数操作和类型构造器，以及空间节省的单体操作方法，并讨论了这些操作的代数性质。

Result: 扩展了图代数理论并应用于深度神经网络和多重网格数值方法，演示了新构造器和操作在灵活高效建模中的潜力。

Conclusion: 该研究为基于分级图的代数类型理论和模型架构开发提供了创新性的方法工具，有利于解决更大规模和多级别的复杂模型问题。

Abstract: Graphs, and sequences of growing graphs, can be used to specify the
architecture of mathematical models in many fields including machine learning
and computational science. Here we define structured graph "lineages" (ordered
by level number) that grow in a hierarchical fashion, so that: (1) the number
of graph vertices and edges increases exponentially in level number; (2)
bipartite graphs connect successive levels within a graph lineage and, as in
multigrid methods, can constrain matrices relating successive levels; (3) using
prolongation maps within a graph lineage, process-derived distance measures
between graphs at successive levels can be defined; (4) a category of "graded
graphs" can be defined, and using it low-cost "skeletal" variants of standard
algebraic graph operations and type constructors (cross product, box product,
disjoint sum, and function types) can be derived for graded graphs and hence
hierarchical graph lineages; (5) these skeletal binary operators have similar
but not identical algebraic and category-theoretic properties to their standard
counterparts; (6) graph lineages and their skeletal product constructors can
approach continuum limit objects. Additional space-efficient unary operators on
graded graphs are also derived: thickening, which creates a graph lineage of
multiscale graphs, and escalation to a graph lineage of search frontiers
(useful as a generalization of adaptive grids and in defining "skeletal"
functions). The result is an algebraic type theory for graded graphs and
(hierarchical) graph lineages. The approach is expected to be well suited to
defining hierarchical model architectures - "hierarchitectures" - and local
sampling, search, or optimization algorithms on them. We demonstrate such
application to deep neural networks (including visual and feature scale spaces)
and to multigrid numerical methods.

</details>


### [10] [Learning Personalised Human Internal Cognition from External Expressive Behaviours for Real Personality Recognition](https://arxiv.org/abs/2508.00205)
*Xiangyu Kong,Hengde Zhu,Haoqin Sun,Zhihao Guo,Jiayan Gu,Xinyi Ni,Wei Zhang,Shizhe Liu,Siyang Song*

Main category: cs.CV

TL;DR: 现有自动真实个性识别方法偏向从外部观察者角度推断，这种方式容易与目标个体的真实个性偏离。本文提出了一种新的方法，通过模拟目标个体易获取的音视频行为生成个性化内部认知，从而提高识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法多从外部观察者视角推测个性，但与目标个体实际个性存在偏差，导致性能较差，寻求提升真实个性识别的精确性。

Method: 提出一种新方法，通过目标个体的音视频行为生成个性化的内部认知，并通过2D图神经网络(2D-GNN)从中推导个性特质；同时采用端到端策略联合训练认知模拟、图构建及性格识别模块。

Result: 通过新方法成功更精确地模拟目标个体的内部认知，提升真实个性识别的性能。

Conclusion: 个性化的认知模拟与2D-GNN结合有效改变了传统方法的局限性，展现了显著的性能改进。

Abstract: Automatic real personality recognition (RPR) aims to evaluate human real
personality traits from their expressive behaviours. However, most existing
solutions generally act as external observers to infer observers' personality
impressions based on target individuals' expressive behaviours, which
significantly deviate from their real personalities and consistently lead to
inferior recognition performance. Inspired by the association between real
personality and human internal cognition underlying the generation of
expressive behaviours, we propose a novel RPR approach that efficiently
simulates personalised internal cognition from easy-accessible external short
audio-visual behaviours expressed by the target individual. The simulated
personalised cognition, represented as a set of network weights that enforce
the personalised network to reproduce the individual-specific facial reactions,
is further encoded as a novel graph containing two-dimensional node and edge
feature matrices, with a novel 2D Graph Neural Network (2D-GNN) proposed for
inferring real personality traits from it. To simulate real personality-related
cognition, an end-to-end strategy is designed to jointly train our cognition
simulation, 2D graph construction, and personality recognition modules.

</details>


### [11] [SAM-PTx: Text-Guided Fine-Tuning of SAM with Parameter-Efficient, Parallel-Text Adapters](https://arxiv.org/abs/2508.00213)
*Shayan Jalilian,Abdul Bais*

Main category: cs.CV

TL;DR: 本文提出了一种名为SAM-PTx的方法，利用冻结的CLIP文本嵌入向量对SAM模型进行改进，实现了基于语义文本的分割。


<details>
  <summary>Details</summary>
Motivation: 传统的SAM主要利用空间提示（如点和框）进行分割，但语义文本提示的潜力尚未被充分探索。本研究希望通过引入语义文本提示，提升分割性能。

Method: 设计了一种轻量级的适配器Parallel-Text，将CLIP得到的文本嵌入注入到SAM的图像编码器中，同时保留大部分原始架构的冻结状态，仅修改了每个Transformer模块中的MLP并行分支。

Result: 在COD10K数据集，以及COCO和ADE20K的小数据子集上进行监督实验和消融实验表明，在输入固定文本嵌入后，相比仅利用空间提示的基线方法，分割性能有所提升。

Conclusion: 通过向SAM架构中引入语义条件，可提供一种高效、实用的适应方法，同时维持较低的计算复杂性，展示了其在COD10K数据集上结合文本提示进行分割的首例实践。

Abstract: The Segment Anything Model (SAM) has demonstrated impressive generalization
in prompt-based segmentation. Yet, the potential of semantic text prompts
remains underexplored compared to traditional spatial prompts like points and
boxes. This paper introduces SAM-PTx, a parameter-efficient approach for
adapting SAM using frozen CLIP-derived text embeddings as class-level semantic
guidance. Specifically, we propose a lightweight adapter design called
Parallel-Text that injects text embeddings into SAM's image encoder, enabling
semantics-guided segmentation while keeping most of the original architecture
frozen. Our adapter modifies only the MLP-parallel branch of each transformer
block, preserving the attention pathway for spatial reasoning. Through
supervised experiments and ablations on the COD10K dataset as well as low-data
subsets of COCO and ADE20K, we show that incorporating fixed text embeddings as
input improves segmentation performance over purely spatial prompt baselines.
To our knowledge, this is the first work to use text prompts for segmentation
on the COD10K dataset. These results suggest that integrating semantic
conditioning into SAM's architecture offers a practical and scalable path for
efficient adaptation with minimal computational complexity.

</details>


### [12] [Object-Centric Cropping for Visual Few-Shot Classification](https://arxiv.org/abs/2508.00218)
*Aymane Abdali,Bartosz Boguslawski,Lucas Drumetz,Vincent Gripon*

Main category: cs.CV

TL;DR: 文章探讨了在少样本图像分类中，引入对象在图像中局部位置的信息如何提升分类性能，并通过实验验证了使用部分或全自动化前景提取模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决少样本图像分类中，由于图像模糊性（如多对象或复杂背景）造成的性能下降问题。

Method: 通过引入对象在图像中的局部位置信息，结合Segment Anything模型（仅需指出目标对象的一个像素）或完全无监督的前景对象提取方法，提升分类性能。

Result: 实验结果表明，引入对象位置数据显著提升了少样本图像分类的性能，并在标准数据集上验证了其有效性。

Conclusion: 包括简单的目标对象像素点标注或无监督提取方法在内的辅助信息可以有效提升少样本图像分类性能，为该领域的发展提供了新的方向。

Abstract: In the domain of Few-Shot Image Classification, operating with as little as
one example per class, the presence of image ambiguities stemming from multiple
objects or complex backgrounds can significantly deteriorate performance. Our
research demonstrates that incorporating additional information about the local
positioning of an object within its image markedly enhances classification
across established benchmarks. More importantly, we show that a significant
fraction of the improvement can be achieved through the use of the Segment
Anything Model, requiring only a pixel of the object of interest to be pointed
out, or by employing fully unsupervised foreground object extraction methods.

</details>


### [13] [Guided Depth Map Super-Resolution via Multi-Scale Fusion U-shaped Mamba Network](https://arxiv.org/abs/2508.00248)
*Chenggang Guo,Hao Xu,XianMing Wan*

Main category: cs.CV

TL;DR: 该论文提出一种名为MSF-UM的模型，用于提升低分辨率深度图的空间分辨率，同时有效恢复高频细节信息。


<details>
  <summary>Details</summary>
Motivation: 传统的卷积神经网络难以处理远距离依赖，且无法充分建模深度图的全局上下文信息，而变换器的高计算复杂度和内存消耗限制了其在高分辨率深度图中的应用。

Method: 设计了多尺度融合的U形Mamba（MSF-UM）模型，通过结合残差密集通道注意块与Mamba状态空间模块，利用卷积的局部特征提取能力与状态空间模型的长距离依赖建模能力，实现多尺度跨模态融合，通过彩色图像的高频纹理信息引导深度图的超分辨率过程。

Result: 相比主流方法，MSF-UM模型显著减少了参数量，同时提升了重建精度。模型在多个公开数据集上的实验验证了其有效性，尤其在大尺度深度图超分辨率任务中表现出优秀的泛化能力。

Conclusion: MSF-UM模型通过创新性地结合多尺度融合结构和状态空间建模显著提高了深度图超分辨率的性能，兼顾精度和效率。

Abstract: Depth map super-resolution technology aims to improve the spatial resolution
of low-resolution depth maps and effectively restore high-frequency detail
information. Traditional convolutional neural network has limitations in
dealing with long-range dependencies and are unable to fully model the global
contextual information in depth maps. Although transformer can model global
dependencies, its computational complexity and memory consumption are
quadratic, which significantly limits its ability to process high-resolution
depth maps. In this paper, we propose a multi-scale fusion U-shaped Mamba
(MSF-UM) model, a novel guided depth map super-resolution framework. The core
innovation of this model is to integrate Mamba's efficient state-space modeling
capabilities into a multi-scale U-shaped fusion structure guided by a color
image. The structure combining the residual dense channel attention block and
the Mamba state space module is designed, which combines the local feature
extraction capability of the convolutional layer with the modeling advantage of
the state space model for long-distance dependencies. At the same time, the
model adopts a multi-scale cross-modal fusion strategy to make full use of the
high-frequency texture information from the color image to guide the
super-resolution process of the depth map. Compared with existing mainstream
methods, the proposed MSF-UM significantly reduces the number of model
parameters while achieving better reconstruction accuracy. Extensive
experiments on multiple publicly available datasets validate the effectiveness
of the model, especially showing excellent generalization ability in the task
of large-scale depth map super-resolution.

</details>


### [14] [PointGauss: Point Cloud-Guided Multi-Object Segmentation for Gaussian Splatting](https://arxiv.org/abs/2508.00259)
*Wentao Sun,Hanqing Xu,Quanyun Wu,Dedong Zhang,Yiping Chen,Lingfei Ma,John S. Zelek,Jonathan Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为PointGauss的新框架，在高斯Splatting表示中实现实时多物体分割，其通过点云分割驱动管道实现高效3D分割。


<details>
  <summary>Details</summary>
Motivation: 现有方法初始化耗时且多视图一致性较差，本文旨在通过直接解析高斯原语并结合点云分割，提升分割效率和多视图一致性。

Method: 提出一个基于点云的高斯原语解码器，可在1分钟内生成3D实例掩膜；并使用GPU加速的2D掩膜渲染系统以确保多视图一致性。

Result: 实验结果显示较之前的SOTA方法提升了1.89%至31.78%的多视图mIoU，同时保持了优异的计算效率。

Conclusion: PointGauss在效率与性能上有显著提升，并提出了一个新数据集DesktopObjects-360以弥补当前基准的不足，全面支持3D分割任务的评价。

Abstract: We introduce PointGauss, a novel point cloud-guided framework for real-time
multi-object segmentation in Gaussian Splatting representations. Unlike
existing methods that suffer from prolonged initialization and limited
multi-view consistency, our approach achieves efficient 3D segmentation by
directly parsing Gaussian primitives through a point cloud segmentation-driven
pipeline. The key innovation lies in two aspects: (1) a point cloud-based
Gaussian primitive decoder that generates 3D instance masks within 1 minute,
and (2) a GPU-accelerated 2D mask rendering system that ensures multi-view
consistency. Extensive experiments demonstrate significant improvements over
previous state-of-the-art methods, achieving performance gains of 1.89 to
31.78% in multi-view mIoU, while maintaining superior computational efficiency.
To address the limitations of current benchmarks (single-object focus,
inconsistent 3D evaluation, small scale, and partial coverage), we present
DesktopObjects-360, a novel comprehensive dataset for 3D segmentation in
radiance fields, featuring: (1) complex multi-object scenes, (2) globally
consistent 2D annotations, (3) large-scale training data (over 27 thousand 2D
masks), (4) full 360{\deg} coverage, and (5) 3D evaluation masks.

</details>


### [15] [Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models](https://arxiv.org/abs/2508.00260)
*Hyundong Jin,Hyung Jin Chang,Eunwoo Kim*

Main category: cs.CV

TL;DR: 该研究提出了一种新框架，通过基于指令内容的视觉信息翻译来改进视觉-语言生成模型的持续学习能力。


<details>
  <summary>Details</summary>
Motivation: 目前的方法可能因为过度调整视觉信息而忽略语言指令，尤其是在面对重复类型的文本指令时。

Method: 提出了一种基于指令上下文的视觉投影器混合模型，并引入专家推荐策略和专家剪枝，以避免干扰与优化性能。

Result: 实验表明，该方法在各种视觉-语言任务上优于现有的持续学习方法，能够生成更符合指令的响应。

Conclusion: 通过对视觉信息的翻译与指令的更好结合，该方法提高了视觉-语言模型在持续学习任务中的表现。

Abstract: Continual learning enables pre-trained generative vision-language models
(VLMs) to incorporate knowledge from new tasks without retraining data from
previous ones. Recent methods update a visual projector to translate visual
information for new tasks, connecting pre-trained vision encoders with large
language models. However, such adjustments may cause the models to prioritize
visual inputs over language instructions, particularly learning tasks with
repetitive types of textual instructions. To address the neglect of language
instructions, we propose a novel framework that grounds the translation of
visual information on instructions for language models. We introduce a mixture
of visual projectors, each serving as a specialized visual-to-language
translation expert based on the given instruction context to adapt to new
tasks. To avoid using experts for irrelevant instruction contexts, we propose
an expert recommendation strategy that reuses experts for tasks similar to
those previously learned. Additionally, we introduce expert pruning to
alleviate interference from the use of experts that cumulatively activated in
previous tasks. Extensive experiments on diverse vision-language tasks
demonstrate that our method outperforms existing continual learning approaches
by generating instruction-following responses.

</details>


### [16] [Multimodal Referring Segmentation: A Survey](https://arxiv.org/abs/2508.00265)
*Henghui Ding,Song Tang,Shuting He,Chang Liu,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 本文综述了多模态引用分割领域，包括背景介绍、通用元架构总结、代表性方法回顾、性能对比及相关应用。


<details>
  <summary>Details</summary>
Motivation: 多模态引用分割因在基于用户指令进行目标感知中的重要作用而受到研究者关注。

Method: 文章提出了一个统一的元架构，并回顾了图像、视频和3D场景中的代表性方法，还讨论了解决现实复杂性挑战的广义引用表达方法及其应用。

Result: 进行全面性能对比，提供标准基准测试的结果。

Conclusion: 多模态引用分割在应用和研究中具有重要价值，且方法因技术进步显著优化。

Abstract: Multimodal referring segmentation aims to segment target objects in visual
scenes, such as images, videos, and 3D scenes, based on referring expressions
in text or audio format. This task plays a crucial role in practical
applications requiring accurate object perception based on user instructions.
Over the past decade, it has gained significant attention in the multimodal
community, driven by advances in convolutional neural networks, transformers,
and large language models, all of which have substantially improved multimodal
perception capabilities. This paper provides a comprehensive survey of
multimodal referring segmentation. We begin by introducing this field's
background, including problem definitions and commonly used datasets. Next, we
summarize a unified meta architecture for referring segmentation and review
representative methods across three primary visual scenes, including images,
videos, and 3D scenes. We further discuss Generalized Referring Expression
(GREx) methods to address the challenges of real-world complexity, along with
related tasks and practical applications. Extensive performance comparisons on
standard benchmarks are also provided. We continually track related works at
https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation.

</details>


### [17] [Towards Robust Semantic Correspondence: A Benchmark and Insights](https://arxiv.org/abs/2508.00272)
*Wenyue Chong*

Main category: cs.CV

TL;DR: 本文关注语义匹配在复杂场景下的鲁棒性问题，提出了一个新基准数据集和方法。


<details>
  <summary>Details</summary>
Motivation: 语义匹配在计算机视觉任务中具有重要作用，但在复杂条件下的鲁棒性研究相对较少。

Method: 创建了包含14种复杂场景的基准数据集，并对主流模型在这些场景下的表现进行了广泛评估。

Result: 现有方法在复杂条件下表现显著下降，大规模视觉模型能提升鲁棒性但微调可能降低相对鲁棒性。DINO模型优于Stable Diffusion，融合方法表现最佳。通用的数据增强无效，任务特定设计很关键。

Conclusion: 复杂条件下语义匹配面临显著挑战，需发展任务特定的鲁棒性提升方法，DINO模型和融合方法值得进一步研究。

Abstract: Semantic correspondence aims to identify semantically meaningful
relationships between different images and is a fundamental challenge in
computer vision. It forms the foundation for numerous tasks such as 3D
reconstruction, object tracking, and image editing. With the progress of
large-scale vision models, semantic correspondence has achieved remarkable
performance in controlled and high-quality conditions. However, the robustness
of semantic correspondence in challenging scenarios is much less investigated.
In this work, we establish a novel benchmark for evaluating semantic
correspondence in adverse conditions. The benchmark dataset comprises 14
distinct challenging scenarios that reflect commonly encountered imaging
issues, including geometric distortion, image blurring, digital artifacts, and
environmental occlusion. Through extensive evaluations, we provide several key
insights into the robustness of semantic correspondence approaches: (1) All
existing methods suffer from noticeable performance drops under adverse
conditions; (2) Using large-scale vision models can enhance overall robustness,
but fine-tuning on these models leads to a decline in relative robustness; (3)
The DINO model outperforms the Stable Diffusion in relative robustness, and
their fusion achieves better absolute robustness; Moreover, We evaluate common
robustness enhancement strategies for semantic correspondence and find that
general data augmentations are ineffective, highlighting the need for
task-specific designs. These results are consistent across both our dataset and
real-world benchmarks.

</details>


### [18] [Privacy-Preserving Driver Drowsiness Detection with Spatial Self-Attention and Federated Learning](https://arxiv.org/abs/2508.00287)
*Tran Viet Khoa,Do Hai Son,Mohammad Abu Alsheikh,Yibeltal F Alem,Dinh Thai Hoang*

Main category: cs.CV

TL;DR: 本文提出了一种新的框架，通过集成空间自注意力机制（SSA）和长短期记忆网络（LSTM），提高司机疲劳检测性能，并在联邦学习环境中实现了89.9%的检测精度。


<details>
  <summary>Details</summary>
Motivation: 驾驶员疲劳是导致交通事故的重要原因，但准确检测疲劳尤其在数据分散和多样化的现实场景中仍然具有挑战性。

Method: 设计了一种具有空间自注意力机制和长短期记忆网络的检测框架，同时结合梯度相似性比较（GSC）方法选择最优模型，并使用自定义工具处理视频数据。

Result: 在联邦学习设置中检测准确率达到89.9%，优于现有方法，且能适应多样化的真实数据场景。

Conclusion: 该框架有效应对了数据多样性问题，对提高道路安全具有重要应用价值，特别是在早期和可靠的疲劳检测方面。

Abstract: Driver drowsiness is one of the main causes of road accidents and is
recognized as a leading contributor to traffic-related fatalities. However,
detecting drowsiness accurately remains a challenging task, especially in
real-world settings where facial data from different individuals is
decentralized and highly diverse. In this paper, we propose a novel framework
for drowsiness detection that is designed to work effectively with
heterogeneous and decentralized data. Our approach develops a new Spatial
Self-Attention (SSA) mechanism integrated with a Long Short-Term Memory (LSTM)
network to better extract key facial features and improve detection
performance. To support federated learning, we employ a Gradient Similarity
Comparison (GSC) that selects the most relevant trained models from different
operators before aggregation. This improves the accuracy and robustness of the
global model while preserving user privacy. We also develop a customized tool
that automatically processes video data by extracting frames, detecting and
cropping faces, and applying data augmentation techniques such as rotation,
flipping, brightness adjustment, and zooming. Experimental results show that
our framework achieves a detection accuracy of 89.9% in the federated learning
settings, outperforming existing methods under various deployment scenarios.
The results demonstrate the effectiveness of our approach in handling
real-world data variability and highlight its potential for deployment in
intelligent transportation systems to enhance road safety through early and
reliable drowsiness detection.

</details>


### [19] [TITAN-Guide: Taming Inference-Time AligNment for Guided Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.00289)
*Christian Simon,Masato Ishii,Akio Hayakawa,Zhi Zhong,Shusuke Takahashi,Takashi Shibuya,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: 本文提出了TITAN-Guide，一个用于文本到视频扩散模型的高效推理引导方案，克服了内存限制和粗糙估计问题，提升了模型控制性能。


<details>
  <summary>Details</summary>
Motivation: 现有条件扩散模型需要较多监督微调，而无训练的引导方法存在内存需求高或控制效果欠佳的问题，限制了扩散模型在高计算需求任务中的应用。

Method: 提出TITAN-Guide，建立了一种无需回传梯度的有效扩散潜变量优化方法，通过研究前向梯度下降探索多种方向指令优化扩散引导过程。

Result: 实验表明TITAN-Guide不仅减少了内存需求，还在多个引导基准测试中显著提升了文本到视频扩散性能。

Conclusion: TITAN-Guide模型通过高效的潜变量优化和前向梯度下降，提供了内存优化的优越控制性能，推动了文本到视频扩散技术的发展。

Abstract: In the recent development of conditional diffusion models still require heavy
supervised fine-tuning for performing control on a category of tasks.
Training-free conditioning via guidance with off-the-shelf models is a
favorable alternative to avoid further fine-tuning on the base model. However,
the existing training-free guidance frameworks either have heavy memory
requirements or offer sub-optimal control due to rough estimation. These
shortcomings limit the applicability to control diffusion models that require
intense computation, such as Text-to-Video (T2V) diffusion models. In this
work, we propose Taming Inference Time Alignment for Guided Text-to-Video
Diffusion Model, so-called TITAN-Guide, which overcomes memory space issues,
and provides more optimal control in the guidance process compared to the
counterparts. In particular, we develop an efficient method for optimizing
diffusion latents without backpropagation from a discriminative guiding model.
In particular, we study forward gradient descents for guided diffusion tasks
with various options on directional directives. In our experiments, we
demonstrate the effectiveness of our approach in efficiently managing memory
during latent optimization, while previous methods fall short. Our proposed
approach not only minimizes memory requirements but also significantly enhances
T2V performance across a range of diffusion guidance benchmarks. Code, models,
and demo are available at https://titanguide.github.io.

</details>


### [20] [AniMer+: Unified Pose and Shape Estimation Across Mammalia and Aves via Family-Aware Transformer](https://arxiv.org/abs/2508.00298)
*Jin Lyu,Liang An,Li Lin,Pujin Cheng,Yebin Liu,Xiaoying Tang*

Main category: cs.CV

TL;DR: 该论文提出AniMer+，一种致力于鸟类和哺乳动物姿态和形状重建的统一方法，通过增强的神经网络架构和生成的大规模数据集显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前多物种的姿态和形状建模因网络容量不足与缺乏多样数据集而受限，统一建模对于提升生物学研究的空间智能具有重要意义。

Method: 采用高容量且具物种感知的Vision Transformer，增加Mixture-of-Experts的设计，并构建了基于扩散模型的合成图像生成管线，生成两个大规模的3D标注数据集CtrlAni3D和CtrlAVES3D。

Result: 方法在包括跨域Animal Kingdom数据集等多项基准测试中表现优异，验证了网络架构和合成数据集对实际性能的提升效果。

Conclusion: AniMer+通过创新的模型设计和数据生成策略，实现了哺乳动物和鸟类的统一建模，为多物种的三维姿态和形状分析提供了新工具。

Abstract: In the era of foundation models, achieving a unified understanding of
different dynamic objects through a single network has the potential to empower
stronger spatial intelligence. Moreover, accurate estimation of animal pose and
shape across diverse species is essential for quantitative analysis in
biological research. However, this topic remains underexplored due to the
limited network capacity of previous methods and the scarcity of comprehensive
multi-species datasets. To address these limitations, we introduce AniMer+, an
extended version of our scalable AniMer framework. In this paper, we focus on a
unified approach for reconstructing mammals (mammalia) and birds (aves). A key
innovation of AniMer+ is its high-capacity, family-aware Vision Transformer
(ViT) incorporating a Mixture-of-Experts (MoE) design. Its architecture
partitions network layers into taxa-specific components (for mammalia and aves)
and taxa-shared components, enabling efficient learning of both distinct and
common anatomical features within a single model. To overcome the critical
shortage of 3D training data, especially for birds, we introduce a
diffusion-based conditional image generation pipeline. This pipeline produces
two large-scale synthetic datasets: CtrlAni3D for quadrupeds and CtrlAVES3D for
birds. To note, CtrlAVES3D is the first large-scale, 3D-annotated dataset for
birds, which is crucial for resolving single-view depth ambiguities. Trained on
an aggregated collection of 41.3k mammalian and 12.4k avian images (combining
real and synthetic data), our method demonstrates superior performance over
existing approaches across a wide range of benchmarks, including the
challenging out-of-domain Animal Kingdom dataset. Ablation studies confirm the
effectiveness of both our novel network architecture and the generated
synthetic datasets in enhancing real-world application performance.

</details>


### [21] [Controllable Pedestrian Video Editing for Multi-View Driving Scenarios via Motion Sequence](https://arxiv.org/abs/2508.00299)
*Danzhen Fu,Jiagao Hu,Daiguo Zhou,Fei Wang,Zepeng Wang,Wenhua Liao*

Main category: cs.CV

TL;DR: 提出了一种用于多视角驾车场景的行人视频编辑框架，以增强自动驾驶训练数据集中危险行人场景的表现力。


<details>
  <summary>Details</summary>
Motivation: 针对自动驾驶系统中的行人检测模型因训练数据集中危险行人场景代表性不足而缺乏稳健性的问题。

Method: 通过结合视频修复和人体动作控制技术，提出了一种行人视频编辑框架，包括多视角行人区域检测、画布构建、二值掩模指定和基于姿势序列控制条件的行人编辑功能。

Result: 实验表明，该框架可以实现高质量的行人编辑，具有良好的视觉真实性、时空一致性和跨视角一致性。

Conclusion: 该方法是一种稳健而多功能的多视角行人视频生成解决方案，适用于自动驾驶场景中的数据增强和场景仿真等广泛应用。

Abstract: Pedestrian detection models in autonomous driving systems often lack
robustness due to insufficient representation of dangerous pedestrian scenarios
in training datasets. To address this limitation, we present a novel framework
for controllable pedestrian video editing in multi-view driving scenarios by
integrating video inpainting and human motion control techniques. Our approach
begins by identifying pedestrian regions of interest across multiple camera
views, expanding detection bounding boxes with a fixed ratio, and resizing and
stitching these regions into a unified canvas while preserving cross-view
spatial relationships. A binary mask is then applied to designate the editable
area, within which pedestrian editing is guided by pose sequence control
conditions. This enables flexible editing functionalities, including pedestrian
insertion, replacement, and removal. Extensive experiments demonstrate that our
framework achieves high-quality pedestrian editing with strong visual realism,
spatiotemporal coherence, and cross-view consistency. These results establish
the proposed method as a robust and versatile solution for multi-view
pedestrian video generation, with broad potential for applications in data
augmentation and scenario simulation in autonomous driving.

</details>


### [22] [Exploring Fourier Prior and Event Collaboration for Low-Light Image Enhancement](https://arxiv.org/abs/2508.00308)
*Chunyan She,Fujun Han,Chengyu Fang,Shukai Duan,Lidan Wang*

Main category: cs.CV

TL;DR: 提出了一种结合事件相机和普通相机的图像增强方法，通过分阶段处理和动态对齐，实现低光照下图像的增强和结构优化。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分利用事件相机和普通相机的独特优势，其图像增强效果受限。

Method: 提出两阶段管道：第一阶段设计了基于傅里叶空间的可见性恢复网络；第二阶段引入了动态对齐的融合策略以解决两种感知模式间的时空不匹配。此外，使用空间频率插值模拟负样本并开发对比损失，增强模型区分能力。

Result: 在实验中，该方法在低光照条件下的图像增强效果优于最新的其他先进方法。

Conclusion: 通过分阶段的增强管道和动态对齐技术，进一步挖掘了事件相机和普通相机的潜能，有效提升了低光照图像的清晰度和结构信息。

Abstract: The event camera, benefiting from its high dynamic range and low latency,
provides performance gain for low-light image enhancement. Unlike frame-based
cameras, it records intensity changes with extremely high temporal resolution,
capturing sufficient structure information. Currently, existing event-based
methods feed a frame and events directly into a single model without fully
exploiting modality-specific advantages, which limits their performance.
Therefore, by analyzing the role of each sensing modality, the enhancement
pipeline is decoupled into two stages: visibility restoration and structure
refinement. In the first stage, we design a visibility restoration network with
amplitude-phase entanglement by rethinking the relationship between amplitude
and phase components in Fourier space. In the second stage, a fusion strategy
with dynamic alignment is proposed to mitigate the spatial mismatch caused by
the temporal resolution discrepancy between two sensing modalities, aiming to
refine the structure information of the image enhanced by the visibility
restoration network. In addition, we utilize spatial-frequency interpolation to
simulate negative samples with diverse illumination, noise and artifact
degradations, thereby developing a contrastive loss that encourages the model
to learn discriminative representations. Experiments demonstrate that the
proposed method outperforms state-of-the-art models.

</details>


### [23] [DocTron-Formula: Generalized Formula Recognition in Complex and Structured Scenarios](https://arxiv.org/abs/2508.00311)
*Yufeng Zhong,Zhixiong Zeng,Lei Chen,Longrong Yang,Liming Zheng,Jing Huang,Siqi Yang,Lin Ma*

Main category: cs.CV

TL;DR: 该论文提出了一种处理数学公式的OCR新方法，利用通用视觉语言模型DocTron-Formula结合新数据集CSFormula，可进行复杂科学文档的自动化解析。


<details>
  <summary>Details</summary>
Motivation: 当前OCR技术和视觉-语言模型难以应对数学内容的结构多样性、复杂性和现实的变异性。

Method: 提出DocTron-Formula，一个基于通用视觉语言模型的统一框架，并构建大规模数据集CSFormula，通过监督微调达到良好效果。

Result: 通过实验验证，DocTron-Formula不仅在准确性和鲁棒性上超越了专用模型，还能适应多种风格、科学领域和复杂结构。

Conclusion: 新方法和数据集为复杂科学文档的自动化理解树立了新范式。

Abstract: Optical Character Recognition (OCR) for mathematical formula is essential for
the intelligent analysis of scientific literature. However, both task-specific
and general vision-language models often struggle to handle the structural
diversity, complexity, and real-world variability inherent in mathematical
content. In this work, we present DocTron-Formula, a unified framework built
upon general vision-language models, thereby eliminating the need for
specialized architectures. Furthermore, we introduce CSFormula, a large-scale
and challenging dataset that encompasses multidisciplinary and structurally
complex formulas at the line, paragraph, and page levels. Through
straightforward supervised fine-tuning, our approach achieves state-of-the-art
performance across a variety of styles, scientific domains, and complex
layouts. Experimental results demonstrate that our method not only surpasses
specialized models in terms of accuracy and robustness, but also establishes a
new paradigm for the automated understanding of complex scientific documents.

</details>


### [24] [GV-VAD : Exploring Video Generation for Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2508.00312)
*Suhang Cai,Xiaohao Peng,Chong Wang,Xiaojie Cai,Jiangbo Qian*

Main category: cs.CV

TL;DR: 提出了一种GV-VAD框架，通过使用基于文本条件的视频生成模型，加强视频异常检测数据集的训练效果。


<details>
  <summary>Details</summary>
Motivation: 视频异常检测(VAD)在公共安全应用中具有重要作用，但真实异常事件的稀缺性、高不可预测性以及高标注成本使得现有数据集规模受限，影响了模型性能和泛化能力。

Method: 提出了GV-VAD框架，借助文本驱动的视频生成模型生成语义可控且物理合理的虚拟视频，以低成本扩充训练数据，同时通过一种合成样本损失缩放策略优化训练效率。

Result: 实验表明，该框架在UCF-Crime数据集上优于现有最优方法。

Conclusion: GV-VAD框架展示了合成数据在提升异常检测中的潜力，并提供了一种低成本的数据扩展方法以改善模型性能与泛化能力。

Abstract: Video anomaly detection (VAD) plays a critical role in public safety
applications such as intelligent surveillance. However, the rarity,
unpredictability, and high annotation cost of real-world anomalies make it
difficult to scale VAD datasets, which limits the performance and
generalization ability of existing models. To address this challenge, we
propose a generative video-enhanced weakly-supervised video anomaly detection
(GV-VAD) framework that leverages text-conditioned video generation models to
produce semantically controllable and physically plausible synthetic videos.
These virtual videos are used to augment training data at low cost. In
addition, a synthetic sample loss scaling strategy is utilized to control the
influence of generated synthetic samples for efficient training. The
experiments show that the proposed framework outperforms state-of-the-art
methods on UCF-Crime datasets. The code is available at
https://github.com/Sumutan/GV-VAD.git.

</details>


### [25] [Steering Guidance for Personalized Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.00319)
*Sunghyun Park,Seokeon Choi,Hyoungwoo Park,Sungrack Yun*

Main category: cs.CV

TL;DR: 该论文提出了一种新的方法来个性化文-图扩散模型，以在文本对齐和目标分布保真度之间找到平衡。


<details>
  <summary>Details</summary>
Motivation: 解决少样本调整中源模型知识和目标概念精度之间的权衡问题，克服现有方法（如无分类器指导和自动指导）的不足。

Method: 提出了一种称为个性化指导的新方法，利用未训练的弱模型，并通过推理过程中在预训练和微调模型间动态调整权重，实现输出平衡。

Result: 实验表明，该方法可以提高文本对齐和目标分布保真度，同时可无缝集成到各种微调策略中。

Conclusion: 个性化指导方法有效解决了现有方法的局限性，在平衡文本编辑能力和目标分布对齐上表现出色。

Abstract: Personalizing text-to-image diffusion models is crucial for adapting the
pre-trained models to specific target concepts, enabling diverse image
generation. However, fine-tuning with few images introduces an inherent
trade-off between aligning with the target distribution (e.g., subject
fidelity) and preserving the broad knowledge of the original model (e.g., text
editability). Existing sampling guidance methods, such as classifier-free
guidance (CFG) and autoguidance (AG), fail to effectively guide the output
toward well-balanced space: CFG restricts the adaptation to the target
distribution, while AG compromises text alignment. To address these
limitations, we propose personalization guidance, a simple yet effective method
leveraging an unlearned weak model conditioned on a null text prompt. Moreover,
our method dynamically controls the extent of unlearning in a weak model
through weight interpolation between pre-trained and fine-tuned models during
inference. Unlike existing guidance methods, which depend solely on guidance
scales, our method explicitly steers the outputs toward a balanced latent space
without additional computational overhead. Experimental results demonstrate
that our proposed guidance can improve text alignment and target distribution
fidelity, integrating seamlessly with various fine-tuning strategies.

</details>


### [26] [Spectral Sensitivity Estimation with an Uncalibrated Diffraction Grating](https://arxiv.org/abs/2508.00330)
*Lilika Makabe,Hiroaki Santo,Fumio Okura,Michael S. Brown,Yasuyuki Matsushita*

Main category: cs.CV

TL;DR: 提出了一种实用且准确的通过衍射光栅进行相机光谱灵敏度校准的方法，无需专门的窄带滤光器或已知光谱反射率的参考目标。


<details>
  <summary>Details</summary>
Motivation: 当前相机光谱灵敏度的准确校准对许多计算机视觉任务至关重要，现有方法通常需要昂贵的过滤器或参考目标，这激发了寻找更经济和实用方法的需求。

Method: 通过使用一个未校准的衍射光栅片捕获直接光照与衍射图样图像，以闭合形式同时估计相机光谱灵敏度和衍射光栅参数。

Result: 实验表明，该方法在合成数据和实际数据中均优于基于传统参考目标的方法，证明了其有效性和实用性。

Conclusion: 此方法提供了一种无需专业设备即可精确校准相机光谱灵敏度的解决方案，兼具高效性和可操作性。

Abstract: This paper introduces a practical and accurate calibration method for camera
spectral sensitivity using a diffraction grating. Accurate calibration of
camera spectral sensitivity is crucial for various computer vision tasks,
including color correction, illumination estimation, and material analysis.
Unlike existing approaches that require specialized narrow-band filters or
reference targets with known spectral reflectances, our method only requires an
uncalibrated diffraction grating sheet, readily available off-the-shelf. By
capturing images of the direct illumination and its diffracted pattern through
the grating sheet, our method estimates both the camera spectral sensitivity
and the diffraction grating parameters in a closed-form manner. Experiments on
synthetic and real-world data demonstrate that our method outperforms
conventional reference target-based methods, underscoring its effectiveness and
practicality.

</details>


### [27] [Analyze-Prompt-Reason: A Collaborative Agent-Based Framework for Multi-Image Vision-Language Reasoning](https://arxiv.org/abs/2508.00356)
*Angelos Vlachos,Giorgos Filandrianos,Maria Lymperaiou,Nikolaos Spanos,Ilias Mitsouras,Vasileios Karampinis,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 提出了一种多图像推理的协作式基于代理人框架，包括生成任务特定提示的PromptEngineer和负责推理的VisionReasoner。


<details>
  <summary>Details</summary>
Motivation: 解决了在不同数据集和任务类型中进行多模态推理的难题。

Method: 使用双代理框架：PromptEngineer生成上下文感知的提示，VisionReasoner进行推理。全程自动化、模块化且无需训练。

Result: 在2025 MIRAGE挑战赛中的18个数据集上表现优异，特别是在TQA、DocVQA和MMCoQA任务中取得了高度性能。

Conclusion: LVLM在有用提示的引导下能够有效地进行多图像推理，并探讨了模型选择等设计对性能的影响。

Abstract: We present a Collaborative Agent-Based Framework for Multi-Image Reasoning.
Our approach tackles the challenge of interleaved multimodal reasoning across
diverse datasets and task formats by employing a dual-agent system: a
language-based PromptEngineer, which generates context-aware, task-specific
prompts, and a VisionReasoner, a large vision-language model (LVLM) responsible
for final inference. The framework is fully automated, modular, and
training-free, enabling generalization across classification, question
answering, and free-form generation tasks involving one or multiple input
images. We evaluate our method on 18 diverse datasets from the 2025 MIRAGE
Challenge (Track A), covering a broad spectrum of visual reasoning tasks
including document QA, visual comparison, dialogue-based understanding, and
scene-level inference. Our results demonstrate that LVLMs can effectively
reason over multiple images when guided by informative prompts. Notably, Claude
3.7 achieves near-ceiling performance on challenging tasks such as TQA (99.13%
accuracy), DocVQA (96.87%), and MMCoQA (75.28 ROUGE-L). We also explore how
design choices-such as model selection, shot count, and input length-influence
the reasoning performance of different LVLMs.

</details>


### [28] [Stable at Any Speed: Speed-Driven Multi-Object Tracking with Learnable Kalman Filtering](https://arxiv.org/abs/2508.00358)
*Yan Gong,Mengjun Chen,Hao Liu,Gao Yongsheng,Lei Yang,Naibang Wang,Ziying Song,Haoqun Ma*

Main category: cs.CV

TL;DR: 本文提出了一种名为SG-LKF（Speed-Guided Learnable Kalman Filter）的方法，其动态适应自车速度变化来改进动态场景中的跟踪稳定性与精度。


<details>
  <summary>Details</summary>
Motivation: 研究表明传统基于检测的跟踪方法在高速动态场景中因忽视自车速度引起的观测噪声和参考坐标变化而导致跟踪稳定性和精确性下降。

Method: 作者提出了SG-LKF，并设计了一个名为MotionScaleNet (MSNet) 的MLP网络预测关键参数，同时使用自监督的轨迹一致性损失函数优化框架内的关联与轨迹连续性。

Result: SG-LKF 在KITTI 2D MOT上以79.59%的HOTA排名第一；在KITTI 3D MOT上获取82.03%的HOTA；并在nuScenes 3D MOT上比SimpleTrack提高了2.2%的AMOTA。

Conclusion: SG-LKF较传统方法具有显著改进，可有效增强动态复杂场景下多目标跟踪的稳定性与精度。

Abstract: Multi-object tracking (MOT) enables autonomous vehicles to continuously
perceive dynamic objects, supplying essential temporal cues for prediction,
behavior understanding, and safe planning. However, conventional
tracking-by-detection methods typically rely on static coordinate
transformations based on ego-vehicle poses, disregarding ego-vehicle
speed-induced variations in observation noise and reference frame changes,
which degrades tracking stability and accuracy in dynamic, high-speed
scenarios. In this paper, we investigate the critical role of ego-vehicle speed
in MOT and propose a Speed-Guided Learnable Kalman Filter (SG-LKF) that
dynamically adapts uncertainty modeling to ego-vehicle speed, significantly
improving stability and accuracy in highly dynamic scenarios. Central to SG-LKF
is MotionScaleNet (MSNet), a decoupled token-mixing and channel-mixing MLP that
adaptively predicts key parameters of SG-LKF. To enhance inter-frame
association and trajectory continuity, we introduce a self-supervised
trajectory consistency loss jointly optimized with semantic and positional
constraints. Extensive experiments show that SG-LKF ranks first among all
vision-based methods on KITTI 2D MOT with 79.59% HOTA, delivers strong results
on KITTI 3D MOT with 82.03% HOTA, and outperforms SimpleTrack by 2.2% AMOTA on
nuScenes 3D MOT.

</details>


### [29] [CoST: Efficient Collaborative Perception From Unified Spatiotemporal Perspective](https://arxiv.org/abs/2508.00359)
*Zongheng Tang,Yi Liu,Yifan Sun,Yulu Gao,Jinyu Chen,Runsheng Xu,Si Liu*

Main category: cs.CV

TL;DR: 文章提出一种协同感知方法CoST，通过在统一时空空间中整合多代理和多时刻的信息，以同时实现高效特征传输和优越的特征融合。


<details>
  <summary>Details</summary>
Motivation: 解决单个代理感知范围限制以及观测遮挡问题，并改进现有方法的多代理与多时融合的分离局限。

Method: 通过在一个统一的时空空间内聚合多代理和不同时间的观测，减少冗余传输，以提升效率，并优化特征融合效果以增强感知性能。

Result: 该方法在效率和感知精度上均有显著改善，并能兼容大多数现有方法，进一步提升其灵活性和性能。

Conclusion: CoST不仅提升效率和精度，还帮助现有方法优化，且具有较强的通用性和适应性。

Abstract: Collaborative perception shares information among different agents and helps
solving problems that individual agents may face, e.g., occlusions and small
sensing range. Prior methods usually separate the multi-agent fusion and
multi-time fusion into two consecutive steps. In contrast, this paper proposes
an efficient collaborative perception that aggregates the observations from
different agents (space) and different times into a unified spatio-temporal
space simultanesouly. The unified spatio-temporal space brings two benefits,
i.e., efficient feature transmission and superior feature fusion. 1) Efficient
feature transmission: each static object yields a single observation in the
spatial temporal space, and thus only requires transmission only once (whereas
prior methods re-transmit all the object features multiple times). 2) superior
feature fusion: merging the multi-agent and multi-time fusion into a unified
spatial-temporal aggregation enables a more holistic perspective, thereby
enhancing perception performance in challenging scenarios. Consequently, our
Collaborative perception with Spatio-temporal Transformer (CoST) gains
improvement in both efficiency and accuracy. Notably, CoST is not tied to any
specific method and is compatible with a majority of previous methods,
enhancing their accuracy while reducing the transmission bandwidth.

</details>


### [30] [Honey Classification using Hyperspectral Imaging and Machine Learning](https://arxiv.org/abs/2508.00361)
*Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh*

Main category: cs.CV

TL;DR: 本文提出了一种基于机器学习的方法，用于自动分类蜂蜜的植物来源，通过数据集准备、特征提取和分类三个阶段实现这一目标。


<details>
  <summary>Details</summary>
Motivation: 开发一种自动化方法，以更高精度识别蜂蜜的植物来源，解决现有技术中分类准确性不足的问题。

Method: 方法包括三个阶段：1. 数据集准备阶段使用类转换方法增强类间可分性；2. 特征提取阶段采用线性判别分析(LDA)提取相关特征并降维；3. 使用支持向量机(SVM)和K近邻(KNN)模型对提取的特征进行分类。

Result: 在标准蜂蜜高光谱成像数据集上，方法实现了95.13%的分类准确率(基于高光谱图像)和92.80%的分类准确率(基于高光谱实例)。

Conclusion: 实验结果表明，所提出的系统在该数据集上实现了当前最好的分类性能，表明其有效性及潜在应用价值。

Abstract: In this paper, we propose a machine learning-based method for automatically
classifying honey botanical origins. Dataset preparation, feature extraction,
and classification are the three main steps of the proposed method. We use a
class transformation method in the dataset preparation phase to maximize the
separability across classes. The feature extraction phase employs the Linear
Discriminant Analysis (LDA) technique for extracting relevant features and
reducing the number of dimensions. In the classification phase, we use Support
Vector Machines (SVM) and K-Nearest Neighbors (KNN) models to classify the
extracted features of honey samples into their botanical origins. We evaluate
our system using a standard honey hyperspectral imaging (HSI) dataset.
Experimental findings demonstrate that the proposed system produces
state-of-the-art results on this dataset, achieving the highest classification
accuracy of 95.13% for hyperspectral image-based classification and 92.80% for
hyperspectral instance-based classification.

</details>


### [31] [SparseRecon: Neural Implicit Surface Reconstruction from Sparse Views with Feature and Depth Consistencies](https://arxiv.org/abs/2508.00366)
*Liang Han,Xu Zhang,Haichuan Song,Kanle Shi,Yu-Shen Liu,Zhizhong Han*

Main category: cs.CV

TL;DR: 本文提出SparseRecon，一种针对于稀疏视图的神经隐式重建方法，利用基于体渲染的特征一致性和不确定性引导的深度约束，实现了更高质量的3D形状或场景重建。


<details>
  <summary>Details</summary>
Motivation: 目前基于泛化的方法对未见过的视图泛化能力有限，而基于过拟合的方法在几何线索有限的情况下重建质量仍受限制，需提出方法改善重建质量。

Method: SparseRecon引入了视图间的特征一致性损失以约束神经隐式场，从而缓解视图信息不足带来的模糊性，并通过不确定性引导的深度约束改进了能在遮挡或特征不显著区域内的重建几何细节。

Result: 实验结果表明，与最先进方法相比，SparseRecon在稀疏视图输入特别是小重叠视图场景下能生成高质量几何。

Conclusion: SparseRecon通过结合特征一致性和深度约束，有效提升了稀疏视图情况下的3D重建质量，尤其在视图重叠程度较低的场景中表现优越。

Abstract: Surface reconstruction from sparse views aims to reconstruct a 3D shape or
scene from few RGB images. The latest methods are either generalization-based
or overfitting-based. However, the generalization-based methods do not
generalize well on views that were unseen during training, while the
reconstruction quality of overfitting-based methods is still limited by the
limited geometry clues. To address this issue, we propose SparseRecon, a novel
neural implicit reconstruction method for sparse views with volume
rendering-based feature consistency and uncertainty-guided depth constraint.
Firstly, we introduce a feature consistency loss across views to constrain the
neural implicit field. This design alleviates the ambiguity caused by
insufficient consistency information of views and ensures completeness and
smoothness in the reconstruction results. Secondly, we employ an
uncertainty-guided depth constraint to back up the feature consistency loss in
areas with occlusion and insignificant features, which recovers geometry
details for better reconstruction quality. Experimental results demonstrate
that our method outperforms the state-of-the-art methods, which can produce
high-quality geometry with sparse-view input, especially in the scenarios with
small overlapping views. Project page: https://hanl2010.github.io/SparseRecon/.

</details>


### [32] [Representation Shift: Unifying Token Compression with FlashAttention](https://arxiv.org/abs/2508.00367)
*Joonmyung Choi,Sanghyeok Lee,Byungoh Ko,Eunseo Kim,Jihyung Kil,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 提出Representation Shift度量，用于无训练的token压缩，与FlashAttention兼容，显著提高效率。


<details>
  <summary>Details</summary>
Motivation: 随着任务复杂性增加，模型参数和token数量的增加导致计算和内存的开销过高，需要低成本、高效率的解决方案。

Method: 提出了一种名为Representation Shift的无训练、模型无关的度量方法，通过衡量每个token的表示变化程度，实现与FlashAttention兼容的token压缩。

Result: 在视频文本检索和问答任务中，分别实现了高达5.5%和4.4%的速度提升。

Conclusion: Representation Shift方法能够在不需要注意力图或重新训练的情况下实现有效的token压缩，并且推广到CNN和状态空间模型，对提高模型效率具有重要意义。

Abstract: Transformers have demonstrated remarkable success across vision, language,
and video. Yet, increasing task complexity has led to larger models and more
tokens, raising the quadratic cost of self-attention and the overhead of GPU
memory access. To reduce the computation cost of self-attention, prior work has
proposed token compression techniques that drop redundant or less informative
tokens. Meanwhile, fused attention kernels such as FlashAttention have been
developed to alleviate memory overhead by avoiding attention map construction
and its associated I/O to HBM. This, however, makes it incompatible with most
training-free token compression methods, which rely on attention maps to
determine token importance. Here, we propose Representation Shift, a
training-free, model-agnostic metric that measures the degree of change in each
token's representation. This seamlessly integrates token compression with
FlashAttention, without attention maps or retraining. Our method further
generalizes beyond Transformers to CNNs and state space models. Extensive
experiments show that Representation Shift enables effective token compression
compatible with FlashAttention, yielding significant speedups of up to 5.5% and
4.4% in video-text retrieval and video QA, respectively. Code is available at
https://github.com/mlvlab/Representation-Shift.

</details>


### [33] [Bidirectional Action Sequence Learning for Long-term Action Anticipation with Large Language Models](https://arxiv.org/abs/2508.00374)
*Yuji Sato,Yasunori Ishii,Takayoshi Yamashita*

Main category: cs.CV

TL;DR: BiAnt方法结合前向预测和后向预测以提升视频中长期动作预测的性能，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法由于受限于单向性，难以捕捉场景中语义上独特的子动作，性能受限。

Method: 提出BiAnt方法，结合了前向预测和基于大型语言模型的后向预测。

Result: 在Ego4D数据集上实验结果显示，BiAnt在编辑距离上优于基线方法。

Conclusion: BiAnt以其改进的预测方式成功提升了长期动作预测的性能。

Abstract: Video-based long-term action anticipation is crucial for early risk detection
in areas such as automated driving and robotics. Conventional approaches
extract features from past actions using encoders and predict future events
with decoders, which limits performance due to their unidirectional nature.
These methods struggle to capture semantically distinct sub-actions within a
scene. The proposed method, BiAnt, addresses this limitation by combining
forward prediction with backward prediction using a large language model.
Experimental results on Ego4D demonstrate that BiAnt improves performance in
terms of edit distance compared to baseline methods.

</details>


### [34] [Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis](https://arxiv.org/abs/2508.00381)
*Kamal Basha S,Athira Nambiar*

Main category: cs.CV

TL;DR: 提出了一种名为“Adapt-WeldNet”的自适应焊接缺陷检测框架，并引入了一种新颖的缺陷检测可解释性分析（DDIA）方法，以提升焊接缺陷检测的性能及可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以检测微小或内部缺陷，且基于神经网络的检测缺乏可解释性，存在安全风险。

Method: 系统性评估不同的预训练架构和传递学习策略，引入可解释性技术（如Grad-CAM和LIME），并结合专家验证的领域特定评估方法，同时采用人机协同设计。

Result: 优化了缺陷检测模型的性能，提升了系统的透明性和可信度，并确保公平性和可靠性。

Conclusion: 通过改进性能和可解释性，提升了海洋和离岸环境中焊接缺陷检测系统的安全性与可靠性，支持关键操作。

Abstract: Weld defect detection is crucial for ensuring the safety and reliability of
piping systems in the oil and gas industry, especially in challenging marine
and offshore environments. Traditional non-destructive testing (NDT) methods
often fail to detect subtle or internal defects, leading to potential failures
and costly downtime. Furthermore, existing neural network-based approaches for
defect classification frequently rely on arbitrarily selected pretrained
architectures and lack interpretability, raising safety concerns for
deployment. To address these challenges, this paper introduces
``Adapt-WeldNet", an adaptive framework for welding defect detection that
systematically evaluates various pre-trained architectures, transfer learning
strategies, and adaptive optimizers to identify the best-performing model and
hyperparameters, optimizing defect detection and providing actionable insights.
Additionally, a novel Defect Detection Interpretability Analysis (DDIA)
framework is proposed to enhance system transparency. DDIA employs Explainable
AI (XAI) techniques, such as Grad-CAM and LIME, alongside domain-specific
evaluations validated by certified ASNT NDE Level II professionals.
Incorporating a Human-in-the-Loop (HITL) approach and aligning with the
principles of Trustworthy AI, DDIA ensures the reliability, fairness, and
accountability of the defect detection system, fostering confidence in
automated decisions through expert validation. By improving both performance
and interpretability, this work enhances trust, safety, and reliability in
welding defect detection systems, supporting critical operations in offshore
and marine environments.

</details>


### [35] [$MV_{Hybrid}$: Improving Spatial Transcriptomics Prediction with Hybrid State Space-Vision Transformer Backbone in Pathology Vision Foundation Models](https://arxiv.org/abs/2508.00383)
*Won June Cho,Hongjun Yoon,Daeky Jeong,Hyeongyeol Lim,Yosep Chong*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新型的病理学视觉基础模型（VFM）架构——$MV_{Hybrid}$，旨在通过克服现有方法的精度和鲁棒性限制，更好地预测基因表达。


<details>
  <summary>Details</summary>
Motivation: 传统的空间转录组学在基因表达领域有重要应用，但存在成本高和技术复杂的问题。通过从常规病理图像中预测空间基因表达模式是一种更实用的替代方案，但现有基于Vision Transformer（ViT）的模型并不能达到临床标准。

Method: 论文提出了一种新型的混合架构$MV_{Hybrid}$，结合了状态空间模型（SSM）与ViT，并通过负实特征值初始化SSM以增强低频模式捕捉能力。对多个骨干架构进行了比较测试，所有模型均在相同数据集上进行了自监督预训练。

Result: 在基因表达预测任务中，$MV_{Hybrid}$在LOSO评估中比最佳ViT模型的相关性高出57%，且鲁棒性提升表现出43%更小的性能衰减。此外，在分类、片段检索和生存预测等任务中它表现出等同或更优的性能。

Conclusion: $MV_{Hybrid}$展示出作为下一代病理学视觉基础模型的潜力，其方法在整体精度和多任务性能中取得显著优势。

Abstract: Spatial transcriptomics reveals gene expression patterns within tissue
context, enabling precision oncology applications such as treatment response
prediction, but its high cost and technical complexity limit clinical adoption.
Predicting spatial gene expression (biomarkers) from routine histopathology
images offers a practical alternative, yet current vision foundation models
(VFMs) in pathology based on Vision Transformer (ViT) backbones perform below
clinical standards. Given that VFMs are already trained on millions of diverse
whole slide images, we hypothesize that architectural innovations beyond ViTs
may better capture the low-frequency, subtle morphological patterns correlating
with molecular phenotypes. By demonstrating that state space models initialized
with negative real eigenvalues exhibit strong low-frequency bias, we introduce
$MV_{Hybrid}$, a hybrid backbone architecture combining state space models
(SSMs) with ViT. We compare five other different backbone architectures for
pathology VFMs, all pretrained on identical colorectal cancer datasets using
the DINOv2 self-supervised learning method. We evaluate all pretrained models
using both random split and leave-one-study-out (LOSO) settings of the same
biomarker dataset. In LOSO evaluation, $MV_{Hybrid}$ achieves 57% higher
correlation than the best-performing ViT and shows 43% smaller performance
degradation compared to random split in gene expression prediction,
demonstrating superior performance and robustness, respectively. Furthermore,
$MV_{Hybrid}$ shows equal or better downstream performance in classification,
patch retrieval, and survival prediction tasks compared to that of ViT, showing
its promise as a next-generation pathology VFM backbone. Our code is publicly
available at: https://github.com/deepnoid-ai/MVHybrid.

</details>


### [36] [Cued-Agent: A Collaborative Multi-Agent System for Automatic Cued Speech Recognition](https://arxiv.org/abs/2508.00391)
*Guanjie Huang,Danny H. K. Tsang,Shan Yang,Guangzhi Lei,Li Liu*

Main category: cs.CV

TL;DR: 该文章提出了一种名为Cued-Agent的多智能体系统，用于解决语音提示识别（CS）问题，并在普通和听力障碍场景下实现了卓越表现。


<details>
  <summary>Details</summary>
Motivation: 解决手部和唇部动作的时间步不同步性，同时克服数据有限性如何限制多模态融合技术训练的问题。

Method: 设计了一个由四个子代理组成的协作多智能体系统，包括基于大语言模型的手部识别代理、基于预训练Transformer的唇部识别代理、动态手部提示解析代理以及自我校正语音到文本代理。

Result: 通过扩展现有的普通话CS数据集，开展了大量实验，结果表明Cued-Agent在正常及听力障碍场景中优于当前最先进的方法。

Conclusion: Cued-Agent为听力障碍人员提供了高效的语音提示识别解决方案，同时展示了多智能体系统在复杂任务中的潜力。

Abstract: Cued Speech (CS) is a visual communication system that combines lip-reading
with hand coding to facilitate communication for individuals with hearing
impairments. Automatic CS Recognition (ACSR) aims to convert CS hand gestures
and lip movements into text via AI-driven methods. Traditionally, the temporal
asynchrony between hand and lip movements requires the design of complex
modules to facilitate effective multimodal fusion. However, constrained by
limited data availability, current methods demonstrate insufficient capacity
for adequately training these fusion mechanisms, resulting in suboptimal
performance. Recently, multi-agent systems have shown promising capabilities in
handling complex tasks with limited data availability. To this end, we propose
the first collaborative multi-agent system for ACSR, named Cued-Agent. It
integrates four specialized sub-agents: a Multimodal Large Language Model-based
Hand Recognition agent that employs keyframe screening and CS expert prompt
strategies to decode hand movements, a pretrained Transformer-based Lip
Recognition agent that extracts lip features from the input video, a Hand
Prompt Decoding agent that dynamically integrates hand prompts with lip
features during inference in a training-free manner, and a Self-Correction
Phoneme-to-Word agent that enables post-process and end-to-end conversion from
phoneme sequences to natural language sentences for the first time through
semantic refinement. To support this study, we expand the existing Mandarin CS
dataset by collecting data from eight hearing-impaired cuers, establishing a
mixed dataset of fourteen subjects. Extensive experiments demonstrate that our
Cued-Agent performs superbly in both normal and hearing-impaired scenarios
compared with state-of-the-art methods. The implementation is available at
https://github.com/DennisHgj/Cued-Agent.

</details>


### [37] [Decouple before Align: Visual Disentanglement Enhances Prompt Tuning](https://arxiv.org/abs/2508.00395)
*Fei Zhang,Tianfei Zhou,Jiangchao Yao,Ya Zhang,Ivor W. Tsang,Yanfeng Wang*

Main category: cs.CV

TL;DR: 提出了DAPT，一个基于解耦与对齐的新型Prompt Tuning框架，通过分离视觉前景和背景，并进行对称对齐，有效解决了视觉-语言模型中的信息不对称问题。


<details>
  <summary>Details</summary>
Motivation: 探讨视觉与语言模态信息不对称对模型性能的影响，并寻求解决方案以提高任务迁移能力。

Method: 通过将视觉模态划分为前景和背景后，与文本模态中的前景文本及人工设定的背景类进行对称对齐，设计视觉拉推正则化以实现区域聚焦。

Result: 在few-shot学习、基础到新颖泛化和数据高效学习中，实现了优越的性能表现。

Conclusion: DAPT在不改变模型架构下，通过增强视觉模态对齐和视觉关注，显著改善任务迁移能力，且代码已开源。

Abstract: Prompt tuning (PT), as an emerging resource-efficient fine-tuning paradigm,
has showcased remarkable effectiveness in improving the task-specific
transferability of vision-language models. This paper delves into a previously
overlooked information asymmetry issue in PT, where the visual modality mostly
conveys more context than the object-oriented textual modality.
Correspondingly, coarsely aligning these two modalities could result in the
biased attention, driving the model to merely focus on the context area. To
address this, we propose DAPT, an effective PT framework based on an intuitive
decouple-before-align concept. First, we propose to explicitly decouple the
visual modality into the foreground and background representation via
exploiting coarse-and-fine visual segmenting cues, and then both of these
decoupled patterns are aligned with the original foreground texts and the
hand-crafted background classes, thereby symmetrically strengthening the modal
alignment. To further enhance the visual concentration, we propose a visual
pull-push regularization tailored for the foreground-background patterns,
directing the original visual representation towards unbiased attention on the
region-of-interest object. We demonstrate the power of architecture-free DAPT
through few-shot learning, base-to-novel generalization, and data-efficient
learning, all of which yield superior performance across prevailing benchmarks.
Our code will be released at https://github.com/Ferenas/DAPT.

</details>


### [38] [Video Forgery Detection with Optical Flow Residuals and Spatial-Temporal Consistency](https://arxiv.org/abs/2508.00397)
*Xi Xue,Kunio Suzuki,Nabarun Goswami,Takuya Shintate*

Main category: cs.CV

TL;DR: 提出一种结合RGB外观特征和光流残差的新框架，用于检测视频伪造，特别是AI生成视频中的细微异常。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉细微的时间不一致性方面存在不足，难以应对高视觉保真度和运动连贯性的AI生成视频。

Method: 采用双分支架构：一支分析RGB帧检测外观伪影，另一支分析光流残差揭示时间合成导致的运动异常，并整合两种特征进行检测。

Result: 方法在10个不同生成模型的文本到视频与图像到视频任务上进行了广泛实验，表现出强的鲁棒性与泛化能力。

Conclusion: 利用空间-时间一致性，该框架能有效检测各类伪造视频，非常适合高视觉质量的AI生成内容的伪造检测。

Abstract: The rapid advancement of diffusion-based video generation models has led to
increasingly realistic synthetic content, presenting new challenges for video
forgery detection. Existing methods often struggle to capture fine-grained
temporal inconsistencies, particularly in AI-generated videos with high visual
fidelity and coherent motion. In this work, we propose a detection framework
that leverages spatial-temporal consistency by combining RGB appearance
features with optical flow residuals. The model adopts a dual-branch
architecture, where one branch analyzes RGB frames to detect appearance-level
artifacts, while the other processes flow residuals to reveal subtle motion
anomalies caused by imperfect temporal synthesis. By integrating these
complementary features, the proposed method effectively detects a wide range of
forged videos. Extensive experiments on text-to-video and image-to-video tasks
across ten diverse generative models demonstrate the robustness and strong
generalization ability of the proposed approach.

</details>


### [39] [iSafetyBench: A video-language benchmark for safety in industrial environment](https://arxiv.org/abs/2508.00399)
*Raiyaan Abdullah,Yogesh Singh Rawat,Shruti Vyas*

Main category: cs.CV

TL;DR: 本文提出了一个名为iSafetyBench的新基准，用于评估视觉语言模型在工业环境中对常规和危险情景的表现。尽管现有模型在视频基准中表现良好，但在iSafetyBench上表现不佳，特别是对于危险活动识别和多标签任务。


<details>
  <summary>Details</summary>
Motivation: 目前的视觉语言模型在零样本设置下有了很大的进展，但其在工业领域的高风险应用场景中是否有效，尚未被充分探索。研究旨在填补这一空白。

Method: 创建了iSafetyBench数据集，包括来自工业环境的1100个视频片段，视频中标注了开放词汇、多标签动作信息，同时设计了单标签和多标签的选择题评估机制。

Result: 对8个最先进的视觉语言模型在零样本条件下进行评估，发现模型在iSafetyBench中表现显著不足，尤其是在识别危险活动和处理多标签情况下。

Conclusion: 当前的视觉语言模型在应对工业领域复杂场景时仍存在重大不足，iSafetyBench为开发更安全、更健壮的多模态模型提供了基准测试和发展的平台。

Abstract: Recent advances in vision-language models (VLMs) have enabled impressive
generalization across diverse video understanding tasks under zero-shot
settings. However, their capabilities in high-stakes industrial domains-where
recognizing both routine operations and safety-critical anomalies is
essential-remain largely underexplored. To address this gap, we introduce
iSafetyBench, a new video-language benchmark specifically designed to evaluate
model performance in industrial environments across both normal and hazardous
scenarios. iSafetyBench comprises 1,100 video clips sourced from real-world
industrial settings, annotated with open-vocabulary, multi-label action tags
spanning 98 routine and 67 hazardous action categories. Each clip is paired
with multiple-choice questions for both single-label and multi-label
evaluation, enabling fine-grained assessment of VLMs in both standard and
safety-critical contexts. We evaluate eight state-of-the-art video-language
models under zero-shot conditions. Despite their strong performance on existing
video benchmarks, these models struggle with iSafetyBench-particularly in
recognizing hazardous activities and in multi-label scenarios. Our results
reveal significant performance gaps, underscoring the need for more robust,
safety-aware multimodal models for industrial applications. iSafetyBench
provides a first-of-its-kind testbed to drive progress in this direction. The
dataset is available at: https://github.com/raiyaan-abdullah/iSafety-Bench.

</details>


### [40] [Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents](https://arxiv.org/abs/2508.00400)
*Janika Deborah Gajo,Gerarld Paul Merales,Jerome Escarcha,Brenden Ashley Molina,Gian Nartea,Emmanuel G. Maminta,Juan Carlos Roldan,Rowel O. Atienza*

Main category: cs.CV

TL;DR: Sari Sandbox是一种高保真、真实感3D零售店模拟环境，用于比较购物任务中具体化代理和人类的表现。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏针对零售环境的具体化代理训练仿真环境。

Method: 开发了一种3D零售店仿真环境，支持API控制，并结合虚拟现实和视-语言模型来实施具体化代理训练。

Result: 生成了一个包含人类演示数据集SariBench并提供了基准测试工具。

Conclusion: 该工具可用于衡量具体化代理与人类的表现差距，并提出了提升仿真环境真实感和可扩展性的建议。

Abstract: We present Sari Sandbox, a high-fidelity, photorealistic 3D retail store
simulation for benchmarking embodied agents against human performance in
shopping tasks. Addressing a gap in retail-specific sim environments for
embodied agent training, Sari Sandbox features over 250 interactive grocery
items across three store configurations, controlled via an API. It supports
both virtual reality (VR) for human interaction and a vision language model
(VLM)-powered embodied agent. We also introduce SariBench, a dataset of
annotated human demonstrations across varied task difficulties. Our sandbox
enables embodied agents to navigate, inspect, and manipulate retail items,
providing baselines against human performance. We conclude with benchmarks,
performance analysis, and recommendations for enhancing realism and
scalability. The source code can be accessed via
https://github.com/upeee/sari-sandbox-env.

</details>


### [41] [PMR: Physical Model-Driven Multi-Stage Restoration of Turbulent Dynamic Videos](https://arxiv.org/abs/2508.00406)
*Tao Wu,Jingyuan Ye,Ying Fu*

Main category: cs.CV

TL;DR: 提出了一种解决大气湍流导致的视频失真和动态场景模糊的三阶段视频恢复框架（PMR），具有高效和高质量恢复能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在强湍流和复杂动态条件下难以恢复边缘细节和消除混合失真，需要新的解决方案。

Method: 提出了动态效率指数（DEI）量化视频动态强度，并通过物理模型驱动的多阶段视频恢复框架（PMR）完成去倾斜、运动分割增强和去模糊。

Result: 实验表明该框架能有效消除运动拖影，恢复视频边缘细节，且在真实高湍流复杂场景中具有强泛化能力。

Conclusion: 该方法在湍流和复杂动态场景的应用中表现优异，未来将公开代码和数据集。

Abstract: Geometric distortions and blurring caused by atmospheric turbulence degrade
the quality of long-range dynamic scene videos. Existing methods struggle with
restoring edge details and eliminating mixed distortions, especially under
conditions of strong turbulence and complex dynamics. To address these
challenges, we introduce a Dynamic Efficiency Index ($DEI$), which combines
turbulence intensity, optical flow, and proportions of dynamic regions to
accurately quantify video dynamic intensity under varying turbulence conditions
and provide a high-dynamic turbulence training dataset. Additionally, we
propose a Physical Model-Driven Multi-Stage Video Restoration ($PMR$) framework
that consists of three stages: \textbf{de-tilting} for geometric stabilization,
\textbf{motion segmentation enhancement} for dynamic region refinement, and
\textbf{de-blurring} for quality restoration. $PMR$ employs lightweight
backbones and stage-wise joint training to ensure both efficiency and high
restoration quality. Experimental results demonstrate that the proposed method
effectively suppresses motion trailing artifacts, restores edge details and
exhibits strong generalization capability, especially in real-world scenarios
characterized by high-turbulence and complex dynamics. We will make the code
and datasets openly available.

</details>


### [42] [Sortblock: Similarity-Aware Feature Reuse for Diffusion Model](https://arxiv.org/abs/2508.00412)
*Hanqi Chen,Xu Zhang,Xiaoliu Guan,Lielin Jiang,Guanzhong Wang,Zeyu Chen,Yi Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为Sortblock的框架，通过动态缓存Transformer模块中的特征以加速Diffusion Transformer的推理速度。


<details>
  <summary>Details</summary>
Motivation: 解决Diffusion Transformer在推理过程中由于序列化去噪导致的高延迟问题，提升其实时应用能力。

Method: 提出Sortblock框架，根据相邻时间步中特征相似性动态缓存模块特征，同时利用线性预测机制减少跳过模块的误差累积。

Result: Sortblock在多个任务和架构中实现了超过2倍的推理加速，同时输出质量下降极小。

Conclusion: Sortblock是一种高效且通用的解决方案，可在不显著降低生成质量的情况下显著加速基于扩散的生成模型。

Abstract: Diffusion Transformers (DiTs) have demonstrated remarkable generative
capabilities, particularly benefiting from Transformer architectures that
enhance visual and artistic fidelity. However, their inherently sequential
denoising process results in high inference latency, limiting their deployment
in real-time scenarios. Existing training-free acceleration approaches
typically reuse intermediate features at fixed timesteps or layers, overlooking
the evolving semantic focus across denoising stages and Transformer blocks.To
address this, we propose Sortblock, a training-free inference acceleration
framework that dynamically caches block-wise features based on their similarity
across adjacent timesteps. By ranking the evolution of residuals, Sortblock
adaptively determines a recomputation ratio, selectively skipping redundant
computations while preserving generation quality. Furthermore, we incorporate a
lightweight linear prediction mechanism to reduce accumulated errors in skipped
blocks.Extensive experiments across various tasks and DiT architectures
demonstrate that Sortblock achieves over 2$\times$ inference speedup with
minimal degradation in output quality, offering an effective and generalizable
solution for accelerating diffusion-based generative models.

</details>


### [43] [DC-AE 1.5: Accelerating Diffusion Model Convergence with Structured Latent Space](https://arxiv.org/abs/2508.00413)
*Junyu Chen,Dongyun Zou,Wenkun He,Junsong Chen,Enze Xie,Song Han,Han Cai*

Main category: cs.CV

TL;DR: 本文介绍了DC-AE 1.5，一种用于高分辨率扩散模型的深度压缩自编码器，通过改进潜在空间结构和扩展扩散训练策略，显著提升收敛速度和生成质量。


<details>
  <summary>Details</summary>
Motivation: 为了解决增加自编码器潜在通道数导致高分辨率扩散模型收敛速度变慢的问题，这种问题严重限制了潜在扩散模型的质量上限。

Method: 引入两种创新策略：1) 在训练中施加强制潜在空间结构的策略，将前部分潜在通道用于捕捉物体结构、后部分用于捕捉图像细节；2) 提出增强型扩散训练策略，通过增加用于物体潜在通道的扩散训练目标来加速收敛。

Result: 在ImageNet 512x512测试集上，采用DC-AE-1.5-f64c128的模型比DC-AE-f32c32生成质量更高，同时速度提升了4倍。

Conclusion: DC-AE 1.5通过创新潜在空间结构和增强扩散训练策略，成功提升了高分辨率扩散模型的收敛速度和生成质量，为潜在扩散模型的进一步发展奠定了基础。

Abstract: We present DC-AE 1.5, a new family of deep compression autoencoders for
high-resolution diffusion models. Increasing the autoencoder's latent channel
number is a highly effective approach for improving its reconstruction quality.
However, it results in slow convergence for diffusion models, leading to poorer
generation quality despite better reconstruction quality. This issue limits the
quality upper bound of latent diffusion models and hinders the employment of
autoencoders with higher spatial compression ratios. We introduce two key
innovations to address this challenge: i) Structured Latent Space, a
training-based approach to impose a desired channel-wise structure on the
latent space with front latent channels capturing object structures and latter
latent channels capturing image details; ii) Augmented Diffusion Training, an
augmented diffusion training strategy with additional diffusion training
objectives on object latent channels to accelerate convergence. With these
techniques, DC-AE 1.5 delivers faster convergence and better diffusion scaling
results than DC-AE. On ImageNet 512x512, DC-AE-1.5-f64c128 delivers better
image generation quality than DC-AE-f32c32 while being 4x faster. Code:
https://github.com/dc-ai-projects/DC-Gen.

</details>


### [44] [IN2OUT: Fine-Tuning Video Inpainting Model for Video Outpainting Using Hierarchical Discriminator](https://arxiv.org/abs/2508.00418)
*Sangwoo Youn,Minji Lee,Nokap Tony Park,Yeonggyoo Jeon,Taeyoung Na*

Main category: cs.CV

TL;DR: 本文提出了利用视频修补模型进行视频扩展的方法，并通过引入分层鉴别器和专门的扩展损失函数来提升生成效果，最终在定量和定性上均超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩展方法通常只生成背景，效果不佳；直接套用或微调修补模型也会导致模糊结果，亟需改进。

Method: 通过实验设计分层鉴别器，结合全局与局部目标，并提出利用局部与全局特征的扩展损失函数进行微调优化。

Result: 提出方法在生成质量的感知一致性和视觉效果上优于现有最先进方法。

Conclusion: 分层鉴别器和专门的扩展损失函数在提升视频扩展效果上具有显著作用，补充材料和代码公开在SigPort。

Abstract: Video outpainting presents a unique challenge of extending the borders while
maintaining consistency with the given content. In this paper, we suggest the
use of video inpainting models that excel in object flow learning and
reconstruction in outpainting rather than solely generating the background as
in existing methods. However, directly applying or fine-tuning inpainting
models to outpainting has shown to be ineffective, often leading to blurry
results. Our extensive experiments on discriminator designs reveal that a
critical component missing in the outpainting fine-tuning process is a
discriminator capable of effectively assessing the perceptual quality of the
extended areas. To tackle this limitation, we differentiate the objectives of
adversarial training into global and local goals and introduce a hierarchical
discriminator that meets both objectives. Additionally, we develop a
specialized outpainting loss function that leverages both local and global
features of the discriminator. Fine-tuning on this adversarial loss function
enhances the generator's ability to produce both visually appealing and
globally coherent outpainted scenes. Our proposed method outperforms
state-of-the-art methods both quantitatively and qualitatively. Supplementary
materials including the demo video and the code are available in SigPort.

</details>


### [45] [UIS-Mamba: Exploring Mamba for Underwater Instance Segmentation via Dynamic Tree Scan and Hidden State Weaken](https://arxiv.org/abs/2508.00421)
*Runmin Cong,Zongji Yu,Hao Fang,Haoyan Sun,Sam Kwong*

Main category: cs.CV

TL;DR: 该论文提出了首个基于Mamba的水下实例分割模型UIS-Mamba，并设计了动态树扫描（DTS）和隐藏状态弱化（HSW）两个创新模块，从而实现了Mamba在水下场景的应用。


<details>
  <summary>Details</summary>
Motivation: 目前水下场景的复杂性使得传统的扫描机制难以保持实例内部连续性，同时复杂背景的隐藏状态抑制了对实例对象的理解，因此需要一种改进的方法。

Method: 提出UIS-Mamba模型，并加入动态树扫描（DTS）模块以动态偏移和缩放补丁，维护实例内部特征的连续性；加入隐藏状态弱化（HSW）模块，以通过Ncut机制抑制复杂背景干扰，增强对实例对象的关注。

Result: 在UIIS和USIS10K数据集上，UIS-Mamba实现了当前最优性能，同时保持了较低的参数数量和计算复杂度。

Conclusion: UIS-Mamba通过创新模块的设计成功将Mamba模型应用于水下实例分割任务，展现了有效性与高效性。

Abstract: Underwater Instance Segmentation (UIS) tasks are crucial for underwater
complex scene detection. Mamba, as an emerging state space model with
inherently linear complexity and global receptive fields, is highly suitable
for processing image segmentation tasks with long sequence features. However,
due to the particularity of underwater scenes, there are many challenges in
applying Mamba to UIS. The existing fixed-patch scanning mechanism cannot
maintain the internal continuity of scanned instances in the presence of
severely underwater color distortion and blurred instance boundaries, and the
hidden state of the complex underwater background can also inhibit the
understanding of instance objects. In this work, we propose the first
Mamba-based underwater instance segmentation model UIS-Mamba, and design two
innovative modules, Dynamic Tree Scan (DTS) and Hidden State Weaken (HSW), to
migrate Mamba to the underwater task. DTS module maintains the continuity of
the internal features of the instance objects by allowing the patches to
dynamically offset and scale, thereby guiding the minimum spanning tree and
providing dynamic local receptive fields. HSW module suppresses the
interference of complex backgrounds and effectively focuses the information
flow of state propagation to the instances themselves through the Ncut-based
hidden state weakening mechanism. Experimental results show that UIS-Mamba
achieves state-of-the-art performance on both UIIS and USIS10K datasets, while
maintaining a low number of parameters and computational complexity. Code is
available at https://github.com/Maricalce/UIS-Mamba.

</details>


### [46] [Contact-Aware Amodal Completion for Human-Object Interaction via Multi-Regional Inpainting](https://arxiv.org/abs/2508.00427)
*Seunggeun Chi,Enna Sachdeva,Pin-Hao Huang,Kwonjoon Lee*

Main category: cs.CV

TL;DR: 提出了一种新的多区域修复方法用于处理复杂的人体-物体交互（HOI）场景中的遮挡问题，显著提升了生成结果的准确性和逼真性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态场景下的生成结果不够合理，因为缺乏对人体-物体交互的深刻理解。

Method: 结合了人体运动学的物理先验和专门为HOI设计的多区域修复技术，定义主要和次要区域，并在扩散模型中使用自定义的去噪策略进行修复。

Result: 实验结果显示，提出的方法在HOI场景下显著优于现有方法，并在没有真实接触注释数据的情况下仍具有鲁棒性。

Conclusion: 该方法不仅改善了机器对动态环境的理解，同时拓宽了在3D重建与新视角/姿势生成等任务中的应用潜力。

Abstract: Amodal completion, which is the process of inferring the full appearance of
objects despite partial occlusions, is crucial for understanding complex
human-object interactions (HOI) in computer vision and robotics. Existing
methods, such as those that use pre-trained diffusion models, often struggle to
generate plausible completions in dynamic scenarios because they have a limited
understanding of HOI. To solve this problem, we've developed a new approach
that uses physical prior knowledge along with a specialized multi-regional
inpainting technique designed for HOI. By incorporating physical constraints
from human topology and contact information, we define two distinct regions:
the primary region, where occluded object parts are most likely to be, and the
secondary region, where occlusions are less probable. Our multi-regional
inpainting method uses customized denoising strategies across these regions
within a diffusion model. This improves the accuracy and realism of the
generated completions in both their shape and visual detail. Our experimental
results show that our approach significantly outperforms existing methods in
HOI scenarios, moving machine perception closer to a more human-like
understanding of dynamic environments. We also show that our pipeline is robust
even without ground-truth contact annotations, which broadens its applicability
to tasks like 3D reconstruction and novel view/pose synthesis.

</details>


### [47] [Reducing the gap between general purpose data and aerial images in concentrated solar power plants](https://arxiv.org/abs/2508.00440)
*M. A. Pérez-Cutiño,J. Valverde,J. Capitán,J. M. Díaz-Báñez*

Main category: cs.CV

TL;DR: 本论文提出AerialCSP虚拟数据集，旨在解决无人机拍摄下CSP（光热发电厂）场景中的图像处理难题，通过生成高质量合成数据来提升模型在真实环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型难以在反射性强、独特的CSP场景中表现良好，因为缺乏标注数据成本昂贵且费时，限制了其快速工业应用。

Method: 提出并创建AerialCSP虚拟数据集，通过模拟CSP工厂的航拍图像，为目标检测和图像分割提供高质量合成标注数据，同时衡量多种模型表现以建立基准。

Result: 实验表明，在AerialCSP上预训练的模型可以显著提升真实环境中的故障检测性能，特别是针对稀有和小缺陷目标，且减少标注数据需求。

Conclusion: AerialCSP数据集为CSP场景的机器学习任务提供了有价值的工具，并能有效减少对大规模人工标注的依赖，推动其工业化应用。

Abstract: In the context of Concentrated Solar Power (CSP) plants, aerial images
captured by drones present a unique set of challenges. Unlike urban or natural
landscapes commonly found in existing datasets, solar fields contain highly
reflective surfaces, and domain-specific elements that are uncommon in
traditional computer vision benchmarks. As a result, machine learning models
trained on generic datasets struggle to generalize to this setting without
extensive retraining and large volumes of annotated data. However, collecting
and labeling such data is costly and time-consuming, making it impractical for
rapid deployment in industrial applications.
  To address this issue, we propose a novel approach: the creation of
AerialCSP, a virtual dataset that simulates aerial imagery of CSP plants. By
generating synthetic data that closely mimic real-world conditions, our
objective is to facilitate pretraining of models before deployment,
significantly reducing the need for extensive manual labeling. Our main
contributions are threefold: (1) we introduce AerialCSP, a high-quality
synthetic dataset for aerial inspection of CSP plants, providing annotated data
for object detection and image segmentation; (2) we benchmark multiple models
on AerialCSP, establishing a baseline for CSP-related vision tasks; and (3) we
demonstrate that pretraining on AerialCSP significantly improves real-world
fault detection, particularly for rare and small defects, reducing the need for
extensive manual labeling. AerialCSP is made publicly available at
https://mpcutino.github.io/aerialcsp/.

</details>


### [48] [TopoTTA: Topology-Enhanced Test-Time Adaptation for Tubular Structure Segmentation](https://arxiv.org/abs/2508.00442)
*Jiale Zhou,Wenhan Wang,Shikun Li,Xiaolei Qu,Xin Guo,Yizhong Liu,Wenzhong Tang,Xun Lin,Yefeng Zheng*

Main category: cs.CV

TL;DR: 论文提出了拓扑增强测试时适配框架（TopoTTA），应对域转移对管状结构分割的挑战，显著提高了分割性能。


<details>
  <summary>Details</summary>
Motivation: 管状结构分割在血流动力学分析和路径导航等应用中至关重要，但域转移引发的性能下降仍是关键挑战之一，尤其是拓扑结构的变化更易破坏分割的完整性。

Method: 提出了TopoTTA框架，包括两个阶段：第一阶段利用拓扑元差分卷积（TopoMDC）适配跨域拓扑差异；第二阶段通过生成拓扑硬样本（TopoHG）和预测对齐改善拓扑连续性。

Result: 实验在四种场景、十个数据集上验证了TopoTTA的技术优势，在clDice评价指标上平均提升了31.81％。

Conclusion: TopoTTA框架有效应对了拓扑分布转移对管状结构分割的影响，同时具备良好的可扩展性，可作为CNN模型的插入式测试时适配方案。

Abstract: Tubular structure segmentation (TSS) is important for various applications,
such as hemodynamic analysis and route navigation. Despite significant progress
in TSS, domain shifts remain a major challenge, leading to performance
degradation in unseen target domains. Unlike other segmentation tasks, TSS is
more sensitive to domain shifts, as changes in topological structures can
compromise segmentation integrity, and variations in local features
distinguishing foreground from background (e.g., texture and contrast) may
further disrupt topological continuity. To address these challenges, we propose
Topology-enhanced Test-Time Adaptation (TopoTTA), the first test-time
adaptation framework designed specifically for TSS. TopoTTA consists of two
stages: Stage 1 adapts models to cross-domain topological discrepancies using
the proposed Topological Meta Difference Convolutions (TopoMDCs), which enhance
topological representation without altering pre-trained parameters; Stage 2
improves topological continuity by a novel Topology Hard sample Generation
(TopoHG) strategy and prediction alignment on hard samples with pseudo-labels
in the generated pseudo-break regions. Extensive experiments across four
scenarios and ten datasets demonstrate TopoTTA's effectiveness in handling
topological distribution shifts, achieving an average improvement of 31.81% in
clDice. TopoTTA also serves as a plug-and-play TTA solution for CNN-based TSS
models.

</details>


### [49] [SDMatte: Grafting Diffusion Models for Interactive Matting](https://arxiv.org/abs/2508.00443)
*Longfei Huang,Yu Liang,Hao Zhang,Jinwei Chen,Wei Dong,Lunde Chen,Wanyu Liu,Bo Li,Pengtao Jiang*

Main category: cs.CV

TL;DR: 最新的互动抠图方法在捕捉对象主要区域方面表现不错，但在提取边缘区域的细节上存在不足。而扩散模型在建模复杂数据分布和生成真实纹理细节方面表现优秀。本文提出SDMatte，一个基于扩散模型驱动的互动抠图方法。


<details>
  <summary>Details</summary>
Motivation: 传统的抠图方法难以在边缘区域捕获精细的细节，而扩散模型展示了处理复杂数据分布的能力，为解决这一问题提供了可能性。

Method: 提出了一种全新的以扩散模型为核心的互动抠图方法：1）通过扩散模型的强大先验，将文本驱动的交互能力转化为视觉提示驱动的交互；2）结合视觉提示的坐标嵌入和目标对象的不透明度嵌入，增强模型对空间位置和不透明度信息的敏感度；3）采用掩码自注意力机制，聚焦于提示指定区域。

Result: 在多个数据集上的广泛实验表明，该方法在互动抠图任务上的性能优于现有方法，并验证了其有效性。

Conclusion: SDMatte通过利用扩散模型实现了更精准和细致的互动抠图，为未来深入研究此方向提供了有力的参考。

Abstract: Recent interactive matting methods have shown satisfactory performance in
capturing the primary regions of objects, but they fall short in extracting
fine-grained details in edge regions. Diffusion models trained on billions of
image-text pairs, demonstrate exceptional capability in modeling highly complex
data distributions and synthesizing realistic texture details, while exhibiting
robust text-driven interaction capabilities, making them an attractive solution
for interactive matting. To this end, we propose SDMatte, a diffusion-driven
interactive matting model, with three key contributions. First, we exploit the
powerful priors of diffusion models and transform the text-driven interaction
capability into visual prompt-driven interaction capability to enable
interactive matting. Second, we integrate coordinate embeddings of visual
prompts and opacity embeddings of target objects into U-Net, enhancing
SDMatte's sensitivity to spatial position information and opacity information.
Third, we propose a masked self-attention mechanism that enables the model to
focus on areas specified by visual prompts, leading to better performance.
Extensive experiments on multiple datasets demonstrate the superior performance
of our method, validating its effectiveness in interactive matting. Our code
and model are available at https://github.com/vivoCameraResearch/SDMatte.

</details>


### [50] [AutoDebias: Automated Framework for Debiasing Text-to-Image Models](https://arxiv.org/abs/2508.00445)
*Hongyi Cai,Mohammad Mahdinur Rahman,Mingkang Dong,Jie Li,Muxin Pu,Zhili Fang,Yinan Peng,Hanjun Luo,Yang Liu*

Main category: cs.CV

TL;DR: 本文提出AutoDebias框架，通过自动检测和缓解T2I模型中的有害偏见问题，以提升生成图片的公平性。


<details>
  <summary>Details</summary>
Motivation: 现有的T2I模型容易无意中生成性别或种族等社会偏见的图片，而现有去偏方法在处理复杂或叠加偏见时表现较差。

Method: AutoDebias利用视觉-语言模型检测偏见视觉模式，通过生成包容性的提示词构建公平性指南，结合CLIP引导的训练过程，减少偏见输出，同时保持模型的图像质量和多样性。

Result: 在包含25种偏见场景的基准测试中，AutoDebias以91.6%的准确率检测偏见模式，将偏见输出从90%降至可忽略水平，同时保持原有模型的视觉保真度。

Conclusion: AutoDebias在有效缓解复杂及叠加偏见上表现优异，显著提升了T2I模型生成的公平性。

Abstract: Text-to-Image (T2I) models generate high-quality images from text prompts but
often exhibit unintended social biases, such as gender or racial stereotypes,
even when these attributes are not mentioned. Existing debiasing methods work
well for simple or well-known cases but struggle with subtle or overlapping
biases. We propose AutoDebias, a framework that automatically identifies and
mitigates harmful biases in T2I models without prior knowledge of specific bias
types. Specifically, AutoDebias leverages vision-language models to detect
biased visual patterns and constructs fairness guides by generating inclusive
alternative prompts that reflect balanced representations. These guides drive a
CLIP-guided training process that promotes fairer outputs while preserving the
original model's image quality and diversity. Unlike existing methods,
AutoDebias effectively addresses both subtle stereotypes and multiple
interacting biases. We evaluate the framework on a benchmark covering over 25
bias scenarios, including challenging cases where multiple biases occur
simultaneously. AutoDebias detects harmful patterns with 91.6% accuracy and
reduces biased outputs from 90% to negligible levels, while preserving the
visual fidelity of the original model.

</details>


### [51] [CLIPTime: Time-Aware Multimodal Representation Learning from Images and Text](https://arxiv.org/abs/2508.00447)
*Anju Rani,Daniel Ortiz-Arroyo,Petar Durdevic*

Main category: cs.CV

TL;DR: 本文提出了CLIPTime，一个基于CLIP架构的多模态多任务框架，用于通过图像和文本输入预测真菌生长的发育阶段和时间戳。通过联合分类和回归任务，实验结果表明其在建模生物学进程和时间感知预测方面表现良好。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在处理时间进程方面能力有限，而理解生物生长的时间动态对于多个领域至关重要，因此需要一个能处理时间进程的模型。

Method: 提出了CLIPTime框架，利用CLIP架构学习联合视觉-文本嵌入，并在没有明确时间输入的情况下实现时间感知推理，同时通过联合分类和回归任务来预测生长阶段和时间戳。

Result: 实验结果表明，CLIPTime可以有效地建模真菌生长等生物过程的时间进程，并能生成可解释的、基于时间的预测结果。

Conclusion: CLIPTime框架展示了视觉语言模型在实际生物监测任务中的潜力，为处理时间动态问题提供了一种有效的解决方案。

Abstract: Understanding the temporal dynamics of biological growth is critical across
diverse fields such as microbiology, agriculture, and biodegradation research.
Although vision-language models like Contrastive Language Image Pretraining
(CLIP) have shown strong capabilities in joint visual-textual reasoning, their
effectiveness in capturing temporal progression remains limited. To address
this, we propose CLIPTime, a multimodal, multitask framework designed to
predict both the developmental stage and the corresponding timestamp of fungal
growth from image and text inputs. Built upon the CLIP architecture, our model
learns joint visual-textual embeddings and enables time-aware inference without
requiring explicit temporal input during testing. To facilitate training and
evaluation, we introduce a synthetic fungal growth dataset annotated with
aligned timestamps and categorical stage labels. CLIPTime jointly performs
classification and regression, predicting discrete growth stages alongside
continuous timestamps. We also propose custom evaluation metrics, including
temporal accuracy and regression error, to assess the precision of time-aware
predictions. Experimental results demonstrate that CLIPTime effectively models
biological progression and produces interpretable, temporally grounded outputs,
highlighting the potential of vision-language models in real-world biological
monitoring applications.

</details>


### [52] [PIF-Net: Ill-Posed Prior Guided Multispectral and Hyperspectral Image Fusion via Invertible Mamba and Fusion-Aware LoRA](https://arxiv.org/abs/2508.00453)
*Baisong Li,Xingwang Wang,Haixiao Xu*

Main category: cs.CV

TL;DR: 本文提出了一种名为PIF-Net的多光谱和高光谱图像融合框架，通过引入先验知识和平衡光谱和空间信息来解决图像融合中的问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能有效解决由数据未对齐引起的融合挑战，提出PIF-Net以明确处理这些不适定问题。

Method: 设计了一个基于可逆Mamba架构的框架，结合信息一致性和轻量化的融合模块（Fusion-Aware Low-Rank Adaptation）来动态校准光谱和空间特征。

Result: 在多个基准数据集上的实验表明，PIF-Net在图像恢复性能上显著优于目前的先进方法，并且保持了模型的高效率。

Conclusion: PIF-Net能够有效解决多光谱和高光谱图像融合中的不适定问题，为实现高质量的图像恢复提供了一个高效稳定的框架。

Abstract: The goal of multispectral and hyperspectral image fusion (MHIF) is to
generate high-quality images that simultaneously possess rich spectral
information and fine spatial details. However, due to the inherent trade-off
between spectral and spatial information and the limited availability of
observations, this task is fundamentally ill-posed. Previous studies have not
effectively addressed the ill-posed nature caused by data misalignment. To
tackle this challenge, we propose a fusion framework named PIF-Net, which
explicitly incorporates ill-posed priors to effectively fuse multispectral
images and hyperspectral images. To balance global spectral modeling with
computational efficiency, we design a method based on an invertible Mamba
architecture that maintains information consistency during feature
transformation and fusion, ensuring stable gradient flow and process
reversibility. Furthermore, we introduce a novel fusion module called the
Fusion-Aware Low-Rank Adaptation module, which dynamically calibrates spectral
and spatial features while keeping the model lightweight. Extensive experiments
on multiple benchmark datasets demonstrate that PIF-Net achieves significantly
better image restoration performance than current state-of-the-art methods
while maintaining model efficiency.

</details>


### [53] [Semantic and Temporal Integration in Latent Diffusion Space for High-Fidelity Video Super-Resolution](https://arxiv.org/abs/2508.00471)
*Yiwen Wang,Xinning Chai,Yuhong Zhang,Zhengxue Cheng,Jun Zhao,Rong Xie,Li Song*

Main category: cs.CV

TL;DR: 提出了一种新的视频超分辨率方法SeTe-VSR，结合语义和时空引导，解决了高保真度和时间一致性间的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视频超分辨率模型在生成质量和时间一致性方面存在不足，需要一种能够更好控制生成过程的方法。

Method: 提出SeTe-VSR方法，通过在潜在扩散空间中结合高层语义信息以及时空指导，实现细节与时间一致性的平衡。

Result: SeTe-VSR在细节恢复和感知质量方面优于现有方法，特别是在复杂视频超分任务中表现尤为出色。

Conclusion: 方法提高了视觉内容的高保真度和一致性，展示了其在视频超分辨率任务中的有效性。

Abstract: Recent advancements in video super-resolution (VSR) models have demonstrated
impressive results in enhancing low-resolution videos. However, due to
limitations in adequately controlling the generation process, achieving high
fidelity alignment with the low-resolution input while maintaining temporal
consistency across frames remains a significant challenge. In this work, we
propose Semantic and Temporal Guided Video Super-Resolution (SeTe-VSR), a novel
approach that incorporates both semantic and temporal-spatio guidance in the
latent diffusion space to address these challenges. By incorporating high-level
semantic information and integrating spatial and temporal information, our
approach achieves a seamless balance between recovering intricate details and
ensuring temporal coherence. Our method not only preserves high-reality visual
content but also significantly enhances fidelity. Extensive experiments
demonstrate that SeTe-VSR outperforms existing methods in terms of detail
recovery and perceptual quality, highlighting its effectiveness for complex
video super-resolution tasks.

</details>


### [54] [Fine-grained Spatiotemporal Grounding on Egocentric Videos](https://arxiv.org/abs/2508.00518)
*Shuo Liang,Yiwu Zhong,Zi-Yuan Hu,Yeyao Tao,Liwei Wang*

Main category: cs.CV

TL;DR: 该论文提出了EgoMask，一个专注于自我视角视频的基准测试工具，并创建了大规模的EgoMask-Train训练数据集，以提高模型对细粒度时空定位的能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注于外部视角视频的时空定位，自我视角的视频研究不足，而这对于增强现实和机器人应用至关重要。

Method: 通过分析自我视角与外部视角视频的不同，提出自动标注机制生成EgoMask基准工具，结合短期、中期及长期视频数据，并构建了EgoMask-Train用于模型开发。

Result: 实验结果表明，现有模型在EgoMask基准上表现较差，但通过EgoMask-Train微调后取得显著改进，同时保留了外部视角数据集的性能。

Conclusion: EgoMask工具和相关数据集的发布，为自我视角视频的理解提供了重要的资源和洞察，推动了这一领域的发展。

Abstract: Spatiotemporal video grounding aims to localize target entities in videos
based on textual queries. While existing research has made significant progress
in exocentric videos, the egocentric setting remains relatively underexplored,
despite its growing importance in applications such as augmented reality and
robotics. In this work, we conduct a systematic analysis of the discrepancies
between egocentric and exocentric videos, revealing key challenges such as
shorter object durations, sparser trajectories, smaller object sizes, and
larger positional shifts. To address these challenges, we introduce EgoMask,
the first pixel-level benchmark for fine-grained spatiotemporal grounding in
egocentric videos. It is constructed by our proposed automatic annotation
pipeline, which annotates referring expressions and object masks across short-,
medium-, and long-term videos. Additionally, we create EgoMask-Train, a
large-scale training dataset to facilitate model development. Experiments
demonstrate that the state-of-the-art spatiotemporal grounding models perform
poorly on our benchmark EgoMask, but fine-tuning on EgoMask-Train yields
significant improvements, while preserving performance on exocentric datasets.
Our work thus provides essential resources and insights for advancing
egocentric video understanding. Our code is available at
https://github.com/LaVi-Lab/EgoMask .

</details>


### [55] [HyPCV-Former: Hyperbolic Spatio-Temporal Transformer for 3D Point Cloud Video Anomaly Detection](https://arxiv.org/abs/2508.00473)
*Jiaping Cao,Kangkang Zhou,Juan Du*

Main category: cs.CV

TL;DR: 本文提出HyPCV-Former，一种用于点云视频异常检测的超曲率时空Transformer，显著提升异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 视频异常检测在公共安全与智能监控系统中有重要应用，但当前方法在捕捉层次事件结构与时空连续性上存在局限性。

Method: 利用点云特征提取器提取空间特征后嵌入洛伦兹超曲率空间，引入超曲率多头自注意力机制（HMHA）学习基于非欧几里得几何的时序依赖，全程在洛伦兹空间完成特征转化与异常评分。

Result: 在多类异常检测中表现出色，TIMo数据集提升7%，DAD数据集提升5.6%。

Conclusion: HyPCV-Former利用超曲率嵌入与注意机制克服现有方法限制，为点云视频异常检测提供了新方法并取得最佳性能。

Abstract: Video anomaly detection is a fundamental task in video surveillance, with
broad applications in public safety and intelligent monitoring systems.
Although previous methods leverage Euclidean representations in RGB or depth
domains, such embeddings are inherently limited in capturing hierarchical event
structures and spatio-temporal continuity. To address these limitations, we
propose HyPCV-Former, a novel hyperbolic spatio-temporal transformer for
anomaly detection in 3D point cloud videos. Our approach first extracts
per-frame spatial features from point cloud sequences via point cloud
extractor, and then embeds them into Lorentzian hyperbolic space, which better
captures the latent hierarchical structure of events. To model temporal
dynamics, we introduce a hyperbolic multi-head self-attention (HMHA) mechanism
that leverages Lorentzian inner products and curvature-aware softmax to learn
temporal dependencies under non-Euclidean geometry. Our method performs all
feature transformations and anomaly scoring directly within full Lorentzian
space rather than via tangent space approximation. Extensive experiments
demonstrate that HyPCV-Former achieves state-of-the-art performance across
multiple anomaly categories, with a 7\% improvement on the TIMo dataset and a
5.6\% gain on the DAD dataset compared to benchmarks. The code will be released
upon paper acceptance.

</details>


### [56] [Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving](https://arxiv.org/abs/2508.00589)
*Stefan Englmeier,Max A. Büttner,Katharina Winter,Fabian B. Flohr*

Main category: cs.CV

TL;DR: 提出一种新颖的上下文感知运动检索框架，提升自动驾驶系统在长尾数据中极端场景的检索能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决在自动驾驶数据集中检索长尾数据中罕见人类行为场景的难题，以支持自动驾驶系统在多样化人类中心场景中的测试和泛化。

Method: 提出利用SMPL运动序列与对应视频帧的结合，通过自然语言对齐嵌入到共享多模态空间中，实现基于文本查询的大规模检索能力。

Result: 在WayMoCo数据集上表现优于先进模型，运动-上下文检索准确率提高了27.5%。

Conclusion: 该方法为自动驾驶系统在安全关键场景的鲁棒测试提供了工具，并展示了运动与场景上下文结合的重要性。

Abstract: Autonomous driving systems must operate reliably in safety-critical
scenarios, particularly those involving unusual or complex behavior by
Vulnerable Road Users (VRUs). Identifying these edge cases in driving datasets
is essential for robust evaluation and generalization, but retrieving such rare
human behavior scenarios within the long tail of large-scale datasets is
challenging. To support targeted evaluation of autonomous driving systems in
diverse, human-centered scenarios, we propose a novel context-aware motion
retrieval framework. Our method combines Skinned Multi-Person Linear
(SMPL)-based motion sequences and corresponding video frames before encoding
them into a shared multimodal embedding space aligned with natural language.
Our approach enables the scalable retrieval of human behavior and their context
through text queries. This work also introduces our dataset WayMoCo, an
extension of the Waymo Open Dataset. It contains automatically labeled motion
and scene context descriptions derived from generated pseudo-ground-truth SMPL
sequences and corresponding image data. Our approach outperforms
state-of-the-art models by up to 27.5% accuracy in motion-context retrieval,
when evaluated on the WayMoCo dataset.

</details>


### [57] [LesiOnTime -- Joint Temporal and Clinical Modeling for Small Breast Lesion Segmentation in Longitudinal DCE-MRI](https://arxiv.org/abs/2508.00496)
*Mohammed Kamran,Maria Bernathova,Raoul Varga,Christian Singer,Zsuzsanna Bago-Horvath,Thomas Helbich,Georg Langs,Philipp Seeböck*

Main category: cs.CV

TL;DR: 提出了一个新颖的3D分割方法，LesiOnTime，用于乳腺动态增强MRI中的小病灶分割，通过结合时间序列影像和BI-RADS分数实现更准确的早期癌症检测。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法主要针对大病灶，忽视利用重要的时间序列和临床信息进行精确的小病灶分割的需求。

Method: 引入了两个核心组件：时间优先注意力（TPA），用于动态整合先前和当前扫描的信息；以及BI-RADS一致性正则化（BCR）损失，促进具有相似放射学评估的扫描在特征空间中的一致性。

Result: 在一个高风险患者的乳腺动态增强MRI纵向数据集上，该方法在Dice指标下比现有单时间点和纵向基线方法提高了5%。

Conclusion: 结合时间序列和临床上下文可以显著提高早期病灶分割的可靠性，验证了方法的有效性并提供了开源代码以促进研究。

Abstract: Accurate segmentation of small lesions in Breast Dynamic Contrast-Enhanced
MRI (DCE-MRI) is critical for early cancer detection, especially in high-risk
patients. While recent deep learning methods have advanced lesion segmentation,
they primarily target large lesions and neglect valuable longitudinal and
clinical information routinely used by radiologists. In real-world screening,
detecting subtle or emerging lesions requires radiologists to compare across
timepoints and consider previous radiology assessments, such as the BI-RADS
score. We propose LesiOnTime, a novel 3D segmentation approach that mimics
clinical diagnostic workflows by jointly leveraging longitudinal imaging and
BIRADS scores. The key components are: (1) a Temporal Prior Attention (TPA)
block that dynamically integrates information from previous and current scans;
and (2) a BI-RADS Consistency Regularization (BCR) loss that enforces latent
space alignment for scans with similar radiological assessments, thus embedding
domain knowledge into the training process. Evaluated on a curated in-house
longitudinal dataset of high-risk patients with DCE-MRI, our approach
outperforms state-of-the-art single-timepoint and longitudinal baselines by 5%
in terms of Dice. Ablation studies demonstrate that both TPA and BCR contribute
complementary performance gains. These results highlight the importance of
incorporating temporal and clinical context for reliable early lesion
segmentation in real-world breast cancer screening. Our code is publicly
available at https://github.com/cirmuw/LesiOnTime

</details>


### [58] [LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer](https://arxiv.org/abs/2508.00477)
*Yuzhuo Chen,Zehua Ma,Jianhua Wang,Kai Kang,Shunyu Yao,Weiming Zhang*

Main category: cs.CV

TL;DR: 提出了LAMIC，一个无需训练的多参考图像生成框架，显著提升了多任务基准测试中的性能。


<details>
  <summary>Details</summary>
Motivation: 解决多参考图像生成时的空间布局一致性问题。

Method: 引入Group Isolation Attention (GIA)和Region-Modulated Attention (RMA)两种注意力机制，在无需额外训练情况下应用扩展。

Result: 在多个评估指标上表现出色，包括身份保留、背景一致性和布局控制等，超越现有的多参考基准方法。

Conclusion: LAMIC无需训练即可实现强大的零次泛化能力，为多图像控制式合成设立了新范式。

Abstract: In controllable image synthesis, generating coherent and consistent images
from multiple references with spatial layout awareness remains an open
challenge. We present LAMIC, a Layout-Aware Multi-Image Composition framework
that, for the first time, extends single-reference diffusion models to
multi-reference scenarios in a training-free manner. Built upon the MMDiT
model, LAMIC introduces two plug-and-play attention mechanisms: 1) Group
Isolation Attention (GIA) to enhance entity disentanglement; and 2)
Region-Modulated Attention (RMA) to enable layout-aware generation. To
comprehensively evaluate model capabilities, we further introduce three
metrics: 1) Inclusion Ratio (IN-R) and Fill Ratio (FI-R) for assessing layout
control; and 2) Background Similarity (BG-S) for measuring background
consistency. Extensive experiments show that LAMIC achieves state-of-the-art
performance across most major metrics: it consistently outperforms existing
multi-reference baselines in ID-S, BG-S, IN-R and AVG scores across all
settings, and achieves the best DPG in complex composition tasks. These results
demonstrate LAMIC's superior abilities in identity keeping, background
preservation, layout control, and prompt-following, all achieved without any
training or fine-tuning, showcasing strong zero-shot generalization ability. By
inheriting the strengths of advanced single-reference models and enabling
seamless extension to multi-image scenarios, LAMIC establishes a new
training-free paradigm for controllable multi-image composition. As foundation
models continue to evolve, LAMIC's performance is expected to scale
accordingly. Our implementation is available at:
https://github.com/Suchenl/LAMIC.

</details>


### [59] [SAMSA 2.0: Prompting Segment Anything with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation](https://arxiv.org/abs/2508.00493)
*Alfie Roddan,Tobias Czempiel,Chi Xu,Daniel S. Elson,Stamatia Giannarou*

Main category: cs.CV

TL;DR: 本文提出了SAMSA 2.0，一种用于高光谱医学影像的交互式分割框架，通过光谱角提示结合空间线索，提升了分割的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为解决高光谱医学影像分割中数据稀缺和噪声问题。

Method: 通过融合光谱角提示与空间线索，无需重新训练模型，即可引导Segment Anything Model (SAM) 提供更精确的分割。

Result: 与RGB模型相比，Dice得分提升最多达3.8%，相比之前的光谱融合方法最高提升3.1%。

Conclusion: SAMSA 2.0在数据少且噪声大的场景下表现出色，提高了分割模型的泛化能力，尤其在few-shot和zero-shot任务中具有优势。

Abstract: We present SAMSA 2.0, an interactive segmentation framework for hyperspectral
medical imaging that introduces spectral angle prompting to guide the Segment
Anything Model (SAM) using spectral similarity alongside spatial cues. This
early fusion of spectral information enables more accurate and robust
segmentation across diverse spectral datasets. Without retraining, SAMSA 2.0
achieves up to +3.8% higher Dice scores compared to RGB-only models and up to
+3.1% over prior spectral fusion methods. Our approach enhances few-shot and
zero-shot performance, demonstrating strong generalization in challenging
low-data and noisy scenarios common in clinical imaging.

</details>


### [60] [Wukong Framework for Not Safe For Work Detection in Text-to-Image systems](https://arxiv.org/abs/2508.00591)
*Mingrui Liu,Sixiao Zhang,Cheng Long*

Main category: cs.CV

TL;DR: 本文提出了Wukong，一个集成于扩散模型过程的NSFW检测框架，利用早期去噪输出实现高效检测。


<details>
  <summary>Details</summary>
Motivation: 为了高效准确地检测生成的NSFW内容，解决现有文本过滤和图像过滤方法的局限性。

Method: 基于扩散模型的早期去噪输出及其交叉注意力层，设计一个基于Transformer的NSFW检测框架Wukong，集成至扩散流程中。

Result: Wukong在一个新数据集及两项公开基准测试上表现优异，效率远高于图像过滤，同时精度相当。

Conclusion: Wukong显著优化了NSFW内容检测的效率和效果，展示了集成于扩散模型的潜力。

Abstract: Text-to-Image (T2I) generation is a popular AI-generated content (AIGC)
technology enabling diverse and creative image synthesis. However, some outputs
may contain Not Safe For Work (NSFW) content (e.g., violence), violating
community guidelines. Detecting NSFW content efficiently and accurately, known
as external safeguarding, is essential. Existing external safeguards fall into
two types: text filters, which analyze user prompts but overlook T2I
model-specific variations and are prone to adversarial attacks; and image
filters, which analyze final generated images but are computationally costly
and introduce latency. Diffusion models, the foundation of modern T2I systems
like Stable Diffusion, generate images through iterative denoising using a
U-Net architecture with ResNet and Transformer blocks. We observe that: (1)
early denoising steps define the semantic layout of the image, and (2)
cross-attention layers in U-Net are crucial for aligning text and image
regions. Based on these insights, we propose Wukong, a transformer-based NSFW
detection framework that leverages intermediate outputs from early denoising
steps and reuses U-Net's pre-trained cross-attention parameters. Wukong
operates within the diffusion process, enabling early detection without waiting
for full image generation. We also introduce a new dataset containing prompts,
seeds, and image-specific NSFW labels, and evaluate Wukong on this and two
public benchmarks. Results show that Wukong significantly outperforms
text-based safeguards and achieves comparable accuracy of image filters, while
offering much greater efficiency.

</details>


### [61] [Leveraging Convolutional and Graph Networks for an Unsupervised Remote Sensing Labelling Tool](https://arxiv.org/abs/2508.00506)
*Tulsi Patel,Mark W. Jones,Thomas Redfern*

Main category: cs.CV

TL;DR: 本文提出了一种无监督的处理Sentinel-2卫星图像的标注方法，利用图像分割及卷积和图神经网络生成更稳健的特征空间。


<details>
  <summary>Details</summary>
Motivation: 当前遥感影像的标注过程耗时高、成本高，且依赖已预标注的数据，无法有效针对新数据提供解决方案。

Method: 使用卷积和图神经网络进行分割，生成基于颜色和空间相似性的像素同质区域，通过图神经网络整合周围段信息构建鲁棒的特征表示。

Result: 减少标注中的异常值，支持更细粒度的标注，同时形成具有图像级旋转不变性的语义关系。

Conclusion: 新方法能够克服以往依赖预标注数据的局限性，为遥感图像标注提供了一种无监督的高效解决方案。

Abstract: Machine learning for remote sensing imaging relies on up-to-date and accurate
labels for model training and testing. Labelling remote sensing imagery is time
and cost intensive, requiring expert analysis. Previous labelling tools rely on
pre-labelled data for training in order to label new unseen data. In this work,
we define an unsupervised pipeline for finding and labelling geographical areas
of similar context and content within Sentinel-2 satellite imagery. Our
approach removes limitations of previous methods by utilising segmentation with
convolutional and graph neural networks to encode a more robust feature space
for image comparison. Unlike previous approaches we segment the image into
homogeneous regions of pixels that are grouped based on colour and spatial
similarity. Graph neural networks are used to aggregate information about the
surrounding segments enabling the feature representation to encode the local
neighbourhood whilst preserving its own local information. This reduces
outliers in the labelling tool, allows users to label at a granular level, and
allows a rotationally invariant semantic relationship at the image level to be
formed within the encoding space.

</details>


### [62] [EPANet: Efficient Path Aggregation Network for Underwater Fish Detection](https://arxiv.org/abs/2508.00528)
*Jinsong Yang,Zeyuan Hu,Yichen Li*

Main category: cs.CV

TL;DR: 提出一种高效路径聚合网络（EPANet），通过增强特征整合，提升低分辨率水下鱼类检测的精度与效率，同时优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有水下鱼类检测方法在解决低分辨率、背景干扰和目标与环境的高相似性问题上存在模型复杂度高、效率低等局限。

Method: 提出EPANet，包括高效路径聚合特征金字塔网络(EPA-FPN)和多尺度多样化分割短路径瓶颈(MS-DDSP Bottleneck)，分别通过长程跳跃连接与跨层融合以及特征细分与多样卷积操作增强特征表示能力。

Result: 在基准数据集上实验表明，EPANet在检测精度和推理速度上优于先进方法，并且具备较低的参数复杂度。

Conclusion: EPANet能够高效集成特征，在提高模型性能的同时避免复杂度上升，为水下鱼类检测领域提供了一种轻量化且准确的解决方案。

Abstract: Underwater fish detection (UFD) remains a challenging task in computer vision
due to low object resolution, significant background interference, and high
visual similarity between targets and surroundings. Existing approaches
primarily focus on local feature enhancement or incorporate complex attention
mechanisms to highlight small objects, often at the cost of increased model
complexity and reduced efficiency. To address these limitations, we propose an
efficient path aggregation network (EPANet), which leverages complementary
feature integration to achieve accurate and lightweight UFD. EPANet consists of
two key components: an efficient path aggregation feature pyramid network
(EPA-FPN) and a multi-scale diverse-division short path bottleneck (MS-DDSP
bottleneck). The EPA-FPN introduces long-range skip connections across
disparate scales to improve semantic-spatial complementarity, while cross-layer
fusion paths are adopted to enhance feature integration efficiency. The MS-DDSP
bottleneck extends the conventional bottleneck structure by introducing
finer-grained feature division and diverse convolutional operations, thereby
increasing local feature diversity and representation capacity. Extensive
experiments on benchmark UFD datasets demonstrate that EPANet outperforms
state-of-the-art methods in terms of detection accuracy and inference speed,
while maintaining comparable or even lower parameter complexity.

</details>


### [63] [Backdoor Attacks on Deep Learning Face Detection](https://arxiv.org/abs/2508.00620)
*Quentin Le Roux,Yannick Teglia,Teddy Furon,Philippe Loubet-Moundi*

Main category: cs.CV

TL;DR: 该论文研究了面部识别系统中的攻击方法和相应的缓解措施。


<details>
  <summary>Details</summary>
Motivation: 研究在非受限环境中，面部识别系统中存在的安全漏洞，如光照变化、不同面部姿势等问题。

Method: 提出了一种称为面部生成攻击的对象生成攻击方法，以及一种称为地标偏移攻击的后门攻击方法，并探讨了缓解这些攻击的策略。

Result: 验证了提出的攻击方法对面部检测模块的影响，例如坐标回归任务的偏差。

Conclusion: 面部识别系统存在安全漏洞，需采取相应的缓解措施来应对潜在攻击。

Abstract: Face Recognition Systems that operate in unconstrained environments capture
images under varying conditions,such as inconsistent lighting, or diverse face
poses. These challenges require including a Face Detection module that
regresses bounding boxes and landmark coordinates for proper Face Alignment.
This paper shows the effectiveness of Object Generation Attacks on Face
Detection, dubbed Face Generation Attacks, and demonstrates for the first time
a Landmark Shift Attack that backdoors the coordinate regression task performed
by face detectors. We then offer mitigations against these vulnerabilities.

</details>


### [64] [Video Color Grading via Look-Up Table Generation](https://arxiv.org/abs/2508.00548)
*Seunghyun Shin,Dongmin Shin,Jisu Shin,Hae-Gon Jeon,Joon-Young Lee*

Main category: cs.CV

TL;DR: 文章提出一种基于参考的自动视频调色框架，通过使用扩散模型生成查找表（LUT）以实现视频与参考场景颜色属性的对齐，并加入用户文本提示进行增强。


<details>
  <summary>Details</summary>
Motivation: 视频调色通常需要专业技能，而传统方法复杂且耗时，限制了非专业用户的使用。本研究旨在简化视频调色流程并提升用户友好性。

Method: 研究通过扩散模型生成查找表（LUT），实现输入视频和参考场景之间的颜色属性对齐，并通过文本提示结合用户偏好来增强低级特征，如亮度和对比度。

Result: 实验结果（包括广泛的用户研究）表明，该方法在视频调色任务中具有良好的效果，快速推理且保持结构细节。

Conclusion: 所提方法实现了便捷且高效的视频调色方案，为艺术性和用户交互提供了新思路，代码已公开。

Abstract: Different from color correction and transfer, color grading involves
adjusting colors for artistic or storytelling purposes in a video, which is
used to establish a specific look or mood. However, due to the complexity of
the process and the need for specialized editing skills, video color grading
remains primarily the domain of professional colorists. In this paper, we
present a reference-based video color grading framework. Our key idea is
explicitly generating a look-up table (LUT) for color attribute alignment
between reference scenes and input video via a diffusion model. As a training
objective, we enforce that high-level features of the reference scenes like
look, mood, and emotion should be similar to that of the input video. Our
LUT-based approach allows for color grading without any loss of structural
details in the whole video frames as well as achieving fast inference. We
further build a pipeline to incorporate a user-preference via text prompts for
low-level feature enhancement such as contrast and brightness, etc.
Experimental results, including extensive user studies, demonstrate the
effectiveness of our approach for video color grading. Codes are publicly
available at https://github.com/seunghyuns98/VideoColorGrading.

</details>


### [65] [Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images](https://arxiv.org/abs/2508.00549)
*Daniel Wolf,Heiko Hillenhagen,Billurvan Taskin,Alex Bäuerle,Meinrad Beer,Michael Götz,Timo Ropinski*

Main category: cs.CV

TL;DR: 该研究探讨视觉语言模型（VLMs）在医学成像中的相对位置判断能力，并发现现有模型在该任务上的表现不佳。提出了MIRP基准数据集以推动相关研究。


<details>
  <summary>Details</summary>
Motivation: 现有的VLMs在临床医学成像的相对位置判断中表现欠缺，然而此能力对医学决策至关重要，作者希望提升VLMs在这方面的表现。

Method: 评估GPT-4o、Llama3.2、Pixtral和JanusPro等模型在医学图像中的相对位置判断能力，结合放置视觉提示（如数字或颜色标记）的方法测试效果，并开发MIRP基准数据集以系统评估模型能力。

Result: 尽管视觉提示提供了适度改进，但模型在医学图像任务上的表现仍显著弱于自然图像。结果显示，VLMs更多依赖先验知识而非图像内容，常导致错误判断。

Conclusion: 现有VLMs难以胜任医学图像的相对位置判断，需依赖更有效的策略和基准数据集来促进性能提升。

Abstract: Clinical decision-making relies heavily on understanding relative positions
of anatomical structures and anomalies. Therefore, for Vision-Language Models
(VLMs) to be applicable in clinical practice, the ability to accurately
determine relative positions on medical images is a fundamental prerequisite.
Despite its importance, this capability remains highly underexplored. To
address this gap, we evaluate the ability of state-of-the-art VLMs, GPT-4o,
Llama3.2, Pixtral, and JanusPro, and find that all models fail at this
fundamental task. Inspired by successful approaches in computer vision, we
investigate whether visual prompts, such as alphanumeric or colored markers
placed on anatomical structures, can enhance performance. While these markers
provide moderate improvements, results remain significantly lower on medical
images compared to observations made on natural images. Our evaluations suggest
that, in medical imaging, VLMs rely more on prior anatomical knowledge than on
actual image content for answering relative position questions, often leading
to incorrect conclusions. To facilitate further research in this area, we
introduce the MIRP , Medical Imaging Relative Positioning, benchmark dataset,
designed to systematically evaluate the capability to identify relative
positions in medical images.

</details>


### [66] [DBLP: Noise Bridge Consistency Distillation For Efficient And Reliable Adversarial Purification](https://arxiv.org/abs/2508.00552)
*Chihan Huang,Belal Alsinglawi,Islam Al-qudah*

Main category: cs.CV

TL;DR: 提出了一种名为Diffusion Bridge Distillation for Purification (DBLP)的新框架，用于高效的对抗样本纯化，显著提升了鲁棒性和图像质量，且推理时间仅约0.2秒。


<details>
  <summary>Details</summary>
Motivation: 现有扩散式对抗样本纯化方法存在迭代去噪过程的计算开销，这限制了实际部署，本文希望通过新的方法提高效率和效果。

Method: 提出了噪声桥蒸馏目标，建立对抗噪声分布和干净数据分布的显式对齐，并结合自适应语义增强，利用多尺度金字塔边缘图作为条件输入指导纯化过程。

Result: 实验显示，多数据集上的DBLP框架实现了SOTA的鲁棒准确率、优秀的图像质量，同时推理时间仅为约0.2秒。

Conclusion: DBLP框架在对抗样本纯化任务中效率高、性能优越，为实时应用提供了可能。

Abstract: Recent advances in deep neural networks (DNNs) have led to remarkable success
across a wide range of tasks. However, their susceptibility to adversarial
perturbations remains a critical vulnerability. Existing diffusion-based
adversarial purification methods often require intensive iterative denoising,
severely limiting their practical deployment. In this paper, we propose
Diffusion Bridge Distillation for Purification (DBLP), a novel and efficient
diffusion-based framework for adversarial purification. Central to our approach
is a new objective, noise bridge distillation, which constructs a principled
alignment between the adversarial noise distribution and the clean data
distribution within a latent consistency model (LCM). To further enhance
semantic fidelity, we introduce adaptive semantic enhancement, which fuses
multi-scale pyramid edge maps as conditioning input to guide the purification
process. Extensive experiments across multiple datasets demonstrate that DBLP
achieves state-of-the-art (SOTA) robust accuracy, superior image quality, and
around 0.2s inference time, marking a significant step toward real-time
adversarial purification.

</details>


### [67] [D3: Training-Free AI-Generated Video Detection Using Second-Order Features](https://arxiv.org/abs/2508.00701)
*Chende Zheng,Ruiqi suo,Chenhao Lin,Zhengyu Zhao,Le Yang,Shuai Liu,Minghui Yang,Cong Wang,Chao Shen*

Main category: cs.CV

TL;DR: 提出一种名为D3的无训练检测方法，利用二阶时间差异特征有效检测AI生成视频，与前沿方法相比，显著提高了检测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法在检测合成视频时对时间伪迹的探索不足，因此需要新的理论框架以有效揭示真实视频与AI生成视频之间的差异。

Method: 基于牛顿力学的二阶动态分析框架，提出Second-order Central Difference特征，并设计Detector by Difference of Differences (D3)算法，无需训练即可检测二阶时间特征分布的差异。

Result: 在4个公开数据集（Gen-Video, VideoPhy, EvalCrafter, VidProM）和40个子集中验证了D3的优越性能，在GenVideo上平均精度比原有最佳方法提升10.39%。

Conclusion: D3方法不仅显著提升了检测精度，还具有出色的计算效率和鲁棒性，为AI生成视频的时间伪迹检测提供了新方向。

Abstract: The evolution of video generation techniques, such as Sora, has made it
increasingly easy to produce high-fidelity AI-generated videos, raising public
concern over the dissemination of synthetic content. However, existing
detection methodologies remain limited by their insufficient exploration of
temporal artifacts in synthetic videos. To bridge this gap, we establish a
theoretical framework through second-order dynamical analysis under Newtonian
mechanics, subsequently extending the Second-order Central Difference features
tailored for temporal artifact detection. Building on this theoretical
foundation, we reveal a fundamental divergence in second-order feature
distributions between real and AI-generated videos. Concretely, we propose
Detection by Difference of Differences (D3), a novel training-free detection
method that leverages the above second-order temporal discrepancies. We
validate the superiority of our D3 on 4 open-source datasets (Gen-Video,
VideoPhy, EvalCrafter, VidProM), 40 subsets in total. For example, on GenVideo,
D3 outperforms the previous best method by 10.39% (absolute) mean Average
Precision. Additional experiments on time cost and post-processing operations
demonstrate D3's exceptional computational efficiency and strong robust
performance. Our code is available at https://github.com/Zig-HS/D3.

</details>


### [68] [HiPrune: Training-Free Visual Token Pruning via Hierarchical Attention in Vision-Language Models](https://arxiv.org/abs/2508.00553)
*Jizhihui Liu,Feiyi Du,Guangdao Zhu,Niu Lian,Jun Li,Bin Chen*

Main category: cs.CV

TL;DR: HiPrune是一种无训练、模型不可知的可视化-语言模型(VLM)Token压缩框架，通过层次化注意力算法显著提高推理效率，同时无损或微损任务准确性。


<details>
  <summary>Details</summary>
Motivation: 当前VLM的图片编码序列过长，导致推理效率低下。虽然已有方法通过剪枝或合并Token优化，但仍需特定Token和任务定制训练，限制了适用性。

Method: HiPrune利用视觉编码器的层次化注意力结构，无重训练条件下选取三类信息Token：在初级层具有高注意力的Anchor Token，空间连续的Buffer Token，以及深层中具备全局特征的Register Token。此方法适用于任何基于ViT的VLM。

Result: 实验表明，HiPrune在保留33.3%和11.1%的Token时任务准确性分别维持在99.3%和99.5%。推理计算量与延迟减少高达9倍，且适用于多模型、多任务的泛化能力表现优越。

Conclusion: HiPrune有效提升VLM模型推理效率，实现高保精度的Token剪枝，具有较强的泛化能力，是一种高效且适用性广的框架。

Abstract: Vision-Language Models (VLMs) encode images into lengthy sequences of visual
tokens, leading to excessive computational overhead and limited inference
efficiency. While prior efforts prune or merge tokens to address this issue,
they often rely on special tokens (e.g., CLS) or require task-specific
training, hindering scalability across architectures. In this paper, we propose
HiPrune, a training-free and model-agnostic token Pruning framework that
exploits the Hierarchical attention structure within vision encoders. We
identify that middle layers attend to object-centric regions, while deep layers
capture global contextual features. Based on this observation, HiPrune selects
three types of informative tokens: (1) Anchor tokens with high attention in
object-centric layers, (2) Buffer tokens adjacent to anchors for spatial
continuity, and (3) Register tokens with strong attention in deep layers for
global summarization. Our method requires no retraining and integrates
seamlessly with any ViT-based VLM. Extensive experiments on LLaVA-1.5,
LLaVA-NeXT, and Qwen2.5-VL demonstrate that HiPrune achieves state-of-the-art
pruning performance, preserving up to 99.3% task accuracy with only 33.3%
tokens, and maintaining 99.5% accuracy with just 11.1% tokens. Meanwhile, it
reduces inference FLOPs and latency by up to 9$\times$, showcasing strong
generalization across models and tasks. Code is available at
https://github.com/Danielement321/HiPrune.

</details>


### [69] [Training-Free Class Purification for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2508.00557)
*Qi Chen,Lingxiao Yang,Yun Chen,Nailong Zhao,Jianhuang Lai,Jie Shao,Xiaohua Xie*

Main category: cs.CV

TL;DR: 提出了一种名为FreeCP的新框架，用于优化开放词汇语义分割性能并解决类别冗余和语义模糊等问题，无需训练。


<details>
  <summary>Details</summary>
Motivation: 受限于开放词汇语义分割的高计算和资源需求，希望找到一种训练友好的方法，同时改善类别冗余和语义模糊问题。

Method: 提出了一种训练自由的类别纯化框架FreeCP，通过净化语义类别以纠正类别冗余和语义模糊引起的误差，最终生成优化的分割结果。

Result: 在八个基准测试上进行了大量实验，验证了FreeCP作为即插即用模块显著提升分割性能的有效性。

Conclusion: FreeCP框架作为一种无需训练的新方法，能够高效解决类别冗余和语义模糊问题，并提升开放词汇语义分割的表现。

Abstract: Fine-tuning pre-trained vision-language models has emerged as a powerful
approach for enhancing open-vocabulary semantic segmentation (OVSS). However,
the substantial computational and resource demands associated with training on
large datasets have prompted interest in training-free methods for OVSS.
Existing training-free approaches primarily focus on modifying model
architectures and generating prototypes to improve segmentation performance.
However, they often neglect the challenges posed by class redundancy, where
multiple categories are not present in the current test image, and
visual-language ambiguity, where semantic similarities among categories create
confusion in class activation. These issues can lead to suboptimal class
activation maps and affinity-refined activation maps. Motivated by these
observations, we propose FreeCP, a novel training-free class purification
framework designed to address these challenges. FreeCP focuses on purifying
semantic categories and rectifying errors caused by redundancy and ambiguity.
The purified class representations are then leveraged to produce final
segmentation predictions. We conduct extensive experiments across eight
benchmarks to validate FreeCP's effectiveness. Results demonstrate that FreeCP,
as a plug-and-play module, significantly boosts segmentation performance when
combined with other OVSS methods.

</details>


### [70] [Guiding Diffusion-Based Articulated Object Generation by Partial Point Cloud Alignment and Physical Plausibility Constraints](https://arxiv.org/abs/2508.00558)
*Jens U. Kreber,Joerg Stueckler*

Main category: cs.CV

TL;DR: 提出PhysNAP，一种基于扩散模型的方法，用于生成与部分点云对齐且物理合理的可动对象。


<details>
  <summary>Details</summary>
Motivation: 解决日常环境下可动对象生成缺乏物理合理性和点云对齐问题。

Method: 通过扩散模型引入SDFs表示部件形状，利用点云对齐损失和非穿透、运动可行性约束引导模型，同时加入分类信息以提升效果。

Result: 在PartNet-Mobility数据集上验证了生成能力和约束一致性，相较无引导模型，PhysNAP显示出一致性改进和生成能力折中。

Conclusion: PhysNAP能生成更物理合理的可动对象，与部分点云对齐，提供了生成能力与物理一致性的平衡。

Abstract: Articulated objects are an important type of interactable objects in everyday
environments. In this paper, we propose PhysNAP, a novel diffusion model-based
approach for generating articulated objects that aligns them with partial point
clouds and improves their physical plausibility. The model represents part
shapes by signed distance functions (SDFs). We guide the reverse diffusion
process using a point cloud alignment loss computed using the predicted SDFs.
Additionally, we impose non-penetration and mobility constraints based on the
part SDFs for guiding the model to generate more physically plausible objects.
We also make our diffusion approach category-aware to further improve point
cloud alignment if category information is available. We evaluate the
generative ability and constraint consistency of samples generated with PhysNAP
using the PartNet-Mobility dataset. We also compare it with an unguided
baseline diffusion model and demonstrate that PhysNAP can improve constraint
consistency and provides a tradeoff with generative ability.

</details>


### [71] [Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images](https://arxiv.org/abs/2508.00563)
*Hannah Kniesel,Leon Sick,Tristan Payer,Tim Bergner,Kavitha Shaga Devan,Clarissa Read,Paul Walther,Timo Ropinski*

Main category: cs.CV

TL;DR: 提出了一种领域特定的弱监督对象检测算法，通过利用图像级别的标注，解决了物体检测中人工标注耗时且需领域专家进行的问题。


<details>
  <summary>Details</summary>
Motivation: 当前先进的物体检测方法需要大量标注数据，这些标注昂贵且需领域专家完成，为减少标注难度及成本，研究提出新方法。

Method: 基于图像级标注，通过使用预训练模型提取伪标签，并使用具有收缩感受野的优化策略直接检测病毒粒子，无需特定的网络结构。

Result: 提出的伪标签方法更加易于获取，并在某些限定时间的情况下，表现优于现有弱标记方法，甚至优于人工标注的真实标签。

Conclusion: 研究表明通过弱监督和伪标签技术，可以降低标注的复杂性和成本，同时提高某些任务上的检测准确性。

Abstract: Current state-of-the-art methods for object detection rely on annotated
bounding boxes of large data sets for training. However, obtaining such
annotations is expensive and can require up to hundreds of hours of manual
labor. This poses a challenge, especially since such annotations can only be
provided by experts, as they require knowledge about the scientific domain. To
tackle this challenge, we propose a domain-specific weakly supervised object
detection algorithm that only relies on image-level annotations, which are
significantly easier to acquire. Our method distills the knowledge of a
pre-trained model, on the task of predicting the presence or absence of a virus
in an image, to obtain a set of pseudo-labels that can be used to later train a
state-of-the-art object detection model. To do so, we use an optimization
approach with a shrinking receptive field to extract virus particles directly
without specific network architectures. Through a set of extensive studies, we
show how the proposed pseudo-labels are easier to obtain, and, more
importantly, are able to outperform other existing weak labeling methods, and
even ground truth labels, in cases where the time to obtain the annotation is
limited.

</details>


### [72] [CoProU-VO: Combining Projected Uncertainty for End-to-End Unsupervised Monocular Visual Odometry](https://arxiv.org/abs/2508.00568)
*Jingchao Xie,Oussema Dhaouadi,Weirong Chen,Johannes Meier,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: 本文提出了一种名为CoProU-VO的新方法，通过结合目标帧和参考帧的不确定性，改进动态场景下的无监督视觉里程计。


<details>
  <summary>Details</summary>
Motivation: 目前无监督视觉里程计方法在动态场景中容易因动态物体违反静态场景假设而产生误差，急需一种能够更好处理动态场景的方法。

Method: 提出了一种联合目标帧和参考帧不确定性的概率模型（CoProU-VO），基于视觉Transformer同时学习深度、不确定性估计以及相机位姿。

Result: 在KITTI与nuScenes数据集上表现优异，尤其在动态场景下优于现有无监督单目两帧方法，并通过消融实验验证了跨帧不确定性传播的有效性。

Conclusion: CoProU-VO显著提升了无监督视觉里程计在动态场景中的精度，为相关领域提供了重要的改进方向。

Abstract: Visual Odometry (VO) is fundamental to autonomous navigation, robotics, and
augmented reality, with unsupervised approaches eliminating the need for
expensive ground-truth labels. However, these methods struggle when dynamic
objects violate the static scene assumption, leading to erroneous pose
estimations. We tackle this problem by uncertainty modeling, which is a
commonly used technique that creates robust masks to filter out dynamic objects
and occlusions without requiring explicit motion segmentation. Traditional
uncertainty modeling considers only single-frame information, overlooking the
uncertainties across consecutive frames. Our key insight is that uncertainty
must be propagated and combined across temporal frames to effectively identify
unreliable regions, particularly in dynamic scenes. To address this challenge,
we introduce Combined Projected Uncertainty VO (CoProU-VO), a novel end-to-end
approach that combines target frame uncertainty with projected reference frame
uncertainty using a principled probabilistic formulation. Built upon vision
transformer backbones, our model simultaneously learns depth, uncertainty
estimation, and camera poses. Consequently, experiments on the KITTI and
nuScenes datasets demonstrate significant improvements over previous
unsupervised monocular end-to-end two-frame-based methods and exhibit strong
performance in challenging highway scenes where other approaches often fail.
Additionally, comprehensive ablation studies validate the effectiveness of
cross-frame uncertainty propagation.

</details>


### [73] [Uncertainty-Aware Likelihood Ratio Estimation for Pixel-Wise Out-of-Distribution Detection](https://arxiv.org/abs/2508.00587)
*Marc Hölle,Walter Kellermann,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 本文提出了一种基于不确定性感知的似然比估计算法，改善了在自主驾驶场景中将未知物体误分类的问题，并显著降低了误警率。


<details>
  <summary>Details</summary>
Motivation: 现有语义分割模型在真实世界自动驾驶场景中，通常会将未知物体错误分类，而现有方法在复杂场景中无法有效检测未知对象。

Method: 采用基于证据的分类器和似然比检测，通过生成捕捉不确定性的概率分布，改进对训练中罕见样本和带有瑕疵的合成异常样本的处理。

Result: 该方法在五个标准基准数据集上达到了最低平均误警率（2.5%），同时保持了较高的平均精度（90.91%），并且几乎没有增加计算开销。

Conclusion: 通过纳入不确定性，该方法有效利用了异常暴露问题，显著改善了语义分割模型在处理未知物体时的表现。

Abstract: Semantic segmentation models trained on known object classes often fail in
real-world autonomous driving scenarios by confidently misclassifying unknown
objects. While pixel-wise out-of-distribution detection can identify unknown
objects, existing methods struggle in complex scenes where rare object classes
are often confused with truly unknown objects. We introduce an
uncertainty-aware likelihood ratio estimation method that addresses these
limitations. Our approach uses an evidential classifier within a likelihood
ratio test to distinguish between known and unknown pixel features from a
semantic segmentation model, while explicitly accounting for uncertainty.
Instead of producing point estimates, our method outputs probability
distributions that capture uncertainty from both rare training examples and
imperfect synthetic outliers. We show that by incorporating uncertainty in this
way, outlier exposure can be leveraged more effectively. Evaluated on five
standard benchmark datasets, our method achieves the lowest average false
positive rate (2.5%) among state-of-the-art while maintaining high average
precision (90.91%) and incurring only negligible computational overhead. Code
is available at https://github.com/glasbruch/ULRE.

</details>


### [74] [A Novel Modeling Framework and Data Product for Extended VIIRS-like Artificial Nighttime Light Image Reconstruction (1986-2024)](https://arxiv.org/abs/2508.00590)
*Yihe Tian,Kwan Man Cheng,Zhengbo Zhang,Tao Zhang,Suju Li,Dongmei Yan,Bing Xu*

Main category: cs.CV

TL;DR: 提出新型重建框架EVAL，将VIIRS类夜间灯光数据的时间记录向前延长26年至1986年，显著提升数据质量和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有VIIRS夜间灯光数据时间覆盖限制了长期研究，现有方法在光强低估和结构缺失上存在不足。

Method: 提出了包含“构建”和“精化”两阶段的新框架，通过分层融合解码器和双特征优化器改善重建初始精度并增强精细结构细节。

Result: 新数据集EVAL相比现有方法，R²从0.68提升至0.80，RMSE从1.27降至0.99，同时与社会经济参数高度相关。

Conclusion: EVAL数据集为社会经济与环境研究提供了可靠的新资源，并已公开共享。

Abstract: Artificial Night-Time Light (NTL) remote sensing is a vital proxy for
quantifying the intensity and spatial distribution of human activities.
Although the NPP-VIIRS sensor provides high-quality NTL observations, its
temporal coverage, which begins in 2012, restricts long-term time-series
studies that extend to earlier periods. Despite the progress in extending
VIIRS-like NTL time-series, current methods still suffer from two significant
shortcomings: the underestimation of light intensity and the structural
omission. To overcome these limitations, we propose a novel reconstruction
framework consisting of a two-stage process: construction and refinement. The
construction stage features a Hierarchical Fusion Decoder (HFD) designed to
enhance the fidelity of the initial reconstruction. The refinement stage
employs a Dual Feature Refiner (DFR), which leverages high-resolution
impervious surface masks to guide and enhance fine-grained structural details.
Based on this framework, we developed the Extended VIIRS-like Artificial
Nighttime Light (EVAL) product for China, extending the standard data record
backwards by 26 years to begin in 1986. Quantitative evaluation shows that EVAL
significantly outperforms existing state-of-the-art products, boosting the
$\text{R}^2$ from 0.68 to 0.80 while lowering the RMSE from 1.27 to 0.99.
Furthermore, EVAL exhibits excellent temporal consistency and maintains a high
correlation with socioeconomic parameters, confirming its reliability for
long-term analysis. The resulting EVAL dataset provides a valuable new resource
for the research community and is publicly available at
https://doi.org/10.11888/HumanNat.tpdc.302930.

</details>


### [75] [Is It Really You? Exploring Biometric Verification Scenarios in Photorealistic Talking-Head Avatar Videos](https://arxiv.org/abs/2508.00748)
*Laura Pedrouzo-Rodriguez,Pedro Delgado-DeRobles,Luis F. Gomez,Ruben Tolosana,Ruben Vera-Rodriguez,Aythami Morales,Julian Fierrez*

Main category: cs.CV

TL;DR: 本研究提出了一种利用头像动态面部动作模式进行身份验证的方法，并使用新数据集进行验证，取得了约80%的身份验证性能。


<details>
  <summary>Details</summary>
Motivation: 虚拟头像广泛应用于虚拟会议、游戏和社交平台中，但其带来的安全风险，特别是身份冒充问题，急需解决。

Method: 研究引入了一个由先进的一次性生成头像模型GAGAvatar创建的真实头像视频数据集，提出了一种轻量化、可解释性空间-时间图卷积网络架构，利用面部关键点动态动作进行身份验证。

Result: 实验结果表明，利用面部运动特征进行身份验证可以获得接近80%的AUC值。

Conclusion: 面部运动模式作为行为生物特征在虚拟头像环境中表现出显著效果，未来应进一步推动行为生物特征在通信系统中的防御应用。

Abstract: Photorealistic talking-head avatars are becoming increasingly common in
virtual meetings, gaming, and social platforms. These avatars allow for more
immersive communication, but they also introduce serious security risks. One
emerging threat is impersonation: an attacker can steal a user's
avatar-preserving their appearance and voice-making it nearly impossible to
detect its fraudulent usage by sight or sound alone. In this paper, we explore
the challenge of biometric verification in such avatar-mediated scenarios. Our
main question is whether an individual's facial motion patterns can serve as
reliable behavioral biometrics to verify their identity when the avatar's
visual appearance is a facsimile of its owner. To answer this question, we
introduce a new dataset of realistic avatar videos created using a
state-of-the-art one-shot avatar generation model, GAGAvatar, with genuine and
impostor avatar videos. We also propose a lightweight, explainable
spatio-temporal Graph Convolutional Network architecture with temporal
attention pooling, that uses only facial landmarks to model dynamic facial
gestures. Experimental results demonstrate that facial motion cues enable
meaningful identity verification with AUC values approaching 80%. The proposed
benchmark and biometric system are available for the research community in
order to bring attention to the urgent need for more advanced behavioral
biometric defenses in avatar-based communication systems.

</details>


### [76] [GeoMoE: Divide-and-Conquer Motion Field Modeling with Mixture-of-Experts for Two-View Geometry](https://arxiv.org/abs/2508.00592)
*Jiajun Le,Jiayi Ma*

Main category: cs.CV

TL;DR: 本文提出了GeoMoE框架，通过引入混合专家模型（MoE）有效处理多样且复杂的运动场景，提高了相对位姿和单应性估计的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的双视几何方法在复杂场景下缺乏针对性的建模策略，无法有效处理包含深度断层等异质运动模式的运动场，导致估计结果偏离真实分布。

Method: 提出GeoMoE框架，包括两大核心模块：1) 概率先验引导分解策略，利用内点概率信号将运动场分解为异质子区域；2) MoE增强的双路径整流器，沿空间-上下文和通道-语义路径增强并交由定制专家建模，从而实现运动场的精细校正。

Result: GeoMoE框架在相对位姿和单应性估计方面优于现有方法，同时在强泛化性上表现良好。

Conclusion: GeoMoE通过引入结构意识和混合专家建模，成功改善了复杂场景中的运动场估计，为双视几何领域提供了一种创新且高效的方法。

Abstract: Recent progress in two-view geometry increasingly emphasizes enforcing
smoothness and global consistency priors when estimating motion fields between
pairs of images. However, in complex real-world scenes, characterized by
extreme viewpoint and scale changes as well as pronounced depth
discontinuities, the motion field often exhibits diverse and heterogeneous
motion patterns. Most existing methods lack targeted modeling strategies and
fail to explicitly account for this variability, resulting in estimated motion
fields that diverge from their true underlying structure and distribution. We
observe that Mixture-of-Experts (MoE) can assign dedicated experts to motion
sub-fields, enabling a divide-and-conquer strategy for heterogeneous motion
patterns. Building on this insight, we re-architect motion field modeling in
two-view geometry with GeoMoE, a streamlined framework. Specifically, we first
devise a Probabilistic Prior-Guided Decomposition strategy that exploits inlier
probability signals to perform a structure-aware decomposition of the motion
field into heterogeneous sub-fields, sharply curbing outlier-induced bias.
Next, we introduce an MoE-Enhanced Bi-Path Rectifier that enhances each
sub-field along spatial-context and channel-semantic paths and routes it to a
customized expert for targeted modeling, thereby decoupling heterogeneous
motion regimes, suppressing cross-sub-field interference and representational
entanglement, and yielding fine-grained motion-field rectification. With this
minimalist design, GeoMoE outperforms prior state-of-the-art methods in
relative pose and homography estimation and shows strong generalization. The
source code and pre-trained models are available at
https://github.com/JiajunLe/GeoMoE.

</details>


### [77] [DPoser-X: Diffusion Model as Robust 3D Whole-body Human Pose Prior](https://arxiv.org/abs/2508.00599)
*Junzhe Lu,Jing Lin,Hongkun Dou,Ailing Zeng,Yue Deng,Xian Liu,Zhongang Cai,Lei Yang,Yulun Zhang,Haoqian Wang,Ziwei Liu*

Main category: cs.CV

TL;DR: 文章介绍了DPoser-X，一种基于扩散模型的3D全身人体姿态生成器，展示其在多个基准上的卓越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的全身人体姿态先验算法由于姿态的复杂性和数据集匮乏存在局限，本文旨在解决这些问题。

Method: 提出DPoser-X模型，结合截断时间步调度方法和掩码训练机制，通过扩散模型和变分采样统一解决各种与姿态相关的反演问题。

Result: 实验表明DPoser-X在多种基准上优于现有技术，展示了其在全身、手部、面部及身体整体姿态建模的鲁棒性和多样性。

Conclusion: DPoser-X确立了全身人体姿态先验建模的新标准，为姿态数据任务提供了强大的工具。

Abstract: We present DPoser-X, a diffusion-based prior model for 3D whole-body human
poses. Building a versatile and robust full-body human pose prior remains
challenging due to the inherent complexity of articulated human poses and the
scarcity of high-quality whole-body pose datasets. To address these
limitations, we introduce a Diffusion model as body Pose prior (DPoser) and
extend it to DPoser-X for expressive whole-body human pose modeling. Our
approach unifies various pose-centric tasks as inverse problems, solving them
through variational diffusion sampling. To enhance performance on downstream
applications, we introduce a novel truncated timestep scheduling method
specifically designed for pose data characteristics. We also propose a masked
training mechanism that effectively combines whole-body and part-specific
datasets, enabling our model to capture interdependencies between body parts
while avoiding overfitting to specific actions. Extensive experiments
demonstrate DPoser-X's robustness and versatility across multiple benchmarks
for body, hand, face, and full-body pose modeling. Our model consistently
outperforms state-of-the-art alternatives, establishing a new benchmark for
whole-body human pose prior modeling.

</details>


### [78] [Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation](https://arxiv.org/abs/2508.00766)
*Irene Iele,Francesco Di Feola,Valerio Guarrasi,Paolo Soda*

Main category: cs.CV

TL;DR: 提出了一种用于医学图像到图像翻译的测试时适应（TTA）框架，通过动态调整翻译过程应对域外样本问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图像到图像翻译方法难以处理域外样本，会导致性能下降。

Method: 引入重构模块量化域偏移，并通过动态适应模块选择性地调整预训练翻译模型的内部特征。

Result: 在低剂量CT去噪和T1到T2 MRI翻译任务上验证了方法的有效性，相比无TTA的基线模型和现有TTA方法表现更好。

Conclusion: 动态、样本特定的调整能够提升模型在真实场景中的鲁棒性，优于现有的统一适应方法。

Abstract: Image-to-image translation has emerged as a powerful technique in medical
imaging, enabling tasks such as image denoising and cross-modality conversion.
However, it suffers from limitations in handling out-of-distribution samples
without causing performance degradation. To address this limitation, we propose
a novel Test-Time Adaptation (TTA) framework that dynamically adjusts the
translation process based on the characteristics of each test sample. Our
method introduces a Reconstruction Module to quantify the domain shift and a
Dynamic Adaptation Block that selectively modifies the internal features of a
pretrained translation model to mitigate the shift without compromising the
performance on in-distribution samples that do not require adaptation. We
evaluate our approach on two medical image-to-image translation tasks: low-dose
CT denoising and T1 to T2 MRI translation, showing consistent improvements over
both the baseline translation model without TTA and prior TTA methods. Our
analysis highlights the limitations of the state-of-the-art that uniformly
apply the adaptation to both out-of-distribution and in-distribution samples,
demonstrating that dynamic, sample-specific adjustment offers a promising path
to improve model resilience in real-world scenarios. The code is available at:
https://github.com/cosbidev/Sample-Aware_TTA.

</details>


### [79] [Minimum Data, Maximum Impact: 20 annotated samples for explainable lung nodule classification](https://arxiv.org/abs/2508.00639)
*Luisa Gallée,Catharina Silvia Lisson,Christoph Gerhard Lisson,Daniela Drees,Felix Weig,Daniel Vogele,Meinrad Beer,Michael Götz*

Main category: cs.CV

TL;DR: 提供具备可解释性的医学影像分类模型，通过生成合成数据增强训练效果。


<details>
  <summary>Details</summary>
Motivation: 通过在AI诊断中引入病理相关视觉属性，提升诊断的透明性和模型输出的验证能力。

Method: 开发了一个增强型扩散模型，进行属性条件的生成，并使用仅20个标注样本进行训练。

Result: 通过合成数据训练的模型使属性预测准确率提高13.4%，目标预测准确率提升1.8%。

Conclusion: 利用生成的合成数据可以有效克服数据集不足的问题，增强可解释模型在医学影像分析中的应用潜力。

Abstract: Classification models that provide human-interpretable explanations enhance
clinicians' trust and usability in medical image diagnosis. One research focus
is the integration and prediction of pathology-related visual attributes used
by radiologists alongside the diagnosis, aligning AI decision-making with
clinical reasoning. Radiologists use attributes like shape and texture as
established diagnostic criteria and mirroring these in AI decision-making both
enhances transparency and enables explicit validation of model outputs.
However, the adoption of such models is limited by the scarcity of large-scale
medical image datasets annotated with these attributes. To address this
challenge, we propose synthesizing attribute-annotated data using a generative
model. We enhance the Diffusion Model with attribute conditioning and train it
using only 20 attribute-labeled lung nodule samples from the LIDC-IDRI dataset.
Incorporating its generated images into the training of an explainable model
boosts performance, increasing attribute prediction accuracy by 13.4% and
target prediction accuracy by 1.8% compared to training with only the small
real attribute-annotated dataset. This work highlights the potential of
synthetic data to overcome dataset limitations, enhancing the applicability of
explainable models in medical image analysis.

</details>


### [80] [Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights](https://arxiv.org/abs/2508.00649)
*Junhao Zheng,Jiahao Sun,Chenhao Lin,Zhengyu Zhao,Chen Ma,Chong Zhang,Cong Wang,Qian Wang,Chao Shen*

Main category: cs.CV

TL;DR: 本文旨在针对目标检测模型的补丁攻击问题，提出首个综合的补丁防御基准测试框架，并通过大规模实验和分析发现了若干新见解，同时提供相关代码和数据集以推进研究。


<details>
  <summary>Details</summary>
Motivation: 目前的补丁攻击防御评估缺乏一个统一的、全面的评估框架，导致对于防御方法的评价不一致且不充分。本研究旨在填补这一空白，系统地重新审视现有防御方法。

Method: 提出了首个补丁攻击防御基准，包含2种攻击目标、13种补丁攻击方法、11种目标检测器和4种多样化的评估指标。由此生成了一个包含94种补丁和94,000张图片的大规模对抗性补丁数据集，并基于此开展了深入分析。

Result: 分析表明：1）防御自然化补丁的难点在于数据分布，而非高频成分；2）被攻击目标的平均精度比补丁检测精度更能有效反映防御性能；3）自适应攻击能够显著突破现有防御，而复杂/随机模型或普适补丁属性的防御方法相对更鲁棒。

Conclusion: 本研究提供了一种有效的方法来评价补丁攻击和防御，并推动了新防御方法的设计改进与发展，为后续研究提供了指导意义。

Abstract: Developing reliable defenses against patch attacks on object detectors has
attracted increasing interest. However, we identify that existing defense
evaluations lack a unified and comprehensive framework, resulting in
inconsistent and incomplete assessments of current methods. To address this
issue, we revisit 11 representative defenses and present the first patch
defense benchmark, involving 2 attack goals, 13 patch attacks, 11 object
detectors, and 4 diverse metrics. This leads to the large-scale adversarial
patch dataset with 94 types of patches and 94,000 images. Our comprehensive
analyses reveal new insights: (1) The difficulty in defending against
naturalistic patches lies in the data distribution, rather than the commonly
believed high frequencies. Our new dataset with diverse patch distributions can
be used to improve existing defenses by 15.09% AP@0.5. (2) The average
precision of the attacked object, rather than the commonly pursued patch
detection accuracy, shows high consistency with defense performance. (3)
Adaptive attacks can substantially bypass existing defenses, and defenses with
complex/stochastic models or universal patch properties are relatively robust.
We hope that our analyses will serve as guidance on properly evaluating patch
attacks/defenses and advancing their design. Code and dataset are available at
https://github.com/Gandolfczjh/APDE, where we will keep integrating new
attacks/defenses.

</details>


### [81] [Can Large Pretrained Depth Estimation Models Help With Image Dehazing?](https://arxiv.org/abs/2508.00698)
*Hongfei Zhang,Kun Zhou,Ruizheng Wu,Jiangbo Lu*

Main category: cs.CV

TL;DR: 提出了一种可插拔的RGB-D融合模块，用于提升图像去雾模型的效果与适应性。


<details>
  <summary>Details</summary>
Motivation: 图像去雾在处理真实场景中具有空间变化的雾效问题时依然面临挑战；现有方法的架构设计限制了其在不同场景中的适应性与灵活性。

Method: 系统性分析了从大规模图像中学到的深度表示在图像去雾中的泛化能力，并通过实验发现深度特征对不同雾浓度具有良好的一致性；基于此，设计了一个可插拔的RGB-D融合模块，可无缝集成到各种去雾架构中。

Result: 通过多个基准测试验证，该方法在有效性和广泛适用性上都表现出色。

Conclusion: 融合深度特征能显著提升图像去雾的表现，同时提出的模块可以灵活应用于多种模型中，为实际场景下的去雾任务提供了更好的解决方案。

Abstract: Image dehazing remains a challenging problem due to the spatially varying
nature of haze in real-world scenes. While existing methods have demonstrated
the promise of large-scale pretrained models for image dehazing, their
architecture-specific designs hinder adaptability across diverse scenarios with
different accuracy and efficiency requirements. In this work, we systematically
investigate the generalization capability of pretrained depth
representations-learned from millions of diverse images-for image dehazing. Our
empirical analysis reveals that the learned deep depth features maintain
remarkable consistency across varying haze levels. Building on this insight, we
propose a plug-and-play RGB-D fusion module that seamlessly integrates with
diverse dehazing architectures. Extensive experiments across multiple
benchmarks validate both the effectiveness and broad applicability of our
approach.

</details>


### [82] [MIHBench: Benchmarking and Mitigating Multi-Image Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2508.00726)
*Jiale Li,Mingrui Wu,Zixiang Jin,Hao Chen,Jiayi Ji,Xiaoshuai Sun,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: MIHBench是一个专门评估多图像多模态大语言模型(MllMs)中的物体相关幻觉问题的新基准。


<details>
  <summary>Details</summary>
Motivation: 研究多图像情境下的幻觉问题，弥补当前仅针对单图像研究的不足。

Method: 提出MIHBench，包括三个任务，并设计动态注意力平衡机制解决多图像幻觉问题。

Result: 发现多图像幻觉的关键因素，并验证动态注意力机制能够减少幻觉发生，并提升语义整合和推理稳健性。

Conclusion: 研究首次系统分析多图像幻觉问题，设计的MIHBench和方法有效应对相关问题。

Abstract: Despite growing interest in hallucination in Multimodal Large Language
Models, existing studies primarily focus on single-image settings, leaving
hallucination in multi-image scenarios largely unexplored. To address this gap,
we conduct the first systematic study of hallucinations in multi-image MLLMs
and propose MIHBench, a benchmark specifically tailored for evaluating
object-related hallucinations across multiple images. MIHBench comprises three
core tasks: Multi-Image Object Existence Hallucination, Multi-Image Object
Count Hallucination, and Object Identity Consistency Hallucination, targeting
semantic understanding across object existence, quantity reasoning, and
cross-view identity consistency. Through extensive evaluation, we identify key
factors associated with the occurrence of multi-image hallucinations,
including: a progressive relationship between the number of image inputs and
the likelihood of hallucination occurrences; a strong correlation between
single-image hallucination tendencies and those observed in multi-image
contexts; and the influence of same-object image ratios and the positional
placement of negative samples within image sequences on the occurrence of
object identity consistency hallucination. To address these challenges, we
propose a Dynamic Attention Balancing mechanism that adjusts inter-image
attention distributions while preserving the overall visual attention
proportion. Experiments across multiple state-of-the-art MLLMs demonstrate that
our method effectively reduces hallucination occurrences and enhances semantic
integration and reasoning stability in multi-image scenarios.

</details>


### [83] [YOLO-Count: Differentiable Object Counting for Text-to-Image Generation](https://arxiv.org/abs/2508.00728)
*Guanning Zeng,Xiang Zhang,Zirui Wang,Haiyang Xu,Zeyuan Chen,Bingnan Li,Zhuowen Tu*

Main category: cs.CV

TL;DR: 本文提出YOLO-Count，一种用于目标计数和文本生成图像(T2I)生成精确数量控制的模型，尤其创新性在于引入了“基数”图，用于处理对象大小和分布的变化。


<details>
  <summary>Details</summary>
Motivation: 目前开集目标计数和文本生成图像系统中对精确数量控制的需求仍未完全满足，需要一种集中处理两者挑战的方法。

Method: 提出了一种“基数”图作为回归目标，同时使用表征对齐和强弱监督相结合的策略，模型是完全可微的架构，便于梯度优化。

Result: 实验表明YOLO-Count在目标计数精度方面达到了最新水平，同时为T2I系统提供了稳健的数量控制。

Conclusion: YOLO-Count是一种突破性的模型，不仅提高了开集目标计数的能力，同时能够在T2I生成中实现精确的数量控制。

Abstract: We propose YOLO-Count, a differentiable open-vocabulary object counting model
that tackles both general counting challenges and enables precise quantity
control for text-to-image (T2I) generation. A core contribution is the
'cardinality' map, a novel regression target that accounts for variations in
object size and spatial distribution. Leveraging representation alignment and a
hybrid strong-weak supervision scheme, YOLO-Count bridges the gap between
open-vocabulary counting and T2I generation control. Its fully differentiable
architecture facilitates gradient-based optimization, enabling accurate object
count estimation and fine-grained guidance for generative models. Extensive
experiments demonstrate that YOLO-Count achieves state-of-the-art counting
accuracy while providing robust and effective quantity control for T2I systems.

</details>


### [84] [Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR](https://arxiv.org/abs/2508.00744)
*Adwait Chandorkar,Hasan Tercan,Tobias Meisen*

Main category: cs.CV

TL;DR: 介绍了一种用于点云3D目标检测的新型轻量级骨干网络Dense Backbone，可显著降低计算成本，性能接近主流方法。


<details>
  <summary>Details</summary>
Motivation: 改进现有3D目标检测骨干网络，降低模型复杂性以及计算成本，同时性能不下降太多。

Method: 提出一种基于Dense层的轻量级骨干网络Dense Backbone，并集成到PillarNet等SOTA方法中进行验证。

Result: Dense Backbone应用于DensePillarNet时，模型参数减少29%，延迟降低28%，检测精度仅下降2%。

Conclusion: Dense Backbone实现了速度、复杂度和检测性能之间的良好权衡，具有很大应用潜力，且可方便地与现有架构集成。

Abstract: Recent advancements in LiDAR-based 3D object detection have significantly
accelerated progress toward the realization of fully autonomous driving in
real-world environments. Despite achieving high detection performance, most of
the approaches still rely on a VGG-based or ResNet-based backbone for feature
exploration, which increases the model complexity. Lightweight backbone design
is well-explored for 2D object detection, but research on 3D object detection
still remains limited. In this work, we introduce Dense Backbone, a lightweight
backbone that combines the benefits of high processing speed, lightweight
architecture, and robust detection accuracy. We adapt multiple SoTA 3d object
detectors, such as PillarNet, with our backbone and show that with our
backbone, these models retain most of their detection capability at a
significantly reduced computational cost. To our knowledge, this is the first
dense-layer-based backbone tailored specifically for 3D object detection from
point cloud data. DensePillarNet, our adaptation of PillarNet, achieves a 29%
reduction in model parameters and a 28% reduction in latency with just a 2%
drop in detection accuracy on the nuScenes test set. Furthermore, Dense
Backbone's plug-and-play design allows straightforward integration into
existing architectures, requiring no modifications to other network components.

</details>


### [85] [GECO: Geometrically Consistent Embedding with Lightspeed Inference](https://arxiv.org/abs/2508.00746)
*Regine Hartwig,Dominik Muhle,Riccardo Marin,Daniel Cremers*

Main category: cs.CV

TL;DR: GECO是一种轻量级架构，能够以30fps的速度生成几何一致的语义分割特征，其性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前自监督视觉模型虽然能够捕获语义对应关系，但常忽略了3D几何特性。GECO旨在弥补这一不足。

Method: 提出一种基于最优传输的训练框架，即使在遮挡情况下也能实现对几何部分的超越关键点监督，同时保持架构轻量化。

Result: 在PFPascal、APK和CUB数据集上分别提高PCK 6.0%、6.2%、4.1%，在速度方面比现有方法快98.2%。

Conclusion: PCK指标不足以全面评估几何特性，研究引入了新的评估指标推动更几何感知的特征学习。

Abstract: Recent advances in feature learning have shown that self-supervised vision
foundation models can capture semantic correspondences but often lack awareness
of underlying 3D geometry. GECO addresses this gap by producing geometrically
coherent features that semantically distinguish parts based on geometry (e.g.,
left/right eyes, front/back legs). We propose a training framework based on
optimal transport, enabling supervision beyond keypoints, even under occlusions
and disocclusions. With a lightweight architecture, GECO runs at 30 fps, 98.2%
faster than prior methods, while achieving state-of-the-art performance on
PFPascal, APK, and CUB, improving PCK by 6.0%, 6.2%, and 4.1%, respectively.
Finally, we show that PCK alone is insufficient to capture geometric quality
and introduce new metrics and insights for more geometry-aware feature
learning. Link to project page:
https://reginehartwig.github.io/publications/geco/

</details>


### [86] [SU-ESRGAN: Semantic and Uncertainty-Aware ESRGAN for Super-Resolution of Satellite and Drone Imagery with Fine-Tuning for Cross Domain Evaluation](https://arxiv.org/abs/2508.00750)
*Prerana Ramkumar*

Main category: cs.CV

TL;DR: 本文提出了首个为卫星图像设计的超分辨率框架SU-ESRGAN，该框架结合了ESRGAN、DeepLabv3分割损失与蒙特卡洛Dropout来生成像素级不确定性图。


<details>
  <summary>Details</summary>
Motivation: 目前GANs在图像超分辨率领域取得了一定进展，但其在语义一致性和像素级可信度上存在不足，制约了其在遥感领域的关键应用。

Method: 提出了SU-ESRGAN框架，集成ESRGAN、DeepLabv3分割损失与蒙特卡洛Dropout，并通过模块化设计支持卫星系统或无人机数据处理管道。

Result: SU-ESRGAN在PSNR、SSIM和LPIPS指标上与标准ESRGAN性能相当，在不同海拔和视角的无人机制数据集上进行了微调测试，模型显示了对某些数据集更强的适应性。

Conclusion: SU-ESRGAN框架通过域感知训练方式显示出在遥感和无人机图像中的潜力，为图像分辨率提升提供了一种语义与不确定性结合的创新方法。

Abstract: Generative Adversarial Networks (GANs) have achieved realistic
super-resolution (SR) of images however, they lack semantic consistency and
per-pixel confidence, limiting their credibility in critical remote sensing
applications such as disaster response, urban planning and agriculture. This
paper introduces Semantic and Uncertainty-Aware ESRGAN (SU-ESRGAN), the first
SR framework designed for satellite imagery to integrate the ESRGAN,
segmentation loss via DeepLabv3 for class detail preservation and Monte Carlo
dropout to produce pixel-wise uncertainty maps. The SU-ESRGAN produces results
(PSNR, SSIM, LPIPS) comparable to the Baseline ESRGAN on aerial imagery. This
novel model is valuable in satellite systems or UAVs that use wide
field-of-view (FoV) cameras, trading off spatial resolution for coverage. The
modular design allows integration in UAV data pipelines for on-board or
post-processing SR to enhance imagery resulting due to motion blur, compression
and sensor limitations. Further, the model is fine-tuned to evaluate its
performance on cross domain applications. The tests are conducted on two drone
based datasets which differ in altitude and imaging perspective. Performance
evaluation of the fine-tuned models show a stronger adaptation to the Aerial
Maritime Drone Dataset, whose imaging characteristics align with the training
data, highlighting the importance of domain-aware training in SR-applications.

</details>


### [87] [Zero-Shot Anomaly Detection with Dual-Branch Prompt Learning](https://arxiv.org/abs/2508.00777)
*Zihan Wang,Samira Ebrahimi Kahou,Narges Armanfard*

Main category: cs.CV

TL;DR: 提出了一个名为PILOT的框架，用于零样本异常检测，在不同领域中的异常检测和定位上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有零样本异常检测方法无法适应域偏移。

Method: 提出双分支提示学习机制和无标签测试时适应策略。

Result: PILOT在13个工业和医学基准上实现了最先进的性能。

Conclusion: PILOT有效解决域偏移下异常检测泛化问题。

Abstract: Zero-shot anomaly detection (ZSAD) enables identifying and localizing defects
in unseen categories by relying solely on generalizable features rather than
requiring any labeled examples of anomalies. However, existing ZSAD methods,
whether using fixed or learned prompts, struggle under domain shifts because
their training data are derived from limited training domains and fail to
generalize to new distributions. In this paper, we introduce PILOT, a framework
designed to overcome these challenges through two key innovations: (1) a novel
dual-branch prompt learning mechanism that dynamically integrates a pool of
learnable prompts with structured semantic attributes, enabling the model to
adaptively weight the most relevant anomaly cues for each input image; and (2)
a label-free test-time adaptation strategy that updates the learnable prompt
parameters using high-confidence pseudo-labels from unlabeled test data.
Extensive experiments on 13 industrial and medical benchmarks demonstrate that
PILOT achieves state-of-the-art performance in both anomaly detection and
localization under domain shift.

</details>


### [88] [Cross-Dataset Semantic Segmentation Performance Analysis: Unifying NIST Point Cloud City Datasets for 3D Deep Learning](https://arxiv.org/abs/2508.00822)
*Alexander Nikitas Dimopoulos,Joseph Grasso*

Main category: cs.CV

TL;DR: 本文分析了点云数据集在语义分割中的性能差异，特别是与公共安全应用相关的数据集，发现分类不平衡和小型物体的几何特征对性能有较大影响。


<details>
  <summary>Details</summary>
Motivation: 研究点云语义分割性能的限制和提升方法，以改进公共安全领域的实际应用效果。

Method: 采用KPConv架构和分级方案，对NIST的Point Cloud City数据集进行IoU性能评估，并探讨异构数据统一化的挑战。

Result: 较大物体（如楼梯、窗户）具有较高的分割性能，小型安全关键物体的识别率较低，性能受限于分类不平衡和几何特征边界。

Conclusion: 提升点云语义分割性能要求标准化标注协议和改进标注技术，以解决数据异构性及小型关键元素的识别问题。

Abstract: This study analyzes semantic segmentation performance across heterogeneously
labeled point-cloud datasets relevant to public safety applications, including
pre-incident planning systems derived from lidar scans. Using NIST's Point
Cloud City dataset (Enfield and Memphis collections), we investigate challenges
in unifying differently labeled 3D data. Our methodology employs a graded
schema with the KPConv architecture, evaluating performance through IoU metrics
on safety-relevant features. Results indicate performance variability:
geometrically large objects (e.g. stairs, windows) achieve higher segmentation
performance, suggesting potential for navigational context, while smaller
safety-critical features exhibit lower recognition rates. Performance is
impacted by class imbalance and the limited geometric distinction of smaller
objects in typical lidar scans, indicating limitations in detecting certain
safety-relevant features using current point-cloud methods. Key identified
challenges include insufficient labeled data, difficulties in unifying class
labels across datasets, and the need for standardization. Potential directions
include automated labeling and multi-dataset learning strategies. We conclude
that reliable point-cloud semantic segmentation for public safety necessitates
standardized annotation protocols and improved labeling techniques to address
data heterogeneity and the detection of small, safety-critical elements.

</details>


### [89] [IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation](https://arxiv.org/abs/2508.00823)
*Wenxuan Guo,Xiuwei Xu,Hang Yin,Ziwei Wang,Jianjiang Feng,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为IGL-Nav的3D感知图像目标导航系统，以实现高效的3D目标图像定位。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以全面建模探索的3D环境与目标图像之间的几何关系，因此需要一种高效的解决方案。

Method: 提出了增量3D高斯定位框架（IGL-Nav），通过逐步更新场景表示以实现3D感知图像导航，包括粗定位与优化精定位两阶段。

Result: IGL-Nav在多个实验配置中显著优于现有方法，并可以处理自由视角图像目标并应用于真实机器人平台。

Conclusion: IGL-Nav结合了高效与准确性，通过3DGS及增量优化为视觉导航问题提供了一种先进解决方案。

Abstract: Visual navigation with an image as goal is a fundamental and challenging
problem. Conventional methods either rely on end-to-end RL learning or
modular-based policy with topological graph or BEV map as memory, which cannot
fully model the geometric relationship between the explored 3D environment and
the goal image. In order to efficiently and accurately localize the goal image
in 3D space, we build our navigation system upon the renderable 3D gaussian
(3DGS) representation. However, due to the computational intensity of 3DGS
optimization and the large search space of 6-DoF camera pose, directly
leveraging 3DGS for image localization during agent exploration process is
prohibitively inefficient. To this end, we propose IGL-Nav, an Incremental 3D
Gaussian Localization framework for efficient and 3D-aware image-goal
navigation. Specifically, we incrementally update the scene representation as
new images arrive with feed-forward monocular prediction. Then we coarsely
localize the goal by leveraging the geometric information for discrete space
matching, which can be equivalent to efficient 3D convolution. When the agent
is close to the goal, we finally solve the fine target pose with optimization
via differentiable rendering. The proposed IGL-Nav outperforms existing
state-of-the-art methods by a large margin across diverse experimental
configurations. It can also handle the more challenging free-view image-goal
setting and be deployed on real-world robotic platform using a cellphone to
capture goal image at arbitrary pose. Project page:
https://gwxuan.github.io/IGL-Nav/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [90] [PhysicsEval: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems](https://arxiv.org/abs/2508.00079)
*Oshayer Siddique,J. M Areeb Uzair Alam,Md Jobayer Rahman Rafy,Syed Rifat Raiyan,Hasan Mahmud,Md Kamrul Hasan*

Main category: cs.CL

TL;DR: 本文探讨了前沿大语言模型（LLMs）在解决物理学问题（包括数学和描述性问题）中的性能，并引入了多代理框架和新的评估基准PHYSICSEVAL。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型如何在复杂的物理问题求解中表现，并探索提升其推理能力的方法。

Method: 应用推理时技术、多代理框架（通过小型LLM验证方案正确性）来改进模型性能，并比较不同技术的效果。

Result: 多代理框架对于模型初始表现不佳的问题提升显著，并且引入了一个包含19609个物理问题的新的评估基准PHYSICSEVAL。

Conclusion: 多代理协作和推理技术可以显著提升大语言模型在物理问题求解中的性能，并提供了全新的评测方式和平台。

Abstract: The discipline of physics stands as a cornerstone of human intellect, driving
the evolution of technology and deepening our understanding of the fundamental
principles of the cosmos. Contemporary literature includes some works centered
on the task of solving physics problems - a crucial domain of natural language
reasoning. In this paper, we evaluate the performance of frontier LLMs in
solving physics problems, both mathematical and descriptive. We also employ a
plethora of inference-time techniques and agentic frameworks to improve the
performance of the models. This includes the verification of proposed solutions
in a cumulative fashion by other, smaller LLM agents, and we perform a
comparative analysis of the performance that the techniques entail. There are
significant improvements when the multi-agent framework is applied to problems
that the models initially perform poorly on. Furthermore, we introduce a new
evaluation benchmark for physics problems, ${\rm P{\small HYSICS}E{\small
VAL}}$, consisting of 19,609 problems sourced from various physics textbooks
and their corresponding correct solutions scraped from physics forums and
educational websites. Our code and data are publicly available at
https://github.com/areebuzair/PhysicsEval.

</details>


### [91] [Do LLMs produce texts with "human-like" lexical diversity?](https://arxiv.org/abs/2508.00086)
*Kelly Kendro,Jeffrey Maloney,Scott Jarvis*

Main category: cs.CL

TL;DR: 研究探讨了生成的LLM文本与人类文本在词汇多样性上的差异，发现最新的LLM生成的文本与人类文本在词汇多样性上更加不同。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLM）生成的文本在词汇多样性方面是否接近于人类书写风格。

Method: 研究测量了4个ChatGPT模型和240名英语母语和非母语者的文本词汇多样性，使用了包括MANOVAs、ANOVAS和支持向量机等分析方法。

Result: 结果表明，LLM生成的文本在词汇多样性上与人类文本存在显著差异，其中最新模型（ChatGPT-4.5）生成的文本与人类文本的差异最大，而人类文本在词汇多样性上则不因教育水平或语言背景而有差异。

Conclusion: LLM生成文本在词汇多样性方面并非真正人类化，且新版本的LLM较旧版本更不人类化，结果对语言教学及相关应用有重要意义。

Abstract: The degree to which LLMs produce writing that is truly human-like remains
unclear despite the extensive empirical attention that this question has
received. The present study addresses this question from the perspective of
lexical diversity. Specifically, the study investigates patterns of lexical
diversity in LLM-generated texts from four ChatGPT models (-3.5, -4, -o4 mini,
and -4.5) in comparison with texts written by L1 and L2 English participants (n
= 240) across four education levels. Six dimensions of lexical diversity were
measured in each text: volume, abundance, variety-repetition, evenness,
disparity, and dispersion. Results from one-way MANOVAs, one-way ANOVAS, and
Support Vector Machines revealed that the LLM-generated texts differed
significantly from human-written texts for each variable, with ChatGPT-o4 mini
and -4.5 differing the most. Within these two groups, ChatGPT-4.5 demonstrated
higher levels of lexical diversity despite producing fewer tokens. The human
writers' lexical diversity did not differ across subgroups (i.e., education,
language status). Altogether, the results indicate that LLMs do not produce
human-like texts in relation to lexical diversity, and the newer LLMs produce
less human-like texts than older models. We discuss the implications of these
results for language pedagogy and related applications.

</details>


### [92] [Semiotic Complexity and Its Epistemological Implications for Modeling Culture](https://arxiv.org/abs/2508.00095)
*Zachary K. Stine,James E. Deitrick*

Main category: cs.CL

TL;DR: 本文探讨计算人文学科中的翻译理论框架，提出其对翻译错误和解释透明性的重要性。


<details>
  <summary>Details</summary>
Motivation: 推动计算人文学科发展需要更深入的方法理论化，以确保认识论及解释性的清晰。

Method: 将建模工作视为从文化、语言领域到计算、数学领域，再回到原领域的翻译过程，并引入符号复杂性的概念。

Result: 指出建模实践中因忽视符号复杂性而导致的翻译错误，尤其是在评价时将复杂数据视为简单数据的问题。

Conclusion: 提出若干建议，帮助研究者更好地处理这些认识论问题，并改善其方法的可靠性。

Abstract: Greater theorizing of methods in the computational humanities is needed for
epistemological and interpretive clarity, and therefore the maturation of the
field. In this paper, we frame such modeling work as engaging in translation
work from a cultural, linguistic domain into a computational, mathematical
domain, and back again. Translators benefit from articulating the theory of
their translation process, and so do computational humanists in their work --
to ensure internal consistency, avoid subtle yet consequential translation
errors, and facilitate interpretive transparency. Our contribution in this
paper is to lay out a particularly consequential dimension of the lack of
theorizing and the sorts of translation errors that emerge in our modeling
practices as a result. Along these lines we introduce the idea of semiotic
complexity as the degree to which the meaning of some text may vary across
interpretive lenses, and make the case that dominant modeling practices --
especially around evaluation -- commit a translation error by treating
semiotically complex data as semiotically simple when it seems
epistemologically convenient by conferring superficial clarity. We then lay out
several recommendations for researchers to better account for these
epistemological issues in their own work.

</details>


### [93] [FACTORY: A Challenging Human-Verified Prompt Set for Long-Form Factuality](https://arxiv.org/abs/2508.00109)
*Mingda Chen,Yang Li,Xilun Chen,Adina Williams,Gargi Ghosh,Scott Yih*

Main category: cs.CL

TL;DR: 本文引入了FACTORY,一个大型人类验证的提示集，用于评估模型生成长形式回答的准确性和全面性，发现现有模型在新基准下存在显著错误率。


<details>
  <summary>Details</summary>
Motivation: 现有长形式事实性评估基准缺乏人类验证质量，因此难以准确评价模型生成的质量。

Method: 采用模型参与循环的方式生成初始数据集，并通过人工进行进一步校正生成FACTORY基准；使用该基准对6种最先进的语言模型进行评估，并结合现有数据集对其表现进行对比。

Result: FACTORY显著挑战了现有语言模型，显示在FACTORY上的事实性错误率约为40%，而其他数据集仅为10%。

Conclusion: FACTORY作为一个更加严谨和可靠的基准，展示了现有模型在长尾事实推理中的不足，并强调了改进事实性生成能力的必要性。

Abstract: Long-form factuality evaluation assesses the ability of models to generate
accurate, comprehensive responses to short prompts. Existing benchmarks often
lack human verification, leading to potential quality issues. To address this
limitation, we introduce FACTORY, a large-scale, human-verified prompt set.
Developed using a model-in-the-loop approach and refined by humans, FACTORY
includes challenging prompts that are fact-seeking, answerable, and
unambiguous. We conduct human evaluations on 6 state-of-the-art language models
using FACTORY and existing datasets. Our results show that FACTORY is a
challenging benchmark: approximately 40% of the claims made in the responses of
SOTA models are not factual, compared to only 10% for other datasets. Our
analysis identifies the strengths of FACTORY over prior benchmarks, emphasizing
its reliability and the necessity for models to reason across long-tailed
facts.

</details>


### [94] [Is neural semantic parsing good at ellipsis resolution, or isn't it?](https://arxiv.org/abs/2508.00121)
*Xiao Zhang,Johan bos*

Main category: cs.CL

TL;DR: 神经语义解析器对英语动词短语省略现象表现较差，即使其在标准测试集上总体表现良好。


<details>
  <summary>Details</summary>
Motivation: 研究神经语义解析器在处理强语境敏感现象（如动词短语省略）的能力，探讨其对上下文语义信息的再现能力。

Method: 构建包含120个动词短语省略实例及其完整语义表示的语料库，并将其作为挑战集测试多种神经语义解析器。

Result: 解析器在标准测试集上表现良好，但在处理省略现象的实例中效果不佳。

Conclusion: 目前神经语义解析器无法很好地处理动词短语省略现象，存在提升空间。

Abstract: Neural semantic parsers have shown good overall performance for a variety of
linguistic phenomena, reaching semantic matching scores of more than 90%. But
how do such parsers perform on strongly context-sensitive phenomena, where
large pieces of semantic information need to be duplicated to form a meaningful
semantic representation? A case in point is English verb phrase ellipsis, a
construct where entire verb phrases can be abbreviated by a single auxiliary
verb. Are the otherwise known as powerful semantic parsers able to deal with
ellipsis or aren't they? We constructed a corpus of 120 cases of ellipsis with
their fully resolved meaning representation and used this as a challenge set
for a large battery of neural semantic parsers. Although these parsers
performed very well on the standard test set, they failed in the instances with
ellipsis. Data augmentation

</details>


### [95] [Comparison of Large Language Models for Deployment Requirements](https://arxiv.org/abs/2508.00185)
*Alper Yaman,Jannik Schwab,Christof Nitsche,Abhirup Sinha,Marco Huber*

Main category: cs.CL

TL;DR: 本文讨论了大型语言模型（LLMs）的发展及其在生成类人文本中的应用，同时介绍了一份对基础模型和领域特定模型的比较列表，用于辅助选择适合的LLM。


<details>
  <summary>Details</summary>
Motivation: 帮助研究人员和企业在众多开源基础模型及微调模型中做出最佳选择。

Method: 通过列出基础模型和领域特定模型，比较它们的发布时间、授权方式以及硬件需求，并将该列表发布至GitLab以供持续更新。

Result: 提出了一份方便研究人员和企业了解不同LLM的比较列表。

Conclusion: 此研究通过汇总和比较LLM的多项特性，为快速变化的LLM选择提供了重要支持。

Abstract: Large Language Models (LLMs), such as Generative Pre-trained Transformers
(GPTs) are revolutionizing the generation of human-like text, producing
contextually relevant and syntactically correct content. Despite challenges
like biases and hallucinations, these Artificial Intelligence (AI) models excel
in tasks, such as content creation, translation, and code generation.
Fine-tuning and novel architectures, such as Mixture of Experts (MoE), address
these issues. Over the past two years, numerous open-source foundational and
fine-tuned models have been introduced, complicating the selection of the
optimal LLM for researchers and companies regarding licensing and hardware
requirements. To navigate the rapidly evolving LLM landscape and facilitate LLM
selection, we present a comparative list of foundational and domain-specific
models, focusing on features, such as release year, licensing, and hardware
requirements. This list is published on GitLab and will be continuously
updated.

</details>


### [96] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: 本文讨论了表格在大语言模型（LLMs）和多模态大语言模型（MLLMs）中逐渐受到重视，分析其在理解任务中的挑战，并提出了相关研究的关键问题和空白。


<details>
  <summary>Details</summary>
Motivation: 表格作为一种二维信息形式，与线性文本相比具有更复杂和多样化的结构。因此，需要探索普通方法以克服当前专门化方法的不统一问题。

Method: 通过对表格输入表示的分类和表格理解任务的综述，本文定义了关键概念，并总结当前研究中存在的不足之处。

Result: 本文揭示了当前表格理解研究的三大限制，包括任务偏向检索、处理复杂表格的困难以及模型在不同表格表示和格式中的泛化能力有限。

Conclusion: 当前的表格理解任务和方法存在显著不足，需进一步研究以提升大语言模型对复杂表格的处理能力及其泛化水平。

Abstract: Tables have gained significant attention in large language models (LLMs) and
multimodal large language models (MLLMs) due to their complex and flexible
structure. Unlike linear text inputs, tables are two-dimensional, encompassing
formats that range from well-structured database tables to complex,
multi-layered spreadsheets, each with different purposes. This diversity in
format and purpose has led to the development of specialized methods and tasks,
instead of universal approaches, making navigation of table understanding tasks
challenging. To address these challenges, this paper introduces key concepts
through a taxonomy of tabular input representations and an introduction of
table understanding tasks. We highlight several critical gaps in the field that
indicate the need for further research: (1) the predominance of
retrieval-focused tasks that require minimal reasoning beyond mathematical and
logical operations; (2) significant challenges faced by models when processing
complex table structures, large-scale tables, length context, or multi-table
scenarios; and (3) the limited generalization of models across different
tabular representations and formats.

</details>


### [97] [Semantic Compression for Word and Sentence Embeddings using Discrete Wavelet Transform](https://arxiv.org/abs/2508.00220)
*Rana Aref Salama,Abdou Youssef,Mona Diab*

Main category: cs.CL

TL;DR: 这篇论文探讨了离散小波变换（DWT）在处理词和句子嵌入中的应用，尤其是在降低维度的同时保持语义信息。


<details>
  <summary>Details</summary>
Motivation: 研究利用小波变换技术在自然语言处理中进行特征提取和压缩的可能性。

Method: 将离散小波变换（DWT）应用于多种嵌入模型，分析其对嵌入表示的分辨率与压缩能力的效果。

Result: DWT可以将嵌入维度减少50-93%，在语义相似任务中的性能几乎不受影响，并在大多数下游任务中表现出更高的准确性。

Conclusion: DWT为改进自然语言处理任务提供了一种有效的新方法。

Abstract: Wavelet transforms, a powerful mathematical tool, have been widely used in
different domains, including Signal and Image processing, to unravel intricate
patterns, enhance data representation, and extract meaningful features from
data. Tangible results from their application suggest that Wavelet transforms
can be applied to NLP capturing a variety of linguistic and semantic
properties. In this paper, we empirically leverage the application of Discrete
Wavelet Transforms (DWT) to word and sentence embeddings. We aim to showcase
the capabilities of DWT in analyzing embedding representations at different
levels of resolution and compressing them while maintaining their overall
quality. We assess the effectiveness of DWT embeddings on semantic similarity
tasks to show how DWT can be used to consolidate important semantic information
in an embedding vector. We show the efficacy of the proposed paradigm using
different embedding models, including large language models, on downstream
tasks. Our results show that DWT can reduce the dimensionality of embeddings by
50-93% with almost no change in performance for semantic similarity tasks,
while achieving superior accuracy in most downstream tasks. Our findings pave
the way for applying DWT to improve NLP applications.

</details>


### [98] [Model Misalignment and Language Change: Traces of AI-Associated Language in Unscripted Spoken English](https://arxiv.org/abs/2508.00238)
*Bryce Anderson,Riley Galpin,Tom S. Juzek*

Main category: cs.CL

TL;DR: 研究探讨大型语言模型（LLMs）是否对科学和教育中的书面语言变化产生了影响，特别是在词汇使用上。通过分析播客对话数据，发现ChatGPT发布后，与LLMs相关的词汇使用显著增加。


<details>
  <summary>Details</summary>
Motivation: 近年来语言使用方式发生变化，尤其是LLMs的广泛应用可能改变了语言体系，但尚不清楚这种影响是由AI直接作用还是语言系统变迁所致。

Method: 构建包含2200万词的对话播客数据集，比较ChatGPT发布前后LLMs相关词汇的使用趋势，并与同义词的使用情况进行对比分析。

Result: 结果显示，ChatGPT发布后，LLMs相关的词汇使用显著增加，而同义词未出现明显变化。

Conclusion: 研究指出LLMs可能正在引发人类语言使用的显著变化，但尚不能确定这是自然语言演化还是AI驱动的现象，也引发了模型伦理影响的担忧。

Abstract: In recent years, written language, particularly in science and education, has
undergone remarkable shifts in word usage. These changes are widely attributed
to the growing influence of Large Language Models (LLMs), which frequently rely
on a distinct lexical style. Divergences between model output and target
audience norms can be viewed as a form of misalignment. While these shifts are
often linked to using Artificial Intelligence (AI) directly as a tool to
generate text, it remains unclear whether the changes reflect broader changes
in the human language system itself. To explore this question, we constructed a
dataset of 22.1 million words from unscripted spoken language drawn from
conversational science and technology podcasts. We analyzed lexical trends
before and after ChatGPT's release in 2022, focusing on commonly LLM-associated
words. Our results show a moderate yet significant increase in the usage of
these words post-2022, suggesting a convergence between human word choices and
LLM-associated patterns. In contrast, baseline synonym words exhibit no
significant directional shift. Given the short time frame and the number of
words affected, this may indicate the onset of a remarkable shift in language
use. Whether this represents natural language change or a novel shift driven by
AI exposure remains an open question. Similarly, although the shifts may stem
from broader adoption patterns, it may also be that upstream training
misalignments ultimately contribute to changes in human language use. These
findings parallel ethical concerns that misaligned models may shape social and
moral beliefs.

</details>


### [99] [Integrating clinical reasoning into large language model-based diagnosis through etiology-aware attention steering](https://arxiv.org/abs/2508.00285)
*Peixian Li,Yu Tian,Ruiqi Tu,Chengkai Wu,Jingjing Ren,Jingsong Li*

Main category: cs.CL

TL;DR: 提出一种病因感知注意力框架，提高大型语言模型在临床诊断中的准确性和推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在复杂临床场景中诊断可靠性有限的问题，增强其诊断准确性与临床推理能力。

Method: 构建基于临床指南的临床推理框架(CRS)，设计病因感知头部识别算法，并通过推理引导的参数高效微调方法校准模型推理。

Result: 在诊断数据集上提升平均诊断准确性15.65％，推理焦点得分提升31.6%。外部验证和频率评估显示模型在复杂场景下更可靠。

Conclusion: 通过整合结构化临床推理，本研究提出了一个构建可解释、高可靠AI诊断系统的有效范式。

Abstract: Objective: Large Language Models (LLMs) demonstrate significant capabilities
in medical text understanding and generation. However, their diagnostic
reliability in complex clinical scenarios remains limited. This study aims to
enhance LLMs' diagnostic accuracy and clinical reasoning ability. Method: We
propose an Etiology-Aware Attention Steering Framework to integrate structured
clinical reasoning into LLM-based diagnosis. Specifically, we first construct
Clinical Reasoning Scaffolding (CRS) based on authoritative clinical guidelines
for three representative acute abdominal emergencies: acute appendicitis, acute
pancreatitis, and acute cholecystitis. Next, we develop the Etiology-Aware Head
Identification algorithm to pinpoint attention heads crucial for the model's
etiology reasoning. To ensure reliable clinical reasoning alignment, we
introduce the Reasoning-Guided Parameter-Efficient Fine-tuning that embeds
etiological reasoning cues into input representations and steers the selected
Etiology-Aware Heads toward critical information through a Reasoning-Guided
Loss function. Result: On the Consistent Diagnosis Cohort, our framework
improves average diagnostic accuracy by 15.65% and boosts the average Reasoning
Focus Score by 31.6% over baselines. External validation on the Discrepant
Diagnosis Cohort further confirms its effectiveness in enhancing diagnostic
accuracy. Further assessments via Reasoning Attention Frequency indicate that
our models exhibit enhanced reliability when faced with real-world complex
scenarios. Conclusion: This study presents a practical and effective approach
to enhance clinical reasoning in LLM-based diagnosis. By aligning model
attention with structured CRS, the proposed framework offers a promising
paradigm for building more interpretable and reliable AI diagnostic systems in
complex clinical settings.

</details>


### [100] [Systematic Evaluation of Optimization Techniques for Long-Context Language Models](https://arxiv.org/abs/2508.00305)
*Ammar Ahmed,Sheng Di,Franck Cappello,Zirui Liu,Jingoo Han,Ali Anwar*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）的优化方法在长上下文任务中的表现，并系统性分析各种优化方法及其组合对性能和生成质量的影响。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的广泛应用，其对资源的高需求及有限的上下文窗口成为重要问题。本研究旨在通过分析多种优化技术，探讨应对这些挑战的方法并优化模型的效率与表现。

Method: 系统性地评估修剪、量化、token丢弃等优化方法的单独表现，以及其组合在不同性能指标上的影响。同时，在较大规模的70亿参数模型上研究这些方法的可扩展性，并结合任务分析与系统配置探索效率与准确性的权衡。

Result: 研究揭示了优化方法的简单组合可能会因近似误差的叠加而对较大模型产生负面影响。此外，在QA任务中单独依赖F1可能掩盖精度-召回率的权衡，通过系统级分析提供了新的洞见。

Conclusion: 分析表明，优化大型语言模型需要结合任务需求和硬件配置，在效率、精度和扩展性之间取得平衡，为LLMs研究者和实践者提供实用参考。

Abstract: Large language models (LLMs) excel across diverse natural language processing
tasks but face resource demands and limited context windows. Although
techniques like pruning, quantization, and token dropping can mitigate these
issues, their efficacy in long-context scenarios and system evaluation remains
underexplored. This paper systematically benchmarks these optimizations,
characterizing memory usage, latency, and throughput, and studies how these
methods impact the quality of text generation. We first analyze individual
optimization methods for two LLM architectures supporting long context and then
systematically evaluate combinations of these techniques to assess how this
deeper analysis impacts performance metrics. We subsequently study the
scalability of individual optimization methods on a larger variant with 70
billion-parameter model. Our novel insights reveal that naive combination
inference optimization algorithms can adversely affect larger models due to
compounded approximation errors, as compared to their smaller counterparts.
Experiments show that relying solely on F1 obscures these effects by hiding
precision-recall trade-offs in question answering tasks. By integrating
system-level profiling with task-specific insights, this study helps LLM
practitioners and researchers explore and balance efficiency, accuracy, and
scalability across tasks and hardware configurations.

</details>


### [101] [Improving Multimodal Contrastive Learning of Sentence Embeddings with Object-Phrase Alignment](https://arxiv.org/abs/2508.00332)
*Kaiyan Zhao,Zhongtao Miao,Yoshimasa Tsuruoka*

Main category: cs.CL

TL;DR: MCSEO方法通过增强多模态中对象与短语的对齐，提高了句子嵌入的表现，并优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 目前多模态句子嵌入模型在训练时使用的图像-文字对可能存在噪声，如多余或无关的信息，这导致表现潜在受限。

Method: 提出MCSEO方法，利用现有的分割和目标检测模型提取精确的对象-短语对齐数据，并结合图像-文字对齐优化经过改进的对比学习目标。

Result: 在语义文本相似性（STS）任务上，MCSEO在不同骨干模型中均性能优越，显著超过强基准模型。

Conclusion: 精确的对象-短语对齐在多模态表示学习中表现出决定性的重要性。

Abstract: Multimodal sentence embedding models typically leverage image-caption pairs
in addition to textual data during training. However, such pairs often contain
noise, including redundant or irrelevant information on either the image or
caption side. To mitigate this issue, we propose MCSEO, a method that enhances
multimodal sentence embeddings by incorporating fine-grained object-phrase
alignment alongside traditional image-caption alignment. Specifically, MCSEO
utilizes existing segmentation and object detection models to extract accurate
object-phrase pairs, which are then used to optimize a contrastive learning
objective tailored to object-phrase correspondence. Experimental results on
semantic textual similarity (STS) tasks across different backbone models
demonstrate that MCSEO consistently outperforms strong baselines, highlighting
the significance of precise object-phrase alignment in multimodal
representation learning.

</details>


### [102] [PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning](https://arxiv.org/abs/2508.00344)
*Keer Lu,Chong Chen,Bin Cui,Huang Leng,Wentao Zhang*

Main category: cs.CL

TL;DR: 本文提出了一个新的基于自适应全局计划的代理范式AdaPlan，以及支持其训练的PilotRL框架，以解决复杂任务中的长期决策问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在LLM中的代理任务中存在长期规划能力不足和泛化能力限制的问题。

Method: 引入AdaPlan代理范式结合PilotRL训练框架，利用逐步强化学习开发对全局计划的跟随能力，并协调规划与执行。

Result: PilotRL在实验中表现优异，LLaMA3.1-8B-Instruct + PilotRL超过GPT-4o 3.60%，相比GPT-4o-mini 提升55.78%。

Conclusion: 该方法显著提升了复杂任务的长期规划与决策性能，为LLM代理任务提供了一种有效的新方案。

Abstract: Large Language Models (LLMs) have shown remarkable advancements in tackling
agent-oriented tasks. Despite their potential, existing work faces challenges
when deploying LLMs in agent-based environments. The widely adopted agent
paradigm ReAct centers on integrating single-step reasoning with immediate
action execution, which limits its effectiveness in complex tasks requiring
long-term strategic planning. Furthermore, the coordination between the planner
and executor during problem-solving is also a critical factor to consider in
agent design. Additionally, current approaches predominantly rely on supervised
fine-tuning, which often leads models to memorize established task completion
trajectories, thereby restricting their generalization ability when confronted
with novel problem contexts. To address these challenges, we introduce an
adaptive global plan-based agent paradigm AdaPlan, aiming to synergize
high-level explicit guidance with execution to support effective long-horizon
decision-making. Based on the proposed paradigm, we further put forward
PilotRL, a global planning-guided training framework for LLM agents driven by
progressive reinforcement learning. We first develop the model's ability to
follow explicit guidance from global plans when addressing agent tasks.
Subsequently, based on this foundation, we focus on optimizing the quality of
generated plans. Finally, we conduct joint optimization of the model's planning
and execution coordination. Experiments indicate that PilotRL could achieve
state-of-the-art performances, with LLaMA3.1-8B-Instruct + PilotRL surpassing
closed-sourced GPT-4o by 3.60%, while showing a more substantial gain of 55.78%
comparing to GPT-4o-mini at a comparable parameter scale.

</details>


### [103] [Lucy: edgerunning agentic web search on mobile with machine generated task vectors](https://arxiv.org/abs/2508.00360)
*Alan Dao,Dinh Bach Vu,Alex Nguyen,Norapat Buppodom*

Main category: cs.CL

TL;DR: 此论文提出了一种新的范式，将模型的内部推理视为动态任务向量机，并开发了一种优化方法，使小型语言模型在知识密集型任务中达到与大型模型相媲美的水平。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型由于容量限制，在知识密集型任务中表现受限，作者希望通过动态推理机制克服这一局限性。

Method: 提出一种将模型内部推理视为动态任务向量机的方法，并通过RLVR优化此过程。另外，训练了一个具有代理功能的网络搜索模型，并集成了MCP机制。

Result: 开发的1.7B参数的小型语言模型Lucy在SimpleQA基准测试中达到了78.3%正确率，与更大型模型DeepSeek-V3表现相近。

Conclusion: 小型语言模型通过结构化和自构建的任务推理能够接近甚至媲美大型模型的性能，从而突破了容量限制。

Abstract: Small language models (SLMs) are inherently limited in knowledge-intensive
tasks due to their constrained capacity. While test-time computation offers a
path to enhanced performance, most approaches treat reasoning as a fixed or
heuristic process. In this work, we propose a new paradigm: viewing the model's
internal reasoning, delimited by <think> and </think> tags, as a dynamic task
vector machine. Rather than treating the content inside these tags as a mere
trace of thought, we interpret the generation process itself as a mechanism
through which the model \textbf{constructs and refines its own task vectors} on
the fly. We developed a method to optimize this dynamic task vector machine
through RLVR and successfully trained an agentic web-search model. We present
Lucy, a 1.7B-parameter SLM that leverages this dynamic reasoning mechanism with
MCP integration to achieve 78.3% accuracy on the SimpleQA benchmark, performing
on par with much larger models such as DeepSeek-V3. This demonstrates that
small models can rival large ones when equipped with structured,
self-constructed task reasoning.

</details>


### [104] [EdgeInfinite-Instruct: Bridging SFT-Based Optimization and NPU-Level Efficiency for Edge Devices](https://arxiv.org/abs/2508.00370)
*Jiyu Chen,Poh Seng Lim,Shuang Peng,Daxiong Luo,JungHau Foo,Yap Deep,Timothy Lee Jun Jie,Kelvin Teh Kae Wen,Fan Yang,Danyu Feng,Hao-Yun Chen,Peng-Wen Chen,Fangyuan Li,Xiaoxin Chen,Wong Wai Mun*

Main category: cs.CL

TL;DR: 提出EdgeInfinite-Instruct，通过改进后训练量化和固定形状计算图优化模型，在移动边缘NPU上取得高效性能。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer模型在长序列任务中资源开销大、TTFT长等问题，同时提升其指令跟随能力和设备优化兼容性。

Method: 通过分段监督微调（S-SFT）策略，结合后训练量化（PTQ）和固定形状计算图设计提升模型性能与适配度。

Result: 在长上下文基准测试与实际移动任务中，EdgeInfinite-Instruct实现领域性能提升及边缘NPU设备高效运算。

Conclusion: EdgeInfinite-Instruct通过优化策略成功改进了模型效能及使用体验，为资源受限设备上的长序列任务提供有效解决方案。

Abstract: Deploying Transformer-based large language models (LLMs) on
resource-constrained edge devices for long-sequence tasks remains challenging
due to the quadratic time complexity of self-attention and growing Key-Value
(KV) cache demands. While existing KV cache optimizations improve memory
efficiency, they often fail to reduce time to first token (TTFT) and may
degrade performance through token pruning. Alternative sequence modeling
architectures address some of these limitations, but typically require full
retraining and lack infrastructure support. EdgeInfinite offers an efficient
solution by fine-tuning only a small subset of parameters, maintaining quality
while reducing both computational and memory costs, including improved TTFT.
However, its instruction-following ability is limited, and it lacks
mobile-specific optimizations. To address these issues, we propose
EdgeInfinite-Instruct, which introduces a Segmented Supervised Fine-Tuning
(S-SFT) strategy tailored to long-sequence tasks such as summarization and
question answering. We further optimized EdgeInfinite-Instruct for efficient
deployment on edge NPUs by employing fine-grained post-training quantization
(PTQ) to reduce computational demands while maintaining accuracy, and by
implementing a fixed-shape computation graph that balances memory usage and
on-device efficiency through scenario-specific customization of input token and
cache sizes. Experiments on long-context benchmarks and real-world mobile tasks
show that our approach improves domain-specific performance while maintaining
efficiency on NPU-accelerated edge devices.

</details>


### [105] [Multi-Layer Attention is the Amplifier of Demonstration Effectiveness](https://arxiv.org/abs/2508.00385)
*Dingzirui Wang,Xuangliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 该论文研究了演示效果不佳的原因，并提出了基于梯度流的GradS方法用于改进演示选择，验证了其在多层大语言模型中的优势，实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要假设提供的演示是有效的，但实际中并非所有演示都对性能有帮助，该研究旨在深入分析导致演示无效的原因。

Method: 以梯度流和线性自注意力模型为基础，通过设置梯度流为零，推导演示无效的条件，提出了基于梯度流的GradS方法用于演示选择。

Result: 实验在五个主流数据集和四个大语言模型上进行，结果表明：1. 随着模型层数增加，演示效果差异被放大；2. GradS方法平均提升了6.8%的性能。

Conclusion: 研究揭示了演示无效的内在机制，并通过设计GradS方法有效提升了大语言模型的演示选择性能，为相关领域研究提供了新思路。

Abstract: Numerous studies have investigated the underlying mechanisms of in-context
learning (ICL) effectiveness to inspire the design of related methods. However,
existing work predominantly assumes the effectiveness of the demonstrations
provided within ICL, while many research indicates that not all demonstrations
are effective, failing to yielding any performance improvement during ICL.
Therefore, in this paper, we investigate the reasons behind demonstration
ineffectiveness. Our analysis is based on gradient flow and linear
self-attention models. By setting the gradient flow to zero, we deduce that a
demonstration becomes ineffective if its information has either been learned by
the model or is irrelevant to the user query. Furthermore, we demonstrate that
in multi-layer models, the disparity in effectiveness among demonstrations is
amplified with layer increasing, causing the model to focus more on effective
ones. Considering that current demonstration selection methods primarily focus
on the relevance to the user query while overlooking the information that the
model has already assimilated, we propose a novel method called GradS, which
leverages gradient flow for demonstration selection. We use the magnitude of
the gradient flow of the demonstration with respect to a given user query as
the criterion, thereby ensuring the effectiveness of the chosen ones. We
validate our derivation and GradS on four prominent LLMs across five mainstream
datasets. The experimental results confirm that the disparity in effectiveness
among demonstrations is magnified as the model layer increases, substantiating
our derivations. Moreover, GradS achieves a relative improvement of $6.8\%$ on
average over the strongest baselines, demonstrating its effectiveness.

</details>


### [106] [SA-GCS: Semantic-Aware Gaussian Curriculum Scheduling for UAV Vision-Language Navigation](https://arxiv.org/abs/2508.00390)
*Hengxing Cai,Jinhan Dong,Yijie Rao,Jingcheng Deng,Jingjun Tan,Qien Chen,Haidong Wang,Zhen Wang,Shiyu Huang,Agachai Sumalee,Renxin Zhong*

Main category: cs.CL

TL;DR: 本文提出了一种新的UAV视觉语言导航训练框架SA-GCS，通过语义感知困难估计器和高斯课程调度器提高效率、收敛速度和模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前RL方法在UAV视觉语言导航中使用训练数据效率低、收敛慢以及对训练样本困难变化考虑不足的挑战。

Method: 设计一个语义感知困难估计器（SA-DE）来量化训练样本难度，并通过高斯课程调度器（GCS）动态调整采样分布，实现从易到难任务的平滑过渡。

Result: 在CityNav基准测试中，SA-GCS在所有指标上均优于强基线，收敛更快且表现更稳定，并能跨不同规模模型良好泛化。

Conclusion: SA-GCS框架显著提升了UAV视觉语言导航任务的训练效率、收敛速度以及模型的整体性能，展现出鲁棒性和可扩展性，并公开了该方法的实施代码。

Abstract: Unmanned Aerial Vehicle (UAV) Vision-Language Navigation (VLN) aims to enable
agents to accurately localize targets and plan flight paths in complex
environments based on natural language instructions, with broad applications in
intelligent inspection, disaster rescue, and urban monitoring. Recent progress
in Vision-Language Models (VLMs) has provided strong semantic understanding for
this task, while reinforcement learning (RL) has emerged as a promising
post-training strategy to further improve generalization. However, existing RL
methods often suffer from inefficient use of training data, slow convergence,
and insufficient consideration of the difficulty variation among training
samples, which limits further performance improvement. To address these
challenges, we propose \textbf{Semantic-Aware Gaussian Curriculum Scheduling
(SA-GCS)}, a novel training framework that systematically integrates Curriculum
Learning (CL) into RL. SA-GCS employs a Semantic-Aware Difficulty Estimator
(SA-DE) to quantify the complexity of training samples and a Gaussian
Curriculum Scheduler (GCS) to dynamically adjust the sampling distribution,
enabling a smooth progression from easy to challenging tasks. This design
significantly improves training efficiency, accelerates convergence, and
enhances overall model performance. Extensive experiments on the CityNav
benchmark demonstrate that SA-GCS consistently outperforms strong baselines
across all metrics, achieves faster and more stable convergence, and
generalizes well across models of different scales, highlighting its robustness
and scalability. The implementation of our approach is publicly available.

</details>


### [107] [Combining Discrete Wavelet and Cosine Transforms for Efficient Sentence Embedding](https://arxiv.org/abs/2508.00420)
*Rana Salama,Abdou Youssef,Mona Diab*

Main category: cs.CL

TL;DR: 文章探讨了小波技术在自然语言处理中的应用，通过将离散小波变换与词和句子的嵌入进行整合，提出了一种非参数化模型，有效压缩句子信息并优化任务表现。


<details>
  <summary>Details</summary>
Motivation: 小波已被证明在图像与信号处理上效果显著，该研究希望探索其在自然语言处理中捕捉语言特性方面的潜力。

Method: 利用离散小波变换对词向量进行降维与信息整合，同时结合离散余弦变换，提出一种非参数模型以压缩句子到固定大小向量中。

Result: 实验表明，提出的方法在多个下游任务中表现与原始嵌入相当甚至在某些任务上更优。

Conclusion: 小波技术通过结合词和句子的嵌入处理，为自然语言处理中的信息整合和任务表现优化提出了一种高效途径。

Abstract: Wavelets have emerged as a cutting edge technology in a number of fields.
Concrete results of their application in Image and Signal processing suggest
that wavelets can be effectively applied to Natural Language Processing (NLP)
tasks that capture a variety of linguistic properties. In this paper, we
leverage the power of applying Discrete Wavelet Transforms (DWT) to word and
sentence embeddings. We first evaluate, intrinsically and extrinsically, how
wavelets can effectively be used to consolidate important information in a word
vector while reducing its dimensionality. We further combine DWT with Discrete
Cosine Transform (DCT) to propose a non-parameterized model that compresses a
sentence with a dense amount of information in a fixed size vector based on
locally varying word features. We show the efficacy of the proposed paradigm on
downstream applications models yielding comparable and even superior (in some
tasks) results to original embeddings.

</details>


### [108] [ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network](https://arxiv.org/abs/2508.00429)
*Minghao Guo,Xi Zhu,Jingyuan Huang,Kai Mei,Yongfeng Zhang*

Main category: cs.CL

TL;DR: 该论文提出了一种新的图神经网络框架ReaGAN，通过自主节点决策和全局语义关系建模，改善了信息传播中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统图神经网络存在信息不均衡和忽略图中远距离但相关信息的问题，导致其学习能力受限。

Method: 提出了一种名为ReaGAN的模型，结合节点行为自主规划和检索增强生成，用以自适应消息传播和全局语义关系建模。

Result: ReaGAN在使用冻结的大语言模型（LLM）主干且无需微调的情况下，在少样本上下文环境中表现出竞争力。

Conclusion: 结果表明，代理式规划和局部-全局检索在图学习中的应用具有巨大潜力。

Abstract: Graph Neural Networks (GNNs) have achieved remarkable success in graph-based
learning by propagating information among neighbor nodes via predefined
aggregation mechanisms. However, such fixed schemes often suffer from two key
limitations. First, they cannot handle the imbalance in node informativeness --
some nodes are rich in information, while others remain sparse. Second,
predefined message passing primarily leverages local structural similarity
while ignoring global semantic relationships across the graph, limiting the
model's ability to capture distant but relevant information. We propose
Retrieval-augmented Graph Agentic Network (ReaGAN), an agent-based framework
that empowers each node with autonomous, node-level decision-making. Each node
acts as an agent that independently plans its next action based on its internal
memory, enabling node-level planning and adaptive message propagation.
Additionally, retrieval-augmented generation (RAG) allows nodes to access
semantically relevant content and build global relationships in the graph.
ReaGAN achieves competitive performance under few-shot in-context settings
using a frozen LLM backbone without fine-tuning, showcasing the potential of
agentic planning and local-global retrieval in graph learning.

</details>


### [109] [Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges](https://arxiv.org/abs/2508.00454)
*Yuqi Tang,Kehua Feng,Yunfeng Wang,Zhiwen Chen,Chengfei Lv,Gang Yu,Qiang Zhang,Keyan Ding*

Main category: cs.CL

TL;DR: 该研究提出了一种高效的对话评估方法，以替代现有的多模型评判方法，同时保留多模型反馈的优点。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型对话评估方法存在偏差问题，多模型评判虽有效，但计算开销大。

Method: 设计了一种将多个语言模型偏好整合到单一模型中的方法，用于高效的多轮对话评价。

Result: 在七个单项评分和成对比较的对话评估基准上，该方法表现优于现有方法，显示了效率与鲁棒性的提升。

Conclusion: 提出的方法实现了快速灵活的对话质量评估，克服了传统方法的偏差与高计算开销问题。

Abstract: Evaluating the conversational abilities of large language models (LLMs)
remains a challenging task. Current mainstream approaches primarily rely on the
``LLM-as-a-judge" paradigm, where an LLM is prompted to serve as an evaluator
to assess dialogue quality. However, such methods often suffer from various
biases, which undermine the reliability and consistency of the evaluation
results. To mitigate these biases, recent methods employ multiple LLMs as
judges and aggregate their judgments to select the optimal assessment. Although
effective, this multi-judge approach incurs significant computational overhead
during inference. In this paper, we propose an efficient multi-turn dialogue
evaluator that captures the collective wisdom of multiple LLM judges by
aggregating their preference knowledge into a single model. Our approach
preserves the advantages of diverse multi-judge feedback while drastically
reducing the evaluation cost, enabling fast and flexible dialogue quality
assessment. Extensive experiments on seven single rating and pairwise
comparison dialogue evaluation benchmarks demonstrate that our method
outperforms existing baselines across diverse scenarios, showcasing its
efficiency and robustness.

</details>


### [110] [GETALP@AutoMin 2025: Leveraging RAG to Answer Questions based on Meeting Transcripts](https://arxiv.org/abs/2508.00476)
*Jeongwoo Kang,Markarit Vartampetian,Felix Herron,Yongxin Zhou,Diandra Fabre,Gabriela Gonzalez-Saez*

Main category: cs.CL

TL;DR: 本文介绍了GETALP在SIGDial 2025自动会议记录任务第三次挑战中所提交的方案，结合RAG与AMR方法进行问答任务。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用RAG和AMR技术改进基于会议记录的问答质量。

Method: 提出三种结合RAG与AMR的方法，用以回答会议记录中的问题，特别关注区分参与者身份的能力。

Result: AMR的引入提高了约35%问题的回答质量，尤其是在区分不同参与者的问题中表现显著提升。

Conclusion: 结合AMR技术在问答任务中特别是细化参与者信息的问题上具有显著优势。

Abstract: This paper documents GETALP's submission to the Third Run of the Automatic
Minuting Shared Task at SIGDial 2025. We participated in Task B:
question-answering based on meeting transcripts. Our method is based on a
retrieval augmented generation (RAG) system and Abstract Meaning
Representations (AMR). We propose three systems combining these two approaches.
Our results show that incorporating AMR leads to high-quality responses for
approximately 35% of the questions and provides notable improvements in
answering questions that involve distinguishing between different participants
(e.g., who questions).

</details>


### [111] [The Missing Parts: Augmenting Fact Verification with Half-Truth Detection](https://arxiv.org/abs/2508.00489)
*Yixuan Tang,Jincheng Wang,Anthony K. H. Tung*

Main category: cs.CL

TL;DR: 本文提出了一个新的事实验证任务——半真相检测，并介绍了PolitiFact-Hidden数据集和TRACER框架，以解决由于省略关键上下文而产生的误导性信息问题。


<details>
  <summary>Details</summary>
Motivation: 现有的事实验证系统无法应对省略重要信息而导致的误导性半真相声明。

Method: 提出了PolitiFact-Hidden数据集和TRACER框架，分别用于标注政治声明的数据集以及用于识别省略信息的模块化再评估框架。

Result: TRACER显著提升了半真相分类的性能，F1分数提高了最多16个百分点。

Conclusion: 通过建模省略信息可以显著改善事实验证的可信度与表现。

Abstract: Fact verification systems typically assess whether a claim is supported by
retrieved evidence, assuming that truthfulness depends solely on what is
stated. However, many real-world claims are half-truths, factually correct yet
misleading due to the omission of critical context. Existing models struggle
with such cases, as they are not designed to reason about what is left unsaid.
We introduce the task of half-truth detection, and propose PolitiFact-Hidden, a
new benchmark with 15k political claims annotated with sentence-level evidence
alignment and inferred claim intent. To address this challenge, we present
TRACER, a modular re-assessment framework that identifies omission-based
misinformation by aligning evidence, inferring implied intent, and estimating
the causal impact of hidden content. TRACER can be integrated into existing
fact-checking pipelines and consistently improves performance across multiple
strong baselines. Notably, it boosts Half-True classification F1 by up to 16
points, highlighting the importance of modeling omissions for trustworthy fact
verification.

</details>


### [112] [EFlat-LoRA: Efficiently Seeking Flat Minima for Better Generalization in Fine-Tuning Large Language Models and Beyond](https://arxiv.org/abs/2508.00522)
*Jiaxin Deng,Qingcheng Zhu,Junbiao Pang,Linlin Yang,Zhongqian Fu,Baochang Zhang*

Main category: cs.CL

TL;DR: 本文提出了Flat-LoRA及其高效版本EFlat-LoRA，旨在低秩适配（LoRA）中寻找平坦最小值以提升广义化能力，并通过大规模语言模型和视觉语言模型的实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 研究低秩适配（LoRA）中表达能力与广义化能力之间的关系，探讨LoRA的广义化与锐度之间的关联，这一问题此前未被深入研究。

Method: 从理论上证明了在全参数空间中的扰动可转移至低秩子空间，同时提出Flat-LoRA及其高效版EFlat-LoRA，避免了低秩子空间内多矩阵扰动的潜在干扰。

Result: EFlat-LoRA在多个实验中展现了与LoRA相当或更优的性能，例如在GLUE数据集上，比LoRA和全参数微调分别高出1.0%和0.5%；在Qwen-VL-Chat等视觉语言模型中，在SQA与VizWiz数据集上性能提高了1.5%和1.0%。

Conclusion: 研究表明LoRA的广义化与锐度密切相关，提出的Flat-LoRA方法在提升模型广义化的同时保持优化效率。

Abstract: Little research explores the correlation between the expressive ability and
generalization ability of the low-rank adaptation (LoRA). Sharpness-Aware
Minimization (SAM) improves model generalization for both Convolutional Neural
Networks (CNNs) and Transformers by encouraging convergence to locally flat
minima. However, the connection between sharpness and generalization has not
been fully explored for LoRA due to the lack of tools to either empirically
seek flat minima or develop theoretical methods. In this work, we propose
Flat-LoRA and its efficient version i.e., EFlat-LoRA, to seek flat minima for
LoRA. Concretely, we theoretically demonstrate that perturbations in the full
parameter space can be transferred to the low-rank subspace. This approach
eliminates the potential interference introduced by perturbations across
multiple matrices in the low-rank subspace. Our extensive experiments on large
language models and vision-language models demonstrate that EFlat-LoRA achieves
optimize efficiency comparable to that of LoRA while simultaneously attaining
comparable or even better performance. For example, on the GLUE dataset with
RoBERTa-large, EFlat-LoRA outperforms LoRA and full fine-tuning by 1.0% and
0.5% on average, respectively. On vision-language models e.g., Qwen-VL-Chat
shows performance improvements of 1.5% and 1.0% on SQA and VizWiz datasets,
respectively. These empirical results also verify that the generalization of
LoRA is closely related to sharpness, which is omitted by previous methods.

</details>


### [113] [The Prosody of Emojis](https://arxiv.org/abs/2508.00537)
*Giulio Zhou,Tsz Kin Lam,Alexandra Birch,Barry Haddow*

Main category: cs.CL

TL;DR: 本研究探讨了表情符号如何影响语音中的韵律特征以及听众如何通过韵律理解其意图。


<details>
  <summary>Details</summary>
Motivation: 由于文本环境中缺乏语调、节奏等特征，表情符号被当作一种替代，丰富情感和语用意义。

Method: 通过以真人语音为基础的生产与感知任务收集数据，从而直接将韵律特征与表情符号关联。

Result: 结果显示说话者会基于表情符号调整语音韵律，听众也能够通过韵律辨别意图表情符号，且表情符号之间语义差异越大，其韵律变化也越显著。

Conclusion: 表情符号可作为韵律意图的载体，揭示了其在数字化交流中的重要作用。

Abstract: Prosodic features such as pitch, timing, and intonation are central to spoken
communication, conveying emotion, intent, and discourse structure. In
text-based settings, where these cues are absent, emojis act as visual
surrogates that add affective and pragmatic nuance. This study examines how
emojis influence prosodic realisation in speech and how listeners interpret
prosodic cues to recover emoji meanings. Unlike previous work, we directly link
prosody and emoji by analysing actual human speech data, collected through
structured but open-ended production and perception tasks. This provides
empirical evidence of how emoji semantics shape spoken delivery and perception.
Results show that speakers adapt their prosody based on emoji cues, listeners
can often identify the intended emoji from prosodic variation alone, and
greater semantic differences between emojis correspond to increased prosodic
divergence. These findings suggest that emojis can act as meaningful carriers
of prosodic intent, offering insight into their communicative role in digitally
mediated contexts.

</details>


### [114] [PaPaformer: Language Model from Pre-trained Paraller Paths](https://arxiv.org/abs/2508.00544)
*Joonas Tapaninaho,Mourad Oussala*

Main category: cs.CL

TL;DR: 该论文提出了一种名为PaPaformer的解码器-仅变压器架构变体，能够大幅缩减语言模型的训练时间，并允许模型个性化调整以适应特定任务。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型训练需耗费巨大计算资源和时间的问题，使得小型语言模型也能快速高效完成训练。

Method: 提出了一种基于低维并行路径的解码器-仅变压器架构PaPaformer，允许单独训练不同路径的数据并将其合并为一个大模型。

Result: 实验表明该方法能减少模型参数与训练时间，同时提高性能。

Conclusion: PaPaformer不仅加快了语言模型的训练速度，还通过并行路径结构提供了定制化的可能性，未来可广泛应用于特定任务的语言模型开发。

Abstract: The training of modern large-language models requires an increasingly amount
of computation power and time. Even smaller variants, such as small-language
models (SLMs), take several days to train in the best-case scenarios, often
requiring multiple GPUs. This paper explores methods to train and evaluate
decoder-only transformer-based language models in hours instead of days/weeks.
We introduces \textit{PaPaformer}, a decoder-only transformer architecture
variant, whose lower-dimensional parallel paths are combined into larger model.
The paper shows that these lower-dimensional paths can be trained individually
with different types of training data and then combined into one larger model.
This method gives the option to reduce the total number of model parameters and
the training time with increasing performance. Moreover, the use of parallel
path structure opens interesting possibilities to customize paths to
accommodate specific task requirements.

</details>


### [115] [SynAdapt: Learning Adaptive Reasoning in Large Language Models via Synthetic Continuous Chain-of-Thought](https://arxiv.org/abs/2508.00574)
*Jianwei Wang,Ziming Wu,Fuming Lai,Shaobing Lian,Ziqian Zeng*

Main category: cs.CL

TL;DR: 提出SynAdapt框架，通过生成合成连续的链式推理（CCoT）和适应性重思策略，提升推理精度与效率。


<details>
  <summary>Details</summary>
Motivation: 现有离散链式推理方法时间消耗大，连续链式推理虽然高效但存在调优间接性和目标不一致的问题。

Method: 设计SynAdapt框架，生成合成CCoT作为对齐目标，通过难度分类器识别复杂问题并适配性地再次思考。

Result: 在不同难度基准上的实验结果表明，该方法在准确性与效率之间达到了最佳平衡。

Conclusion: SynAdapt通过改进的CCoT生成与难度分类策略有效解决了性能与效率的权衡问题。

Abstract: While Chain-of-Thought (CoT) reasoning improves model performance, it incurs
significant time costs due to the generation of discrete CoT tokens (DCoT).
Continuous CoT (CCoT) offers a more efficient alternative, but existing CCoT
methods are hampered by indirect fine-tuning, limited alignment, or
inconsistent targets. To overcome these limitations, we propose
\textit{SynAdapt}, an innovative efficient reasoning framework. Specifically,
\textit{SynAdapt} generates the synthetic CCoT to serve as a precise and
effective alignment target for LLMs. This synthetic CCoT explicitly guides the
LLM to learn CCoT and derive accurate answers directly. Furthermore, relying
solely on CCoT is insufficient for solving hard questions. To address this,
\textit{SynAdapt} integrates a difficulty classifier that leverages both
question context and CCoT to identify hard questions. CCoT can effectively help
identify hard questions after some brief reasoning. We then adaptively prompt
the LLM to re-think these hard questions for improved performance. Extensive
experimental results across various benchmarks from different difficulty levels
strongly demonstrate the effectiveness of our method, achieving the best
accuracy-efficiency trade-off.

</details>


### [116] [NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts](https://arxiv.org/abs/2502.18148)
*Muhammad Farid Adilazuarda,Musa Izzanardi Wijanarko,Lucky Susanto,Khumaisa Nur'aini,Derry Wijaya,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 本文提出NusaAksara，这是一个融合印尼语言及原始文字脚本的公共基准数据集，用于OCR、翻译等多任务研究。


<details>
  <summary>Details</summary>
Motivation: 在现有NLP技术主要以拉丁化文本为主的情况下，扩大对低资源语言及其原始文字脚本的研究。

Method: 通过专家精心构建的8种脚本、7种语言的多模态数据集，建立并测试多种NLP模型和系统。

Result: 现有的NLP技术在处理印尼本地脚本时表现不佳，大多数情况下性能接近于零。

Conclusion: NusaAksara为研究多样化的印尼语言及文字提供了宝贵资源，但目前主流技术对此支持有限，需进一步改进。

Abstract: Indonesia is rich in languages and scripts. However, most NLP progress has
been made using romanized text. In this paper, we present NusaAksara, a novel
public benchmark for Indonesian languages that includes their original scripts.
Our benchmark covers both text and image modalities and encompasses diverse
tasks such as image segmentation, OCR, transliteration, translation, and
language identification. Our data is constructed by human experts through
rigorous steps. NusaAksara covers 8 scripts across 7 languages, including
low-resource languages not commonly seen in NLP benchmarks. Although
unsupported by Unicode, the Lampung script is included in this dataset. We
benchmark our data across several models, from LLMs and VLMs such as GPT-4o,
Llama 3.2, and Aya 23 to task-specific systems such as PP-OCR and LangID, and
show that most NLP technologies cannot handle Indonesia's local scripts, with
many achieving near-zero performance.

</details>


### [117] [A Context-Aware Dual-Metric Framework for Confidence Estimation in Large Language Models](https://arxiv.org/abs/2508.00600)
*Mingruo Yuan,Shuyi Zhang,Ben Kao*

Main category: cs.CL

TL;DR: 论文提出了一个名为CRUX的新框架，用于大语言模型的上下文相关置信度估计，并显著高于现有基准评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型置信估计方法忽略了输出与上下文信息的相关性，这对可靠性评估尤为重要，尤其是在存在背景知识的场景中。

Method: 提出了CRUX框架，包含两个新颖的指标：1. 上下文熵减少，通过对比有无上下文的采样方法表示数据不确定性。2. 统一一致性检查，通过检查答案在有无上下文情况下的一致性来表示模型潜在的不确定性。

Result: CRUX在三个基准数据集（CoQA, SQuAD, QuAC）和两个领域特定数据集（BioASQ, EduQG）上均取得了超过现有基线的最高AUROC。

Conclusion: 通过结合上下文真实性和全局一致性，CRUX框架有效提升了置信度估计性能，展示了在大语言模型中应用的潜力。

Abstract: Accurate confidence estimation is essential for trustworthy large language
models (LLMs) systems, as it empowers the user to determine when to trust
outputs and enables reliable deployment in safety-critical applications.
Current confidence estimation methods for LLMs neglect the relevance between
responses and contextual information, a crucial factor in output quality
evaluation, particularly in scenarios where background knowledge is provided.
To bridge this gap, we propose CRUX (Context-aware entropy Reduction and
Unified consistency eXamination), the first framework that integrates context
faithfulness and consistency for confidence estimation via two novel metrics.
First, contextual entropy reduction represents data uncertainty with the
information gain through contrastive sampling with and without context. Second,
unified consistency examination captures potential model uncertainty through
the global consistency of the generated answers with and without context.
Experiments across three benchmark datasets (CoQA, SQuAD, QuAC) and two
domain-specific datasets (BioASQ, EduQG) demonstrate CRUX's effectiveness,
achieving the highest AUROC than existing baselines.

</details>


### [118] [GHTM: A Graph based Hybrid Topic Modeling Approach in Low-Resource Bengali Language](https://arxiv.org/abs/2508.00605)
*Farhana Haque,Md. Abdur Rahman,Sumon Ahmed*

Main category: cs.CL

TL;DR: 提出了一个基于图卷积网络(GCN)的新型主题建模模型(GHTM)，在三个孟加拉语数据集上表现优异，并引入了新的数据集“NCTBText”。


<details>
  <summary>Details</summary>
Motivation: 尽管主题建模在英语文本处理上研究较多，但孟加拉语因形态复杂性和资源匮乏而研究不足。本研究旨在解决这一问题。

Method: 基于图卷积网络(GCN)进行文本嵌入，然后利用非负矩阵分解(NMF)生成主题表示，与多种传统与现代算法进行对比实验验证。

Result: GHTM模型在主题一致性和多样性上优于其他模型，并通过新数据集“NCTBText”扩展了数据多样性。

Conclusion: GCN与NMF基础上的GHTM模型能高效捕捉孟加拉语文本的潜在主题，具有显著的实用价值，可用于孟加拉语自然语言处理的更多场景。

Abstract: Topic modeling is a Natural Language Processing (NLP) technique that is used
to identify latent themes and extract topics from text corpora by grouping
similar documents based on their most significant keywords. Although widely
researched in English, topic modeling remains understudied in Bengali due to
its morphological complexity, lack of adequate resources and initiatives. In
this contribution, a novel Graph Convolutional Network (GCN) based model called
GHTM (Graph-Based Hybrid Topic Model) is proposed. This model represents input
vectors of documents as nodes in the graph, which GCN uses to produce
semantically rich embeddings. The embeddings are then decomposed using
Non-negative Matrix Factorization (NMF) to get the topical representations of
the underlying themes of the text corpus. This study compares the proposed
model against a wide range of Bengali topic modeling techniques, from
traditional methods such as LDA, LSA, and NMF to contemporary frameworks such
as BERTopic and Top2Vec on three Bengali datasets. The experimental results
demonstrate the effectiveness of the proposed model by outperforming other
models in topic coherence and diversity. In addition, we introduce a novel
Bengali dataset called "NCTBText" sourced from Bengali textbook materials to
enrich and diversify the predominantly newspaper-centric Bengali corpora.

</details>


### [119] [Prompting Science Report 3: I'll pay you or I'll kill you -- but will you care?](https://arxiv.org/abs/2508.00614)
*Lennart Meincke,Ethan Mollick,Lilach Mollick,Dan Shapiro*

Main category: cs.CL

TL;DR: 本文主要讨论针对AI模型的提示策略（小费与威胁）是否对其表现有意义影响。结论表明，这两种策略通常不会显著改善性能，而提示变化在个别问题上有影响但难以预料。


<details>
  <summary>Details</summary>
Motivation: 探讨常见提示策略如给予“奖励”或“威胁”是否能显著提高AI模型的表现，尤其是基于一些流传的实用建议与理论假设。

Method: 通过对两种类型的提示策略在GPQA和MMLU-Pro基准上的实验，评估其对模型性能的实际影响。

Result: 威胁或小费提示策略对整体的基准性能没有显著影响，但提示方式的细微变化可能对单一问题产生显著效果。

Conclusion: 简单的提示变化不像预期那样对困难问题有效，但仍可能对某些具体问题有较大的结果差异。

Abstract: This is the third in a series of short reports that seek to help business,
education, and policy leaders understand the technical details of working with
AI through rigorous testing. In this report, we investigate two commonly held
prompting beliefs: a) offering to tip the AI model and b) threatening the AI
model. Tipping was a commonly shared tactic for improving AI performance and
threats have been endorsed by Google Founder Sergey Brin (All-In, May 2025,
8:20) who observed that 'models tend to do better if you threaten them,' a
claim we subject to empirical testing here. We evaluate model performance on
GPQA (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024).
  We demonstrate two things:
  - Threatening or tipping a model generally has no significant effect on
benchmark performance.
  - Prompt variations can significantly affect performance on a per-question
level. However, it is hard to know in advance whether a particular prompting
approach will help or harm the LLM's ability to answer any particular question.
  Taken together, this suggests that simple prompting variations might not be
as effective as previously assumed, especially for difficult problems. However,
as reported previously (Meincke et al. 2025a), prompting approaches can yield
significantly different results for individual questions.

</details>


### [120] [DACTYL: Diverse Adversarial Corpus of Texts Yielded from Large Language Models](https://arxiv.org/abs/2508.00619)
*Shantanu Thorat,Andrew Caines*

Main category: cs.CL

TL;DR: 现有的AI生成文本检测器在实际应用中表现不佳。本研究提出了一个新的数据集——DACTYL，用于评估一拍/少拍生成的文本检测器，并发现许多现有检测器在该数据集上表现较差。而使用深度X风险优化（DXO）训练的模型在分布外数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的AIG文本检测器尽管在内部测试表现良好，但在实际使用中表现不佳，这表明它们可能缺乏鲁棒性。需要改进这些检测器以应对一拍/少拍生成以及领域特定模型生成的文本。

Method: 提出并构建了DACTYL数据集，专注于一拍/少拍生成的挑战性文本，同时引入领域特定训练模型。训练了两种分类器：标准BCE优化和基于深度X风险优化(DXO)的方法，评估其在分布外数据中的表现。

Result: 标准BCE训练的分类器在DACTYL测试集上表现略优，但DXO模型在分布外数据上表现更出色。在模拟学生论文检测的场景中，DXO分类器在低误报率下提高了50.56的macro-F1分数，与最佳BCE分类器相比。

Conclusion: DXO优化方法能够更好地进行泛化，避免过拟合于测试集，为现有AIG文本检测器提供改进方向。

Abstract: Existing AIG (AI-generated) text detectors struggle in real-world settings
despite succeeding in internal testing, suggesting that they may not be robust
enough. We rigorously examine the machine-learning procedure to build these
detectors to address this. Most current AIG text detection datasets focus on
zero-shot generations, but little work has been done on few-shot or one-shot
generations, where LLMs are given human texts as an example. In response, we
introduce the Diverse Adversarial Corpus of Texts Yielded from Language models
(DACTYL), a challenging AIG text detection dataset focusing on
one-shot/few-shot generations. We also include texts from domain-specific
continued-pre-trained (CPT) language models, where we fully train all
parameters using a memory-efficient optimization approach. Many existing AIG
text detectors struggle significantly on our dataset, indicating a potential
vulnerability to one-shot/few-shot and CPT-generated texts. We also train our
own classifiers using two approaches: standard binary cross-entropy (BCE)
optimization and a more recent approach, deep X-risk optimization (DXO). While
BCE-trained classifiers marginally outperform DXO classifiers on the DACTYL
test set, the latter excels on out-of-distribution (OOD) texts. In our mock
deployment scenario in student essay detection with an OOD student essay
dataset, the best DXO classifier outscored the best BCE-trained classifier by
50.56 macro-F1 score points at the lowest false positive rates for both. Our
results indicate that DXO classifiers generalize better without overfitting to
the test set. Our experiments highlight several areas of improvement for AIG
text detectors.

</details>


### [121] [Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement Techniques and Applications](https://arxiv.org/abs/2508.00669)
*Wenxuan Wang,Zizhan Ma,Meidan Ding,Shiyi Zheng,Shengyuan Liu,Jie Liu,Jiaming Ji,Wenting Chen,Xiang Li,Linlin Shen,Yixuan Yuan*

Main category: cs.CL

TL;DR: 文章探讨了医学领域中的大语言模型（LLMs），分析其在医疗推理中的应用与挑战，并提出未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 填补当前LLMs在医学推理中系统性和可验证性能力的不足，推动多步推理模型的研究。

Method: 提出一种分类法，涵盖训练阶段（如监督微调、强化学习）和测试阶段（如提示工程、多代理系统）在内的推理增强技术；分析其在不同数据模态及临床应用中的应用。

Result: 基于2022-2025年间的60项研究，综合评估LLMs在医学推理中的表现，考察评估基准的演变并识别医学AI面临的核心挑战。

Conclusion: 需要解决信实性-合理性差距，开发能够进行原生多模态推理的模型，并推动医学AI向高效、健壮、负责任的方向发展。

Abstract: The proliferation of Large Language Models (LLMs) in medicine has enabled
impressive capabilities, yet a critical gap remains in their ability to perform
systematic, transparent, and verifiable reasoning, a cornerstone of clinical
practice. This has catalyzed a shift from single-step answer generation to the
development of LLMs explicitly designed for medical reasoning. This paper
provides the first systematic review of this emerging field. We propose a
taxonomy of reasoning enhancement techniques, categorized into training-time
strategies (e.g., supervised fine-tuning, reinforcement learning) and test-time
mechanisms (e.g., prompt engineering, multi-agent systems). We analyze how
these techniques are applied across different data modalities (text, image,
code) and in key clinical applications such as diagnosis, education, and
treatment planning. Furthermore, we survey the evolution of evaluation
benchmarks from simple accuracy metrics to sophisticated assessments of
reasoning quality and visual interpretability. Based on an analysis of 60
seminal studies from 2022-2025, we conclude by identifying critical challenges,
including the faithfulness-plausibility gap and the need for native multimodal
reasoning, and outlining future directions toward building efficient, robust,
and sociotechnically responsible medical AI.

</details>


### [122] [MELAC: Massive Evaluation of Large Language Models with Alignment of Culture in Persian Language](https://arxiv.org/abs/2508.00673)
*Farhan Farsi,Farnaz Aghababaloo,Shahriar Shariati Motlagh,Parsa Ghofrani,MohammadAli SadraeiJavaheri,Shayan Bali,Amirhossein Shabani,Farbod Bijary,Ghazal Zamaninejad,AmirMohammad Salehoof,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 本文着重评估大语言模型（LLMs）在波斯语和伊朗文化背景下的表现，并引入了19个新评估数据集，同时评价了41个主流LLMs。


<details>
  <summary>Details</summary>
Motivation: 现有LLM性能评估主要聚焦于英语及其文化背景，而其他语言和非西方文化缺乏完善的评估资源，尤其是波斯语和伊朗文化领域。

Method: 本文创建了19个含括伊朗法律、波斯语语法、波斯谚语及大学入学考试等主题的评估数据集，并使用这些数据集测试了41种主流LLMs。

Result: 研究证明这些新数据集可以显著弥补文化和语言评估的差距，全面揭示了不同LLMs在非西方语境下的表现。

Conclusion: 通过提出新型评估数据集，本文为针对非英语语种和文化的LLM性能评估提供了重要工具，填补了现有研究的空白。

Abstract: As large language models (LLMs) become increasingly embedded in our daily
lives, evaluating their quality and reliability across diverse contexts has
become essential. While comprehensive benchmarks exist for assessing LLM
performance in English, there remains a significant gap in evaluation resources
for other languages. Moreover, because most LLMs are trained primarily on data
rooted in European and American cultures, they often lack familiarity with
non-Western cultural contexts. To address this limitation, our study focuses on
the Persian language and Iranian culture. We introduce 19 new evaluation
datasets specifically designed to assess LLMs on topics such as Iranian law,
Persian grammar, Persian idioms, and university entrance exams. Using these
datasets, we benchmarked 41 prominent LLMs, aiming to bridge the existing
cultural and linguistic evaluation gap in the field.

</details>


### [123] [Team "better_call_claude": Style Change Detection using a Sequential Sentence Pair Classifier](https://arxiv.org/abs/2508.00675)
*Gleb Schmidt,Johannes Römisch,Mariia Halchynska,Svetlana Gorovaia,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 本文提出了一种基于顺序句对分类器(SSPC)的风格转换检测方法，并在PAN-2025数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 风格变化检测是计算机作者身份分析的重要问题，此次任务要求检测单句级别的风格变化。

Method: 使用预训练语言模型(PLM)提取句子表示，使用双向LSTM(BiLSTM)进行上下文建模，再通过多层感知机预测相邻句子的风格切换。

Result: 模型在PAN-2025数据集上的EASY、MEDIUM和HARD任务分别达到0.923、0.828和0.724的macro-F1分数，超越多种基线表现。

Conclusion: 尽管方法轻量化，SSPC模型通过有效利用上下文信息，在短小且风格浅显的句子上表现出色，适用于复杂风格检测任务。

Abstract: Style change detection - identifying the points in a document where writing
style shifts - remains one of the most important and challenging problems in
computational authorship analysis. At PAN 2025, the shared task challenges
participants to detect style switches at the most fine-grained level:
individual sentences. The task spans three datasets, each designed with
controlled and increasing thematic variety within documents. We propose to
address this problem by modeling the content of each problem instance - that
is, a series of sentences - as a whole, using a Sequential Sentence Pair
Classifier (SSPC). The architecture leverages a pre-trained language model
(PLM) to obtain representations of individual sentences, which are then fed
into a bidirectional LSTM (BiLSTM) to contextualize them within the document.
The BiLSTM-produced vectors of adjacent sentences are concatenated and passed
to a multi-layer perceptron for prediction per adjacency. Building on the work
of previous PAN participants classical text segmentation, the approach is
relatively conservative and lightweight. Nevertheless, it proves effective in
leveraging contextual information and addressing what is arguably the most
challenging aspect of this year's shared task: the notorious problem of
"stylistically shallow", short sentences that are prevalent in the proposed
benchmark data. Evaluated on the official PAN-2025 test datasets, the model
achieves strong macro-F1 scores of 0.923, 0.828, and 0.724 on the EASY, MEDIUM,
and HARD data, respectively, outperforming not only the official random
baselines but also a much more challenging one: claude-3.7-sonnet's zero-shot
performance.

</details>


### [124] [Segment First, Retrieve Better: Realistic Legal Search via Rhetorical Role-Based Queries](https://arxiv.org/abs/2508.00679)
*Shubham Kumar Nigam,Tanmay Dubey,Noel Shallum,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: TraceRetriever 提出了一种针对法律先例检索的新方法，通过处理部分案件信息并提取具有修辞意义的段落，提高了检索效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 在普通法体系中，法律先例检索要求司法决策的一致性，但传统检索方法难以应对日益复杂和庞大的法律文档。

Method: 提出了包含 BM25、向量数据库和 Cross-Encoder 模型的流水线方法，在初步结果后通过倒数排名融合(Reciprocal Rank Fusion)汇总并重新排序，结合一个基于 Hierarchical BiLSTM CRF 的分类器生成修辞注释。

Result: 在 IL-PCR 和 COLIEE 2025 数据集上的评估表明，TraceRetriever 能够在只有部分案件信息的情况下改进检索表现，具备可靠性和扩展性。

Conclusion: TraceRetriever 提供了一个切合实际搜索需求的框架，适合处理法律文献数量的增长问题，同时提升了法律研究的效率和准确性。

Abstract: Legal precedent retrieval is a cornerstone of the common law system, governed
by the principle of stare decisis, which demands consistency in judicial
decisions. However, the growing complexity and volume of legal documents
challenge traditional retrieval methods. TraceRetriever mirrors real-world
legal search by operating with limited case information, extracting only
rhetorically significant segments instead of requiring complete documents. Our
pipeline integrates BM25, Vector Database, and Cross-Encoder models, combining
initial results through Reciprocal Rank Fusion before final re-ranking.
Rhetorical annotations are generated using a Hierarchical BiLSTM CRF classifier
trained on Indian judgments. Evaluated on IL-PCR and COLIEE 2025 datasets,
TraceRetriever addresses growing document volume challenges while aligning with
practical search constraints, reliable and scalable foundation for precedent
retrieval enhancing legal research when only partial case knowledge is
available.

</details>


### [125] [Better Call Claude: Can LLMs Detect Changes of Writing Style?](https://arxiv.org/abs/2508.00680)
*Johannes Römisch,Svetlana Gorovaia,Mariia Halchynska,Gleb Schmidt,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 研究探讨了最新的大型语言模型在句子级风格变化检测任务上的零样本表现，通过在PAN 2024和2025数据集上的测试，发现其具有良好的灵敏度和准确性，并提出了新的挑战性基线。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在句子级作者风格变化检测任务上的潜力，尤其是在零样本情况下的性能表现。

Method: 选取四种流行的大型语言模型，并在PAN 2024和2025“多作者写作风格分析”数据集上进行零样本测试与对比分析。

Result: 研究表明，这些语言模型有着对写作风格变化的敏感性，设立了优于比赛建议基线的挑战性新基线。同时，发现这些模型可能对独立于语义的纯风格信号更为敏感。

Conclusion: 最新一代的大型语言模型具备较高的句子级写作风格检测能力，展现出对样式与非语义信号的独特敏感性，为研究风格变化检测提供了新方向。

Abstract: This article explores the zero-shot performance of state-of-the-art large
language models (LLMs) on one of the most challenging tasks in authorship
analysis: sentence-level style change detection. Benchmarking four LLMs on the
official PAN~2024 and 2025 "Multi-Author Writing Style Analysis" datasets, we
present several observations. First, state-of-the-art generative models are
sensitive to variations in writing style - even at the granular level of
individual sentences. Second, their accuracy establishes a challenging baseline
for the task, outperforming suggested baselines of the PAN competition.
Finally, we explore the influence of semantics on model predictions and present
evidence suggesting that the latest generation of LLMs may be more sensitive to
content-independent and purely stylistic signals than previously reported.

</details>


### [126] [NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian Common Law System](https://arxiv.org/abs/2508.00709)
*Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Ajay Varghese Thomas,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: 提出了NyayaRAG，一个结合事实描述、法律法规和先例的RAG框架，提升了印度法律系统中司法预测的准确性和解释质量。


<details>
  <summary>Details</summary>
Motivation: 提升印度法律系统中司法预测的准确性，并结合法律法规和先例来补充判决理由。

Method: 提出NyayaRAG框架，结合事实描述、法律法规和语义检索的法律先例，使用标准指标和LLM评估其有效性。

Result: 组合输入的加入显著提高了预测的精准度和法律解释的质量。

Conclusion: 在印度法律系统中，使用基于RAG的框架能更好地进行司法判决预测并生成高质量的法律解释。

Abstract: Legal Judgment Prediction (LJP) has emerged as a key area in AI for law,
aiming to automate judicial outcome forecasting and enhance interpretability in
legal reasoning. While previous approaches in the Indian context have relied on
internal case content such as facts, issues, and reasoning, they often overlook
a core element of common law systems, which is reliance on statutory provisions
and judicial precedents. In this work, we propose NyayaRAG, a
Retrieval-Augmented Generation (RAG) framework that simulates realistic
courtroom scenarios by providing models with factual case descriptions,
relevant legal statutes, and semantically retrieved prior cases. NyayaRAG
evaluates the effectiveness of these combined inputs in predicting court
decisions and generating legal explanations using a domain-specific pipeline
tailored to the Indian legal system. We assess performance across various input
configurations using both standard lexical and semantic metrics as well as
LLM-based evaluators such as G-Eval. Our results show that augmenting factual
inputs with structured legal knowledge significantly improves both predictive
accuracy and explanation quality.

</details>


### [127] [Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA](https://arxiv.org/abs/2508.00719)
*Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siwei Liu*

Main category: cs.CL

TL;DR: 本文提出了一种称为DAMR的KGQA框架，使用MCTS结合LLM进行动态路径搜索与评估，优于当前方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有KGQA方法中静态路径难以适应、多次调用LLM计算成本高且路径评估不够准确等问题。

Method: 提出DAMR框架，采用MCTS为骨干，结合LLM规划器与轻量Transformer评分器进行动态路径评估，结合伪路径生成机制提升模型适应性。

Result: DAMR在多个KGQA基准测试中显著优于最新方法。

Conclusion: 通过动态、上下文感知的路径搜索与评估策略，DAMR解决了KGQA现存方法的不足，展示了优越性能。

Abstract: Knowledge Graph Question Answering (KGQA) aims to interpret natural language
queries and perform structured reasoning over knowledge graphs by leveraging
their relational and semantic structures to retrieve accurate answers. Recent
KGQA methods primarily follow either retrieve-then-reason paradigm, relying on
GNNs or heuristic rules for static paths extraction, or dynamic path generation
strategies that use large language models (LLMs) with prompting to jointly
perform retrieval and reasoning. However, the former suffers from limited
adaptability due to static path extraction and lack of contextual refinement,
while the latter incurs high computational costs and struggles with accurate
path evaluation due to reliance on fixed scoring functions and extensive LLM
calls. To address these issues, this paper proposes Dynamically Adaptive
MCTS-based Reasoning (DAMR), a novel framework that integrates symbolic search
with adaptive path evaluation for efficient and context-aware KGQA. DAMR
employs a Monte Carlo Tree Search (MCTS) backbone guided by an LLM-based
planner, which selects top-$k$ relevant relations at each step to reduce search
space. To improve path evaluation accuracy, we introduce a lightweight
Transformer-based scorer that performs context-aware plausibility estimation by
jointly encoding the question and relation sequence through cross-attention,
enabling the model to capture fine-grained semantic shifts during multi-hop
reasoning. Furthermore, to alleviate the scarcity of high-quality supervision,
DAMR incorporates a dynamic pseudo-path refinement mechanism that periodically
generates training signals from partial paths explored during search, allowing
the scorer to continuously adapt to the evolving distribution of reasoning
trajectories. Extensive experiments on multiple KGQA benchmarks show that DAMR
significantly outperforms state-of-the-art methods.

</details>


### [128] [Out-of-Context Abduction: LLMs Make Inferences About Procedural Data Leveraging Declarative Facts in Earlier Training Data](https://arxiv.org/abs/2508.00741)
*Sohaib Imran,Rob Lamb,Peter M. Atkinson*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型（LLMs）是否能够基于训练数据进行推理，特别是关于其在训练数据中存在的相关事实的非语境背景下的溯因能力。


<details>
  <summary>Details</summary>
Motivation: 旨在验证LLMs能否通过训练数据中的信息推断出更符合情理的解释，并探讨其情境认知能力对于人工智能安全的潜在影响。

Method: 通过将实验模型训练在假设聊天机器人的名称和行为描述上，同时避免提供交互对话示例，以测试模型在观察特定行为后能否正确推断机器人名称的能力。

Result: GPT 4o能够通过观察示例行为正确归因于特定机器人名称，并在接受描述性行为训练后更显现特定机器人的行为特征。

Conclusion: LLMs表现出了潜在的情境认知能力，研究结果对LLMs的应用以及AI安全领域具有重要意义。

Abstract: Large language models (LLMs) are trained on large corpora, yet it is unclear
whether they can reason about the information present within their training
data. We design experiments to study out-of-context abduction in LLMs, the
ability to infer the most plausible explanations for observations using
relevant facts present in training data. We train treatment LLMs on names and
behavior descriptions of fictitious chatbots, but not on examples of dialogue
with the chatbots. We find that OpenAI's GPT 4o LLM can correctly infer at
least one chatbot's name after observing example responses characteristic of
that chatbot. We also find that previously training GPT 4o on descriptions of a
chatbot's behavior allows it to display behaviors more characteristic of the
chatbot when iteratively trained to display such behaviors. Our results have
implications for situational awareness in LLMs and, therefore, for AI safety.

</details>


### [129] [Applying Psychometrics to Large Language Model Simulated Populations: Recreating the HEXACO Personality Inventory Experiment with Generative Agents](https://arxiv.org/abs/2508.00742)
*Sarah Mercer,Daniel P. Martin,Phil Swatton*

Main category: cs.CL

TL;DR: 本研究利用GPT-4生成代理探索人格模型的表征效用，部分验证了HEXACO人格模型的一致性和可靠性，但也指出了模型偏差和局限性。


<details>
  <summary>Details</summary>
Motivation: 为了探讨基于生成型语言模型的代理是否能够有效表征人类人格及其在社会科学研究中的潜力。

Method: 通过为310个GPT-4代理赋予特定角色，使用HEXACO人格测评进行实验，结合因素分析对结果执行检验并与2004年的原始研究结果对比。

Result: 实验表明，GPT-4代理的反应中可恢复出一致且部分对齐于HEXACO结构的人格维度，但跨模型分析发现了模型偏差和局限性。

Conclusion: 生成性代理可作为研究人类人格的工具，有助于补充社会科学研究，但需设计一致且具代表性的角色，避免模型特定的偏差影响结果。

Abstract: Generative agents powered by Large Language Models demonstrate human-like
characteristics through sophisticated natural language interactions. Their
ability to assume roles and personalities based on predefined character
biographies has positioned them as cost-effective substitutes for human
participants in social science research. This paper explores the validity of
such persona-based agents in representing human populations; we recreate the
HEXACO personality inventory experiment by surveying 310 GPT-4 powered agents,
conducting factor analysis on their responses, and comparing these results to
the original findings presented by Ashton, Lee, & Goldberg in 2004. Our results
found 1) a coherent and reliable personality structure was recoverable from the
agents' responses demonstrating partial alignment to the HEXACO framework. 2)
the derived personality dimensions were consistent and reliable within GPT-4,
when coupled with a sufficiently curated population, and 3) cross-model
analysis revealed variability in personality profiling, suggesting
model-specific biases and limitations. We discuss the practical considerations
and challenges encountered during the experiment. This study contributes to the
ongoing discourse on the potential benefits and limitations of using generative
agents in social science research and provides useful guidance on designing
consistent and representative agent personas to maximise coverage and
representation of human personality traits.

</details>


### [130] [Agentic large language models improve retrieval-based radiology question answering](https://arxiv.org/abs/2508.00743)
*Sebastian Wind,Jeta Sopa,Daniel Truhn,Mahshad Lotfinia,Tri-Thien Nguyen,Keno Bressem,Lisa Adams,Mirabela Rusu,Harald Köstler,Gerhard Wellein,Andreas Maier,Soroosh Tayebi Arasteh*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新的代理型RAG框架，用于在放射学问答中实现更好的诊断准确性和减少幻觉现象，并进行了广泛的模型评估与性能提升分析。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统在处理复杂临床推理任务上存在局限性，需要一种能够自主分解问题并动态检索和合成证据的新方法。

Method: 提出并评估了一种代理型RAG框架，利用大语言模型自主分解问题，并通过迭代检索Radiopaedia中的针对性临床证据来动态生成基于证据的回答。

Result: 代理型RAG显著提高了诊断准确性（从64%提升至73%）和临床语境相关性，同时减少了幻觉现象（平均9.4%）。中小规模模型收益最大，而超大规模模型收益有限。

Conclusion: 代理型框架在提升中小规模模型的诊断准确性和基于证据的回答能力上尤其有效，这种方法在放射学问答中的潜力值得进一步研究。

Abstract: Clinical decision-making in radiology increasingly benefits from artificial
intelligence (AI), particularly through large language models (LLMs). However,
traditional retrieval-augmented generation (RAG) systems for radiology question
answering (QA) typically rely on single-step retrieval, limiting their ability
to handle complex clinical reasoning tasks. Here we propose an agentic RAG
framework enabling LLMs to autonomously decompose radiology questions,
iteratively retrieve targeted clinical evidence from Radiopaedia, and
dynamically synthesize evidence-based responses. We evaluated 24 LLMs spanning
diverse architectures, parameter scales (0.5B to >670B), and training paradigms
(general-purpose, reasoning-optimized, clinically fine-tuned), using 104
expert-curated radiology questions from previously established RSNA-RadioQA and
ExtendedQA datasets. Agentic retrieval significantly improved mean diagnostic
accuracy over zero-shot prompting (73% vs. 64%; P<0.001) and conventional
online RAG (73% vs. 68%; P<0.001). The greatest gains occurred in mid-sized
models (e.g., Mistral Large improved from 72% to 81%) and small-scale models
(e.g., Qwen 2.5-7B improved from 55% to 71%), while very large models (>200B
parameters) demonstrated minimal changes (<2% improvement). Additionally,
agentic retrieval reduced hallucinations (mean 9.4%) and retrieved clinically
relevant context in 46% of cases, substantially aiding factual grounding. Even
clinically fine-tuned models exhibited meaningful improvements (e.g.,
MedGemma-27B improved from 71% to 81%), indicating complementary roles of
retrieval and fine-tuning. These results highlight the potential of agentic
frameworks to enhance factuality and diagnostic accuracy in radiology QA,
particularly among mid-sized LLMs, warranting future studies to validate their
clinical utility.

</details>


### [131] [GLiDRE: Generalist Lightweight model for Document-level Relation Extraction](https://arxiv.org/abs/2508.00757)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: GLiDRE模型在文档级关系提取任务中表现出色，特别是在少样本场景中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究者希望通过紧凑模型GLiDRE进行文档级关系提取，以在复杂的跨句子实体交互建模问题中取得进展，尤其在零样本与少样本设置中探索性能。

Method: 在GLiDRE模型中，借鉴了紧凑型NER模型GLiNER的关键思想，并对其进行改良，致力于文档级关系提取任务。进一步在Re-DocRED数据集上对其与最先进模型进行基准测试。

Result: GLiDRE在少样本场景中达到了最先进的性能，优于目前的最优方法。

Conclusion: GLiDRE模型在少样本文档级关系提取中表现优越，可作为此领域的重要进展，代码开源。

Abstract: Relation Extraction (RE) is a fundamental task in Natural Language
Processing, and its document-level variant poses significant challenges, due to
the need to model complex interactions between entities across sentences.
Current approaches, largely based on the ATLOP architecture, are commonly
evaluated on benchmarks like DocRED and Re-DocRED. However, their performance
in zero-shot or few-shot settings remains largely underexplored due to the
task's complexity. Recently, the GLiNER model has shown that a compact NER
model can outperform much larger Large Language Models. With a similar
motivation, we introduce GLiDRE, a new model for document-level relation
extraction that builds on the key ideas of GliNER. We benchmark GLiDRE against
state-of-the-art models across various data settings on the Re-DocRED dataset.
Our results demonstrate that GLiDRE achieves state-of-the-art performance in
few-shot scenarios. Our code is publicly available.

</details>


### [132] [MMBERT: Scaled Mixture-of-Experts Multimodal BERT for Robust Chinese Hate Speech Detection under Cloaking Perturbations](https://arxiv.org/abs/2508.00760)
*Qiyao Xue,Yuchen Dou,Ryan Shi,Xiang Lorraine Li,Wei Gao*

Main category: cs.CL

TL;DR: 本文提出MMBERT，一个基于BERT的多模态框架，通过整合文本、语音和视觉模态用于应对中文社交网络中的仇恨言论检测问题。


<details>
  <summary>Details</summary>
Motivation: 解决中文社交网络仇恨言论检测中多模态技术应用不足及规避传统文本检测技术的问题。

Method: 使用基于Mixture-of-Experts架构的BERT框架，结合逐步式三阶段训练方式，整合多模态专家、共享自注意力机制和基于路由的专家分配策略。

Result: 在多个中文仇恨言论数据集上的实验证明，MMBERT显著优于微调的BERT、LLM模型和基于上下文学习的LLM方法。

Conclusion: MMBERT框架结合多模态信息和创新的训练方法，有效提高了仇恨言论检测的鲁棒性和检测性能。

Abstract: Hate speech detection on Chinese social networks presents distinct
challenges, particularly due to the widespread use of cloaking techniques
designed to evade conventional text-based detection systems. Although large
language models (LLMs) have recently improved hate speech detection
capabilities, the majority of existing work has concentrated on English
datasets, with limited attention given to multimodal strategies in the Chinese
context. In this study, we propose MMBERT, a novel BERT-based multimodal
framework that integrates textual, speech, and visual modalities through a
Mixture-of-Experts (MoE) architecture. To address the instability associated
with directly integrating MoE into BERT-based models, we develop a progressive
three-stage training paradigm. MMBERT incorporates modality-specific experts, a
shared self-attention mechanism, and a router-based expert allocation strategy
to enhance robustness against adversarial perturbations. Empirical results in
several Chinese hate speech datasets show that MMBERT significantly surpasses
fine-tuned BERT-based encoder models, fine-tuned LLMs, and LLMs utilizing
in-context learning approaches.

</details>


### [133] [ITUNLP at SemEval-2025 Task 8: Question-Answering over Tabular Data: A Zero-Shot Approach using LLM-Driven Code Generation](https://arxiv.org/abs/2508.00762)
*Atakan Site,Emre Hakan Erdemir,Gülşen Eryiğit*

Main category: cs.CL

TL;DR: 本文讲述了一个专用于SemEval-2025 Task 8的系统，用于跨多领域表格数据进行问答。通过提出一种基于大型语言模型（LLM）的Python代码生成框架，系统显著提升表格问答性能。


<details>
  <summary>Details</summary>
Motivation: 探讨如何利用LLM进行代码生成以提高表格问答任务的效果。

Method: 提出了一种基于LLM的Python代码生成框架，通过优化提示策略生成可执行的Pandas代码，用于表格数据问答任务。

Result: 实验显示，基于Python代码生成的方法优于其他方法，并在两个子任务中分别获得第八和第六的名次。

Conclusion: 基于LLM的代码生成在表格问答任务中表现突出，显示了其潜力，尽管系统仍有改进空间。

Abstract: This paper presents our system for SemEval-2025 Task 8: DataBench,
Question-Answering over Tabular Data. The primary objective of this task is to
perform question answering on given tabular datasets from diverse domains under
two subtasks: DataBench QA (Subtask I) and DataBench Lite QA (Subtask II). To
tackle both subtasks, we developed a zero-shot solution with a particular
emphasis on leveraging Large Language Model (LLM)-based code generation.
Specifically, we propose a Python code generation framework utilizing
state-of-the-art open-source LLMs to generate executable Pandas code via
optimized prompting strategies. Our experiments reveal that different LLMs
exhibit varying levels of effectiveness in Python code generation.
Additionally, results show that Python code generation achieves superior
performance in tabular question answering compared to alternative approaches.
Although our ranking among zero-shot systems is unknown at the time of this
paper's submission, our system achieved eighth place in Subtask I and sixth
place in Subtask~II among the 30 systems that outperformed the baseline in the
open-source models category.

</details>


### [134] [Do They Understand Them? An Updated Evaluation on Nonbinary Pronoun Handling in Large Language Models](https://arxiv.org/abs/2508.00788)
*Xushuo Tang,Yi Ding,Zhengyi Yang,Yin Chen,Yongrui Gu,Wenke Yang,Mingchen Ju,Xin Cao,Yongfei Liu,Wenjie Zhang*

Main category: cs.CL

TL;DR: 该研究通过扩展与更新的MISGENDERED+基准测试评估五种大型语言模型(LLMs)在性别中立与新兴代词处理上的能力，发现代词准确性改进明显，但在新代词及反向推理任务上仍存在不足。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs被广泛应用于敏感领域，确保公平性与包容性尤为重要，该研究瞄准了代词使用，特别是性别中立代词和新兴代词处理中的挑战。

Method: 引入更新的MISGENDERED+基准，通过零样本、少样本和性别推理三种模式评估五种代表性LLMs的代词处理能力，包括GPT-4o、Claude 4等。

Result: 五种模型在二元性别及性别中立代词的准确性方面取得显著改进，但在新兴代词和反向推理任务上仍表现不稳定，暴露在身份敏感推理上的差距。

Conclusion: 尽管取得局部改进，但LLMs在包容性AI领域仍需进一步研究与优化，特别是在处理新代词和复杂性别推理任务时。

Abstract: Large language models (LLMs) are increasingly deployed in sensitive contexts
where fairness and inclusivity are critical. Pronoun usage, especially
concerning gender-neutral and neopronouns, remains a key challenge for
responsible AI. Prior work, such as the MISGENDERED benchmark, revealed
significant limitations in earlier LLMs' handling of inclusive pronouns, but
was constrained to outdated models and limited evaluations. In this study, we
introduce MISGENDERED+, an extended and updated benchmark for evaluating LLMs'
pronoun fidelity. We benchmark five representative LLMs, GPT-4o, Claude 4,
DeepSeek-V3, Qwen Turbo, and Qwen2.5, across zero-shot, few-shot, and gender
identity inference. Our results show notable improvements compared with
previous studies, especially in binary and gender-neutral pronoun accuracy.
However, accuracy on neopronouns and reverse inference tasks remains
inconsistent, underscoring persistent gaps in identity-sensitive reasoning. We
discuss implications, model-specific observations, and avenues for future
inclusive AI research.

</details>


### [135] [Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models](https://arxiv.org/abs/2508.00819)
*Jinsong Li,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jiaqi Wang,Dahua Lin*

Main category: cs.CL

TL;DR: DAEDAL提出一种新方法，以动态扩展的方式解决扩散大语言模型（DLLMs）生成长度的限制问题，提升了性能与计算效率。


<details>
  <summary>Details</summary>
Motivation: 当前的DLLMs在生成过程中需要预定义静态长度，很难平衡性能和计算成本。

Method: DAEDAL通过两阶段流程动态调整生成长度：第一个阶段起始于短初始长度并逐步扩展至接近任务所需长度，第二阶段在去噪过程中动态插入掩码以扩展生成不足区域。

Result: 实验表明，DAEDAL在性能和计算效率上优于固定长度模型基线，显著提高了有效生成率。

Conclusion: DAEDAL突破了DLLMs的静态长度限制，填补了与自回归语言模型的差距，为更高效的生成铺平了道路。

Abstract: Diffusion Large Language Models (DLLMs) are emerging as a powerful
alternative to the dominant Autoregressive Large Language Models, offering
efficient parallel generation and capable global context modeling. However, the
practical application of DLLMs is hindered by a critical architectural
constraint: the need for a statically predefined generation length. This static
length allocation leads to a problematic trade-off: insufficient lengths
cripple performance on complex tasks, while excessive lengths incur significant
computational overhead and sometimes result in performance degradation. While
the inference framework is rigid, we observe that the model itself possesses
internal signals that correlate with the optimal response length for a given
task. To bridge this gap, we leverage these latent signals and introduce
DAEDAL, a novel training-free denoising strategy that enables Dynamic Adaptive
Length Expansion for Diffusion Large Language Models. DAEDAL operates in two
phases: 1) Before the denoising process, DAEDAL starts from a short initial
length and iteratively expands it to a coarse task-appropriate length, guided
by a sequence completion metric. 2) During the denoising process, DAEDAL
dynamically intervenes by pinpointing and expanding insufficient generation
regions through mask token insertion, ensuring the final output is fully
developed. Extensive experiments on DLLMs demonstrate that DAEDAL achieves
performance comparable, and in some cases superior, to meticulously tuned
fixed-length baselines, while simultaneously enhancing computational efficiency
by achieving a higher effective token ratio. By resolving the static length
constraint, DAEDAL unlocks new potential for DLLMs, bridging a critical gap
with their Autoregressive counterparts and paving the way for more efficient
and capable generation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [136] [Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench](https://arxiv.org/abs/2508.00081)
*Fred Mutisya,Shikoh Gitau,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha*

Main category: cs.AI

TL;DR: 本文旨在改进HealthBench，使其更具全球相关性和公平性。


<details>
  <summary>Details</summary>
Motivation: 目前HealthBench依赖于专家意见，而非高质量临床证据，容易产生偏见和局限性，特别是在低收入和中等收入地区。

Method: 通过将奖励函数锚定于基于系统评价和GRADE证据评级的临床实践指南（CPGs），实现“证据稳健”强化学习。此外，方法还包括评分中的证据权重和情境覆盖逻辑等。

Result: 提出了一种基于证据的新框架与路线图，能够提高医疗语言模型的可靠性和临床可信程度。

Conclusion: 建议通过基于证据的CPGs优化奖励系统，使医疗语言模型更加可信并具有伦理性和全球相关性，同时保留了方法的透明性和可操作性。

Abstract: HealthBench, a benchmark designed to measure the capabilities of AI systems
for health better (Arora et al., 2025), has advanced medical language model
evaluation through physician-crafted dialogues and transparent rubrics.
However, its reliance on expert opinion, rather than high-tier clinical
evidence, risks codifying regional biases and individual clinician
idiosyncrasies, further compounded by potential biases in automated grading
systems. These limitations are particularly magnified in low- and middle-income
settings, where issues like sparse neglected tropical disease coverage and
region-specific guideline mismatches are prevalent.
  The unique challenges of the African context, including data scarcity,
inadequate infrastructure, and nascent regulatory frameworks, underscore the
urgent need for more globally relevant and equitable benchmarks. To address
these shortcomings, we propose anchoring reward functions in version-controlled
Clinical Practice Guidelines (CPGs) that incorporate systematic reviews and
GRADE evidence ratings.
  Our roadmap outlines "evidence-robust" reinforcement learning via
rubric-to-guideline linkage, evidence-weighted scoring, and contextual override
logic, complemented by a focus on ethical considerations and the integration of
delayed outcome feedback. By re-grounding rewards in rigorously vetted CPGs,
while preserving HealthBench's transparency and physician engagement, we aim to
foster medical language models that are not only linguistically polished but
also clinically trustworthy, ethically sound, and globally relevant.

</details>


### [137] [Hyperproperty-Constrained Secure Reinforcement Learning](https://arxiv.org/abs/2508.00106)
*Ernest Bonnah,Luan Viet Nguyen,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: 本文提出了一种基于HyperTWTL约束的安全增强学习方法，并验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有文献关注于带有时序逻辑约束的安全增强学习，但鲜有人探索使用超属性进行安全学习，研究中存在空白。

Method: 提出一种基于动态Boltzmann softmax强化学习的方法，在满足HyperTWTL约束的情况下学习安全的最优策略。

Result: 通过接送任务的机器人案例研究证明了方法的有效性和可扩展性，并与两种基线算法对比表明其性能优越。

Conclusion: 该方法能够有效地处理带有超属性约束的安全增强学习问题，为机器人应用中的安全性提供保障。

Abstract: Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a
domain-specific formal specification language known for its effectiveness in
compactly representing security, opacity, and concurrency properties for
robotics applications. This paper focuses on HyperTWTL-constrained secure
reinforcement learning (SecRL). Although temporal logic-constrained safe
reinforcement learning (SRL) is an evolving research problem with several
existing literature, there is a significant research gap in exploring
security-aware reinforcement learning (RL) using hyperproperties. Given the
dynamics of an agent as a Markov Decision Process (MDP) and opacity/security
constraints formalized as HyperTWTL, we propose an approach for learning
security-aware optimal policies using dynamic Boltzmann softmax RL while
satisfying the HyperTWTL constraints. The effectiveness and scalability of our
proposed approach are demonstrated using a pick-up and delivery robotic mission
case study. We also compare our results with two other baseline RL algorithms,
showing that our proposed method outperforms them.

</details>


### [138] [No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence](https://arxiv.org/abs/2508.00116)
*Wil M. P. van der Aalst*

Main category: cs.AI

TL;DR: 本文讨论了AI在组织运营过程中的应用，提出将对象中心流程挖掘（OCPM）与生成、预测和规范性AI结合以提升流程管理的效率和效果的重要性。


<details>
  <summary>Details</summary>
Motivation: 组织在工业环境下成功应用AI面临挑战，特别是针对端到端操作流程的改进。因此，有必要寻找支撑AI于流程改进中的方法和技术。

Method: 本文通过引入对象中心流程挖掘（OCPM）技术，将其与生成、预测和规范性AI相结合，提出了流程智能（PI）的概念，用以有效处理多样化的对象和事件数据。

Result: 使用OCPM可将数据和流程连接起来，为不同形式的AI应用提供支持，从而使组织得以诊断和改进其操作流程。

Conclusion: AI需要结合流程智能（PI）才能建立在组织上下文中的有效应用，同时OCPM为实现这一结合提供了基础，为组织流程优化和AI结合开辟了新机遇。

Abstract: The uptake of Artificial Intelligence (AI) impacts the way we work, interact,
do business, and conduct research. However, organizations struggle to apply AI
successfully in industrial settings where the focus is on end-to-end
operational processes. Here, we consider generative, predictive, and
prescriptive AI and elaborate on the challenges of diagnosing and improving
such processes. We show that AI needs to be grounded using Object-Centric
Process Mining (OCPM). Process-related data are structured and
organization-specific and, unlike text, processes are often highly dynamic.
OCPM is the missing link connecting data and processes and enables different
forms of AI. We use the term Process Intelligence (PI) to refer to the
amalgamation of process-centric data-driven techniques able to deal with a
variety of object and event types, enabling AI in an organizational context.
This paper explains why AI requires PI to improve operational processes and
highlights opportunities for successfully combining OCPM and generative,
predictive, and prescriptive AI.

</details>


### [139] [Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis](https://arxiv.org/abs/2508.00129)
*Agustín Borda,Juan Bautista Cabral,Gonzalo Giarda,Diego Nicolás Gimenez Irusta,Paula Pacheco,Alvaro Roy Schachner*

Main category: cs.AI

TL;DR: 该论文探讨了如何检测多准则决策方法中的排序反转问题，并通过三种测试方法实现检测。


<details>
  <summary>Details</summary>
Motivation: 解决排序反转对多准则决策结果的影响，并提供一种评估不同方法有效性的机制。

Method: 提出了三种检测排序反转的测试方法，并将其集成到Scikit-Criteria库中。

Result: 成功实现了排序反转检测，并探讨了在不同场景中应用这些检测方法的设计和实现考量。

Conclusion: 这些测试方法有助于判断多准则决策方法的有效性，并且在决策问题求解中可能发挥重要作用。

Abstract: In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem
that can greatly affect the results of a Multi-Criteria Decision Method against
a particular set of alternatives. It is therefore useful to have a mechanism
that allows one to measure the performance of a method on a set of
alternatives. This idea could be taken further to build a global ranking of the
effectiveness of different methods to solve a problem. In this paper, we
present three tests that detect the presence of Rank Reversals, along with
their implementation in the Scikit-Criteria library. We also address the
complications that arise when implementing these tests for general scenarios
and the design considerations we made to handle them. We close with a
discussion about how these additions could play a major role in the judgment of
multi-criteria decision methods for problem solving.

</details>


### [140] [SHACL Validation under Graph Updates (Extended Paper)](https://arxiv.org/abs/2508.00137)
*Shqiponja Ahmetaj,George Konstantinidis,Magdalena Ortiz,Paolo Pareti,Mantas Simkus*

Main category: cs.AI

TL;DR: 本文研究了在RDF图更新情况下的SHACL验证问题，包括提出了一种基于SHACL的更新语言并研究了静态验证。


<details>
  <summary>Details</summary>
Motivation: 为了在RDF图随更新演变时高效验证SHACL规范的有效性，提供对动态RDF图推理的基础。

Method: 通过将更新动作嵌入到SHACL约束中，使用回归技术将静态验证问题转化为SHACL扩展中约束的（不）可满足性问题，并分析其计算复杂性。还开发了一个原型实现用于静态验证和其他分析任务。

Result: 证明了静态验证问题可以通过扩展的SHACL约束解决，并通过实验验证了原型工具的有效性。

Conclusion: 研究展示了在动态RDF图环境中进行SHACL验证的可能性，并为策略推理提供了基础，同时设计的工具也证明了其实用性。

Abstract: SHACL (SHApe Constraint Language) is a W3C standardized constraint language
for RDF graphs. In this paper, we study SHACL validation in RDF graphs under
updates. We present a SHACL-based update language that can capture intuitive
and realistic modifications on RDF graphs and study the problem of static
validation under such updates. This problem asks to verify whether every graph
that validates a SHACL specification will still do so after applying a given
update sequence. More importantly, it provides a basis for further services for
reasoning about evolving RDF graphs. Using a regression technique that embeds
the update actions into SHACL constraints, we show that static validation under
updates can be reduced to (un)satisfiability of constraints in (a minor
extension of) SHACL. We analyze the computational complexity of the static
validation problem for SHACL and some key fragments. Finally, we present a
prototype implementation that performs static validation and other static
analysis tasks on SHACL constraints and demonstrate its behavior through
preliminary experiments.

</details>


### [141] [Co-Producing AI: Toward an Augmented, Participatory Lifecycle](https://arxiv.org/abs/2508.00138)
*Rashid Mushkani,Hugo Berard,Toumadher Ammar,Cassandre Chatonnier,Shin Koseki*

Main category: cs.AI

TL;DR: 本文提出了一种增强型AI生命周期模型，通过五个互相关联的阶段解决AI系统中的风险和偏见问题，特别是对弱势群体的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的AI算法在应对潜在的风险和偏见时成效有限，尤其是对文化边缘化群体可能造成的不利影响，需重新设计生产流程以实现公平性和责任性。

Method: 参考设计正义理论、扩展学习理论以及参与式AI的经验研究，作者提出了一个以协作生产、多样性、公平性、包容性及跨学科合作为核心的AI生产流程。该流程包含共同行动的五个阶段，并通过四次多学科技术研讨会形成方案。

Result: 提出了包含共框定、共设计、共实施、共部署和共维护五个阶段的增强型AI生命周期模型，并将其与现有的伦理框架相关联，提出了适用于参与性治理的关键研究问题。

Conclusion: AI生产流程需要进行根本性的重新构建，增强型AI生命周期模型可作为指导未来研究和实践的有力框架，同时需要进一步研究以实现可扩展的参与式治理。

Abstract: Despite efforts to mitigate the inherent risks and biases of artificial
intelligence (AI) algorithms, these algorithms can disproportionately impact
culturally marginalized groups. A range of approaches has been proposed to
address or reduce these risks, including the development of ethical guidelines
and principles for responsible AI, as well as technical solutions that promote
algorithmic fairness. Drawing on design justice, expansive learning theory, and
recent empirical work on participatory AI, we argue that mitigating these harms
requires a fundamental re-architecture of the AI production pipeline. This
re-design should center co-production, diversity, equity, inclusion (DEI), and
multidisciplinary collaboration. We introduce an augmented AI lifecycle
consisting of five interconnected phases: co-framing, co-design,
co-implementation, co-deployment, and co-maintenance. The lifecycle is informed
by four multidisciplinary workshops and grounded in themes of distributed
authority and iterative knowledge exchange. Finally, we relate the proposed
lifecycle to several leading ethical frameworks and outline key research
questions that remain for scaling participatory governance.

</details>


### [142] [Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation](https://arxiv.org/abs/2508.00143)
*Danielle R. Thomas,Conrad Borchers,Kenneth R. Koedinger*

Main category: cs.AI

TL;DR: 本文讨论了人类作为评估者的局限性，提出采用多种替代方法取代传统的IRR指标，以改善教育数据标注质量和增强模型的预测能力。


<details>
  <summary>Details</summary>
Motivation: 指出传统的IRR指标在教育数据标注中过度依赖人类评估可能限制了改进学习模型的潜力，需寻求更有效的替代方法。

Method: 提出五种补充评估方法，包括多标签注释方案、基于专家的评估方法以及闭环验证等，并强调外部效度的重要性。

Result: 这些方法能够更好地提高训练数据的质量，优化模型的预测能力，从而支持更有效的学生学习和产生可操作的洞察力。

Conclusion: 呼吁对注释质量和真值概念重新思考，强调应将有效性和教育影响放在优先位置，而非仅仅追求一致性指标。

Abstract: Humans can be notoriously imperfect evaluators. They are often biased,
unreliable, and unfit to define "ground truth." Yet, given the surging need to
produce large amounts of training data in educational applications using AI,
traditional inter-rater reliability (IRR) metrics like Cohen's kappa remain
central to validating labeled data. IRR remains a cornerstone of many machine
learning pipelines for educational data. Take, for example, the classification
of tutors' moves in dialogues or labeling open responses in machine-graded
assessments. This position paper argues that overreliance on human IRR as a
gatekeeper for annotation quality hampers progress in classifying data in ways
that are valid and predictive in relation to improving learning. To address
this issue, we highlight five examples of complementary evaluation methods,
such as multi-label annotation schemes, expert-based approaches, and
close-the-loop validity. We argue that these approaches are in a better
position to produce training data and subsequent models that produce improved
student learning and more actionable insights than IRR approaches alone. We
also emphasize the importance of external validity, for example, by
establishing a procedure of validating tutor moves and demonstrating that it
works across many categories of tutor actions (e.g., providing hints). We call
on the field to rethink annotation quality and ground truth--prioritizing
validity and educational impact over consensus alone.

</details>


### [143] [Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power](https://arxiv.org/abs/2508.00159)
*Jobst Heitzig,Ram Potham*

Main category: cs.AI

TL;DR: 本文提出了通过强制AI提高人类能力和管理人类与AI之间权力平衡的目标函数，以增强安全性和福祉。


<details>
  <summary>Details</summary>
Motivation: 探讨如何通过增强人类权力与福祉来同时推动AI安全与人类福祉。

Method: 设计了一个可参数化和分解的目标函数，基于对人类权力的长期累积考虑，结合人类有限理性和社会规范。同时，衍生了算法以通过反向归纳法或多智能体强化学习来计算此指标。

Result: 研究展示了最大化该权力衡量指标在不同情境中的具体效果，以及这种方法在实际情况下会导致的潜在工具性子目标。

Conclusion: 温和地最大化合适的人类权力总指标可以作为比直接基于效用的目标更安全的AI设计方向。

Abstract: Power is a key concept in AI safety: power-seeking as an instrumental goal,
sudden or gradual disempowerment of humans, power balance in human-AI
interaction and international AI governance. At the same time, power as the
ability to pursue diverse goals is essential for wellbeing.
  This paper explores the idea of promoting both safety and wellbeing by
forcing AI agents explicitly to empower humans and to manage the power balance
between humans and AI agents in a desirable way. Using a principled, partially
axiomatic approach, we design a parametrizable and decomposable objective
function that represents an inequality- and risk-averse long-term aggregate of
human power. It takes into account humans' bounded rationality and social
norms, and, crucially, considers a wide variety of possible human goals.
  We derive algorithms for computing that metric by backward induction or
approximating it via a form of multi-agent reinforcement learning from a given
world model. We exemplify the consequences of (softly) maximizing this metric
in a variety of paradigmatic situations and describe what instrumental
sub-goals it will likely imply. Our cautious assessment is that softly
maximizing suitable aggregate metrics of human power might constitute a
beneficial objective for agentic AI systems that is safer than direct
utility-based objectives.

</details>


### [144] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
*Yihong Dong,Xue Jiang,Yongding Tao,Huanyu Liu,Kechi Zhang,Lili Mou,Rongyu Cao,Yingwei Ma,Jue Chen,Binhua Li,Zhi Jin,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.AI

TL;DR: 该论文提出了一种新方法RL-PLUS，通过理论分析和实验验证，其在数学推理基准和分布外任务上表现优越，相较现有方法表现出显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法在大语言模型的推理能力提升上受限，存在能力边界无法突破，以及能力边界坍塌的问题，从而需要改进方法突破这些问题。

Method: 作者提出RL-PLUS，将内部推理（Thinking）与外部学习（Learning）相结合，使用多重重要性采样解决分布失配，并通过基于探索的优势函数引导模型发现高价值、未探索的推理路径。

Result: RL-PLUS在多个数学推理基准任务和分布外推理任务上达到最先进的性能，在多种模型族中实现21.1%到69.2%的性能提升，并有效解决了能力边界坍塌问题。

Conclusion: RL-PLUS通过新的方法论成功超越了现有RLVR的能力界限，为提高语言模型复杂推理能力提供了有效解决方案，并展示了优良的泛化性和实用潜力。

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has significantly
advanced the complex reasoning abilities of Large Language Models (LLMs).
However, it struggles to break through the inherent capability boundaries of
the base LLM, due to its inherently on-policy strategy with LLM's immense
action space and sparse reward. Further, RLVR can lead to the capability
boundary collapse, narrowing the LLM's problem-solving scope. To address this
problem, we propose RL-PLUS, a novel approach that synergizes internal
exploitation (i.e., Thinking) with external data (i.e., Learning) to achieve
stronger reasoning capabilities and surpass the boundaries of base models.
RL-PLUS integrates two core components: Multiple Importance Sampling to address
for distributional mismatch from external data, and an Exploration-Based
Advantage Function to guide the model towards high-value, unexplored reasoning
paths. We provide both theoretical analysis and extensive experiments to
demonstrate the superiority and generalizability of our approach. The results
show that RL-PLUS achieves state-of-the-art performance compared with existing
RLVR methods on six math reasoning benchmarks and exhibits superior performance
on six out-of-distribution reasoning tasks. It also achieves consistent and
significant gains across diverse model families, with average relative
improvements ranging from 21.1\% to 69.2\%. Moreover, Pass@k curves across
multiple benchmarks indicate that RL-PLUS effectively resolves the capability
boundary collapse problem.

</details>


### [145] [MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning](https://arxiv.org/abs/2508.00271)
*Hongjin Qian,Zheng Liu*

Main category: cs.AI

TL;DR: 提出MetaAgent，一个通过实践和自我改进发展的自我进化代理系统，适用于知识发现任务，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 通过引入一种新型的自我进化模型，解决在知识发现任务中对工具使用的有效整合与逐步优化的难题。

Method: MetaAgent以最小的工作流开始，结合自然语言求助请求的工具路由、自我反思和答案验证，建立知识库和内置工具，通过“元工具学习”逐步优化自身的推理能力和工具使用策略。

Result: 在GAIA、WebWalkerQA和BrowseCamp等基准测试中表现出色，性能优于传统工作流模型，并与端到端训练代理相当或更好。

Conclusion: MetaAgent展现了自我进化型代理系统在知识发现任务中的潜力，为鲁棒且通用的知识发现提供了一种新方法。

Abstract: In this work, we propose MetaAgent, an agentic paradigm inspired by the
principle of learning-by-doing, where expertise is developed through hands-on
practice and continual self-improvement. MetaAgent starts with a minimal
workflow, equipped only with basic reasoning and adaptive help-seeking
abilities. When a knowledge gap is encountered, MetaAgent generates natural
language help requests, which are routed to the most suitable external tool by
a dedicated tool router. As MetaAgent solves tasks, it continually conducts
self-reflection and answer verification, distilling actionable experience into
concise texts that are dynamically incorporated into future task contexts.
Besides, MetaAgent autonomously builds in-house tools and a persistent
knowledge base by organizing its tool-use history, further enhancing its
ability to retrieve and integrate relevant information We term this continual,
data-driven process as \textit{meta tool learning}, through which MetaAgent
incrementally refines its reasoning and tool-use strategies, without changing
model parameters or requiring further post-training. Evaluated on challenging
knowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,
MetaAgent consistently outperforms workflow-based baselines and matches or
exceeds end-to-end trained agents, demonstrating the promise of self-evolving
agentic systems for robust, general-purpose knowledge discovery. We provide our
source codes in https://github.com/qhjqhj00/MetaAgent.

</details>


### [146] [Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](https://arxiv.org/abs/2508.00282)
*Yi-Long Lu,Jiajun Song,Chunhui Zhang,Wei Wang*

Main category: cs.AI

TL;DR: 研究比较了人类和LLM在生成任务时的行为差异，发现LLM无法真实反映人类行为模式中的心理驱动力。


<details>
  <summary>Details</summary>
Motivation: 探索LLM能否模拟人类受内在动机驱使的复杂任务生成行为。

Method: 通过实验比较人类的任务生成过程与GPT-4o的表现，并分析其心理驱动因素的体现程度。

Result: LLM生成的任务在社交性、身体性上表现不足，并且倾向于抽象主题，难以准确映射人类的心理驱动力。

Conclusion: LLM与人类认知的价值驱动、具身性质存在核心差异，需要在设计中加入内在动机和物理嵌入性以对齐人类行为。

Abstract: Humans constantly generate a diverse range of tasks guided by internal
motivations. While generative agents powered by large language models (LLMs)
aim to simulate this complex behavior, it remains uncertain whether they
operate on similar cognitive principles. To address this, we conducted a
task-generation experiment comparing human responses with those of an LLM agent
(GPT-4o). We find that human task generation is consistently influenced by
psychological drivers, including personal values (e.g., Openness to Change) and
cognitive style. Even when these psychological drivers are explicitly provided
to the LLM, it fails to reflect the corresponding behavioral patterns. They
produce tasks that are markedly less social, less physical, and thematically
biased toward abstraction. Interestingly, while the LLM's tasks were perceived
as more fun and novel, this highlights a disconnect between its linguistic
proficiency and its capacity to generate human-like, embodied goals.We conclude
that there is a core gap between the value-driven, embodied nature of human
cognition and the statistical patterns of LLMs, highlighting the necessity of
incorporating intrinsic motivation and physical grounding into the design of
more human-aligned agents.

</details>


### [147] [Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning](https://arxiv.org/abs/2508.00323)
*Jianyi Zhang,Xu Ji,Ziyin Zhou,Yuchen Zhou,Shubo Shi,Haoyu Wu,Zhen Li,Shizhao Liu*

Main category: cs.AI

TL;DR: 本文提出ReasonBench，一种评估VLMs在复杂图形推理能力上的基准，并验证了当前模型的显著局限性，同时通过DiaCoT和ReasonTune两种优化策略提高33.5%的性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在复杂图形推理（包括空间、关系和抽象推理）方面表现不足，且缺乏全面评测工具。

Method: 提出ReasonBench基准，涵盖地点、属性、数量等推理维度；并对11种主流VLMs模型进行评测。提出DiaCoT和ReasonTune两种优化方法，分别增强模型的解释性与适应性。

Result: 利用ReasonBench基准，发现当前模型在图形推理任务上的显著局限性，通过DiaCoT和ReasonTune优化后性能提升33.5%。

Conclusion: ReasonBench提供了一个全面的评估平台，揭示现有VLMs的不足，并通过优化进一步推动了图形推理任务的发展。

Abstract: Evaluating the performance of visual language models (VLMs) in graphic
reasoning tasks has become an important research topic. However, VLMs still
show obvious deficiencies in simulating human-level graphic reasoning
capabilities, especially in complex graphic reasoning and abstract problem
solving, which are less studied and existing studies only focus on simple
graphics. To evaluate the performance of VLMs in complex graphic reasoning, we
propose ReasonBench, the first evaluation benchmark focused on structured
graphic reasoning tasks, which includes 1,613 questions from real-world
intelligence tests. ReasonBench covers reasoning dimensions related to
location, attribute, quantity, and multi-element tasks, providing a
comprehensive evaluation of the performance of VLMs in spatial, relational, and
abstract reasoning capabilities. We benchmark 11 mainstream VLMs (including
closed-source and open-source models) and reveal significant limitations of
current models. Based on these findings, we propose a dual optimization
strategy: Diagrammatic Reasoning Chain (DiaCoT) enhances the interpretability
of reasoning by decomposing layers, and ReasonTune enhances the task
adaptability of model reasoning through training, all of which improves VLM
performance by 33.5\%. All experimental data and code are in the repository:
https://huggingface.co/datasets/cistine/ReasonBench.

</details>


### [148] [R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge](https://arxiv.org/abs/2508.00324)
*Yeonjun In,Wonjoong Kim,Sangwu Park,Chanyoung Park*

Main category: cs.AI

TL;DR: 提出了一种名为R1-Act的后训练方法，可改善大型推理模型的安全性，同时保持推理表现。


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型在面对有害指令时安全性不足的问题。

Method: 通过R1-Act后训练方法，该方法显式触发安全知识并引导结构化推理过程，仅需1000个训练样例和90分钟训练。

Result: R1-Act在提高模型安全性方面超越了之前的方法，同时展示出良好的鲁棒性、可扩展性和高效性。

Conclusion: R1-Act是一种简单高效的方法，能够有效改善大型推理模型的安全性，并具有实际应用价值。

Abstract: Although large reasoning models (LRMs) have demonstrated impressive
capabilities on complex tasks, recent studies reveal that these models
frequently fulfill harmful user instructions, raising significant safety
concerns. In this paper, we investigate the underlying cause of LRM safety
risks and find that models already possess sufficient safety knowledge but fail
to activate it during reasoning. Based on this insight, we propose R1-Act, a
simple and efficient post-training method that explicitly triggers safety
knowledge through a structured reasoning process. R1-Act achieves strong safety
improvements while preserving reasoning performance, outperforming prior
alignment methods. Notably, it requires only 1,000 training examples and 90
minutes of training on a single RTX A6000 GPU. Extensive experiments across
multiple LRM backbones and sizes demonstrate the robustness, scalability, and
practical efficiency of our approach.

</details>


### [149] [CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding](https://arxiv.org/abs/2508.00378)
*Shixin Yi,Lin Shang*

Main category: cs.AI

TL;DR: 提出了一种模块化框架CoRGI，通过引入视觉验证模块提高视觉-语言模型的推理性能，提升了解释的真实性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决视觉-语言模型推理过程中缺乏视觉内容基础的问题，增强推理解释的真实性。

Method: 提出CoRGI框架，包括三个阶段：生成推理链、通过视觉模块提取支持证据、结合生成解释和答案，无需端到端重新训练，易于集成到现有模型中。

Result: 在VCR基准测试上验证了CoRGI的有效性，不仅提升了模型性能，且人类评估表明其解释更加真实有帮助。分析了视觉验证步骤的重要性与设计考量。

Conclusion: CoRGI证明了在推理过程中引入视觉证据的重要性，可提升多模态推理的鲁棒性，但也需要关注框架的局限性。

Abstract: Chain-of-Thought (CoT) prompting has shown promise in improving reasoning in
vision-language models (VLMs), but it often produces explanations that are
linguistically fluent yet lack grounding in visual content. We observe that
such hallucinations arise in part from the absence of an explicit verification
mechanism during multi-step reasoning. To address this, we propose
\textbf{CoRGI}(\textbf{C}hain \textbf{o}f \textbf{R}easoning with
\textbf{G}rounded \textbf{I}nsights), a modular framework that introduces
visual verification into the reasoning process. CoRGI follows a three-stage
pipeline: it first generates a textual reasoning chain, then extracts
supporting visual evidence for each reasoning step via a dedicated module
(VEVM), and finally synthesizes the textual rationale with visual evidence to
generate a grounded, verified answer. The framework can be integrated with
existing VLMs without end-to-end retraining. We evaluate CoRGI on the VCR
benchmark and find that it improves reasoning performance on two representative
open-source VLM backbones, Qwen-2.5VL and LLaVA-1.6. Ablation studies confirm
the contribution of each step in the verification module, and human evaluations
suggest that CoRGI leads to more factual and helpful explanations. We also
examine alternative designs for the visual verification step and discuss
potential limitations of post-hoc verification frameworks. These findings
highlight the importance of grounding intermediate reasoning steps in visual
evidence to enhance the robustness of multimodal reasoning.

</details>


### [150] [Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation](https://arxiv.org/abs/2508.00401)
*Riddhi J. Pitliya,Ozan Catal,Toon Van de Maele,Corrado Pezzato,Tim Verbelen*

Main category: cs.AI

TL;DR: 提出了一种新方法，通过在主动推理中实施心智理论（ToM）来实现多智能体合作，代理人可以推测他人的信念和目标而无需共享生成模型或显式通信。


<details>
  <summary>Details</summary>
Motivation: 心智理论使代理人能够推测他人的信念和目标，从而改进多智能体协作中的行为表现。

Method: 框架让拥有ToM的代理人维护其自身和他人信念及目标的不同表征，并通过扩展的推理树规划算法探索联合策略空间。

Result: 通过碰撞避免和觅食任务模拟验证，表明拥有ToM的代理人能更好地合作，减少碰撞并降低重复努力。

Conclusion: 采用ToM代理人仅通过可观测的行为推测他人的信念，显著增强了AI多智能体协作效率，同时对心智理论提供了计算洞察。

Abstract: We present a novel approach to multi-agent cooperation by implementing theory
of mind (ToM) within active inference. ToM - the ability to understand that
others can have differing knowledge and goals - enables agents to reason about
others' beliefs while planning their own actions. Unlike previous active
inference approaches to multi-agent cooperation, our method neither relies on
task-specific shared generative models nor requires explicit communication,
while being generalisable. In our framework, the ToM-equipped agent maintains
distinct representations of its own and others' beliefs and goals. We extend
the sophisticated inference tree-based planning algorithm to systematically
explore joint policy spaces through recursive reasoning. Our approach is
evaluated through collision avoidance and foraging task simulations. Results
demonstrate that ToM-equipped agents cooperate better compared to non-ToM
counterparts by being able to avoid collisions and reduce redundant efforts.
Crucially, ToM agents accomplish this by inferring others' beliefs solely from
observable behaviour. This work advances practical applications in artificial
intelligence while providing computational insights into ToM.

</details>


### [151] [Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](https://arxiv.org/abs/2508.00414)
*Tianqing Fang,Zhisong Zhang,Xiaoyang Wang,Rui Wang,Can Qin,Yuxuan Wan,Jun-Yu Ma,Ce Zhang,Jiaqi Chen,Xiyun Li,Hongming Zhang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: 本文提出了完全开源且免费的多模块代理框架Cognitive Kernel-Pro，可实现复杂推理、网络交互、编码及自主研究能力，旨在推动先进AI代理的发展与评估的民主化。


<details>
  <summary>Details</summary>
Motivation: 当前的代理系统大多闭源且依赖付费API或专有工具，限制了研究社区的可访问性与可重复性，因此需要一个开放且免费的框架来降低开发门槛。

Method: 提出Cognitive Kernel-Pro，通过高质量训练数据的整理和测试时的反思与投票策略提升代理性能，并且在四个主要领域构建查询、轨迹与可验证答案。

Result: 通过对开源模型模型GAIA的评估，Cognitive Kernel-Pro的8B参数模型超越了WebDancer和WebSailor等系统，在开放性与高性能代理领域建立了新的标准。

Conclusion: Cognitive Kernel-Pro 的推出不仅推动了AI代理领域的性能突破，还为开放与公平的AI研究提供了重要工具，其代码已开放供研究社区使用。

Abstract: General AI Agents are increasingly recognized as foundational frameworks for
the next generation of artificial intelligence, enabling complex reasoning, web
interaction, coding, and autonomous research capabilities. However, current
agent systems are either closed-source or heavily reliant on a variety of paid
APIs and proprietary tools, limiting accessibility and reproducibility for the
research community. In this work, we present \textbf{Cognitive Kernel-Pro}, a
fully open-source and (to the maximum extent) free multi-module agent framework
designed to democratize the development and evaluation of advanced AI agents.
Within Cognitive Kernel-Pro, we systematically investigate the curation of
high-quality training data for Agent Foundation Models, focusing on the
construction of queries, trajectories, and verifiable answers across four key
domains: web, file, code, and general reasoning. Furthermore, we explore novel
strategies for agent test-time reflection and voting to enhance agent
robustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving
state-of-the-art results among open-source and free agents. Notably, our
8B-parameter open-source model surpasses previous leading systems such as
WebDancer and WebSailor, establishing a new performance standard for
accessible, high-capability AI agents. Code is available at
https://github.com/Tencent/CognitiveKernel-Pro

</details>


### [152] [Thinking Machines: Mathematical Reasoning in the Age of LLMs](https://arxiv.org/abs/2508.00459)
*Andrea Asperti,Alberto Naibo,Claudio Sacerdoti Coen*

Main category: cs.AI

TL;DR: 本文讨论了大语言模型（LLMs）在编程和形式数学任务中的表现差异，特别研究在自动证明生成中的挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在形式数学证明生成的局限性以及提高其数学认知能力的可能性。

Method: 概述当前的模型与基准，分析形式与非形式数学作为训练领域的权衡，探讨证明生成脆弱性的深层原因，以及LLMs是否具有逻辑推理状态的表征能力。

Result: 在形式数学与编程任务中发现了推理能力的显著差异，并提出了一些可能的改善预期。

Conclusion: LLMs在证明生成上目前仍存在局限性，但通过深刻理解其问题来源，未来有可能进一步突破其在这一领域的能力。

Abstract: Large Language Models (LLMs) have shown remarkable abilities in structured
reasoning and symbolic tasks, with coding emerging as a particular area of
strength. This success has sparked growing interest in applying LLMs to
mathematics, both in informal problem-solving and formal theorem proving.
However, progress in formal mathematics has proven to be significantly more
difficult, despite surface-level similarities between programming and proof
construction. This discrepancy raises important questions about how LLMs
``reason'', how they are supervised, and whether they internally track a notion
of computational or deductive state. In this article, we address the
state-of-the-art of the discipline, focusing on recent models and benchmarks,
and explore three central issues at the intersection of machine learning and
mathematical cognition: (i) the trade-offs between formal and informal
mathematics as training domains; (ii) the deeper reasons why proof generation
remains more brittle than code synthesis; (iii) and the question of whether
LLMs represent, or merely mimic, a notion of evolving logical state. Our goal
is not to draw hard boundaries, but to identify where the current limits lie,
and how they might be extended.

</details>


### [153] [Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking](https://arxiv.org/abs/2508.00500)
*Haoyu Wang,Chris M. Poskitt,Jun Sun,Jiali Wei*

Main category: cs.AI

TL;DR: 本研究提出了一种名为Pro2Guard的框架，用于通过概率可达性分析提升大语言模型代理的运行安全性，它可在危险发生之前进行预测并介入，显著提高了各领域的安全表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理因其随机行为具有显著的安全风险，现有的基于规则的安全体系对长期依赖性以及分布迁移问题表现不足，设计一种更具有前瞻性的实时安全保障机制成为关键需求。

Method: 提出Pro2Guard框架，将代理行为抽象为符号状态，基于离散时间马尔可夫链（DTMC）学习代理行为路径，通过概率预测未来潜在风险，并在高于阈值时提前介入，同时利用语义有效性检查和PAC界限增强模型的统计可靠性。

Result: 通过家庭环境中的体态代理和自动驾驶两个安全关键领域验证是否有效，显著提高未安全行为的预测和干预效果。在体态代理中，最高提前预测93.6%的不安全任务，在自动驾驶中可提前最多38.66秒预测交通违规或碰撞。

Conclusion: Pro2Guard能够提前预测潜在风险并介入，使安全与任务成功率在29%以上转换中取得平衡，显著提升了LLM代理在复杂实际应用中安全运行的能力。

Abstract: Large Language Model (LLM) agents exhibit powerful autonomous capabilities
across domains such as robotics, virtual assistants, and web automation.
However, their stochastic behavior introduces significant safety risks that are
difficult to anticipate. Existing rule-based enforcement systems, such as
AgentSpec, focus on developing reactive safety rules, which typically respond
only when unsafe behavior is imminent or has already occurred. These systems
lack foresight and struggle with long-horizon dependencies and distribution
shifts. To address these limitations, we propose Pro2Guard, a proactive runtime
enforcement framework grounded in probabilistic reachability analysis.
Pro2Guard abstracts agent behaviors into symbolic states and learns a
Discrete-Time Markov Chain (DTMC) from execution traces. At runtime, it
anticipates future risks by estimating the probability of reaching unsafe
states, triggering interventions before violations occur when the predicted
risk exceeds a user-defined threshold. By incorporating semantic validity
checks and leveraging PAC bounds, Pro2Guard ensures statistical reliability
while approximating the underlying ground-truth model. We evaluate Pro2Guard
extensively across two safety-critical domains: embodied household agents and
autonomous vehicles. In embodied agent tasks, Pro2Guard enforces safety early
on up to 93.6% of unsafe tasks using low thresholds, while configurable modes
(e.g., reflect) allow balancing safety with task success, maintaining up to
80.4% task completion. In autonomous driving scenarios, Pro2Guard achieves 100%
prediction of traffic law violations and collisions, anticipating risks up to
38.66 seconds ahead.

</details>


### [154] [MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal Interactions in Multimodal AI Models](https://arxiv.org/abs/2508.00576)
*Zhanliang Wang,Kai Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为MultiSHAP的解释框架，可以以模型无关的方式解释多模态AI模型的跨模态交互。


<details>
  <summary>Details</summary>
Motivation: 多模态AI模型难以解释其内部的跨模态交互机制，这在需要高可信度和可解释性的场景中形成了重大障碍。

Method: 通过使用Shapley互动指数，MultiSHAP能够为多模态AI模型的预测归因至细粒度视觉和文本元素间的交互作用，并支持适用于开源和闭源模型的解释。

Result: MultiSHAP成功捕捉了模型的跨模态推理机制，在公开基准和实际用例中展现了其实用性与可靠性。

Conclusion: MultiSHAP为多模态AI模型的解释提供了一种通用且高效的解决方案，扩展潜力超越两种模态的范畴。

Abstract: Multimodal AI models have achieved impressive performance in tasks that
require integrating information from multiple modalities, such as vision and
language. However, their "black-box" nature poses a major barrier to deployment
in high-stakes applications where interpretability and trustworthiness are
essential. How to explain cross-modal interactions in multimodal AI models
remains a major challenge. While existing model explanation methods, such as
attention map and Grad-CAM, offer coarse insights into cross-modal
relationships, they cannot precisely quantify the synergistic effects between
modalities, and are limited to open-source models with accessible internal
weights. Here we introduce MultiSHAP, a model-agnostic interpretability
framework that leverages the Shapley Interaction Index to attribute multimodal
predictions to pairwise interactions between fine-grained visual and textual
elements (such as image patches and text tokens), while being applicable to
both open- and closed-source models. Our approach provides: (1) instance-level
explanations that reveal synergistic and suppressive cross-modal effects for
individual samples - "why the model makes a specific prediction on this input",
and (2) dataset-level explanation that uncovers generalizable interaction
patterns across samples - "how the model integrates information across
modalities". Experiments on public multimodal benchmarks confirm that MultiSHAP
faithfully captures cross-modal reasoning mechanisms, while real-world case
studies demonstrate its practical utility. Our framework is extensible beyond
two modalities, offering a general solution for interpreting complex multimodal
AI models.

</details>


### [155] [From EMR Data to Clinical Insight: An LLM-Driven Framework for Automated Pre-Consultation Questionnaire Generation](https://arxiv.org/abs/2508.00581)
*Ruiqing Ding,Qianfang Sun,Yongkang Leng,Hui Yin,Xiaojian Li*

Main category: cs.AI

TL;DR: 本文提出了一种新型的多阶段大语言模型框架，用于从电子病历生成全面的预咨询问卷，并通过案例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前直接使用大语言模型生成预咨询问卷在信息完整性、逻辑顺序及疾病综合方面存在挑战。

Method: 提出一个三阶段框架：第一阶段从电子病历中提取关键事实，第二阶段构建个人因果网络并通过聚类生成疾病的代表性网络，第三阶段基于结构化信息生成个性化及标准化的问卷。

Result: 在真实电子病历数据上进行测试并通过临床专家验证，方法在信息覆盖率、诊断相关性、可理解性及生成时间等方面表现优异。

Conclusion: 该方法可有效提升患者信息收集的全面性与效率，具有实际应用潜力。

Abstract: Pre-consultation is a critical component of effective healthcare delivery.
However, generating comprehensive pre-consultation questionnaires from complex,
voluminous Electronic Medical Records (EMRs) is a challenging task. Direct
Large Language Model (LLM) approaches face difficulties in this task,
particularly regarding information completeness, logical order, and
disease-level synthesis. To address this issue, we propose a novel multi-stage
LLM-driven framework: Stage 1 extracts atomic assertions (key facts with
timing) from EMRs; Stage 2 constructs personal causal networks and synthesizes
disease knowledge by clustering representative networks from an EMR corpus;
Stage 3 generates tailored personal and standardized disease-specific
questionnaires based on these structured representations. This framework
overcomes limitations of direct methods by building explicit clinical
knowledge. Evaluated on a real-world EMR dataset and validated by clinical
experts, our method demonstrates superior performance in information coverage,
diagnostic relevance, understandability, and generation time, highlighting its
practical potential to enhance patient information collection.

</details>


### [156] [Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings](https://arxiv.org/abs/2508.00632)
*Alexia Jolicoeur-Martineau*

Main category: cs.AI

TL;DR: 该论文提出了一种新的多媒体内容质量评估指标（AVR-Eval）和一个多智能体系统（AVR-Agent），用于生成和优化交互式音视频内容，如电子游戏。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能在生成交互式多媒体内容（例如电子游戏）方面面临挑战，特别是在需要长期协作和复杂资产的情况下。

Method: 提出AVR-Eval作为评价多媒体内容质量的相对指标，并开发AVR-Agent多智能体系统，用于从多媒体资产库中自动生成和改进JavaScript代码。该系统通过多轮选择、反馈和改进提升内容质量。

Result: 实验表明，AVR-Agent生成的内容相比一次性生成方法有较高的胜率。然而，在利用自定义资产和AVR反馈方面，模型表现尚不理想。

Conclusion: 尽管系统展示了潜力，但当前生成模型在充分利用高质量资产和音视频反馈方面仍存在局限，突显了人与机器内容创作方式上的根本差异。

Abstract: While AI excels at generating text, audio, images, and videos, creating
interactive audio-visual content such as video games remains challenging.
Current LLMs can generate JavaScript games and animations, but lack automated
evaluation metrics and struggle with complex content that normally requires
teams of humans working for many months (multi-shot, multi-agents) using assets
made by artists. To tackle these issues, we built a new metric and a
multi-agent system.
  We propose AVR-Eval, a relative metric for multimedia content quality using
Audio-Visual Recordings (AVRs). An omni-modal model (processing text, video,
and audio) compares the AVRs of two contents, with a text model reviewing
evaluations to determine superiority. We show that AVR-Eval properly identifies
good from broken or mismatched content.
  We built AVR-Agent, a multi-agent system generating JavaScript code from a
bank of multimedia assets (audio, images, 3D models). The coding agent selects
relevant assets, generates multiple initial codes, uses AVR-Eval to identify
the best version, and iteratively improves it through omni-modal agent feedback
from the AVR.
  We run experiments on games and animations with AVR-Eval (win rate of content
A against B). We find that content generated by AVR-Agent has a significantly
higher win rate against content made through one-shot generation. However,
models struggle to leverage custom assets and AVR feedback effectively, showing
no higher win rate. This reveals a critical gap: while humans benefit from
high-quality assets and audio-visual feedback, current coding models do not
seem to utilize these resources as effectively, highlighting fundamental
differences between human and machine content creation approaches.

</details>


### [157] [Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies](https://arxiv.org/abs/2508.00658)
*Chakattrai Sookkongwaree,Tattep Lakmuang,Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: 提出了一种新型的多频带变量时滞Granger因果分析（MB-VLGC）框架，用于更准确地在时间序列中推断因果关系。


<details>
  <summary>Details</summary>
Motivation: 现有的Granger因果分析方法在假定固定时滞的情况下不能准确反映复杂系统中的因果关系，且未考虑频率带对因果关系的影响。

Method: 提出了MB-VLGC框架，形式化定义了多频带变量时滞Granger因果关系，理论上证明其合理性，并设计了高效的推断管道。

Result: 在多个领域的实验表明，新框架在合成和真实数据集上明显优于现有方法。

Conclusion: 新方法可以广泛适用于任何类型的时间序列数据，具有很强的实用性，其代码与数据集也已公开。

Abstract: Understanding causal relationships in time series is fundamental to many
domains, including neuroscience, economics, and behavioral science. Granger
causality is one of the well-known techniques for inferring causality in time
series. Typically, Granger causality frameworks have a strong fix-lag
assumption between cause and effect, which is often unrealistic in complex
systems. While recent work on variable-lag Granger causality (VLGC) addresses
this limitation by allowing a cause to influence an effect with different time
lags at each time point, it fails to account for the fact that causal
interactions may vary not only in time delay but also across frequency bands.
For example, in brain signals, alpha-band activity may influence another region
with a shorter delay than slower delta-band oscillations. In this work, we
formalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a
novel framework that generalizes traditional VLGC by explicitly modeling
frequency-dependent causal delays. We provide a formal definition of MB-VLGC,
demonstrate its theoretical soundness, and propose an efficient inference
pipeline. Extensive experiments across multiple domains demonstrate that our
framework significantly outperforms existing methods on both synthetic and
real-world datasets, confirming its broad applicability to any type of time
series data. Code and datasets are publicly available.

</details>


### [158] [Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI](https://arxiv.org/abs/2508.00665)
*Maryam Mosleh,Marie Devlin,Ellis Solaiman*

Main category: cs.AI

TL;DR: 本论文提出一种结合传统可解释AI技术与生成式AI模型及用户个性化的混合框架，用于教育中的可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的人工智能教育系统缺乏透明性，限制了用户对系统决策的理解，尤其在用户角色和理解层面有所忽视。

Method: 提出一种混合框架，将传统XAI技术、生成式AI模型和用户个性化结合，提供多模态、针对用户需求定制的解释。

Result: 新的框架重新定义了可解释性为动态通信过程，并以用户角色和学习目标为核心，提出具体设计和现有教育领域XAI的局限性。

Conclusion: 研究方向聚焦于提高准确性、公平性和个性化，以实现增强透明性和支持用户为中心的AI体验。

Abstract: Artificial intelligence-driven adaptive learning systems are reshaping
education through data-driven adaptation of learning experiences. Yet many of
these systems lack transparency, offering limited insight into how decisions
are made. Most explainable AI (XAI) techniques focus on technical outputs but
neglect user roles and comprehension. This paper proposes a hybrid framework
that integrates traditional XAI techniques with generative AI models and user
personalisation to generate multimodal, personalised explanations tailored to
user needs. We redefine explainability as a dynamic communication process
tailored to user roles and learning goals. We outline the framework's design,
key XAI limitations in education, and research directions on accuracy,
fairness, and personalisation. Our aim is to move towards explainable AI that
enhances transparency while supporting user-centred experiences.

</details>


### [159] [Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations](https://arxiv.org/abs/2508.00674)
*Banan Alkhateeb,Ellis Solaiman*

Main category: cs.AI

TL;DR: 互联网平台通过个性化的视觉化解释系统来提升用户体验。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体平台的AI推荐虽然显著改进了用户体验，但用户对推荐的原因缺乏理解，导致解释性不足的问题，影响推荐的使用价值。

Method: 提出了一个用户分段与上下文感知的解释系统，基于不同需求与上下文提供视觉化的多样化解释，包括细化的专家版和简化的普通版。

Result: 框架是首个将视觉与数值风格及专家与普通用户所需粒度相结合的系统。计划通过30位用户的公测验证其对决策及信任的影响。

Conclusion: 框架旨在增强推荐的透明性与合理性，为多样化的用户提供个性化的解释方式。

Abstract: Social media platforms today strive to improve user experience through AI
recommendations, yet the value of such recommendations vanishes as users do not
understand the reasons behind them. This issue arises because explainability in
social media is general and lacks alignment with user-specific needs. In this
vision paper, we outline a user-segmented and context-aware explanation layer
by proposing a visual explanation system with diverse explanation methods. The
proposed system is framed by the variety of user needs and contexts, showing
explanations in different visualized forms, including a technically detailed
version for AI experts and a simplified one for lay users. Our framework is the
first to jointly adapt explanation style (visual vs. numeric) and granularity
(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will
validate its impact on decision-making and trust.

</details>


### [160] [Unraveling Hidden Representations: A Multi-Modal Layer Analysis for Better Synthetic Content Forensics](https://arxiv.org/abs/2508.00784)
*Tom Or,Omri Azencot*

Main category: cs.AI

TL;DR: 该论文提出使用大型预训练多模态模型的潜在编码来检测生成内容，其线性分类器在跨多种模态的假内容检测中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型在多个数据领域的成功应用，恶意用户同样利用生成内容进行虚假信息传播及制作深度伪造，这凸显了开发稳健的假内容检测器的必要性。

Method: 提出利用大型预训练多模态模型的潜在编码来区分真假，并训练线性分类器以实现高效准确的跨模态生成内容检测。

Result: 所提出方法在音频和图像的假内容检测上表现优异，超过或媲美强基线方法，并且具有高效的训练和计算性能。

Conclusion: 利用多模态模型的潜在编码可以有效检测真假生成内容，并具备通用性和高效性，展现了成为通用分类器的潜力。

Abstract: Generative models achieve remarkable results in multiple data domains,
including images and texts, among other examples. Unfortunately, malicious
users exploit synthetic media for spreading misinformation and disseminating
deepfakes. Consequently, the need for robust and stable fake detectors is
pressing, especially when new generative models appear everyday. While the
majority of existing work train classifiers that discriminate between real and
fake information, such tools typically generalize only within the same family
of generators and data modalities, yielding poor results on other generative
classes and data domains. Towards a universal classifier, we propose the use of
large pre-trained multi-modal models for the detection of generative content.
Effectively, we show that the latent code of these models naturally captures
information discriminating real from fake. Building on this observation, we
demonstrate that linear classifiers trained on these features can achieve
state-of-the-art results across various modalities, while remaining
computationally efficient, fast to train, and effective even in few-shot
settings. Our work primarily focuses on fake detection in audio and images,
achieving performance that surpasses or matches that of strong baseline
methods.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [161] [Predicting Large-scale Urban Network Dynamics with Energy-informed Graph Neural Diffusion](https://arxiv.org/abs/2508.00037)
*Tong Nie,Jian Sun,Wei Ma*

Main category: cs.LG

TL;DR: 提出了一种基于Transformer架构的可扩展时空网络模型（ScaleSTF），以线性复杂度实现对大规模城市系统动态的高效预测。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络在大规模网络应用中效率与效果上存在权衡问题，亟需设计能够兼顾效率与性能的预测模型。

Method: 从物理法则中汲取灵感，提出一种基于Transformer的可解释的神经扩散模型，其注意力层由低维嵌入引导，具有线性复杂度。

Result: 在交通流、太阳能、智能电表等大规模城市系统的验证中，ScaleSTF展现出优越的性能与良好的可扩展性。

Conclusion: 提出的ScaleSTF模型为大规模城市网络的动态预测提供了一种新视角，可实现高效和可解释的预测能力。

Abstract: Networked urban systems facilitate the flow of people, resources, and
services, and are essential for economic and social interactions. These systems
often involve complex processes with unknown governing rules, observed by
sensor-based time series. To aid decision-making in industrial and engineering
contexts, data-driven predictive models are used to forecast spatiotemporal
dynamics of urban systems. Current models such as graph neural networks have
shown promise but face a trade-off between efficacy and efficiency due to
computational demands. Hence, their applications in large-scale networks still
require further efforts. This paper addresses this trade-off challenge by
drawing inspiration from physical laws to inform essential model designs that
align with fundamental principles and avoid architectural redundancy. By
understanding both micro- and macro-processes, we present a principled
interpretable neural diffusion scheme based on Transformer-like structures
whose attention layers are induced by low-dimensional embeddings. The proposed
scalable spatiotemporal Transformer (ScaleSTF), with linear complexity, is
validated on large-scale urban systems including traffic flow, solar power, and
smart meters, showing state-of-the-art performance and remarkable scalability.
Our results constitute a fresh perspective on the dynamics prediction in
large-scale urban networks.

</details>


### [162] [Hybrid LSTM-Transformer Models for Profiling Highway-Railway Grade Crossings](https://arxiv.org/abs/2508.00039)
*Kaustav Chatterjee,Joshua Q. Li,Fatemeh Ansari,Masud Rana Munna,Kundan Parajulee,Jared Schwennesen*

Main category: cs.LG

TL;DR: 本研究提出了一种结合LSTM和Transformer的混合深度学习框架，用于高轮廓公路铁路交叉口（HRGCs）的廓形测量，并实现了快速、精确的HRGC廓形评估。


<details>
  <summary>Details</summary>
Motivation: 传统HRGC廓形测量方法存在成本高、耗时长、交通扰动和安全隐患，本研究旨在通过创新方法解决这些问题并提高安全性。

Method: 研究开发了一种结合LSTM和Transformer的深度学习框架，利用IMU和GPS传感器获取仪器数据，同时使用工业标准步行剖面仪测量真实数据，并通过不同模型组合进行性能对比。

Result: 模型2（LSTM-Transformer顺序）和模型3（LSTM-Transformer并行）表现出优异的性能，成功生成了HRGC的2D/3D廓形。

Conclusion: 深度学习模型能够快速、准确地评估HRGC挂点敏感性，展示了提高公路和铁路安全性的潜力。

Abstract: Hump crossings, or high-profile Highway Railway Grade Crossings (HRGCs), pose
safety risks to highway vehicles due to potential hang-ups. These crossings
typically result from post-construction railway track maintenance activities or
non-compliance with design guidelines for HRGC vertical alignments.
Conventional methods for measuring HRGC profiles are costly, time-consuming,
traffic-disruptive, and present safety challenges. To address these issues,
this research employed advanced, cost-effective techniques and innovative
modeling approaches for HRGC profile measurement. A novel hybrid deep learning
framework combining Long Short-Term Memory (LSTM) and Transformer architectures
was developed by utilizing instrumentation and ground truth data.
Instrumentation data were gathered using a highway testing vehicle equipped
with Inertial Measurement Unit (IMU) and Global Positioning System (GPS)
sensors, while ground truth data were obtained via an industrial-standard
walking profiler. Field data was collected at the Red Rock Railroad Corridor in
Oklahoma. Three advanced deep learning models Transformer-LSTM sequential
(model 1), LSTM-Transformer sequential (model 2), and LSTM-Transformer parallel
(model 3) were evaluated to identify the most efficient architecture. Models 2
and 3 outperformed the others and were deployed to generate 2D/3D HRGC
profiles. The deep learning models demonstrated significant potential to
enhance highway and railroad safety by enabling rapid and accurate assessment
of HRGC hang-up susceptibility.

</details>


### [163] [Regime-Aware Conditional Neural Processes with Multi-Criteria Decision Support for Operational Electricity Price Forecasting](https://arxiv.org/abs/2508.00040)
*Abhinav Das,Stephan Schlüter*

Main category: cs.LG

TL;DR: 本文结合贝叶斯状态检测与条件神经网络方法，提出了一种用于德国市场电价24小时预测的模型，展示了其相比其他模型的独特优势。


<details>
  <summary>Details</summary>
Motivation: 目标是提高电价预测模型在不同操作场景下的表现，提供更平衡的解决方案，以应对复杂操作需求的决策优化问题。

Method: 使用DS-HDP-HMM进行状态检测后，将数据分为不同状态群，每个状态由独立的CNP负责建模，将输出作为权重混合计算最终预测结果。

Result: 相比DNN和LEAR模型，R-NP模型在多指标评估中展现了较平衡的性能，是2021-2023年综合表现最佳的方案。

Conclusion: 虽然精度最高的模型未必具有最佳操作性，但R-NP模型在多种评估指标中展现较优的平衡性，适合用作综合预测与决策支持工具。

Abstract: This work integrates Bayesian regime detection with conditional neural
processes for 24-hour electricity price prediction in the German market. Our
methodology integrates regime detection using a disentangled sticky
hierarchical Dirichlet process hidden Markov model (DS-HDP-HMM) applied to
daily electricity prices. Each identified regime is subsequently modeled by an
independent conditional neural process (CNP), trained to learn localized
mappings from input contexts to 24-dimensional hourly price trajectories, with
final predictions computed as regime-weighted mixtures of these CNP outputs. We
rigorously evaluate R-NP against deep neural networks (DNN) and Lasso estimated
auto-regressive (LEAR) models by integrating their forecasts into diverse
battery storage optimization frameworks, including price arbitrage, risk
management, grid services, and cost minimization. This operational utility
assessment revealed complex performance trade-offs: LEAR often yielded superior
absolute profits or lower costs, while DNN showed exceptional optimality in
specific cost-minimization contexts. Recognizing that raw prediction accuracy
doesn't always translate to optimal operational outcomes, we employed TOPSIS as
a comprehensive multi-criteria evaluation layer. Our TOPSIS analysis identified
LEAR as the top-ranked model for 2021, but crucially, our proposed R-NP model
emerged as the most balanced and preferred solution for 2021, 2022 and 2023.

</details>


### [164] [Learning Like Humans: Resource-Efficient Federated Fine-Tuning through Cognitive Developmental Stages](https://arxiv.org/abs/2508.00041)
*Yebo Wu,Jingguang Li,Zhijiang Guo,Li Li*

Main category: cs.LG

TL;DR: 引入了一种名为Developmental Federated Tuning (DevFT)的新方法，通过分阶段优化过程实现联邦微调，提升效率和性能，同时减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLM）的联邦微调需要大量计算资源，限制了其在边缘设备上的应用。本研究的目标是设计一种高效的联邦微调方法，既能保护数据隐私，又能降低资源需求。

Method: DevFT采用了类似于认知发展的分阶段微调方法，逐步构建具有更高能力的模型。引入了冲突引导的层分组和基于差分的层融合技术，从而有效提取关键信息并优化参数初始化，避免局部最小值问题。

Result: 实验表明，DevFT在多项基准测试中超越了现有方法，实现了4.59倍的收敛速度提升、10.67倍的通信开销减少，以及平均9.07%的性能提升。

Conclusion: DevFT是一种高效且兼容现有方法的解决方案，能够通过分阶段的联邦微调提升模型性能，同时显著节省计算资源和通信成本。

Abstract: Federated fine-tuning enables Large Language Models (LLMs) to adapt to
downstream tasks while preserving data privacy, but its resource-intensive
nature limits deployment on edge devices. In this paper, we introduce
Developmental Federated Tuning (DevFT), a resource-efficient approach inspired
by cognitive development that progressively builds a powerful LLM from a
compact foundation. DevFT decomposes the fine-tuning process into developmental
stages, each optimizing submodels with increasing parameter capacity. Knowledge
from earlier stages transfers to subsequent submodels, providing optimized
initialization parameters that prevent convergence to local minima and
accelerate training. This paradigm mirrors human learning, gradually
constructing comprehensive knowledge structure while refining existing skills.
To efficiently build stage-specific submodels, DevFT introduces
deconfliction-guided layer grouping and differential-based layer fusion to
distill essential information and construct representative layers. Evaluations
across multiple benchmarks demonstrate that DevFT significantly outperforms
state-of-the-art methods, achieving up to 4.59$\times$ faster convergence,
10.67$\times$ reduction in communication overhead, and 9.07% average
performance improvement, while maintaining compatibility with existing
approaches.

</details>


### [165] [Improved Robustness and Functional Localization in Topographic CNNs Through Weight Similarity](https://arxiv.org/abs/2508.00043)
*Nhut Truong,Uri Hasson*

Main category: cs.LG

TL;DR: 本文探讨了两种拓扑约束（权重相似性WS和激活相似性AS）在卷积神经网络中的应用及其影响，展示了WS优于AS和标准卷积神经网络（CNN）的多方面优势。


<details>
  <summary>Details</summary>
Motivation: 探讨拓扑约束对神经网络表征学习及空间功能组织的影响，以弥补以往在拓扑实现对比方面研究的不足。

Method: 利用带有两种拓扑约束（WS和AS）的拓扑卷积神经网络进行实验，分析其分类准确性、权重扰动和输入降解下的鲁棒性，以及学习到的表征的空间组织特性。

Result: 发现WS在噪声鲁棒性、网络权重破坏条件下的准确性、输入敏感性、功能定位、和网络几何表征上均显示出显著优势。

Conclusion: 权重相似性拓扑约束（WS）能够在端到端训练中生成更加鲁棒的表征，并能有效塑造特征学习和功能组织，因此具有重要研究意义。

Abstract: Topographic neural networks are computational models that can simulate the
spatial and functional organization of the brain. Topographic constraints in
neural networks can be implemented in multiple ways, with potentially different
impacts on the representations learned by the network. The impact of such
different implementations has not been systematically examined. To this end,
here we compare topographic convolutional neural networks trained with two
spatial constraints: Weight Similarity (WS), which pushes neighboring units to
develop similar incoming weights, and Activation Similarity (AS), which
enforces similarity in unit activations. We evaluate the resulting models on
classification accuracy, robustness to weight perturbations and input
degradation, and the spatial organization of learned representations. Compared
to both AS and standard CNNs, WS provided three main advantages: i) improved
robustness to noise, also showing higher accuracy under weight corruption; ii)
greater input sensitivity, reflected in higher activation variance; and iii)
stronger functional localization, with units showing similar activations
positioned at closer distances. In addition, WS produced differences in
orientation tuning, symmetry sensitivity, and eccentricity profiles of units,
indicating an influence of this spatial constraint on the representational
geometry of the network. Our findings suggest that during end-to-end training,
WS constraints produce more robust representations than AS or non-topographic
CNNs. These findings also suggest that weight-based spatial constraints can
shape feature learning and functional organization in biophysical inspired
models.

</details>


### [166] [Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains](https://arxiv.org/abs/2508.00046)
*Ruo Yu Tao,Kaicheng Guo,Cameron Allen,George Konidaris*

Main category: cs.LG

TL;DR: 本文提出了一种用于评测部分可观性强化学习算法的基准框架。


<details>
  <summary>Details</summary>
Motivation: 当前的部分可观性评估基准仅覆盖简单的状态别名形式，不能充分代表真实环境中的复杂现象。

Method: 作者提出POBAX框架，涵盖多种部分可观性的基准任务，并为其设计了记忆可改进环境，提供推荐超参数和算法实现。

Result: 实验显示所选任务具有记忆可改进性，能有效检测算法应对部分可观性的能力。

Conclusion: POBAX框架能够为部分可观性研究提供具体信号，并促进相关算法的公平评估和发展。

Abstract: Mitigating partial observability is a necessary but challenging task for
general reinforcement learning algorithms. To improve an algorithm's ability to
mitigate partial observability, researchers need comprehensive benchmarks to
gauge progress. Most algorithms tackling partial observability are only
evaluated on benchmarks with simple forms of state aliasing, such as feature
masking and Gaussian noise. Such benchmarks do not represent the many forms of
partial observability seen in real domains, like visual occlusion or unknown
opponent intent. We argue that a partially observable benchmark should have two
key properties. The first is coverage in its forms of partial observability, to
ensure an algorithm's generalizability. The second is a large gap between the
performance of a agents with more or less state information, all other factors
roughly equal. This gap implies that an environment is memory improvable: where
performance gains in a domain are from an algorithm's ability to cope with
partial observability as opposed to other factors. We introduce best-practice
guidelines for empirically benchmarking reinforcement learning under partial
observability, as well as the open-source library POBAX: Partially Observable
Benchmarks in JAX. We characterize the types of partial observability present
in various environments and select representative environments for our
benchmark. These environments include localization and mapping, visual control,
games, and more. Additionally, we show that these tasks are all memory
improvable and require hard-to-learn memory functions, providing a concrete
signal for partial observability research. This framework includes recommended
hyperparameters as well as algorithm implementations for fast, out-of-the-box
evaluation, as well as highly performant environments implemented in JAX for
GPU-scalable experimentation.

</details>


### [167] [TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection](https://arxiv.org/abs/2508.00047)
*Yuan-Cheng Yu,Yen-Chieh Ouyang,Chun-An Lin*

Main category: cs.LG

TL;DR: 本文提出一种多分支大语言模型（TriP-LLM）用于时间序列异常检测，实验表明其优于现有方法，并且节省内存。


<details>
  <summary>Details</summary>
Motivation: 随着物联网和智能制造的发展，时间序列数据在规模和复杂性上快速增长，传统统计方法难以应对，需引入更加先进的技术。

Method: 通过三分支网络（本地分支、选择分支和全局分支）将时间序列编码为片段化token，并利用预训练的大语言模型处理。

Result: 在多组公开基准数据集上进行评估，TriP-LLM在无偏、统一框架下优于最新方法，并验证了大语言模型对架构的显著贡献。

Conclusion: TriP-LLM方法同时具备检测能力强和更低内存消耗的优点，适合GPU内存受限场景，全部代码和模型公开发布。

Abstract: Time-series anomaly detection plays a central role across a wide range of
application domains. With the increasing proliferation of the Internet of
Things (IoT) and smart manufacturing, time-series data has dramatically
increased in both scale and dimensionality. This growth has exposed the
limitations of traditional statistical methods in handling the high
heterogeneity and complexity of such data. Inspired by the recent success of
large language models (LLMs) in multimodal tasks across language and vision
domains, we propose a novel unsupervised anomaly detection framework: A
Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly
Detection (TriP-LLM). TriP-LLM integrates local and global temporal features
through a tri-branch design-Patching, Selection, and Global-to encode the input
time series into patch-wise tokens, which are then processed by a frozen,
pretrained LLM. A lightweight patch-wise decoder reconstructs the input, from
which anomaly scores are derived. We evaluate TriP-LLM on several public
benchmark datasets using PATE, a recently proposed threshold-free evaluation
metric, and conduct all comparisons within a unified open-source framework to
ensure fairness. Experimental results show that TriP-LLM consistently
outperforms recent state-of-the-art methods across all datasets, demonstrating
strong detection capabilities. Furthermore, through extensive ablation studies,
we verify the substantial contribution of the LLM to the overall architecture.
Compared to LLM-based approaches using Channel Independence (CI) patch
processing, TriP-LLM achieves significantly lower memory consumption, making it
more suitable for GPU memory-constrained environments. All code and model
checkpoints are publicly available on https://github.com/YYZStart/TriP-LLM.git

</details>


### [168] [Evaluating COVID 19 Feature Contributions to Bitcoin Return Forecasting: Methodology Based on LightGBM and Genetic Optimization](https://arxiv.org/abs/2508.00078)
*Imen Mahmoud,Andrei Velichko*

Main category: cs.LG

TL;DR: 本文提出了一个结合LightGBM回归模型与遗传算法（GA）的新方法框架，用于评估与COVID-19相关指标对比特币回报预测的贡献，发现健康数据显著提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 旨在探讨将疫情相关健康数据纳入模型是否能显著提升比特币回报预测的准确性，而不仅仅是进行回报预测。

Method: 整合LightGBM回归模型与遗传算法（GA），采用包含或不包含COVID-19特征的数据集，以深入评估健康数据对预测模型性能的影响。通过31次独立实验，利用PFI分析个体特征贡献，统计比较重要性能指标。

Result: 1. COVID-19指标显著提升模型性能（R2提高40%，RMSE降低2%）。2. 疫苗接种率（特别是全接种75分位数）为最重要预测因子。

Conclusion: 所提方法拓展现有金融分析工具，将公共健康信号整合进来，为投资者和政策制定者在系统性危机中提供了更精确的市场不确定性预测工具。

Abstract: This study proposes a novel methodological framework integrating a LightGBM
regression model and genetic algorithm (GA) optimization to systematically
evaluate the contribution of COVID-19-related indicators to Bitcoin return
prediction. The primary objective was not merely to forecast Bitcoin returns
but rather to determine whether including pandemic-related health data
significantly enhances prediction accuracy. A comprehensive dataset comprising
daily Bitcoin returns and COVID-19 metrics (vaccination rates,
hospitalizations, testing statistics) was constructed. Predictive models,
trained with and without COVID-19 features, were optimized using GA over 31
independent runs, allowing robust statistical assessment. Performance metrics
(R2, RMSE, MAE) were statistically compared through distribution overlaps and
Mann-Whitney U tests. Permutation Feature Importance (PFI) analysis quantified
individual feature contributions. Results indicate that COVID-19 indicators
significantly improved model performance, particularly in capturing extreme
market fluctuations (R2 increased by 40%, RMSE decreased by 2%, both highly
significant statistically). Among COVID-19 features, vaccination metrics,
especially the 75th percentile of fully vaccinated individuals, emerged as
dominant predictors. The proposed methodology extends existing financial
analytics tools by incorporating public health signals, providing investors and
policymakers with refined indicators to navigate market uncertainty during
systemic crises.

</details>


### [169] [Foundations of Interpretable Models](https://arxiv.org/abs/2508.00545)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Alberto Termine,Mateja Jamnik,Giuseppe Marra*

Main category: cs.LG

TL;DR: 本文提出现有的可解释性定义不可操作，并提出了一个新的定义，以及用于设计可解释模型的通用蓝图和开源库。


<details>
  <summary>Details</summary>
Motivation: 目前的可解释性定义缺乏指导性，无法支持鲁棒的可解释模型设计。

Method: 提出一个新的简单且包含现有非正式概念的可解释性定义，展示其行动性，并提供通用模型设计蓝图和开源库。

Result: 证明了新定义的可操作性，开发了支持可解释性数据结构和流程的开源库。

Conclusion: 通过新定义和配套工具为可解释AI模型的设计提供了系统化的支持。

Abstract: We argue that existing definitions of interpretability are not actionable in
that they fail to inform users about general, sound, and robust interpretable
model design. This makes current interpretability research fundamentally
ill-posed. To address this issue, we propose a definition of interpretability
that is general, simple, and subsumes existing informal notions within the
interpretable AI community. We show that our definition is actionable, as it
directly reveals the foundational properties, underlying assumptions,
principles, data structures, and architectural features necessary for designing
interpretable models. Building on this, we propose a general blueprint for
designing interpretable models and introduce the first open-sourced library
with native support for interpretable data structures and processes.

</details>


### [170] [Stress-Aware Resilient Neural Training](https://arxiv.org/abs/2508.00098)
*Ashkan Shakarami,Yousef Yeganeh,Azade Farshad,Lorenzo Nicole,Stefano Ghidoni,Nassir Navab*

Main category: cs.LG

TL;DR: 提出了一种名为“压力感知学习”的鲁棒神经网络训练范式，模拟材料科学中的结构疲劳原理，动态调整优化行为，提升模型鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 受材料科学中临时和永久变形概念的启发，希望通过应对训练过程中的不稳定性和优化难度，提升深度学习模型的鲁棒性和泛化性能。

Method: 提出了“塑性变形优化器”，利用动态噪声扰动参数，通过“应力信号”检测训练损失和准确率的停滞状况，帮助模型逃离尖锐极小值并寻求较平坦且更具泛化能力的损失区间。

Result: 在六种架构、四种优化器和七个视觉任务基准上进行了实验，显示模型的鲁棒性和泛化性均得到了显著提升，且计算开销极低。

Conclusion: 应力感知学习通过动态调整优化行为，训练出性能更佳、鲁棒性和泛化能力更强的模型，具有一定的实用价值和可扩展性。

Abstract: This paper introduces Stress-Aware Learning, a resilient neural training
paradigm in which deep neural networks dynamically adjust their optimization
behavior - whether under stable training regimes or in settings with uncertain
dynamics - based on the concept of Temporary (Elastic) and Permanent (Plastic)
Deformation, inspired by structural fatigue in materials science. To
instantiate this concept, we propose Plastic Deformation Optimizer, a
stress-aware mechanism that injects adaptive noise into model parameters
whenever an internal stress signal - reflecting stagnation in training loss and
accuracy - indicates persistent optimization difficulty. This enables the model
to escape sharp minima and converge toward flatter, more generalizable regions
of the loss landscape. Experiments across six architectures, four optimizers,
and seven vision benchmarks demonstrate improved robustness and generalization
with minimal computational overhead. The code and 3D visuals will be available
on GitHub: https://github.com/Stress-Aware-Learning/SAL.

</details>


### [171] [StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection](https://arxiv.org/abs/2508.00117)
*Md. Ehsanul Haque,S. M. Jahidul Islam,Shakil Mia,Rumana Sharmin,Ashikuzzaman,Md Samir Morshed,Md. Tahmidul Huque*

Main category: cs.LG

TL;DR: 提出了一种新的机器学习模型StackLiverNet，用于精准检测肝病，并解决了现有方法的分类错误率高、解释性差和计算成本高等问题。


<details>
  <summary>Details</summary>
Motivation: 肝病需要精确及时的诊断，但现有模型在误分类、可解释性和计算效率等方面存在不足，促使研究者开发更有效的方法。

Method: 开发了StackLiverNet，利用数据预处理、特征选择与随机欠采样，结合多个经过超参数优化的分类器和LightGBM作为元模型，提升模型的性能与稳健性。

Result: 模型表现优异，测试准确率99.89%，Cohen Kappa值0.9974，AUC值0.9993，具有快速训练与推断速度，训练时间4.2783秒，推断时间0.1106秒。

Conclusion: StackLiverNet模型提升了肝病检测的精准性、效率及可解释性，并具备临床应用的潜力。

Abstract: Liver diseases are a serious health concern in the world, which requires
precise and timely diagnosis to enhance the survival chances of patients. The
current literature implemented numerous machine learning and deep learning
models to classify liver diseases, but most of them had some issues like high
misclassification error, poor interpretability, prohibitive computational
expense, and lack of good preprocessing strategies. In order to address these
drawbacks, we introduced StackLiverNet in this study; an interpretable stacked
ensemble model tailored to the liver disease detection task. The framework uses
advanced data preprocessing and feature selection technique to increase model
robustness and predictive ability. Random undersampling is performed to deal
with class imbalance and make the training balanced. StackLiverNet is an
ensemble of several hyperparameter-optimized base classifiers, whose
complementary advantages are used through a LightGBM meta-model. The provided
model demonstrates excellent performance, with the testing accuracy of 99.89%,
Cohen Kappa of 0.9974, and AUC of 0.9993, having only 5 misclassifications, and
efficient training and inference speeds that are amenable to clinical practice
(training time 4.2783 seconds, inference time 0.1106 seconds). Besides, Local
Interpretable Model-Agnostic Explanations (LIME) are applied to generate
transparent explanations of individual predictions, revealing high
concentrations of Alkaline Phosphatase and moderate SGOT as important
observations of liver disease. Also, SHAP was used to rank features by their
global contribution to predictions, while the Morris method confirmed the most
influential features through sensitivity analysis.

</details>


### [172] [Structured Transformations for Stable and Interpretable Neural Computation](https://arxiv.org/abs/2508.00127)
*Saleh Nikooroo,Thomas Engel*

Main category: cs.LG

TL;DR: 本文提出了一种对神经网络层级变换的新表述，通过分解线性操作和残差矫正部件，实现信号传播的改善和训练动态的优化，以提升神经网络的稳定性和解释性。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络虽然具有强大的性能，但通常缺乏促进稳定学习和可解释行为的结构性保障。本文旨在提出一种新的方法来解决这个问题。

Method: 将层级变换分解为结构化线性算子和残差矫正，并兼容标准学习目标和反向传播，确保信息稳定流动并提高训练动态。

Result: 实验表明，采用该结构化变换的模型表现出更好的梯度条件、更低的扰动敏感性和更强的层级鲁棒性，这些优势在不同规模和训练条件下均得到验证。

Conclusion: 该研究为构建更稳定、更透明的神经网络架构奠定了基础，为理解和分析学习行为提供了新工具，同时保持了模型的表达能力。

Abstract: Despite their impressive performance, contemporary neural networks often lack
structural safeguards that promote stable learning and interpretable behavior.
In this work, we introduce a reformulation of layer-level transformations that
departs from the standard unconstrained affine paradigm. Each transformation is
decomposed into a structured linear operator and a residual corrective
component, enabling more disciplined signal propagation and improved training
dynamics. Our formulation encourages internal consistency and supports stable
information flow across depth, while remaining fully compatible with standard
learning objectives and backpropagation. Through a series of synthetic and
real-world experiments, we demonstrate that models constructed with these
structured transformations exhibit improved gradient conditioning, reduced
sensitivity to perturbations, and layer-wise robustness. We further show that
these benefits persist across architectural scales and training regimes. This
study serves as a foundation for a more principled class of neural
architectures that prioritize stability and transparency-offering new tools for
reasoning about learning behavior without sacrificing expressive power.

</details>


### [173] [ECG Latent Feature Extraction with Autoencoders for Downstream Prediction Tasks](https://arxiv.org/abs/2508.00131)
*Christopher Harvey,Sumaiya Shomaji,Zijun Yao,Amit Noheria*

Main category: cs.LG

TL;DR: 该研究提出通过特征生成方法简化心电图数据复杂性，并使用新型变分自编码器（VAE）变体显著提高信号重建质量和预测性能。


<details>
  <summary>Details</summary>
Motivation: 由于心电图信号高度复杂以及个体差异性较大，在小样本训练数据条件下难以被深度学习模型有效利用。

Method: 采用特征生成方法，包括主成分分析（PCA）和变分自编码器（VAE）变体（如SAE，Annealed beta-VAE，Cyclical beta-VAE）来降低心电图数据复杂性，并结合轻量梯度提升机（LGBM）进行下游预测。

Result: A beta-VAE在信号重建方面表现最佳，MAE降至噪声水平；结合SAE编码和传统心电图特征，模型对左心室射血分数降低的预测AUROC达到0.901，与现有CNN模型表现相当，但计算资源需求更低。该方法还在少数据条件下避免了过拟合。

Conclusion: 研究表明，VAE编码不仅能简化心电图数据复杂性，还为小规模标记数据场景下的深度学习应用提供了实用解决方案。

Abstract: The electrocardiogram (ECG) is an inexpensive and widely available tool for
cardiac assessment. Despite its standardized format and small file size, the
high complexity and inter-individual variability of ECG signals (typically a
60,000-size vector with 12 leads at 500 Hz) make it challenging to use in deep
learning models, especially when only small training datasets are available.
This study addresses these challenges by exploring feature generation methods
from representative beat ECGs, focusing on Principal Component Analysis (PCA)
and Autoencoders to reduce data complexity. We introduce three novel
Variational Autoencoder (VAE) variants-Stochastic Autoencoder (SAE), Annealed
beta-VAE (A beta-VAE), and Cyclical beta VAE (C beta-VAE)-and compare their
effectiveness in maintaining signal fidelity and enhancing downstream
prediction tasks using a Light Gradient Boost Machine (LGBM). The A beta-VAE
achieved superior signal reconstruction, reducing the mean absolute error (MAE)
to 15.7+/-3.2 muV, which is at the level of signal noise. Moreover, the SAE
encodings, when combined with traditional ECG summary features, improved the
prediction of reduced Left Ventricular Ejection Fraction (LVEF), achieving an
holdout test set area under the receiver operating characteristic curve (AUROC)
of 0.901 with a LGBM classifier. This performance nearly matches the 0.909
AUROC of state-of-the-art CNN model but requires significantly less
computational resources. Further, the ECG feature extraction-LGBM pipeline
avoids overfitting and retains predictive performance when trained with less
data. Our findings demonstrate that these VAE encodings are not only effective
in simplifying ECG data but also provide a practical solution for applying deep
learning in contexts with limited-scale labeled training data.

</details>


### [174] [INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling Network Prediction via Reinforcement Learning Boosted Graph Neural Networks](https://arxiv.org/abs/2508.00141)
*Mohit Gupta,Debjit Bhowmick,Rhys Newbury,Meead Saberi,Shirui Pan,Ben Beck*

Main category: cs.LG

TL;DR: 本文提出了一种新型的基于强化学习和图神经网络的框架INSPIRE-GNN，用于优化传感器布局并改善稀疏数据环境下的自行车流量估计。实验表明，其在改善估计性能方面优于传统及其他机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 在城市交通规划中，精确的自行车流量估计是关键，但大多数城市因传感器覆盖有限面临稀疏数据的问题。

Method: 提出INSPIRE-GNN框架，将图卷积网络（GCN）、图注意力网络（GAT）与基于深度Q网络（DQN）的强化学习算法相结合，以优化传感器布局、提升稀疏自行车流量数据估计准确性。

Result: 在墨尔本的自行车网络实验中，通过新增50、100、200和500个传感器的布局，INSPIRE-GNN显著提高估计准确性，优于基于启发式算法和传统学习模型。

Conclusion: 此框架为交通规划者提供了一种高效扩展传感器网络并提升流量估计和数据可靠性的工具，助力改善交通规划决策。

Abstract: Accurate link-level bicycling volume estimation is essential for sustainable
urban transportation planning. However, many cities face significant challenges
of high data sparsity due to limited bicycling count sensor coverage. To
address this issue, we propose INSPIRE-GNN, a novel Reinforcement Learning
(RL)-boosted hybrid Graph Neural Network (GNN) framework designed to optimize
sensor placement and improve link-level bicycling volume estimation in
data-sparse environments. INSPIRE-GNN integrates Graph Convolutional Networks
(GCN) and Graph Attention Networks (GAT) with a Deep Q-Network (DQN)-based RL
agent, enabling a data-driven strategic selection of sensor locations to
maximize estimation performance. Applied to Melbourne's bicycling network,
comprising 15,933 road segments with sensor coverage on only 141 road segments
(99% sparsity) - INSPIRE-GNN demonstrates significant improvements in volume
estimation by strategically selecting additional sensor locations in
deployments of 50, 100, 200 and 500 sensors. Our framework outperforms
traditional heuristic methods for sensor placement such as betweenness
centrality, closeness centrality, observed bicycling activity and random
placement, across key metrics such as Mean Squared Error (MSE), Root Mean
Squared Error (RMSE) and Mean Absolute Error (MAE). Furthermore, our
experiments benchmark INSPIRE-GNN against standard machine learning and deep
learning models in the bicycle volume estimation performance, underscoring its
effectiveness. Our proposed framework provides transport planners actionable
insights to effectively expand sensor networks, optimize sensor placement and
maximize volume estimation accuracy and reliability of bicycling data for
informed transportation planning decisions.

</details>


### [175] [Watch the Weights: Unsupervised monitoring and control of fine-tuned LLMs](https://arxiv.org/abs/2508.00161)
*Ziqian Zhong,Aditi Raghunathan*

Main category: cs.LG

TL;DR: 本文提出了一种基于权重差分的解释方法，用于监控和控制微调后的大语言模型(LLMs)，无需使用类似于训练数据分布的数据。


<details>
  <summary>Details</summary>
Motivation: 现有的模型可解释性方法主要依赖于激活值，需假设数据分布相似，这在处理出分布数据(如后门攻击)时存在局限性。

Method: 通过分析模型微调前后权重的奇异向量，并监测激活值的余弦相似性，来检测和理解微调模型的行为变化。

Result: 1. 在检测后门模型攻击时，可阻止高达100%的攻击，误报率低于1.2%。2. 对已“遗忘”主题，检测准确率达95.42%，并可复原被“遗忘”的信息。

Conclusion: 新方法不仅有助于模型的行为监控和检测，还可用于对商用微调模型的预部署审计，并揭示其策略和重点。

Abstract: The releases of powerful open-weight large language models (LLMs) are often
not accompanied by access to their full training data. Existing
interpretability methods, particularly those based on activations, often
require or assume distributionally similar data. This is a significant
limitation when detecting and defending against novel potential threats like
backdoors, which are by definition out-of-distribution.
  In this work, we introduce a new method for understanding, monitoring and
controlling fine-tuned LLMs that interprets weights, rather than activations,
thereby side stepping the need for data that is distributionally similar to the
unknown training data. We demonstrate that the top singular vectors of the
weight difference between a fine-tuned model and its base model correspond to
newly acquired behaviors. By monitoring the cosine similarity of activations
along these directions, we can detect salient behaviors introduced during
fine-tuning with high precision.
  For backdoored models that bypasses safety mechanisms when a secret trigger
is present, our method stops up to 100% of attacks with a false positive rate
below 1.2%. For models that have undergone unlearning, we detect inference on
erased topics with accuracy up to 95.42% and can even steer the model to
recover "unlearned" information. Besides monitoring, our method also shows
potential for pre-deployment model auditing: by analyzing commercial
instruction-tuned models (OLMo, Llama, Qwen), we are able to uncover
model-specific fine-tuning focus including marketing strategies and Midjourney
prompt generation.
  Our implementation can be found at https://github.com/fjzzq2002/WeightWatch.

</details>


### [176] [DiSC-Med: Diffusion-based Semantic Communications for Robust Medical Image Transmission](https://arxiv.org/abs/2508.00172)
*Fupei Guo,Hao Zheng,Xiang Zhang,Li Chen,Yue Wang,Songyang Zhang*

Main category: cs.LG

TL;DR: 提出了一种名为DiSC-Med的新型扩散式语义通信框架，用于高效和鲁棒的医疗图像远程传输。


<details>
  <summary>Details</summary>
Motivation: 解决远程医疗中，通过噪声信道和有限带宽传输医疗数据的关键挑战。

Method: 开发了一个名为DiSC-Med的框架，结合医学增强的压缩和去噪模块，在噪声条件下高效捕捉语义信息并实现超高效带宽利用。

Result: 在真实医疗数据集上的广泛实验验证了该框架的有效性和优越性能。

Conclusion: 该方法具有实现鲁棒和高效远程医疗应用的潜力。

Abstract: The rapid development of artificial intelligence has driven smart health with
next-generation wireless communication technologies, stimulating exciting
applications in remote diagnosis and intervention. To enable a timely and
effective response for remote healthcare, efficient transmission of medical
data through noisy channels with limited bandwidth emerges as a critical
challenge. In this work, we propose a novel diffusion-based semantic
communication framework, namely DiSC-Med, for the medical image transmission,
where medical-enhanced compression and denoising blocks are developed for
bandwidth efficiency and robustness, respectively. Unlike conventional
pixel-wise communication framework, our proposed DiSC-Med is able to capture
the key semantic information and achieve superior reconstruction performance
with ultra-high bandwidth efficiency against noisy channels. Extensive
experiments on real-world medical datasets validate the effectiveness of our
framework, demonstrating its potential for robust and efficient telehealth
applications.

</details>


### [177] [RL as Regressor: A Reinforcement Learning Approach for Function Approximation](https://arxiv.org/abs/2508.00174)
*Yongchao Huang*

Main category: cs.LG

TL;DR: 本文提出将回归问题框架化为强化学习（RL）问题，通过自定义奖励信号和使用RL算法解决复杂目标函数的回归任务。


<details>
  <summary>Details</summary>
Motivation: 旨在突破传统回归技术对预定义、可微损失函数的限制，解决非对称成本及复杂非可微目标的回归问题。

Method: 将回归预测视为强化学习中的行动，用自定义的预测误差作为奖励信号，并逐步开发强大的Actor-Critic代理，采用优先经验回放、网络扩容和位置编码等优化措施。

Result: 实验表明，提出的RL框架不仅成功解决了回归问题，还显著提高了定义目标和引导学习的灵活性。

Conclusion: 通过将回归问题重构为RL问题，提供了一种更灵活的目标定义和学习引导方式，拓展了传统回归的应用领域。

Abstract: Standard regression techniques, while powerful, are often constrained by
predefined, differentiable loss functions such as mean squared error. These
functions may not fully capture the desired behavior of a system, especially
when dealing with asymmetric costs or complex, non-differentiable objectives.
In this paper, we explore an alternative paradigm: framing regression as a
Reinforcement Learning (RL) problem. We demonstrate this by treating a model's
prediction as an action and defining a custom reward signal based on the
prediction error, and we can leverage powerful RL algorithms to perform
function approximation. Through a progressive case study of learning a noisy
sine wave, we illustrate the development of an Actor-Critic agent, iteratively
enhancing it with Prioritized Experience Replay, increased network capacity,
and positional encoding to enable a capable RL agent for this regression task.
Our results show that the RL framework not only successfully solves the
regression problem but also offers enhanced flexibility in defining objectives
and guiding the learning process.

</details>


### [178] [EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes](https://arxiv.org/abs/2508.00180)
*Adam Block,Cyril Zhang*

Main category: cs.LG

TL;DR: 研究提出了一种名为BEMA的方法，用于改进语言模型微调过程中的训练稳定性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统的EMA方法虽能抑制训练中的随机性，但引入的历史偏差导致优化滞后。为了解决这一问题，研究提出了可以消除偏差但保留减小方差特性的BEMA。

Method: 提出了一种改进的指数移动平均方法（BEMA），通过引入偏差校正机制，在理论模型中证明其优化性能优于标准EMA和传统训练方式。

Result: 在语言模型基准测试中，实验表明BEMA显著提升了训练收敛速度和最终性能。

Conclusion: BEMA是一种理论驱动且实用的方法，可以在语言模型微调中提供更稳定高效的训练。

Abstract: Stochasticity in language model fine-tuning, often caused by the small batch
sizes typically used in this regime, can destabilize training by introducing
large oscillations in generation quality. A popular approach to mitigating this
instability is to take an Exponential moving average (EMA) of weights
throughout training. While EMA reduces stochasticity, thereby smoothing
training, the introduction of bias from old iterates often creates a lag in
optimization relative to vanilla training. In this work, we propose the
Bias-Corrected Exponential Moving Average (BEMA), a simple and practical
augmentation of EMA that retains variance-reduction benefits while eliminating
bias. BEMA is motivated by a simple theoretical model wherein we demonstrate
provable acceleration of BEMA over both a standard EMA and vanilla training.
Through an extensive suite of experiments on Language Models, we show that BEMA
leads to significantly improved convergence rates and final performance over
both EMA and vanilla training in a variety of standard LM benchmarks, making
BEMA a practical and theoretically motivated intervention for more stable and
efficient fine-tuning.

</details>


### [179] [RecoMind: A Reinforcement Learning Framework for Optimizing In-Session User Satisfaction in Recommendation Systems](https://arxiv.org/abs/2508.00201)
*Mehdi Ben Ayed,Fei Feng,Jay Adams,Vishwakarma Singh,Kritarth Anand,Jiajing Xu*

Main category: cs.LG

TL;DR: 该论文提出了一种名为RecoMind的强化学习框架，用于优化会话式用户满意度，并证明其在大规模Web推荐系统中的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于现有的Web规模的推荐系统主要使用基于监督学习的方法，难以解决长远目标优化问题，这些方法往往忽略了用户的长期交互和满意度。强化学习提供了优越的解决方案，但在大规模环境中的实施存在巨大挑战。

Method: RecoMind结合现有的推荐模型构建模拟环境，并通过自定义的探索策略，优化会话目标。它还兼容主流工业流程，简化RL策略的训练和部署，并有效处理大规模的动作空间问题。

Result: 实验结果显示，通过RecoMind训练的RL策略显著优于传统的监督学习方法。在在线A/B测试中，视频观看超过10秒的增加了15.81%，多交互会话深度提升了4.71%。

Conclusion: RecoMind提供了一个系统化且可扩展的解决方案，将RL成功嵌入到大规模Web推荐系统中，可有效优化会话阶段的用户满意度和交互。

Abstract: Existing web-scale recommendation systems commonly use supervised learning
methods that prioritize immediate user feedback. Although reinforcement
learning (RL) offers a solution to optimize longer-term goals, such as
in-session engagement, applying it at web scale is challenging due to the
extremely large action space and engineering complexity. In this paper, we
introduce RecoMind, a simulator-based RL framework designed for the effective
optimization of session-based goals at web-scale. RecoMind leverages existing
recommendation models to establish a simulation environment and to bootstrap
the RL policy to optimize immediate user interactions from the outset. This
method integrates well with existing industry pipelines, simplifying the
training and deployment of RL policies. Additionally, RecoMind introduces a
custom exploration strategy to efficiently explore web-scale action spaces with
hundreds of millions of items. We evaluated RecoMind through extensive offline
simulations and online A/B testing on a video streaming platform. Both methods
showed that the RL policy trained using RecoMind significantly outperforms
traditional supervised learning recommendation approaches in in-session user
satisfaction. In online A/B tests, the RL policy increased videos watched for
more than 10 seconds by 15.81\% and improved session depth by 4.71\% for
sessions with at least 10 interactions. As a result, RecoMind presents a
systematic and scalable approach for embedding RL into web-scale recommendation
systems, showing great promise for optimizing session-based user satisfaction.

</details>


### [180] [Robust Classification under Noisy Labels: A Geometry-Aware Reliability Framework for Foundation Models](https://arxiv.org/abs/2508.00202)
*Ecem Bozkurt,Antonio Ortega*

Main category: cs.LG

TL;DR: 本文提出了一种在标签噪声存在下进行分类的新框架，通过结合局部几何信息和可靠性加权推理，以提高基于基础模型的鲁棒性表现。


<details>
  <summary>Details</summary>
Motivation: 当前基础模型在标签噪声数据中表现受限，而kNN方法虽然表现优秀但未充分利用局部几何信息，本文致力于改善这一问题。

Method: 提出了两阶段框架：第一阶段进行可靠性估计，第二阶段引入基于非负核(NNK)构建的局部几何信息进行可靠性加权推理。

Result: 通过在CIFAR-10和DermaMNIST数据集上的实验表明，该方法在不同噪声条件下展现了优于标准kNN和自适应邻居方法的鲁棒性。

Conclusion: 引入局部几何信息显著提升了基础模型在标签噪声场景下的性能，体现了结合局部几何与可靠性估计的重要性。

Abstract: Foundation models (FMs) pretrained on large datasets have become fundamental
for various downstream machine learning tasks, in particular in scenarios where
obtaining perfectly labeled data is prohibitively expensive. In this paper, we
assume an FM has to be fine-tuned with noisy data and present a two-stage
framework to ensure robust classification in the presence of label noise
without model retraining. Recent work has shown that simple k-nearest neighbor
(kNN) approaches using an embedding derived from an FM can achieve good
performance even in the presence of severe label noise. Our work is motivated
by the fact that these methods make use of local geometry. In this paper,
following a similar two-stage procedure, reliability estimation followed by
reliability-weighted inference, we show that improved performance can be
achieved by introducing geometry information. For a given instance, our
proposed inference uses a local neighborhood of training data, obtained using
the non-negative kernel (NNK) neighborhood construction. We propose several
methods for reliability estimation that can rely less on distance and local
neighborhood as the label noise increases. Our evaluation on CIFAR-10 and
DermaMNIST shows that our methods improve robustness across various noise
conditions, surpassing standard K-NN approaches and recent
adaptive-neighborhood baselines.

</details>


### [181] [Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product](https://arxiv.org/abs/2508.00230)
*Paul Albert,Frederic Z. Zhang,Hemanth Saratchandran,Anton van den Hengel,Ehsan Abbasnejad*

Main category: cs.LG

TL;DR: 本文提出KRAdapter，一种基于Khatri-Rao积的PEFT方法，弥补了LoRA在多模态和大语言模型上的不足，尤其是在处理高有效低秩矩阵时表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前低秩适配方法LoRA在多模态和大语言模型上的性能受到局限，需要新的方法来提升其效果，尤其在高有效秩矩阵逼近任务中。

Method: 通过一个带控制谱属性的合成矩阵逼近基准测试，量化对比全秩和低秩PEFT方法的表现，提出KRAdapter利用Khatri-Rao积生成权重更新，使其更倾向于生成高有效秩的矩阵乘积。

Result: KRAdapter在1B参数的视觉语言模型和8B参数的大语言模型上实现性能提升，尤其在未知的常识推理任务上表现出色，同时保留了LoRA的内存和计算效率。

Conclusion: KRAdapter是一种既高效又实用的PEFT替代方案，能够在大规模参数模型中提供更好的适配性能，具有实践意义。

Abstract: Parameter-efficient fine-tuning (PEFT) has become a standard approach for
adapting large pre-trained models. Amongst PEFT methods, low-rank adaptation
(LoRA) has achieved notable success. However, recent studies have highlighted
its limitations compared against full-rank alternatives, particularly when
applied to multimodal and large language models. In this work, we present a
quantitative comparison amongst full-rank and low-rank PEFT methods using a
synthetic matrix approximation benchmark with controlled spectral properties.
Our results confirm that LoRA struggles to approximate matrices with relatively
flat spectrums or high frequency components -- signs of high effective ranks.
To this end, we introduce KRAdapter, a novel PEFT algorithm that leverages the
Khatri-Rao product to produce weight updates, which, by construction, tends to
produce matrix product with a high effective rank. We demonstrate performance
gains with KRAdapter on vision-language models up to 1B parameters and on large
language models up to 8B parameters, particularly on unseen common-sense
reasoning tasks. In addition, KRAdapter maintains the memory and compute
efficiency of LoRA, making it a practical and robust alternative to fine-tune
billion-scale parameter models.

</details>


### [182] [Calibrated Language Models and How to Find Them with Label Smoothing](https://arxiv.org/abs/2508.00264)
*Jerry Huang,Peng Lu,Qiuhao Zeng*

Main category: cs.LG

TL;DR: 研究揭示指令微调后的大型语言模型（LLMs）会出现置信度校准退化问题，并探讨了通过标签平滑技术缓解此问题的方法，同时优化了标签平滑计算的内存占用。


<details>
  <summary>Details</summary>
Motivation: 探讨在指令微调过程中，如何有效应对LLMs置信度校准退化的问题，以提升模型输出的可靠性。

Method: 采用标签平滑技术，分析了其对校准效果的影响，并设计了优化的计算内核以减少内存消耗。

Result: 指出标签平滑在大词汇表模型（LV-LLMs）中效果受限，提供理论和实验支撑，同时优化了内存使用的计算方式。

Conclusion: 标签平滑是SFT过程中的有效方法，但在某些场景存在局限性，需针对性解决内存和模型规模带来的问题。

Abstract: Recent advances in natural language processing (NLP) have opened up greater
opportunities to enable fine-tuned large language models (LLMs) to behave as
more powerful interactive agents through improved instruction-following
ability. However, understanding how this impacts confidence calibration for
reliable model output has not been researched in full. In this work, we examine
various open-sourced LLMs, identifying significant calibration degradation
after instruction tuning in each. Seeking a practical solution, we look towards
label smoothing, which has been shown as an effective method to regularize for
overconfident predictions but has yet to be widely adopted in the supervised
fine-tuning (SFT) of LLMs. We first provide insight as to why label smoothing
is sufficient to maintain calibration throughout the SFT process. However,
settings remain where the effectiveness of smoothing is severely diminished, in
particular the case of large vocabulary LLMs (LV-LLMs). We posit the cause to
stem from the ability to become over-confident, which has a direct relationship
with the hidden size and vocabulary size, and justify this theoretically and
experimentally. Finally, we address an outstanding issue regarding the memory
footprint of the cross-entropy loss computation in the label smoothed loss
setting, designing a customized kernel to dramatically reduce memory
consumption without sacrificing speed or performance in comparison to existing
solutions for non-smoothed losses.

</details>


### [183] [Learning to Optimize Feedback for One Million Students: Insights from Multi-Armed and Contextual Bandits in Large-Scale Online Tutoring](https://arxiv.org/abs/2508.00270)
*Robin Schmucker,Nimish Pachapurkar,Shanmuga Bala,Miral Shah,Tom Mitchell*

Main category: cs.LG

TL;DR: 本文介绍了一个在线辅导系统，该系统利用百万学生数据学习选择最佳的反馈方式，提高学生的学习效果。核心技术包括多臂老虎机（MAB）框架与上下文老虎机（CB）策略。


<details>
  <summary>Details</summary>
Motivation: 动机在于开发能够根据学生个性需求提供智能反馈的在线辅导系统，从而提高教育效果。

Method: 采用多臂老虎机（MAB）框架，通过分析43000种反馈行为，优化学生学习结果，并结合因果推断方法探索上下文老虎机（CB）策略的个性化反馈潜力。

Result: 在166,000次实践过程中验证了MAB策略，显著提升了学生的学习表现。然而，CB策略未能明显超越优化后的MAB策略。

Conclusion: 尽管个性化反馈存在潜力，但优化后的MAB策略对大多数学生已足够有效。未来研究应聚焦于更微观的学生差异与系统改进。

Abstract: We present an online tutoring system that learns to provide effective
feedback to students after they answer questions incorrectly. Using data from
one million students, the system learns which assistance action (e.g., one of
multiple hints) to provide for each question to optimize student learning.
Employing the multi-armed bandit (MAB) framework and offline policy evaluation,
we assess 43,000 assistance actions, and identify trade-offs between assistance
policies optimized for different student outcomes (e.g., response correctness,
session completion). We design an algorithm that for each question decides on a
suitable policy training objective to enhance students' immediate second
attempt success and overall practice session performance. We evaluate the
resulting MAB policies in 166,000 practice sessions, verifying significant
improvements in student outcomes. While MAB policies optimize feedback for the
overall student population, we further investigate whether contextual bandit
(CB) policies can enhance outcomes by personalizing feedback based on
individual student features (e.g., ability estimates, response times). Using
causal inference, we examine (i) how effects of assistance actions vary across
students and (ii) whether CB policies, which leverage such effect
heterogeneity, outperform MAB policies. While our analysis reveals that some
actions for some questions exhibit effect heterogeneity, effect sizes may often
be too small for CB policies to provide significant improvements beyond what
well-optimized MAB policies that deliver the same action to all students
already achieve. We discuss insights gained from deploying data-driven systems
at scale and implications for future refinements. Today, the teaching policies
optimized by our system support thousands of students daily.

</details>


### [184] [Toward using explainable data-driven surrogate models for treating performance-based seismic design as an inverse engineering problem](https://arxiv.org/abs/2508.00286)
*Mohsen Zaker Esteghamati*

Main category: cs.LG

TL;DR: 本文提出将基于性能的地震设计视为逆向工程问题，通过解释性机器学习模型直接映射设计变量与性能指标，并结合遗传优化算法进行求解。


<details>
  <summary>Details</summary>
Motivation: 为了解决基于性能的地震设计计算效率低的问题，同时优化结构物的抗震性能与经济损耗。

Method: 提出一种结合解释性机器学习模型与遗传优化算法的逆向设计方法，直接推导能满足特定性能目标的设计参数。

Result: 通过对洛杉矶和查尔斯顿两个不同库存的钢筋混凝土框架的研究，验证了算法的高准确性（R2> 90%）及在优化框架成员截面属性方面的有效性。

Conclusion: 基于机器学习和优化算法的逆向工程方法能有效解决地震设计中的效率与优化难题，并符合工程原理。

Abstract: This study presents a methodology to treat performance-based seismic design
as an inverse engineering problem, where design parameters are directly derived
to achieve specific performance objectives. By implementing explainable machine
learning models, this methodology directly maps design variables and
performance metrics, tackling computational inefficiencies of performance-based
design. The resultant machine learning model is integrated as an evaluation
function into a genetic optimization algorithm to solve the inverse problem.
The developed methodology is then applied to two different inventories of steel
and concrete moment frames in Los Angeles and Charleston to obtain sectional
properties of frame members that minimize expected annualized seismic loss in
terms of repair costs. The results show high accuracy of the surrogate models
(e.g., R2> 90%) across a diverse set of building types, geometries, seismic
design, and site hazard, where the optimization algorithm could identify the
optimum values of members' properties for a fixed set of geometric variables,
consistent with engineering principles.

</details>


### [185] [Invariant Graph Transformer for Out-of-Distribution Generalization](https://arxiv.org/abs/2508.00304)
*Tianyin Liao,Ziwei Zhang,Yufei Sun,Chunyu Hu,Jianxin Li*

Main category: cs.LG

TL;DR: 本文提出Graph Out-Of-Distribution generalized Transformer (GOODFormer)，旨在通过捕获图结构和标签间的不变量关系来学习可泛化的图表征。


<details>
  <summary>Details</summary>
Motivation: 现有的Graph Transformers（GTs）在处理同分布的图数据方面表现良好，但在分布变化下难以泛化；需要探索基于图不变学习的注意力机制和编码方法。

Method: 提出了一个包含三个模块的框架：(1) 基于GT的熵引导不变子图分离器，用于区分不变与可变子图；(2) 动态子图的位置与结构编码器；(3) 使用子图节点表征与编码进行不变学习的模块。

Result: 在多个基准数据集上的实验表明，GOODFormer在分布变化下相比现有方法具有显著优势。

Conclusion: GOODFormer通过创新模块设计，实现了图不变学习目标，能有效应对分布变化问题，理论和实验上都得到验证。

Abstract: Graph Transformers (GTs) have demonstrated great effectiveness across various
graph analytical tasks. However, the existing GTs focus on training and testing
graph data originated from the same distribution, but fail to generalize under
distribution shifts. Graph invariant learning, aiming to capture generalizable
graph structural patterns with labels under distribution shifts, is potentially
a promising solution, but how to design attention mechanisms and positional and
structural encodings (PSEs) based on graph invariant learning principles
remains challenging. To solve these challenges, we introduce Graph
Out-Of-Distribution generalized Transformer (GOODFormer), aiming to learn
generalized graph representations by capturing invariant relationships between
predictive graph structures and labels through jointly optimizing three
modules. Specifically, we first develop a GT-based entropy-guided invariant
subgraph disentangler to separate invariant and variant subgraphs while
preserving the sharpness of the attention function. Next, we design an evolving
subgraph positional and structural encoder to effectively and efficiently
capture the encoding information of dynamically changing subgraphs during
training. Finally, we propose an invariant learning module utilizing subgraph
node representations and encodings to derive generalizable graph
representations that can to unseen graphs. We also provide theoretical
justifications for our method. Extensive experiments on benchmark datasets
demonstrate the superiority of our method over state-of-the-art baselines under
distribution shifts.

</details>


### [186] [PnP-DA: Towards Principled Plug-and-Play Integration of Variational Data Assimilation and Generative Models](https://arxiv.org/abs/2508.00325)
*Yongquan Qu,Matthieu Blanke,Sara Shamekh,Pierre Gentine*

Main category: cs.LG

TL;DR: 提出了一种名为PnP-DA的算法，改进了地球系统建模中的数据同化过程。


<details>
  <summary>Details</summary>
Motivation: 当前的地球系统建模在处理复杂的非线性多尺度动力学时存在误差累积问题，传统方法难以捕捉真实的非高斯行为。

Method: 提出PnP-DA算法，该方法结合了基于马氏距离的梯度分析更新与通过条件Wasserstein耦合的生成先验模型，不需要显式的正则化函数。

Result: 实验表明该方法在多种观测稀疏性和噪声水平下均能减少预测误差，优于传统的变分方法。

Conclusion: PnP-DA算法通过新颖的数据同化方法显著提升了建模精度，为地球系统建模发展提供了新的思路。

Abstract: Earth system modeling presents a fundamental challenge in scientific
computing: capturing complex, multiscale nonlinear dynamics in computationally
efficient models while minimizing forecast errors caused by necessary
simplifications. Even the most powerful AI- or physics-based forecast system
suffer from gradual error accumulation. Data assimilation (DA) aims to mitigate
these errors by optimally blending (noisy) observations with prior model
forecasts, but conventional variational methods often assume Gaussian error
statistics that fail to capture the true, non-Gaussian behavior of chaotic
dynamical systems. We propose PnP-DA, a Plug-and-Play algorithm that alternates
(1) a lightweight, gradient-based analysis update (using a Mahalanobis-distance
misfit on new observations) with (2) a single forward pass through a pretrained
generative prior conditioned on the background forecast via a conditional
Wasserstein coupling. This strategy relaxes restrictive statistical assumptions
and leverages rich historical data without requiring an explicit regularization
functional, and it also avoids the need to backpropagate gradients through the
complex neural network that encodes the prior during assimilation cycles.
Experiments on standard chaotic testbeds demonstrate that this strategy
consistently reduces forecast errors across a range of observation sparsities
and noise levels, outperforming classical variational methods.

</details>


### [187] [Embryology of a Language Model](https://arxiv.org/abs/2508.00331)
*George Wang,Garrett Baker,Andrew Gordon,Daniel Murfet*

Main category: cs.LG

TL;DR: 研究提出了一种通过UMAP和敏感性矩阵来可视化语言模型训练结构发展的新方法，揭示了已知和未知的模型内部特征。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型内部计算结构的形成与发展，以便更深入理解深度学习中的网络组织。

Method: 运用敏感性矩阵并结合UMAP方法对语言模型训练期间的结构变化进行可视化分析，从而揭示内部的"身体计划"特征。

Result: 发现了语言模型的已知特性（如归纳回路）以及新的结构特性（如负责计数空格符号的"spacing fin"）。

Conclusion: 敏感性分析可以超越验证功能，用于发现语言模型的新机制，是研究复杂神经网络发展的有力工具。

Abstract: Understanding how language models develop their internal computational
structure is a central problem in the science of deep learning. While
susceptibilities, drawn from statistical physics, offer a promising analytical
tool, their full potential for visualizing network organization remains
untapped. In this work, we introduce an embryological approach, applying UMAP
to the susceptibility matrix to visualize the model's structural development
over training. Our visualizations reveal the emergence of a clear ``body
plan,'' charting the formation of known features like the induction circuit and
discovering previously unknown structures, such as a ``spacing fin'' dedicated
to counting space tokens. This work demonstrates that susceptibility analysis
can move beyond validation to uncover novel mechanisms, providing a powerful,
holistic lens for studying the developmental principles of complex neural
networks.

</details>


### [188] [BOOD: Boundary-based Out-Of-Distribution Data Generation](https://arxiv.org/abs/2508.00350)
*Qilin Liao,Shuo Yang,Bo Zhao,Ping Luo,Hengshuang Zhao*

Main category: cs.LG

TL;DR: 本文提出一种名为BOOD的新框架，利用扩散模型生成边界附近的OOD特征和图像，从而提高OOD检测性能并显著超越当前的最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过扩散模型生成辅助训练数据来增强OOD检测，但在类间决策边界附近提取有效特征仍具有挑战性。

Method: BOOD首先通过ID数据学习一个文本条件的潜在特征空间，选取接近决策边界的ID特征，进行扰动使其跨越边界生成OOD特征，最后通过扩散模型将这些特征解码为像素空间中的图像。

Result: 在CIFAR-100数据集上的实验结果表明，BOOD平均FPR95降低了29.64个百分点（40.31% vs. 10.67%），平均AUROC提高了7.27个百分点（90.15% vs. 97.42%），超越了当前最先进方法。

Conclusion: BOOD生成高质量的OOD特征和图像，在提升OOD检测性能的同时显著提升了训练效率，并在多个基准测试中取得了明显优势。

Abstract: Harnessing the power of diffusion models to synthesize auxiliary training
data based on latent space features has proven effective in enhancing
out-of-distribution (OOD) detection performance. However, extracting effective
features outside the in-distribution (ID) boundary in latent space remains
challenging due to the difficulty of identifying decision boundaries between
classes. This paper proposes a novel framework called Boundary-based
Out-Of-Distribution data generation (BOOD), which synthesizes high-quality OOD
features and generates human-compatible outlier images using diffusion models.
BOOD first learns a text-conditioned latent feature space from the ID dataset,
selects ID features closest to the decision boundary, and perturbs them to
cross the decision boundary to form OOD features. These synthetic OOD features
are then decoded into images in pixel space by a diffusion model. Compared to
previous works, BOOD provides a more training efficient strategy for
synthesizing informative OOD features, facilitating clearer distinctions
between ID and OOD data. Extensive experimental results on common benchmarks
demonstrate that BOOD surpasses the state-of-the-art method significantly,
achieving a 29.64% decrease in average FPR95 (40.31% vs. 10.67%) and a 7.27%
improvement in average AUROC (90.15% vs. 97.42%) on the CIFAR-100 dataset.

</details>


### [189] [Sheaf Graph Neural Networks via PAC-Bayes Spectral Optimization](https://arxiv.org/abs/2508.00357)
*Yoonhyuk Choi,Jiho Choi,Chong-Kwon Kim*

Main category: cs.LG

TL;DR: 提出了一种名为SGPC的新型图神经网络，旨在解决GNN在异配图中过度平滑的问题，并在九个基准测试中证明其优越性能。


<details>
  <summary>Details</summary>
Motivation: 针对异配图中GNN过度平滑导致的节点特征塌陷问题，以及现有基于分支结构具有限制性的问题，提出改进方法。

Method: 结合细胞分支消息传递、最优传输提升、减方差扩散及PAC-Bayes频谱正则化的统一架构，提供线性复杂度的端到端训练解决方案。

Result: SGPC模型在九个均匀及异配基准数据集上均超过现有最优模型，同时提供未见节点的置信区间。

Conclusion: SGPC不仅提升了基于分支及频谱的GNN性能，还提供了理论上的稳定性保障，适合广泛应用。

Abstract: Over-smoothing in Graph Neural Networks (GNNs) causes collapse in distinct
node features, particularly on heterophilic graphs where adjacent nodes often
have dissimilar labels. Although sheaf neural networks partially mitigate this
problem, they typically rely on static or heavily parameterized sheaf
structures that hinder generalization and scalability. Existing sheaf-based
models either predefine restriction maps or introduce excessive complexity, yet
fail to provide rigorous stability guarantees. In this paper, we introduce a
novel scheme called SGPC (Sheaf GNNs with PAC-Bayes Calibration), a unified
architecture that combines cellular-sheaf message passing with several
mechanisms, including optimal transport-based lifting, variance-reduced
diffusion, and PAC-Bayes spectral regularization for robust semi-supervised
node classification. We establish performance bounds theoretically and
demonstrate that the resulting bound-aware objective can be achieved via
end-to-end training in linear computational complexity. Experiments on nine
homophilic and heterophilic benchmarks show that SGPC outperforms
state-of-the-art spectral and sheaf-based GNNs while providing certified
confidence intervals on unseen nodes.

</details>


### [190] [OID-PPO: Optimal Interior Design using Proximal Policy Optimization by Transforming Design Guidelines into Reward Functions](https://arxiv.org/abs/2508.00364)
*Chanyoung Yoon,Sangbong Yoo,Soobin Yim,Chansoo Kim,Yun Jang*

Main category: cs.LG

TL;DR: 提出了OID-PPO，一个基于强化学习的室内设计框架，通过结合专家设计原则与连续家具布局策略，实现了高质量的设计布局。


<details>
  <summary>Details</summary>
Motivation: 现有的室内设计方法往往要求高计算量或依赖专家知识，而传统优化或深度学习方法受限于数据稀缺或有限的设计规则应用。强化学习方法也常存在家具摆放位置离散化与设计原则整合不足的问题。

Method: 提出OID-PPO框架，通过引入一种基于近端策略优化的强化学习策略，并结合专家定义的功能与视觉设计原则，以奖励函数形式引导连续的家具布局设计。

Result: 在多种房间形状与家具配置实验中，OID-PPO在布局质量与计算效率方面明显优于现有的先进方法。

Conclusion: OID-PPO通过整合设计规则和优化结构奖励机制，解决了室内设计中空间布局和设计约束的协调问题，为室内设计提供了更加优质与高效的算法支持。

Abstract: Designing residential interiors strongly impacts occupant satisfaction but
remains challenging due to unstructured spatial layouts, high computational
demands, and reliance on expert knowledge. Existing methods based on
optimization or deep learning are either computationally expensive or
constrained by data scarcity. Reinforcement learning (RL) approaches often
limit furniture placement to discrete positions and fail to incorporate design
principles adequately. We propose OID-PPO, a novel RL framework for Optimal
Interior Design using Proximal Policy Optimization, which integrates
expert-defined functional and visual guidelines into a structured reward
function. OID-PPO utilizes a diagonal Gaussian policy for continuous and
flexible furniture placement, effectively exploring latent environmental
dynamics under partial observability. Experiments conducted across diverse room
shapes and furniture configurations demonstrate that OID-PPO significantly
outperforms state-of-the-art methods in terms of layout quality and
computational efficiency. Ablation studies further demonstrate the impact of
structured guideline integration and reveal the distinct contributions of
individual design constraints.

</details>


### [191] [Dual Adaptivity: Universal Algorithms for Minimizing the Adaptive Regret of Convex Functions](https://arxiv.org/abs/2508.00392)
*Lijun Zhang,Wenhao Yang,Guanghui Wang,Wei Jiang,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种普适性的在线学习算法，能够在未知函数类型和环境变化的条件下，通过动态创建和聚合专家来最小化适应性遗憾。


<details>
  <summary>Details</summary>
Motivation: 当前算法受限于只能处理单一类型的凸函数且需要先验参数，难以应用于现实场景；需要一种普适性更强的算法。

Method: 提出基于元专家框架的双重适应性算法，通过动态创建专家并结合元算法进行聚合；运用睡眠专家技术应对环境变化；引入增加专家数量或增强专家能力的策略实现普适性。

Result: 算法能够同时最小化多类型凸函数的适应性遗憾，并支持不同函数类型间的动态切换；此外，还成功扩展到复合函数的在线优化中。

Conclusion: 该方法实现了函数类型与环境的双重自适应，为在线学习领域提供了一种高效且普适的解决方案。

Abstract: To deal with changing environments, a new performance measure -- adaptive
regret, defined as the maximum static regret over any interval, was proposed in
online learning. Under the setting of online convex optimization, several
algorithms have been successfully developed to minimize the adaptive regret.
However, existing algorithms lack universality in the sense that they can only
handle one type of convex functions and need apriori knowledge of parameters,
which hinders their application in real-world scenarios. To address this
limitation, this paper investigates universal algorithms with dual adaptivity,
which automatically adapt to the property of functions (convex, exponentially
concave, or strongly convex), as well as the nature of environments (stationary
or changing). Specifically, we propose a meta-expert framework for dual
adaptive algorithms, where multiple experts are created dynamically and
aggregated by a meta-algorithm. The meta-algorithm is required to yield a
second-order bound, which can accommodate unknown function types. We further
incorporate the technique of sleeping experts to capture the changing
environments. For the construction of experts, we introduce two strategies
(increasing the number of experts or enhancing the capabilities of experts) to
achieve universality. Theoretical analysis shows that our algorithms are able
to minimize the adaptive regret for multiple types of convex functions
simultaneously, and also allow the type of functions to switch between rounds.
Moreover, we extend our meta-expert framework to online composite optimization,
and develop a universal algorithm for minimizing the adaptive regret of
composite functions.

</details>


### [192] [ExeKGLib: A Platform for Machine Learning Analytics based on Knowledge Graphs](https://arxiv.org/abs/2508.00394)
*Antonis Klironomos,Baifan Zhou,Zhipeng Tan,Zhuoxun Zheng,Mohamed H. Gad-Elrab,Heiko Paulheim,Evgeny Kharlamov*

Main category: cs.LG

TL;DR: 该论文提出了一个名为ExeKGLib的Python库，旨在通过简化的图形界面帮助非机器学习专家构建ML管道，同时提高工作流的透明度和可重用性。


<details>
  <summary>Details</summary>
Motivation: 尽管许多ML库可用，但缺乏ML专长的领域专家在压力下仍难以构建高质量的ML管道，因此需要一种简易工具帮助完成。

Method: 设计了包含图形界面的Python库ExeKGLib，利用知识图谱编码ML知识，使非专家也能构建ML管道。

Result: ExeKGLib通过展示实际使用案例，证明其在提升可用性和透明度上的有效性。

Conclusion: ExeKGLib支持领域专家使用简易的步骤构建满足需求的ML工作流，同时增强了工作流的透明度和可重用性。

Abstract: Nowadays machine learning (ML) practitioners have access to numerous ML
libraries available online. Such libraries can be used to create ML pipelines
that consist of a series of steps where each step may invoke up to several ML
libraries that are used for various data-driven analytical tasks. Development
of high-quality ML pipelines is non-trivial; it requires training, ML
expertise, and careful development of each step. At the same time, domain
experts in science and engineering may not possess such ML expertise and
training while they are in pressing need of ML-based analytics. In this paper,
we present our ExeKGLib, a Python library enhanced with a graphical interface
layer that allows users with minimal ML knowledge to build ML pipelines. This
is achieved by relying on knowledge graphs that encode ML knowledge in simple
terms accessible to non-ML experts. ExeKGLib also allows improving the
transparency and reusability of the built ML workflows and ensures that they
are executable. We show the usability and usefulness of ExeKGLib by presenting
real use cases.

</details>


### [193] [Co-Reward: Self-supervised Reinforcement Learning for Large Language Model Reasoning via Contrastive Agreement](https://arxiv.org/abs/2508.00410)
*Zizhuo Zhang,Jianing Zhu,Xinmu Ge,Zihua Zhao,Zhanke Zhou,Xuan Li,Xiao Feng,Jiangchao Yao,Bo Han*

Main category: cs.LG

TL;DR: 本文提出了一种名为Co-Reward的新型强化学习框架，通过对语义类比问题之间的对比性一致进行奖励设计，以改进大型语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法对人类标注的依赖在任务复杂性上存在局限，而现有的自我奖励信号方法存在崩溃问题。

Method: 提出了Co-Reward框架，通过为训练样本构造相似问题并合成代理标签，通过检查问题对的标签一致性构建奖励机制，从而提升推理表现。

Result: Co-Reward在多个推理基准和LLM系列中优于其他自我奖励方法，并在某些情况下超过了基于真实标签的奖励性能，例如在Llama-3.2-3B-Instruct的MATH500任务上提高了6.8%。

Conclusion: Co-Reward提供了一种新的自我监督奖励设计方法，显著改善了推理能力，减少了崩溃现象，并扩大了可用输入样本的多样性。

Abstract: Although reinforcement learning with verifiable rewards (RLVR) shows promise
in improving the reasoning ability of large language models (LLMs), the scaling
up dilemma remains due to the reliance on human annotated labels especially for
complex tasks. Recent alternatives that explore various self-reward signals
exhibit the eliciting potential of LLM reasoning, but suffer from the
non-negligible collapse issue. Inspired by the success of self-supervised
learning, we propose \textit{Co-Reward}, a novel RL framework that leverages
contrastive agreement across semantically analogical questions as a reward
basis. Specifically, we construct a similar question for each training sample
(without labels) and synthesize their individual surrogate labels through a
simple rollout voting, and then the reward is constructed by cross-referring
the labels of each question pair to enforce the internal reasoning consistency
across analogical inputs. Intuitively, such a self-supervised reward-shaping
mechanism increases the difficulty of learning collapse into a trivial
solution, and promotes stable reasoning elicitation and improvement through
expanding the input sample variants. Empirically, Co-Reward achieves superior
performance compared to other self-reward baselines on multiple reasoning
benchmarks and LLM series, and reaches or even surpasses ground-truth (GT)
labeled reward, with improvements of up to $+6.8\%$ on MATH500 over GT reward
on Llama-3.2-3B-Instruct. Our code is publicly available at
https://github.com/tmlr-group/Co-Reward.

</details>


### [194] [Transforming Credit Risk Analysis: A Time-Series-Driven ResE-BiLSTM Framework for Post-Loan Default Detection](https://arxiv.org/abs/2508.00415)
*Yue Yang,Yuxiang Lin,Ying Zhang,Zihan Su,Chang Chuan Goh,Tangtangfang Fang,Anthony Graham Bellotti,Boon Giin Lee*

Main category: cs.LG

TL;DR: 该研究提出了一种新的机器学习模型ResE-BiLSTM，用于预测贷款违约。


<details>
  <summary>Details</summary>
Motivation: 改进现有的贷款违约预测模型，提高检测财务异常的能力。

Method: 提出ResE-BiLSTM模型，结合滑动窗口技术，并通过与五种基线模型进行比较验证其性能。

Result: 实验结果表明，ResE-BiLSTM在多项评估指标上均优于基线模型，具有实际应用价值。

Conclusion: ResE-BiLSTM模型在预测贷款违约和解释模型决策方面表现优越，适用于实际场景。

Abstract: Prediction of post-loan default is an important task in credit risk
management, and can be addressed by detection of financial anomalies using
machine learning. This study introduces a ResE-BiLSTM model, using a sliding
window technique, and is evaluated on 44 independent cohorts from the extensive
Freddie Mac US mortgage dataset, to improve prediction performance. The
ResE-BiLSTM is compared with five baseline models: Long Short-Term Memory
(LSTM), BiLSTM, Gated Recurrent Units (GRU), Convolutional Neural Networks
(CNN), and Recurrent Neural Networks (RNN), across multiple metrics, including
Accuracy, Precision, Recall, F1, and AUC. An ablation study was conducted to
evaluate the contribution of individual components in the ResE-BiLSTM
architecture. Additionally, SHAP analysis was employed to interpret the
underlying features the model relied upon for its predictions. Experimental
results demonstrate that ResE-BiLSTM achieves superior predictive performance
compared to baseline models, underscoring its practical value and applicability
in real-world scenarios.

</details>


### [195] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: 提出了ctdGAN，一种解决表格数据类别不平衡的条件GAN，通过空间划分、概率采样和新损失函数实现高保真数据生成和分类精度的提升。


<details>
  <summary>Details</summary>
Motivation: 现有GAN模型未考虑输入样本在真实数据空间的向量子空间分布，同时类别标签处理方式导致条件采样效果较差。

Method: 提出一种新条件GAN（ctdGAN），包括空间划分步骤、基于概率的采样策略、新损失函数，以及一个捕捉多特征模式的集群缩放技术。

Result: 在14个不平衡数据集上的实验表明，ctdGAN能够生成高保真样本并显著提高分类准确率。

Conclusion: ctdGAN是解决表格数据类别不平衡问题的有效工具，可在多个特征模式下生成高质量样本，同时提升分类性能。

Abstract: The tabular form constitutes the standard way of representing data in
relational database systems and spreadsheets. But, similarly to other forms,
tabular data suffers from class imbalance, a problem that causes serious
performance degradation in a wide variety of machine learning tasks. One of the
most effective solutions dictates the usage of Generative Adversarial Networks
(GANs) in order to synthesize artificial data instances for the
under-represented classes. Despite their good performance, none of the proposed
GAN models takes into account the vector subspaces of the input samples in the
real data space, leading to data generation in arbitrary locations. Moreover,
the class labels are treated in the same manner as the other categorical
variables during training, so conditional sampling by class is rendered less
effective. To overcome these problems, this study presents ctdGAN, a
conditional GAN for alleviating class imbalance in tabular datasets. Initially,
ctdGAN executes a space partitioning step to assign cluster labels to the input
samples. Subsequently, it utilizes these labels to synthesize samples via a
novel probabilistic sampling strategy and a new loss function that penalizes
both cluster and class mis-predictions. In this way, ctdGAN is trained to
generate samples in subspaces that resemble those of the original data
distribution. We also introduce several other improvements, including a simple,
yet effective cluster-wise scaling technique that captures multiple feature
modes without affecting data dimensionality. The exhaustive evaluation of
ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating
high fidelity samples and improving classification accuracy.

</details>


### [196] [Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection](https://arxiv.org/abs/2508.00507)
*Yiming Xu,Jiarun Chen,Zhen Peng,Zihan Chen,Qika Lin,Lan Ma,Bin Shi,Bo Dong*

Main category: cs.LG

TL;DR: 本文提出了一种结合大语言模型（LLMs）和图神经网络（GNNs）的新框架CoLL，以改进文本属性图（TAGs）上的异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前的图异常检测方法过于依赖图域的复杂优化目标，忽略了文本模态的潜在价值，而常用的浅层嵌入方法无法有效捕捉异常相关的语义背景，因此需要更强大的模型来弥补这一不足。

Method: 设计了一个整合LLMs和GNNs的框架CoLL，其中LLMs用于提供基于多模型协作的语义增强生成，捕获异常相关的上下文信息；GNN配备门控机制，用于自适应地融合文本特征与证据，同时保留高阶拓扑信息。

Result: 实验结果表明，CoLL在平均AP指标上实现了13.37%的性能提升，具有显著的优越性。

Conclusion: 该研究展示了将大语言模型纳入图异常检测的潜力，为该领域的进一步研究提供了新思路。

Abstract: The natural combination of intricate topological structures and rich textual
information in text-attributed graphs (TAGs) opens up a novel perspective for
graph anomaly detection (GAD). However, existing GAD methods primarily focus on
designing complex optimization objectives within the graph domain, overlooking
the complementary value of the textual modality, whose features are often
encoded by shallow embedding techniques, such as bag-of-words or skip-gram, so
that semantic context related to anomalies may be missed. To unleash the
enormous potential of textual modality, large language models (LLMs) have
emerged as promising alternatives due to their strong semantic understanding
and reasoning capabilities. Nevertheless, their application to TAG anomaly
detection remains nascent, and they struggle to encode high-order structural
information inherent in graphs due to input length constraints. For
high-quality anomaly detection in TAGs, we propose CoLL, a novel framework that
combines LLMs and graph neural networks (GNNs) to leverage their complementary
strengths. CoLL employs multi-LLM collaboration for evidence-augmented
generation to capture anomaly-relevant contexts while delivering human-readable
rationales for detected anomalies. Moreover, CoLL integrates a GNN equipped
with a gating mechanism to adaptively fuse textual features with evidence while
preserving high-order topological information. Extensive experiments
demonstrate the superiority of CoLL, achieving an average improvement of 13.37%
in AP. This study opens a new avenue for incorporating LLMs in advancing GAD.

</details>


### [197] [Text-Attributed Graph Anomaly Detection via Multi-Scale Cross- and Uni-Modal Contrastive Learning](https://arxiv.org/abs/2508.00513)
*Yiming Xu,Xu Hua,Zhen Peng,Bin Shi,Jiarun Chen,Xingbo Fu,Song Wang,Bo Dong*

Main category: cs.LG

TL;DR: 本文提出了一种名为CMUCL的新方法，用于处理文本属性图(Tags)中的异常检测。


<details>
  <summary>Details</summary>
Motivation: 面对现实世界中存在文本属性图的异常检测任务，现有方法在文本编码和图域异常检测目标之间存在分离，限制了检测效果。

Method: 提出一种端到端范式CMUCL，同时建模文本与图结构数据，利用跨模态和单一模态多尺度一致性训练编码器，并基于不一致挖掘设计异常评分器。

Result: CMUCL在8个新发布数据集上的测试结果表现优异，平均准确度（AP）提升11.13%。

Conclusion: CMUCL显著提高了文本属性图异常检测的效果，并通过新数据集推进了该领域的研究。

Abstract: The widespread application of graph data in various high-risk scenarios has
increased attention to graph anomaly detection (GAD). Faced with real-world
graphs that often carry node descriptions in the form of raw text sequences,
termed text-attributed graphs (TAGs), existing graph anomaly detection
pipelines typically involve shallow embedding techniques to encode such textual
information into features, and then rely on complex self-supervised tasks
within the graph domain to detect anomalies. However, this text encoding
process is separated from the anomaly detection training objective in the graph
domain, making it difficult to ensure that the extracted textual features focus
on GAD-relevant information, seriously constraining the detection capability.
How to seamlessly integrate raw text and graph topology to unleash the vast
potential of cross-modal data in TAGs for anomaly detection poses a challenging
issue. This paper presents a novel end-to-end paradigm for text-attributed
graph anomaly detection, named CMUCL. We simultaneously model data from both
text and graph structures, and jointly train text and graph encoders by
leveraging cross-modal and uni-modal multi-scale consistency to uncover
potential anomaly-related information. Accordingly, we design an anomaly score
estimator based on inconsistency mining to derive node-specific anomaly scores.
Considering the lack of benchmark datasets tailored for anomaly detection on
TAGs, we release 8 datasets to facilitate future research. Extensive
evaluations show that CMUCL significantly advances in text-attributed graph
anomaly detection, delivering an 11.13% increase in average accuracy (AP) over
the suboptimal.

</details>


### [198] [Online Nonsubmodular Optimization with Delayed Feedback in the Bandit Setting](https://arxiv.org/abs/2508.00523)
*Sifan Yang,Yuanyu Wan,Lijun Zhang*

Main category: cs.LG

TL;DR: 本文研究了延迟反馈下的在线非次模优化问题，并提出两种新算法分别改进当前的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 现有工作对延迟的遗憾界过于依赖最大延迟，不适应不规则延迟。此外，其遗憾界联结了延迟和带宽反馈的影响，难以分别分析。

Method: 提出DBGD-NF算法，通过单点梯度估计器利用所有可用的估计梯度；并扩展为结合阻塞更新机制以解耦延迟和反馈两者影响。

Result: DBGD-NF算法遗憾界达到了以平均延迟$\bar{d}$为相关的$\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$，扩展算法遗憾界为$\mathcal{O}(n(T^{2/3} + \sqrt{dT}))$，并证明适当情况下可以匹配无延迟带宽情形的界。

Conclusion: 实验结果表明所提算法在结构稀疏学习情景中具有优越性，尤其在更宽泛的延迟设定下性能突出。

Abstract: We investigate the online nonsubmodular optimization with delayed feedback in
the bandit setting, where the loss function is $\alpha$-weakly DR-submodular
and $\beta$-weakly DR-supermodular. Previous work has established an
$(\alpha,\beta)$-regret bound of $\mathcal{O}(nd^{1/3}T^{2/3})$, where $n$ is
the dimensionality and $d$ is the maximum delay. However, its regret bound
relies on the maximum delay and is thus sensitive to irregular delays.
Additionally, it couples the effects of delays and bandit feedback as its bound
is the product of the delay term and the $\mathcal{O}(nT^{2/3})$ regret bound
in the bandit setting without delayed feedback. In this paper, we develop two
algorithms to address these limitations, respectively. Firstly, we propose a
novel method, namely DBGD-NF, which employs the one-point gradient estimator
and utilizes all the available estimated gradients in each round to update the
decision. It achieves a better $\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$ regret
bound, which is relevant to the average delay $\bar{d} =
\frac{1}{T}\sum_{t=1}^T d_t\leq d$. Secondly, we extend DBGD-NF by employing a
blocking update mechanism to decouple the joint effect of the delays and bandit
feedback, which enjoys an $\mathcal{O}(n(T^{2/3} + \sqrt{dT}))$ regret bound.
When $d = \mathcal{O}(T^{1/3})$, our regret bound matches the
$\mathcal{O}(nT^{2/3})$ bound in the bandit setting without delayed feedback.
Compared to our first $\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$ bound, it is more
advantageous when the maximum delay $d = o(\bar{d}^{2/3}T^{1/3})$. Finally, we
conduct experiments on structured sparse learning to demonstrate the
superiority of our methods.

</details>


### [199] [Phase-Locked SNR Band Selection for Weak Mineral Signal Detection in Hyperspectral Imagery](https://arxiv.org/abs/2508.00539)
*Judy X Yang*

Main category: cs.LG

TL;DR: 该研究提出了一种两阶段框架用于增强Cuprite矿区的高光谱矿物检测性能，通过信噪比甄选波段和模型优化，改善矿物弱信号检测和混合光谱分解精度。


<details>
  <summary>Details</summary>
Motivation: 通过高光谱成像进行矿物映射时，弱矿物信号容易被噪声和冗余波段掩盖，导致检测性能降低，研究旨在解决该瓶颈。

Method: 第一阶段使用信噪比计算和相位阈值技术挑选波段，结合Savitzky-Golay滤波进行平滑处理；第二阶段基于KMeans聚类与非负最小二乘方法完成矿物光谱源和丰度分解，并与实验室光谱比较。

Result: 实验结果显示，该方法提升了光谱解混精度，并增强了弱矿区检测性能。

Conclusion: 该两阶段方法提供了一种在地质高光谱成像中降维和解混的有效方案，具有实际应用和可重复性。

Abstract: Hyperspectral imaging offers detailed spectral information for mineral
mapping; however, weak mineral signatures are often masked by noisy and
redundant bands, limiting detection performance. To address this, we propose a
two-stage integrated framework for enhanced mineral detection in the Cuprite
mining district. In the first stage, we compute the signal-to-noise ratio (SNR)
for each spectral band and apply a phase-locked thresholding technique to
discard low-SNR bands, effectively removing redundancy and suppressing
background noise. Savitzky-Golay filtering is then employed for spectral
smoothing, serving a dual role first to stabilize trends during band selection,
and second to preserve fine-grained spectral features during preprocessing. In
the second stage, the refined HSI data is reintroduced into the model, where
KMeans clustering is used to extract 12 endmember spectra (W1 custom), followed
by non negative least squares (NNLS) for abundance unmixing. The resulting
endmembers are quantitatively compared with laboratory spectra (W1 raw) using
cosine similarity and RMSE metrics. Experimental results confirm that our
proposed pipeline improves unmixing accuracy and enhances the detection of weak
mineral zones. This two-pass strategy demonstrates a practical and reproducible
solution for spectral dimensionality reduction and unmixing in geological HSI
applications.

</details>


### [200] [Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides](https://arxiv.org/abs/2508.00578)
*Marlen Neubert,Patrick Reiser,Frauke Gräter,Pascal Friederich*

Main category: cs.LG

TL;DR: 本文探究了利用机器学习势函数模拟氢原子转移反应（HAT）的方法，通过构建大规模数据库并评估多个图神经网络的性能，发现MACE模型在能量、力和反应能垒预测方面表现最佳，推动了复杂生物分子体系的量子精度模拟。


<details>
  <summary>Details</summary>
Motivation: 理解氢原子转移反应的机制对于研究受损蛋白中的自由基迁移等生物过程至关重要，但因其量子化学复杂性，目前相关模拟存在技术困难。

Method: 通过半经验方法和密度泛函理论（DFT）系统生成肽链的HAT反应构型数据集，并评估SchNet、Allegro和MACE三种图神经网络在学习构型势能面及预测反应能垒方面的表现。

Result: 在模型比较中，MACE模型全方位优于其他架构，在分布外DFT反应能垒预测中的平均绝对误差仅为1.13 kcal/mol，准确性显著提升。

Conclusion: 该研究证明了基于机器学习的势函数可以以量子精度模拟复杂环境中的化学反应，并提出了优化潜力表生成和计算效率的策略，为其他生物分子体系的研究提供了工具。

Abstract: Hydrogen atom transfer (HAT) reactions are essential in many biological
processes, such as radical migration in damaged proteins, but their mechanistic
pathways remain incompletely understood. Simulating HAT is challenging due to
the need for quantum chemical accuracy at biologically relevant scales; thus,
neither classical force fields nor DFT-based molecular dynamics are applicable.
Machine-learned potentials offer an alternative, able to learn potential energy
surfaces (PESs) with near-quantum accuracy. However, training these models to
generalize across diverse HAT configurations, especially at radical positions
in proteins, requires tailored data generation and careful model selection.
Here, we systematically generate HAT configurations in peptides to build large
datasets using semiempirical methods and DFT. We benchmark three graph neural
network architectures (SchNet, Allegro, and MACE) on their ability to learn HAT
PESs and indirectly predict reaction barriers from energy predictions. MACE
consistently outperforms the others in energy, force, and barrier prediction,
achieving a mean absolute error of 1.13 kcal/mol on out-of-distribution DFT
barrier predictions. This accuracy enables integration of ML potentials into
large-scale collagen simulations to compute reaction rates from predicted
barriers, advancing mechanistic understanding of HAT and radical migration in
peptides. We analyze scaling laws, model transferability, and cost-performance
trade-offs, and outline strategies for improvement by combining ML potentials
with transition state search algorithms and active learning. Our approach is
generalizable to other biomolecular systems, enabling quantum-accurate
simulations of chemical reactivity in complex environments.

</details>


### [201] [The Role of Active Learning in Modern Machine Learning](https://arxiv.org/abs/2508.00586)
*Thorben Werner,Lars Schmidt-Thieme,Vijaya Krishna Yalavarthi*

Main category: cs.LG

TL;DR: 研究了三种对抗低数据情景的方法：数据增强(DA)、半监督学习(SSL)和主动学习(AL)，发现AL在独立使用时效率最低，但结合DA和SSL时仍有提升效果。


<details>
  <summary>Details</summary>
Motivation: 主动学习很少在其科学文献以外的环境中应用，主要原因可能是其计算成本较高且在少量标注数据情景下提升有限。本研究旨在探讨三种方法在低数据情景中的作用。

Method: 研究了数据增强(DA)、半监督学习(SSL)和主动学习(AL)，分析其在解决低数据问题时的效率与效果，并测试了AL结合强DA和SSL技术的表现。

Result: AL独立使用时表现较差，但结合DA和SSL时能够进一步提升性能。DA和SSL可独立产生高达60%的提升，而AL单独仅提升1-4%。

Conclusion: 将主动学习视为在应用适当的DA和SSL方法后，榨取数据性能的关键补充手段，而非单独解决标注缺失问题的方法。

Abstract: Even though Active Learning (AL) is widely studied, it is rarely applied in
contexts outside its own scientific literature. We posit that the reason for
this is AL's high computational cost coupled with the comparatively small lifts
it is typically able to generate in scenarios with few labeled points. In this
work we study the impact of different methods to combat this low data scenario,
namely data augmentation (DA), semi-supervised learning (SSL) and AL. We find
that AL is by far the least efficient method of solving the low data problem,
generating a lift of only 1-4\% over random sampling, while DA and SSL methods
can generate up to 60\% lift in combination with random sampling. However, when
AL is combined with strong DA and SSL techniques, it surprisingly is still able
to provide improvements. Based on these results, we frame AL not as a method to
combat missing labels, but as the final building block to squeeze the last bits
of performance out of data after appropriate DA and SSL methods as been
applied.

</details>


### [202] [Similarity-Based Self-Construct Graph Model for Predicting Patient Criticalness Using Graph Neural Networks and EHR Data](https://arxiv.org/abs/2508.00615)
*Mukesh Kumar Sahu,Pinki Roy*

Main category: cs.LG

TL;DR: 本文提出了一种基于相似性构建图的模型（SBSCGM）和混合图神经网络架构（HybridGraphMedGNN），用于预测ICU患者的死亡率和病危指数，显示出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有预测ICU患者病危的重要性的方法难以利用电子健康记录（EHR）中的关系结构，因此需要改进模型利用多模态数据的能力。

Method: 利用SBSCGM动态构建基于混合相似性（特征和结构相似性）的患者相似性图，结合HybridGraphMedGNN（整合了GCN、GraphSAGE和GAT层）进行预测，增强模型对图结构信息的学习能力。

Result: 在MIMIC-III数据集的6000个ICU病例上，模型AUC-ROC达到0.94，超越基准分类器和单一类型的GNN模型，同时提高了精确率和召回率，并通过注意力机制提供了可解释性。

Conclusion: 该框架为重症监护风险预测提供了可扩展且具有解释性的解决方案，具备在实际ICU环境中支持临床医生的潜力。

Abstract: Accurately predicting the criticalness of ICU patients (such as in-ICU
mortality risk) is vital for early intervention in critical care. However,
conventional models often treat each patient in isolation and struggle to
exploit the relational structure in Electronic Health Records (EHR). We propose
a Similarity-Based Self-Construct Graph Model (SBSCGM) that dynamically builds
a patient similarity graph from multi-modal EHR data, and a HybridGraphMedGNN
architecture that operates on this graph to predict patient mortality and a
continuous criticalness score. SBSCGM uses a hybrid similarity measure
(combining feature-based and structural similarities) to connect patients with
analogous clinical profiles in real-time. The HybridGraphMedGNN integrates
Graph Convolutional Network (GCN), GraphSAGE, and Graph Attention Network (GAT)
layers to learn robust patient representations, leveraging both local and
global graph patterns. In experiments on 6,000 ICU stays from the MIMIC-III
dataset, our model achieves state-of-the-art performance (AUC-ROC $0.94$)
outperforming baseline classifiers and single-type GNN models. We also
demonstrate improved precision/recall and show that the attention mechanism
provides interpretable insights into model predictions. Our framework offers a
scalable and interpretable solution for critical care risk prediction, with
potential to support clinicians in real-world ICU deployment.

</details>


### [203] [IAMAP: Unlocking Deep Learning in QGIS for non-coders and limited computing resources](https://arxiv.org/abs/2508.00627)
*Paul Tresson,Pierre Le Coz,Hadrien Tulet,Anthony Malkassian,Maxime Réjou Méchain*

Main category: cs.LG

TL;DR: IAMAP是一个用户友好的QGIS插件，利用深度学习和自监督学习技术，使非AI专家能够高效进行遥感图像分析，而无需大量计算资源或编程技能。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在遥感中的技术壁垒，包括数据需求大、计算资源要求高和编程技能门槛高问题。

Method: 开发基于QGIS的IAMAP插件，引入自监督学习的基础模型，支持少样本或零样本场景，通过友好的界面完成特征提取、降维、聚类和模型验证等任务。

Result: IAMAP使非AI专家能够高效应用深度学习技术进行遥感图像分析，无需GPU或大规模参考数据集。

Conclusion: IAMAP拓宽了深度学习在遥感领域的应用范围，有利于推动计算效率高、能耗低的深度学习方法的普及和发展。

Abstract: Remote sensing has entered a new era with the rapid development of artificial
intelligence approaches. However, the implementation of deep learning has
largely remained restricted to specialists and has been impractical because it
often requires (i) large reference datasets for model training and validation;
(ii) substantial computing resources; and (iii) strong coding skills. Here, we
introduce IAMAP, a user-friendly QGIS plugin that addresses these three
challenges in an easy yet flexible way. IAMAP builds on recent advancements in
self-supervised learning strategies, which now provide robust feature
extractors, often referred to as foundation models. These generalist models can
often be reliably used in few-shot or zero-shot scenarios (i.e., with little to
no fine-tuning). IAMAP's interface allows users to streamline several key steps
in remote sensing image analysis: (i) extracting image features using a wide
range of deep learning architectures; (ii) reducing dimensionality with
built-in algorithms; (iii) performing clustering on features or their reduced
representations; (iv) generating feature similarity maps; and (v) calibrating
and validating supervised machine learning models for prediction. By enabling
non-AI specialists to leverage the high-quality features provided by recent
deep learning approaches without requiring GPU capacity or extensive reference
datasets, IAMAP contributes to the democratization of computationally efficient
and energy-conscious deep learning methods.

</details>


### [204] [Separated-Variable Spectral Neural Networks: A Physics-Informed Learning Approach for High-Frequency PDEs](https://arxiv.org/abs/2508.00628)
*Xiong Xiong,Zhuo Zhang,Rongchun Hu,Chen Gao,Zichen Deng*

Main category: cs.LG

TL;DR: 提出了一种解决高频振荡PDE问题的框架：SV-SNN，通过分离变量和自适应谱方法应对传统PINNs的频谱偏差问题。


<details>
  <summary>Details</summary>
Motivation: 高频振荡的偏微分方程（PDE）在科学计算中至关重要，而传统PINNs难以捕捉高频分量。

Method: 提出结合变量分离方法和自适应频谱方法的SV-SNN框架，包括多变量分解为一元函数乘积、自适应傅里叶频谱特征和SVD理论框架。

Result: 在多个基准问题中表现出显著的精度提升（1-3个数量级），同时减少参数量超过90%，训练时间减少60%。

Conclusion: SV-SNN有效解决了神经网络求解PDE中的频谱偏差问题，是高效的解决方案。

Abstract: Solving high-frequency oscillatory partial differential equations (PDEs) is a
critical challenge in scientific computing, with applications in fluid
mechanics, quantum mechanics, and electromagnetic wave propagation. Traditional
physics-informed neural networks (PINNs) suffer from spectral bias, limiting
their ability to capture high-frequency solution components. We introduce
Separated-Variable Spectral Neural Networks (SV-SNN), a novel framework that
addresses these limitations by integrating separation of variables with
adaptive spectral methods. Our approach features three key innovations: (1)
decomposition of multivariate functions into univariate function products,
enabling independent spatial and temporal networks; (2) adaptive Fourier
spectral features with learnable frequency parameters for high-frequency
capture; and (3) theoretical framework based on singular value decomposition to
quantify spectral bias. Comprehensive evaluation on benchmark problems
including Heat equation, Helmholtz equation, Poisson equations and
Navier-Stokes equations demonstrates that SV-SNN achieves 1-3 orders of
magnitude improvement in accuracy while reducing parameter count by over 90\%
and training time by 60\%. These results establish SV-SNN as an effective
solution to the spectral bias problem in neural PDE solving. The implementation
will be made publicly available upon acceptance at
https://github.com/xgxgnpu/SV-SNN.

</details>


### [205] [KFS: KAN based adaptive Frequency Selection learning architecture for long term time series forecasting](https://arxiv.org/abs/2508.00635)
*Changning Wu,Gao Wu,Rongyao Cai,Yong Liu,Kexin Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种基于Kolmogorov-Arnold Networks(KAN)的自适应频率选择学习架构(KFS)，通过跨尺度噪声干扰和复杂模式建模来解决时间序列预测中的问题，并在多项数据集实验中达到了领先表现。


<details>
  <summary>Details</summary>
Motivation: 现有的多尺度分解架构在时间序列预测中存在噪声干扰和异质频率信息分布的问题，该研究试图通过创新架构解决此类问题。

Method: 采用KAN框架，提出FreK模块以频谱域内主导频率选择，并通过时间戳嵌入对齐实现跨尺度时间表示对齐，同时通过特征混合模块融合特征。

Result: 在多项实际时间序列数据集中，所提方法显示出领先于其他方法的预测性能和效果。

Conclusion: 该架构简单高效，能够有效解决时间序列预测中的跨尺度噪声干扰和复杂模式建模问题，并取得了先进的预测性能。

Abstract: Multi-scale decomposition architectures have emerged as predominant
methodologies in time series forecasting. However, real-world time series
exhibit noise interference across different scales, while heterogeneous
information distribution among frequency components at varying scales leads to
suboptimal multi-scale representation. Inspired by Kolmogorov-Arnold Networks
(KAN) and Parseval's theorem, we propose a KAN based adaptive Frequency
Selection learning architecture (KFS) to address these challenges. This
framework tackles prediction challenges stemming from cross-scale noise
interference and complex pattern modeling through its FreK module, which
performs energy-distribution-based dominant frequency selection in the spectral
domain. Simultaneously, KAN enables sophisticated pattern representation while
timestamp embedding alignment synchronizes temporal representations across
scales. The feature mixing module then fuses scale-specific patterns with
aligned temporal features. Extensive experiments across multiple real-world
time series datasets demonstrate that KT achieves state-of-the-art performance
as a simple yet effective architecture.

</details>


### [206] [Reinforcement Learning for Decision-Level Interception Prioritization in Drone Swarm Defense](https://arxiv.org/abs/2508.00641)
*Alessandro Palmas*

Main category: cs.LG

TL;DR: 本文研究使用强化学习来应对低成本自杀式无人机群威胁，提出了强化学习策略在拦截决策中的优势并验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 低成本自杀式无人机群的威胁对现代防御系统提出了快速和战略性决策的需求，需要优先拦截并协调多个拦截装置对高价值目标区域的保护。

Method: 引入一个高保真模拟环境，捕捉现实约束条件下的操作因素，并通过强化学习代理学会在离散的动作空间中，基于状态特征（如位置、类别和装置状态）选择效用的拦截目标。方法与手工制定的规则基线在数百种模拟攻击场景中比较。

Result: 强化学习策略相较于规则基准具有更低的平均伤害并能提高防御效率。

Conclusion: 强化学习可以作为防御架构中的战略层面，增强防御韧性，同时不排斥现有控制系统的使用。

Abstract: The growing threat of low-cost kamikaze drone swarms poses a critical
challenge to modern defense systems demanding rapid and strategic
decision-making to prioritize interceptions across multiple effectors and
high-value target zones. In this work, we present a case study demonstrating
the practical advantages of reinforcement learning in addressing this
challenge. We introduce a high-fidelity simulation environment that captures
realistic operational constraints, within which a decision-level reinforcement
learning agent learns to coordinate multiple effectors for optimal interception
prioritization. Operating in a discrete action space, the agent selects which
drone to engage per effector based on observed state features such as
positions, classes, and effector status. We evaluate the learned policy against
a handcrafted rule-based baseline across hundreds of simulated attack
scenarios. The reinforcement learning based policy consistently achieves lower
average damage and higher defensive efficiency in protecting critical zones.
This case study highlights the potential of reinforcement learning as a
strategic layer within defense architectures, enhancing resilience without
displacing existing control systems. All code and simulation assets are
publicly released for full reproducibility, and a video demonstration
illustrates the policy's qualitative behavior.

</details>


### [207] [Light-Weight Diffusion Multiplier and Uncertainty Quantification for Fourier Neural Operators](https://arxiv.org/abs/2508.00643)
*Albert Matveev,Sanmitra Ghosh,Aamal Hussain,James-Michael Leahy,Michalis Michaelides*

Main category: cs.LG

TL;DR: DINOZAUR 引入基于扩散的神经算子参数化，并实现了不依赖维度的参数减少和高效的不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 解决 FNO 存在的参数过多、扩展性差以及缺乏原生不确定性量化能力的问题，满足科学与工程中可靠应用的需求。

Method: 借鉴热核结构，替换 FNO 中的密集张量乘法器为具有单通道可学习时间参数的扩散乘法器。通过对时间参数定义先验，将模型转化为贝叶斯神经算子，实现空间相关输出和校准的不确定性估计。

Result: 在多个偏微分方程（PDE）基准任务中表现出色，有竞争力，提供了高效的不确定性量化，同时降低了参数数量和内存占用。

Conclusion: DINOZAUR 不仅保留了 FNO 的预测性能，减少了过度参数化问题，同时通过贝叶斯框架实现了高效的不确定性量化，是计算效率和可靠性的有效结合。

Abstract: Operator learning is a powerful paradigm for solving partial differential
equations, with Fourier Neural Operators serving as a widely adopted
foundation. However, FNOs face significant scalability challenges due to
overparameterization and offer no native uncertainty quantification -- a key
requirement for reliable scientific and engineering applications. Instead,
neural operators rely on post hoc UQ methods that ignore geometric inductive
biases. In this work, we introduce DINOZAUR: a diffusion-based neural operator
parametrization with uncertainty quantification. Inspired by the structure of
the heat kernel, DINOZAUR replaces the dense tensor multiplier in FNOs with a
dimensionality-independent diffusion multiplier that has a single learnable
time parameter per channel, drastically reducing parameter count and memory
footprint without compromising predictive performance. By defining priors over
those time parameters, we cast DINOZAUR as a Bayesian neural operator to yield
spatially correlated outputs and calibrated uncertainty estimates. Our method
achieves competitive or superior performance across several PDE benchmarks
while providing efficient uncertainty quantification.

</details>


### [208] [TrajSurv: Learning Continuous Latent Trajectories from Electronic Health Records for Trustworthy Survival Prediction](https://arxiv.org/abs/2508.00657)
*Sihang Zeng,Lucas Jing Liu,Jun Wen,Meliha Yetisgen,Ruth Etzioni,Gang Luo*

Main category: cs.LG

TL;DR: TrajSurv模型利用NCDE从纵向EHR数据中提取连续潜在轨迹，用于生存预测，测试显示其准确性和透明度领先于现有方法。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够准确建模患者持续临床进展并能与生存预测结果透明关联的方法。

Method: 采用神经控制微分方程（NCDE）提取连续潜在状态，结合时间感知对比学习对潜在空间进行校准，并通过两步解释过程实现透明关联。

Result: 在MIMIC-III和eICU数据集上，TrajSurv表现出与现有方法相比更高的准确性和透明度。

Conclusion: TrajSurv能够可信地从不规则采样数据中提取临床进展信息并精准关联生存结果，为临床决策提供了重要助力。

Abstract: Trustworthy survival prediction is essential for clinical decision making.
Longitudinal electronic health records (EHRs) provide a uniquely powerful
opportunity for the prediction. However, it is challenging to accurately model
the continuous clinical progression of patients underlying the irregularly
sampled clinical features and to transparently link the progression to survival
outcomes. To address these challenges, we develop TrajSurv, a model that learns
continuous latent trajectories from longitudinal EHR data for trustworthy
survival prediction. TrajSurv employs a neural controlled differential equation
(NCDE) to extract continuous-time latent states from the irregularly sampled
data, forming continuous latent trajectories. To ensure the latent trajectories
reflect the clinical progression, TrajSurv aligns the latent state space with
patient state space through a time-aware contrastive learning approach. To
transparently link clinical progression to the survival outcome, TrajSurv uses
latent trajectories in a two-step divide-and-conquer interpretation process.
First, it explains how the changes in clinical features translate into the
latent trajectory's evolution using a learned vector field. Second, it clusters
these latent trajectories to identify key clinical progression patterns
associated with different survival outcomes. Evaluations on two real-world
medical datasets, MIMIC-III and eICU, show TrajSurv's competitive accuracy and
superior transparency over existing deep learning methods.

</details>


### [209] [DP-DGAD: A Generalist Dynamic Graph Anomaly Detector with Dynamic Prototypes](https://arxiv.org/abs/2508.00664)
*Jialun Zheng,Jie Liu,Jiannong Cao,Xiao Wang,Hanchen Yang,Yankai Chen,Philip S. Yu*

Main category: cs.LG

TL;DR: 提出了一种名为DP-DGAD的新型动态图异常检测模型，利用动态原型来检测随时间演变的领域特定和领域无关的异常模式，效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有的常规静态图异常检测方法难以处理动态图中的演化异常问题。动态图中的异常不仅需要识别领域特定的模式，还需探索领域无关的跨时间演化特征，尤其是在新领域和数据稀缺情况下的挑战。

Method: 提出的DP-DGAD模型通过提取动态原型，存储于一个选择性更新的内存缓冲区中，以保留领域无关模式并集成领域特定模式；利用异常评分机制对输入数据与动态原型进行比较，以及使用基于置信度的伪标签实现目标领域的自监督适应。

Result: 在来自不同领域的10个真实数据集上进行的广泛实验表明，该方法达到了目前最先进的性能。

Conclusion: DP-DGAD模型可以有效捕获动态图中的领域特定和领域无关的异常模式，并且在多种真实领域中具有良好的跨域适应性能。

Abstract: Dynamic graph anomaly detection (DGAD) is essential for identifying anomalies
in evolving graphs across domains such as finance, traffic, and social
networks. Recently, generalist graph anomaly detection (GAD) models have shown
promising results. They are pretrained on multiple source datasets and
generalize across domains. While effective on static graphs, they struggle to
capture evolving anomalies in dynamic graphs. Moreover, the continuous
emergence of new domains and the lack of labeled data further challenge
generalist DGAD. Effective cross-domain DGAD requires both domain-specific and
domain-agnostic anomalous patterns. Importantly, these patterns evolve
temporally within and across domains. Building on these insights, we propose a
DGAD model with Dynamic Prototypes (DP) to capture evolving domain-specific and
domain-agnostic patterns. Firstly, DP-DGAD extracts dynamic prototypes, i.e.,
evolving representations of normal and anomalous patterns, from temporal
ego-graphs and stores them in a memory buffer. The buffer is selectively
updated to retain general, domain-agnostic patterns while incorporating new
domain-specific ones. Then, an anomaly scorer compares incoming data with
dynamic prototypes to flag both general and domain-specific anomalies. Finally,
DP-DGAD employs confidence-based pseudo-labeling for effective self-supervised
adaptation in target domains. Extensive experiments demonstrate
state-of-the-art performance across ten real-world datasets from different
domains.

</details>


### [210] [Wind Power Scenario Generation based on the Generalized Dynamic Factor Model and Generative Adversarial Network](https://arxiv.org/abs/2508.00692)
*Young-ho Cho,Hao Zhu,Duehee Lee,Ross Baldick*

Main category: cs.LG

TL;DR: 结合GDFM和GAN方法以改善风电场长时间尺度的风电功率场景合成。


<details>
  <summary>Details</summary>
Motivation: 希望通过新的方法更准确地生成反映风电场分布和时间特性的数据场景，以提高资源充足性研究的准确性。

Method: 基于GDFM提取的波形空间特性，结合GAN处理的时间相关性样本，通过GDFM和GAN的融合生成更真实的风电功率场景。

Result: 与以往的单一方法相比，GDFM与GAN的结合方法能够更准确地生成符合风电功率实际统计特性的风电场景，在澳大利亚数据集上的数值验证展示了优异的性能。

Conclusion: 将GAN的动态因子提取能力和GDFM的空间及频率相关性建模能力相结合，能够更准确地实现长时间数据的风电功率场景合成，提升合成质量。

Abstract: For conducting resource adequacy studies, we synthesize multiple long-term
wind power scenarios of distributed wind farms simultaneously by using the
spatio-temporal features: spatial and temporal correlation, waveforms, marginal
and ramp rates distributions of waveform, power spectral densities, and
statistical characteristics. Generating the spatial correlation in scenarios
requires the design of common factors for neighboring wind farms and
antithetical factors for distant wind farms. The generalized dynamic factor
model (GDFM) can extract the common factors through cross spectral density
analysis, but it cannot closely imitate waveforms. The GAN can synthesize
plausible samples representing the temporal correlation by verifying samples
through a fake sample discriminator. To combine the advantages of GDFM and GAN,
we use the GAN to provide a filter that extracts dynamic factors with temporal
information from the observation data, and we then apply this filter in the
GDFM to represent both spatial and frequency correlations of plausible
waveforms. Numerical tests on the combination of GDFM and GAN have demonstrated
performance improvements over competing alternatives in synthesizing wind power
scenarios from Australia, better realizing plausible statistical
characteristics of actual wind power compared to alternatives such as the GDFM
with a filter synthesized from distributions of actual dynamic filters and the
GAN with direct synthesis without dynamic factors.

</details>


### [211] [Classification of Psychiatry Clinical Notes by Diagnosis: A Deep Learning and Machine Learning Approach](https://arxiv.org/abs/2508.00695)
*Sergio Rubio-Martín,María Teresa García-Ordás,Antonio Serrano-García,Clara Margarita Franch-Pato,Arturo Crespo-Álvaro,José Alberto Benítez-Andrades*

Main category: cs.LG

TL;DR: 本研究比较了多种人工智能模型在分类临床笔记为焦虑症和适应障碍诊断的表现，并探讨了过采样策略和超参数优化的影响，结果显示超参数优化显著提高了准确率。


<details>
  <summary>Details</summary>
Motivation: 通过将临床笔记分类为特定诊断类别，尤其在心理健康诊断如焦虑症和适应障碍中，以促进更有效的AI辅助诊断工具开发。

Method: 本研究采用传统机器学习模型（如随机森林、支持向量机等）和深度学习模型（如DistilBERT和SciBERT），并结合三种过采样策略及超参数优化，对焦虑症和适应障碍的分类进行性能评估。

Result: 过采样技术整体影响较小，但SMOTE对基于BERT的模型表现有积极作用。超参数优化显著提升了模型的准确率，决策树和极端梯度提升模型在机器学习中表现最佳（准确率96%），DistilBERT和SciBERT在深度学习中表现均达96%。

Conclusion: 超参数优化对提升模型性能至关重要。本研究通过评估不同模型架构和数据平衡方法，为心理健康AI诊断工具的开发提供了宝贵的洞察。

Abstract: The classification of clinical notes into specific diagnostic categories is
critical in healthcare, especially for mental health conditions like Anxiety
and Adjustment Disorder. In this study, we compare the performance of various
Artificial Intelligence models, including both traditional Machine Learning
approaches (Random Forest, Support Vector Machine, K-nearest neighbors,
Decision Tree, and eXtreme Gradient Boost) and Deep Learning models (DistilBERT
and SciBERT), to classify clinical notes into these two diagnoses.
Additionally, we implemented three oversampling strategies: No Oversampling,
Random Oversampling, and Synthetic Minority Oversampling Technique (SMOTE), to
assess their impact on model performance. Hyperparameter tuning was also
applied to optimize model accuracy. Our results indicate that oversampling
techniques had minimal impact on model performance overall. The only exception
was SMOTE, which showed a positive effect specifically with BERT-based models.
However, hyperparameter optimization significantly improved accuracy across the
models, enhancing their ability to generalize and perform on the dataset. The
Decision Tree and eXtreme Gradient Boost models achieved the highest accuracy
among machine learning approaches, both reaching 96%, while the DistilBERT and
SciBERT models also attained 96% accuracy in the deep learning category. These
findings underscore the importance of hyperparameter tuning in maximizing model
performance. This study contributes to the ongoing research on AI-assisted
diagnostic tools in mental health by providing insights into the efficacy of
different model architectures and data balancing methods.

</details>


### [212] [Learning Network Dismantling without Handcrafted Inputs](https://arxiv.org/abs/2508.00706)
*Haozhe Tian,Pietro Ferraro,Robert Shorten,Mahdi Jalili,Homayoun Hamedmoghadam*

Main category: cs.LG

TL;DR: 该论文提出了一种新的基于消息传递的网络拆解模型（MIND），通过消除手工特征，改进注意力机制和优化训练集生成，实现了更高效的性能。


<details>
  <summary>Details</summary>
Motivation: 现有以消息传递图神经网络为基础的方法存在依赖手工特征的缺点，这不仅增加了计算复杂度，还可能引入偏差。因此需要一种纯数据驱动且更高效的方法。

Method: 引入注意力机制，利用消息迭代特征，并通过合成网络生成算法构建结构多样化的训练集，开发了一种更高表达能力的消息传递框架。

Result: 该方法在大型真实网络（节点数达百万）上表现出色，超过了当前最先进的网络拆解方法，并展现出较强的泛化能力。

Conclusion: MIND模型能有效解决NP难问题的网络拆解，并拥有更高效和更通用的特性，可扩展应用于复杂网络问题的多个领域。

Abstract: The application of message-passing Graph Neural Networks has been a
breakthrough for important network science problems. However, the competitive
performance often relies on using handcrafted structural features as inputs,
which increases computational cost and introduces bias into the otherwise
purely data-driven network representations. Here, we eliminate the need for
handcrafted features by introducing an attention mechanism and utilizing
message-iteration profiles, in addition to an effective algorithmic approach to
generate a structurally diverse training set of small synthetic networks.
Thereby, we build an expressive message-passing framework and use it to
efficiently solve the NP-hard problem of Network Dismantling, virtually
equivalent to vital node identification, with significant real-world
applications. Trained solely on diversified synthetic networks, our proposed
model -- MIND: Message Iteration Network Dismantler -- generalizes to large,
unseen real networks with millions of nodes, outperforming state-of-the-art
network dismantling methods. Increased efficiency and generalizability of the
proposed model can be leveraged beyond dismantling in a range of complex
network problems.

</details>


### [213] [Efficient Solution and Learning of Robust Factored MDPs](https://arxiv.org/abs/2508.00707)
*Yannik Schnitzer,Alessandro Abate,David Parker*

Main category: cs.LG

TL;DR: 本文研究了利用分解状态空间表示解决和学习稳健马尔可夫决策过程（r-MDPs）的方法，通过线性规划解决非凸优化问题，并实现了高效样本利用。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从未知环境中学习r-MDPs时需要大量样本交互，提升样本利用效率的需求紧迫。

Method: 提出基于分解状态空间表示学习r-MDPs的方法，将复杂的非凸优化转化为可处理的线性规划，并直接学习分解的模型表示。

Result: 实验结果显示，利用分解结构可显著提高样本效率，比现有方法生成更有效的稳健策略并提供更严格的性能保证。

Conclusion: 分解状态空间表示有助于提升r-MDPs学习的样本效率和稳健性能，展示了其在相关领域的巨大潜力。

Abstract: Robust Markov decision processes (r-MDPs) extend MDPs by explicitly modelling
epistemic uncertainty about transition dynamics. Learning r-MDPs from
interactions with an unknown environment enables the synthesis of robust
policies with provable (PAC) guarantees on performance, but this can require a
large number of sample interactions. We propose novel methods for solving and
learning r-MDPs based on factored state-space representations that leverage the
independence between model uncertainty across system components. Although
policy synthesis for factored r-MDPs leads to hard, non-convex optimisation
problems, we show how to reformulate these into tractable linear programs.
Building on these, we also propose methods to learn factored model
representations directly. Our experimental results show that exploiting
factored structure can yield dimensional gains in sample efficiency, producing
more effective robust policies with tighter performance guarantees than
state-of-the-art methods.

</details>


### [214] [JSON-Bag: A generic game trajectory representation](https://arxiv.org/abs/2508.00712)
*Dien Nguyen,Diego Perez-Liebana,Simon Lucas*

Main category: cs.LG

TL;DR: 提出了一种称为JSON Bag-of-Tokens (JSON-Bag) 的模型，用于表示游戏轨迹，并运用Jensen-Shannon距离（JSD）作为其距离度量。


<details>
  <summary>Details</summary>
Motivation: 解决游戏轨迹通用表示方法的问题，目标是提升性能并实现自动特征提取。

Method: 通过JSON-Bag模型将游戏轨迹JSON描述数据进行token化，结合JSD度量计算差异，并通过原型邻近搜索（P-NNS）进行验证及分类任务评估。

Result: 在六款桌面游戏上验证了JSON-Bag的优越性，大部分任务超过了基线性能，并展示了其特征提取的潜力。

Conclusion: JSON-Bag不仅在多数分类任务中表现出色，还能高效地表示类别和提取特征，显著提升准确率，并揭示了JSD与策略差异的相关性。

Abstract: We introduce JSON Bag-of-Tokens model (JSON-Bag) as a method to generically
represent game trajectories by tokenizing their JSON descriptions and apply
Jensen-Shannon distance (JSD) as distance metric for them. Using a
prototype-based nearest-neighbor search (P-NNS), we evaluate the validity of
JSON-Bag with JSD on six tabletop games -- \textit{7 Wonders},
\textit{Dominion}, \textit{Sea Salt and Paper}, \textit{Can't Stop},
\textit{Connect4}, \textit{Dots and boxes} -- each over three game trajectory
classification tasks: classifying the playing agents, game parameters, or game
seeds that were used to generate the trajectories.
  Our approach outperforms a baseline using hand-crafted features in the
majority of tasks. Evaluating on N-shot classification suggests using JSON-Bag
prototype to represent game trajectory classes is also sample efficient.
Additionally, we demonstrate JSON-Bag ability for automatic feature extraction
by treating tokens as individual features to be used in Random Forest to solve
the tasks above, which significantly improves accuracy on underperforming
tasks. Finally, we show that, across all six games, the JSD between JSON-Bag
prototypes of agent classes highly correlates with the distances between
agents' policies.

</details>


### [215] [Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning](https://arxiv.org/abs/2508.00716)
*Yingxu Wang,Mengzhu Wang,Zhichao Huang,Suyu Liu*

Main category: cs.LG

TL;DR: 本文提出一种用于图域自适应的新框架NeGPR，旨在解决源域标签噪声对适配性能的影响，通过多分支预训练和嵌套伪标签细化机制实现跨域学习，并通过噪声感知正则化增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有图域自适应方法假设源域标签干净，但现实中普遍存在标签噪声，这对特征对齐和适配性能造成严重影响。该论文旨在解决这一挑战。

Method: 提出了NeGPR框架，包含语义分支与拓扑分支的多分支预训练，通过嵌套细化机制交替选择高置信样本引导跨域学习，并结合噪声感知正则化以减轻伪标签噪声和源域过拟合的影响。

Result: 实验表明，NeGPR在多个基准数据集上展示了显著优于现有方法的性能，在严重标签噪声情况下，精度提升可达12.7%。

Conclusion: NeGPR通过解决标签噪声和源域过拟合问题，显著提高了图域自适应任务中的跨域学习效果和鲁棒性。

Abstract: Graph Domain Adaptation (GDA) facilitates knowledge transfer from labeled
source graphs to unlabeled target graphs by learning domain-invariant
representations, which is essential in applications such as molecular property
prediction and social network analysis. However, most existing GDA methods rely
on the assumption of clean source labels, which rarely holds in real-world
scenarios where annotation noise is pervasive. This label noise severely
impairs feature alignment and degrades adaptation performance under domain
shifts. To address this challenge, we propose Nested Graph Pseudo-Label
Refinement (NeGPR), a novel framework tailored for graph-level domain
adaptation with noisy labels. NeGPR first pretrains dual branches, i.e.,
semantic and topology branches, by enforcing neighborhood consistency in the
feature space, thereby reducing the influence of noisy supervision. To bridge
domain gaps, NeGPR employs a nested refinement mechanism in which one branch
selects high-confidence target samples to guide the adaptation of the other,
enabling progressive cross-domain learning. Furthermore, since pseudo-labels
may still contain noise and the pre-trained branches are already overfitted to
the noisy labels in the source domain, NeGPR incorporates a noise-aware
regularization strategy. This regularization is theoretically proven to
mitigate the adverse effects of pseudo-label noise, even under the presence of
source overfitting, thus enhancing the robustness of the adaptation process.
Extensive experiments on benchmark datasets demonstrate that NeGPR consistently
outperforms state-of-the-art methods under severe label noise, achieving gains
of up to 12.7% in accuracy.

</details>


### [216] [Democratizing Tabular Data Access with an Open$\unicode{x2013}$Source Synthetic$\unicode{x2013}$Data SDK](https://arxiv.org/abs/2508.00718)
*Ivona Krchova,Mariana Vargas Vieyra,Mario Scriminaci,Andrey Sidorenko*

Main category: cs.LG

TL;DR: 本文提出了一个开源的工具包，用于生成高质量的表格数据以应对数据获取的障碍。


<details>
  <summary>Details</summary>
Motivation: 由于隐私、专利权益和伦理问题，数据访问受到限制，需要一种既保护敏感信息又能高效利用数据的方案。

Method: 提出了一个名为MOSTLY AI Synthetic Data SDK的开源工具包，通过TabularARGN框架支持多种数据类型，同时包含差分隐私、数据公平性和数据质量保障功能。

Result: 该工具提升了多表和序列数据的合成性能，并显著提高速度和易用性，已被广泛采用。

Conclusion: 该工具提供了一种实际可行的解决方案，缓解了数据获取难题，推动了数据民主化。

Abstract: Machine learning development critically depends on access to high-quality
data. However, increasing restrictions due to privacy, proprietary interests,
and ethical concerns have created significant barriers to data accessibility.
Synthetic data offers a viable solution by enabling safe, broad data usage
without compromising sensitive information. This paper presents the MOSTLY AI
Synthetic Data Software Development Kit (SDK), an open-source toolkit designed
specifically for synthesizing high-quality tabular data. The SDK integrates
robust features such as differential privacy guarantees, fairness-aware data
generation, and automated quality assurance into a flexible and accessible
Python interface. Leveraging the TabularARGN autoregressive framework, the SDK
supports diverse data types and complex multi-table and sequential datasets,
delivering competitive performance with notable improvements in speed and
usability. Currently deployed both as a cloud service and locally installable
software, the SDK has seen rapid adoption, highlighting its practicality in
addressing real-world data bottlenecks and promoting widespread data
democratization.

</details>


### [217] [Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for Failure Analysis of Nonlinear Stochastic Systems](https://arxiv.org/abs/2508.00734)
*Liuyun Xu,Seymour M. J. Spence*

Main category: cs.LG

TL;DR: 本文提出一种用于稀有事件分析的多保真分层抽样方法，结合了自适应机器学习元模型和高、低保真度数据，以实现高效的不确定性传播和小概率失效估计，并应用于实际工程案例。


<details>
  <summary>Details</summary>
Motivation: 克服复杂非线性有限元建模环境中计算稀有事件失效概率时的高计算成本问题，尤其是在系统受到随机激励的情况下。

Method: 提出一种多保真分层抽样方案，利用分层采样生成高保真数据集训练深度学习元模型作为低保真模型，并通过自适应训练平衡近似质量和计算需求。结合多保真蒙特卡罗框架，使用全概率公式评估整体失效概率。

Result: 在全尺寸高层钢结构受随机风激励的案例中，该方法显著减少计算成本，同时准确估计非线性响应的超越概率曲线。

Conclusion: 多保真分层采样与自适应深度学习元模型相结合的方案，在精准度和效率上优于单一保真度的方差减小方法，具有实际工程应用潜力。

Abstract: Existing variance reduction techniques used in stochastic simulations for
rare event analysis still require a substantial number of model evaluations to
estimate small failure probabilities. In the context of complex, nonlinear
finite element modeling environments, this can become computationally
challenging-particularly for systems subjected to stochastic excitation. To
address this challenge, a multi-fidelity stratified sampling scheme with
adaptive machine learning metamodels is introduced for efficiently propagating
uncertainties and estimating small failure probabilities. In this approach, a
high-fidelity dataset generated through stratified sampling is used to train a
deep learning-based metamodel, which then serves as a cost-effective and highly
correlated low-fidelity model. An adaptive training scheme is proposed to
balance the trade-off between approximation quality and computational demand
associated with the development of the low-fidelity model. By integrating the
low-fidelity outputs with additional high-fidelity results, an unbiased
estimate of the strata-wise failure probabilities is obtained using a
multi-fidelity Monte Carlo framework. The overall probability of failure is
then computed using the total probability theorem. Application to a full-scale
high-rise steel building subjected to stochastic wind excitation demonstrates
that the proposed scheme can accurately estimate exceedance probability curves
for nonlinear responses of interest, while achieving significant computational
savings compared to single-fidelity variance reduction approaches.

</details>


### [218] [A Simple and Effective Method for Uncertainty Quantification and OOD Detection](https://arxiv.org/abs/2508.00754)
*Yaxin Ma,Benjamin Colburn,Jose C. Principe*

Main category: cs.LG

TL;DR: 提出了一种基于特征空间密度的新方法，用于分布转变和分布外检测，性能优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 目前贝叶斯神经网络和深度集成方法在不确定性量化中表现出色，但计算成本高且存储需求大，因此需要一种既高效又轻量化的方法。

Method: 通过单一确定性模型，利用核密度估计生成的信息势场近似训练集特征空间密度，并将其与测试样本的特征空间表示进行对比，以检测分布转变。

Result: 在2D合成数据集和一个OOD检测任务（CIFAR-10与SVHN）上实验，结果显示提出的方法优于基线模型。

Conclusion: 所提方法通过高效的特征空间密度计算实现了对分布转变和OOD的准确检测，为高效不确定性量化开辟了新方向。

Abstract: Bayesian neural networks and deep ensemble methods have been proposed for
uncertainty quantification; however, they are computationally intensive and
require large storage. By utilizing a single deterministic model, we can solve
the above issue. We propose an effective method based on feature space density
to quantify uncertainty for distributional shifts and out-of-distribution (OOD)
detection. Specifically, we leverage the information potential field derived
from kernel density estimation to approximate the feature space density of the
training set. By comparing this density with the feature space representation
of test samples, we can effectively determine whether a distributional shift
has occurred. Experiments were conducted on a 2D synthetic dataset (Two Moons
and Three Spirals) as well as an OOD detection task (CIFAR-10 vs. SVHN). The
results demonstrate that our method outperforms baseline models.

</details>


### [219] [Diffusion-Scheduled Denoising Autoencoders for Anomaly Detection in Tabular Data](https://arxiv.org/abs/2508.00758)
*Timur Sattarov,Marco Schreyer,Damian Borth*

Main category: cs.LG

TL;DR: 本文提出了一个名为DDAE（Diffusion-Scheduled Denoising Autoencoder）的模型，用于解决表格数据中的异常检测问题，并在多个基准数据集上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决表格数据异常检测中的特征复杂交互问题及异常样本稀缺问题，同时克服传统去噪自动编码器固定噪声策略的局限性。

Method: 结合扩散噪声调度和对比学习，将扩散噪声调度融入编码过程中，以改进异常检测性能。使用57个来自ADBench的数据集进行评价。

Result: DDAE在半监督设置下性能优越，在无监督设置下表现出了竞争力，相较于最先进模型提高了PR-AUC最多65%（9%）及ROC-AUC最多16%（6%）。

Conclusion: 合理的噪声策略对于优化表格数据异常检测至关重要，且噪声水平需要根据设置（无监督或半监督）进行调整以获得最佳效果。

Abstract: Anomaly detection in tabular data remains challenging due to complex feature
interactions and the scarcity of anomalous examples. Denoising autoencoders
rely on fixed-magnitude noise, limiting adaptability to diverse data
distributions. Diffusion models introduce scheduled noise and iterative
denoising, but lack explicit reconstruction mappings. We propose the
Diffusion-Scheduled Denoising Autoencoder (DDAE), a framework that integrates
diffusion-based noise scheduling and contrastive learning into the encoding
process to improve anomaly detection. We evaluated DDAE on 57 datasets from
ADBench. Our method outperforms in semi-supervised settings and achieves
competitive results in unsupervised settings, improving PR-AUC by up to 65%
(9%) and ROC-AUC by 16% (6%) over state-of-the-art autoencoder (diffusion)
model baselines. We observed that higher noise levels benefit unsupervised
training, while lower noise with linear scheduling is optimal in
semi-supervised settings. These findings underscore the importance of
principled noise strategies in tabular anomaly detection.

</details>


### [220] [Evaluating Angle and Amplitude Encoding Strategies for Variational Quantum Machine Learning: their impact on model's accuracy](https://arxiv.org/abs/2508.00768)
*Antonio Tudisco,Andrea Marchesin,Maurizio Zamboni,Mariagrazia Graziano,Giovanna Turvani*

Main category: cs.LG

TL;DR: 这篇文章研究了量子机器学习中的变分量子电路（VQC），分析了不同编码方式和旋转门类型对分类性能的影响。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算和机器学习的发展，使用量子计算框架开发机器学习模型成为热点。文章希望了解量子编码和门设计如何影响模型表现。

Method: 文章选取了两种数据集（Wine和Diabetes），通过变分量子电路，分别对振幅编码和角度编码方式模型进行性能对比，分析旋转门对于分类精度的影响。

Result: 实验表明，不同模型的最佳与最差精度相差10%-30%，部分情况差距可达41%。旋转门设计对分类精度有重要影响。

Conclusion: 嵌入策略是VQC模型的重要超参数，不同旋转门实现的选择可以显著影响量子机器学习模型的分类性能。

Abstract: Recent advancements in Quantum Computing and Machine Learning have increased
attention to Quantum Machine Learning (QML), which aims to develop machine
learning models by exploiting the quantum computing paradigm. One of the widely
used models in this area is the Variational Quantum Circuit (VQC), a hybrid
model where the quantum circuit handles data inference while classical
optimization adjusts the parameters of the circuit. The quantum circuit
consists of an encoding layer, which loads data into the circuit, and a
template circuit, known as the ansatz, responsible for processing the data.
This work involves performing an analysis by considering both Amplitude- and
Angle-encoding models, and examining how the type of rotational gate applied
affects the classification performance of the model. This comparison is carried
out by training the different models on two datasets, Wine and Diabetes, and
evaluating their performance. The study demonstrates that, under identical
model topologies, the difference in accuracy between the best and worst models
ranges from 10% to 30%, with differences reaching up to 41%. Moreover, the
results highlight how the choice of rotational gates used in encoding can
significantly impact the model's classification performance. The findings
confirm that the embedding represents a hyperparameter for VQC models.

</details>


### [221] [Explainable AI and Machine Learning for Exam-based Student Evaluation: Causal and Predictive Analysis of Socio-academic and Economic Factors](https://arxiv.org/abs/2508.00785)
*Bushra Akter,Md Biplob Hosen,Sabbir Ahmed,Mehrin Anannya,Md. Farhad Hossain*

Main category: cs.LG

TL;DR: 本研究通过调查关键影响因素，结合因果分析和预测模型，构建了一种优化学生CGPA的策略，并开发了基于网络的应用程序。


<details>
  <summary>Details</summary>
Motivation: 探索影响学生学术表现的关键因素，以帮助学生优化CGPA并做出明智决策。

Method: 通过文献综述和假设因果图构建，结合线上调查数据，应用数据预处理、因果分析、回归与分类模型，以及解释性AI技术（如SHAP与LIME）进行研究。

Result: 回归模型中岭回归表现最佳，MAE为0.12，MSE为0.023；随机森林分类模型F1得分接近完美，准确率达98.68%。

Conclusion: 研究开发了一个网络应用，提供个性化建议和CGPA预测，帮助学生改善学术表现并做出更明智的选择。

Abstract: Academic performance depends on a multivariable nexus of socio-academic and
financial factors. This study investigates these influences to develop
effective strategies for optimizing students' CGPA. To achieve this, we
reviewed various literature to identify key influencing factors and constructed
an initial hypothetical causal graph based on the findings. Additionally, an
online survey was conducted, where 1,050 students participated, providing
comprehensive data for analysis. Rigorous data preprocessing techniques,
including cleaning and visualization, ensured data quality before analysis.
Causal analysis validated the relationships among variables, offering deeper
insights into their direct and indirect effects on CGPA. Regression models were
implemented for CGPA prediction, while classification models categorized
students based on performance levels. Ridge Regression demonstrated strong
predictive accuracy, achieving a Mean Absolute Error of 0.12 and a Mean Squared
Error of 0.023. Random Forest outperformed in classification, attaining an
F1-score near perfection and an accuracy of 98.68%. Explainable AI techniques
such as SHAP, LIME, and Interpret enhanced model interpretability, highlighting
critical factors such as study hours, scholarships, parental education, and
prior academic performance. The study culminated in the development of a
web-based application that provides students with personalized insights,
allowing them to predict academic performance, identify areas for improvement,
and make informed decisions to enhance their outcomes.

</details>


### [222] [Adacc: Adaptive Compression and Activation Checkpointing for LLM Memory Management](https://arxiv.org/abs/2508.00806)
*Ping Chen,Zhuohong Deng,Ping Li,Shuibing He,Hongzi Zhu,Yi Zheng,Zhefeng Wang,Baoxing Huai,Minyi Guo*

Main category: cs.LG

TL;DR: 该研究提出了Adacc框架，通过自适应压缩与激活检查点降低GPU内存占用，并加速大模型训练。


<details>
  <summary>Details</summary>
Motivation: 解决因重计算操作导致大规模语言模型训练内存压力大与额外开销的问题。

Method: 结合自适应压缩和激活检查点的独特框架Adacc，包括指定层压缩算法、MILP最优调度策略及政策演化机制。

Result: 实验结果表明，Adacc在保持模型准确性的情况下，相较最先进框架可将LLM训练速度加快1.01至1.37倍。

Conclusion: Adacc框架有效提高了LLM训练效率并减少了GPU内存消耗，兼具速度与精度优势，是一种较优的训练优化方案。

Abstract: Training large language models often employs recomputation to alleviate
memory pressure, which can introduce up to 30% overhead in real-world
scenarios. In this paper, we propose Adacc, a novel memory management framework
that combines adaptive compression and activation checkpointing to reduce the
GPU memory footprint. It comprises three modules: (1) We design layer-specific
compression algorithms that account for outliers in LLM tensors, instead of
directly quantizing floats from FP16 to INT4, to ensure model accuracy. (2) We
propose an optimal scheduling policy that employs MILP to determine the best
memory optimization for each tensor. (3) To accommodate changes in training
tensors, we introduce an adaptive policy evolution mechanism that adjusts the
policy during training to enhance throughput. Experimental results show that
Adacc can accelerate the LLM training by 1.01x to 1.37x compared to
state-of-the-art frameworks, while maintaining comparable model accuracy to the
Baseline.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [223] [Reinitializing weights vs units for maintaining plasticity in neural networks](https://arxiv.org/abs/2508.00212)
*J. Fernando Hernandez-Garcia,Shibhansh Dohare,Jun Luo,Rich S. Sutton*

Main category: cs.NE

TL;DR: 研究了神经网络在非平稳数据上训练时间过长导致的学习能力丧失现象，并提出了一种新的权重重新初始化算法来减缓该问题。


<details>
  <summary>Details</summary>
Motivation: 解决由于持续学习中的非平稳数据训练导致的神经网络学习能力丧失问题。

Method: 提出了选择性权重重新初始化算法，对网络中最不重要的权重进行重新初始化，并与现有重新初始化单元的算法（如continual backpropagation和ReDo）进行对比实验。

Result: 发现在以下两种情况下，权重重新初始化比单元重新初始化更有效：1. 网络单元较少时；2. 网络使用层归一化时。而在网络足够大且不使用层归一化时，两种方法效果相当。

Conclusion: 权重重新初始化在更广泛的设置中能更有效地维持网络的学习能力。

Abstract: Loss of plasticity is a phenomenon in which a neural network loses its
ability to learn when trained for an extended time on non-stationary data. It
is a crucial problem to overcome when designing systems that learn continually.
An effective technique for preventing loss of plasticity is reinitializing
parts of the network. In this paper, we compare two different reinitialization
schemes: reinitializing units vs reinitializing weights. We propose a new
algorithm, which we name \textit{selective weight reinitialization}, for
reinitializing the least useful weights in a network. We compare our algorithm
to continual backpropagation and ReDo, two previously proposed algorithms that
reinitialize units in the network. Through our experiments in continual
supervised learning problems, we identify two settings when reinitializing
weights is more effective at maintaining plasticity than reinitializing units:
(1) when the network has a small number of units and (2) when the network
includes layer normalization. Conversely, reinitializing weights and units are
equally effective at maintaining plasticity when the network is of sufficient
size and does not include layer normalization. We found that reinitializing
weights maintains plasticity in a wider variety of settings than reinitializing
units.

</details>


### [224] [Sequential, Parallel and Consecutive Hybrid Evolutionary-Swarm Optimization Metaheuristics](https://arxiv.org/abs/2508.00229)
*Piotr Urbańczyk,Aleksandra Urbańczyk,Magdalena Król,Leszek Rutkowski,Marek Kisiel-Dorohinicki*

Main category: cs.NE

TL;DR: 本文研究了结合PSO和GA特点的混合进化-群体智能元启发式算法，并提出了一个新颖的连续型混合PSO-GA算法。


<details>
  <summary>Details</summary>
Motivation: 探索混合进化-群体智能元启发式方法的优势，并解决高维搜索空间中的一致性问题。

Method: 提出了顺序、并行和连续方式结合PSO与GA的混合算法，并测试其在多个基准函数上的性能；同时设计了一个通过信息传递机制改进的连续型混合PSO-GA算法。

Result: 混合算法在高维空间中表现出更好的收敛性和一致性。

Conclusion: 混合算法优于传统PSO与GA，而提出的新连续型混合PSO-GA方法通过信息传递机制进一步提高了算法性能。

Abstract: The goal of this paper is twofold. First, it explores hybrid
evolutionary-swarm metaheuristics that combine the features of PSO and GA in a
sequential, parallel and consecutive manner in comparison with their standard
basic form: Genetic Algorithm and Particle Swarm Optimization. The algorithms
were tested on a set of benchmark functions, including Ackley, Griewank, Levy,
Michalewicz, Rastrigin, Schwefel, and Shifted Rotated Weierstrass, across
multiple dimensions. The experimental results demonstrate that the hybrid
approaches achieve superior convergence and consistency, especially in
higher-dimensional search spaces. The second goal of this paper is to introduce
a novel consecutive hybrid PSO-GA evolutionary algorithm that ensures
continuity between PSO and GA steps through explicit information transfer
mechanisms, specifically by modifying GA's variation operators to inherit
velocity and personal best information.

</details>


### [225] [Evolutionary Generative Optimization: Towards Fully Data-Driven Evolutionary Optimization via Generative Learning](https://arxiv.org/abs/2508.00380)
*Kebin Sun,Tao Jiang,Ran Cheng,Yaochu Jin,Kay Chen Tan*

Main category: cs.NE

TL;DR: 本文提出了一种名为EvoGO的进化生成优化框架，通过生成式学习改进优化精度与适应性，并在各种优化任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动进化算法依赖手动设计的启发式规则，限制了其通用性和自动化能力，本文提出全数据驱动的解决方案。

Method: EvoGO框架分为数据准备、模型训练和群体生成三阶段，利用生成式模型替代传统再生产算子，实现无额外评价成本的优化过程。

Result: 实验表明，EvoGO在仅10代中即可稳定收敛，并显著优于传统EAs、贝叶斯优化与强化学习等方法。

Conclusion: EvoGO通过生成式学习改造进化算法，证明了其在各种任务上的高效性与通用性，为优化领域提供了新的实现机制。

Abstract: Recent advances in data-driven evolutionary algorithms (EAs) have
demonstrated the potential of leveraging data to improve optimization accuracy
and adaptability. Nevertheless, most existing approaches remain dependent on
handcrafted heuristics, which limits their generality and automation. To
address this challenge, we propose Evolutionary Generative Optimization
(EvoGO), a fully data-driven framework empowered by generative learning. EvoGO
streamlines the evolutionary optimization process into three stages: data
preparation, model training, and population generation. The data preparation
stage constructs a pairwise dataset to enrich training diversity without
incurring additional evaluation costs. During model training, a tailored
generative model learns to transform inferior solutions into superior ones. In
the population generation stage, EvoGO replaces traditional reproduction
operators with a scalable and parallelizable generative mechanism. Extensive
experiments on numerical benchmarks, classical control problems, and
high-dimensional robotic tasks demonstrate that EvoGO consistently converges
within merely 10 generations and significantly outperforms a wide spectrum of
optimization approaches, including traditional EAs, Bayesian optimization, and
reinforcement learning based methods. Source code will be made publicly
available.

</details>


### [226] [STF: Shallow-Level Temporal Feedback to Enhance Spiking Transformers](https://arxiv.org/abs/2508.00387)
*Zeqi Zheng,Zizheng Zhu,Yingchao Yu,Yanchen Huang,Changze Lv,Junfeng Tang,Zhaofei Yu,Yaochu Jin*

Main category: cs.NE

TL;DR: 研究提出了一种名为STF的模块，用于提升基于Transformer的SNN性能，尤其是在静态数据集上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的SNN存在性能与ANN之间的显著差距，特别是由于脉冲信号的二进制特性。现有方法为缩小差距引入深层反馈，但导致较高的计算和能源成本。

Method: 引入了浅层时间反馈（STF）模块，包含时间-空间位置嵌入（TSPE）和时间反馈（TF）。该模块设计为轻量级且可方便插入编码层中。

Result: 实验表明，STF在CIFAR-10、CIFAR-100和ImageNet-1K等数据集上能显著提升各类Transformer-SNN骨架的表现，并改善脉冲模式的多样性。

Conclusion: STF作为一种新型脉冲编码方案在静态场景下表现出显著优势，未来可望在提升SNN性能方面发挥重要作用。

Abstract: Transformer-based Spiking Neural Networks (SNNs) suffer from a great
performance gap compared to floating-point Artificial Neural Networks (ANNs)
due to the binary nature of spike trains. Recent efforts have introduced
deep-level feedback loops to transmit high-level semantic information to narrow
this gap. However, these designs often span multiple deep layers, resulting in
costly feature transformations, higher parameter overhead, increased energy
consumption, and longer inference latency. To address this issue, we propose
Shallow-level Temporal Feedback (STF), a lightweight plug-and-play module for
the encoding layer, which consists of Temporal-Spatial Position Embedding
(TSPE) and Temporal Feedback (TF).Extensive experiments show that STF
consistently improves performance across various Transformer-based SNN
backbones on static datasets, including CIFAR-10, CIFAR-100, and ImageNet-1K,
under different spike timestep settings. Further analysis reveals that STF
enhances the diversity of the spike patterns, which is key to performance gain.
Moreover, evaluations on adversarial robustness and temporal sensitivity
confirm that STF outperforms direct coding and its variants, highlighting its
potential as a new spike encoding scheme for static scenarios. Our code will be
released upon acceptance.

</details>
