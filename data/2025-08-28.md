<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.CL](#cs.CL) [Total: 60]
- [cs.AI](#cs.AI) [Total: 17]
- [cs.LG](#cs.LG) [Total: 72]
- [cs.NE](#cs.NE) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Context-aware Sparse Spatiotemporal Learning for Event-based Vision](https://arxiv.org/abs/2508.19806)
*Shenqi Wang,Guangzhi Tang*

Main category: cs.CV

TL;DR: 提出了一种称为上下文感知稀疏时空学习（CSSL）的新框架，针对事件相机数据，实现了高效的目标检测和光流估计，同时保持高稀疏性。


<details>
  <summary>Details</summary>
Motivation: 为了在资源受限的情况下充分利用事件相机数据的稀疏性，开发一个既能节能又高效的方法。

Method: 引入上下文感知阈值，通过动态调节神经元激活来减少激活密度，而不依赖显性稀疏约束。

Result: 在事件目标检测和光流估计任务中，CSSL与先进方法相比具有相当或更优的性能，并大幅提升神经元稀疏性。

Conclusion: CSSL框架为神经形态处理的高效事件视觉提供了重要支持，展现出优越的稀疏性和性能。

Abstract: Event-based camera has emerged as a promising paradigm for robot perception,
offering advantages with high temporal resolution, high dynamic range, and
robustness to motion blur. However, existing deep learning-based event
processing methods often fail to fully leverage the sparse nature of event
data, complicating their integration into resource-constrained edge
applications. While neuromorphic computing provides an energy-efficient
alternative, spiking neural networks struggle to match of performance of
state-of-the-art models in complex event-based vision tasks, like object
detection and optical flow. Moreover, achieving high activation sparsity in
neural networks is still difficult and often demands careful manual tuning of
sparsity-inducing loss terms. Here, we propose Context-aware Sparse
Spatiotemporal Learning (CSSL), a novel framework that introduces context-aware
thresholding to dynamically regulate neuron activations based on the input
distribution, naturally reducing activation density without explicit sparsity
constraints. Applied to event-based object detection and optical flow
estimation, CSSL achieves comparable or superior performance to
state-of-the-art methods while maintaining extremely high neuronal sparsity.
Our experimental results highlight CSSL's crucial role in enabling efficient
event-based vision for neuromorphic processing.

</details>


### [2] [Real-Time Intuitive AI Drawing System for Collaboration: Enhancing Human Creativity through Formal and Contextual Intent Integration](https://arxiv.org/abs/2508.19254)
*Jookyung Song,Mookyoung Kang,Nojun Kwak*

Main category: cs.CV

TL;DR: 该论文提出了一种实时生成绘画系统，结合了草图的结构属性和语义等高低层次特征，进行转化生成。


<details>
  <summary>Details</summary>
Motivation: 现有生成系统主要关注语义高层描述，缺乏对几何细节的分析和交互性。

Method: 通过多阶段生成管道联合处理草图的几何特征和语义线索，并结合触屏界面实现分布式推理架构。

Result: 实现了低延迟的双阶段转化，支持多用户协作，促进无艺术技能者的同步画作创作。

Conclusion: 重新定义了人机交互中的共创过程，促进了AI与人的协作性提升。

Abstract: This paper presents a real-time generative drawing system that interprets and
integrates both formal intent - the structural, compositional, and stylistic
attributes of a sketch - and contextual intent - the semantic and thematic
meaning inferred from its visual content - into a unified transformation
process. Unlike conventional text-prompt-based generative systems, which
primarily capture high-level contextual descriptions, our approach
simultaneously analyzes ground-level intuitive geometric features such as line
trajectories, proportions, and spatial arrangement, and high-level semantic
cues extracted via vision-language models. These dual intent signals are
jointly conditioned in a multi-stage generation pipeline that combines
contour-preserving structural control with style- and content-aware image
synthesis. Implemented with a touchscreen-based interface and distributed
inference architecture, the system achieves low-latency, two-stage
transformation while supporting multi-user collaboration on shared canvases.
The resulting platform enables participants, regardless of artistic expertise,
to engage in synchronous, co-authored visual creation, redefining human-AI
interaction as a process of co-creation and mutual enhancement.

</details>


### [3] [TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models](https://arxiv.org/abs/2508.19257)
*Chenghao Liu,Jiachen Zhang,Chengxuan Li,Zhimu Zhou,Shixin Wu,Songfang Huang,Huiling Duan*

Main category: cs.CV

TL;DR: 本文提出了Temporal Token Fusion (TTF)，这是一个无需训练的方法，通过整合历史与当前视觉表示来提升视觉-语言-动作模型的推理质量。这一策略主要通过检测灰度像素差异和语义相关性评估，实现选择性融合，从而解决现有模型对时间序列信息利用不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型在处理视频序列时逐帧操作，未能充分利用视频时间序列的一致性且易受视觉噪声影响。因此，需要一种方法更好地整合时序信息以提升模型性能。

Method: 提出了TTF方法，通过结合灰度像素差异分析与基于注意力的语义相关性评估进行双维度检测，实现选择性时间令牌融合，并采用关键帧锚定策略避免误差累积。

Result: TTF在多个任务中显示出显著性能提升：在LIBERO上平均提高4个百分点（72.4% vs 68.4%）、在SimplerEnv上相对提升4.8%、在真实机器人任务上相对提升8.7%。同样验证了其在OpenVLA与VLA-Cache架构中的模型无关性。

Conclusion: TTF方法表明，通过选择性地重用注意力机制中的Query矩阵可以提升性能，为直接重用KQV矩阵以实现计算加速和任务成功率的提高提供了新的方向。

Abstract: Vision-Language-Action (VLA) models process visual inputs independently at
each timestep, discarding valuable temporal information inherent in robotic
manipulation tasks. This frame-by-frame processing makes models vulnerable to
visual noise while ignoring the substantial coherence between consecutive
frames in manipulation sequences. We propose Temporal Token Fusion (TTF), a
training-free approach that intelligently integrates historical and current
visual representations to enhance VLA inference quality. Our method employs
dual-dimension detection combining efficient grayscale pixel difference
analysis with attention-based semantic relevance assessment, enabling selective
temporal token fusion through hard fusion strategies and keyframe anchoring to
prevent error accumulation. Comprehensive experiments across LIBERO,
SimplerEnv, and real robot tasks demonstrate consistent improvements: 4.0
percentage points average on LIBERO (72.4\% vs 68.4\% baseline),
cross-environment validation on SimplerEnv (4.8\% relative improvement), and
8.7\% relative improvement on real robot tasks. Our approach proves
model-agnostic, working across OpenVLA and VLA-Cache architectures. Notably,
TTF reveals that selective Query matrix reuse in attention mechanisms enhances
rather than compromises performance, suggesting promising directions for direct
KQV matrix reuse strategies that achieve computational acceleration while
improving task success rates.

</details>


### [4] [Seeing Like a Designer Without One: A Study on Unsupervised Slide Quality Assessment via Designer Cue Augmentation](https://arxiv.org/abs/2508.19289)
*Tai Inui,Steven Oh,Magdeline Kuan*

Main category: cs.CV

TL;DR: 提出了一种结合视觉设计指标与CLIP-ViT嵌入的无监督幻灯片质量评估方法，该方法通过孤立森林算法对幻灯片进行异常评分，与人类视觉质量评分的相关性高达0.83。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏高效客观的幻灯片质量评估方法。

Method: 结合七种视觉设计指标（如留白、颜色、边缘密度等）与CLIP-ViT嵌入，并运用孤立森林算法评估幻灯片质量。

Result: 在12k专业演讲幻灯片数据集上训练，并在115张学术幻灯片中验证，实现了与人类视觉评分高达0.83的Pearson相关性，比领先模型高1.79至3.23倍。

Conclusion: 通过低级设计线索与多模态嵌入的结合，可以接近用户对幻灯片质量的主观感受，提供实时、可扩展、客观的反馈。

Abstract: We present an unsupervised slide-quality assessment pipeline that combines
seven expert-inspired visual-design metrics (whitespace, colorfulness, edge
density, brightness contrast, text density, color harmony, layout balance) with
CLIP-ViT embeddings, using Isolation Forest-based anomaly scoring to evaluate
presentation slides. Trained on 12k professional lecture slides and evaluated
on six academic talks (115 slides), our method achieved Pearson correlations up
to 0.83 with human visual-quality ratings-1.79x to 3.23x stronger than scores
from leading vision-language models (ChatGPT o4-mini-high, ChatGPT o3, Claude
Sonnet 4, Gemini 2.5 Pro). We demonstrate convergent validity with visual
ratings, discriminant validity against speaker-delivery scores, and exploratory
alignment with overall impressions. Our results show that augmenting low-level
design cues with multimodal embeddings closely approximates audience
perceptions of slide quality, enabling scalable, objective feedback in real
time.

</details>


### [5] [Efficient Model-Based Purification Against Adversarial Attacks for LiDAR Segmentation](https://arxiv.org/abs/2508.19290)
*Alexandros Gkillas,Ioulia Kapsali,Nikos Piperigkos,Aris S. Lalos*

Main category: cs.CV

TL;DR: 研究提出了一种轻量级的2D范围视图LiDAR分割对抗防御框架，解决现有3D点云模型防御方法的计算复杂问题，实现在实践场景中的强鲁棒性和高效性。


<details>
  <summary>Details</summary>
Motivation: 受现有防御方法的计算开销和大面积应用普遍但仍未深入研究的2D范围视图需求驱动，解决其对抗防御的轻量化需求。

Method: 通过在范围视图领域的直接攻击形式，基于数学优化问题开发一种可解释的净化网络，以低计算负担实现对抗鲁棒性。

Result: 该方法在公开基准测试中表现优越，超越生成式和对抗训练基线。同时在实际自动驾驶场景的试验车辆上展示了准确性和实用性。

Conclusion: 研究提供了一种高效且鲁棒的2D范围视图LiDAR分割对抗防御方案，证明其在实际自动驾驶应用中的潜力和价值。

Abstract: LiDAR-based segmentation is essential for reliable perception in autonomous
vehicles, yet modern segmentation networks are highly susceptible to
adversarial attacks that can compromise safety. Most existing defenses are
designed for networks operating directly on raw 3D point clouds and rely on
large, computationally intensive generative models. However, many
state-of-the-art LiDAR segmentation pipelines operate on more efficient 2D
range view representations. Despite their widespread adoption, dedicated
lightweight adversarial defenses for this domain remain largely unexplored. We
introduce an efficient model-based purification framework tailored for
adversarial defense in 2D range-view LiDAR segmentation. We propose a direct
attack formulation in the range-view domain and develop an explainable
purification network based on a mathematical justified optimization problem,
achieving strong adversarial resilience with minimal computational overhead.
Our method achieves competitive performance on open benchmarks, consistently
outperforming generative and adversarial training baselines. More importantly,
real-world deployment on a demo vehicle demonstrates the framework's ability to
deliver accurate operation in practical autonomous driving scenarios.

</details>


### [6] [Object Detection with Multimodal Large Vision-Language Models: An In-depth Review](https://arxiv.org/abs/2508.19294)
*Ranjan Sapkota,Manoj Karkee*

Main category: cs.CV

TL;DR: 本论文审视了大型视觉语言模型（LVLMs）在目标检测中的最新进展，包括其结构创新、训练方式和将视觉与语言信息融合的策略，并指出未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 研究探讨了LVLMs如何通过结合自然语言处理（NLP）和计算机视觉（CV）技术，重新定义目标检测领域，提供更高级的上下文理解和适应性。

Method: 采用系统性三步论文回顾，分析LVLMs的功能、结构创新和整合视觉与文本信息的方法，并通过可视化说明其在检测与定位任务中的效果。

Result: LVLMs在多样化场景中的定位和分割任务中表现出色，其实时性能、适应性和复杂性在逐渐接近或超越传统方法的水平。

Conclusion: 研究总结了LVLMs对目标检测领域变革性影响，以及在未来机器人应用中的潜力，提出解决当前技术局限的建议和发展路线图。

Abstract: The fusion of language and vision in large vision-language models (LVLMs) has
revolutionized deep learning-based object detection by enhancing adaptability,
contextual reasoning, and generalization beyond traditional architectures. This
in-depth review presents a structured exploration of the state-of-the-art in
LVLMs, systematically organized through a three-step research review process.
First, we discuss the functioning of vision language models (VLMs) for object
detection, describing how these models harness natural language processing
(NLP) and computer vision (CV) techniques to revolutionize object detection and
localization. We then explain the architectural innovations, training
paradigms, and output flexibility of recent LVLMs for object detection,
highlighting how they achieve advanced contextual understanding for object
detection. The review thoroughly examines the approaches used in integration of
visual and textual information, demonstrating the progress made in object
detection using VLMs that facilitate more sophisticated object detection and
localization strategies. This review presents comprehensive visualizations
demonstrating LVLMs' effectiveness in diverse scenarios including localization
and segmentation, and then compares their real-time performance, adaptability,
and complexity to traditional deep learning systems. Based on the review, its
is expected that LVLMs will soon meet or surpass the performance of
conventional methods in object detection. The review also identifies a few
major limitations of the current LVLM modes, proposes solutions to address
those challenges, and presents a clear roadmap for the future advancement in
this field. We conclude, based on this study, that the recent advancement in
LVLMs have made and will continue to make a transformative impact on object
detection and robotic applications in the future.

</details>


### [7] [Large VLM-based Stylized Sports Captioning](https://arxiv.org/abs/2508.19295)
*Sauptik Dhar,Nicholas Buoncristiani,Joe Anakata,Haoyu Zhang,Michelle Munson*

Main category: cs.CV

TL;DR: 本文讨论了当前大规模视觉语言模型在描述体育比赛中的不足，提出了一种两级微调的解决方案来改进生成体育图片说明的精确性和风格化表达。


<details>
  <summary>Details</summary>
Motivation: 目前大规模语言模型较少聚焦于体育领域，尤其是生成体育比赛相关的自然语言描述，其不足之处包括缺乏领域专属的术语和生产级的描述能力。

Method: 文章设计了一种两级微调的大规模视觉语言模型流程，通过模型的训练优化实现对体育图片生成更多精确且具风格化的描述。

Result: 提出的流程在F1得分和BERT得分上分别提升了超过8-10%和2-10%，并且具备小的内存占用和快速的执行速度。

Conclusion: 此流程在超级碗LIX赛事中成功应用，实时生成超过1000张体育图片说明，展现了其在专业体育新闻领域的实际价值。

Abstract: The advent of large (visual) language models (LLM / LVLM) have led to a
deluge of automated human-like systems in several domains including social
media content generation, search and recommendation, healthcare prognosis, AI
assistants for cognitive tasks etc. Although these systems have been
successfully integrated in production; very little focus has been placed on
sports, particularly accurate identification and natural language description
of the game play. Most existing LLM/LVLMs can explain generic sports
activities, but lack sufficient domain-centric sports' jargon to create natural
(human-like) descriptions. This work highlights the limitations of existing
SoTA LLM/LVLMs for generating production-grade sports captions from images in a
desired stylized format, and proposes a two-level fine-tuned LVLM pipeline to
address that. The proposed pipeline yields an improvement > 8-10% in the F1,
and > 2-10% in BERT score compared to alternative approaches. In addition, it
has a small runtime memory footprint and fast execution time. During Super Bowl
LIX the pipeline proved its practical application for live professional sports
journalism; generating highly accurate and stylized captions at the rate of 6
images per 3-5 seconds for over 1000 images during the game play.

</details>


### [8] [DemoBias: An Empirical Study to Trace Demographic Biases in Vision Foundation Models](https://arxiv.org/abs/2508.19298)
*Abu Sufian,Anirudha Ghosh,Debaditya Barman,Marco Leo,Cosimo Distante*

Main category: cs.CV

TL;DR: 本文研究了大型视觉语言模型（LVLMs）在人脸识别任务中表现出的种族、性别和年龄等人口统计学偏差，并提出了一种名为DemoBias的方法进行评估。


<details>
  <summary>Details</summary>
Motivation: 探讨LVLMs在人脸识别任务中是否存在因人口统计学而导致的不公平性，以及如何量化和减少这些偏差。

Method: 研究选用了三种预训练的LVLMs模型（LLaVA、BLIP-2 和 PaliGemma），对其进行了微调并在一个人口统计平衡的数据集上评估。此外，采用诸如BERTScore和公平性差异率等多个指标来评价性能差异。

Result: 实验表明，PaliGemma和LLaVA在人口统计学特定人群（如西班牙裔、白人和南亚裔）中表现出较高的差异性，而BLIP-2模型则相对表现一致，公平性较好。

Conclusion: 研究揭示了LVLMs在人脸识别中存在的显著偏差，并提供了衡量和研究偏差的工具，为未来解决公平性问题提供了依据。

Abstract: Large Vision Language Models (LVLMs) have demonstrated remarkable
capabilities across various downstream tasks, including biometric face
recognition (FR) with description. However, demographic biases remain a
critical concern in FR, as these foundation models often fail to perform
equitably across diverse demographic groups, considering ethnicity/race,
gender, and age. Therefore, through our work DemoBias, we conduct an empirical
evaluation to investigate the extent of demographic biases in LVLMs for
biometric FR with textual token generation tasks. We fine-tuned and evaluated
three widely used pre-trained LVLMs: LLaVA, BLIP-2, and PaliGemma on our own
generated demographic-balanced dataset. We utilize several evaluation metrics,
like group-specific BERTScores and the Fairness Discrepancy Rate, to quantify
and trace the performance disparities. The experimental results deliver
compelling insights into the fairness and reliability of LVLMs across diverse
demographic groups. Our empirical study uncovered demographic biases in LVLMs,
with PaliGemma and LLaVA exhibiting higher disparities for Hispanic/Latino,
Caucasian, and South Asian groups, whereas BLIP-2 demonstrated comparably
consistent. Repository: https://github.com/Sufianlab/DemoBias.

</details>


### [9] [Geo2Vec: Shape- and Distance-Aware Neural Representation of Geospatial Entities](https://arxiv.org/abs/2508.19305)
*Chen Chu,Cyrus Shahabi*

Main category: cs.CV

TL;DR: Geo2Vec 是一种面向 GeoAI 的新方法，直接在原始空间中操作，通过采样点及编码签名距离（SDF）生成统一且几何感知的空间表示工具。它解决了现有方法计算成本高、不精确采样的缺点，同时显著提升表现效率。


<details>
  <summary>Details</summary>
Motivation: 在城市数据分析等领域，现有空间表示学习方法要么针对单一地理实体，要么通过分解复杂形态进行傅里叶转换，带来高计算成本; 采样不适应性模糊特征边缘，限制了性能。

Method: 基于 SDF（签名距离场）启发，Geo2Vec 直接操作在原始空间，适应性地采样点并编码内外差距，由神经网络训练近似生成简洁、统一的表示；同时还引入旋转不变位置编码，提高对高频空间变化的感知能力。

Result: Geo2Vec 在形状与位置表示、拓扑和距离关系捕获方面超越现有方法；验证其在实际 GeoAI 应用中的高效表现。

Conclusion: Geo2Vec 优化了空间表示方法，提出了一种更高效、精确和适应性的解决方案，为 GeoAI 应用的进一步开发提供了支持。

Abstract: Spatial representation learning is essential for GeoAI applications such as
urban analytics, enabling the encoding of shapes, locations, and spatial
relationships (topological and distance-based) of geo-entities like points,
polylines, and polygons. Existing methods either target a single geo-entity
type or, like Poly2Vec, decompose entities into simpler components to enable
Fourier transformation, introducing high computational cost. Moreover, since
the transformed space lacks geometric alignment, these methods rely on uniform,
non-adaptive sampling, which blurs fine-grained features like edges and
boundaries. To address these limitations, we introduce Geo2Vec, a novel method
inspired by signed distance fields (SDF) that operates directly in the original
space. Geo2Vec adaptively samples points and encodes their signed distances
(positive outside, negative inside), capturing geometry without decomposition.
A neural network trained to approximate the SDF produces compact,
geometry-aware, and unified representations for all geo-entity types.
Additionally, we propose a rotation-invariant positional encoding to model
high-frequency spatial variations and construct a structured and robust
embedding space for downstream GeoAI models. Empirical results show that
Geo2Vec consistently outperforms existing methods in representing shape and
location, capturing topological and distance relationships, and achieving
greater efficiency in real-world GeoAI applications. Code and Data can be found
at: https://github.com/chuchen2017/GeoNeuralRepresentation.

</details>


### [10] [Advancements in Crop Analysis through Deep Learning and Explainable AI](https://arxiv.org/abs/2508.19307)
*Hamza Khan*

Main category: cs.CV

TL;DR: 本文提出利用CNN对五种大米品种进行分类，并结合XAI技术开发了大米叶病的诊断方法，达到了高分类准确度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前大米质量控制和病害诊断存在人工检测效率低、误差大等问题，亟需自动化解决方案。

Method: 研究使用CNN模型分类大米品种，并结合VGG16、ResNet50等深度学习模型，通过SHAP和LIME等XAI技术解释模型决策。

Result: 模型对大米品种分类表现出高准确率，对大米叶病如褐斑、白叶枯病等诊断性能可靠，且具备良好解释性和透明性。

Conclusion: 深度学习结合解释性AI方法在农业领域的应用展现出巨大潜力，有助于实现自动化的大米质量检测和病害诊断，推进农业经济发展。

Abstract: Rice is a staple food of global importance in terms of trade, nutrition, and
economic growth. Among Asian nations such as China, India, Pakistan, Thailand,
Vietnam and Indonesia are leading producers of both long and short grain
varieties, including basmati, jasmine, arborio, ipsala, and kainat saila. To
ensure consumer satisfaction and strengthen national reputations, monitoring
rice crops and grain quality is essential. Manual inspection, however, is
labour intensive, time consuming and error prone, highlighting the need for
automated solutions for quality control and yield improvement. This study
proposes an automated approach to classify five rice grain varieties using
Convolutional Neural Networks (CNN). A publicly available dataset of 75000
images was used for training and testing. Model evaluation employed accuracy,
recall, precision, F1-score, ROC curves, and confusion matrices. Results
demonstrated high classification accuracy with minimal misclassifications,
confirming the model effectiveness in distinguishing rice varieties. In
addition, an accurate diagnostic method for rice leaf diseases such as Brown
Spot, Blast, Bacterial Blight, and Tungro was developed. The framework combined
explainable artificial intelligence (XAI) with deep learning models including
CNN, VGG16, ResNet50, and MobileNetV2. Explainability techniques such as SHAP
(SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic
Explanations) revealed how specific grain and leaf features influenced
predictions, enhancing model transparency and reliability. The findings
demonstrate the strong potential of deep learning in agricultural applications,
paving the way for robust, interpretable systems that can support automated
crop quality inspection and disease diagnosis, ultimately benefiting farmers,
consumers, and the agricultural economy.

</details>


### [11] [Sistema de Reconocimiento Facial Federado en Conjuntos Abiertos basado en OpenMax](https://arxiv.org/abs/2508.19312)
*Ander Galván,Marivi Higuero,Jorge Sasiain,Eduardo Jacob*

Main category: cs.CV

TL;DR: 本文提出了一种针对开放集场景的基于联邦学习的面部识别系统，利用OpenMax算法提升隐私保护与准确性。实验结果表明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 面部识别虽然在某些场景中精准，但在处理隐私管理和未知身份检测方面仍存挑战。

Method: 设计并实现一个在联邦学习环境下工作的面部识别系统，通过OpenMax算法结合平均激活向量和局部距离分析来区分已知与未知身份。

Result: 实验验证了该方法在提升隐私保护及增强分布式环境下的面部识别效率上的有效性。

Conclusion: 这种基于联合学习和OpenMax的解决方案能够可靠地支持开放集场景的隐私保护型面部识别。

Abstract: Facial recognition powered by Artificial Intelligence has achieved high
accuracy in specific scenarios and applications. Nevertheless, it faces
significant challenges regarding privacy and identity management, particularly
when unknown individuals appear in the operational context. This paper presents
the design, implementation, and evaluation of a facial recognition system
within a federated learning framework tailored to open-set scenarios. The
proposed approach integrates the OpenMax algorithm into federated learning,
leveraging the exchange of mean activation vectors and local distance measures
to reliably distinguish between known and unknown subjects. Experimental
results validate the effectiveness of the proposed solution, demonstrating its
potential for enhancing privacy-aware and robust facial recognition in
distributed environments.
  --
  El reconocimiento facial impulsado por Inteligencia Artificial ha demostrado
una alta precisi\'on en algunos escenarios y aplicaciones. Sin embargo,
presenta desaf\'ios relacionados con la privacidad y la identificaci\'on de
personas, especialmente considerando que pueden aparecer sujetos desconocidos
para el sistema que lo implementa. En este trabajo, se propone el dise\~no,
implementaci\'on y evaluaci\'on de un sistema de reconocimiento facial en un
escenario de aprendizaje federado, orientado a conjuntos abiertos.
Concretamente, se dise\~na una soluci\'on basada en el algoritmo OpenMax para
escenarios de aprendizaje federado. La propuesta emplea el intercambio de los
vectores de activaci\'on promedio y distancias locales para identificar de
manera eficaz tanto personas conocidas como desconocidas. Los experimentos
realizados demuestran la implementaci\'on efectiva de la soluci\'on propuesta.

</details>


### [12] [Automated classification of natural habitats using ground-level imagery](https://arxiv.org/abs/2508.19314)
*Mahdis Tourian,Sareh Rowlands,Remy Vandaele,Max Fancourt,Rebecca Mein,Hywel T. P. Williams*

Main category: cs.CV

TL;DR: 本文通过深度学习方法仅依靠地面图像对栖息地进行分类，模型涵盖18个类别，整体表现良好，部分类别表现尤为突出。


<details>
  <summary>Details</summary>
Motivation: 填补以往基于卫星图像的栖息地分类在精度验证和大规模分类上的不足，特别是支持结合公民科学数据实现普适分类的需求。

Method: 采用DeepLabV3-ResNet101深度学习模型，对地面栖息地图像进行重新采样、归一化、增强后训练分类，模型通过五折交叉验证评估表现。

Result: 模型在18种栖息地分类上总体表现优异，平均F1分数为0.61，其中较明确类别如裸露土壤（BSSP）和裸沙（BS）分类表现突出（F1>0.90），而混合类或不明确类别成绩较低。

Conclusion: 本方法通过基于地面图像的深度学习分类模型为生态监测提供新途径，表现出广泛实用性，并伴有支持实践者使用的网络应用程序。

Abstract: Accurate classification of terrestrial habitats is critical for biodiversity
conservation, ecological monitoring, and land-use planning. Several habitat
classification schemes are in use, typically based on analysis of satellite
imagery with validation by field ecologists. Here we present a methodology for
classification of habitats based solely on ground-level imagery (photographs),
offering improved validation and the ability to classify habitats at scale (for
example using citizen-science imagery). In collaboration with Natural England,
a public sector organisation responsible for nature conservation in England,
this study develops a classification system that applies deep learning to
ground-level habitat photographs, categorising each image into one of 18
classes defined by the 'Living England' framework. Images were pre-processed
using resizing, normalisation, and augmentation; re-sampling was used to
balance classes in the training data and enhance model robustness. We developed
and fine-tuned a DeepLabV3-ResNet101 classifier to assign a habitat class label
to each photograph. Using five-fold cross-validation, the model demonstrated
strong overall performance across 18 habitat classes, with accuracy and
F1-scores varying between classes. Across all folds, the model achieved a mean
F1-score of 0.61, with visually distinct habitats such as Bare Soil, Silt and
Peat (BSSP) and Bare Sand (BS) reaching values above 0.90, and mixed or
ambiguous classes scoring lower. These findings demonstrate the potential of
this approach for ecological monitoring. Ground-level imagery is readily
obtained, and accurate computational methods for habitat classification based
on such data have many potential applications. To support use by practitioners,
we also provide a simple web application that classifies uploaded images using
our model.

</details>


### [13] [MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation](https://arxiv.org/abs/2508.19320)
*Ming Chen,Liyuan Cui,Wenyuan Zhang,Haoxian Zhang,Yan Zhou,Xiaohan Li,Xiaoqiang Liu,Pengfei Wan*

Main category: cs.CV

TL;DR: 提出一种交互式多模态控制和低延迟视频生成框架，结合大规模对话数据和深度压缩自编码器以实现高效且可控的数字人视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在实时、多样信号交互的数字人视频生成中存在高延迟、计算成本高以及可控性有限的问题。

Method: 引入一种自回归视频生成框架，并结合标准大型语言模型进行最小化修改，接受包括音频、姿势和文本等多模态条件编码，同时设计深度压缩自编码器，提供高效处理能力。

Result: 实验展示了在双向对话、多语言人类合成和交互式世界模型中的低延迟、高效率和多模态精细控制优势。

Conclusion: 该框架是高效、可控且支持实时多模态交互的数字人视频生成的有效解决方案。

Abstract: Recently, interactive digital human video generation has attracted widespread
attention and achieved remarkable progress. However, building such a practical
system that can interact with diverse input signals in real time remains
challenging to existing methods, which often struggle with high latency, heavy
computational cost, and limited controllability. In this work, we introduce an
autoregressive video generation framework that enables interactive multimodal
control and low-latency extrapolation in a streaming manner. With minimal
modifications to a standard large language model (LLM), our framework accepts
multimodal condition encodings including audio, pose, and text, and outputs
spatially and semantically coherent representations to guide the denoising
process of a diffusion head. To support this, we construct a large-scale
dialogue dataset of approximately 20,000 hours from multiple sources, providing
rich conversational scenarios for training. We further introduce a deep
compression autoencoder with up to 64$\times$ reduction ratio, which
effectively alleviates the long-horizon inference burden of the autoregressive
model. Extensive experiments on duplex conversation, multilingual human
synthesis, and interactive world model highlight the advantages of our approach
in low latency, high efficiency, and fine-grained multimodal controllability.

</details>


### [14] [Deep Data Hiding for ICAO-Compliant Face Images: A Survey](https://arxiv.org/abs/2508.19324)
*Jefferson David Rodriguez Chivata,Davide Ghiani,Simone Maurizio La Cava,Marco Micheletto,Giulia Orrù,Federico Lama,Gian Luca Marcialis*

Main category: cs.CV

TL;DR: 本论文探讨在国际民航组织（ICAO）标准照片中嵌入数字水印和隐写术，以实现防篡改，并对现有技术进行了全面分析。


<details>
  <summary>Details</summary>
Motivation: ICAO标准面部图像在身份验证应用中具有普遍性，但其全球化标准使其易受篡改及欺诈行为攻击（如深度伪造）。传统防护措施如攻击检测限于实时捕捉，后续无法持续保护。

Method: 研究数字水印与隐写术，将篡改提示嵌入图像中，不影响ICAO合规性，并全面分析现有技术的潜力及限制。

Result: 本研究首次全面汇总并分析了ICAO合规下的最新技术，评估其在不同应用场景中可能的适用性和限制。

Conclusion: 论文提供关于数字水印与隐写术应用于安全身份系统的权衡建议，指导其在现实中部署。

Abstract: ICAO-compliant facial images, initially designed for secure biometric
passports, are increasingly becoming central to identity verification in a wide
range of application contexts, including border control, digital travel
credentials, and financial services. While their standardization enables global
interoperability, it also facilitates practices such as morphing and deepfakes,
which can be exploited for harmful purposes like identity theft and illegal
sharing of identity documents. Traditional countermeasures like Presentation
Attack Detection (PAD) are limited to real-time capture and offer no
post-capture protection. This survey paper investigates digital watermarking
and steganography as complementary solutions that embed tamper-evident signals
directly into the image, enabling persistent verification without compromising
ICAO compliance. We provide the first comprehensive analysis of
state-of-the-art techniques to evaluate the potential and drawbacks of the
underlying approaches concerning the applications involving ICAO-compliant
images and their suitability under standard constraints. We highlight key
trade-offs, offering guidance for secure deployment in real-world identity
systems.

</details>


### [15] [PRISM: A Framework Harnessing Unsupervised Visual Representations and Textual Prompts for Explainable MACE Survival Prediction from Cardiac Cine MRI](https://arxiv.org/abs/2508.19325)
*Haoyang Su,Jin-Yi Xiang,Shaohao Rui,Yifan Gao,Xingyu Chen,Tingxuan Yin,Xiaosong Wang,Lian-Ming Wu*

Main category: cs.CV

TL;DR: 该论文提出PRISM框架，通过整合心脏磁共振成像和电子健康记录进行生存分析，在四个临床队列中优于传统和最新深度学习模型，并揭示了与主要心脏不良事件相关的影像和临床特征。


<details>
  <summary>Details</summary>
Motivation: 现有方法在预测主要心脏不良事件（MACE）时的精准性有限，亟需结合多维数据和先进分析方法改善预测效果。

Method: 提出PRISM框架，自监督整合非对比心脏磁共振影像和结构化电子健康记录，利用运动感知的多视图蒸馏并结合医学提示生成高分辨率风险评估。

Result: PRISM在四个独立临床队列中的内部和外部验证中，超越传统生存预测方法和最新深度学习模型，并发现若干与MACE风险相关的影像和健康记录特征。

Conclusion: PRISM框架显著提升了心脏风险预测能力，并通过影像与临床特征的结合，为心血管疾病的诊断与干预提供了重要依据。

Abstract: Accurate prediction of major adverse cardiac events (MACE) remains a central
challenge in cardiovascular prognosis. We present PRISM (Prompt-guided
Representation Integration for Survival Modeling), a self-supervised framework
that integrates visual representations from non-contrast cardiac cine magnetic
resonance imaging with structured electronic health records (EHRs) for survival
analysis. PRISM extracts temporally synchronized imaging features through
motion-aware multi-view distillation and modulates them using medically
informed textual prompts to enable fine-grained risk prediction. Across four
independent clinical cohorts, PRISM consistently surpasses classical survival
prediction models and state-of-the-art (SOTA) deep learning baselines under
internal and external validation. Further clinical findings demonstrate that
the combined imaging and EHR representations derived from PRISM provide
valuable insights into cardiac risk across diverse cohorts. Three distinct
imaging signatures associated with elevated MACE risk are uncovered, including
lateral wall dyssynchrony, inferior wall hypersensitivity, and anterior
elevated focus during diastole. Prompt-guided attribution further identifies
hypertension, diabetes, and smoking as dominant contributors among clinical and
physiological EHR factors.

</details>


### [16] [EffNetViTLoRA: An Efficient Hybrid Deep Learning Approach for Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.19349)
*Mahdieh Behjat Khatooni,Mohsen Soryani*

Main category: cs.CV

TL;DR: 本文提出EffNetViTLoRA方法，用于阿尔茨海默病(AD)的诊断。该方法将CNN与ViT集成，并结合LoRA适配技术，在整个ADNI MRI数据集上达到92.52%的准确率和92.76%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 由于AD不可逆转，早期诊断对控制病情至关重要。然而，诊断MCI具有挑战性，因为其与其他阶段的差异较为细微。

Method: 本文将CNN与ViT相结合，通过LoRA技术适配预训练的ViT模型，在整个T1加权MRI数据集上进行训练，提高了模型的鲁棒性和适应性。

Result: 模型在AD、MCI和CN三类诊断分类中实现了92.52%的准确率和92.76%的F1分数，显示出高临床可靠性。

Conclusion: EffNetViTLoRA综合了局部与全局特征，充分利用完整数据集并利用LoRA技术进行高效适配，为AD的精准诊断提供了一个更为可靠的方法。

Abstract: Alzheimer's disease (AD) is one of the most prevalent neurodegenerative
disorders worldwide. As it progresses, it leads to the deterioration of
cognitive functions. Since AD is irreversible, early diagnosis is crucial for
managing its progression. Mild Cognitive Impairment (MCI) represents an
intermediate stage between Cognitively Normal (CN) individuals and those with
AD, and is considered a transitional phase from normal cognition to Alzheimer's
disease. Diagnosing MCI is particularly challenging due to the subtle
differences between adjacent diagnostic categories. In this study, we propose
EffNetViTLoRA, a generalized end-to-end model for AD diagnosis using the whole
Alzheimer's Disease Neuroimaging Initiative (ADNI) Magnetic Resonance Imaging
(MRI) dataset. Our model integrates a Convolutional Neural Network (CNN) with a
Vision Transformer (ViT) to capture both local and global features from MRI
images. Unlike previous studies that rely on limited subsets of data, our
approach is trained on the full T1-weighted MRI dataset from ADNI, resulting in
a more robust and unbiased model. This comprehensive methodology enhances the
model's clinical reliability. Furthermore, fine-tuning large pretrained models
often yields suboptimal results when source and target dataset domains differ.
To address this, we incorporate Low-Rank Adaptation (LoRA) to effectively adapt
the pretrained ViT model to our target domain. This method enables efficient
knowledge transfer and reduces the risk of overfitting. Our model achieves a
classification accuracy of 92.52% and an F1-score of 92.76% across three
diagnostic categories: AD, MCI, and CN for full ADNI dataset.

</details>


### [17] [Concurrent validity of computer-vision artificial intelligence player tracking software using broadcast footage](https://arxiv.org/abs/2508.19477)
*Zachary L. Crang,Rich D. Johnston,Katie L. Mills,Johsan Billingham,Sam Robertson,Michael H. Cole,Jonathon Weakley,Adam Hewitt and,Grant M. Duthie*

Main category: cs.CV

TL;DR: 研究评估了商业化的计算机视觉和人工智能（AI）播放器跟踪软件在实际场景中的精确度，并分析了摄像头画面和分辨率对结果的影响。


<details>
  <summary>Details</summary>
Motivation: 探索商业化计算机视觉和AI跟踪技术在足球比赛中应用的可行性和准确性。

Method: 利用2022年卡塔尔世界杯比赛数据，与高精度多摄像头跟踪系统（TRACAB Gen 5）进行对比分析，计算根均方误差（RMSE）和均值偏差。

Result: 位置的RMSE在1.68到16.39米之间，速度的RMSE在0.34到2.38 m/s之间，不同提供商的总比赛距离均值偏差范围为-21.8%到24.3%。

Conclusion: 计算机视觉和AI追踪技术在适当条件下具备较好的追踪精度，并建议使用战术视角提供最大化的球员检测，720p和1080p分辨率均适合实现良好的性能。

Abstract: This study aimed to: (1) understand whether commercially available
computer-vision and artificial intelligence (AI) player tracking software can
accurately measure player position, speed and distance using broadcast footage
and (2) determine the impact of camera feed and resolution on accuracy. Data
were obtained from one match at the 2022 Qatar Federation Internationale de
Football Association (FIFA) World Cup. Tactical, programme and camera 1 feeds
were used. Three commercial tracking providers that use computer-vision and AI
participated. Providers analysed instantaneous position (x, y coordinates) and
speed (m\,s^{-1}) of each player. Their data were compared with a
high-definition multi-camera tracking system (TRACAB Gen 5). Root mean square
error (RMSE) and mean bias were calculated. Position RMSE ranged from 1.68 to
16.39 m, while speed RMSE ranged from 0.34 to 2.38 m\,s^{-1}. Total match
distance mean bias ranged from -1745 m (-21.8%) to 1945 m (24.3%) across
providers. Computer-vision and AI player tracking software offer the ability to
track players with fair precision when players are detected by the software.
Providers should use a tactical feed when tracking position and speed, which
will maximise player detection, improving accuracy. Both 720p and 1080p
resolutions are suitable, assuming appropriate computer-vision and AI models
are implemented.

</details>


### [18] [JVLGS: Joint Vision-Language Gas Leak Segmentation](https://arxiv.org/abs/2508.19485)
*Xinlong Zhao,Qixiang Pang,Shan Du*

Main category: cs.CV

TL;DR: 本文介绍了一种名为JVLGS的框架，通过结合视觉和文本模态的优势提升气体泄漏检测与分割的效果。


<details>
  <summary>Details</summary>
Motivation: 气体泄漏对人类健康和大气污染有重大威胁，但当前缺乏有效检测方法。传统基于视觉的技术因气体云模糊和非刚性特性而效果有限。

Method: 提出了JVLGS框架，将视觉和文本模态结合起来，并添加后处理步骤以减少噪声引起的误报。

Result: 在多样场景的实验中，JVLGS明显优于当前气体泄漏分割方法，无论在监督还是少样本学习中均表现优异。

Conclusion: JVLGS在气体泄漏检测准确性上具有显著优势，且适用于不同场景和学习设定。提供了代码以供进一步研究。

Abstract: Gas leaks pose serious threats to human health and contribute significantly
to atmospheric pollution, drawing increasing public concern. However, the lack
of effective detection methods hampers timely and accurate identification of
gas leaks. While some vision-based techniques leverage infrared videos for leak
detection, the blurry and non-rigid nature of gas clouds often limits their
effectiveness. To address these challenges, we propose a novel framework called
Joint Vision-Language Gas leak Segmentation (JVLGS), which integrates the
complementary strengths of visual and textual modalities to enhance gas leak
representation and segmentation. Recognizing that gas leaks are sporadic and
many video frames may contain no leak at all, our method incorporates a
post-processing step to reduce false positives caused by noise and non-target
objects, an issue that affects many existing approaches. Extensive experiments
conducted across diverse scenarios show that JVLGS significantly outperforms
state-of-the-art gas leak segmentation methods. We evaluate our model under
both supervised and few-shot learning settings, and it consistently achieves
strong performance in both, whereas competing methods tend to perform well in
only one setting or poorly in both. Code available at:
https://github.com/GeekEagle/JVLGS

</details>


### [19] [UNIFORM: Unifying Knowledge from Large-scale and Diverse Pre-trained Models](https://arxiv.org/abs/2508.19498)
*Yimu Wang,Weiming Zhuang,Chen Chen,Jiabo Huang,Jingtao Li,Lingjuan Lyu*

Main category: cs.CV

TL;DR: 本文提出了一个名为UNIFORM的框架，用于从多样的预训练模型中整合知识到一个学生模型中，并验证了其优越性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在知识整合过程中依赖于训练数据分布和网络架构的强假设，无法充分利用多样化的预训练模型的知识。

Method: 设计了一种投票机制，通过logit层级捕捉目标预测共识以及通过特征层级利用视觉表征，从多样化预训练模型中整合知识，无需依赖强假设。

Result: 实验表明，UNIFORM相较于现有知识传输基线在无监督目标识别中表现更优，并且在支持超百个教师模型的可扩展性方面表现优秀。

Conclusion: UNIFORM打破了现有方法的局限性，通过创新设计有效地整合了多样化预训练模型的知识，为知识传输领域提供了新的思路和实践。

Abstract: In the era of deep learning, the increasing number of pre-trained models
available online presents a wealth of knowledge. These models, developed with
diverse architectures and trained on varied datasets for different tasks,
provide unique interpretations of the real world. Their collective consensus is
likely universal and generalizable to unseen data. However, effectively
harnessing this collective knowledge poses a fundamental challenge due to the
heterogeneity of pre-trained models. Existing knowledge integration solutions
typically rely on strong assumptions about training data distributions and
network architectures, limiting them to learning only from specific types of
models and resulting in data and/or inductive biases. In this work, we
introduce a novel framework, namely UNIFORM, for knowledge transfer from a
diverse set of off-the-shelf models into one student model without such
constraints. Specifically, we propose a dedicated voting mechanism to capture
the consensus of knowledge both at the logit level -- incorporating teacher
models that are capable of predicting target classes of interest -- and at the
feature level, utilizing visual representations learned on arbitrary label
spaces. Extensive experiments demonstrate that UNIFORM effectively enhances
unsupervised object recognition performance compared to strong knowledge
transfer baselines. Notably, it exhibits remarkable scalability by benefiting
from over one hundred teachers, while existing methods saturate at a much
smaller scale.

</details>


### [20] [Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow Generation from Satellite Imagery](https://arxiv.org/abs/2508.19499)
*Xiangxu Wang,Tianhong Zhao,Wei Tu,Bowen Zhang,Guanzhou Chen,Jinzhou Cao*

Main category: cs.CV

TL;DR: 提出了Sat2Flow，一个基于卫星图像生成OD流矩阵的框架，克服了现有方法对辅助特征的依赖和对空间拓扑的敏感性问题。


<details>
  <summary>Details</summary>
Motivation: 现有OD流矩阵生成方法存在对昂贵且覆盖有限的辅助特征依赖，以及对空间拓扑结构敏感的问题，亟需一种高效且鲁棒的解决方案。

Method: Sat2Flow使用基于卫星图像的多核编码器捕捉区域交互，结合感知排列的扩散过程和对比学习方法，在不依赖辅助数据的情况下生成结构一致的OD流矩阵。

Result: 在真实城市数据集上的实验表明，Sat2Flow在数值精度和保持拓扑结构方面优于传统基于物理模型和数据驱动的基线方法，且对区域索引变化具有鲁棒性。

Conclusion: Sat2Flow为数据匮乏的城市环境中OD流生成提供了一种无需依赖特定辅助数据且结构上具有不变性的可扩展解决方案。

Abstract: Origin-Destination (OD) flow matrices are essential for urban mobility
analysis, underpinning applications in traffic forecasting, infrastructure
planning, and policy design. However, existing methods suffer from two critical
limitations: (1) reliance on auxiliary features (e.g., Points of Interest,
socioeconomic statistics) that are costly to collect and have limited spatial
coverage; and (2) sensitivity to spatial topology, where minor index reordering
of urban regions (e.g., census tract relabeling) disrupts structural coherence
in generated flows. To address these challenges, we propose Sat2Flow, a latent
structure-aware diffusion-based framework that generates structurally coherent
OD flows using solely satellite imagery as input. Our approach introduces a
multi-kernel encoder to capture diverse regional interactions and employs a
permutation-aware diffusion process that aligns latent representations across
different regional orderings. Through a joint contrastive training objective
that bridges satellite-derived features with OD patterns, combined with
equivariant diffusion training that enforces structural consistency, Sat2Flow
ensures topological robustness under arbitrary regional reindexing.
Experimental results on real-world urban datasets demonstrate that Sat2Flow
outperforms both physics-based and data-driven baselines in numerical accuracy
while preserving empirical distributions and spatial structures under index
permutations. Sat2Flow offers a globally scalable solution for OD flow
generation in data-scarce urban environments, eliminating region-specific
auxiliary data dependencies while maintaining structural invariance for robust
mobility modeling.

</details>


### [21] [Weed Detection in Challenging Field Conditions: A Semi-Supervised Framework for Overcoming Shadow Bias and Data Scarcity](https://arxiv.org/abs/2508.19511)
*Alzayat Saleh,Shunsuke Hatano,Mostafa Rahimi Azghadi*

Main category: cs.CV

TL;DR: 本文提出了一种诊断驱动的半监督框架，用于解决深度学习模型在实际农田中的环境条件挑战和高数据标注成本的问题，提升了模型对家庭甘蔗地中豚草检测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在农业应用中因环境条件复杂和数据标注成本高导致的性能下降问题。

Method: 提出了一种半监督学习方法，通过整合约975张有标注图像和10,000张无标注图像，同时结合伪标注技术来提升模型的鲁棒性，并通过诊断工具识别和缓解模型中的“阴影偏差”。

Result: 所提方法显著提高了模型对豚草检测的性能，将F1分数提高到0.90，mAP50超过0.82，并通过伪标注技术有效提升模型的召回率。

Conclusion: 方法验证了在低数据量条件下使用半监督框架结合诊断工具能够显著增强精密农业领域中计算机视觉系统的鲁棒性。

Abstract: The automated management of invasive weeds is critical for sustainable
agriculture, yet the performance of deep learning models in real-world fields
is often compromised by two factors: challenging environmental conditions and
the high cost of data annotation. This study tackles both issues through a
diagnostic-driven, semi-supervised framework. Using a unique dataset of
approximately 975 labeled and 10,000 unlabeled images of Guinea Grass in
sugarcane, we first establish strong supervised baselines for classification
(ResNet) and detection (YOLO, RF-DETR), achieving F1 scores up to 0.90 and
mAP50 scores exceeding 0.82. Crucially, this foundational analysis, aided by
interpretability tools, uncovered a pervasive "shadow bias," where models
learned to misidentify shadows as vegetation. This diagnostic insight motivated
our primary contribution: a semi-supervised pipeline that leverages unlabeled
data to enhance model robustness. By training models on a more diverse set of
visual information through pseudo-labeling, this framework not only helps
mitigate the shadow bias but also provides a tangible boost in recall, a
critical metric for minimizing weed escapes in automated spraying systems. To
validate our methodology, we demonstrate its effectiveness in a low-data regime
on a public crop-weed benchmark. Our work provides a clear and field-tested
framework for developing, diagnosing, and improving robust computer vision
systems for the complex realities of precision agriculture.

</details>


### [22] [MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment](https://arxiv.org/abs/2508.19527)
*Zhiting Gao,Dan Song,Diqiong Jiang,Chao Xue,An-An Liu*

Main category: cs.CV

TL;DR: 本文提出了TAPO框架和MotionFLUX方法以改进虚拟角色的运动生成，解决了文本描述与运动语义对齐，以及生成效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动的运动生成方法在语义对齐和多步推理的效率上存在不足，亟需提升生成质量和实时性。

Method: 设计了TAPO框架用于强化运动语义与文本修饰的对齐，并通过MotionFLUX的确定性流匹配方法实现实时生成。

Result: 实验结果表明，TAPO和MotionFLUX能够在生成速度、语义一致性和运动质量上均优于现有方法。

Conclusion: TAPO与MotionFLUX形成了一个统一系统，不仅效果先进，而且显著提升了生成速度。同时代码和预训练模型将公开。

Abstract: Motion generation is essential for animating virtual characters and embodied
agents. While recent text-driven methods have made significant strides, they
often struggle with achieving precise alignment between linguistic descriptions
and motion semantics, as well as with the inefficiencies of slow, multi-step
inference. To address these issues, we introduce TMR++ Aligned Preference
Optimization (TAPO), an innovative framework that aligns subtle motion
variations with textual modifiers and incorporates iterative adjustments to
reinforce semantic grounding. To further enable real-time synthesis, we propose
MotionFLUX, a high-speed generation framework based on deterministic rectified
flow matching. Unlike traditional diffusion models, which require hundreds of
denoising steps, MotionFLUX constructs optimal transport paths between noise
distributions and motion spaces, facilitating real-time synthesis. The
linearized probability paths reduce the need for multi-step sampling typical of
sequential methods, significantly accelerating inference time without
sacrificing motion quality. Experimental results demonstrate that, together,
TAPO and MotionFLUX form a unified system that outperforms state-of-the-art
approaches in both semantic consistency and motion quality, while also
accelerating generation speed. The code and pretrained models will be released.

</details>


### [23] [CVBench: Evaluating Cross-Video Synergies for Complex Multimodal Understanding and Reasoning](https://arxiv.org/abs/2508.19542)
*Nannan Zhu,Yonghao Dong,Teng Wang,Xueqian Li,Shengjun Deng,Yijia Wang,Zheng Hong,Tiantian Geng,Guo Niu,Hanyan Huang,Xiongfei Yao,Shuaiwei Jiao*

Main category: cs.CV

TL;DR: CVBench是一个评估跨视频关系推理的基准，用于衡量当前多模态大语言模型（MLLMs）的性能，揭示其在多视频任务上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型擅长单视频任务，但在处理多视频任务（如多摄像头监控和跨视频程序学习）方面表现不足，因此需要一个系统的基准评估工具。

Method: 提出CVBench，包含三个层级的推理任务（对象关联、事件关联、复杂推理），涵盖五个领域的视频集。通过零样本和逐步思考提示范式，对10多种先进MLLMs进行了性能评估。

Result: 发现现有模型在因果推理上的准确率（如GPT-4o的60%）远低于人类表现（91%），暴露了模型在跨视频上下文保留和歧义消除方面的不足。

Conclusion: CVBench为诊断和改进多视频推理提供了基础框架，并为下一代多模态语言模型的架构设计提供了启示。

Abstract: While multimodal large language models (MLLMs) exhibit strong performance on
single-video tasks (e.g., video question answering), their ability across
multiple videos remains critically underexplored. However, this capability is
essential for real-world applications, including multi-camera surveillance and
cross-video procedural learning. To bridge this gap, we present CVBench, the
first comprehensive benchmark designed to assess cross-video relational
reasoning rigorously. CVBench comprises 1,000 question-answer pairs spanning
three hierarchical tiers: cross-video object association (identifying shared
entities), cross-video event association (linking temporal or causal event
chains), and cross-video complex reasoning (integrating commonsense and domain
knowledge). Built from five domain-diverse video clusters (e.g., sports, life
records), the benchmark challenges models to synthesise information across
dynamic visual contexts. Extensive evaluation of 10+ leading MLLMs (including
GPT-4o, Gemini-2.0-flash, Qwen2.5-VL) under zero-shot or chain-of-thought
prompting paradigms. Key findings reveal stark performance gaps: even top
models, such as GPT-4o, achieve only 60% accuracy on causal reasoning tasks,
compared to the 91% accuracy of human performance. Crucially, our analysis
reveals fundamental bottlenecks inherent in current MLLM architectures, notably
deficient inter-video context retention and poor disambiguation of overlapping
entities. CVBench establishes a rigorous framework for diagnosing and advancing
multi-video reasoning, offering architectural insights for next-generation
MLLMs.The data and evaluation code are available at
https://github.com/Hokhim2/CVBench.

</details>


### [24] [WEBEYETRACK: Scalable Eye-Tracking for the Browser via On-Device Few-Shot Personalization](https://arxiv.org/abs/2508.19544)
*Eduardo Davalos,Yike Zhang,Namrata Srivastava,Yashvitha Thatigotla,Jorge A. Salas,Sara McFadden,Sun-Joo Cho,Amanda Goodwin,Ashwin TS,Gautam Biswas*

Main category: cs.CV

TL;DR: WebEyeTrack框架在浏览器中整合了轻量级SOTA注视估计模型，解决了传统方法中的准确性和实际应用问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI驱动的注视估计方法虽超越SOTA，但在实际应用中与商业眼动追踪解决方案仍有差距，尤其是由于头部运动导致的问题。

Method: 提出了WebEyeTrack框架，通过模型化的头部姿态估计和设备端少样本学习，实现即便仅用九个样本也能适配新用户。

Result: 在GazeCapture上实现了误差为2.32厘米的SOTA性能，在iPhone 14上实现了2.4毫秒的实时推理速度。

Conclusion: WebEyeTrack展示了在浏览器内实现高性能注视估计的潜力，且提升了实际应用的适应性。

Abstract: With advancements in AI, new gaze estimation methods are exceeding
state-of-the-art (SOTA) benchmarks, but their real-world application reveals a
gap with commercial eye-tracking solutions. Factors like model size, inference
time, and privacy often go unaddressed. Meanwhile, webcam-based eye-tracking
methods lack sufficient accuracy, in particular due to head movement. To tackle
these issues, we introduce We bEyeTrack, a framework that integrates
lightweight SOTA gaze estimation models directly in the browser. It
incorporates model-based head pose estimation and on-device few-shot learning
with as few as nine calibration samples (k < 9). WebEyeTrack adapts to new
users, achieving SOTA performance with an error margin of 2.32 cm on
GazeCapture and real-time inference speeds of 2.4 milliseconds on an iPhone 14.
Our open-source code is available at
https://github.com/RedForestAi/WebEyeTrack.

</details>


### [25] [MonoRelief V2: Leveraging Real Data for High-Fidelity Monocular Relief Recovery](https://arxiv.org/abs/2508.19555)
*Yu-Wei Zhang,Tongju Han,Lipeng Gao,Mingqiang Wei,Hui Liu,Changbao Li,Caiming Zhang*

Main category: cs.CV

TL;DR: MonoRelief V2是一种从单张图像中直接恢复2.5D浮雕的新模型，改进了材料和光照变化下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的模型（如MonoRelief V1）仅依赖合成数据训练，无法有效应用于复杂真实场景，因此需要提高模型的鲁棒性和实用性。

Method: 结合生成约15,000张伪真实图像及相应的深度伪标签，以及通过多视角重建和细节优化构建800个真实样本的小规模数据集，逐步训练模型。

Result: 模型在深度和法线预测上表现出色，具有先进水平，适用于多个下游任务。

Conclusion: MonoRelief V2在复杂场景下表现更强，展现出其在各种真实应用中的潜力。

Abstract: This paper presents MonoRelief V2, an end-to-end model designed for directly
recovering 2.5D reliefs from single images under complex material and
illumination variations. In contrast to its predecessor, MonoRelief V1 [1],
which was solely trained on synthetic data, MonoRelief V2 incorporates real
data to achieve improved robustness, accuracy and efficiency. To overcome the
challenge of acquiring large-scale real-world dataset, we generate
approximately 15,000 pseudo real images using a text-to-image generative model,
and derive corresponding depth pseudo-labels through fusion of depth and normal
predictions. Furthermore, we construct a small-scale real-world dataset (800
samples) via multi-view reconstruction and detail refinement. MonoRelief V2 is
then progressively trained on the pseudo-real and real-world datasets.
Comprehensive experiments demonstrate its state-of-the-art performance both in
depth and normal predictions, highlighting its strong potential for a range of
downstream applications. Code is at: https://github.com/glp1001/MonoreliefV2.

</details>


### [26] [FlowDet: Overcoming Perspective and Scale Challenges in Real-Time End-to-End Traffic Detection](https://arxiv.org/abs/2508.19565)
*Yuhang Zhao,Zixing Wang*

Main category: cs.CV

TL;DR: FlowDet改进了DETR架构，通过引入几何变形单元（GDU）和尺度感知注意模块（SAA），在高效性和准确性上取得了突破，为交叉路口交通监控等复杂场景提供了新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端目标检测器在实时性和高效性上存在瓶颈，特别是针对复杂场景如交叉路口流量监测，计算成本过高成为主要挑战。

Method: 提出FlowDet，结合几何变形单元（GDU）与尺度感知注意模块（SAA），优化DETR架构中的编码器部分，以实现对繁忙交通场景的几何建模和多尺度表示能力。

Result: 在新数据集Intersection-Flow-5k上，FlowDet相较于RT-DETR基线，测试平均精度AP提高了1.5%，测试AP50提高了1.6%，同时推理速度提高16.2%，GFLOPs减少63.2%。

Conclusion: FlowDet在实时高效检测方面开辟了新方向，尤其在高密度和遮挡困难的现实场景中表现出卓越性能，并通过开放Intersection-Flow-5k数据集为该领域提供支持。

Abstract: End-to-end object detectors offer a promising NMS-free paradigm for real-time
applications, yet their high computational cost remains a significant barrier,
particularly for complex scenarios like intersection traffic monitoring. To
address this challenge, we propose FlowDet, a high-speed detector featuring a
decoupled encoder optimization strategy applied to the DETR architecture.
Specifically, FlowDet employs a novel Geometric Deformable Unit (GDU) for
traffic-aware geometric modeling and a Scale-Aware Attention (SAA) module to
maintain high representational power across extreme scale variations. To
rigorously evaluate the model's performance in environments with severe
occlusion and high object density, we collected the Intersection-Flow-5k
dataset, a new challenging scene for this task. Evaluated on
Intersection-Flow-5k, FlowDet establishes a new state-of-the-art. Compared to
the strong RT-DETR baseline, it improves AP(test) by 1.5% and AP50(test) by
1.6%, while simultaneously reducing GFLOPs by 63.2% and increasing inference
speed by 16.2%. Our work demonstrates a new path towards building highly
efficient and accurate detectors for demanding, real-world perception systems.
The Intersection-Flow-5k dataset is available at
https://github.com/AstronZh/Intersection-Flow-5K.

</details>


### [27] [DNP-Guided Contrastive Reconstruction with a Reverse Distillation Transformer for Medical Anomaly Detection](https://arxiv.org/abs/2508.19573)
*Luhu Li,Bowen Lin,Mukhtiar Khan,Shujun Fu*

Main category: cs.CV

TL;DR: 该论文提出了一种融合可训练编码器与原型引导的重建方法，并引入新颖的“多样性对齐损失”来改善医学图像异常检测。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像异常检测方法受限于有限注释和与自然图像的域差异，且传统方法依赖冻结的预训练编码器和存在原型崩塌问题。

Method: 提出了一种结合可训练编码器与原型引导重建的框架，并设计了轻量级原型提取器和多样性对齐损失，避免原型崩塌并提升重建精度。

Result: 通过多个医学图像基准的实验证明，提出的方法显著改进了表示质量和异常定位效果，优于现有方法。

Conclusion: 该方法在增强数据适应性、异常定位及解释性方面表现优越，是医学图像异常检测领域的一项进步。

Abstract: Anomaly detection in medical images is challenging due to limited annotations
and a domain gap compared to natural images. Existing reconstruction methods
often rely on frozen pre-trained encoders, which limits adaptation to
domain-specific features and reduces localization accuracy. Prototype-based
learning offers interpretability and clustering benefits but suffers from
prototype collapse, where few prototypes dominate training, harming diversity
and generalization. To address this, we propose a unified framework combining a
trainable encoder with prototype-guided reconstruction and a novel
Diversity-Aware Alignment Loss. The trainable encoder, enhanced by a momentum
branch, enables stable domain-adaptive feature learning. A lightweight
Prototype Extractor mines informative normal prototypes to guide the decoder
via attention for precise reconstruction. Our loss enforces balanced prototype
use through diversity constraints and per-prototype normalization, effectively
preventing collapse. Experiments on multiple medical imaging benchmarks show
significant improvements in representation quality and anomaly localization,
outperforming prior methods. Visualizations and prototype assignment analyses
further validate the effectiveness of our anti-collapse mechanism and enhanced
interpretability.

</details>


### [28] [Multimodal Prototype Alignment for Semi-supervised Pathology Image Segmentation](https://arxiv.org/abs/2508.19574)
*Mingxi Fu,Fanglei Fu,Xitong Ling,Huaitian Yuan,Tian Guan,Yonghong He,Lianghui Zhu*

Main category: cs.CV

TL;DR: 本文提出MPAMatch框架，通过多模态原型引导的监督范式进行病理图像分割，显著提升了语义边界建模能力，并在多项公开数据集上取得了优越的表现。


<details>
  <summary>Details</summary>
Motivation: 病理图像分割挑战较多，包括语义边界模糊、像素级标注代价高；现有基于一致性正则化的半监督方法难以捕获高层语义先验，特别在结构复杂的病理图像中。

Method: 提出MPAMatch框架，采用图像原型与像素标签、文本原型与像素标签间的双重对比学习。同时，将基础TransUNet结构中的ViT替换为病理预训练模型Uni，改善病理相关特征的提取。

Result: MPAMatch在GLAS、EBHI-SEG-GLAND、EBHI-SEG-CANCER及KPI数据集上优于当前最先进方法，验证了其在结构和语义建模中的双重优势。

Conclusion: MPAMatch引入了文本原型监督，首次在病理图像分割中结合多模态的监督策略，提升了无标注样本的辨别能力和语义边界质量，同时验证了其有效性。

Abstract: Pathological image segmentation faces numerous challenges, particularly due
to ambiguous semantic boundaries and the high cost of pixel-level annotations.
Although recent semi-supervised methods based on consistency regularization
(e.g., UniMatch) have made notable progress, they mainly rely on
perturbation-based consistency within the image modality, making it difficult
to capture high-level semantic priors, especially in structurally complex
pathology images. To address these limitations, we propose MPAMatch - a novel
segmentation framework that performs pixel-level contrastive learning under a
multimodal prototype-guided supervision paradigm. The core innovation of
MPAMatch lies in the dual contrastive learning scheme between image prototypes
and pixel labels, and between text prototypes and pixel labels, providing
supervision at both structural and semantic levels. This coarse-to-fine
supervisory strategy not only enhances the discriminative capability on
unlabeled samples but also introduces the text prototype supervision into
segmentation for the first time, significantly improving semantic boundary
modeling. In addition, we reconstruct the classic segmentation architecture
(TransUNet) by replacing its ViT backbone with a pathology-pretrained
foundation model (Uni), enabling more effective extraction of
pathology-relevant features. Extensive experiments on GLAS, EBHI-SEG-GLAND,
EBHI-SEG-CANCER, and KPI show MPAMatch's superiority over state-of-the-art
methods, validating its dual advantages in structural and semantic modeling.

</details>


### [29] [Interact-Custom: Customized Human Object Interaction Image Generation](https://arxiv.org/abs/2508.19575)
*Zhu Xu,Zhaowen Wang,Yuxin Peng,Yang Liu*

Main category: cs.CV

TL;DR: 該研究提出並解決了定制化人與物體交互圖像生成（CHOI）問題，設計了Interact-Custom模型來實現高精度交互和目標外觀保留。


<details>
  <summary>Details</summary>
Motivation: 現有方法多聚焦於目標外觀的保存，忽略細粒度的多對象交互控制。因此，提出在定制化人與物體的交互場景中生成定制圖像的研究，解決現實應用中的挑戰。

Method: 通過構建大規模數據集（包含同一人與物體在不同交互姿態的樣本）並提出兩階段Interact-Custom模型，其中包括生成交互行為的前景遮罩以及在該遮罩影響下進行目標交互對象的圖像生成。

Result: 基於設計的CHOI任務評估指標，該方法在保留目標身份特徵和控制交互語義方面均展示了其效能。

Conclusion: 研究通過設計Interact-Custom模型有效解決了CHOI任務中的挑戰，在實現目標交互圖像生成的同時，提供了高度的內容可控性。

Abstract: Compositional Customized Image Generation aims to customize multiple target
concepts within generation content, which has gained attention for its wild
application.Existing approaches mainly concentrate on the target entity's
appearance preservation, while neglecting the fine-grained interaction control
among target entities.To enable the model of such interaction control
capability, we focus on human object interaction scenario and propose the task
of Customized Human Object Interaction Image Generation(CHOI), which
simultaneously requires identity preservation for target human object and the
interaction semantic control between them.Two primary challenges exist for
CHOI:(1)simultaneous identity preservation and interaction control demands
require the model to decompose the human object into self-contained identity
features and pose-oriented interaction features, while the current HOI image
datasets fail to provide ideal samples for such feature-decomposed
learning.(2)inappropriate spatial configuration between human and object may
lead to the lack of desired interaction semantics.To tackle it, we first
process a large-scale dataset, where each sample encompasses the same pair of
human object involving different interactive poses.Then we design a two-stage
model Interact-Custom, which firstly explicitly models the spatial
configuration by generating a foreground mask depicting the interaction
behavior, then under the guidance of this mask, we generate the target human
object interacting while preserving their identities features.Furthermore, if
the background image and the union location of where the target human object
should appear are provided by users, Interact-Custom also provides the optional
functionality to specify them, offering high content controllability. Extensive
experiments on our tailored metrics for CHOI task demonstrate the effectiveness
of our approach.

</details>


### [30] [High-Speed FHD Full-Color Video Computer-Generated Holography](https://arxiv.org/abs/2508.19579)
*Haomiao Zhang,Miao Cao,Xuan Yu,Hui Luo,Yanling Piao,Mengjie Qin,Zhangyuan Li,Ping Wang,Xin Yuan*

Main category: cs.CV

TL;DR: 该论文提出了一种生成高帧速率、高质量全彩视频计算全息图的新方法，通过频率调制提高色彩显示质量，并引入轻量级网络架构增强计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有学习模型导致的过度平滑问题及帧间空间-时间相关性被忽略导致的低效问题。

Method: 引入频谱引导深度分割复用（SGDDM）和轻量级不对称Mamba-Unet结构（HoloMamba），分别改善全彩显示质量和空间-时间相关性问题。

Result: 在模拟和现实实验中，SGDDM实现了高帧率全彩色显示，HoloMamba在1080p视频生成中显著提升计算速度（每秒超过260帧）。

Conclusion: 提议的方法不仅解决了色彩保真与帧速率之间的矛盾，还显著提高了全息视频生成的质量和效率。

Abstract: Computer-generated holography (CGH) is a promising technology for
next-generation displays. However, generating high-speed, high-quality
holographic video requires both high frame rate display and efficient
computation, but is constrained by two key limitations: ($i$) Learning-based
models often produce over-smoothed phases with narrow angular spectra, causing
severe color crosstalk in high frame rate full-color displays such as
depth-division multiplexing and thus resulting in a trade-off between frame
rate and color fidelity. ($ii$) Existing frame-by-frame optimization methods
typically optimize frames independently, neglecting spatial-temporal
correlations between consecutive frames and leading to computationally
inefficient solutions. To overcome these challenges, in this paper, we propose
a novel high-speed full-color video CGH generation scheme. First, we introduce
Spectrum-Guided Depth Division Multiplexing (SGDDM), which optimizes phase
distributions via frequency modulation, enabling high-fidelity full-color
display at high frame rates. Second, we present HoloMamba, a lightweight
asymmetric Mamba-Unet architecture that explicitly models spatial-temporal
correlations across video sequences to enhance reconstruction quality and
computational efficiency. Extensive simulated and real-world experiments
demonstrate that SGDDM achieves high-fidelity full-color display without
compromise in frame rate, while HoloMamba generates FHD (1080p) full-color
holographic video at over 260 FPS, more than 2.6$\times$ faster than the prior
state-of-the-art Divide-Conquer-and-Merge Strategy.

</details>


### [31] [Guiding Noisy Label Conditional Diffusion Models with Score-based Discriminator Correction](https://arxiv.org/abs/2508.19581)
*Dat Nguyen Cong,Hieu Tran Bao,Hoang Thanh-Tung*

Main category: cs.CV

TL;DR: 本论文介绍了一种用于校正扩散模型生成能力的指导技术：基于分数的判别器校正（SBDC）。


<details>
  <summary>Details</summary>
Motivation: 研究了扩散模型在处理带有人工标注错误的大型数据集时的生成能力和控制能力问题。

Method: 提出了SBDC方法，利用对抗损失进行判别器训练，根据先验噪声检测技术评估样本真实性，限定指导应用于生成的早期阶段以提升性能。

Result: 在不同噪声设置的实验中，方法表现优于之前的最新方法，且计算效率高，对推理时间影响较小。

Conclusion: SBDC是无需重新训练扩散模型的有效校正方法，能够提升其对噪声数据集的生成能力和性能。

Abstract: Diffusion models have gained prominence as state-of-the-art techniques for
synthesizing images and videos, particularly due to their ability to scale
effectively with large datasets. Recent studies have uncovered that these
extensive datasets often contain mistakes from manual labeling processes.
However, the extent to which such errors compromise the generative capabilities
and controllability of diffusion models is not well studied. This paper
introduces Score-based Discriminator Correction (SBDC), a guidance technique
for aligning noisy pre-trained conditional diffusion models. The guidance is
built on discriminator training using adversarial loss, drawing on prior noise
detection techniques to assess the authenticity of each sample. We further show
that limiting the usage of our guidance to the early phase of the generation
process leads to better performance. Our method is computationally efficient,
only marginally increases inference time, and does not require retraining
diffusion models. Experiments on different noise settings demonstrate the
superiority of our method over previous state-of-the-art methods.

</details>


### [32] [Generalizing Monocular 3D Object Detection](https://arxiv.org/abs/2508.19593)
*Abhinav Kumar*

Main category: cs.CV

TL;DR: 单目3D目标检测（Mono3D）是一项通过单张图像估计物体类别、3D位置、尺寸和方向的任务，本研究提出了多种方法增强Mono3D模型的泛化性和适应能力。


<details>
  <summary>Details</summary>
Motivation: 单目3D检测在自动驾驶、增强现实和机器人领域依赖于对3D环境的准确理解，但模型的场景适应性和鲁棒性仍然是挑战。

Method: 提出了数学可微的NMS（GrooMeD-NMS）增强遮挡鲁棒性；采用深度等变（DEVIANT）骨干网络提升数据集间的泛化能力；分析并解决大物体检测中的噪声敏感问题，引入鸟瞰视角分割方法并使用dice损失（SeaBird）；对不同摄像机高度下模型泛化性进行数学分析并优化。

Result: 通过上述方法提升了单目3D检测在多种场景中的适配能力，改善了遮挡、数据集、物体尺寸及摄像机参数的泛化性能。

Conclusion: 研究提出了若干新颖方法提升单目3D检测的场景泛化性和准确性，并为未来相关任务提供了坚实的理论和技术支持。

Abstract: Monocular 3D object detection (Mono3D) is a fundamental computer vision task
that estimates an object's class, 3D position, dimensions, and orientation from
a single image. Its applications, including autonomous driving, augmented
reality, and robotics, critically rely on accurate 3D environmental
understanding. This thesis addresses the challenge of generalizing Mono3D
models to diverse scenarios, including occlusions, datasets, object sizes, and
camera parameters. To enhance occlusion robustness, we propose a mathematically
differentiable NMS (GrooMeD-NMS). To improve generalization to new datasets, we
explore depth equivariant (DEVIANT) backbones. We address the issue of large
object detection, demonstrating that it's not solely a data imbalance or
receptive field problem but also a noise sensitivity issue. To mitigate this,
we introduce a segmentation-based approach in bird's-eye view with dice loss
(SeaBird). Finally, we mathematically analyze the extrapolation of Mono3D
models to unseen camera heights and improve Mono3D generalization in such
out-of-distribution settings.

</details>


### [33] [Quantization Robustness to Input Degradations for Object Detection](https://arxiv.org/abs/2508.19600)
*Toghrul Karimov,Hassan Imani,Allan Kazakov*

Main category: cs.CV

TL;DR: 研究探讨后训练量化(PTQ)对YOLO模型鲁棒性的影响，尤其是在有降级的输入条件下。结果显示改进的降级感知校准方法对多数情况下的鲁棒性改进有限，但特定条件和大模型规模下有潜在好处。


<details>
  <summary>Details</summary>
Motivation: 推动YOLO模型在资源受限设备上的部署，同时评估低位精度对模型应对真实降级输入的鲁棒性影响。

Method: 对不同量化格式(FP32、FP16、Dynamic UINT8、Static INT8)的YOLO模型进行实验，并提出并评估了一种降级感知校准策略，结合干净和降解图像进行INT8校准。

Result: 静态INT8实现了显著速度提升(1.5-3.3倍)以及适度准确率下降(3-7% mAP50-95)；降级感知校准未在大多数模型和降级情况下取得明显的鲁棒性提升，但在某些噪声条件下对大模型规模有效。

Conclusion: PTQ在提升推理性能的同时，也面临加强鲁棒性的挑战。给出了在不受控环境中部署量化检测器的有价值见解。

Abstract: Post-training quantization (PTQ) is crucial for deploying efficient object
detection models, like YOLO, on resource-constrained devices. However, the
impact of reduced precision on model robustness to real-world input
degradations such as noise, blur, and compression artifacts is a significant
concern. This paper presents a comprehensive empirical study evaluating the
robustness of YOLO models (nano to extra-large scales) across multiple
precision formats: FP32, FP16 (TensorRT), Dynamic UINT8 (ONNX), and Static INT8
(TensorRT). We introduce and evaluate a degradation-aware calibration strategy
for Static INT8 PTQ, where the TensorRT calibration process is exposed to a mix
of clean and synthetically degraded images. Models were benchmarked on the COCO
dataset under seven distinct degradation conditions (including various types
and levels of noise, blur, low contrast, and JPEG compression) and a
mixed-degradation scenario. Results indicate that while Static INT8 TensorRT
engines offer substantial speedups (~1.5-3.3x) with a moderate accuracy drop
(~3-7% mAP50-95) on clean data, the proposed degradation-aware calibration did
not yield consistent, broad improvements in robustness over standard clean-data
calibration across most models and degradations. A notable exception was
observed for larger model scales under specific noise conditions, suggesting
model capacity may influence the efficacy of this calibration approach. These
findings highlight the challenges in enhancing PTQ robustness and provide
insights for deploying quantized detectors in uncontrolled environments. All
code and evaluation tables are available at https://github.com/AllanK24/QRID.

</details>


### [34] [IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation](https://arxiv.org/abs/2508.19604)
*Qizhe Fan,Chaoyu Liu,Zhonghua Qiao,Xiaoqin Shen*

Main category: cs.CV

TL;DR: 本文提出了一种增强域泛化语义分割的方法，通过引入逆进化层（IEL）到生成过程及分割网络中，并结合多尺度频率融合（MFF）模块，显著提升了模型在跨域任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 目前的域泛化语义分割方法通常依赖通过扩散模型合成数据来增强源域数据。但这些合成图像往往存在结构或语义缺陷，训练分割模型时容易引发性能下降及错误积累。

Method: 提出了一种名为IELDM的新框架，引入逆进化层（IEL）来突出空间不连续性和语义不一致性，从而过滤掉生成过程中不良模式。同时在分割模型中集成IEL，并采用多尺度频率融合（MFF）模块，提升语义一致性与跨域泛化能力。

Result: 实验表明，本文方法在多个基准数据集上实现了优于现有方法的跨域泛化性能。

Conclusion: 通过引入基于IEL的生成与分割策略，以及MFF模块，本研究有效提升了模型的跨域泛化能力，为域泛化语义分割问题提供了新的解决方案。

Abstract: Domain Generalized Semantic Segmentation (DGSS) focuses on training a model
using labeled data from a source domain, with the goal of achieving robust
generalization to unseen target domains during inference. A common approach to
improve generalization is to augment the source domain with synthetic data
generated by diffusion models (DMs). However, the generated images often
contain structural or semantic defects due to training imperfections. Training
segmentation models with such flawed data can lead to performance degradation
and error accumulation. To address this issue, we propose to integrate inverse
evolution layers (IELs) into the generative process. IELs are designed to
highlight spatial discontinuities and semantic inconsistencies using
Laplacian-based priors, enabling more effective filtering of undesirable
generative patterns. Based on this mechanism, we introduce IELDM, an enhanced
diffusion-based data augmentation framework that can produce higher-quality
images. Furthermore, we observe that the defect-suppression capability of IELs
can also benefit the segmentation network by suppressing artifact propagation.
Based on this insight, we embed IELs into the decoder of the DGSS model and
propose IELFormer to strengthen generalization capability in cross-domain
scenarios. To further strengthen the model's semantic consistency across
scales, IELFormer incorporates a multi-scale frequency fusion (MFF) module,
which performs frequency-domain analysis to achieve structured integration of
multi-resolution features, thereby improving cross-scale coherence. Extensive
experiments on benchmark datasets demonstrate that our approach achieves
superior generalization performance compared to existing methods.

</details>


### [35] [Controllable Skin Synthesis via Lesion-Focused Vector Autoregression Model](https://arxiv.org/abs/2508.19626)
*Jiajun Sun,Zhen Yu,Siyuan Yan,Jason J. Ong,Zongyuan Ge,Lei Zhang*

Main category: cs.CV

TL;DR: 提出了LF-VAR模型，用于基于语言提示生成具有特定病灶特征的高保真皮肤图像，并在七种病灶类型上实现了最佳FID得分0.74。


<details>
  <summary>Details</summary>
Motivation: 现有皮肤图像生成方法的图像质量较低，且难以控制病灶的位置和类型。

Method: 利用多尺度病灶聚焦VQVAE对图像编码，生成离散潜在表征。再通过VAR Transformer进行图像合成，并将病灶测量和类型嵌入条件以提高合成质量。

Result: 在七种病灶类型上，LF-VAR模型的平均FID得分为0.74，较之前最优方法提高6.3%。

Conclusion: LF-VAR模型能生成高保真、具有临床相关性的合成皮肤图像，验证了其在医学图像生成中的有效性。

Abstract: Skin images from real-world clinical practice are often limited, resulting in
a shortage of training data for deep-learning models. While many studies have
explored skin image synthesis, existing methods often generate low-quality
images and lack control over the lesion's location and type. To address these
limitations, we present LF-VAR, a model leveraging quantified lesion
measurement scores and lesion type labels to guide the clinically relevant and
controllable synthesis of skin images. It enables controlled skin synthesis
with specific lesion characteristics based on language prompts. We train a
multiscale lesion-focused Vector Quantised Variational Auto-Encoder (VQVAE) to
encode images into discrete latent representations for structured tokenization.
Then, a Visual AutoRegressive (VAR) Transformer trained on tokenized
representations facilitates image synthesis. Lesion measurement from the lesion
region and types as conditional embeddings are integrated to enhance synthesis
fidelity. Our method achieves the best overall FID score (average 0.74) among
seven lesion types, improving upon the previous state-of-the-art (SOTA) by
6.3%. The study highlights our controllable skin synthesis model's
effectiveness in generating high-fidelity, clinically relevant synthetic skin
images. Our framework code is available at
https://github.com/echosun1996/LF-VAR.

</details>


### [36] [Divide, Weight, and Route: Difficulty-Aware Optimization with Dynamic Expert Fusion for Long-tailed Recognition](https://arxiv.org/abs/2508.19630)
*Xiaolei Wei,Yi Ouyang,Haibo Ye*

Main category: cs.CV

TL;DR: 研究提出了DQRoute框架，通过模块化的困难感知优化和动态专家协作解决长尾视觉识别中的挑战，显著提升稀有和困难类别的性能。


<details>
  <summary>Details</summary>
Motivation: 克服长尾视觉识别中的类别不平衡和跨类别分类难度差异所带来的挑战。

Method: 提出DQRoute框架，结合基于预测不确定性和历史表现进行的困难感知优化，以及基于专家特定的置信度加权预测的动态专家协作。

Result: 在标准长尾基准测试中显著提升了稀有和困难类别的性能。

Conclusion: 将困难建模与去中心化专家路由结合，可以有效提高长尾视觉识别的表现。

Abstract: Long-tailed visual recognition is challenging not only due to class imbalance
but also because of varying classification difficulty across categories. Simply
reweighting classes by frequency often overlooks those that are intrinsically
hard to learn. To address this, we propose \textbf{DQRoute}, a modular
framework that combines difficulty-aware optimization with dynamic expert
collaboration. DQRoute first estimates class-wise difficulty based on
prediction uncertainty and historical performance, and uses this signal to
guide training with adaptive loss weighting. On the architectural side, DQRoute
employs a mixture-of-experts design, where each expert specializes in a
different region of the class distribution. At inference time, expert
predictions are weighted by confidence scores derived from expert-specific OOD
detectors, enabling input-adaptive routing without the need for a centralized
router. All components are trained jointly in an end-to-end manner. Experiments
on standard long-tailed benchmarks demonstrate that DQRoute significantly
improves performance, particularly on rare and difficult classes, highlighting
the benefit of integrating difficulty modeling with decentralized expert
routing.

</details>


### [37] [Beyond BEV: Optimizing Point-Level Tokens for Collaborative Perception](https://arxiv.org/abs/2508.19638)
*Yang Li,Quan Yuan,Guiyang Luo,Xiaoyuan Fu,Rui Pan,Yujia Yang,Congzhang Shao,Yuewen Liu,Jinglin Li*

Main category: cs.CV

TL;DR: CoPLOT是一种新的协作感知框架，引入点级优化标记来增强感知能力，同时优化通信与计算效率。


<details>
  <summary>Details</summary>
Motivation: 多数现有方法通过2D BEV表示特征，但忽略了关键的3D结构信息，影响了目标识别与定位的准确性。

Method: 提出CoPLOT框架，采用点级优化标记，包含语义感知重排序、频率增强状态空间模型和邻居-自我对齐模块。

Result: 在模拟和真实数据集上，CoPLOT超过了当前最先进的模型，同时具有更低的通信和计算开销。

Conclusion: CoPLOT通过保持详细的结构信息和高效的协作感知，显著提高了模型性能。

Abstract: Collaborative perception allows agents to enhance their perceptual
capabilities by exchanging intermediate features. Existing methods typically
organize these intermediate features as 2D bird's-eye-view (BEV)
representations, which discard critical fine-grained 3D structural cues
essential for accurate object recognition and localization. To this end, we
first introduce point-level tokens as intermediate representations for
collaborative perception. However, point-cloud data are inherently unordered,
massive, and position-sensitive, making it challenging to produce compact and
aligned point-level token sequences that preserve detailed structural
information. Therefore, we present CoPLOT, a novel Collaborative perception
framework that utilizes Point-Level Optimized Tokens. It incorporates a
point-native processing pipeline, including token reordering, sequence
modeling, and multi-agent spatial alignment. A semantic-aware token reordering
module generates adaptive 1D reorderings by leveraging scene-level and
token-level semantic information. A frequency-enhanced state space model
captures long-range sequence dependencies across both spatial and spectral
domains, improving the differentiation between foreground tokens and background
clutter. Lastly, a neighbor-to-ego alignment module applies a closed-loop
process, combining global agent-level correction with local token-level
refinement to mitigate localization noise. Extensive experiments on both
simulated and real-world datasets show that CoPLOT outperforms state-of-the-art
models, with even lower communication and computation overhead. Code will be
available at https://github.com/CheeryLeeyy/CoPLOT.

</details>


### [38] [UTAL-GNN: Unsupervised Temporal Action Localization using Graph Neural Networks](https://arxiv.org/abs/2508.19647)
*Bikash Kumar Badatya,Vipul Baghel,Ravi Hegde*

Main category: cs.CV

TL;DR: 论文提出一种轻量级、无监督的骨架动作定位管道，通过时空图神经网络的注意力机制表征，实现了在无标签数据上的高效动作边界检测。


<details>
  <summary>Details</summary>
Motivation: 传统的动作定位方法依赖于强监督和弱监督模式，需要大量标注数据，且计算量大，不适用于实际场景。

Method: 提出了一种基于注意力的时空图卷积网络(ASTGCN)，利用姿势序列去噪任务预训练，并计算动作动力学度量(ADM)以检测动作边界。

Result: 在DSV Diving数据集上mAP达82.66%，定位延时为29.09毫秒，与现有监督方法性能相当，并且具有高效计算优势。

Conclusion: 该方法适用于嵌入式或动态环境中的轻量级实时动作分析系统，且无需重训练即可对新数据集进行稳健泛化。

Abstract: Fine-grained action localization in untrimmed sports videos presents a
significant challenge due to rapid and subtle motion transitions over short
durations. Existing supervised and weakly supervised solutions often rely on
extensive annotated datasets and high-capacity models, making them
computationally intensive and less adaptable to real-world scenarios. In this
work, we introduce a lightweight and unsupervised skeleton-based action
localization pipeline that leverages spatio-temporal graph neural
representations. Our approach pre-trains an Attention-based Spatio-Temporal
Graph Convolutional Network (ASTGCN) on a pose-sequence denoising task with
blockwise partitions, enabling it to learn intrinsic motion dynamics without
any manual labeling. At inference, we define a novel Action Dynamics Metric
(ADM), computed directly from low-dimensional ASTGCN embeddings, which detects
motion boundaries by identifying inflection points in its curvature profile.
Our method achieves a mean Average Precision (mAP) of 82.66% and average
localization latency of 29.09 ms on the DSV Diving dataset, matching
state-of-the-art supervised performance while maintaining computational
efficiency. Furthermore, it generalizes robustly to unseen, in-the-wild diving
footage without retraining, demonstrating its practical applicability for
lightweight, real-time action analysis systems in embedded or dynamic
environments.

</details>


### [39] [IDF: Iterative Dynamic Filtering Networks for Generalizable Image Denoising](https://arxiv.org/abs/2508.19649)
*Dongjin Kim,Jaekyun Ko,Muhammad Kashif Ali,Tae Hyun Kim*

Main category: cs.CV

TL;DR: 本文提出了一种基于动态内核生成的高效图像去噪方法，旨在解决当前深度学习方法在面对未见噪声类型和水平时的泛化性不足问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习方法尽管在图像去噪上表现出色，但其对特定噪声分布的依赖性限制了其推广能力，目前方法需要大量训练数据和高计算资源，存在显著的过拟合问题。

Method: 采用动态生成的内核进行去噪，通过特征提取模块获取鲁棒的噪声不变特征，结合全局统计和局部相关性模块捕捉噪声特性与结构相关性，最后通过内核预测模块生成适应局部结构的像素级内核，并迭代应用以进行去噪。

Result: 仅在单级高斯噪声上训练的小型模型（约0.04M参数量）在多种噪声类型和水平下表现出卓越的效果，证明了迭代动态滤波在实际图像去噪中的潜力。

Conclusion: 方法不仅提高了对未见噪声的鲁棒性，还避免了过拟合，并兼顾了效率与去噪质量，适用于实际场景。

Abstract: Image denoising is a fundamental challenge in computer vision, with
applications in photography and medical imaging. While deep learning-based
methods have shown remarkable success, their reliance on specific noise
distributions limits generalization to unseen noise types and levels. Existing
approaches attempt to address this with extensive training data and high
computational resources but they still suffer from overfitting. To address
these issues, we conduct image denoising by utilizing dynamically generated
kernels via efficient operations. This approach helps prevent overfitting and
improves resilience to unseen noise. Specifically, our method leverages a
Feature Extraction Module for robust noise-invariant features, Global
Statistics and Local Correlation Modules to capture comprehensive noise
characteristics and structural correlations. The Kernel Prediction Module then
employs these cues to produce pixel-wise varying kernels adapted to local
structures, which are then applied iteratively for denoising. This ensures both
efficiency and superior restoration quality. Despite being trained on
single-level Gaussian noise, our compact model (~ 0.04 M) excels across diverse
noise types and levels, demonstrating the promise of iterative dynamic
filtering for practical image denoising.

</details>


### [40] [Video-LevelGauge: Investigating Contextual Positional Bias in Large Video Language Models](https://arxiv.org/abs/2508.19650)
*Hou Xia,Zheren Fu,Fangcan Ling,Jiajun Li,Yi Tu,Zhendong Mao,Yongdong Zhang*

Main category: cs.CV

TL;DR: 提出Video-LevelGauge基准，用于评估大规模视频语言模型（LVLMs）的上下文位置偏置，并对27个模型进行测试，发现显著偏置现象。


<details>
  <summary>Details</summary>
Motivation: 当前评估基准忽略了LVLMs的细微表现，如上下文位置偏置，需要专门工具评估这种性能。

Method: 设计Video-LevelGauge基准，包括手动筛选的视频和高质量测试问题，结合统计和形态识别方法，分析位置偏置，并对27种模型进行全面评估。

Result: 发现许多开源模型存在显著位置偏置，而一些商用模型（如Gemini2.5-Pro）表现相对稳定，分析了上下文长度和变化对模型偏置的影响。

Conclusion: Video-LevelGauge提供了一种系统方法来评估和改进LVLMs偏置问题，为后续模型优化提供见解。

Abstract: Large video language models (LVLMs) have made notable progress in video
understanding, spurring the development of corresponding evaluation benchmarks.
However, existing benchmarks generally assess overall performance across entire
video sequences, overlooking nuanced behaviors such as contextual positional
bias, a critical yet under-explored aspect of LVLM performance. We present
Video-LevelGauge, a dedicated benchmark designed to systematically assess
positional bias in LVLMs. We employ standardized probes and customized
contextual setups, allowing flexible control over context length, probe
position, and contextual types to simulate diverse real-world scenarios. In
addition, we introduce a comprehensive analysis method that combines
statistical measures with morphological pattern recognition to characterize
bias. Our benchmark comprises 438 manually curated videos spanning multiple
types, yielding 1,177 high-quality multiple-choice questions and 120 open-ended
questions, validated for their effectiveness in exposing positional bias. Based
on these, we evaluate 27 state-of-the-art LVLMs, including both commercial and
open-source models. Our findings reveal significant positional biases in many
leading open-source models, typically exhibiting head or neighbor-content
preferences. In contrast, commercial models such as Gemini2.5-Pro show
impressive, consistent performance across entire video sequences. Further
analyses on context length, context variation, and model scale provide
actionable insights for mitigating bias and guiding model enhancement.

</details>


### [41] [Scalable Object Detection in the Car Interior With Vision Foundation Models](https://arxiv.org/abs/2508.19651)
*Bálint Mészáros,Ahmet Firintepe,Sebastian Schmidt,Stephan Günnemann*

Main category: cs.CV

TL;DR: 本文提出了一种名为Object Detection and Localization (ODAL)的框架来解决汽车内场景理解中的对象识别与定位问题，并通过分布式架构在车载设备和云端之间分担计算。


<details>
  <summary>Details</summary>
Motivation: 由于车载系统的计算资源高度受限，无法直接在车辆中运行复杂的基础模型，作者提出了一个新的框架来应对这一限制。

Method: 设计了一个分布式架构，利用视觉基础模型将计算任务分配至车载设备和云，同时引入了一个名为ODALbench的新评测指标，用于评估检测和定位性能。

Result: 微调后的ODAL-LLaVA模型在性能上远超基准，ODAL$_{score}$达到89%（比基准提高71%），同时超越GPT-4o 近20%。此外，微调模型大幅减少了错误定位现象，ODAL$_{SNR}$是GPT-4o的三倍。

Conclusion: 该框架展示了其在限制条件下实现高质量场景理解的巨大潜力，为车载人工智能任务的实现提供了新标准。

Abstract: AI tasks in the car interior like identifying and localizing externally
introduced objects is crucial for response quality of personal assistants.
However, computational resources of on-board systems remain highly constrained,
restricting the deployment of such solutions directly within the vehicle. To
address this limitation, we propose the novel Object Detection and Localization
(ODAL) framework for interior scene understanding. Our approach leverages
vision foundation models through a distributed architecture, splitting
computational tasks between on-board and cloud. This design overcomes the
resource constraints of running foundation models directly in the car. To
benchmark model performance, we introduce ODALbench, a new metric for
comprehensive assessment of detection and localization.Our analysis
demonstrates the framework's potential to establish new standards in this
domain. We compare the state-of-the-art GPT-4o vision foundation model with the
lightweight LLaVA 1.5 7B model and explore how fine-tuning enhances the
lightweight models performance. Remarkably, our fine-tuned ODAL-LLaVA model
achieves an ODAL$_{score}$ of 89%, representing a 71% improvement over its
baseline performance and outperforming GPT-4o by nearly 20%. Furthermore, the
fine-tuned model maintains high detection accuracy while significantly reducing
hallucinations, achieving an ODAL$_{SNR}$ three times higher than GPT-4o.

</details>


### [42] [Self-Rewarding Vision-Language Model via Reasoning Decomposition](https://arxiv.org/abs/2508.19652)
*Zongxia Li,Wenhao Yu,Chengsong Huang,Rui Liu,Zhenwen Liang,Fuxiao Liu,Jingxi Che,Dian Yu,Jordan Boyd-Graber,Haitao Mi,Dong Yu*

Main category: cs.CV

TL;DR: 本文提出了一种称为Vision-SR1的方法，通过自奖励机制增强视觉推理能力，避免依靠外部视觉监督，解决视觉幻觉和语言捷径问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型在视觉幻觉和语言捷径问题上表现不佳，因为其后训练方法通常只关注答案的正确性，忽视了中间的视觉推理过程。

Method: Vision-SR1将视觉-语言模型的推理分解为视觉感知和语言推理两个阶段，通过自监督机制结合强化学习，使模型能在没有外部视觉监督的情况下改进视觉推理。

Result: 实验表明，Vision-SR1在多种视觉-语言任务中改进了视觉推理能力，减少了视觉幻觉现象，并降低了对语言捷径的依赖。

Conclusion: Vision-SR1通过提供平衡的训练信号，既加强了视觉感知，又改进了语言推理，为解决视觉幻觉和语言捷径问题提供了有效的方法。

Abstract: Vision-Language Models (VLMs) often suffer from visual hallucinations, saying
things that are not actually in the image, and language shortcuts, where they
skip the visual part and just rely on text priors. These issues arise because
most post-training methods for VLMs rely on simple verifiable answer matching
and supervise only final outputs, leaving intermediate visual reasoning without
explicit guidance. As a result, VLMs receive sparse visual signals and often
learn to prioritize language-based reasoning over visual perception. To
mitigate this, some existing methods add visual supervision using human
annotations or distilled labels from external large models. However, human
annotations are labor-intensive and costly, and because external signals cannot
adapt to the evolving policy, they cause distributional shifts that can lead to
reward hacking. In this paper, we introduce Vision-SR1, a self-rewarding method
that improves visual reasoning without relying on external visual supervisions
via reinforcement learning. Vision-SR1 decomposes VLM reasoning into two
stages: visual perception and language reasoning. The model is first prompted
to produce self-contained visual perceptions that are sufficient to answer the
question without referring back the input image. To validate this
self-containment, the same VLM model is then re-prompted to perform language
reasoning using only the generated perception as input to compute reward. This
self-reward is combined with supervision on final outputs, providing a balanced
training signal that strengthens both visual perception and language reasoning.
Our experiments demonstrate that Vision-SR1 improves visual reasoning,
mitigates visual hallucinations, and reduces reliance on language shortcuts
across diverse vision-language tasks.

</details>


### [43] [Hardware-aware vs. Hardware-agnostic Energy Estimation for SNN in Space Applications](https://arxiv.org/abs/2508.19654)
*Matthias Höfflin,Jürgen Wassner*

Main category: cs.CV

TL;DR: 本文研究了基于尖峰神经网络（SNNs）的多输出回归问题，针对3D卫星位置估计提出了一种新方法，并与传统人工神经网络（ANNs）在能耗上进行对比分析。


<details>
  <summary>Details</summary>
Motivation: 尖峰神经网络因其对生物智能的模拟被认为具有高效的能源利用特性，但这种声誉在近期研究中受到了挑战。作者希望检验这一领域的假设，特别是在数字化实现条件下。

Method: 提出了一种基于SNN的模型，结合Leaky Integrate-and-Fire (LIF) 神经元膜电位的训练方法，并使用硬件相关和硬件无关的能耗估算方法对其进行评估。

Result: 结果表明，提出的SNN在预测性能（例如均方误差）上与传统卷积神经网络（CNN）相当。然而，能耗优势仅在神经形态硬件和高输入稀疏度条件下得以显现。

Conclusion: 研究强调了数据特性和硬件假设对能耗评估的影响，呼吁制定透明的评估方法和明确的假设披露，以确保神经网络能效的公平比较。

Abstract: Spiking Neural Networks (SNNs), inspired by biological intelligence, have
long been considered inherently energy-efficient, making them attractive for
resource-constrained domains such as space applications. However, recent
comparative studies with conventional Artificial Neural Networks (ANNs) have
begun to question this reputation, especially for digital implementations. This
work investigates SNNs for multi-output regression, specifically 3-D satellite
position estimation from monocular images, and compares hardware-aware and
hardware-agnostic energy estimation methods. The proposed SNN, trained using
the membrane potential of the Leaky Integrate-and-Fire (LIF) neuron in the
final layer, achieves comparable Mean Squared Error (MSE) to a reference
Convolutional Neural Network (CNN) on a photorealistic satellite dataset.
Energy analysis shows that while hardware-agnostic methods predict a consistent
50-60% energy advantage for SNNs over CNNs, hardware-aware analysis reveals
that significant energy savings are realized only on neuromorphic hardware and
with high input sparsity. The influence of dark pixel ratio on energy
consumption is quantified, emphasizing the impact of data characteristics and
hardware assumptions. These findings highlight the need for transparent
evaluation methods and explicit disclosure of underlying assumptions to ensure
fair comparisons of neural network energy efficiency.

</details>


### [44] [A Frequency-Aware Self-Supervised Learning for Ultra-Wide-Field Image Enhancement](https://arxiv.org/abs/2508.19664)
*Weicheng Liao,Zan Chen,Jianyang Xie,Yalin Zheng,Yuhui Ma,Yitian Zhao*

Main category: cs.CV

TL;DR: 提出了一种针对超广视野视网膜图像增强的新方法，可有效提升图像质量和诊断性能。


<details>
  <summary>Details</summary>
Motivation: 超广视野视网膜图像因模糊和不均匀亮度等因素导致细节和病理信息丢失，现有方法无法满足其特有需求。

Method: 提出了一种频率感知自监督学习方法，包括频率解耦去模糊与Retinex引导的照明补偿模块，并结合高低频信息与颜色保真单元。

Result: 实验表明该方法不仅改善了可视化质量，还提升了疾病诊断性能。

Conclusion: 本研究首次提出超广视野视网膜图像增强方法，为视网膜疾病管理提供了有价值的工具。

Abstract: Ultra-Wide-Field (UWF) retinal imaging has revolutionized retinal diagnostics
by providing a comprehensive view of the retina. However, it often suffers from
quality-degrading factors such as blurring and uneven illumination, which
obscure fine details and mask pathological information. While numerous retinal
image enhancement methods have been proposed for other fundus imageries, they
often fail to address the unique requirements in UWF, particularly the need to
preserve pathological details. In this paper, we propose a novel
frequency-aware self-supervised learning method for UWF image enhancement. It
incorporates frequency-decoupled image deblurring and Retinex-guided
illumination compensation modules. An asymmetric channel integration operation
is introduced in the former module, so as to combine global and local views by
leveraging high- and low-frequency information, ensuring the preservation of
fine and broader structural details. In addition, a color preservation unit is
proposed in the latter Retinex-based module, to provide multi-scale spatial and
frequency information, enabling accurate illumination estimation and
correction. Experimental results demonstrate that the proposed work not only
enhances visualization quality but also improves disease diagnosis performance
by restoring and correcting fine local details and uneven intensity. To the
best of our knowledge, this work is the first attempt for UWF image
enhancement, offering a robust and clinically valuable tool for improving
retinal disease management.

</details>


### [45] [SAT: Supervisor Regularization and Animation Augmentation for Two-process Monocular Texture 3D Human Reconstruction](https://arxiv.org/abs/2508.19688)
*Gangjian Zhang,Jian Shu,Nanjie Yao,Hao Wang*

Main category: cs.CV

TL;DR: SAT框架通过单张RGB图像实现高质量3D人像重建，解决几何模态整合与数据不足问题，实验表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D纹理人像重建受几何模态整合不佳和训练数据不足限制，导致效果不理想。

Method: 提出SAT框架，综合多几何模态信息，并通过引入监督特征正则化和在线动画增强模块，改善几何学习和数据扩充。

Result: 在两个基准测试中表现出色，与最新技术相比具有显著优势。

Conclusion: SAT框架显著改善了单目3D人像重建的效果，解决了几何整合与数据不足的问题，未来有望促进该领域进一步发展。

Abstract: Monocular texture 3D human reconstruction aims to create a complete 3D
digital avatar from just a single front-view human RGB image. However, the
geometric ambiguity inherent in a single 2D image and the scarcity of 3D human
training data are the main obstacles limiting progress in this field. To
address these issues, current methods employ prior geometric estimation
networks to derive various human geometric forms, such as the SMPL model and
normal maps. However, they struggle to integrate these modalities effectively,
leading to view inconsistencies, such as facial distortions. To this end, we
propose a two-process 3D human reconstruction framework, SAT, which seamlessly
learns various prior geometries in a unified manner and reconstructs
high-quality textured 3D avatars as the final output. To further facilitate
geometry learning, we introduce a Supervisor Feature Regularization module. By
employing a multi-view network with the same structure to provide intermediate
features as training supervision, these varied geometric priors can be better
fused. To tackle data scarcity and further improve reconstruction quality, we
also propose an Online Animation Augmentation module. By building a
one-feed-forward animation network, we augment a massive number of samples from
the original 3D human data online for model training. Extensive experiments on
two benchmarks show the superiority of our approach compared to
state-of-the-art methods.

</details>


### [46] [Synthetic Image Detection via Spectral Gaps of QC-RBIM Nishimori Bethe-Hessian Operators](https://arxiv.org/abs/2508.19698)
*V. S. Usatyuk,D. A. Sapozhnikov,S. I. Egorov*

Main category: cs.CV

TL;DR: 提出一种基于物理启发的、模型无关的检测器，可用于区分生成图片与真实照片，实验证明其准确率达94%以上。


<details>
  <summary>Details</summary>
Motivation: 随着深度生成模型的发展，可生成与真照片几乎无法区分的图像，这对媒体取证和生物安全构成威胁，需要一种更鲁棒的检测方法。

Method: 采用预训练CNN提取图像特征并降至32维，嵌入到多边类型QC-LDPC图中，通过对相似性转换和谱分析，检测图像真实性。

Result: 无需标注的生成数据或重训练，检测器在不同应用场景中准确率达94%以上；真实图像集的谱分布呈明显分隔，生成图像集的谱分布则塌陷。

Conclusion: 提出了一种新颖的基于LDPC图的检测方法，链接了RBIM与Bethe-Hessian谱分析，并设计出对生成架构更鲁棒的无监督检测器。

Abstract: The rapid advance of deep generative models such as GANs and diffusion
networks now produces images that are virtually indistinguishable from genuine
photographs, undermining media forensics and biometric security. Supervised
detectors quickly lose effectiveness on unseen generators or after adversarial
post-processing, while existing unsupervised methods that rely on low-level
statistical cues remain fragile. We introduce a physics-inspired,
model-agnostic detector that treats synthetic-image identification as a
community-detection problem on a sparse weighted graph. Image features are
first extracted with pretrained CNNs and reduced to 32 dimensions, each feature
vector becomes a node of a Multi-Edge Type QC-LDPC graph. Pairwise similarities
are transformed into edge couplings calibrated at the Nishimori temperature,
producing a Random Bond Ising Model (RBIM) whose Bethe-Hessian spectrum
exhibits a characteristic gap when genuine community structure (real images) is
present. Synthetic images violate the Nishimori symmetry and therefore lack
such gaps. We validate the approach on binary tasks cat versus dog and male
versus female using real photos from Flickr-Faces-HQ and CelebA and synthetic
counterparts generated by GANs and diffusion models. Without any labeled
synthetic data or retraining of the feature extractor, the detector achieves
over 94% accuracy. Spectral analysis shows multiple well separated gaps for
real image sets and a collapsed spectrum for generated ones. Our contributions
are threefold: a novel LDPC graph construction that embeds deep image features,
an analytical link between Nishimori temperature RBIM and the Bethe-Hessian
spectrum providing a Bayes optimal detection criterion; and a practical,
unsupervised synthetic image detector robust to new generative architectures.
Future work will extend the framework to video streams and multi-class anomaly
detection.

</details>


### [47] [LabelGS: Label-Aware 3D Gaussian Splatting for 3D Scene Segmentation](https://arxiv.org/abs/2508.19699)
*Yupeng Zhang,Dezhi Zheng,Ping Lu,Han Zhang,Lei Wang,Liping xiang,Cheng Luo,Kaijun Deng,Xiaowen Fu,Linlin Shen,Jinbao Wang*

Main category: cs.CV

TL;DR: 本文提出了Label-aware 3D Gaussian Splatting (LabelGS)，用于增强3D Gaussian Splatting模型的3D分割能力。


<details>
  <summary>Details</summary>
Motivation: 3D Gaussian Splatting虽然在高保真重建和高效渲染方面表现出色，但缺乏3D分割能力，限制了其在场景理解任务中的适用性。

Method: 提出通过跨视图一致的语义掩码和一个新型遮挡分析模型，结合随机区域采样策略，优化3D Gaussian的语义标注，提升分解与效率。

Result: LabelGS在3D场景分割中超过了最先进的Feature-3DGS模型，训练速度提高了22倍（1440X1080分辨率下）。

Conclusion: LabelGS显著提升了3D Gaussian Splatting模型在3D分割任务中的性能和效率，为场景理解任务提供了前景方案，相关代码已开源。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a novel explicit representation
for 3D scenes, offering both high-fidelity reconstruction and efficient
rendering. However, 3DGS lacks 3D segmentation ability, which limits its
applicability in tasks that require scene understanding. The identification and
isolating of specific object components is crucial. To address this limitation,
we propose Label-aware 3D Gaussian Splatting (LabelGS), a method that augments
the Gaussian representation with object label.LabelGS introduces cross-view
consistent semantic masks for 3D Gaussians and employs a novel Occlusion
Analysis Model to avoid overfitting occlusion during optimization, Main
Gaussian Labeling model to lift 2D semantic prior to 3D Gaussian and Gaussian
Projection Filter to avoid Gaussian label conflict. Our approach achieves
effective decoupling of Gaussian representations and refines the 3DGS
optimization process through a random region sampling strategy, significantly
improving efficiency. Extensive experiments demonstrate that LabelGS
outperforms previous state-of-the-art methods, including Feature-3DGS, in the
3D scene segmentation task. Notably, LabelGS achieves a remarkable 22X speedup
in training compared to Feature-3DGS, at a resolution of 1440X1080. Our code
will be at https://github.com/garrisonz/LabelGS.

</details>


### [48] [FreeVPS: Repurposing Training-Free SAM2 for Generalizable Video Polyp Segmentation](https://arxiv.org/abs/2508.19705)
*Qiang Hu,Ying Zhou,Gepeng Ji,Nick Barnes,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: 现有的视频息肉分割方法难以在时空建模和领域泛化之间取得平衡，该研究通过创新的跟踪检测方法改进方法，实现了在临床场景中的应用提升。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在时空建模与领域泛化上的不足，提升视频息肉分割在真实临床场景中的适用性。

Method: 提出一种结合图像分割模型和改进的SAM2模型的跟踪检测框架，并通过两种无需训练的模块（空间关联过滤模块和时序关联优化模块）改善长期息肉追踪中的误差累积问题。

Result: Proposed方法在域内和域外场景中实现了最先进的性能。此外，还在长时间未修剪的结肠镜视频中验证了其稳定的追踪能力。

Conclusion: FreeVPS在视频息肉分割中的应用前景良好，显示出可靠的临床分析潜力。

Abstract: Existing video polyp segmentation (VPS) paradigms usually struggle to balance
between spatiotemporal modeling and domain generalization, limiting their
applicability in real clinical scenarios. To embrace this challenge, we recast
the VPS task as a track-by-detect paradigm that leverages the spatial contexts
captured by the image polyp segmentation (IPS) model while integrating the
temporal modeling capabilities of segment anything model 2 (SAM2). However,
during long-term polyp tracking in colonoscopy videos, SAM2 suffers from error
accumulation, resulting in a snowball effect that compromises segmentation
stability. We mitigate this issue by repurposing SAM2 as a video polyp
segmenter with two training-free modules. In particular, the intra-association
filtering module eliminates spatial inaccuracies originating from the detecting
stage, reducing false positives. The inter-association refinement module
adaptively updates the memory bank to prevent error propagation over time,
enhancing temporal coherence. Both modules work synergistically to stabilize
SAM2, achieving cutting-edge performance in both in-domain and out-of-domain
scenarios. Furthermore, we demonstrate the robust tracking capabilities of
FreeVPS in long-untrimmed colonoscopy videos, underscoring its potential
reliable clinical analysis.

</details>


### [49] [Improving Generalization in Deepfake Detection with Face Foundation Models and Metric Learning](https://arxiv.org/abs/2508.19730)
*Stelios Mylonas,Symeon Papadopoulos*

Main category: cs.CV

TL;DR: 深伪检测模型面临泛化性挑战。本文提出了一种鲁棒的视频深伪检测框架，利用面部基础模型的丰富表示，显著提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深伪检测模型在训练分布之外的泛化能力较差，尤其是在真实环境下应用时表现受限。

Method: 本方法基于FSFM（一个自监督模型），结合多种深伪数据集，通过引入三元组损失和归因监督策略，提升模型的检测能力和泛化性。

Result: 实验显示，该方法在各种评估基准上表现出色，特别是在处理真实世界深伪案例时效果显著。

Conclusion: 通过整合基础模型和多种优化手段，本文有效提高了深伪检测系统的鲁棒性和适应性，为处理深伪技术的威胁提供了有效方案。

Abstract: The increasing realism and accessibility of deepfakes have raised critical
concerns about media authenticity and information integrity. Despite recent
advances, deepfake detection models often struggle to generalize beyond their
training distributions, particularly when applied to media content found in the
wild. In this work, we present a robust video deepfake detection framework with
strong generalization that takes advantage of the rich facial representations
learned by face foundation models. Our method is built on top of FSFM, a
self-supervised model trained on real face data, and is further fine-tuned
using an ensemble of deepfake datasets spanning both face-swapping and
face-reenactment manipulations. To enhance discriminative power, we incorporate
triplet loss variants during training, guiding the model to produce more
separable embeddings between real and fake samples. Additionally, we explore
attribution-based supervision schemes, where deepfakes are categorized by
manipulation type or source dataset, to assess their impact on generalization.
Extensive experiments across diverse evaluation benchmarks demonstrate the
effectiveness of our approach, especially in challenging real-world scenarios.

</details>


### [50] [POEv2: a flexible and robust framework for generic line segment detection and wireframe line segment detection](https://arxiv.org/abs/2508.19742)
*Chenguang Liu,Chisheng Wang,Yuhua Cai,Chuanhua Zhu,Qingquan Li*

Main category: cs.CV

TL;DR: 本文提出了一种改进的像素方向估计(POE)的线段检测框架POEv2，兼顾通用线段检测和框架线段检测，并在三个公开数据集上实现最新性能。


<details>
  <summary>Details</summary>
Motivation: 现有线段检测器分为通用线段检测器和框架线段检测器，但它们在彼此任务上的性能有限，亟需一种通用且高效的检测器。

Method: 提出了一种基于像素方向估计(POE)并结合边缘检测器的改进方法POEv2，用于从边缘强度图中检测线段，可适用于多种线段检测场景。

Result: 通过将POEv2与高效的边缘检测器结合，作者展示了在三个公开数据集上的性能达到最优水平。

Conclusion: POEv2是一种通用且性能突出的线段检测框架，为通用和框架线段检测任务提供了一种新方法，并证明其在多种场景中具有适用性和优越性。

Abstract: Line segment detection in images has been studied for several decades.
Existing line segment detectors can be roughly divided into two categories:
generic line segment detectors and wireframe line segment detectors. Generic
line segment detectors aim to detect all meaningful line segments in images and
traditional approaches usually fall into this category. Recent deep learning
based approaches are mostly wireframe line segment detectors. They detect only
line segments that are geometrically meaningful and have large spatial support.
Due to the difference in the aim of design, the performance of generic line
segment detectors for the task of wireframe line segment detection won't be
satisfactory, and vice versa. In this work, we propose a robust framework that
can be used for both generic line segment detection and wireframe line segment
detection. The proposed method is an improved version of the Pixel Orientation
Estimation (POE) method. It is thus named as POEv2. POEv2 detects line segments
from edge strength maps, and can be combined with any edge detector. We show in
our experiments that by combining the proposed POEv2 with an efficient edge
detector, it achieves state-of-the-art performance on three publicly available
datasets.

</details>


### [51] [SPLF-SAM: Self-Prompting Segment Anything Model for Light Field Salient Object Detection](https://arxiv.org/abs/2508.19746)
*Qiyao Xu,Qiming Wu,Xiaowei Li*

Main category: cs.CV

TL;DR: 本研究提出了一个新的自提示轻场分割模型（SPLF-SAM），通过整合多尺度特征嵌入和频域学习，在轻场显著目标检测任务中表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有模型多忽视提示信息的提取，同时未对频域信息进行分析，导致小目标易被噪声淹没。本研究希望通过提出改进方法解决这些问题。

Method: 提出了自提示轻场分割模型SPLF-SAM，配备有统一多尺度特征嵌入模块（UMFEB）和多尺度自适应滤波适配器（MAFA），前者识别不同大小目标，后者通过学习频域特征防止噪声干扰。

Result: 实验表明，与当前10种最先进的轻场显著目标检测方法相比，本方法显示出更优越的性能。

Conclusion: 研究提出的方法显著提升了轻场显著目标检测的效果，验证了自提示和频域分析的有效性。代码开源以促进进一步研究。

Abstract: Segment Anything Model (SAM) has demonstrated remarkable capabilities in
solving light field salient object detection (LF SOD). However, most existing
models tend to neglect the extraction of prompt information under this task.
Meanwhile, traditional models ignore the analysis of frequency-domain
information, which leads to small objects being overwhelmed by noise. In this
paper, we put forward a novel model called self-prompting light field segment
anything model (SPLF-SAM), equipped with unified multi-scale feature embedding
block (UMFEB) and a multi-scale adaptive filtering adapter (MAFA). UMFEB is
capable of identifying multiple objects of varying sizes, while MAFA, by
learning frequency features, effectively prevents small objects from being
overwhelmed by noise. Extensive experiments have demonstrated the superiority
of our method over ten state-of-the-art (SOTA) LF SOD methods. Our code will be
available at https://github.com/XucherCH/splfsam.

</details>


### [52] [FastAvatar: Towards Unified Fast High-Fidelity 3D Avatar Reconstruction with Large Gaussian Reconstruction Transformers](https://arxiv.org/abs/2508.19754)
*Yue Wu,Yufan Wu,Wen Li,Yuxi Lu,Kairui Feng,Xuanhong Chen*

Main category: cs.CV

TL;DR: FastAvatar是一种高效的3D头像重建框架，可通过输入单一图像、多视角观测或单目视频，在数秒内重建高质量3D模型。


<details>
  <summary>Details</summary>
Motivation: 当前3D头像重建存在时间复杂度高、数据质量敏感、数据利用率低的挑战。目标是开发一种灵活、精确且高效的重建方法。

Method: 引入了一种基于VGGT-style变体变压器架构的大型高斯重建变压器，结合多层次引导编码和增量高斯聚合，实现了3D头像的增量重建和数据利用最大化。

Result: FastAvatar能以更快的速度比以往方法提供更高质量的3D头像模型，同时支持逐步提高重建质量。

Conclusion: FastAvatar开创了一种质量和速度兼顾的重建范式，在提升3D建模效率的同时大幅改进模型质量，为实际应用提供了极大的便利性。

Abstract: Despite significant progress in 3D avatar reconstruction, it still faces
challenges such as high time complexity, sensitivity to data quality, and low
data utilization. We propose FastAvatar, a feedforward 3D avatar framework
capable of flexibly leveraging diverse daily recordings (e.g., a single image,
multi-view observations, or monocular video) to reconstruct a high-quality 3D
Gaussian Splatting (3DGS) model within seconds, using only a single unified
model. FastAvatar's core is a Large Gaussian Reconstruction Transformer
featuring three key designs: First, a variant VGGT-style transformer
architecture aggregating multi-frame cues while injecting initial 3D prompt to
predict an aggregatable canonical 3DGS representation; Second, multi-granular
guidance encoding (camera pose, FLAME expression, head pose) mitigating
animation-induced misalignment for variable-length inputs; Third, incremental
Gaussian aggregation via landmark tracking and sliced fusion losses.
Integrating these features, FastAvatar enables incremental reconstruction,
i.e., improving quality with more observations, unlike prior work wasting input
data. This yields a quality-speed-tunable paradigm for highly usable avatar
modeling. Extensive experiments show that FastAvatar has higher quality and
highly competitive speed compared to existing methods.

</details>


### [53] [BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions](https://arxiv.org/abs/2508.19762)
*Ahmed Emam,Mohamed Elbassiouny,Julius Miller,Patrick Donworth,Sabine Seidel,Ribana Roscher*

Main category: cs.CV

TL;DR: 研究介绍了一个名为BuzzSet的大规模数据集，用于蜂类传粉昆虫的自动化监测，采用变换器模型RF-DETR进行检测，并展示了高检测性能。


<details>
  <summary>Details</summary>
Motivation: 由于传粉昆虫在全球粮食生产和生态系统稳定中至关重要，但其种群因各种压力正在减少，因此需要开发可扩展的自动监测方法来支持保护措施。

Method: 构建了包含7856张高分辨率图片的BuzzSet数据集，通过YOLOv12模型生成初始标注，然后以人工验证的方式完善标注。用RF-DETR变换器模型完成了昆虫检测和分类实验。

Result: 模型F1分数在蜜蜂和大黄蜂类别分别达到0.94和0.92，总体mAP@0.50达到0.559，但对未识别类别的检测仍有挑战。

Conclusion: BuzzSet为小目标检测、标签不确定性的类间分离及生态计算机视觉提供了重要基准，并展示了其在实际农业场景下的高效性。

Abstract: Pollinator insects such as honeybees and bumblebees are vital to global food
production and ecosystem stability, yet their populations are declining due to
increasing anthropogenic and environmental stressors. To support scalable,
automated pollinator monitoring, we introduce BuzzSet, a new large-scale
dataset of high-resolution pollinator images collected in real agricultural
field conditions. BuzzSet contains 7856 manually verified and labeled images,
with over 8000 annotated instances across three classes: honeybees, bumblebees,
and unidentified insects. Initial annotations were generated using a YOLOv12
model trained on external data and refined via human verification using
open-source labeling tools. All images were preprocessed into 256~$\times$~256
tiles to improve the detection of small insects. We provide strong baselines
using the RF-DETR transformer-based object detector. The model achieves high
F1-scores of 0.94 and 0.92 for honeybee and bumblebee classes, respectively,
with confusion matrix results showing minimal misclassification between these
categories. The unidentified class remains more challenging due to label
ambiguity and lower sample frequency, yet still contributes useful insights for
robustness evaluation. Overall detection quality is strong, with a best
mAP@0.50 of 0.559. BuzzSet offers a valuable benchmark for small object
detection, class separation under label noise, and ecological computer vision.

</details>


### [54] [AIM: Adaptive Intra-Network Modulation for Balanced Multimodal Learning](https://arxiv.org/abs/2508.19769)
*Shu Shen,C. L. Philip Chen,Tong Zhang*

Main category: cs.CV

TL;DR: 提出了一个名为AIM的新方法，用于解决多模态学习中的优化偏差问题，并在不妨碍任何模态的情况下实现平衡的多模态学习。


<details>
  <summary>Details</summary>
Motivation: 解决多模态学习中弱模态与强模态之间的不平衡问题，同时克服现有方法限制强模态表现的问题。

Method: 提出了自适应网络内调制（AIM），包括将强模态的未优化参数分离到辅助模块，并在不同深度自适应调整调制强度。

Result: AIM在多个基准上优于现有方法，并表现出在不同架构、融合策略和优化器上的强泛化能力。

Conclusion: AIM能够有效解决多模态学习中的优化偏差问题，促进了平衡的多模态学习，并具有较强的应用潜力。

Abstract: Multimodal learning has significantly enhanced machine learning performance
but still faces numerous challenges and limitations. Imbalanced multimodal
learning is one of the problems extensively studied in recent works and is
typically mitigated by modulating the learning of each modality. However, we
find that these methods typically hinder the dominant modality's learning to
promote weaker modalities, which affects overall multimodal performance. We
analyze the cause of this issue and highlight a commonly overlooked problem:
optimization bias within networks. To address this, we propose Adaptive
Intra-Network Modulation (AIM) to improve balanced modality learning. AIM
accounts for differences in optimization state across parameters and depths
within the network during modulation, achieving balanced multimodal learning
without hindering either dominant or weak modalities for the first time.
Specifically, AIM decouples the dominant modality's under-optimized parameters
into Auxiliary Blocks and encourages reliance on these performance-degraded
blocks for joint training with weaker modalities. This approach effectively
prevents suppression of weaker modalities while enabling targeted optimization
of under-optimized parameters to improve the dominant modality. Additionally,
AIM assesses modality imbalance level across network depths and adaptively
adjusts modulation strength at each depth. Experimental results demonstrate
that AIM outperforms state-of-the-art imbalanced modality learning methods
across multiple benchmarks and exhibits strong generalizability across
different backbones, fusion strategies, and optimizers.

</details>


### [55] [The Return of Structural Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2508.19773)
*Jakob Seitz,Tobias Lengfeld,Radu Timofte*

Main category: cs.CV

TL;DR: 本文提出了一种新的结构化识别方法，旨在改进手写数学表达式识别任务的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 为了克服当前现代模型在LaTeX生成中缺乏显式符号与笔迹对应关系的局限性，解决误差分析、可解释性和交互性任务中的挑战。

Method: 引入一个自动注释系统和模块化的结构化识别系统；结合图形追踪排序、混合卷积-循环网络和基于Transformer的修正方法，实现高效识别。

Result: 在CROHME-2023基准测试上表现出竞争力，并实现了从手写笔迹到符号预测的直接映射，支持透明的误差分析。

Conclusion: 该系统不仅在性能上达到了领先，还显著提高了可解释性和交互性，为手写数学公式识别领域提供了新的解决方案。

Abstract: Handwritten Mathematical Expression Recognition is foundational for
educational technologies, enabling applications like digital note-taking and
automated grading. While modern encoder-decoder architectures with large
language models excel at LaTeX generation, they lack explicit symbol-to-trace
alignment, a critical limitation for error analysis, interpretability, and
spatially aware interactive applications requiring selective content updates.
This paper introduces a structural recognition approach with two innovations: 1
an automatic annotation system that uses a neural network to map LaTeX
equations to raw traces, automatically generating annotations for symbol
segmentation, classification, and spatial relations, and 2 a modular structural
recognition system that independently optimizes segmentation, classification,
and relation prediction. By leveraging a dataset enriched with structural
annotations from our auto-labeling system, the proposed recognition system
combines graph-based trace sorting, a hybrid convolutional-recurrent network,
and transformer-based correction to achieve competitive performance on the
CROHME-2023 benchmark. Crucially, our structural recognition system generates a
complete graph structure that directly links handwritten traces to predicted
symbols, enabling transparent error analysis and interpretable outputs.

</details>


### [56] [MAPo : Motion-Aware Partitioning of Deformable 3D Gaussian Splatting for High-Fidelity Dynamic Scene Reconstruction](https://arxiv.org/abs/2508.19786)
*Han Jiao,Jiakai Sun,Yexing Xu,Lei Zhao,Wei Xing,Huaizhong Lin*

Main category: cs.CV

TL;DR: 本文提出了一种名为MAPo的动态场景重建新框架，通过动态得分分区策略识别高动态和低动态的3D高斯体，并采用特定策略以高保真地建模动态场景，同时控制计算成本。


<details>
  <summary>Details</summary>
Motivation: 目前基于形变的3D高斯动态场景重建方法在处理复杂运动时易产生模糊渲染及丢失细节，这是由于单一模型无法很好地表征多样化的运动模式。

Method: MAPo框架通过动态得分分区策略将高动态和低动态高斯体分类，高动态区域采用时间递归分区和独立形变网络建模，而低动态区域视为静态以降低计算成本。此外，通过跨帧一致性损失来确保视觉连贯性并提升渲染质量。

Result: 实验表明，MAPo能够在复杂或快速运动区域显著提升渲染质量，同时保持计算成本可控，相较基线方法表现优越。

Conclusion: MAPo成功解决了高动态场景中模糊渲染和运动细节丢失问题，为动态场景重建提供了一种高效且高保真的解决方案。

Abstract: 3D Gaussian Splatting, known for enabling high-quality static scene
reconstruction with fast rendering, is increasingly being applied to dynamic
scene reconstruction. A common strategy involves learning a deformation field
to model the temporal changes of a canonical set of 3D Gaussians. However,
these deformation-based methods often produce blurred renderings and lose fine
motion details in highly dynamic regions due to the inherent limitations of a
single, unified model in representing diverse motion patterns. To address these
challenges, we introduce Motion-Aware Partitioning of Deformable 3D Gaussian
Splatting (MAPo), a novel framework for high-fidelity dynamic scene
reconstruction. Its core is a dynamic score-based partitioning strategy that
distinguishes between high- and low-dynamic 3D Gaussians. For high-dynamic 3D
Gaussians, we recursively partition them temporally and duplicate their
deformation networks for each new temporal segment, enabling specialized
modeling to capture intricate motion details. Concurrently, low-dynamic 3DGs
are treated as static to reduce computational costs. However, this temporal
partitioning strategy for high-dynamic 3DGs can introduce visual
discontinuities across frames at the partition boundaries. To address this, we
introduce a cross-frame consistency loss, which not only ensures visual
continuity but also further enhances rendering quality. Extensive experiments
demonstrate that MAPo achieves superior rendering quality compared to baselines
while maintaining comparable computational costs, particularly in regions with
complex or rapid motions.

</details>


### [57] [StableIntrinsic: Detail-preserving One-step Diffusion Model for Multi-view Material Estimation](https://arxiv.org/abs/2508.19789)
*Xiuchao Wu,Pengfei Zhu,Jiangjing Lyu,Xinguo Liu,Jie Guo,Yanwen Guo,Weiwei Xu,Chengfei Lyu*

Main category: cs.CV

TL;DR: 本文提出了一种名为StableIntrinsic的新方法，通过一种一步扩散模型实现多视图材料估计，解决了现有方法的高时间成本和高结果方差问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多步扩散模型存在时间和精确性上的限制，无法满足高效和低方差的材料估计需求。

Method: StableIntrinsic采用一步扩散模型，并引入像素空间损失和细节注入网络(DIN)以解决过度平滑以及细节丢失的问题。

Result: 实验结果表明，StableIntrinsic在相关指标上超越现有技术，包括反照率PSNR提升9.9%，金属MSE减少44.4%，粗糙度MSE减少60.0%。

Conclusion: StableIntrinsic证明了在材料估计任务中结合一步扩散模型和专门设计的损失函数的有效性，可实现更高效、低方差且高质量的材料估计结果。

Abstract: Recovering material information from images has been extensively studied in
computer graphics and vision. Recent works in material estimation leverage
diffusion model showing promising results. However, these diffusion-based
methods adopt a multi-step denoising strategy, which is time-consuming for each
estimation. Such stochastic inference also conflicts with the deterministic
material estimation task, leading to a high variance estimated results. In this
paper, we introduce StableIntrinsic, a one-step diffusion model for multi-view
material estimation that can produce high-quality material parameters with low
variance. To address the overly-smoothing problem in one-step diffusion,
StableIntrinsic applies losses in pixel space, with each loss designed based on
the properties of the material. Additionally, StableIntrinsic introduces a
Detail Injection Network (DIN) to eliminate the detail loss caused by VAE
encoding, while further enhancing the sharpness of material prediction results.
The experimental results indicate that our method surpasses the current
state-of-the-art techniques by achieving a $9.9\%$ improvement in the Peak
Signal-to-Noise Ratio (PSNR) of albedo, and by reducing the Mean Square Error
(MSE) for metallic and roughness by $44.4\%$ and $60.0\%$, respectively.

</details>


### [58] [Not Every Gift Comes in Gold Paper or with a Red Ribbon: Exploring Color Perception in Text-to-Image Models](https://arxiv.org/abs/2508.19791)
*Shay Shomer Chai,Wenxuan Peng,Bharath Hariharan,Hadar Averbuch-Elor*

Main category: cs.CV

TL;DR: 本文研究了在文本生成图像（text-to-image generation）中，现有方法在处理复杂多对象提示时存在的语义对齐问题，特别是颜色属性的多样性。作者提出了一种新的图像编辑技术，显著提升了多颜色提示的生成效果。


<details>
  <summary>Details</summary>
Motivation: 尽管文本生成图像技术取得了显著的进展，但现有方法在准确捕捉复杂多对象语义时仍面临挑战，特别是在多颜色属性语义对齐方面。当前方法通常依赖于难以在大规模上执行的粗糙指标或人工评估。

Method: 作者专注于颜色属性作为案例研究，分析了预训练模型在多颜色提示生成上的不足，并提出了一种专门的图像编辑技术解决这些语义不对齐问题。

Result: 实验表明，新的编辑技术在多种评估指标上显著提升了多颜色提示的生成表现，并适用于多种基于扩散的文本生成图像技术。

Conclusion: 新的方法有效解决了多颜色语义对齐问题，提升了文本生成图像的精确性和泛用性。

Abstract: Text-to-image generation has recently seen remarkable success, granting users
with the ability to create high-quality images through the use of text.
However, contemporary methods face challenges in capturing the precise
semantics conveyed by complex multi-object prompts. Consequently, many works
have sought to mitigate such semantic misalignments, typically via
inference-time schemes that modify the attention layers of the denoising
networks. However, prior work has mostly utilized coarse metrics, such as the
cosine similarity between text and image CLIP embeddings, or human evaluations,
which are challenging to conduct on a larger-scale. In this work, we perform a
case study on colors -- a fundamental attribute commonly associated with
objects in text prompts, which offer a rich test bed for rigorous evaluation.
Our analysis reveals that pretrained models struggle to generate images that
faithfully reflect multiple color attributes-far more so than with single-color
prompts-and that neither inference-time techniques nor existing editing methods
reliably resolve these semantic misalignments. Accordingly, we introduce a
dedicated image editing technique, mitigating the issue of multi-object
semantic alignment for prompts containing multiple colors. We demonstrate that
our approach significantly boosts performance over a wide range of metrics,
considering images generated by various text-to-image diffusion-based
techniques.

</details>


### [59] [FusionSort: Enhanced Cluttered Waste Segmentation with Advanced Decoding and Comprehensive Modality Optimization](https://arxiv.org/abs/2508.19798)
*Muhammad Ali,Omar Ali AlSuwaidi*

Main category: cs.CV

TL;DR: 该论文提出一种增强型的神经网络架构，将其用于改进废弃物分类的准确性和效率，显示出显著优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前废物管理中的挑战在于非生物降解材料分类过程的复杂性和废物流的多样性，作者希望解决这一问题。

Method: 设计了基于现有编码器-解码器结构的增强模型，引入全面注意力模块(Data Fusion Block)，并结合Mamba架构，以融合多通道影像数据及使用PCA降维以最大化保留有效信息。

Result: 模型在RGB图像、超光谱、光谱以及RGB与超光谱数据组合上进行了测试，结果表明显著优于现有方法。

Conclusion: 通过注意力机制的改进与多通道数据的有效融合，该方法为废弃物分类系统提供了一种更高效的解决方案。

Abstract: In the realm of waste management, automating the sorting process for
non-biodegradable materials presents considerable challenges due to the
complexity and variability of waste streams. To address these challenges, we
introduce an enhanced neural architecture that builds upon an existing
Encoder-Decoder structure to improve the accuracy and efficiency of waste
sorting systems. Our model integrates several key innovations: a Comprehensive
Attention Block within the decoder, which refines feature representations by
combining convolutional and upsampling operations. In parallel, we utilize
attention through the Mamba architecture, providing an additional performance
boost. We also introduce a Data Fusion Block that fuses images with more than
three channels. To achieve this, we apply PCA transformation to reduce the
dimensionality while retaining the maximum variance and essential information
across three dimensions, which are then used for further processing. We
evaluated the model on RGB, hyperspectral, multispectral, and a combination of
RGB and hyperspectral data. The results demonstrate that our approach
outperforms existing methods by a significant margin.

</details>


### [60] [A bag of tricks for real-time Mitotic Figure detection](https://arxiv.org/abs/2508.19804)
*Christian Marzahl,Brian Napora*

Main category: cs.CV

TL;DR: 本文提出了一种基于RTMDet的高效方法，用于在组织病理学图像中实时检测有丝分裂体，并通过多域训练数据、平衡采样和数据增强来提高模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 检测组织病理学图像中的有丝分裂体因扫描仪、染色协议、组织类型及伪影的多样性而极具挑战，因此需要开发一种鲁棒、高效的检测方法。

Method: 采用基于RTMDet的单阶段目标检测器，通过多域训练数据、平衡采样、精细增强技术以及对坏死和碎片组织的硬负样本挖掘减少误报。

Result: 在多个数据集的分组五折交叉验证中，模型F1分数在0.78到0.84之间；在MIDOG 2025测试集中，单阶段RTMDet-S方法实现F1分数0.81，优于较大的模型。

Conclusion: 本方法在准确性和速度之间提供了实用的折衷方案，适合实际临床应用，且具有适应新领域的能力。

Abstract: Mitotic figure (MF) detection in histopathology images is challenging due to
large variations in slide scanners, staining protocols, tissue types, and the
presence of artifacts. This paper presents a collection of training techniques
- a bag of tricks - that enable robust, real-time MF detection across diverse
domains. We build on the efficient RTMDet single stage object detector to
achieve high inference speed suitable for clinical deployment. Our method
addresses scanner variability and tumor heterogeneity via extensive
multi-domain training data, balanced sampling, and careful augmentation.
Additionally, we employ targeted, hard negative mining on necrotic and debris
tissue to reduce false positives. In a grouped 5-fold cross-validation across
multiple MF datasets, our model achieves an F1 score between 0.78 and 0.84. On
the preliminary test set of the MItosis DOmain Generalization (MIDOG) 2025
challenge, our single-stage RTMDet-S based approach reaches an F1 of 0.81,
outperforming larger models and demonstrating adaptability to new, unfamiliar
domains. The proposed solution offers a practical trade-off between accuracy
and speed, making it attractive for real-world clinical adoption.

</details>


### [61] [AutoQ-VIS: Improving Unsupervised Video Instance Segmentation via Automatic Quality Assessment](https://arxiv.org/abs/2508.19808)
*Kaixuan Lu,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: 本文提出了一个名为AutoQ-VIS的无监督视频实例分割框架，利用质量引导的自我训练，从合成数据向真实数据逐步适应，并在多个基准数据集上取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 传统的VIS方法需要像素级标注和时间一致性的双重标签，这导致其标注成本高昂。当前无监督方法虽然减少了对光流等依赖，但合成数据和真实数据之间的域差距限制了其效果。

Method: 设计了一个基于质量引导自我训练的闭环系统，该系统通过伪标签生成和自动质量评估的迭代，逐步实现从合成视频到真实视频的适应。

Result: AutoQ-VIS在YouTubeVIS-2019验证集上达到52.6 AP$_{50}$，比之前的VideoCutLER方法高4.4%，并完全无需人工标注。

Conclusion: 质量感知的自我训练是一种有效的无监督视频实例分割方法，表现出了很强的实际可行性。

Abstract: Video Instance Segmentation (VIS) faces significant annotation challenges due
to its dual requirements of pixel-level masks and temporal consistency labels.
While recent unsupervised methods like VideoCutLER eliminate optical flow
dependencies through synthetic data, they remain constrained by the
synthetic-to-real domain gap. We present AutoQ-VIS, a novel unsupervised
framework that bridges this gap through quality-guided self-training. Our
approach establishes a closed-loop system between pseudo-label generation and
automatic quality assessment, enabling progressive adaptation from synthetic to
real videos. Experiments demonstrate state-of-the-art performance with 52.6
$\text{AP}_{50}$ on YouTubeVIS-2019 val set, surpassing the previous
state-of-the-art VideoCutLER by 4.4$\%$, while requiring no human annotations.
This demonstrates the viability of quality-aware self-training for unsupervised
VIS. The source code of our method is available at
https://github.com/wcbup/AutoQ-VIS.

</details>


### [62] [ERSR: An Ellipse-constrained pseudo-label refinement and symmetric regularization framework for semi-supervised fetal head segmentation in ultrasound images](https://arxiv.org/abs/2508.19815)
*Linkuan Zhou,Zhexin Chen,Yufei Shen,Junlin Xu,Ping Xuan,Yixin Zhu,Yuqi Fang,Cong Cong,Leyi Wei,Ran Su,Jia Zhou,Qiangguo Jin*

Main category: cs.CV

TL;DR: 本文提出了一种名为ERSR的新型半监督框架，用于胎儿头部超声图像分割，通过包含自适应过滤策略、椭圆约束伪标签优化，以及基于对称性的多重一致性正则化，实现了领域内最高性能。


<details>
  <summary>Details</summary>
Motivation: 由于胎儿头部超声图像质量差且缺乏标注数据，现有方法在生成可靠的伪标签和一致性正则约束时表现不佳，因此需要提出新的解决方案。

Method: ERSR框架由三部分组成：1）基于边界一致性和轮廓规则性的双评分自适应过滤策略；2）基于最小二乘椭圆拟合的伪标签优化，强化了椭圆中心像素并抑制噪声；3）基于对称性的多重一致性正则化，在扰动图像、对称区域及伪标签内强制一致性。

Result: 在HC18数据集上，当标注数据占比为10%和20%时，Dice得分分别为92.05%和95.36%；在PSFH数据集上，得分为91.68%和93.70%。

Conclusion: ERSR框架成功实现了胎儿头部超声图像半监督分割，并显著提升了分割性能。

Abstract: Automated segmentation of the fetal head in ultrasound images is critical for
prenatal monitoring. However, achieving robust segmentation remains challenging
due to the poor quality of ultrasound images and the lack of annotated data.
Semi-supervised methods alleviate the lack of annotated data but struggle with
the unique characteristics of fetal head ultrasound images, making it
challenging to generate reliable pseudo-labels and enforce effective
consistency regularization constraints. To address this issue, we propose a
novel semi-supervised framework, ERSR, for fetal head ultrasound segmentation.
Our framework consists of the dual-scoring adaptive filtering strategy, the
ellipse-constrained pseudo-label refinement, and the symmetry-based multiple
consistency regularization. The dual-scoring adaptive filtering strategy uses
boundary consistency and contour regularity criteria to evaluate and filter
teacher outputs. The ellipse-constrained pseudo-label refinement refines these
filtered outputs by fitting least-squares ellipses, which strengthens pixels
near the center of the fitted ellipse and suppresses noise simultaneously. The
symmetry-based multiple consistency regularization enforces multi-level
consistency across perturbed images, symmetric regions, and between original
predictions and pseudo-labels, enabling the model to capture robust and stable
shape representations. Our method achieves state-of-the-art performance on two
benchmarks. On the HC18 dataset, it reaches Dice scores of 92.05% and 95.36%
with 10% and 20% labeled data, respectively. On the PSFH dataset, the scores
are 91.68% and 93.70% under the same settings.

</details>


### [63] [Gradient Rectification for Robust Calibration under Distribution Shift](https://arxiv.org/abs/2508.19830)
*Yilin Zhang,Cai Xu,You Wu,Ziyu Guan,Wei Zhao*

Main category: cs.CV

TL;DR: 该研究提出了一种无需目标域信息的校准框架，可在保持分布内性能的同时，提高分布迁移下的校准能力。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在分布迁移下生成过于自信的预测，降低了其在安全关键应用中的可靠性，现有方法依赖目标域信息，实用性受限。

Method: 从频域角度出发，通过低频滤波策略减少对高频视觉线索的依赖，同时引入基于梯度的校正机制以优化分布内校准表现。

Result: 在CIFAR-10/100-C和WILDS等数据集上的实验显示，该方法在分布迁移下显著提升了校准性能，且保持了良好的分布内性能。

Conclusion: 该方法有效解决了分布迁移下的校准问题，为无需目标域信息的校准提供了新的方法。

Abstract: Deep neural networks often produce overconfident predictions, undermining
their reliability in safety-critical applications. This miscalibration is
further exacerbated under distribution shift, where test data deviates from the
training distribution due to environmental or acquisition changes. While
existing approaches improve calibration through training-time regularization or
post-hoc adjustment, their reliance on access to or simulation of target
domains limits their practicality in real-world scenarios. In this paper, we
propose a novel calibration framework that operates without access to target
domain information. From a frequency-domain perspective, we identify that
distribution shifts often distort high-frequency visual cues exploited by deep
models, and introduce a low-frequency filtering strategy to encourage reliance
on domain-invariant features. However, such information loss may degrade
In-Distribution (ID) calibration performance. Therefore, we further propose a
gradient-based rectification mechanism that enforces ID calibration as a hard
constraint during optimization. Experiments on synthetic and real-world shifted
datasets, including CIFAR-10/100-C and WILDS, demonstrate that our method
significantly improves calibration under distribution shift while maintaining
strong in-distribution performance.

</details>


### [64] [Image Quality Assessment for Machines: Paradigm, Large-scale Database, and Models](https://arxiv.org/abs/2508.19850)
*Xiaoqi Wang,Yun Zhang,Weisi Lin*

Main category: cs.CV

TL;DR: 这篇文章提出了一种名为MIQA的框架，用于评估图像质量对机器视觉系统（MVS）性能的影响。同时构建了一个包含250万样本的大型数据库，以及一种名为RA-MIQA的模型，用于分析视觉降解的细粒度影响。


<details>
  <summary>Details</summary>
Motivation: 传统以人类视觉系统为基础的图像质量评估方法无法有效评估机器视觉系统在复杂视觉条件下的可靠性。因此，提出了一种以机器为中心的评估方法。

Method: 通过建立一个具有250万样本的MIQD-2.5M数据库，覆盖75种视觉模型、250种降解类型和3种视觉任务，并设计了RA-MIQA模型进行细粒度空间降解分析。

Result: 实验结果表明，RA-MIQA在多维度上优于现有方法，在图像分类的一致性和准确性指标上分别提高了13.56%和13.37%。同时揭示了任务特定的降解敏感性。

Conclusion: HVS算法不足以预测MVS质量，本研究的MIQA框架和数据库为机器视觉的可靠性提升提供了重要基础，并推动了以机器为中心的图像处理及优化方向。

Abstract: Machine vision systems (MVS) are intrinsically vulnerable to performance
degradation under adverse visual conditions. To address this, we propose a
machine-centric image quality assessment (MIQA) framework that quantifies the
impact of image degradations on MVS performance. We establish an MIQA paradigm
encompassing the end-to-end assessment workflow. To support this, we construct
a machine-centric image quality database (MIQD-2.5M), comprising 2.5 million
samples that capture distinctive degradation responses in both consistency and
accuracy metrics, spanning 75 vision models, 250 degradation types, and three
representative vision tasks. We further propose a region-aware MIQA (RA-MIQA)
model to evaluate MVS visual quality through fine-grained spatial degradation
analysis. Extensive experiments benchmark the proposed RA-MIQA against seven
human visual system (HVS)-based IQA metrics and five retrained classical
backbones. Results demonstrate RA-MIQA's superior performance in multiple
dimensions, e.g., achieving SRCC gains of 13.56% on consistency and 13.37% on
accuracy for image classification, while also revealing task-specific
degradation sensitivities. Critically, HVS-based metrics prove inadequate for
MVS quality prediction, while even specialized MIQA models struggle with
background degradations, accuracy-oriented estimation, and subtle distortions.
This study can advance MVS reliability and establish foundations for
machine-centric image processing and optimization. The model and code are
available at: https://github.com/XiaoqiWang/MIQA.

</details>


### [65] [KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA Attuned to Diverse Visual Contexts](https://arxiv.org/abs/2508.19944)
*Taebaek Hwang,Minseo Kim,Gisang Lee,Seonuk Kim,Hyunjun Eun*

Main category: cs.CV

TL;DR: 本文介绍了一个新基准KRETA，用于评估韩语的文本丰富视觉问答能力，同时开发了一种半自动VQA生成流程，以支持多语言的视觉语言模型研究。


<details>
  <summary>Details</summary>
Motivation: 面对真实场景中视觉上下文复杂性和多样性，低资源语言如韩语缺乏全面的基准用于模型评价和对比。

Method: 提出了名为KRETA的基准，覆盖15个领域和26种图片类型，并开发了优化的半自动VQA生成流程，结合逐步图像分解和七项评估指标以保证数据质量。

Result: KRETA显著提升了对韩语视觉文本理解和推理的评估能力，为多语言VLM研究提供了重要支持。

Conclusion: KRETA不仅针对韩语优化，其生成流程的适应性和可扩展性也为其他语言的基准开发铺平了道路，加速了多语言视觉语言模型的研究。

Abstract: Understanding and reasoning over text within visual contexts poses a
significant challenge for Vision-Language Models (VLMs), given the complexity
and diversity of real-world scenarios. To address this challenge, text-rich
Visual Question Answering (VQA) datasets and benchmarks have emerged for
high-resource languages like English. However, a critical gap persists for
low-resource languages such as Korean, where the lack of comprehensive
benchmarks hinders robust model evaluation and comparison. To bridge this gap,
we introduce KRETA, a benchmark for Korean Reading and rEasoning in Text-rich
VQA Attuned to diverse visual contexts. KRETA facilitates an in-depth
evaluation of both visual text understanding and reasoning capabilities, while
also supporting a multifaceted assessment across 15 domains and 26 image types.
Additionally, we introduce a semi-automated VQA generation pipeline
specifically optimized for text-rich settings, leveraging refined stepwise
image decomposition and a rigorous seven-metric evaluation protocol to ensure
data quality. While KRETA is tailored for Korean, we hope our adaptable and
extensible pipeline will facilitate the development of similar benchmarks in
other languages, thereby accelerating multilingual VLM research. The code and
dataset for KRETA are available at https://github.com/tabtoyou/KRETA.

</details>


### [66] [Ego-centric Predictive Model Conditioned on Hand Trajectories](https://arxiv.org/abs/2508.19852)
*Binjie Zhang,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 提出了一种新的统一预测框架，可以在自中心场景下联合预测下一步动作和视觉结果未来。


<details>
  <summary>Details</summary>
Motivation: 现有模型要么专注于动作预测，缺少对动作如何影响视觉场景的建模，要么无法基于特定动作预测未来帧，从而导致不合理的结果。因此需要一个同时对动作和视觉未来进行建模的框架。

Method: 提出一个两阶段预测框架：第一阶段通过连续状态建模预测未来手部轨迹；第二阶段使用因果交叉注意力融合多模态线索，利用推导的动作信号指导基于潜在扩散模型（LDM）的逐帧未来视频生成。

Result: 在Ego4D、BridgeData和RLBench数据集上的实验表明，该方法在动作预测和未来视频合成两方面均优于最先进的基线方法。

Conclusion: 该方法是首个设计用于处理自中心人类活动理解和机器人操作任务的统一模型，能够显式预测未来的动作及其视觉后果。

Abstract: In egocentric scenarios, anticipating both the next action and its visual
outcome is essential for understanding human-object interactions and for
enabling robotic planning. However, existing paradigms fall short of jointly
modeling these aspects. Vision-Language-Action (VLA) models focus on action
prediction but lack explicit modeling of how actions influence the visual
scene, while video prediction models generate future frames without
conditioning on specific actions, often resulting in implausible or
contextually inconsistent outcomes. To bridge this gap, we propose a unified
two-stage predictive framework that jointly models action and visual future in
egocentric scenarios, conditioned on hand trajectories. In the first stage, we
perform consecutive state modeling to process heterogeneous inputs (visual
observations, language, and action history) and explicitly predict future hand
trajectories. In the second stage, we introduce causal cross-attention to fuse
multi-modal cues, leveraging inferred action signals to guide an image-based
Latent Diffusion Model (LDM) for frame-by-frame future video generation. Our
approach is the first unified model designed to handle both egocentric human
activity understanding and robotic manipulation tasks, providing explicit
predictions of both upcoming actions and their visual consequences. Extensive
experiments on Ego4D, BridgeData, and RLBench demonstrate that our method
outperforms state-of-the-art baselines in both action prediction and future
video synthesis.

</details>


### [67] [GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity](https://arxiv.org/abs/2508.19972)
*Seongheon Park,Yixuan Li*

Main category: cs.CV

TL;DR: 提出一种新方法GLSim，用于检测大型视觉语言模型中的对象幻觉问题，具备高性能和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型中对象幻觉问题对实际应用的严重影响，提高检测可靠性。

Method: 提出名为GLSim的训练无关框架，将图像和文本的全局和局部嵌入相似性信号结合，用于检测对象幻觉。

Result: GLSim在多种场景中实现了更准确和可靠的幻觉检测，显著优于其他现有基线方法。

Conclusion: GLSim提供了一种更优的解决方案，为对象幻觉问题提供了更准确的检测方法。

Abstract: Object hallucination in large vision-language models presents a significant
challenge to their safe deployment in real-world applications. Recent works
have proposed object-level hallucination scores to estimate the likelihood of
object hallucination; however, these methods typically adopt either a global or
local perspective in isolation, which may limit detection reliability. In this
paper, we introduce GLSim, a novel training-free object hallucination detection
framework that leverages complementary global and local embedding similarity
signals between image and text modalities, enabling more accurate and reliable
hallucination detection in diverse scenarios. We comprehensively benchmark
existing object hallucination detection methods and demonstrate that GLSim
achieves superior detection performance, outperforming competitive baselines by
a significant margin.

</details>


### [68] [Multimodal Conditional MeshGAN for Personalized Aneurysm Growth Prediction](https://arxiv.org/abs/2508.19862)
*Long Chen,Ashiv Patel,Mengyun Qiao,Mohammad Yousuf Salmasi,Salah A. Hammouche,Vasilis Stavrinides,Jasleen Nagi,Soodeh Kalaie,Xiao Yun Xu,Wenjia Bai,Declan P. O'Regan*

Main category: cs.CV

TL;DR: 本文提出了MCMeshGAN，这是首个用于3D主动脉瘤增长预测的多模态条件网格到网格生成对抗网络。


<details>
  <summary>Details</summary>
Motivation: 个性化的主动脉瘤进展预测对于及时干预至关重要，但由于需要同时建模复杂3D几何中的局部微小变形和全局解剖变化，仍然是一个挑战。

Method: MCMeshGAN采用双分支架构，结合局部KNN卷积网络和全局图卷积网络，同时包含条件分支用以编码年龄、性别等临床属性及目标时间间隔，用于生成解剖合理且时间可控的预测。

Result: MCMeshGAN在几何精度和临床重要的直径估算方面均优于现有方法，在新构建的主动脉瘤网格数据集上通过广泛实验验证了其优越性。

Conclusion: 作为个性化3D疾病轨迹建模的一个重要进步，MCMeshGAN为临床可落地的预测框架提供了可靠基础。

Abstract: Personalized, accurate prediction of aortic aneurysm progression is essential
for timely intervention but remains challenging due to the need to model both
subtle local deformations and global anatomical changes within complex 3D
geometries. We propose MCMeshGAN, the first multimodal conditional mesh-to-mesh
generative adversarial network for 3D aneurysm growth prediction. MCMeshGAN
introduces a dual-branch architecture combining a novel local KNN-based
convolutional network (KCN) to preserve fine-grained geometric details and a
global graph convolutional network (GCN) to capture long-range structural
context, overcoming the over-smoothing limitations of deep GCNs. A dedicated
condition branch encodes clinical attributes (age, sex) and the target time
interval to generate anatomically plausible, temporally controlled predictions,
enabling retrospective and prospective modeling. We curated TAAMesh, a new
longitudinal thoracic aortic aneurysm mesh dataset consisting of 590 multimodal
records (CT scans, 3D meshes, and clinical data) from 208 patients. Extensive
experiments demonstrate that MCMeshGAN consistently outperforms
state-of-the-art baselines in both geometric accuracy and clinically important
diameter estimation. This framework offers a robust step toward clinically
deployable, personalized 3D disease trajectory modeling. The source code for
MCMeshGAN and the baseline methods is publicly available at
https://github.com/ImperialCollegeLondon/MCMeshGAN.

</details>


### [69] [Self-supervised structured object representation learning](https://arxiv.org/abs/2508.19864)
*Oussama Hadjerci,Antoine Letienne,Mohamed Abbas Hedjazi,Adel Hafiane*

Main category: cs.CV

TL;DR: 本研究提出了一种新型的自监督学习方法，通过ProtoScale模块实现多尺度的视觉要素捕捉，相较于传统方法DINO表现更佳。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法在捕捉场景的结构化表示方面有所局限，特别是在细粒度视觉任务的表现不足。

Method: 提出了一种结合语义分组、实例级分离和层次结构化的新型自监督方法，ProtoScale模块用于捕捉多尺度的场景信息，同时保留全场景的上下文。

Result: 方法在下游目标检测任务（如COCO与UA-DETRAC子集）中表现优异，甚至在有限标注数据和较少微调轮次的情况下，也超越了现有的最先进方法。

Conclusion: 利用ProtoScale模块的方法能够有效学习基于对象的表示，在提升监督目标检测任务表现的同时，展现了更具潜力的自监督学习能力。

Abstract: Self-supervised learning (SSL) has emerged as a powerful technique for
learning visual representations. While recent SSL approaches achieve strong
results in global image understanding, they are limited in capturing the
structured representation in scenes. In this work, we propose a self-supervised
approach that progressively builds structured visual representations by
combining semantic grouping, instance level separation, and hierarchical
structuring. Our approach, based on a novel ProtoScale module, captures visual
elements across multiple spatial scales. Unlike common strategies like DINO
that rely on random cropping and global embeddings, we preserve full scene
context across augmented views to improve performance in dense prediction
tasks. We validate our method on downstream object detection tasks using a
combined subset of multiple datasets (COCO and UA-DETRAC). Experimental results
show that our method learns object centric representations that enhance
supervised object detection and outperform the state-of-the-art methods, even
when trained with limited annotated data and fewer fine-tuning epochs.

</details>


### [70] [TrajFusionNet: Pedestrian Crossing Intention Prediction via Fusion of Sequential and Visual Trajectory Representations](https://arxiv.org/abs/2508.19866)
*François G. Landry,Moulay A. Akhloufi*

Main category: cs.CV

TL;DR: TrajFusionNet是一种用于预测行人过马路意图的创新变压器模型，结合行人轨迹和车辆速度预测，在推断时间和性能上优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术应用于公共道路，预测行人是否过马路成为重要的研究方向。

Method: 提出基于变压器的TrajFusionNet模型，结合观察和预测轨迹及速度的序列表示（SAM）和基于图像的视觉表示（VAM）。

Result: 在三个主流数据集上取得了性能的最优结果，同时总推断时间低于现有方法。

Conclusion: TrajFusionNet模型利用少量轻量化特征实现快速、高精度的行人过马路意图预测，提升了自动驾驶场景的安全性和效率。

Abstract: With the introduction of vehicles with autonomous capabilities on public
roads, predicting pedestrian crossing intention has emerged as an active area
of research. The task of predicting pedestrian crossing intention involves
determining whether pedestrians in the scene are likely to cross the road or
not. In this work, we propose TrajFusionNet, a novel transformer-based model
that combines future pedestrian trajectory and vehicle speed predictions as
priors for predicting crossing intention. TrajFusionNet comprises two branches:
a Sequence Attention Module (SAM) and a Visual Attention Module (VAM). The SAM
branch learns from a sequential representation of the observed and predicted
pedestrian trajectory and vehicle speed. Complementarily, the VAM branch
enables learning from a visual representation of the predicted pedestrian
trajectory by overlaying predicted pedestrian bounding boxes onto scene images.
By utilizing a small number of lightweight modalities, TrajFusionNet achieves
the lowest total inference time (including model runtime and data
preprocessing) among current state-of-the-art approaches. In terms of
performance, it achieves state-of-the-art results across the three most
commonly used datasets for pedestrian crossing intention prediction.

</details>


### [71] [Sky Background Building of Multi-objective Fiber spectra Based on Mutual Information Network](https://arxiv.org/abs/2508.19875)
*Hui Zhang,Jianghui Cai,Haifeng Yang,Ali Luo,Yuqing Yang,Xiao Kong,Zhichao Ding,Lichan Zhou,Qin Han*

Main category: cs.CV

TL;DR: 提出了一种利用互信息和增量训练的天空背景建模方法（SMI），通过光谱板上的所有光纤光谱，提供更准确的天空背景估计。


<details>
  <summary>Details</summary>
Motivation: 当前的背景扣除方法主要基于天空光纤光谱构建超级天空，缺乏对目标周围环境的建模能力。本研究旨在解决这一问题。

Method: 提出基于互信息和增量训练方法的天空背景估计模型（SMI），构建包含两部分网络：①通过波长校准模块提取光谱中天空特征，并校正特征偏移；②通过最大化和最小化互信息的方法，捕获公共成分并获取个性化天空背景。

Result: 实验表明，SMI在观测期间，尤其在蓝端，能更好地实现个性化天空背景估计。

Conclusion: SMI模型有效解决了目前天空背景扣除方法的局限性，可以更精确地估计目标的个性化天空背景。

Abstract: Sky background subtraction is a critical step in Multi-objective Fiber
spectra process. However, current subtraction relies mainly on sky fiber
spectra to build Super Sky. These average spectra are lacking in the modeling
of the environment surrounding the objects. To address this issue, a sky
background estimation model: Sky background building based on Mutual
Information (SMI) is proposed. SMI based on mutual information and incremental
training approach. It utilizes spectra from all fibers in the plate to estimate
the sky background. SMI contains two main networks, the first network applies a
wavelength calibration module to extract sky features from spectra, and can
effectively solve the feature shift problem according to the corresponding
emission position. The second network employs an incremental training approach
to maximize mutual information between representations of different spectra to
capturing the common component. Then, it minimizes the mutual information
between adjoining spectra representations to obtain individual components. This
network yields an individual sky background at each location of the object. To
verify the effectiveness of the method in this paper, we conducted experiments
on the spectra of LAMOST. Results show that SMI can obtain a better object sky
background during the observation, especially in the blue end.

</details>


### [72] [Multispectral LiDAR data for extracting tree points in urban and suburban areas](https://arxiv.org/abs/2508.19881)
*Narges Takhtkeshha,Gabriele Mazzacca,Fabio Remondino,Juha Hyyppä,Gottfried Mandlburger*

Main category: cs.CV

TL;DR: 该研究探讨了利用多光谱激光雷达（MS-LiDAR）和深度学习模型提取城市树木点云的方法，发现结合光谱和空间数据可以显著提高精度。


<details>
  <summary>Details</summary>
Motivation: 人们需要实时监测城市树木的变化，以支持绿化政策并减少对电力基础设施的潜在风险。现有方法面临城市复杂环境和树木多样性的挑战。

Method: 研究通过评估三种深度学习模型（SPT、PTv3和PTv1）的表现，结合MS-LiDAR获取的3D空间和光谱数据，优化树木点云提取。

Result: SPT在时间效率和准确性方面表现最佳，其平均交并比（mIoU）达85.28%。结合伪归一化植被指数（pNDVI）和空间数据，将误差率比仅用空间信息减少了10.61个百分点。

Conclusion: 研究表明，结合MS-LiDAR和深度学习技术可以显著提高城市树木的提取精度，为树木资源管理提供更高效的解决方案。

Abstract: Monitoring urban tree dynamics is vital for supporting greening policies and
reducing risks to electrical infrastructure. Airborne laser scanning has
advanced large-scale tree management, but challenges remain due to complex
urban environments and tree variability. Multispectral (MS) light detection and
ranging (LiDAR) improves this by capturing both 3D spatial and spectral data,
enabling detailed mapping. This study explores tree point extraction using
MS-LiDAR and deep learning (DL) models. Three state-of-the-art models are
evaluated: Superpoint Transformer (SPT), Point Transformer V3 (PTv3), and Point
Transformer V1 (PTv1). Results show the notable time efficiency and accuracy of
SPT, with a mean intersection over union (mIoU) of 85.28%. The highest
detection accuracy is achieved by incorporating pseudo normalized difference
vegetation index (pNDVI) with spatial data, reducing error rate by 10.61
percentage points (pp) compared to using spatial information alone. These
findings highlight the potential of MS-LiDAR and DL to improve tree extraction
and further tree inventories.

</details>


### [73] [PersonaAnimator: Personalized Motion Transfer from Unconstrained Videos](https://arxiv.org/abs/2508.19895)
*Ziyun Qian,Runyu Xiao,Shuyuan Tu,Wei Xue,Dingkang Yang,Mingcheng Li,Dongliang Kou,Minghao Han,Zizhi Chen,Lihua Zhang*

Main category: cs.CV

TL;DR: 提出了一种新的任务：视频到视频的运动个性化，并引入PersonaAnimator框架和PersonaVid数据集，以解决现有运动生成方法在风格、数据需求和物理合理性上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前运动生成方法在捕捉运动风格、依赖动作捕捉数据和物理合理性方面存在不足。

Method: 提出PersonaAnimator框架，通过非约束视频学习个性化运动模式，同时引入PersonaVid数据集和物理感知的运动风格正则机制。

Result: 实验表明，PersonaAnimator在运动转移任务中表现优于现有方法，并在视频到视频的运动个性化任务上树立了新的基准。

Conclusion: 新方法不仅提高了运动生成的个性化和表达力，还提高了生成结果的物理合理性，为相关领域提供了重要进展。

Abstract: Recent advances in motion generation show remarkable progress. However,
several limitations remain: (1) Existing pose-guided character motion transfer
methods merely replicate motion without learning its style characteristics,
resulting in inexpressive characters. (2) Motion style transfer methods rely
heavily on motion capture data, which is difficult to obtain. (3) Generated
motions sometimes violate physical laws. To address these challenges, this
paper pioneers a new task: Video-to-Video Motion Personalization. We propose a
novel framework, PersonaAnimator, which learns personalized motion patterns
directly from unconstrained videos. This enables personalized motion transfer.
To support this task, we introduce PersonaVid, the first video-based
personalized motion dataset. It contains 20 motion content categories and 120
motion style categories. We further propose a Physics-aware Motion Style
Regularization mechanism to enforce physical plausibility in the generated
motions. Extensive experiments show that PersonaAnimator outperforms
state-of-the-art motion transfer methods and sets a new benchmark for the
Video-to-Video Motion Personalization task.

</details>


### [74] [Hyperspectral Sensors and Autonomous Driving: Technologies, Limitations, and Opportunities](https://arxiv.org/abs/2508.19905)
*Imad Ali Shah,Jiarong Li,Roshan George,Tim Brophy,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 本文评估高光谱成像（HSI）在先进驾驶辅助系统（ADAS）和自动驾驶中的应用潜力，指出其技术尚未达到商业化要求，并提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探讨HSI如何通过超越传统RGB成像的光谱分辨能力，为ADAS/AD应用提供材料级别的场景理解。

Method: 回顾了当前HSI技术，分析了216种商用相机是否符合ADAS/AD的关键指标；同时检查了HSI数据集及其在语义分割、行人分离和恶劣天气感知等方面的应用。

Result: 仅有四款HSI相机满足性能指标且均不符合AEC-Q100温度标准。现有数据集在规模、光谱一致性和环境多样性方面存在局限，影响开发与验证。

Conclusion: 尽管高光谱成像展现了科研潜力，但商用化准备不足。需要更大规模、多样化的数据集及符合汽车标准的设备支持，以实现其在ADAS/AD中的实际应用。

Abstract: Hyperspectral imaging (HSI) offers a transformative sensing modality for
Advanced Driver Assistance Systems (ADAS) and autonomous driving (AD)
applications, enabling material-level scene understanding through fine spectral
resolution beyond the capabilities of traditional RGB imaging. This paper
presents the first comprehensive review of HSI for automotive applications,
examining the strengths, limitations, and suitability of current HSI
technologies in the context of ADAS/AD. In addition to this qualitative review,
we analyze 216 commercially available HSI and multispectral imaging cameras,
benchmarking them against key automotive criteria: frame rate, spatial
resolution, spectral dimensionality, and compliance with AEC-Q100 temperature
standards. Our analysis reveals a significant gap between HSI's demonstrated
research potential and its commercial readiness. Only four cameras meet the
defined performance thresholds, and none comply with AEC-Q100 requirements. In
addition, the paper reviews recent HSI datasets and applications, including
semantic segmentation for road surface classification, pedestrian separability,
and adverse weather perception. Our review shows that current HSI datasets are
limited in terms of scale, spectral consistency, the number of spectral
channels, and environmental diversity, posing challenges for the development of
perception algorithms and the adequate validation of HSI's true potential in
ADAS/AD applications. This review paper establishes the current state of HSI in
automotive contexts as of 2025 and outlines key research directions toward
practical integration of spectral imaging in ADAS and autonomous systems.

</details>


### [75] [Streamlining the Development of Active Learning Methods in Real-World Object Detection](https://arxiv.org/abs/2508.19906)
*Moussa Kassem Sbeyti,Nadja Klein,Michelle Karg,Christian Wirth,Sahin Albayrak*

Main category: cs.CV

TL;DR: 提出了一个新的度量标准对象集相似性（OSS），用于在对象检测中的活跃学习中提高计算效率和评价可靠性。


<details>
  <summary>Details</summary>
Motivation: 针对现有活跃学习方法在对象检测中的高计算成本与可靠性问题，特别是在如自动驾驶这样的实际应用中，传统方法需耗费大量GPU时间，同时评价结果也在不同验证集之间有所波动。

Method: 通过提出OSS指标，该指标用对象级特征来衡量训练集与目标域之间的相似性，从而不需要训练探测器即可量化活跃学习效果，还可以选择具有代表性的验证集进行稳定的评估。

Result: 利用OSS进行研究，使用三种自动驾驶数据集（KITTI、BDD100K、CODA）、两种探测器架构（EfficientDet、YOLOv3）和基于不确定性的活跃学习方法作为案例研究，验证了OSS的有效性。

Conclusion: OSS是一种与探测器无关的评价指标，通过减少无效方法训练并根据代表性验证集进行稳健评估，提供了一个实用的框架，能有效部署到实际活跃学习应用中。

Abstract: Active learning (AL) for real-world object detection faces computational and
reliability challenges that limit practical deployment. Developing new AL
methods requires training multiple detectors across iterations to compare
against existing approaches. This creates high costs for autonomous driving
datasets where the training of one detector requires up to 282 GPU hours.
Additionally, AL method rankings vary substantially across validation sets,
compromising reliability in safety-critical transportation systems. We
introduce object-based set similarity ($\mathrm{OSS}$), a metric that addresses
these challenges. $\mathrm{OSS}$ (1) quantifies AL method effectiveness without
requiring detector training by measuring similarity between training sets and
target domains using object-level features. This enables the elimination of
ineffective AL methods before training. Furthermore, $\mathrm{OSS}$ (2) enables
the selection of representative validation sets for robust evaluation. We
validate our similarity-based approach on three autonomous driving datasets
(KITTI, BDD100K, CODA) using uncertainty-based AL methods as a case study with
two detector architectures (EfficientDet, YOLOv3). This work is the first to
unify AL training and evaluation strategies in object detection based on object
similarity. $\mathrm{OSS}$ is detector-agnostic, requires only labeled object
crops, and integrates with existing AL pipelines. This provides a practical
framework for deploying AL in real-world applications where computational
efficiency and evaluation reliability are critical. Code is available at
https://mos-ks.github.io/publications/.

</details>


### [76] [Integrating SAM Supervision for 3D Weakly Supervised Point Cloud Segmentation](https://arxiv.org/abs/2508.19909)
*Lechun You,Zhonghua Wu,Weide Liu,Xulei Yang,Jun Cheng,Wei Zhou,Bharadwaj Veeravalli,Guosheng Lin*

Main category: cs.CV

TL;DR: 使用稀疏3D注解与2D基础模型生成的分割掩码结合，改进3D弱监督语义分割。


<details>
  <summary>Details</summary>
Motivation: 当前的3D语义分割方法难以处理因标注成本高和数据无序性导致的注释不足问题。此外，这些方法通常局限于3D领域，未利用2D与3D数据的互补性。

Method: 提出一种将2D基础模型生成的分割掩码与稀疏的3D注解相结合的方法，将这些2D掩码传播到3D空间。通过几何对应关系扩展3D掩码范围，并基于可靠的伪标签生成更多标签。

Result: 扩充3D标签池并提升3D弱监督分割性能。

Conclusion: 创新性地将有限的3D注释与2D基础模型能力相结合，显著提高了3D弱监督分割效率。

Abstract: Current methods for 3D semantic segmentation propose training models with
limited annotations to address the difficulty of annotating large, irregular,
and unordered 3D point cloud data. They usually focus on the 3D domain only,
without leveraging the complementary nature of 2D and 3D data. Besides, some
methods extend original labels or generate pseudo labels to guide the training,
but they often fail to fully use these labels or address the noise within them.
Meanwhile, the emergence of comprehensive and adaptable foundation models has
offered effective solutions for segmenting 2D data. Leveraging this
advancement, we present a novel approach that maximizes the utility of sparsely
available 3D annotations by incorporating segmentation masks generated by 2D
foundation models. We further propagate the 2D segmentation masks into the 3D
space by establishing geometric correspondences between 3D scenes and 2D views.
We extend the highly sparse annotations to encompass the areas delineated by 3D
masks, thereby substantially augmenting the pool of available labels.
Furthermore, we apply confidence- and uncertainty-based consistency
regularization on augmentations of the 3D point cloud and select the reliable
pseudo labels, which are further spread on the 3D masks to generate more
labels. This innovative strategy bridges the gap between limited 3D annotations
and the powerful capabilities of 2D foundation models, ultimately improving the
performance of 3D weakly supervised segmentation.

</details>


### [77] [WaveHiT-SR: Hierarchical Wavelet Network for Efficient Image Super-Resolution](https://arxiv.org/abs/2508.19927)
*Fayaz Ali,Muhammad Zawish,Steven Davy,Radu Timofte*

Main category: cs.CV

TL;DR: 本文提出了一种结合小波变换与分层Transformer框架的新方法，显著提升了图像超分辨率任务的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 目前基于Transformer的图像超分辨率方法受限于窗口自注意力机制的高计算复杂度，只能使用小而固定的窗口，从而限制了感受野范围。

Method: 通过将小波变换融入分层Transformer框架中，提出了自适应分层窗口机制捕捉多层次特征，并利用小波变换将图像分解为多个频率子带以关注不同细节和结构。

Result: 这种方法不仅减少了计算复杂度，还能在保留性能的同时提高效率。实验表明，改进后的SwinIR-Light、SwinIR-NG和SRFormer-Light模型具有更高的效率和较少的参数成本，取得了前沿的超分辨率结果。

Conclusion: WaveHiT-SR通过分层处理逐步重建高分辨率图像，同时利用小波变换实现细节增强，在效率和效果上达到了新的高度。

Abstract: Transformers have demonstrated promising performance in computer vision
tasks, including image super-resolution (SR). The quadratic computational
complexity of window self-attention mechanisms in many transformer-based SR
methods forces the use of small, fixed windows, limiting the receptive field.
In this paper, we propose a new approach by embedding the wavelet transform
within a hierarchical transformer framework, called (WaveHiT-SR). First, using
adaptive hierarchical windows instead of static small windows allows to capture
features across different levels and greatly improve the ability to model
long-range dependencies. Secondly, the proposed model utilizes wavelet
transforms to decompose images into multiple frequency subbands, allowing the
network to focus on both global and local features while preserving structural
details. By progressively reconstructing high-resolution images through
hierarchical processing, the network reduces computational complexity without
sacrificing performance. The multi-level decomposition strategy enables the
network to capture fine-grained information in lowfrequency components while
enhancing high-frequency textures. Through extensive experimentation, we
confirm the effectiveness and efficiency of our WaveHiT-SR. Our refined
versions of SwinIR-Light, SwinIR-NG, and SRFormer-Light deliver cutting-edge SR
results, achieving higher efficiency with fewer parameters, lower FLOPs, and
faster speeds.

</details>


### [78] [Reimagining Image Segmentation using Active Contour: From Chan Vese Algorithm into a Proposal Novel Functional Loss Framework](https://arxiv.org/abs/2508.19946)
*Gianluca Guzzetta*

Main category: cs.CV

TL;DR: 本文对图像分割的Chan-Vese算法进行全面研究，提出基于现代计算机视觉方法的分割损失函数，并通过实验验证效果。


<details>
  <summary>Details</summary>
Motivation: 研究旨在优化经典算法Chan-Vese在图像分割中的应用，探究其与现代计算机视觉方法结合的可能性。

Method: 基于Chan-Vese模型能量函数和偏微分方程的离散化方案，提出使用PyTorch.nn.ModuleLoss实现改进；并使用经典数据集进行性能对比。

Result: 提出的分割损失函数在某些常见计算机视觉分割数据集上表现优于传统方法。

Conclusion: 本文证明了结合现代方法的Chan-Vese算法能提升图像分割效率，并提供了文中使用的方法代码供研究者参考。

Abstract: In this paper, we present a comprehensive study and analysis of the Chan-Vese
algorithm for image segmentation. We employ a discretized scheme derived from
the empirical study of the Chan-Vese model's functional energy and its partial
differential equation based on its level set function. We provide a proof of
the results and an implementation using MATLAB. Leveraging modern computer
vision methodologies, we propose a functional segmentation loss based on active
contours, utilizing pytorch.nn.ModuleLoss and a level set based on the
Chan-Vese algorithm. We compare our results with common computer vision
segmentation datasets and evaluate the performance of classical loss functions
against our proposed method. All code and materials used are available at
https://github.com/gguzzy/chan_vese_functional_loss.

</details>


### [79] [Assessing the Geolocation Capabilities, Limitations and Societal Risks of Generative Vision-Language Models](https://arxiv.org/abs/2508.19967)
*Oliver Grainge,Sania Waheed,Jack Stilgoe,Michael Milford,Shoaib Ehsan*

Main category: cs.CV

TL;DR: 研究评估了25个最先进的视觉语言模型（VLMs）在多样化环境中的图像地理定位能力，并揭示了隐私风险。


<details>
  <summary>Details</summary>
Motivation: 图片地理定位技术具有广泛应用，但随着视觉语言模型的应用，潜在隐私风险增大。研究缺乏对生成型VLMs地理定位精度及风险的系统性评估。

Method: 综合评估了25个视觉语言模型在4个具备多样环境的基准数据集上的地理定位能力，研究其内部推理机制及性能极限。

Result: 当前视觉语言模型对一般街景图片表现不佳，但对社交媒体类图片达到61%的准确度。

Conclusion: 模型的性能揭示了其优势与局限性，同时强调了现阶段及未来可能的隐私问题与社会风险。

Abstract: Geo-localization is the task of identifying the location of an image using
visual cues alone. It has beneficial applications, such as improving disaster
response, enhancing navigation, and geography education. Recently,
Vision-Language Models (VLMs) are increasingly demonstrating capabilities as
accurate image geo-locators. This brings significant privacy risks, including
those related to stalking and surveillance, considering the widespread uses of
AI models and sharing of photos on social media. The precision of these models
is likely to improve in the future. Despite these risks, there is little work
on systematically evaluating the geolocation precision of Generative VLMs,
their limits and potential for unintended inferences. To bridge this gap, we
conduct a comprehensive assessment of the geolocation capabilities of 25
state-of-the-art VLMs on four benchmark image datasets captured in diverse
environments. Our results offer insight into the internal reasoning of VLMs and
highlight their strengths, limitations, and potential societal risks. Our
findings indicate that current VLMs perform poorly on generic street-level
images yet achieve notably high accuracy (61\%) on images resembling social
media content, raising significant and urgent privacy concerns.

</details>


### [80] [GS: Generative Segmentation via Label Diffusion](https://arxiv.org/abs/2508.20020)
*Yuhao Chen,Shubin Chen,Liang Lin,Guangrun Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新型的基于生成的图像分割框架GS，通过标签扩散直接生成分割掩码，在语言驱动分割任务上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统方法将语言驱动分割视作判别性问题，近期的扩散模型虽然引入了新概念但仍偏重图像处理，缺乏对标签生成本身的关注。

Method: 提出GS框架，通过标签扩散直接生成分割掩码，条件是输入图像和语言描述，从而以生成任务替代判别任务。

Result: 在Panoptic Narrative Grounding基准上，GS显著优于现有判别及扩散方法，达到了最新的性能水平。

Conclusion: GS框架将语言驱动分割重新定义为生成任务，通过显式控制显著提升了空间和语义保真度，为多模态分割任务提供了新思路。

Abstract: Language-driven image segmentation is a fundamental task in vision-language
understanding, requiring models to segment regions of an image corresponding to
natural language expressions. Traditional methods approach this as a
discriminative problem, assigning each pixel to foreground or background based
on semantic alignment. Recently, diffusion models have been introduced to this
domain, but existing approaches remain image-centric: they either (i) use image
diffusion models as visual feature extractors, (ii) synthesize segmentation
data via image generation to train discriminative models, or (iii) perform
diffusion inversion to extract attention cues from pre-trained image diffusion
models-thereby treating segmentation as an auxiliary process. In this paper, we
propose GS (Generative Segmentation), a novel framework that formulates
segmentation itself as a generative task via label diffusion. Instead of
generating images conditioned on label maps and text, GS reverses the
generative process: it directly generates segmentation masks from noise,
conditioned on both the input image and the accompanying language description.
This paradigm makes label generation the primary modeling target, enabling
end-to-end training with explicit control over spatial and semantic fidelity.
To demonstrate the effectiveness of our approach, we evaluate GS on Panoptic
Narrative Grounding (PNG), a representative and challenging benchmark for
multimodal segmentation that requires panoptic-level reasoning guided by
narrative captions. Experimental results show that GS significantly outperforms
existing discriminative and diffusion-based methods, setting a new
state-of-the-art for language-driven segmentation.

</details>


### [81] [Segmentation Assisted Incremental Test Time Adaptation in an Open World](https://arxiv.org/abs/2508.20029)
*Manogna Sreenivas,Soma Biswas*

Main category: cs.CV

TL;DR: 本文提出了一种新的增量测试时间适应框架，用于视觉语言模型，在测试过程中应对未见类别和领域的连续变化，并引入了一个无训练的分割辅助模块。


<details>
  <summary>Details</summary>
Motivation: 面对动态环境下未见对象和分布变化，传统模型的泛化能力受限，需要一种能适应测试中类别和领域同时变化的方法。

Method: 提出了新的ITTA基准，结合单图像TTA方法和主动标注技术，以分割辅助模块SegAssist改进样本选择，识别潜在未见类别的样本。

Result: 通过若干基准数据集的实验验证，SegAssist显著提升了VLM的性能，证明其在真实场景中持续适应新数据的能力。

Conclusion: SegAssist模块通过无训练地利用VLM的分割能力，有效提升增量测试时间适应框架的表现，为应对现实中的动态数据流提供了一种创新解决方案。

Abstract: In dynamic environments, unfamiliar objects and distribution shifts are often
encountered, which challenge the generalization abilities of the deployed
trained models. This work addresses Incremental Test Time Adaptation of Vision
Language Models, tackling scenarios where unseen classes and unseen domains
continuously appear during testing. Unlike traditional Test Time Adaptation
approaches, where the test stream comes only from a predefined set of classes,
our framework allows models to adapt simultaneously to both covariate and label
shifts, actively incorporating new classes as they emerge. Towards this goal,
we establish a new benchmark for ITTA, integrating single image TTA methods for
VLMs with active labeling techniques that query an oracle for samples
potentially representing unseen classes during test time. We propose a
segmentation assisted active labeling module, termed SegAssist, which is
training free and repurposes the segmentation capabilities of VLMs to refine
active sample selection, prioritizing samples likely to belong to unseen
classes. Extensive experiments on several benchmark datasets demonstrate the
potential of SegAssist to enhance the performance of VLMs in real world
scenarios, where continuous adaptation to emerging data is essential.
Project-page:https://manogna-s.github.io/segassist/

</details>


### [82] [OpenM3D: Open Vocabulary Multi-view Indoor 3D Object Detection without Human Annotations](https://arxiv.org/abs/2508.20063)
*Peng-Hao Hsu,Ke Zhang,Fu-En Wang,Tao Tu,Ming-Feng Li,Yu-Lun Liu,Albert Y. C. Chen,Min Sun,Cheng-Hao Kuo*

Main category: cs.CV

TL;DR: 本文提出了OpenM3D，一种无需人工标注训练的开放类别多视角室内3D目标检测器，其基于ImGeoNet模型2D诱导的体素特征进行单阶段检测，展示出在准确性和速度上的优越性能。


<details>
  <summary>Details</summary>
Motivation: 在3D对象检测中，采用图像的方法较点云方法探究较少，因此需要探索没有人工注释的开放式类别3D目标检测方法。

Method: OpenM3D通过3D伪框生成方法将2D片段组合成三维结构，采用图嵌技术生成伪框，并利用从2D片段中采样的多样化CLIP特征，与体素特征对齐。通过无类别3D定位损失与体素语义对齐损失进行联合训练。

Result: OpenM3D在ScanNet200和ARKitScenes室内基准上，以更高的准确性和速度超越现有方法，包括一种基于ViT CLIP的两阶段方法和基线多视角深度估计模型。

Conclusion: OpenM3D实现了无需人工标注的高效的开放类别3D目标检测，证明了其在准确性和速度上的优越性，展示了很好的检测前景。

Abstract: Open-vocabulary (OV) 3D object detection is an emerging field, yet its
exploration through image-based methods remains limited compared to 3D point
cloud-based methods. We introduce OpenM3D, a novel open-vocabulary multi-view
indoor 3D object detector trained without human annotations. In particular,
OpenM3D is a single-stage detector adapting the 2D-induced voxel features from
the ImGeoNet model. To support OV, it is jointly trained with a class-agnostic
3D localization loss requiring high-quality 3D pseudo boxes and a
voxel-semantic alignment loss requiring diverse pre-trained CLIP features. We
follow the training setting of OV-3DET where posed RGB-D images are given but
no human annotations of 3D boxes or classes are available. We propose a 3D
Pseudo Box Generation method using a graph embedding technique that combines 2D
segments into coherent 3D structures. Our pseudo-boxes achieve higher precision
and recall than other methods, including the method proposed in OV-3DET. We
further sample diverse CLIP features from 2D segments associated with each
coherent 3D structure to align with the corresponding voxel feature. The key to
training a highly accurate single-stage detector requires both losses to be
learned toward high-quality targets. At inference, OpenM3D, a highly efficient
detector, requires only multi-view images for input and demonstrates superior
accuracy and speed (0.3 sec. per scene) on ScanNet200 and ARKitScenes indoor
benchmarks compared to existing methods. We outperform a strong two-stage
method that leverages our class-agnostic detector with a ViT CLIP-based OV
classifier and a baseline incorporating multi-view depth estimator on both
accuracy and speed.

</details>


### [83] [Patch Progression Masked Autoencoder with Fusion CNN Network for Classifying Evolution Between Two Pairs of 2D OCT Slices](https://arxiv.org/abs/2508.20064)
*Philippe Zhang,Weili Jiang,Yihao Li,Jing Zhang,Sarah Matta,Yubo Tan,Hui Lin,Haoshen Wang,Jiangtian Pan,Hui Xu,Laurent Borderie,Alexandre Le Guilcher,Béatrice Cochener,Chubin Ou,Gwenolé Quellec,Mathieu Lamard*

Main category: cs.CV

TL;DR: 研究在MARIO挑战中提出了基于OCT扫描的个性化AMD治疗方法并取得前10名的成绩。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过OCT扫描监测湿性年龄相关性黄斑变性（AMD）的新生血管活动进展，从而为患者量身定制更有效的治疗方案。

Method: Task 1中使用融合CNN网络及模型集成来分类连续OCT截面进展；Task 2中提出了一种补丁进展掩码自动编码器，生成未来OCT并利用Task 1的解决方案进行进展预测。

Result: 研究在MARIO挑战的两个任务中均取得前10名的成绩。

Conclusion: 通过定制化算法，验证了基于OCT扫描预测湿性AMD进展的潜力，并展示了在该领域研究中的成效与未来应用潜力。

Abstract: Age-related Macular Degeneration (AMD) is a prevalent eye condition affecting
visual acuity. Anti-vascular endothelial growth factor (anti-VEGF) treatments
have been effective in slowing the progression of neovascular AMD, with better
outcomes achieved through timely diagnosis and consistent monitoring. Tracking
the progression of neovascular activity in OCT scans of patients with exudative
AMD allows for the development of more personalized and effective treatment
plans. This was the focus of the Monitoring Age-related Macular Degeneration
Progression in Optical Coherence Tomography (MARIO) challenge, in which we
participated. In Task 1, which involved classifying the evolution between two
pairs of 2D slices from consecutive OCT acquisitions, we employed a fusion CNN
network with model ensembling to further enhance the model's performance. For
Task 2, which focused on predicting progression over the next three months
based on current exam data, we proposed the Patch Progression Masked
Autoencoder that generates an OCT for the next exam and then classifies the
evolution between the current OCT and the one generated using our solution from
Task 1. The results we achieved allowed us to place in the Top 10 for both
tasks. Some team members are part of the same organization as the challenge
organizers; therefore, we are not eligible to compete for the prize.

</details>


### [84] [PAUL: Uncertainty-Guided Partition and Augmentation for Robust Cross-View Geo-Localization under Noisy Correspondence](https://arxiv.org/abs/2508.20066)
*Zheng Li,Yanming Guo,WenZhe Liu,Xueyi Zhang,Zhaoyun Ding,Long Xu,Mingrui Lao*

Main category: cs.CV

TL;DR: 研究提出了一个名为PAUL的新框架，专注解决跨视角地理定位任务中的GPS偏移问题，通过不确定性学习来分区和增强训练数据。


<details>
  <summary>Details</summary>
Motivation: 当前的跨视角地理定位方法假设训练中图像对的完美对齐，但实际场景中GPS偏移导致这种假设常常不成立，这种情况目前的研究很少关注。

Method: 提出PAUL框架，通过不确定性感知的协同增强和证据协同训练，基于不确定性分区和增强训练数据，为高置信度区域提高监督质量，并抑制对齐错误带来的噪声影响。

Result: PAUL框架在多个噪声比例实验中表现优于其他竞争方法，验证了其有效性。

Conclusion: PAUL通过结合数据不确定性和损失差异，提供了新的方法应对跨视角地理定位中的对齐噪声问题，为实际应用提供了更坚实的解决方案。

Abstract: Cross-view geo-localization is a critical task for UAV navigation, event
detection, and aerial surveying, as it enables matching between drone-captured
and satellite imagery. Most existing approaches embed multi-modal data into a
joint feature space to maximize the similarity of paired images. However, these
methods typically assume perfect alignment of image pairs during training,
which rarely holds true in real-world scenarios. In practice, factors such as
urban canyon effects, electromagnetic interference, and adverse weather
frequently induce GPS drift, resulting in systematic alignment shifts where
only partial correspondences exist between pairs. Despite its prevalence, this
source of noisy correspondence has received limited attention in current
research. In this paper, we formally introduce and address the Noisy
Correspondence on Cross-View Geo-Localization (NC-CVGL) problem, aiming to
bridge the gap between idealized benchmarks and practical applications. To this
end, we propose PAUL (Partition and Augmentation by Uncertainty Learning), a
novel framework that partitions and augments training data based on estimated
data uncertainty through uncertainty-aware co-augmentation and evidential
co-training. Specifically, PAUL selectively augments regions with high
correspondence confidence and utilizes uncertainty estimation to refine feature
learning, effectively suppressing noise from misaligned pairs. Distinct from
traditional filtering or label correction, PAUL leverages both data uncertainty
and loss discrepancy for targeted partitioning and augmentation, thus providing
robust supervision for noisy samples. Comprehensive experiments validate the
effectiveness of individual components in PAUL,which consistently achieves
superior performance over other competitive noisy-correspondence-driven methods
in various noise ratios.

</details>


### [85] [Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies](https://arxiv.org/abs/2508.20072)
*Zhixuan Liang,Yizhuo Li,Tianshuo Yang,Chengyue Wu,Sitong Mao,Liuao Pei,Xiaokang Yang,Jiangmiao Pang,Yao Mu,Ping Luo*

Main category: cs.CV

TL;DR: 提出了一种新的离散扩散VLA模型，使用离散扩散方法提升机器人动作生成的效率与一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有VLA模型固定解码顺序和外部模块对统一性和可扩展性的限制。

Method: 提出一个单一转换器政策，将动作离散成块并通过离散扩散建模，结合VLM的离散标记接口进行训练和改进。

Result: 模型在多个数据集上显著提升性能，例如LIBERO上的96.3%平均SR，SimplerEnv Fractal上的71.2%视觉匹配率等表现。

Conclusion: 离散扩散动作解码器提升了动作建模的精确度、一致性和扩展性，为更大规模VLA模型的设计奠定基础。

Abstract: Vision-Language-Action (VLA) models adapt large vision-language backbones to
map images and instructions to robot actions. However, prevailing VLA decoders
either generate actions autoregressively in a fixed left-to-right order or
attach continuous diffusion or flow matching heads outside the backbone,
demanding specialized training and iterative sampling that hinder a unified,
scalable architecture. We present Discrete Diffusion VLA, a single-transformer
policy that models discretized action chunks with discrete diffusion and is
trained with the same cross-entropy objective as the VLM backbone. The design
retains diffusion's progressive refinement paradigm while remaining natively
compatible with the discrete token interface of VLMs. Our method achieves an
adaptive decoding order that resolves easy action elements before harder ones
and uses secondary remasking to revisit uncertain predictions across refinement
rounds, which improves consistency and enables robust error correction. This
unified decoder preserves pretrained vision language priors, supports parallel
decoding, breaks the autoregressive bottleneck, and reduces the number of
function evaluations. Discrete Diffusion VLA achieves 96.3% avg. SR on LIBERO,
71.2% visual matching on SimplerEnv Fractal and 49.3% overall on SimplerEnv
Bridge, improving over both autoregressive and continuous diffusion baselines.
These findings indicate that discrete-diffusion action decoder supports precise
action modeling and consistent training, laying groundwork for scaling VLA to
larger models and datasets.

</details>


### [86] [Seam360GS: Seamless 360° Gaussian Splatting from Real-World Omnidirectional Images](https://arxiv.org/abs/2508.20080)
*Changha Shin,Woong Oh Cho,Seon Joo Kim*

Main category: cs.CV

TL;DR: 提出了一种新型校准框架，将双鱼眼相机模型整合到3D高斯喷射管道中，用于生成无缺陷的360度全景图像。


<details>
  <summary>Details</summary>
Motivation: 针对双鱼眼相机因镜头分离和角度变形导致全景图像质量欠佳的问题，开发了一种改进方法以提升图像渲染效果。

Method: 构建了一种框架，通过联合优化3D高斯参数与校准变量（包括镜头间隙和角度变形），实现对双鱼眼相机视觉伪影的逼真模拟和无缝全景图像的合成。

Result: 实验验证表明，该方法在真实数据集上的渲染效果优于现有的360度渲染模型，可以从不完美输入生成无缺陷的全景图像。

Conclusion: 新框架显著提高了双鱼眼相机生成的全景图像质量，为虚拟现实、机器人和自动导航领域提供了新的解决方案。

Abstract: 360-degree visual content is widely shared on platforms such as YouTube and
plays a central role in virtual reality, robotics, and autonomous navigation.
However, consumer-grade dual-fisheye systems consistently yield imperfect
panoramas due to inherent lens separation and angular distortions. In this
work, we introduce a novel calibration framework that incorporates a
dual-fisheye camera model into the 3D Gaussian splatting pipeline. Our approach
not only simulates the realistic visual artifacts produced by dual-fisheye
cameras but also enables the synthesis of seamlessly rendered 360-degree
images. By jointly optimizing 3D Gaussian parameters alongside calibration
variables that emulate lens gaps and angular distortions, our framework
transforms imperfect omnidirectional inputs into flawless novel view synthesis.
Extensive evaluations on real-world datasets confirm that our method produces
seamless renderings-even from imperfect images-and outperforms existing
360-degree rendering models.

</details>


### [87] [AudioStory: Generating Long-Form Narrative Audio with Large Language Models](https://arxiv.org/abs/2508.20088)
*Yuxin Guo,Teng Wang,Yuying Ge,Shijie Ma,Yixiao Ge,Wei Zou,Ying Shan*

Main category: cs.CV

TL;DR: 本文提出AudioStory，一种结合大语言模型（LLMs）和文本到音频（TTA）生成系统的框架，用于生成结构化的长篇叙事音频，超越现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到音频生成技术在短音频合成领域表现优异，但在生成长篇叙事音频时存在时间连贯性和组合推理的挑战。

Method: AudioStory通过引入大语言模型将复杂叙事任务分解为有序的子任务，并采用解耦桥接机制和端到端训练方式，实现跨事件语义对齐与音频生成的整合。

Result: AudioStory在单一音频生成和叙事音频生成任务中表现优于现有基线模型，在指令遵循能力和音频质量上都有明显提升。

Conclusion: 通过统一的框架和性能优化，AudioStory有效解决了长篇叙事音频生成中的关键问题，为文本到音频研究领域提供了新的基准和可能性。

Abstract: Recent advances in text-to-audio (TTA) generation excel at synthesizing short
audio clips but struggle with long-form narrative audio, which requires
temporal coherence and compositional reasoning. To address this gap, we propose
AudioStory, a unified framework that integrates large language models (LLMs)
with TTA systems to generate structured, long-form audio narratives. AudioStory
possesses strong instruction-following reasoning generation capabilities. It
employs LLMs to decompose complex narrative queries into temporally ordered
sub-tasks with contextual cues, enabling coherent scene transitions and
emotional tone consistency. AudioStory has two appealing features: (1)
Decoupled bridging mechanism: AudioStory disentangles LLM-diffuser
collaboration into two specialized components, i.e., a bridging query for
intra-event semantic alignment and a residual query for cross-event coherence
preservation. (2) End-to-end training: By unifying instruction comprehension
and audio generation within a single end-to-end framework, AudioStory
eliminates the need for modular training pipelines while enhancing synergy
between components. Furthermore, we establish a benchmark AudioStory-10K,
encompassing diverse domains such as animated soundscapes and natural sound
narratives. Extensive experiments show the superiority of AudioStory on both
single-audio generation and narrative audio generation, surpassing prior TTA
baselines in both instruction-following ability and audio fidelity. Our code is
available at https://github.com/TencentARC/AudioStory

</details>


### [88] [Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors](https://arxiv.org/abs/2508.20089)
*Ross J Gardiner,Guillaume Mougeot,Sareh Rowlands,Benno I Simmons,Flemming Helsing,Toke Thomas Høye*

Main category: cs.CV

TL;DR: 研究提出了一种结合专家标注数据和知识蒸馏的轻量化分类方法，解决昆虫图像分类中的域转移问题，并在丹麦飞蛾的图像分类任务中取得了高效和精准的结果。


<details>
  <summary>Details</summary>
Motivation: 基于自动相机系统的飞蛾（Lepidoptera）图像标注对理解昆虫数量下降至关重要，但领域差异导致准确分类极具挑战性。

Method: 提出了一种轻量级分类方法，将包含有限专家标注的野外数据与高性能BioCLIP2预训练模型通过知识蒸馏融入ConvNeXt-tiny架构中。

Result: 在AMI相机捕获的101种丹麦飞蛾图像上，BioCLIP2的表现优于其他方法，而蒸馏生成的轻量模型在保持相近准确率的同时大幅降低了计算成本。

Conclusion: 研究为高效的昆虫监测系统开发提供了实践指南，并减小了领域差异对细粒度分类的影响。

Abstract: Labelling images of Lepidoptera (moths) from automated camera systems is
vital for understanding insect declines. However, accurate species
identification is challenging due to domain shifts between curated images and
noisy field imagery. We propose a lightweight classification approach,
combining limited expert-labelled field data with knowledge distillation from
the high-performance BioCLIP2 foundation model into a ConvNeXt-tiny
architecture. Experiments on 101 Danish moth species from AMI camera systems
demonstrate that BioCLIP2 substantially outperforms other methods and that our
distilled lightweight model achieves comparable accuracy with significantly
reduced computational cost. These insights offer practical guidelines for the
development of efficient insect monitoring systems and bridging domain gaps for
fine-grained classification.

</details>


### [89] [CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning](https://arxiv.org/abs/2508.20096)
*Zeyi Sun,Yuhang Cao,Jianze Liang,Qiushi Sun,Ziyu Liu,Zhixiong Zhang,Yuhang Zang,Xiaoyi Dong,Kai Chen,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: 本文提出了CODA框架，将通用规划器(Cerebrum)和专业执行器(Cerebellum)相结合，解决了自动化GUI代理在科学计算领域中的规划与执行的矛盾问题。


<details>
  <summary>Details</summary>
Motivation: 当前GUI代理在科学领域面临长远规划与精确执行之间的难题，现有方法在规划与执行能力之间存在权衡，并且数据稀缺性限制了其适应能力。

Method: 提出了CODA，一个可训练的组合框架，通过两阶段流程训练。第一阶段是利用每个科学应用的任务轨迹数据训练专家规划器；第二阶段则基于所有成功的专家轨迹进行监督微调，整合通用规划能力。

Result: 在ScienceBoard基准测试中的四个应用中表现显著优于基线模型，并成为开放源代码模型中的最新技术水平。

Conclusion: CODA框架成功实现了跨领域通用规划和可靠执行能力，填补了现有静态方法的不足。

Abstract: Autonomous agents for Graphical User Interfaces (GUIs) face significant
challenges in specialized domains such as scientific computing, where both
long-horizon planning and precise execution are required. Existing approaches
suffer from a trade-off: generalist agents excel at planning but perform poorly
in execution, while specialized agents demonstrate the opposite weakness.
Recent compositional frameworks attempt to bridge this gap by combining a
planner and an actor, but they are typically static and non-trainable, which
prevents adaptation from experience. This is a critical limitation given the
scarcity of high-quality data in scientific domains. To address these
limitations, we introduce CODA, a novel and trainable compositional framework
that integrates a generalist planner (Cerebrum) with a specialist executor
(Cerebellum), trained via a dedicated two-stage pipeline. In the first stage,
Specialization, we apply a decoupled GRPO approach to train an expert planner
for each scientific application individually, bootstrapping from a small set of
task trajectories. In the second stage, Generalization, we aggregate all
successful trajectories from the specialized experts to build a consolidated
dataset, which is then used for supervised fine-tuning of the final planner.
This equips CODA with both robust execution and cross-domain generalization.
Evaluated on four challenging applications from the ScienceBoard benchmark,
CODA significantly outperforms baselines and establishes a new state of the art
among open-source models.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [90] [MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts](https://arxiv.org/abs/2508.19268)
*Qing Wang,Xue Han,Jiahui Wang,Lehao Xing,Qian Hu,Lianlian Zhang,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: 提出了一种名为MultiPL-MoE的模型，旨在通过混合专家模型提升基础LLMs在多编程语言生成任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 多编程语言代码生成是一个极具挑战性的任务，作者希望在有限计算资源下，提升LLMs在多编程语言生成中的表现。

Method: 提出了MultiPL-MoE模型，结合了基于Token和Segment的混合专家模型。其中Token级MoE使用了共享专家和门控权重归一化，而Segment级MoE设计了滑动窗口分割输入序列和专家选择最佳段的路由策略。

Result: 实验结果表明MultiPL-MoE模型的有效性。

Conclusion: MultiPL-MoE通过优化专家选择机制和对编程语言上下文模式的更好捕捉，显著提升了多编程语言生成的性能。

Abstract: Despite LLMs' excellent code creation capabilities, multilingual code
generation remains extremely challenging. To address this, we intent to improve
the multi-programming-lingual (MultiPL) performance of the base LLMs while
retaining the most popular ones using restricted computational resources. We
consider MultiPL to be a special case of multiple natural languages and propose
a MultiPL extension of LLMs utilizing a hybrid mixture of experts (MoE), called
MultiPL-MoE. Specifically, MultiPL-MoE combines two paired MoEs to optimize
expert selection at both the token and segment levels. The token-level MoE is a
standard upcycling MoE structure with a shared expert and a novel gate weight
normalization approach that aids in the final fusion with the segment-level
MoE. The segment-level MoE incorporates two innovative designs to better
capture the syntactic structure and contextual patterns of programming
languages: First, using a sliding window to partition the input token sequence
into multiple segments; Then, adopting an expert-choice routing strategy that
allows experts to select the top-k segments. The results of the experiment
proved the effectiveness of MultiPL-MoE.

</details>


### [91] [Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English](https://arxiv.org/abs/2508.19270)
*Nguyen Huu Nhat Minh,Tran Nguyen Anh,Truong Dinh Dung,Vo Van Nam,Le Pham Tuyen*

Main category: cs.CL

TL;DR: 本文提出了一种新的双语语音识别方法，用于解决越南语和英语的语音识别挑战，尤其是在音素的对齐和识别上。


<details>
  <summary>Details</summary>
Motivation: 越南语和英语在语音系统中差异显著：越南语依赖声调区分词义，而英语具有强调模式和非标准发音，导致双语语音中音素对齐困难。

Method: 提出构建一个新的双语音素集以平衡两种语言间的差异，并设计了基于PhoWhisper预训练编码器的端到端系统来改善音素识别。

Result: 实验表明，该方法提高了双语（特别是越南语与英语混合）语音识别的准确性。

Conclusion: 该研究不仅成功优化了双语语音识别性能，还为具有声调和重音复杂性的语言音素识别提供了坚实框架。

Abstract: Cross-lingual phoneme recognition has emerged as a significant challenge for
accurate automatic speech recognition (ASR) when mixing Vietnamese and English
pronunciations. Unlike many languages, Vietnamese relies on tonal variations to
distinguish word meanings, whereas English features stress patterns and
non-standard pronunciations that hinder phoneme alignment between the two
languages. To address this challenge, we propose a novel bilingual speech
recognition approach with two primary contributions: (1) constructing a
representative bilingual phoneme set that bridges the differences between
Vietnamese and English phonetic systems; (2) designing an end-to-end system
that leverages the PhoWhisper pre-trained encoder for deep high-level
representations to improve phoneme recognition. Our extensive experiments
demonstrate that the proposed approach not only improves recognition accuracy
in bilingual speech recognition for Vietnamese but also provides a robust
framework for addressing the complexities of tonal and stress-based phoneme
recognition

</details>


### [92] [Rethinking Reasoning in LLMs: Neuro-Symbolic Local RetoMaton Beyond ICL and CoT](https://arxiv.org/abs/2508.19271)
*Rushitha Santhoshi Mamidala,Anshuman Chhabra,Ankur Mali*

Main category: cs.CL

TL;DR: 提出了一种基于局部加权有限自动机（WFA）的RetoMaton变体，通过从外部领域语料构建任务适应性自动机，改进大语言模型（LLMs）在推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的提示式推理方法（例如链式推理CoT和上下文学习ICL）在模型输出的稳定性和可解释性方面存在问题，因此需要引入一种更稳定、可追溯的方法。

Method: 作者扩展了RetoMaton框架，用局部任务适应的加权有限自动机（WFA）替代了全局的数据存储，从而支持基于结构化和符号化的检索。

Result: 在使用两种预训练大模型（LLaMA-3.2-1B和Gemma-3-1B-PT）进行的三个推理任务（TriviaQA、GSM8K、MMLU）测试中，新方法相比基础模型和提示方法提升了性能，并实现了透明、可重复的检索动态。

Conclusion: 该研究展示了通过轻量级的自动机引导记忆实现现代LLMs可信符号推理的潜力，为领域迁移和互操作性提供了新的方向。

Abstract: Prompt-based reasoning strategies such as Chain-of-Thought (CoT) and
In-Context Learning (ICL) have become widely used for eliciting reasoning
capabilities in large language models (LLMs). However, these methods rely on
fragile, implicit mechanisms often yielding inconsistent outputs across seeds,
formats, or minor prompt variations making them fundamentally unreliable for
tasks requiring stable, interpretable reasoning. In contrast, automata-based
neuro-symbolic frameworks like RetoMaton offer a more structured and
trustworthy alternative by grounding retrieval in symbolic memory with
deterministic transitions. In this work, we extend RetoMaton by replacing its
global datastore with a local, task-adaptive Weighted Finite Automaton (WFA),
constructed directly from external domain corpora. This local automaton
structure promotes robust, context-aware retrieval while preserving symbolic
traceability and low inference overhead. Unlike prompting, which entangles
context and memory in opaque ways, our approach leverages the explicit
structure of WFAs to provide verifiable and modular retrieval behavior, making
it better suited for domain transfer and interoperability. We evaluate this
local RetoMaton variant on two pretrained LLMs LLaMA-3.2-1B and Gemma-3-1B-PT
across three reasoning tasks: TriviaQA (reading comprehension), GSM8K
(multi-step math), and MMLU (domain knowledge). Compared to the base model and
prompting-based methods, augmenting these setups with local RetoMaton
consistently improves performance while enabling transparent and reproducible
retrieval dynamics. Our results highlight a promising shift toward trustworthy,
symbolic reasoning in modern LLMs via lightweight, automaton-guided memory.

</details>


### [93] [RAGAPHENE: A RAG Annotation Platform with Human Enhancements and Edits](https://arxiv.org/abs/2508.19272)
*Kshitij Fadnis,Sara Rosenthal,Maeda Hanafi,Yannis Katsis,Marina Danilevsky*

Main category: cs.CL

TL;DR: 本文引入RAGAPHENE，一种用于标注和评估LLM多轮RAG对话的工具，由约40名标注者成功构建了数千个真实世界的对话。


<details>
  <summary>Details</summary>
Motivation: 研发一种工具以产生高质量的多轮RAG对话数据，用于评估和基准测试LLMs，以解决生成事实性错误信息的问题。

Method: 提出了RAGAPHENE，一个聊天式标注平台，允许标注者模拟真实对话进行数据构建和评估。

Result: RAGAPHENE已被约40名标注者使用，用于创建数千条真实的对话数据。

Conclusion: RAGAPHENE是一种有效的工具，能为多轮RAG对话的研究提供真实场景下的优质数据支持。

Abstract: Retrieval Augmented Generation (RAG) is an important aspect of conversing
with Large Language Models (LLMs) when factually correct information is
important. LLMs may provide answers that appear correct, but could contain
hallucinated information. Thus, building benchmarks that can evaluate LLMs on
multi-turn RAG conversations has become an increasingly important task.
Simulating real-world conversations is vital for producing high quality
evaluation benchmarks. We present RAGAPHENE, a chat-based annotation platform
that enables annotators to simulate real-world conversations for benchmarking
and evaluating LLMs. RAGAPHENE has been successfully used by approximately 40
annotators to build thousands of real-world conversations.

</details>


### [94] [Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis](https://arxiv.org/abs/2508.19274)
*Yue Chu*

Main category: cs.CL

TL;DR: 论文探讨了如何利用预训练语言模型和机器学习技术，将口头尸检（VA）中叙述部分的信息用于死因分类，研究表明，基于叙述的分类表现优于基于问题的传统方法，并通过多模态策略进一步提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 在没有民事登记和生命统计的国家，口头尸检（VA）是一种估计死因并为政策提供建议的重要手段。目前的自动化VA方法只利用结构化问题信息，忽略了叙述内容，作者希望探讨如何利用这些未被充分利用的叙述信息，提高死因分类的性能。

Method: 利用南非的经验数据，采用预训练语言模型（PLM）进行针对性微调，结合叙述信息与问题信息进行多模态融合策略研究，并评估模型在死因分类中的表现。同时，分析医生对VA材料信息充分性的感知及其对分类准确性的影响。

Result: 单纯利用叙述，基于Transformer的语言模型可优于传统基于问题的算法，尤其是在非传染性疾病识别方面。多模态策略通过结合叙述与问题信息，进一步提高分类性能，证实每种模式都有其独特贡献且能捕捉到对方未包含的信息。

Conclusion: 叙述部分在死因分类中具有重要价值。论文强调需要更多来自多样化地区的高质量数据用于PLM/ML方法的训练与微调，提出了对VA工具及访谈重新设计的必要性，以进一步改进死因分类方法。

Abstract: In countries without civil registration and vital statistics, verbal autopsy
(VA) is a critical tool for estimating cause of death (COD) and inform policy
priorities. In VA, interviewers ask proximal informants for details on the
circumstances preceding a death, in the form of unstructured narratives and
structured questions. Existing automated VA cause classification algorithms
only use the questions and ignore the information in the narratives. In this
thesis, we investigate how the VA narrative can be used for automated COD
classification using pretrained language models (PLMs) and machine learning
(ML) techniques. Using empirical data from South Africa, we demonstrate that
with the narrative alone, transformer-based PLMs with task-specific fine-tuning
outperform leading question-only algorithms at both the individual and
population levels, particularly in identifying non-communicable diseases. We
explore various multimodal fusion strategies combining narratives and questions
in unified frameworks. Multimodal approaches further improve performance in COD
classification, confirming that each modality has unique contributions and may
capture valuable information that is not present in the other modality. We also
characterize physician-perceived information sufficiency in VA. We describe
variations in sufficiency levels by age and COD and demonstrate that
classification accuracy is affected by sufficiency for both physicians and
models. Overall, this thesis advances the growing body of knowledge at the
intersection of natural language processing, epidemiology, and global health.
It demonstrates the value of narrative in enhancing COD classification. Our
findings underscore the need for more high-quality data from more diverse
settings to use in training and fine-tuning PLM/ML methods, and offer valuable
insights to guide the rethinking and redesign of the VA instrument and
interview.

</details>


### [95] [FLAIRR-TS -- Forecasting LLM-Agents with Iterative Refinement and Retrieval for Time Series](https://arxiv.org/abs/2508.19279)
*Gunjan Jalori,Preetika Verma,Sercan Ö Arık*

Main category: cs.CL

TL;DR: 该论文提出了FLAIRR-TS框架，用于改进大语言模型(LLMs)在时间序列预测中的表现，通过优化提示生成并且无需复杂的预处理或微调。


<details>
  <summary>Details</summary>
Motivation: 目前将LLMs应用于时间序列预测需要大量的提示工程，以及繁琐的预处理和微调操作。而开发通用的、自适应的提示优化方法可以降低复杂度并提升预测效果。

Method: FLAIRR-TS利用预测代理(Forecaster-agent)和优化代理(Refiner-agent)构建自适应提示优化框架，基于初始提示预测结果，通过对过去输出和提取的类似数据进行分析迭代改进提示。

Result: 在多个测试数据集上，该框架在准确性上优于静态及检索增强型方法，并接近手工优化的专业提示效果。

Conclusion: FLAIRR-TS通过自适应提示优化免除了传统的调试工作，提供了一种高效且通用的方法，显著增强了大语言模型在时间序列预测中的能力。

Abstract: Time series Forecasting with large languagemodels (LLMs) requires bridging
numericalpatterns and natural language. Effective fore-casting on LLM often
relies on extensive pre-processing and fine-tuning.Recent studiesshow that a
frozen LLM can rival specializedforecasters when supplied with a carefully
en-gineered natural-language prompt, but craft-ing such a prompt for each task
is itself oner-ous and ad-hoc. We introduce FLAIRR-TS, atest-time prompt
optimization framework thatutilizes an agentic system: a
Forecaster-agentgenerates forecasts using an initial prompt,which is then
refined by a refiner agent, in-formed by past outputs and retrieved
analogs.This adaptive prompting generalizes across do-mains using creative
prompt templates andgenerates high-quality forecasts without inter-mediate code
generation.Experiments onbenchmark datasets show improved accuracyover static
prompting and retrieval-augmentedbaselines, approaching the performance
ofspecialized prompts.FLAIRR-TS providesa practical alternative to tuning,
achievingstrong performance via its agentic approach toadaptive prompt
refinement and retrieval.

</details>


### [96] [CORE: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning](https://arxiv.org/abs/2508.19282)
*Ziqiang Cui,Yunpeng Weng,Xing Tang,Peiyang Liu,Shiwei Li,Bowei He,Jiamin Chen,Xiuqiang He,Chen Ma*

Main category: cs.CL

TL;DR: CORE通过使用强化学习实现无损压缩上下文，有效支持RAG模型的端任务性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决RAG中包括过多检索文档导致的计算成本过高和现有文档压缩方法会损失端任务性能的问题。

Method: 提出CORE方法，使用强化学习（GRPO）优化压缩过程，以端任务性能作为回报信号，生成无损压缩的上下文摘要。

Result: 在四个数据集上进行了实验，CORE在压缩率达到3%的情况下，表现出色，不仅避免性能下降，还使EM分数平均提高3.3分。

Conclusion: CORE方法证明了通过深度强化学习进行上下文压缩能够显著提高RAG模型的效率和精确性，为相关领域问题提供了有力支持。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach to
enhance the timeliness of knowledge and the factual accuracy of responses in
Large Language Models (LLMs). However, the inclusion of excessive retrieved
documents substantially increases the input length, leading to higher
computational costs. Previous studies have attempted to compress retrieved
documents into shorter texts before in-context integration, but such methods
often compromise end-task performance. The lack of well-defined compression
targets forces many approaches to rely on fixed heuristics, which cannot
guarantee that the compressed content will effectively support the end task. To
address these limitations, we propose CORE, a novel method designed to achieve
lossless context compression for RAG. CORE employs reinforcement learning to
optimize the compression process without relying on predefined compression
labels. Specifically, it utilizes end-task performance as a reward signal and
applies Generalized Reinforcement Learning Policy Optimization (GRPO) to train
the compressor. This end-to-end training framework enables the compressor to
generate summaries that maximize the accuracy of answers generated by the LLM.
Extensive experiments on four datasets demonstrate the superiority of our
approach. With a high compression ratio of 3\%, our method not only avoids
performance degradation compared to prepending full documents across all
datasets but also improves the average Exact Match (EM) score by 3.3 points.
The code will be released soon.

</details>


### [97] [Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains](https://arxiv.org/abs/2508.19357)
*Peiran Zhou,Junnan Zhu,Yichen Shen,Ruoxi Yu*

Main category: cs.CL

TL;DR: 提出了一种称为CASC的新框架，旨在解决传统RAG在处理复杂领域多文档任务中的缺陷。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在复杂领域任务中的信息过载和低效综合问题，增强其准确性与可信度。

Method: 引入Context Analyzer & Synthesizer模块，通过精调的较小LLM执行关键信息提取、文档一致性检查、冲突解决及面向问题的结构化综合。

Result: 在SciDocs-QA数据集上的实验证明CASC相比于强基线模型具有显著的性能提升。

Conclusion: CASC框架有效改进了多文档任务处理中上下文综合的效率与答案准确性，为科学问答领域提供了重要的技术方案。

Abstract: Large Language Models (LLMs) excel in language tasks but are prone to
hallucinations and outdated knowledge. Retrieval-Augmented Generation (RAG)
mitigates these by grounding LLMs in external knowledge. However, in complex
domains involving multiple, lengthy, or conflicting documents, traditional RAG
suffers from information overload and inefficient synthesis, leading to
inaccurate and untrustworthy answers. To address this, we propose CASC
(Context-Adaptive Synthesis and Compression), a novel framework that
intelligently processes retrieved contexts. CASC introduces a Context Analyzer
& Synthesizer (CAS) module, powered by a fine-tuned smaller LLM, which performs
key information extraction, cross-document consistency checking and conflict
resolution, and question-oriented structured synthesis. This process transforms
raw, scattered information into a highly condensed, structured, and
semantically rich context, significantly reducing the token count and cognitive
load for the final Reader LLM. We evaluate CASC on SciDocs-QA, a new
challenging multi-document question answering dataset designed for complex
scientific domains with inherent redundancies and conflicts. Our extensive
experiments demonstrate that CASC consistently outperforms strong baselines.

</details>


### [98] [Reflective Agreement: Combining Self-Mixture of Agents with a Sequence Tagger for Robust Event Extraction](https://arxiv.org/abs/2508.19359)
*Fatemeh Haji,Mazal Bethany,Cho-Yu Jason Chiang,Anthony Rios,Peyman Najafirad*

Main category: cs.CL

TL;DR: 提出一种名为ARIS的混合方法，结合了多个自监督代理和序列标注器，用于提高事件抽取任务的表现。


<details>
  <summary>Details</summary>
Motivation: 传统模型虽然精确但召回率低，生成式大语言模型灵活但存在幻觉问题，因此需要一种兼具两者优点的新方法。

Method: 提出一种混合方法ARIS，结合了自监督代理模型、鉴别式序列标注器、结构共识、基于置信度的过滤及LLM反射推理模块。此外，还研究了分解指令微调方法。

Result: 实验证明，ARIS在三个基准数据集上均优于现有最先进的事件抽取方法。

Conclusion: ARIS有效改善了事件抽取的精确性和鲁棒性，为未来事件抽取任务提供了新的方法论。

Abstract: Event Extraction (EE) involves automatically identifying and extracting
structured information about events from unstructured text, including triggers,
event types, and arguments. Traditional discriminative models demonstrate high
precision but often exhibit limited recall, particularly for nuanced or
infrequent events. Conversely, generative approaches leveraging Large Language
Models (LLMs) provide higher semantic flexibility and recall but suffer from
hallucinations and inconsistent predictions. To address these challenges, we
propose Agreement-based Reflective Inference System (ARIS), a hybrid approach
combining a Self Mixture of Agents with a discriminative sequence tagger. ARIS
explicitly leverages structured model consensus, confidence-based filtering,
and an LLM reflective inference module to reliably resolve ambiguities and
enhance overall event prediction quality. We further investigate decomposed
instruction fine-tuning for enhanced LLM event extraction understanding.
Experiments demonstrate our approach outperforms existing state-of-the-art
event extraction methods across three benchmark datasets.

</details>


### [99] [LongReasonArena: A Long Reasoning Benchmark for Large Language Models](https://arxiv.org/abs/2508.19363)
*Jiayu Ding,Shuming Ma,Lei Cui,Nanning Zheng,Furu Wei*

Main category: cs.CL

TL;DR: 本文提出了一个名为LongReasonArena的新基准，评估大语言模型(LLMs)的长推理能力，强调多步骤算法的应用能力。


<details>
  <summary>Details</summary>
Motivation: 现有的长文本基准大多只评估模型对长文本的理解能力，缺乏对模型长逻辑推理能力的系统性评估。因此，作者设计了一个能够系统评估这方面能力的新任务。

Method: 通过设计多步算法任务，模拟长逻辑推理场景。控制输入规模，该方法支持推理长度灵活扩展，任务最高可达100万tokens的推理长度，且评估开放源代码和专有大语言模型的性能。

Result: 评估表明，LongReasonArena对现有LLMs具备显著挑战性，例如Deepseek-R1模型在任务中的准确率仅为7.5%。进一步分析显示，推理准确性随推理步数的对数呈线性下降。

Conclusion: LongReasonArena对现有LLMs提出了显著挑战，是测试模型长逻辑推理能力的有效工具，为研究提供了新的测试平台。

Abstract: Existing long-context benchmarks for Large Language Models (LLMs) focus on
evaluating comprehension of long inputs, while overlooking the evaluation of
long reasoning abilities. To address this gap, we introduce LongReasonArena, a
benchmark specifically designed to assess the long reasoning capabilities of
LLMs. Our tasks require models to solve problems by executing multi-step
algorithms that reflect key aspects of long reasoning, such as retrieval and
backtracking. By controlling the inputs, the required reasoning length can be
arbitrarily scaled, reaching up to 1 million tokens of reasoning for the most
challenging tasks. Extensive evaluation results demonstrate that
LongReasonArena presents a significant challenge for both open-source and
proprietary LLMs. For instance, Deepseek-R1 achieves only 7.5% accuracy on our
task. Further analysis also reveals that the accuracy exhibits a linear decline
with respect to the logarithm of the expected number of reasoning steps. Our
code and data is available at
https://github.com/LongReasonArena/LongReasonArena.

</details>


### [100] [Database Entity Recognition with Data Augmentation and Deep Learning](https://arxiv.org/abs/2508.19372)
*Zikun Fu,Chen Yang,Kourosh Davoudi,Ken Q. Pu*

Main category: cs.CL

TL;DR: 本文探讨了自然语言查询中的数据库实体识别问题，提出了一种结合基准数据集、数据增强及基于T5模型的识别方法，显著提升精确率与召回率。


<details>
  <summary>Details</summary>
Motivation: 数据库实体识别是自然语言查询与SQL对接的重要环节，但目前在标注数据、方法优化等方面存在不足，因此需要更加精确和高效的解决方案。

Method: 提出了基于人类标注的DB-ER基准数据集，利用SQL查询的自动注释进行数据增强，并基于T5模型设计了序列标注与标记分类的双任务模式来优化实体识别。

Result: 与两种最先进的命名实体识别模型相比，新模型在精确率与召回率上均表现更优。数据增强提高了超过10%的指标，T5模型的微调还带来5-10%的提升。

Conclusion: 新方法通过数据扩展和模型微调，为数据库实体识别提供了高性能框架，达到了最新的方法效果并显著改善精确率与召回率。

Abstract: This paper addresses the challenge of Database Entity Recognition (DB-ER) in
Natural Language Queries (NLQ). We present several key contributions to advance
this field: (1) a human-annotated benchmark for DB-ER task, derived from
popular text-to-sql benchmarks, (2) a novel data augmentation procedure that
leverages automatic annotation of NLQs based on the corresponding SQL queries
which are available in popular text-to-SQL benchmarks, (3) a specialized
language model based entity recognition model using T5 as a backbone and two
down-stream DB-ER tasks: sequence tagging and token classification for
fine-tuning of backend and performing DB-ER respectively. We compared our DB-ER
tagger with two state-of-the-art NER taggers, and observed better performance
in both precision and recall for our model. The ablation evaluation shows that
data augmentation boosts precision and recall by over 10%, while fine-tuning of
the T5 backbone boosts these metrics by 5-10%.

</details>


### [101] [One Joke to Rule them All? On the (Im)possibility of Generalizing Humor](https://arxiv.org/abs/2508.19402)
*Mor Turgeman,Chen Shani,Dafna Shahaf*

Main category: cs.CL

TL;DR: 研究探讨了对特定幽默任务的能力是否能迁移到新的幽默类型，通过一系列跨数据集的迁移学习实验，发现模型在未见过的数据集任务上最高可达75%准确率。


<details>
  <summary>Details</summary>
Motivation: 探索机器在处理幽默时能否跨越不同幽默类型的界限，提高其迁移和泛化能力，以应对不断变化的幽默形式。

Method: 进行了基于四个代表不同幽默任务的数据集的迁移学习实验，评估多样性训练对未知幽默任务上的模型表现的影响。

Result: 模型在多样性训练下提高了迁移能力，未见任务准确率最高可达75%，在域内表现几乎无损，‘Dad Jokes’对迁移帮助最大。

Conclusion: 幽默类型间存在关联性，对模型进行多样性训练有助于提升跨类型迁移能力，研究成果对未来幽默处理技术有启发。

Abstract: Humor is a broad and complex form of communication that remains challenging
for machines. Despite its broadness, most existing research on computational
humor traditionally focused on modeling a specific type of humor. In this work,
we wish to understand whether competence on one or more specific humor tasks
confers any ability to transfer to novel, unseen types; in other words, is this
fragmentation inevitable? This question is especially timely as new humor types
continuously emerge in online and social media contexts (e.g., memes,
anti-humor, AI fails). If Large Language Models (LLMs) are to keep up with this
evolving landscape, they must be able to generalize across humor types by
capturing deeper, transferable mechanisms. To investigate this, we conduct a
series of transfer learning experiments across four datasets, representing
different humor tasks. We train LLMs under varied diversity settings (1-3
datasets in training, testing on a novel task). Experiments reveal that models
are capable of some transfer, and can reach up to 75% accuracy on unseen
datasets; training on diverse sources improves transferability (1.88-4.05%)
with minimal-to-no drop in in-domain performance. Further analysis suggests
relations between humor types, with Dad Jokes surprisingly emerging as the best
enabler of transfer (but is difficult to transfer to). We release data and
code.

</details>


### [102] [A perishable ability? The future of writing in the face of generative artificial intelligence](https://arxiv.org/abs/2508.19427)
*Evandro L. T. P. Cunha*

Main category: cs.CL

TL;DR: 2020年代见证了生成型人工智能工具的发展，这些工具可能导致人类写作能力的削弱。


<details>
  <summary>Details</summary>
Motivation: 探讨生成型人工智能工具对人类写作能力的潜在影响，以及其与历史上类似情形的比较。

Method: 通过分析当前生成型AI工具的影响，类比希腊黑暗时期书写能力丧失的历史事件。

Result: 提出人类可能因依赖机器而失去写作能力，呼吁对此未来场景深思。

Conclusion: 生成型AI的广泛运用可能使写作外包给机器，写作能力的残缺可能成为人类文化的历史性转折点。

Abstract: The 2020s have been witnessing a very significant advance in the development
of generative artificial intelligence tools, including text generation systems
based on large language models. These tools have been increasingly used to
generate texts in the most diverse domains -- from technical texts to literary
texts --, which might eventually lead to a lower volume of written text
production by humans. This article discusses the possibility of a future in
which human beings will have lost or significantly decreased their ability to
write due to the outsourcing of this activity to machines. This possibility
parallels the loss of the ability to write in other moments of human history,
such as during the so-called Greek Dark Ages (approx. 1200 BCE - 800 BCE).

</details>


### [103] [Heterogeneous LLM Methods for Ontology Learning (Few-Shot Prompting, Ensemble Typing, and Attention-Based Taxonomies)](https://arxiv.org/abs/2508.19428)
*Aleksandra Beliaeva,Temurbek Rahmatullaev*

Main category: cs.CL

TL;DR: 本文介绍了一整套系统，解决LLMs4OL 2025挑战的任务A、B和C，涵盖了整个本体构建流程，包括术语提取、分类和分类关系发现。通过基于检索增强的提示、零样本分类和注意力图建模，取得了所有任务中的顶级排名表现。


<details>
  <summary>Details</summary>
Motivation: 目标是为本体结构的生成任务（术语提取、类型分类和分类发现）设计一个高效、可扩展且适应性强的方法。

Method: 使用三种技术解决不同任务：任务A采用检索增强生成（RAG）方法结合语义相似性，通过单次无模型微调实现词语提取与类型标注；任务B在有样本情况下使用RAG策略，零样本情况下使用余弦相似度与分类器加权；任务C通过轻量化交叉注意力层和嵌入预测分类关系。

Result: 在官方排行榜中，该系统在任务A、B和C上均取得顶级表现。

Conclusion: 这些策略展示了基于LLM的体系在异构领域本体学习的可扩展性、适应性和鲁棒性。

Abstract: We present a comprehensive system for addressing Tasks A, B, and C of the
LLMs4OL 2025 challenge, which together span the full ontology construction
pipeline: term extraction, typing, and taxonomy discovery. Our approach
combines retrieval-augmented prompting, zero-shot classification, and
attention-based graph modeling -- each tailored to the demands of the
respective task. For Task A, we jointly extract domain-specific terms and their
ontological types using a retrieval-augmented generation (RAG) pipeline.
Training data was reformulated into a document to terms and types
correspondence, while test-time inference leverages semantically similar
training examples. This single-pass method requires no model finetuning and
improves overall performance through lexical augmentation Task B, which
involves assigning types to given terms, is handled via a dual strategy. In the
few-shot setting (for domains with labeled training data), we reuse the RAG
scheme with few-shot prompting. In the zero-shot setting (for previously unseen
domains), we use a zero-shot classifier that combines cosine similarity scores
from multiple embedding models using confidence-based weighting. In Task C, we
model taxonomy discovery as graph inference. Using embeddings of type labels,
we train a lightweight cross-attention layer to predict is-a relations by
approximating a soft adjacency matrix. These modular, task-specific solutions
enabled us to achieve top-ranking results in the official leaderboard across
all three tasks. Taken together these strategies showcase the scalability,
adaptability, and robustness of LLM-based architectures for ontology learning
across heterogeneous domains.
  Code is available at:
https://github.com/BelyaevaAlex/LLMs4OL-Challenge-Alexbek

</details>


### [104] [Bridging Language Gaps: Enhancing Few-Shot Language Adaptation](https://arxiv.org/abs/2508.19464)
*Philipp Borchert,Jochen De Weerdt,Marie-Francine Moens*

Main category: cs.CL

TL;DR: 提出了CoLAP方法，用于解决多语言NLP中的资源不平衡问题，能够高效地实现高资源语言向低资源语言的知识转移，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前多语言NLP中，资源丰富和资源稀缺语言之间数据不平衡的问题阻碍了低资源语言的高效模型训练。

Method: 提出了一种名为CoLAP的方法，将对比学习与跨语言表示相结合，通过提示完成高效任务知识转移。

Result: 该方法在自然语言理解任务中的多语言模型实验中表现出色，超越了跨语言少样本基线和上下文学习。

Conclusion: CoLAP方法有效缩小了跨语言性能差距，为高效多语言NLP技术的发展提供了新的思路。

Abstract: The disparity in language resources poses a challenge in multilingual NLP,
with high-resource languages benefiting from extensive data, while low-resource
languages lack sufficient data for effective training. Our Contrastive Language
Alignment with Prompting (CoLAP) method addresses this gap by integrating
contrastive learning with cross-lingual representations, facilitating
task-specific knowledge transfer from high-resource to lower-resource
languages. The primary advantage of our approach is its data efficiency,
enabling rapid adaptation to new languages and reducing the need for large
labeled datasets. We conduct experiments with multilingual encoder-only and
decoder-only language models on natural language understanding tasks, including
natural language inference and relation extraction, evaluating performance
across both high- and low-resource languages. Our results demonstrate that
CoLAP outperforms few-shot cross-lingual transfer baselines and in-context
learning, even with limited available data. This effectively narrows the
cross-lingual performance gap, contributing to the development of more
efficient multilingual NLP techniques.

</details>


### [105] [Inference Gap in Domain Expertise and Machine Intelligence in Named Entity Recognition: Creation of and Insights from a Substance Use-related Dataset](https://arxiv.org/abs/2508.19467)
*Sumon Kanti Dey,Jeanne M. Powell,Azra Ismail,Jeanmarie Perrone,Abeed Sarker*

Main category: cs.CL

TL;DR: 研究利用社交媒体分析非医疗用途阿片类药物的临床和社会影响，并通过一个命名实体识别（NER）框架提取这些信息。


<details>
  <summary>Details</summary>
Motivation: 非医疗阿片类药物使用带来了显著的公共健康挑战。然而，此类影响通常在传统医疗中被低估。社交媒体提供了一个公开分享第一人称经历的平台，是探索这一问题的未被充分利用的资源。

Method: 通过一个命名实体识别（NER）框架，从社交媒体内容中提取与阿片类药物使用相关的两类后果：临床影响（如戒断、抑郁）和社会影响（如失业）。开发了一种名为RedditImpacts 2.0的数据集并进行了基于DeBERTa-large模型的训练与评估，同时对比了大语言模型在零样本和少量样本设定下的表现。

Result: DeBERTa-large模型达到放松版F1评分0.61（95%置信区间：0.43-0.62），在精确度、片段准确度及任务特定指导符合度方面优于大语言模型。此外，研究表明在数据资源有限的情况下仍可构建较强的NER性能模型。

Conclusion: 领域特定的微调对临床自然语言处理至关重要，其有助于负责任地开发AI工具，支持成瘾监控和医疗决策。尽管如此，目前最佳模型的表现仍显著低于专家之间的一致性，表明需要进一步提升NER/AI能力以应对深度领域知识任务的挑战。

Abstract: Nonmedical opioid use is an urgent public health challenge, with far-reaching
clinical and social consequences that are often underreported in traditional
healthcare settings. Social media platforms, where individuals candidly share
first-person experiences, offer a valuable yet underutilized source of insight
into these impacts. In this study, we present a named entity recognition (NER)
framework to extract two categories of self-reported consequences from social
media narratives related to opioid use: ClinicalImpacts (e.g., withdrawal,
depression) and SocialImpacts (e.g., job loss). To support this task, we
introduce RedditImpacts 2.0, a high-quality dataset with refined annotation
guidelines and a focus on first-person disclosures, addressing key limitations
of prior work. We evaluate both fine-tuned encoder-based models and
state-of-the-art large language models (LLMs) under zero- and few-shot
in-context learning settings. Our fine-tuned DeBERTa-large model achieves a
relaxed token-level F1 of 0.61 [95% CI: 0.43-0.62], consistently outperforming
LLMs in precision, span accuracy, and adherence to task-specific guidelines.
Furthermore, we show that strong NER performance can be achieved with
substantially less labeled data, emphasizing the feasibility of deploying
robust models in resource-limited settings. Our findings underscore the value
of domain-specific fine-tuning for clinical NLP tasks and contribute to the
responsible development of AI tools that may enhance addiction surveillance,
improve interpretability, and support real-world healthcare decision-making.
The best performing model, however, still significantly underperforms compared
to inter-expert agreement (Cohen's kappa: 0.81), demonstrating that a gap
persists between expert intelligence and current state-of-the-art NER/AI
capabilities for tasks requiring deep domain knowledge.

</details>


### [106] [Automatic Question & Answer Generation Using Generative Large Language Model (LLM)](https://arxiv.org/abs/2508.19475)
*Md. Alvee Ehsan,A. S. M Mehedi Hasan,Kefaya Benta Shahnoor,Syeda Sumaiya Tasneem*

Main category: cs.CL

TL;DR: 本文研究采用自动问答生成（AQAG）技术，结合微调生成式LLM，帮助教育工作者生成多样化的试题，从而简化学生评估过程。


<details>
  <summary>Details</summary>
Motivation: 当前的学生评估过程需要教师花费大量精力手动从多种教学资料中提取信息并设计试题，这一过程耗时且主观性较强。

Method: 提出使用基于无监督学习的NLP方法，主要针对英语语言，通过微调Meta-Llama 2-7B模型并使用RACE数据集进行训练，以生成教师所需的题型。

Result: 实现了一个定制化模型，可以高效地生成适合各种评估需求的试题类型，显著减少了教师的工作量。

Conclusion: 通过AQAG技术与生成式LLM的结合，为教育工作者提供了一种高效可靠的工具，大幅优化了评估流程。

Abstract: \Abstract{In the realm of education, student evaluation holds equal
significance as imparting knowledge. To be evaluated, students usually need to
go through text-based academic assessment methods. Instructors need to make
diverse sets of questions that need to be fair for all students to prove their
adequacy over a particular topic. This can prove to be quite challenging as
they may need to manually go through several different lecture materials. Our
objective is to make this whole process much easier by implementing Automatic
Question Answer Generation /(AQAG), using fine-tuned generative LLM. For
tailoring the instructor's preferred question style (MCQ, conceptual, or
factual questions), prompt Engineering (PE) is being utilized. In this
research, we propose to leverage unsupervised learning methods in NLP,
primarily focusing on the English language. This approach empowers the base
Meta-Llama 2-7B model to integrate RACE dataset as training data for the
fine-tuning process. Creating a customized model that will offer efficient
solutions for educators, instructors, and individuals engaged in text-based
evaluations. A reliable and efficient tool for generating questions and answers
can free up valuable time and resources, thus streamlining their evaluation
processes.}

</details>


### [107] [MovieCORE: COgnitive REasoning in Movies](https://arxiv.org/abs/2508.19026)
*Gueter Josmy Faure,Min-Hung Chen,Jia-Fong Yeh,Ying Cheng,Hung-Ting Su,Yung-Hao Tang,Shang-Hong Lai,Winston H. Hsu*

Main category: cs.CL

TL;DR: 提出了一个名为MovieCORE的新型视频问答数据集，专注于电影内容的深入认知理解，并通过多个大语言模型生成和优化高质量问答对，同时开发了评估认知深度和模型表现的测试方法和模块。


<details>
  <summary>Details</summary>
Motivation: 现有数据集大多停留在表面理解层面，难以评估对电影内容的深层次认知需求。

Method: 通过多大语言模型进行头脑风暴生成问答对；设计认知测试评估数据集质量；提出ACE模块以改善模型的推理能力。

Result: ACE模块可在后训练阶段将模型的推理能力提升至25%；验证了现有VLMs在复杂性问题上的局限性。

Conclusion: 工作提升了AI系统对电影内容的理解能力，并揭示现有VQA模型在处理更具挑战性问题上的局限。

Abstract: This paper introduces MovieCORE, a novel video question answering (VQA)
dataset designed to probe deeper cognitive understanding of movie content.
Unlike existing datasets that focus on surface-level comprehension, MovieCORE
emphasizes questions that engage System-2 thinking while remaining specific to
the video material. We present an innovative agentic brainstorming approach,
utilizing multiple large language models (LLMs) as thought agents to generate
and refine high-quality question-answer pairs. To evaluate dataset quality, we
develop a set of cognitive tests assessing depth, thought-provocation
potential, and syntactic complexity. We also propose a comprehensive evaluation
scheme for assessing VQA model performance on deeper cognitive tasks. To
address the limitations of existing video-language models (VLMs), we introduce
an agentic enhancement module, Agentic Choice Enhancement (ACE), which improves
model reasoning capabilities post-training by up to 25%. Our work contributes
to advancing movie understanding in AI systems and provides valuable insights
into the capabilities and limitations of current VQA models when faced with
more challenging, nuanced questions about cinematic content. Our project page,
dataset and code can be found at
https://joslefaure.github.io/assets/html/moviecore.html.

</details>


### [108] [Improving Low-Resource Translation with Dictionary-Guided Fine-Tuning and RL: A Spanish-to-Wayuunaiki Study](https://arxiv.org/abs/2508.19481)
*Manuel Mosquera,Melissa Robles,Johan Rodriguez,Ruben Manrique*

Main category: cs.CL

TL;DR: 本文提出了一种利用外部词典工具和强化学习提升低资源语言翻译的新方法，在西班牙语-Wayuunaiki 语言对上实现了BLEU得分显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在低资源语言翻译中因缺乏预训练暴露和有限平行数据而表现较差的问题。

Method: 整合外部双语词典，将翻译建模为工具增强的决策问题，通过强化学习指导奖励优化（GRPO）结合监督优化训练模型，利用BLEU相似度得分作为奖励信号。

Result: 与无词典接入的监督基线相比，该方法在西班牙语-Wayuunaiki测试集上取得了+3.37 BLEU得分提升和18%的相对增益。

Conclusion: 结合外部工具和强化学习能有效提高低资源语言环境下的翻译质量，也能够为未来相关任务的研究提供启发性方向。

Abstract: Low-resource machine translation remains a significant challenge for large
language models (LLMs), which often lack exposure to these languages during
pretraining and have limited parallel data for fine-tuning. We propose a novel
approach that enhances translation for low-resource languages by integrating an
external dictionary tool and training models end-to-end using reinforcement
learning, in addition to supervised fine-tuning. Focusing on the
Spanish-Wayuunaiki language pair, we frame translation as a tool-augmented
decision-making problem in which the model can selectively consult a bilingual
dictionary during generation. Our method combines supervised instruction tuning
with Guided Reward Policy Optimization (GRPO), enabling the model to learn both
when and how to use the tool effectively. BLEU similarity scores are used as
rewards to guide this learning process. Preliminary results show that our
tool-augmented models achieve up to +3.37 BLEU improvement over previous work,
and a 18% relative gain compared to a supervised baseline without dictionary
access, on the Spanish-Wayuunaiki test set from the AmericasNLP 2025 Shared
Task. We also conduct ablation studies to assess the effects of model
architecture and training strategy, comparing Qwen2.5-0.5B-Instruct with other
models such as LLaMA and a prior NLLB-based system. These findings highlight
the promise of combining LLMs with external tools and the role of reinforcement
learning in improving translation quality in low-resource language settings.

</details>


### [109] [Rule Synergy Analysis using LLMs: State of the Art and Implications](https://arxiv.org/abs/2508.19484)
*Bahar Bateni,Benjamin Pratt,Jim Whitehead*

Main category: cs.CL

TL;DR: 文章探讨了大型语言模型(LLMs)在动态环境下对复杂规则交互的理解，特别是在卡片游戏中的表现。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在逻辑推理和规则复杂动态环境中的适用性，例如卡片游戏中的规则交互。

Method: 提出了一个基于《杀戮尖塔》游戏卡片协同效应的数据集，对LLMs进行评测，分类它们对卡片之间正面、负面或中性交互的分析能力。

Result: 研究表明，LLMs较擅长识别非协同卡片对，但在检测正面和负面协同作用时表现较差，并定义了常见错误类型。

Conclusion: LLMs在动态环境下复杂规则交互的预测能力有限，未来研究需提升它们对规则及其交互影响的表现。

Abstract: Large language models (LLMs) have demonstrated strong performance across a
variety of domains, including logical reasoning, mathematics, and more. In this
paper, we investigate how well LLMs understand and reason about complex rule
interactions in dynamic environments, such as card games. We introduce a
dataset of card synergies from the game Slay the Spire, where pairs of cards
are classified based on their positive, negative, or neutral interactions. Our
evaluation shows that while LLMs excel at identifying non-synergistic pairs,
they struggle with detecting positive and, particularly, negative synergies. We
categorize common error types, including issues with timing, defining game
states, and following game rules. Our findings suggest directions for future
research to improve model performance in predicting the effect of rules and
their interactions.

</details>


### [110] [Blockwise SFT for Diffusion Language Models: Reconciling Bidirectional Attention and Autoregressive Decoding](https://arxiv.org/abs/2508.19529)
*Bowen Sun,Yujun Cai,Ming-Hsuan Yang,Yiwei Wang*

Main category: cs.CL

TL;DR: 该研究提出了一种名为Blockwise SFT的训练方法，用于提升离散扩散语言模型在文本生成中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统的监督微调（SFT）训练方法与扩散模型的半自回归推理过程不匹配，会引入噪声，引导梯度偏离目标的分块似然。

Method: 提出Blockwise SFT方法，将响应切分为固定大小的块，每个步骤仅随机遮掩一个活动块，并冻结之前的所有token，同时完全隐藏未来的内容，仅对当前块计算损失。

Result: 在GSM8K、MATH和MetaMathQA任务上，Blockwise SFT在计算和token预算相等的条件下比传统SFT取得了更好的表现，提升了训练-推理对齐性。

Conclusion: 通过更好地匹配训练监督的粒度和解码过程，可以提升基于扩散模型的语言模型的性能。

Abstract: Discrete diffusion language models have shown strong potential for text
generation, yet standard supervised fine-tuning (SFT) misaligns with their
semi-autoregressive inference: training randomly masks tokens across the entire
response, while inference generates fixed-size blocks sequentially. This
mismatch introduces noisy prefixes and leaky suffixes, biasing gradients away
from the desired blockwise likelihood. We propose Blockwise SFT, which
partitions responses into fixed-size blocks, selects one active block per step
for stochastic masking, freezes all preceding tokens, and fully hides future
ones. Loss is computed only over the active block, directly mirroring the
blockwise decoding process. Experiments on GSM8K, MATH, and MetaMathQA show
consistent gains over classical SFT under equal compute or token budgets. Block
size consistency studies and ablations confirm that improvements stem from
faithful training-inference alignment rather than incidental masking effects.
Our results highlight the importance of matching supervision granularity to the
decoding procedure in diffusion-based language models.

</details>


### [111] [Alignment with Fill-In-the-Middle for Enhancing Code Generation](https://arxiv.org/abs/2508.19532)
*Houxing Ren,Zimu Lu,Weikang Shi,Haotian Hou,Yunqiao Yang,Ke Wang,Aojun Zhou,Junting Pan,Mingjie Zhan,Hongsheng Li*

Main category: cs.CL

TL;DR: 该论文提出一种新方法，通过将代码片段分割为更小的粒度模块，创造了更多样化的直接偏好优化(DPO)对，并结合抽象语法树(AST)分割及课程训练法，显著提升代码生成任务性能，成果已在多个基准数据集中验证。


<details>
  <summary>Details</summary>
Motivation: 目前代码相关任务的性能提升受限于可以通过准确测试案例验证的训练数据匮乏问题，直接偏好优化虽表现出潜力，但测试案例的生成方法有限。

Method: 提出将代码片段分割为更小的粒度模块的技术，并创建多样化的DPO对，结合抽象语法树(AST)分割方法和课程训练策略优化DPO训练。

Result: 在多个基准数据集如HumanEval、MBPP、APPS、LiveCodeBench及BigCodeBench上，证明了其方法在代码生成任务中的显著改进效果。

Conclusion: 通过引入新的分割和训练方法，显著改善了基于直接偏好优化的代码生成任务性能，同时提供了代码及数据以供使用。

Abstract: The code generation capabilities of Large Language Models (LLMs) have
advanced applications like tool invocation and problem-solving. However,
improving performance in code-related tasks remains challenging due to limited
training data that is verifiable with accurate test cases. While Direct
Preference Optimization (DPO) has shown promise, existing methods for
generating test cases still face limitations. In this paper, we propose a novel
approach that splits code snippets into smaller, granular blocks, creating more
diverse DPO pairs from the same test cases. Additionally, we introduce the
Abstract Syntax Tree (AST) splitting and curriculum training method to enhance
the DPO training. Our approach demonstrates significant improvements in code
generation tasks, as validated by experiments on benchmark datasets such as
HumanEval (+), MBPP (+), APPS, LiveCodeBench, and BigCodeBench. Code and data
are available at https://github.com/SenseLLM/StructureCoder.

</details>


### [112] [Emotion Transfer with Enhanced Prototype for Unseen Emotion Recognition in Conversation](https://arxiv.org/abs/2508.19533)
*Kun Peng,Cong Cao,Hao Peng,Guanlin Wu,Zhifeng Hao,Lei Jiang,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文提出了一个新任务UERC（未见情绪识别任务），并引入原型型的情绪转移框架ProEmoTrans。


<details>
  <summary>Details</summary>
Motivation: 现有情绪对话识别集中于闭域分类，但实际中有许多未见情绪难以定义，这是一个现实应用的挑战。

Method: 提出ProEmoTrans框架，包含三大改进：通过LLM优化情绪定义描述；通过无参数机制编码长对话中的话语；使用改进的Attention Viterbi解码方法刻画情绪的Markov流动特性。

Result: 在三个数据集上的实验结果显示，该方法为这一新研究领域提供了强有力的基线。

Conclusion: ProEmoTrans框架为未见情绪识别领域初期探索提供了有效解决方案，并对未来工作提供了方向。

Abstract: Current Emotion Recognition in Conversation (ERC) research follows a
closed-domain assumption. However, there is no clear consensus on emotion
classification in psychology, which presents a challenge for models when it
comes to recognizing previously unseen emotions in real-world applications. To
bridge this gap, we introduce the Unseen Emotion Recognition in Conversation
(UERC) task for the first time and propose ProEmoTrans, a solid prototype-based
emotion transfer framework. This prototype-based approach shows promise but
still faces key challenges: First, implicit expressions complicate emotion
definition, which we address by proposing an LLM-enhanced description approach.
Second, utterance encoding in long conversations is difficult, which we tackle
with a proposed parameter-free mechanism for efficient encoding and overfitting
prevention. Finally, the Markovian flow nature of emotions is hard to transfer,
which we address with an improved Attention Viterbi Decoding (AVD) method to
transfer seen emotion transitions to unseen emotions. Extensive experiments on
three datasets show that our method serves as a strong baseline for preliminary
exploration in this new area.

</details>


### [113] [Language Models Identify Ambiguities and Exploit Loopholes](https://arxiv.org/abs/2508.19546)
*Jio Choi,Mohit Bansal,Elias Stengel-Eskin*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）对漏洞的响应，并通过实验发现，这种对漏洞的利用可能会带来AI安全风险。


<details>
  <summary>Details</summary>
Motivation: 利用漏洞需要识别模糊性并进行复杂的语用推理，本研究旨在揭示LLMs在此方面的能力以及这种现象引发的对齐问题。

Method: 设计场景测试LLMs在目标与用户含糊指令冲突时如何回应，涵盖标量暗示、结构模糊和权力动态等情景。

Result: 发现无论是闭源还是强大的开源模型都能够识别并利用模糊性及其产生的漏洞。

Conclusion: 模型利用漏洞时会明确识别模糊性并推理冲突目标，这可能构成AI安全隐患。

Abstract: Studying the responses of large language models (LLMs) to loopholes presents
a two-fold opportunity. First, it affords us a lens through which to examine
ambiguity and pragmatics in LLMs, since exploiting a loophole requires
identifying ambiguity and performing sophisticated pragmatic reasoning. Second,
loopholes pose an interesting and novel alignment problem where the model is
presented with conflicting goals and can exploit ambiguities to its own
advantage. To address these questions, we design scenarios where LLMs are given
a goal and an ambiguous user instruction in conflict with the goal, with
scenarios covering scalar implicature, structural ambiguities, and power
dynamics. We then measure different models' abilities to exploit loopholes to
satisfy their given goals as opposed to the goals of the user. We find that
both closed-source and stronger open-source models can identify ambiguities and
exploit their resulting loopholes, presenting a potential AI safety risk. Our
analysis indicates that models which exploit loopholes explicitly identify and
reason about both ambiguity and conflicting goals.

</details>


### [114] [Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts](https://arxiv.org/abs/2508.19578)
*Jiaqi Deng,Yuho Lee,Nicole Hee-Yeon Kim,Hyangsuk Min,Taewon Yun,Minjeong Ban,Kim Yul,Hwanjun Song*

Main category: cs.CL

TL;DR: HAMLET 是一个用于评估大型语言模型 (LLMs) 长上下文理解的自动化框架，通过三层关键信息结构和查询摘要评估模型的理解与忠实性。


<details>
  <summary>Details</summary>
Motivation: 解决因大语言模型在长上下文中细粒度理解能力不足的问题，尤其是信息忠实性和层级理解的评估。

Method: 将源文本结构化为根、枝、叶三层关键信息层次，并使用查询导向的摘要方法自动评估模型的信息回忆与忠实性，结合人工研究验证自动评估的可靠性。

Result: 自动评估系统实现了超过 90% 的专家人工评估一致性，同时大幅降低了评估成本（最高降至1/25）。揭示了 LLM 在叶层级理解、位置效应等方面的不足，以及开源与专有模型间的一致性表现差距。

Conclusion: HAMLET 提供了一种高效可靠的长上下文评估方法，对于进一步探索 LLMs 的细粒度分析能力以及模型改进提供了重要基础。

Abstract: We introduce HAMLET, a holistic and automated framework for evaluating the
long-context comprehension of large language models (LLMs). HAMLET structures
source texts into a three-level key-fact hierarchy at root-, branch-, and
leaf-levels, and employs query-focused summarization to evaluate how well
models recall and faithfully represent information at each level. To validate
the reliability of our fully automated pipeline, we conduct a systematic human
study, showing that our automatic evaluation achieves over 90% agreement with
expert human judgments, while reducing the cost by up to 25 times. HAMLET
reveals that LLMs struggle with fine-grained comprehension, especially at the
leaf level, and are sensitive to positional effects like the
lost-in-the-middle. Analytical queries pose greater challenges than narrative
ones, and consistent performance gaps emerge between open-source and
proprietary models, as well as across model scales. Our code and dataset are
publicly available at https://github.com/DISL-Lab/HAMLET.

</details>


### [115] [ArgCMV: An Argument Summarization Benchmark for the LLM-era](https://arxiv.org/abs/2508.19580)
*Omkar Gurjar,Agam Goyal,Eshwar Chandrasekharan*

Main category: cs.CL

TL;DR: 该论文提出ArgCMV数据集，用于改进从在线辩论中提取关键点的难题。


<details>
  <summary>Details</summary>
Motivation: 现有的ArgKP21数据集在复杂性和真实人类对话的代表性方面存在不足。

Method: 通过使用最先进的大型语言模型（LLMs），从实际的在线人类辩论中创建了一个包含约12K辩论内容的新的关键点提取数据集ArgCMV。

Result: 发现现有方法在新的ArgCMV数据集上的表现不佳，并通过实验验证了基线模型和最新开源模型的表现。

Conclusion: 该数据集为研究长文本在线讨论中关键点提取及下一代基于LLM的总结技术提供了平台支持。

Abstract: Key point extraction is an important task in argument summarization which
involves extracting high-level short summaries from arguments. Existing
approaches for KP extraction have been mostly evaluated on the popular ArgKP21
dataset. In this paper, we highlight some of the major limitations of the
ArgKP21 dataset and demonstrate the need for new benchmarks that are more
representative of actual human conversations. Using SoTA large language models
(LLMs), we curate a new argument key point extraction dataset called ArgCMV
comprising of around 12K arguments from actual online human debates spread
across over 3K topics. Our dataset exhibits higher complexity such as longer,
co-referencing arguments, higher presence of subjective discourse units, and a
larger range of topics over ArgKP21. We show that existing methods do not adapt
well to ArgCMV and provide extensive benchmark results by experimenting with
existing baselines and latest open source models. This work introduces a novel
KP extraction dataset for long-context online discussions, setting the stage
for the next generation of LLM-driven summarization research.

</details>


### [116] [Towards stable AI systems for Evaluating Arabic Pronunciations](https://arxiv.org/abs/2508.19587)
*Hadi Zaatiti,Hatem Hajri,Osama Abdullah,Nader Masmoudi*

Main category: cs.CL

TL;DR: 本文重点研究阿拉伯语的孤立字母识别问题，提出使用对抗训练从而提升模型稳健性，并发布相关数据与代码。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是孤立字母识别对语言学习、语音治疗和语音学研究很重要，但现有模型表现不佳。

Method: 使用一个包含重音标记的多样化阿拉伯语孤立字母语料库，基于wav2vec嵌入训练轻量化神经网络，并引入对抗训练缓解噪声对性能的影响。

Result: wav2vec 2.0模型在该任务中的初始准确率为35%，通过训练轻量化神经网络将准确率提升至65%；但加入微小扰动后准确率降为32%，通过对抗训练后降幅限制在9%。

Conclusion: 阿拉伯语孤立字母识别需要增强模型的鲁棒性，对抗训练是一种有效的手段，未来研究可扩展至单词与句子层面。

Abstract: Modern Arabic ASR systems such as wav2vec 2.0 excel at word- and
sentence-level transcription, yet struggle to classify isolated letters. In
this study, we show that this phoneme-level task, crucial for language
learning, speech therapy, and phonetic research, is challenging because
isolated letters lack co-articulatory cues, provide no lexical context, and
last only a few hundred milliseconds. Recogniser systems must therefore rely
solely on variable acoustic cues, a difficulty heightened by Arabic's emphatic
(pharyngealized) consonants and other sounds with no close analogues in many
languages. This study introduces a diverse, diacritised corpus of isolated
Arabic letters and demonstrates that state-of-the-art wav2vec 2.0 models
achieve only 35% accuracy on it. Training a lightweight neural network on
wav2vec embeddings raises performance to 65%. However, adding a small amplitude
perturbation (epsilon = 0.05) cuts accuracy to 32%. To restore robustness, we
apply adversarial training, limiting the noisy-speech drop to 9% while
preserving clean-speech accuracy. We detail the corpus, training pipeline, and
evaluation protocol, and release, on demand, data and code for reproducibility.
Finally, we outline future work extending these methods to word- and
sentence-level frameworks, where precise letter pronunciation remains critical.

</details>


### [117] [Understanding and Leveraging the Expert Specialization of Context Faithfulness in Mixture-of-Experts LLMs](https://arxiv.org/abs/2508.19594)
*Jun Bai,Minghao Tong,Yang Liu,Zixia Jia,Zilong Zheng*

Main category: cs.CL

TL;DR: 本文探讨了如何通过大规模语言模型中的专家机制优化上下文忠实度，提出Router Lens方法发现忠实专家，并基于此设计了轻量高效的CEFT优化方法。


<details>
  <summary>Details</summary>
Motivation: 在上下文相关场景中，大语言模型常难以基于提供的上下文生成相关输出，因此需要探索改进的方法。

Method: 提出Router Lens方法以精准识别上下文忠实的专家，并基于此开发CEFT（Context-faithful Expert Fine-Tuning）轻量优化方法。

Result: 实验表明，CEFT在高效性和效果上超越传统全面微调方法，提供更优解。

Conclusion: 通过Router Lens识别忠实专家并选择性优化，可以有效强化上下文忠实性，同时提升模型性能和效率。

Abstract: Context faithfulness is essential for reliable reasoning in context-dependent
scenarios. However, large language models often struggle to ground their
outputs in the provided context, resulting in irrelevant responses. Inspired by
the emergent expert specialization observed in mixture-of-experts
architectures, this work investigates whether certain experts exhibit
specialization in context utilization, offering a potential pathway toward
targeted optimization for improved context faithfulness. To explore this, we
propose Router Lens, a method that accurately identifies context-faithful
experts. Our analysis reveals that these experts progressively amplify
attention to relevant contextual information, thereby enhancing context
grounding. Building on this insight, we introduce Context-faithful Expert
Fine-Tuning (CEFT), a lightweight optimization approach that selectively
fine-tunes context-faithful experts. Experiments across a wide range of
benchmarks and models demonstrate that CEFT matches or surpasses the
performance of full fine-tuning while being significantly more efficient.

</details>


### [118] [LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.19614)
*Yang Sun,Lixin Zou,Dan Luo,Zhiyong Xie,Long Zhang,Liming Dong,Yunwei Zhao,Xixun Lin,Yanxiong Lu,Chenliang Li*

Main category: cs.CL

TL;DR: 本文探讨在大语言模型中引入检索增强生成（RAG）中噪声反而提高外部知识利用和生成质量。提出了一种新的解码策略Layer Fused Decoding (LFD)，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究噪声对RAG系统利用外部知识的影响，并希望通过解码策略优化外部知识的整合和应用。

Method: 通过分析模型层功能分布，提出Layer Fused Decoding (LFD)策略，结合中间层和最终层的输出，并通过内部知识分数（IKS）选择最优中间层进行解码。

Result: 实验结果表明，新策略在多个基准任务上提升了RAG系统的外部知识利用效果，同时成本较低。

Conclusion: 本文证明了通过Layer Fused Decoding可以更高效地利用检索到的外部知识，有助于大语言模型任务的优化。

Abstract: Retrieval-augmented generation (RAG) incorporates external knowledge into
large language models (LLMs), improving their adaptability to downstream tasks
and enabling information updates. Surprisingly, recent empirical evidence
demonstrates that injecting noise into retrieved relevant documents
paradoxically facilitates exploitation of external knowledge and improves
generation quality. Although counterintuitive and challenging to apply in
practice, this phenomenon enables granular control and rigorous analysis of how
LLMs integrate external knowledge. Therefore, in this paper, we intervene on
noise injection and establish a layer-specific functional demarcation within
the LLM: shallow layers specialize in local context modeling, intermediate
layers focus on integrating long-range external factual knowledge, and deeper
layers primarily rely on parametric internal knowledge. Building on this
insight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that
directly combines representations from an intermediate layer with final-layer
decoding outputs to fully exploit the external factual knowledge. To identify
the optimal intermediate layer, we introduce an internal knowledge score (IKS)
criterion that selects the layer with the lowest IKS value in the latter half
of layers. Experimental results across multiple benchmarks demonstrate that LFD
helps RAG systems more effectively surface retrieved context knowledge with
minimal cost.

</details>


### [119] [A Symbolic Adversarial Learning Framework for Evolving Fake News Generation and Detection](https://arxiv.org/abs/2508.19633)
*Chong Tian,Qirong Ho,Xiuying Chen*

Main category: cs.CL

TL;DR: 本文提出了一个名为Symbolic Adversarial Learning Framework (SALF)的新框架，通过以符号学习为基础的对抗训练机制，生成更复杂的虚假新闻，并改进了侦测虚假新闻的效果。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）的发展让生成复杂虚假信息变得更加简单，这是打击假新闻的重要挑战。现有的检测方法对动态变化的假新闻效果有限，需要更灵活、鲁棒的解决方案。

Method: 提出SALF框架，采用符号学习形式的对抗训练机制：生成代理生成虚假叙述，检测代理通过结构化争辩找到逻辑和事实中的缺陷，两者通过对抗式交互迭代完善。与传统神经网络方法不同，SALF用自然语言表达权重、损失和梯度，模拟反向传播和梯度下降。

Result: 实验结果表明，SALF在两个多语言数据集上表现突出。它能显著削弱现有顶尖检测模型的识别效果（中文下降规模最大达53.4%，英文为34.2%），同时能够提升检测器对改进内容的识别精度（最高增加7.7%）。

Conclusion: SALF框架展示了其在生成复杂虚假信息和改进假新闻检测器方面的潜力，为开发更鲁棒、适应性强的假新闻检测系统提供了启发。

Abstract: Rapid LLM advancements heighten fake news risks by enabling the automatic
generation of increasingly sophisticated misinformation. Previous detection
methods, including fine-tuned small models or LLM-based detectors, often
struggle with its dynamically evolving nature. In this work, we propose a novel
framework called the Symbolic Adversarial Learning Framework (SALF), which
implements an adversarial training paradigm by an agent symbolic learning
optimization process, rather than relying on numerical updates. SALF introduces
a paradigm where the generation agent crafts deceptive narratives, and the
detection agent uses structured debates to identify logical and factual flaws
for detection, and they iteratively refine themselves through such adversarial
interactions. Unlike traditional neural updates, we represent agents using
agent symbolic learning, where learnable weights are defined by agent prompts,
and simulate back-propagation and gradient descent by operating on natural
language representations of weights, loss, and gradients. Experiments on two
multilingual benchmark datasets demonstrate SALF's effectiveness, showing it
generates sophisticated fake news that degrades state-of-the-art detection
performance by up to 53.4% in Chinese and 34.2% in English on average. SALF
also refines detectors, improving detection of refined content by up to 7.7%.
We hope our work inspires further exploration into more robust, adaptable fake
news detection systems.

</details>


### [120] [Automatic integration of SystemC in the FMI standard for Software-defined Vehicle design](https://arxiv.org/abs/2508.19665)
*Giovanni Pollo,Andrei Mihai Albu,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Loris Panaro,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 该文章提出了一种基于FMI标准的自动化方法，将SystemC模型封装，使其支持跨领域的鲁棒联合仿真。


<details>
  <summary>Details</summary>
Motivation: 当前汽车行业需要能够在硬件和软件领域实现早期验证和无缝集成的联合仿真方法，而现有的专有平台和缺乏标准接口限制了这一进程。

Method: 通过使用Functional Mock-up Interface (FMI)标准自动封装SystemC模型，结合SystemC建模的精确性与FMI的互操作性和封装优势。

Result: 方法在真实案例中验证，证明其对复杂设计的有效性。

Conclusion: 该方法实现了嵌入式组件的安全、可移植的集成，使复杂汽车设计的联合仿真成为可能。

Abstract: The recent advancements of the automotive sector demand robust co-simulation
methodologies that enable early validation and seamless integration across
hardware and software domains. However, the lack of standardized interfaces and
the dominance of proprietary simulation platforms pose significant challenges
to collaboration, scalability, and IP protection. To address these limitations,
this paper presents an approach for automatically wrapping SystemC models by
using the Functional Mock-up Interface (FMI) standard. This method combines the
modeling accuracy and fast time-to-market of SystemC with the interoperability
and encapsulation benefits of FMI, enabling secure and portable integration of
embedded components into co-simulation workflows. We validate the proposed
methodology on real-world case studies, demonstrating its effectiveness with
complex designs.

</details>


### [121] [Survey of Specialized Large Language Model](https://arxiv.org/abs/2508.19667)
*Chenghan Yang,Ruiyu Zhao,Yang Liu,Ling Jiang*

Main category: cs.CL

TL;DR: 该论文回顾了专用大型语言模型（LLMs）的发展，重点分析其在医疗、金融、法律和技术领域的应用与技术突破。


<details>
  <summary>Details</summary>
Motivation: 探讨专用LLMs如何通过创新技术克服通用LLMs在专业领域中的局限性。

Method: 系统审查专用LLMs在各领域中的发展，分析其在参数效率、稀疏计算、量化与多模态能力等技术进步的应用。

Result: 专用LLMs在领域特定基准中表现出显著的性能提升，并展示了这些创新在解决通用LLMs的局限性方面的潜力。

Conclusion: 专用LLMs的发展不仅推动了领域技术的进步，也为电子商务和其他专业领域提供了重要启示与指导方向。

Abstract: The rapid evolution of specialized large language models (LLMs) has
transitioned from simple domain adaptation to sophisticated native
architectures, marking a paradigm shift in AI development. This survey
systematically examines this progression across healthcare, finance, legal, and
technical domains. Besides the wide use of specialized LLMs, technical
breakthrough such as the emergence of domain-native designs beyond fine-tuning,
growing emphasis on parameter efficiency through sparse computation and
quantization, increasing integration of multimodal capabilities and so on are
applied to recent LLM agent. Our analysis reveals how these innovations address
fundamental limitations of general-purpose LLMs in professional applications,
with specialized models consistently performance gains on domain-specific
benchmarks. The survey further highlights the implications for E-Commerce field
to fill gaps in the field.

</details>


### [122] [Building Task Bots with Self-learning for Enhanced Adaptability, Extensibility, and Factuality](https://arxiv.org/abs/2508.19689)
*Xiaoying Zhang*

Main category: cs.CL

TL;DR: 本论文探讨了创建自主学习和适应的对话机器人的挑战和潜在解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决开发对话机器人在不断变化环境中自主学习和适应的难题。

Method: 通过探索创新技术，研究如何让对话机器人实现自主学习和适应能力。

Result: 提出了能够帮助机器人在不断变化环境中自主调整的技术和方法。

Conclusion: 研究为开发适应性强、可扩展且精确的对话机器人提供了新的方向。

Abstract: Developing adaptable, extensible, and accurate task bots with minimal or zero
human intervention is a significant challenge in dialog research. This thesis
examines the obstacles and potential solutions for creating such bots, focusing
on innovative techniques that enable bots to learn and adapt autonomously in
constantly changing environments.

</details>


### [123] [Continuously Steering LLMs Sensitivity to Contextual Knowledge with Proxy Models](https://arxiv.org/abs/2508.19720)
*Yilin Wang,Heng Wang,Yuyang Bai,Minnan Luo*

Main category: cs.CL

TL;DR: 本文提出了一种名为CSKS的框架，通过调整LLM对上下文知识的敏感性来解决知识冲突问题，而无需修改模型权重，具有较低的计算成本和高效率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在生成过程中存在知识冲突，尤其是内置（参数化）知识与上下文知识的矛盾问题。现有方法在解决此类问题时多存在效率低下、无法在黑盒模型中应用或无法持续调整模型敏感性的局限。

Method: CSKS框架通过训练两个小型代理模型，利用其输出分布差异调整大语言模型的输出分布，而无需直接修改LLM的权重，实现一种轻量级的上下文知识敏感性控制方法。

Result: 实验表明，CSKS框架能够实现对LLM上下文知识敏感性的持续且精确的控制，既可以提高对上下文知识的敏感性，也可以降低敏感性，使LLM灵活平衡上下文和参数化知识的优先级。

Conclusion: 提出的CSKS框架在经济高效的前提下显著改善了LLM在知识冲突情境中的灵活性和适配性，验证了该方法的实用性和有效性。

Abstract: In Large Language Models (LLMs) generation, there exist knowledge conflicts
and scenarios where parametric knowledge contradicts knowledge provided in the
context. Previous works studied tuning, decoding algorithms, or locating and
editing context-aware neurons to adapt LLMs to be faithful to new contextual
knowledge. However, they are usually inefficient or ineffective for large
models, not workable for black-box models, or unable to continuously adjust
LLMs' sensitivity to the knowledge provided in the context. To mitigate these
problems, we propose CSKS (Continuously Steering Knowledge Sensitivity), a
simple framework that can steer LLMs' sensitivity to contextual knowledge
continuously at a lightweight cost. Specifically, we tune two small LMs (i.e.
proxy models) and use the difference in their output distributions to shift the
original distribution of an LLM without modifying the LLM weights. In the
evaluation process, we not only design synthetic data and fine-grained metrics
to measure models' sensitivity to contextual knowledge but also use a real
conflict dataset to validate CSKS's practical efficacy. Extensive experiments
demonstrate that our framework achieves continuous and precise control over
LLMs' sensitivity to contextual knowledge, enabling both increased sensitivity
and reduced sensitivity, thereby allowing LLMs to prioritize either contextual
or parametric knowledge as needed flexibly. Our data and code are available at
https://github.com/OliveJuiceLin/CSKS.

</details>


### [124] [CAMÕES: A Comprehensive Automatic Speech Recognition Benchmark for European Portuguese](https://arxiv.org/abs/2508.19721)
*Carlos Carvalho,Francisco Teixeira,Catarina Botelho,Anna Pompili,Rubén Solera-Ureña,Sérgio Paulo,Mariana Julião,Thomas Rolland,John Mendonça,Diogo Pereira,Isabel Trancoso,Alberto Abad*

Main category: cs.CL

TL;DR: 本文提出CAMÕES，这是一个专门为欧洲葡萄牙语及其他葡萄牙语变体设计的开源框架，包含测试数据和顶尖模型。


<details>
  <summary>Details</summary>
Motivation: 现有的自动语音识别资源主要集中在巴西葡萄牙语，欧洲葡萄牙语及其他变体受重视程度较低。

Method: 提供46小时的EP测试数据和多领域基础模型，包括零样本、微调及全新训练模型。

Result: 微调后的基础模型与从零开始训练的分支模型在EP语言识别上表现相当，最佳模型相较于最佳零样本模型WER提升超过35%。

Conclusion: CAMÕES为EP及葡萄牙语其他变体设立了新的语音识别基准，表现显著提升。

Abstract: Existing resources for Automatic Speech Recognition in Portuguese are mostly
focused on Brazilian Portuguese, leaving European Portuguese (EP) and other
varieties under-explored. To bridge this gap, we introduce CAM\~OES, the first
open framework for EP and other Portuguese varieties. It consists of (1) a
comprehensive evaluation benchmark, including 46h of EP test data spanning
multiple domains; and (2) a collection of state-of-the-art models. For the
latter, we consider multiple foundation models, evaluating their zero-shot and
fine-tuned performances, as well as E-Branchformer models trained from scratch.
A curated set of 425h of EP was used for both fine-tuning and training. Our
results show comparable performance for EP between fine-tuned foundation models
and the E-Branchformer. Furthermore, the best-performing models achieve
relative improvements above 35% WER, compared to the strongest zero-shot
foundation model, establishing a new state-of-the-art for EP and other
varieties.

</details>


### [125] [NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks](https://arxiv.org/abs/2508.19724)
*Aritra Dutta,Swapnanil Mukherjee,Deepanway Ghosal,Somak Aditya*

Main category: cs.CL

TL;DR: 研究通过整合常识性知识以提高小型视觉语言模型（sVLMs）的性能。提出的方法在三个数据集上使答案准确率提升了7%，并通过抗噪训练进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前小型视觉语言模型在常识视觉问答任务中表现不及更大的生成模型，主要是因为缺乏与图像或问题相关的外部常识知识。

Method: 提出了一种端到端的框架（NLKI），通过：1）召回基于自然语言的事实；2）利用大语言模型（LLM）生成自然语言解释；3）将这些信息整合进sVLMs，进行常识视觉问答任务。

Result: NLKI框架能够将事实引入sVLMs并减少生成的幻觉（错误解释），使模型性能超过一些中型视觉语言模型，并通过抗噪损失进一步提升精确度。

Conclusion: 基于 LLM 的常识知识在某些情境中比知识库检索更有效，小型模型通过稳定的外部知识增强实现了参数高效化的常识推理。

Abstract: Commonsense visual-question answering often hinges on knowledge that is
missing from the image or the question. Small vision-language models (sVLMs)
such as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative
counterparts. To study the effect of careful commonsense knowledge integration
on sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural
language facts, (ii) prompts an LLM to craft natural language explanations, and
(iii) feeds both signals to sVLMs respectively across two commonsense VQA
datasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts
retrieved using a fine-tuned ColBERTv2 and an object information-enriched
prompt yield explanations that largely cut down hallucinations, while lifting
the end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA
and other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B
and SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional
finetuning using noise-robust losses (such as symmetric cross entropy and
generalised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our
findings expose when LLM-based commonsense knowledge beats retrieval from
commonsense knowledge bases, how noise-aware training stabilises small models
in the context of external knowledge augmentation, and why parameter-efficient
commonsense reasoning is now within reach for 250M models.

</details>


### [126] [Spotlight Attention: Towards Efficient LLM Generation via Non-linear Hashing-based KV Cache Retrieval](https://arxiv.org/abs/2508.19740)
*Wenhao Li,Yuxin Zhang,Gen Luo,Haiyuan Wan,Ziyang Gong,Fei Chao,Rongrong Ji*

Main category: cs.CL

TL;DR: Spotlight Attention通过新型非线性哈希方法优化大模型KV缓存，加速推理。


<details>
  <summary>Details</summary>
Motivation: 解决传统随机线性哈希方法效率低的问题，并提升推理性能。

Method: 提出Spotlight Attention，它结合非线性哈希函数与Bradley-Terry排名损失优化，使用轻量框架在GPU上高效训练。

Result: Spotlight Attention提升了检索精度，将码长缩短至少5倍，同时在A100 GPU上实现512K令牌的高效检索，推理速度提高3倍。

Conclusion: 该方法显著改善了KV缓存管理的效率和稳定性，为大语言模型推理开辟了更高效的途径。

Abstract: Reducing the key-value (KV) cache burden in Large Language Models (LLMs)
significantly accelerates inference. Dynamically selecting critical KV caches
during decoding helps maintain performance. Existing methods use random linear
hashing to identify important tokens, but this approach is inefficient due to
the orthogonal distribution of queries and keys within two narrow cones in
LLMs. We introduce Spotlight Attention, a novel method that employs non-linear
hashing functions to optimize the embedding distribution of queries and keys,
enhancing coding efficiency and robustness. We also developed a lightweight,
stable training framework using a Bradley-Terry ranking-based loss, enabling
optimization of the non-linear hashing module on GPUs with 16GB memory in 8
hours. Experimental results show that Spotlight Attention drastically improves
retrieval precision while shortening the length of the hash code at least
5$\times$ compared to traditional linear hashing. Finally, we exploit the
computational advantages of bitwise operations by implementing specialized CUDA
kernels, achieving hashing retrieval for 512K tokens in under 100$\mu$s on a
single A100 GPU, with end-to-end throughput up to 3$\times$ higher than vanilla
decoding.

</details>


### [127] [Uncovering the Bigger Picture: Comprehensive Event Understanding Via Diverse News Retrieval](https://arxiv.org/abs/2508.19758)
*Yixuan Tang,Yuanyuan Shi,Yiqun Sun,Anthony Kum Hoe Tung*

Main category: cs.CL

TL;DR: 提出了一种名为NEWSCOPE的两阶段框架，用于多样化新闻检索，能有效提高事件覆盖范围并减少信息冗余。


<details>
  <summary>Details</summary>
Motivation: 当前新闻检索系统倾向于优先保证文本相关性，导致结果冗余和视角单一。

Method: 两个阶段：1. 使用密集检索获取主题相关内容；2. 基于句子级别的聚类和多样性排序，呈现互补信息。并引入三个可解释指标和两个新的评估基准。

Result: NEWSCOPE在实验中表现突出，在提升结果多样性同时未损失相关性。

Conclusion: 细粒度且可解释的建模方式可减少新闻冗余，促进全面的事件理解。

Abstract: Access to diverse perspectives is essential for understanding real-world
events, yet most news retrieval systems prioritize textual relevance, leading
to redundant results and limited viewpoint exposure. We propose NEWSCOPE, a
two-stage framework for diverse news retrieval that enhances event coverage by
explicitly modeling semantic variation at the sentence level. The first stage
retrieves topically relevant content using dense retrieval, while the second
stage applies sentence-level clustering and diversity-aware re-ranking to
surface complementary information. To evaluate retrieval diversity, we
introduce three interpretable metrics, namely Average Pairwise Distance,
Positive Cluster Coverage, and Information Density Ratio, and construct two
paragraph-level benchmarks: LocalNews and DSGlobal. Experiments show that
NEWSCOPE consistently outperforms strong baselines, achieving significantly
higher diversity without compromising relevance. Our results demonstrate the
effectiveness of fine-grained, interpretable modeling in mitigating redundancy
and promoting comprehensive event understanding. The data and code are
available at https://github.com/tangyixuan/NEWSCOPE.

</details>


### [128] [Principled Personas: Defining and Measuring the Intended Effects of Persona Prompting on Task Performance](https://arxiv.org/abs/2508.19764)
*Pedro Henrique Luz de Araujo,Paul Röttger,Dirk Hovy,Benjamin Roth*

Main category: cs.CL

TL;DR: 文本探讨了给予语言模型专家角色是否有助于任务表现，发现其效果因任务而异且需更精心设计。


<details>
  <summary>Details</summary>
Motivation: 探讨专家角色设定对语言模型任务表现的影响与潜在问题。

Method: 通过分析文献，归纳出三个理想指标，并使用9个LLMs在27项任务上进行评估，提出了改进模型稳健性的策略。

Result: 专家角色设定大多正面或无显著影响，但对无关角色细节异常敏感，改进方法仅在能力最强的大模型中有效。

Conclusion: 需要更加谨慎的角色设定设计以及与角色使用效果一致的评估方案。

Abstract: Expert persona prompting -- assigning roles such as expert in math to
language models -- is widely used for task improvement. However, prior work
shows mixed results on its effectiveness, and does not consider when and why
personas should improve performance. We analyze the literature on persona
prompting for task improvement and distill three desiderata: 1) performance
advantage of expert personas, 2) robustness to irrelevant persona attributes,
and 3) fidelity to persona attributes. We then evaluate 9 state-of-the-art LLMs
across 27 tasks with respect to these desiderata. We find that expert personas
usually lead to positive or non-significant performance changes. Surprisingly,
models are highly sensitive to irrelevant persona details, with performance
drops of almost 30 percentage points. In terms of fidelity, we find that while
higher education, specialization, and domain-relatedness can boost performance,
their effects are often inconsistent or negligible across tasks. We propose
mitigation strategies to improve robustness -- but find they only work for the
largest, most capable models. Our findings underscore the need for more careful
persona design and for evaluation schemes that reflect the intended effects of
persona usage.

</details>


### [129] [T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables](https://arxiv.org/abs/2508.19813)
*Jie Zhang,Changzai Pan,Kaiwen Wei,Sishi Xiong,Yu Zhao,Xiangyu Li,Jiaxin Peng,Xiaoyan Gu,Jian Yang,Wenhan Chang,Zhenhe Wu,Jiang Zhong,Shuangyong Song,Yongxiang Li,Xuelong Li*

Main category: cs.CL

TL;DR: 本文探索大语言模型（LLMs）在表格推理中的能力，提出了表格到报告的任务及一个双语基准T2R-bench，用于评估模型在工业应用中的性能。实验结果显示现有LLMs仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 促进LLMs在工业场景中从表格信息生成报告的能力，并弥补现有基准评估能力不足的空白。

Method: 提出表格到报告任务，并构建T2R-bench基准数据集，涵盖457个真实工业表格，19个行业领域及4种表格类型，还设计了一套评价指标来评估报告生成质量。

Result: 实验测试了25种LLMs，表明即使是最先进的模型Deepseek-R1也仅取得62.71的总分，验证了提升LLMs能力的必要性。

Conclusion: LLMs在复杂表格到报告生成的任务中仍有显著发展空间，所提出的T2R-bench基准具有重要意义以推动该领域的发展。

Abstract: Extensive research has been conducted to explore the capabilities of large
language models (LLMs) in table reasoning. However, the essential task of
transforming tables information into reports remains a significant challenge
for industrial applications. This task is plagued by two critical issues: 1)
the complexity and diversity of tables lead to suboptimal reasoning outcomes;
and 2) existing table benchmarks lack the capacity to adequately assess the
practical application of this task. To fill this gap, we propose the
table-to-report task and construct a bilingual benchmark named T2R-bench, where
the key information flow from the tables to the reports for this task. The
benchmark comprises 457 industrial tables, all derived from real-world
scenarios and encompassing 19 industry domains as well as 4 types of industrial
tables. Furthermore, we propose an evaluation criteria to fairly measure the
quality of report generation. The experiments on 25 widely-used LLMs reveal
that even state-of-the-art models like Deepseek-R1 only achieves performance
with 62.71 overall score, indicating that LLMs still have room for improvement
on T2R-bench. Source code and data will be available after acceptance.

</details>


### [130] [Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning](https://arxiv.org/abs/2508.19828)
*Sikuan Yan,Xiufeng Yang,Zuchao Huang,Ercong Nie,Zifeng Ding,Zonggen Li,Xiaowen Ma,Hinrich Schütze,Volker Tresp,Yunpu Ma*

Main category: cs.CL

TL;DR: 本文提出了Memory-R1，一种强化学习框架，赋予大语言模型(LLMs)主动管理和利用外部记忆的能力，超越了现有最强基线，在多种问题类型中表现出强泛化性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型尽管在NLP任务上表现出色，但因缺乏状态性和上下文窗口限制，其长时间推理能力受制约。现有增强策略多通过外部记忆库支持，但往往是静态的、依赖于启发式规则，缺乏学习机制。

Method: 引入Memory-R1框架，设置两个专门的智能体：记忆管理器，学习执行结构化记忆操作（如添加、更新、删除等）；回答智能体，选择最相关的记忆内容并进行推理。通过强化学习算法(PPO和GRPO)微调两者以实现适应性记忆管理。

Result: 使用仅152个问答对和对应的时间记忆库进行训练时，Memory-R1已超越现有最强基线，同时在多种问题类型和语言模型后端上展现了强泛化能力。

Conclusion: Memory-R1的研究揭示了强化学习如何促进LLMs实现更智能的、记忆感知的行为，推动更加丰富和持久的推理系统发展。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities across
a wide range of NLP tasks, but they remain fundamentally stateless, constrained
by limited context windows that hinder long-horizon reasoning. Recent efforts
to address this limitation often augment LLMs with an external memory bank, yet
most existing pipelines are static and heuristic-driven, lacking any learned
mechanism for deciding what to store, update, or retrieve. We present
Memory-R1, a reinforcement learning (RL) framework that equips LLMs with the
ability to actively manage and utilize external memory through two specialized
agents: a Memory Manager that learns to perform structured memory operations
{ADD, UPDATE, DELETE, NOOP}, and an Answer Agent that selects the most relevant
entries and reasons over them to produce an answer. Both agents are fine-tuned
with outcome-driven RL (PPO and GRPO), enabling adaptive memory management and
use with minimal supervision. With as few as 152 question-answer pairs and a
corresponding temporal memory bank for training, Memory-R1 outperforms the most
competitive existing baseline and demonstrates strong generalization across
diverse question types and LLM backbones. Beyond presenting an effective
approach, this work provides insights into how RL can unlock more agentic,
memory-aware behaviors in LLMs, pointing toward richer, more persistent
reasoning systems.

</details>


### [131] [Benchmarking Hindi LLMs: A New Suite of Datasets and a Comparative Analysis](https://arxiv.org/abs/2508.19831)
*Anusha Kamath,Kanishk Singla,Rakesh Paul,Raviraj Joshi,Utkarsh Vaidya,Sanjay Singh Chauhan,Niranjan Wartikar*

Main category: cs.CL

TL;DR: 本文介绍了五个用于评估印度语大语言模型的基准数据集，并进行基于这些数据集的模型分析。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏高质量的评估基准，评估印度语言模型的能力变得困难，现有方法无法捕捉语言和文化的细微差别。

Method: 提出了一种结合从头人工注释与翻译验证的方法，创建了五个针对印度语的评估数据集，并基于这些数据集对多种开源模型进行了综合分析。

Result: 生成的五个评估数据集可以可靠地评估印度语语言模型的性能，同时提供了一种可复制的方法来开发其他低资源语言的基准。

Conclusion: 本文提出的评估方法和数据集不仅提升了对印度语大语言模型的评估质量，还为低资源语言的模型评估提供了新路径。

Abstract: Evaluating instruction-tuned Large Language Models (LLMs) in Hindi is
challenging due to a lack of high-quality benchmarks, as direct translation of
English datasets fails to capture crucial linguistic and cultural nuances. To
address this, we introduce a suite of five Hindi LLM evaluation datasets:
IFEval-Hi, MT-Bench-Hi, GSM8K-Hi, ChatRAG-Hi, and BFCL-Hi. These were created
using a methodology that combines from-scratch human annotation with a
translate-and-verify process. We leverage this suite to conduct an extensive
benchmarking of open-source LLMs supporting Hindi, providing a detailed
comparative analysis of their current capabilities. Our curation process also
serves as a replicable methodology for developing benchmarks in other
low-resource languages.

</details>


### [132] [Scalable and consistent few-shot classification of survey responses using text embeddings](https://arxiv.org/abs/2508.19836)
*Jonas Timmann Mjaaland,Markus Fleten Kreutzer,Halvor Tyseng,Rebeckah K. Fussell,Gina Passante,N. G. Holmes,Anders Malthe-Sørenssen,Tor Ole B. Odden*

Main category: cs.CL

TL;DR: 本文提出了一种基于文本嵌入的分类框架，能够支持少量示例即可进行开放式调查问卷的质量分析，并与现有社科研究中的质性工作流很好地兼容。


<details>
  <summary>Details</summary>
Motivation: 传统质性分析方法耗时且易受不一致性影响，而现有的NLP解决方案要求大量标签数据或不符合现有工作流的需求，亟需一种高效且可扩展的方法。

Method: 提出了一种基于文本嵌入的分类框架，仅需少量示例数据，结合预训练模型和微调技术来提高编码准确性，并与标准质性分析流程兼容。

Result: 方法在物理概念调查数据中验证，达到了Cohen's Kappa值0.74至0.83，与专家一致性高。此外，通过微调嵌入模型进一步提升了性能，证明其在大规模数据集上的可行性。

Conclusion: 基于文本嵌入的编码方法可灵活处理数千条响应，兼顾可解释性及扩展性，为大规模质性分析提供了新思路。

Abstract: Qualitative analysis of open-ended survey responses is a commonly-used
research method in the social sciences, but traditional coding approaches are
often time-consuming and prone to inconsistency. Existing solutions from
Natural Language Processing such as supervised classifiers, topic modeling
techniques, and generative large language models have limited applicability in
qualitative analysis, since they demand extensive labeled data, disrupt
established qualitative workflows, and/or yield variable results. In this
paper, we introduce a text embedding-based classification framework that
requires only a handful of examples per category and fits well with standard
qualitative workflows. When benchmarked against human analysis of a conceptual
physics survey consisting of 2899 open-ended responses, our framework achieves
a Cohen's Kappa ranging from 0.74 to 0.83 as compared to expert human coders in
an exhaustive coding scheme. We further show how performance of this framework
improves with fine-tuning of the text embedding model, and how the method can
be used to audit previously-analyzed datasets. These findings demonstrate that
text embedding-assisted coding can flexibly scale to thousands of responses
without sacrificing interpretability, opening avenues for deductive qualitative
analysis at scale.

</details>


### [133] [TokenVerse++: Towards Flexible Multitask Learning with Dynamic Task Activation](https://arxiv.org/abs/2508.19856)
*Shashi Kumar,Srikanth Madikeri,Esaú Villatoro-Tello,Sergio Burdisso,Pradeep Rangappa,Andrés Carofilis,Petr Motlicek,Karthik Pandia,Shankar Venkatesan,Kadri Hacioğlu,Andreas Stolcke*

Main category: cs.CL

TL;DR: TokenVerse++提出一种多任务学习方法，通过动态任务激活机制解决了TokenVerse需全标注数据的问题，在多个任务上表现优异，且未降低ASR性能。


<details>
  <summary>Details</summary>
Motivation: 现有的TokenVerse框架需要所有任务的数据都具备完整标注，这限制了其扩展和部分标注数据的利用能力。

Method: 引入可学习向量至XLSR-Transducer ASR模型的声学嵌入空间，实现动态任务激活，允许利用仅部分任务有标注的数据进行训练。

Result: 在集成部分标注数据集（如ASR和语言识别任务）后，TokenVerse++表现可与TokenVerse持平或超越，尤其在任务扩展性方面更具优势。

Conclusion: TokenVerse++作为一种更加实用的多任务学习框架，解决了TokenVerse的局限性，且保证了ASR性能不受影响。

Abstract: Token-based multitasking frameworks like TokenVerse require all training
utterances to have labels for all tasks, hindering their ability to leverage
partially annotated datasets and scale effectively. We propose TokenVerse++,
which introduces learnable vectors in the acoustic embedding space of the
XLSR-Transducer ASR model for dynamic task activation. This core mechanism
enables training with utterances labeled for only a subset of tasks, a key
advantage over TokenVerse. We demonstrate this by successfully integrating a
dataset with partial labels, specifically for ASR and an additional task,
language identification, improving overall performance. TokenVerse++ achieves
results on par with or exceeding TokenVerse across multiple tasks, establishing
it as a more practical multitask alternative without sacrificing ASR
performance.

</details>


### [134] [Beyond Shallow Heuristics: Leveraging Human Intuition for Curriculum Learning](https://arxiv.org/abs/2508.19873)
*Vanessa Toborek,Sebastian Müller,Tim Selbach,Tamás Horváth,Christian Bauckhage*

Main category: cs.CL

TL;DR: 本文探讨了通过简单语言引导课程学习是否可以改善语言模型的预训练得分，发现适当的课程结构化输入可以显著提升简单语言的困惑度指标。


<details>
  <summary>Details</summary>
Motivation: 课程学习通过从易到难的呈现数据来优化模型训练，但语言难度的定义和测量仍然是个难题。本文尝试利用人工设计的简单语言作为课程学习的信号。

Method: 利用Simple Wikipedia语料库中的文章级别标签，比较了基于标签的课程和基于模型训练能力的课程，并采用BERT-tiny模型进行实验。

Result: 实验表明，仅仅添加简单语言数据并未带来显著好处，但通过课程学习策略，尤其是优先引入简单数据，能显著降低困惑度。然而基于训练能力的课程学习未能产生一致的效果。

Conclusion: 研究表明，人工对语言难度的直觉可以为语言模型的课程学习提供有效的指导。

Abstract: Curriculum learning (CL) aims to improve training by presenting data from
"easy" to "hard", yet defining and measuring linguistic difficulty remains an
open challenge. We investigate whether human-curated simple language can serve
as an effective signal for CL. Using the article-level labels from the Simple
Wikipedia corpus, we compare label-based curricula to competence-based
strategies relying on shallow heuristics. Our experiments with a BERT-tiny
model show that adding simple data alone yields no clear benefit. However,
structuring it via a curriculum -- especially when introduced first --
consistently improves perplexity, particularly on simple language. In contrast,
competence-based curricula lead to no consistent gains over random ordering,
probably because they fail to effectively separate the two classes. Our results
suggest that human intuition about linguistic difficulty can guide CL for
language model pre-training.

</details>


### [135] [AI-Powered Detection of Inappropriate Language in Medical School Curricula](https://arxiv.org/abs/2508.19883)
*Chiman Salavati,Shannon Song,Scott A. Hale,Roberto E. Montenegro,Shiri Dori-Hacohen,Fabricio Murai*

Main category: cs.CL

TL;DR: 该论文研究了小型语言模型（SLMs）和大型语言模型（LLMs）在检测医学教学材料中不适当语言的性能，发现SLMs表现优于LLMs。


<details>
  <summary>Details</summary>
Motivation: 医学教学材料中不适当语言的存在可能影响临床训练和患者健康，因此需要高效方法检测这些语言。

Method: 使用包含约500份文档和12000页的数据集，分别评估了SLMs和LLMs在检测不适当语言方面的性能，并测试了多种模型结构和提示策略。

Result: SLMs表现优异，尤其是多标签分类器表现最佳。此外，加入未标记负例后，二分类器的AUC提升高达25%。

Conclusion: SLMs在检测不适当语言方面效果更佳，提出的方法可以有效减少医学课程中有害语言的使用。

Abstract: The use of inappropriate language -- such as outdated, exclusionary, or
non-patient-centered terms -- medical instructional materials can significantly
influence clinical training, patient interactions, and health outcomes. Despite
their reputability, many materials developed over past decades contain examples
now considered inappropriate by current medical standards. Given the volume of
curricular content, manually identifying instances of inappropriate use of
language (IUL) and its subcategories for systematic review is prohibitively
costly and impractical. To address this challenge, we conduct a first-in-class
evaluation of small language models (SLMs) fine-tuned on labeled data and
pre-trained LLMs with in-context learning on a dataset containing approximately
500 documents and over 12,000 pages. For SLMs, we consider: (1) a general IUL
classifier, (2) subcategory-specific binary classifiers, (3) a multilabel
classifier, and (4) a two-stage hierarchical pipeline for general IUL detection
followed by multilabel classification. For LLMs, we consider variations of
prompts that include subcategory definitions and/or shots. We found that both
LLama-3 8B and 70B, even with carefully curated shots, are largely outperformed
by SLMs. While the multilabel classifier performs best on annotated data,
supplementing training with unflagged excerpts as negative examples boosts the
specific classifiers' AUC by up to 25%, making them most effective models for
mitigating harmful language in medical curricula.

</details>


### [136] [Bangla-Bayanno: A 52K-Pair Bengali Visual Question Answering Dataset with LLM-Assisted Translation Refinement](https://arxiv.org/abs/2508.19887)
*Mohammed Rakibul Hasan,Rafi Majid,Ahanaf Tahmid*

Main category: cs.CL

TL;DR: 本文介绍了一个名为Bangla-Bayanno的开放式视觉问答数据集，聚焦于低资源语言孟加拉语，共包含52,650个问题答案对，分类为三种回答类型：名义型、数量型和极性型。


<details>
  <summary>Details</summary>
Motivation: 多数现有数据集受到特定域、查询类型或答案格式的局限性，且翻译质量参差不齐。提出Bangla-Bayanno是为了弥补这些不足，为低资源语言的多模态AI研究提供支持。

Method: 通过多语言大模型辅助的翻译优化流程，确保数据集的高质量翻译及清晰度，并基于4750+幅图像创建了 52,650 个问答对。提供三种回答类型分类，以覆盖更广的适用场景。

Result: 构建了一个高质量、开放的孟加拉语视觉问答基准数据集Bangla-Bayanno，解决了多语言翻译质量参差以及传统数据集局限性的问题。

Conclusion: Bangla-Bayanno成为首个高质量的孟加拉语视觉问答基准，旨在推动低资源多模态学习研究并促进更具包容性的AI系统开发。

Abstract: In this paper, we introduce Bangla-Bayanno, an open-ended Visual Question
Answering (VQA) Dataset in Bangla, a widely used, low-resource language in
multimodal AI research. The majority of existing datasets are either manually
annotated with an emphasis on a specific domain, query type, or answer type or
are constrained by niche answer formats. In order to mitigate human-induced
errors and guarantee lucidity, we implemented a multilingual LLM-assisted
translation refinement pipeline. This dataset overcomes the issues of
low-quality translations from multilingual sources. The dataset comprises
52,650 question-answer pairs across 4750+ images. Questions are classified into
three distinct answer types: nominal (short descriptive), quantitative
(numeric), and polar (yes/no). Bangla-Bayanno provides the most comprehensive
open-source, high-quality VQA benchmark in Bangla, aiming to advance research
in low-resource multimodal learning and facilitate the development of more
inclusive AI systems.

</details>


### [137] [Logical Reasoning with Outcome Reward Models for Test-Time Scaling](https://arxiv.org/abs/2508.19903)
*Ramya Keerthy Thatikonda,Wray Buntine,Ehsan Shareghi*

Main category: cs.CL

TL;DR: 本文提出并研究了用于演绎逻辑推理任务的结果奖励模型（ORMs），并通过链式思维（CoT）生成和Echo生成策略改进了模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究目的是提升大语言模型在复杂演绎逻辑推理任务上推导出有效结论的能力，探索如何更好地利用测试时扩展与奖励模型提升逻辑推理性能。

Method: 首先通过链式思维（CoT）生成单个和多个样例的数据用于ORMs训练，此外创新性地引入“Echo生成策略”，从LLM对错误假设的反映中提取额外数据以涵盖新类型的错误。

Result: 训练后的ORMs在FOLIO, JustLogic 和 ProverQA等数据集上的逻辑推理表现获得了显著提升，验证了方法的有效性。

Conclusion: 通过CoT 和 echo 数据增强技术，可以训练更强大的结果奖励模型，有效提升演绎逻辑推理任务的表现，为逻辑推理增强任务提供了新方向。

Abstract: Logical reasoning is a critical benchmark for evaluating the capabilities of
large language models (LLMs), as it reflects their ability to derive valid
conclusions from given premises. While the combination of test-time scaling
with dedicated outcome or process reward models has opened up new avenues to
enhance LLMs performance in complex reasoning tasks, this space is
under-explored in deductive logical reasoning. We present a set of Outcome
Reward Models (ORMs) for deductive reasoning. To train the ORMs we mainly
generate data using Chain-of-Thought (CoT) with single and multiple samples.
Additionally, we propose a novel tactic to further expand the type of errors
covered in the training dataset of the ORM. In particular, we propose an echo
generation technique that leverages LLMs' tendency to reflect incorrect
assumptions made in prompts to extract additional training data, covering
previously unexplored error types. While a standard CoT chain may contain
errors likely to be made by the reasoner, the echo strategy deliberately steers
the model toward incorrect reasoning. We show that ORMs trained on CoT and
echo-augmented data demonstrate improved performance on the FOLIO, JustLogic,
and ProverQA datasets across four different LLMs.

</details>


### [138] [Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2508.19919)
*Jingyu Guo,Yingying Xu*

Main category: cs.CL

TL;DR: 研究发现基于大语言模型（LLM）的多智能体系统在没有预先设定偏见的情况下，也会在交互过程中自发形成刻板印象，并随着交互轮次和决策权力的增加而加剧。


<details>
  <summary>Details</summary>
Motivation: 探讨AI系统中刻板印象是否能够在无偏见的初始条件下通过智能体交互自动生成。

Method: 设计模拟工作场景的新实验框架，分析基于LLM的多智能体系统在中立初始条件下的交互过程及其刻板印象的生成和演变。

Result: 研究发现：1. AI智能体在无预定义偏见下能自发形成由刻板印象驱动的偏见；2. 更多的交互与更强的决策权会加剧刻板印象，特别是在引入层级结构后；3. 系统表现出类似人类的社会行为，包括光环效应、确认偏误和角色一致性；4. 这些现象在不同的LLM架构中都有一致性。

Conclusion: AI系统中的刻板印象可能是多智能体交互的涌现特性，而不仅仅来源于训练数据的偏见。这一发现强调了未来需要探索其机制并开发减轻伦理影响的策略。

Abstract: While stereotypes are well-documented in human social interactions, AI
systems are often presumed to be less susceptible to such biases. Previous
studies have focused on biases inherited from training data, but whether
stereotypes can emerge spontaneously in AI agent interactions merits further
exploration. Through a novel experimental framework simulating workplace
interactions with neutral initial conditions, we investigate the emergence and
evolution of stereotypes in LLM-based multi-agent systems. Our findings reveal
that (1) LLM-Based AI agents develop stereotype-driven biases in their
interactions despite beginning without predefined biases; (2) stereotype
effects intensify with increased interaction rounds and decision-making power,
particularly after introducing hierarchical structures; (3) these systems
exhibit group effects analogous to human social behavior, including halo
effects, confirmation bias, and role congruity; and (4) these stereotype
patterns manifest consistently across different LLM architectures. Through
comprehensive quantitative analysis, these findings suggest that stereotype
formation in AI systems may arise as an emergent property of multi-agent
interactions, rather than merely from training data biases. Our work
underscores the need for future research to explore the underlying mechanisms
of this phenomenon and develop strategies to mitigate its ethical impacts.

</details>


### [139] [HEAL: A Hypothesis-Based Preference-Aware Analysis Framework](https://arxiv.org/abs/2508.19922)
*Yifu Huo,Chenglong Wang,Qiren Zhu,Shunjie Xing,Tong Xiao,Chunliang Zhang,Tongran Liu,Jinbo Zhu*

Main category: cs.CL

TL;DR: 本文提出了HEAL评估框架，用于解决现有偏好优化方法评估单一输出的问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有偏好优化方法评估只基于单一输出、无法全面反映潜在生成输出的问题。

Method: 提出HEAL，作为假设空间中的重新排序过程评估偏好对齐，包含排名准确性和偏好强度相关性两种指标。并开发了统一假设基准UniHypoBench。

Result: 实验表明当前偏好学习方法能够有效捕捉代理模型提供的偏好并抑制负样本。

Conclusion: 理论上引入假设空间分析创新范式；实际为优化偏好方法提供诊断工具，并指出改进算法方向。

Abstract: Preference optimization methods like DPO have achieved remarkable performance
in LLM alignment. However, the evaluation for these methods relies on a single
response and overlooks other potential outputs, which could also be generated
in real-world applications within this hypothetical space. To address this
issue, this paper presents a \textbf{H}ypothesis-based
Pr\textbf{E}ference-aware \textbf{A}na\textbf{L}ysis Framework (HEAL), a novel
evaluation paradigm that formulates preference alignment as a re-ranking
process within hypothesis spaces. The framework incorporates two complementary
metrics: ranking accuracy for evaluating ordinal consistency and preference
strength correlation for assessing continuous alignment. To facilitate this
framework, we develop UniHypoBench, a unified hypothesis benchmark constructed
from diverse instruction-response pairs. Through extensive experiments based on
HEAL, with a particular focus on the intrinsic mechanisms of preference
learning, we demonstrate that current preference learning methods can
effectively capture preferences provided by proxy models while simultaneously
suppressing negative samples. These findings contribute to preference learning
research through two significant avenues. Theoretically, we introduce
hypothesis space analysis as an innovative paradigm for understanding
preference alignment. Practically, HEAL offers researchers robust diagnostic
tools for refining preference optimization methods, while our empirical results
identify promising directions for developing more advanced alignment algorithms
capable of comprehensive preference capture.

</details>


### [140] [Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation](https://arxiv.org/abs/2508.19966)
*Slimane Bellaouar,Attia Nehar,Soumia Souffi,Mounia Bouameur*

Main category: cs.CL

TL;DR: 该研究提出了一种新的阿拉伯语主观性分析方法，并开发了一个综合性数据集AraDhati+，结合多种模型实现了97.79%的准确率。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语资源有限，其语言复杂性导致主观性分析发展的困难，因此需要开发高效的分析方法与数据集。

Method: 通过整合多个现有的阿拉伯语数据集创建AraDhati+数据集，对XLM-RoBERTa、AraBERT和ArabianGPT等先进语言模型进行微调，并尝试模型集成决策的方法。

Result: 实现了97.79%的阿拉伯语主观性分类准确率，证明了方法的有效性。

Conclusion: 该研究表明，结合定制数据集和先进语言模型的方法可以成功应对阿拉伯语自然语言处理中的资源受限问题，为未来研究开辟了新方向。

Abstract: Despite its significance, Arabic, a linguistically rich and morphologically
complex language, faces the challenge of being under-resourced. The scarcity of
large annotated datasets hampers the development of accurate tools for
subjectivity analysis in Arabic. Recent advances in deep learning and
Transformers have proven highly effective for text classification in English
and French. This paper proposes a new approach for subjectivity assessment in
Arabic textual data. To address the dearth of specialized annotated datasets,
we developed a comprehensive dataset, AraDhati+, by leveraging existing Arabic
datasets and collections (ASTD, LABR, HARD, and SANAD). Subsequently, we
fine-tuned state-of-the-art Arabic language models (XLM-RoBERTa, AraBERT, and
ArabianGPT) on AraDhati+ for effective subjectivity classification.
Furthermore, we experimented with an ensemble decision approach to harness the
strengths of individual models. Our approach achieves a remarkable accuracy of
97.79\,\% for Arabic subjectivity classification. Results demonstrate the
effectiveness of the proposed approach in addressing the challenges posed by
limited resources in Arabic language processing.

</details>


### [141] [Diffusion Language Models Know the Answer Before Decoding](https://arxiv.org/abs/2508.19982)
*Pengxiang Li,Yefan Zhou,Dilxat Muhtar,Lu Yin,Shilin Yan,Li Shen,Yi Liang,Soroush Vosoughi,Shiwei Liu*

Main category: cs.CL

TL;DR: 该论文提出了一种名为Prophet的解码范式，通过利用扩散语言模型（DLM）中早期答案收敛的特性，大幅减少解码步骤，提高推理速度，同时保持高生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型尽管具有并行生成及灵活的令牌排序的优势，但其推理速度仍然慢于自回归模型，主要由于双向注意力和大量优化步骤的开销。本研究动机是通过减少模型解码步骤来加速推理。

Method: 发现DLM在解码过程中答案早期收敛的特性，并提出Prophet解码范式，通过动态决定是否继续优化或一次性完成解码（"all-in"），以前两名预测结果的置信度差距为标准，自适应停止解码。该方法无需额外训练，能无缝整合到现有DLM实现中，并带来很小额外开销。

Result: 实验证明，使用Prophet后，在多个任务上，LLaDA-8B和Dream-7B的解码步骤减少了最多3.4倍，且生成质量保持较高水平。

Conclusion: Prophet将DLM解码问题转化为何时停止优化的问题，表明答案早期收敛是加速推理的一种简单但有效的技术手段，与现有提速方法互为补充。

Abstract: Diffusion language models (DLMs) have recently emerged as an alternative to
autoregressive approaches, offering parallel sequence generation and flexible
token orders. However, their inference remains slower than that of
autoregressive models, primarily due to the cost of bidirectional attention and
the large number of refinement steps required for high quality outputs. In this
work, we highlight and leverage an overlooked property of DLMs early answer
convergence: in many cases, the correct answer can be internally identified by
half steps before the final decoding step, both under semi-autoregressive and
random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99%
of instances, respectively, can be decoded correctly using only half of the
refinement steps. Building on this observation, we introduce Prophet, a
training-free fast decoding paradigm that enables early commit decoding.
Specifically, Prophet dynamically decides whether to continue refinement or to
go "all-in" (i.e., decode all remaining tokens in one step), using the
confidence gap between the top-2 prediction candidates as the criterion. It
integrates seamlessly into existing DLM implementations, incurs negligible
overhead, and requires no additional training. Empirical evaluations of
LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the
number of decoding steps by up to 3.4x while preserving high generation
quality. These results recast DLM decoding as a problem of when to stop
sampling, and demonstrate that early decode convergence provides a simple yet
powerful mechanism for accelerating DLM inference, complementary to existing
speedup techniques. Our code is publicly available at
https://github.com/pixeli99/Prophet.

</details>


### [142] [AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios](https://arxiv.org/abs/2508.19988)
*Lisa Alazraki,Lihu Chen,Ana Brassard,Joe Stacey,Hossein A. Rahmani,Marek Rei*

Main category: cs.CL

TL;DR: 本研究提出了一个名为AgentCoMa的新基准，用以评估大型语言模型（LLMs）在混合常识与数学推理任务中的表现，发现模型在单独推理中表现较好，但组合任务表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要评估LLMs在常识推理或数学推理中的能力，而真实任务通常需要结合两者的能力，因此需要开发新的基准来评估这种混合推理能力。

Method: 提出AgentCoMa基准，每个任务要求结合常识推理和数学推理的步骤，并测试了61种不同规模、训练策略的LLMs，研究了它们在单步与组合任务上的表现落差；通过神经元模式、注意力图和成员推断等技术进行解释性分析。

Result: 研究发现，LLMs在单独处理常识或数学推理步骤时表现良好，但在要求组合两种推理时，其准确率平均下降约30%，这一表现落差在先前的仅同类型推理基准中并未出现。

Conclusion: LLMs在混合类型推理任务中的显著脆弱性需要关注，AgentCoMa可作为未来改进和研究的测试平台。

Abstract: Large Language Models (LLMs) have achieved high accuracy on complex
commonsense and mathematical problems that involve the composition of multiple
reasoning steps. However, current compositional benchmarks testing these skills
tend to focus on either commonsense or math reasoning, whereas LLM agents
solving real-world tasks would require a combination of both. In this work, we
introduce an Agentic Commonsense and Math benchmark (AgentCoMa), where each
compositional task requires a commonsense reasoning step and a math reasoning
step. We test it on 61 LLMs of different sizes, model families, and training
strategies. We find that LLMs can usually solve both steps in isolation, yet
their accuracy drops by ~30% on average when the two are combined. This is a
substantially greater performance gap than the one we observe in prior
compositional benchmarks that combine multiple steps of the same reasoning
type. In contrast, non-expert human annotators can solve the compositional
questions and the individual steps in AgentCoMa with similarly high accuracy.
Furthermore, we conduct a series of interpretability studies to better
understand the performance gap, examining neuron patterns, attention maps and
membership inference. Our work underscores a substantial degree of model
brittleness in the context of mixed-type compositional reasoning and offers a
test bed for future improvement.

</details>


### [143] [MathBuddy: A Multimodal System for Affective Math Tutoring](https://arxiv.org/abs/2508.19993)
*Debanjana Kar,Leopold Böss,Dacia Braca,Sebastian Maximilian Dennerlein,Nina Christine Hubig,Philipp Wintersberger,Yufang Hou*

Main category: cs.CL

TL;DR: 文章提出了一种名为MathBuddy的情感感知数学学习助手，通过结合学生情绪与语言模型改进其教学能力，并在实验应用中展现了显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有的学习模型缺乏对学生情感状态的关注，而研究表明情绪对学习能力有重要影响，因此需要设计一种情感意识融入教学的方法。

Method: 通过学生对话文本和面部表情捕捉情绪，并结合语言模型生成情感感知的教学策略，打造更具同理心的数学学习助手。

Result: 实验表明，该模型在八个教学维度上的评价中取得了显著提升，测试中胜率提高23分，DAMR总体得分提高3分。

Conclusion: 为LLM创建的情感感知系统有助于显著增强教学效果，展示了将学生情感与模型结合的新可能性。

Abstract: The rapid adoption of LLM-based conversational systems is already
transforming the landscape of educational technology. However, the current
state-of-the-art learning models do not take into account the student's
affective states. Multiple studies in educational psychology support the claim
that positive or negative emotional states can impact a student's learning
capabilities. To bridge this gap, we present MathBuddy, an emotionally aware
LLM-powered Math Tutor, which dynamically models the student's emotions and
maps them to relevant pedagogical strategies, making the tutor-student
conversation a more empathetic one. The student's emotions are captured from
the conversational text as well as from their facial expressions. The student's
emotions are aggregated from both modalities to confidently prompt our LLM
Tutor for an emotionally-aware response. We have effectively evaluated our
model using automatic evaluation metrics across eight pedagogical dimensions
and user studies. We report a massive 23 point performance gain using the win
rate and a 3 point gain at an overall level using DAMR scores which strongly
supports our hypothesis of improving LLM-based tutor's pedagogical abilities by
modeling students' emotions.

</details>


### [144] [ReSURE: Regularizing Supervision Unreliability for Multi-turn Dialogue Fine-tuning](https://arxiv.org/abs/2508.19996)
*Yiming Du,Yifan Xiang,Bin Liang,Dahua Lin,Kam-Fai Wong,Fei Tan*

Main category: cs.CL

TL;DR: 本文针对多轮对话系统中的监督质量问题，提出ReSURE方法，通过动态调整权重来缓解监督不可靠性对训练的负面影响。


<details>
  <summary>Details</summary>
Motivation: 解决多轮对话系统中因数据质量差导致性能下降的问题，尤其是早期回合的监督错误向后传播问题。

Method: 利用Welford在线统计方法估计逐回合的损失分布，动态调整训练样本的权重，减少不可靠监督的负面影响。

Result: 在单一来源和混合质量数据集上实验，ReSURE提升了系统稳定性和响应质量，且在多个基准上获得了正相关系数（0.21~1.0）。

Conclusion: ReSURE方法通过动态调整权重改善了低质量数据对训练的影响，为有效利用大规模数据提供了可能性。

Abstract: Fine-tuning multi-turn dialogue systems requires high-quality supervision but
often suffers from degraded performance when exposed to low-quality data.
Supervision errors in early turns can propagate across subsequent turns,
undermining coherence and response quality. Existing methods typically address
data quality via static prefiltering, which decouples quality control from
training and fails to mitigate turn-level error propagation. In this context,
we propose ReSURE (Regularizing Supervision UnREliability), an adaptive
learning method that dynamically down-weights unreliable supervision without
explicit filtering. ReSURE estimates per-turn loss distributions using
Welford's online statistics and reweights sample losses on the fly accordingly.
Experiments on both single-source and mixed-quality datasets show improved
stability and response quality. Notably, ReSURE enjoys positive Spearman
correlations (0.21 ~ 1.0 across multiple benchmarks) between response scores
and number of samples regardless of data quality, which potentially paves the
way for utilizing large-scale data effectively. Code is publicly available at
https://github.com/Elvin-Yiming-Du/ReSURE_Multi_Turn_Training.

</details>


### [145] [Selective Retrieval-Augmentation for Long-Tail Legal Text Classification](https://arxiv.org/abs/2508.19997)
*Boheng Mao*

Main category: cs.CL

TL;DR: 该论文提出了一种称为选择性检索增强（SRA）的方法，用于改善法律文本分类中稀有类别的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有的法律文本分类数据集中存在长尾标签分布问题，许多标签类别样本不足，导致模型对稀有类别的性能较差。

Method: SRA 方法通过给训练集中低频标签类别的样本进行增强，同时避免为高频类别引入噪声，且无需更改模型架构。此外，仅从训练数据中进行检索以防止信息泄漏，也不需要外部语料支持。

Result: SRA 方法在两个长尾分布的法律文本分类基准数据集上（LEDGAR 和 UNFAIR-ToS）进行了测试，结果显示其在 micro-F1 和 macro-F1 分数上优于当前所有 LexGLUE 的基线方法。

Conclusion: 选择性检索增强（SRA）方法在解决长尾分布的法律文本分类任务中表现出显著优势，是一种有效的解决方案。

Abstract: Legal text classification is a fundamental NLP task in the legal domain.
Benchmark datasets in this area often exhibit a long-tail label distribution,
where many labels are underrepresented, leading to poor model performance on
rare classes. This paper proposes Selective Retrieval-Augmentation (SRA) as a
solution to this problem. SRA focuses on augmenting samples belonging to
low-frequency labels in the training set, preventing the introduction of noise
for well-represented classes, and requires no changes to the model
architecture. Retrieval is performed only from the training data to ensure
there is no potential information leakage, removing the need for external
corpora simultaneously. The proposed SRA method is tested on two legal text
classification benchmark datasets with long-tail distributions: LEDGAR
(single-label) and UNFAIR-ToS (multi-label). The results indicate that SRA
attains higher micro-F1 and macro-F1 scores compared to all current LexGLUE
baselines across both datasets, illustrating consistent improvements in
long-tail legal text classification. The code repository is available at:
https://github.com/Boheng-Mao/sra-legal

</details>


### [146] [DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis](https://arxiv.org/abs/2508.20033)
*Liana Patel,Negar Arabzadeh,Harshit Gupta,Ankita Sundar,Ion Stoica,Matei Zaharia,Carlos Guestrin*

Main category: cs.CL

TL;DR: 本文引入了DeepScholar-bench，一个用于评估生成性研究综合能力的实时框架，并提出了DeepScholar-base作为参考管线。


<details>
  <summary>Details</summary>
Motivation: 解决现有问答基准无法满足对复杂、动态的研究综合任务评估需求的问题。

Method: 基于最近高质量ArXiv论文创建查询，并开发评估维度，设计一个参考实现方案DeepScholar-base，利用这个框架对多个系统进行系统性评估。

Result: DeepScholar-base表现优越，超过了其他方法，但DeepScholar-bench的整体得分仍低于19%，表明任务难度较高。

Conclusion: DeepScholar-bench为生成性研究综合能力提供了一个重要的基准评估工具，有助于推动该领域的发展。

Abstract: The ability to research and synthesize knowledge is central to human
expertise and progress. An emerging class of systems promises these exciting
capabilities through generative research synthesis, performing retrieval over
the live web and synthesizing discovered sources into long-form, cited
summaries. However, evaluating such systems remains an open challenge: existing
question-answering benchmarks focus on short-form factual responses, while
expert-curated datasets risk staleness and data contamination. Both fail to
capture the complexity and evolving nature of real research synthesis tasks. In
this work, we introduce DeepScholar-bench, a live benchmark and holistic,
automated evaluation framework designed to evaluate generative research
synthesis. DeepScholar-bench draws queries from recent, high-quality ArXiv
papers and focuses on a real research synthesis task: generating the related
work sections of a paper by retrieving, synthesizing, and citing prior
research. Our evaluation framework holistically assesses performance across
three key dimensions, knowledge synthesis, retrieval quality, and
verifiability. We also develop DeepScholar-base, a reference pipeline
implemented efficiently using the LOTUS API. Using the DeepScholar-bench
framework, we perform a systematic evaluation of prior open-source systems,
search AI's, OpenAI's DeepResearch, and DeepScholar-base. We find that
DeepScholar-base establishes a strong baseline, attaining competitive or higher
performance than each other method. We also find that DeepScholar-bench remains
far from saturated, with no system exceeding a score of $19\%$ across all
metrics. These results underscore the difficulty of DeepScholar-bench, as well
as its importance for progress towards AI systems capable of generative
research synthesis. We make our code available at
https://github.com/guestrin-lab/deepscholar-bench.

</details>


### [147] [Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks](https://arxiv.org/abs/2508.20038)
*Sheng Liu,Qiang Sheng,Danding Wang,Yang Li,Guang Yang,Juan Cao*

Main category: cs.CL

TL;DR: 针对大语言模型(LLM)在对抗恶意指令方面的脆弱性，提出了一种名为IMAGINE的生成框架，通过嵌入空间分布分析生成类似恶意指令以填补分布鸿沟，从而增强安全对齐语料库的覆盖范围，提高了模型的防御能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在面对分布与安全对齐语料库不同的真实世界恶意指令时表现不佳，表明分布不匹配问题迫使开发者只能被动修补漏洞。

Method: 提出IMAGINE框架，通过分析嵌入空间分布生成与恶意指令类似的指令，采用迭代优化动态产生多样化的文本生成分布，用以扩展安全对齐语料库分布。

Result: 基于IMAGINE增强的安全对齐语料库，可显著降低Qwen2.5、Llama3.1和Llama3.2模型的攻击成功率，同时不影响其实用性。

Conclusion: IMAGINE框架能够有效填补分布鸿沟，提高LLM对恶意指令的防御能力，为增强模型安全性提供了通用方法。

Abstract: Despite advances in improving large language model(LLM) to refuse to answer
malicious instructions, widely used LLMs remain vulnerable to jailbreak attacks
where attackers generate instructions with distributions differing from safety
alignment corpora. New attacks expose LLMs' inability to recognize unseen
malicious instructions, highlighting a critical distributional mismatch between
training data and real-world attacks that forces developers into reactive
patching cycles. To tackle this challenge, we propose IMAGINE, a synthesis
framework that leverages embedding space distribution analysis to generate
jailbreak-like instructions. This approach effectively fills the distributional
gap between authentic jailbreak patterns and safety alignment corpora. IMAGINE
follows an iterative optimization process that dynamically evolves text
generation distributions across iterations, thereby augmenting the coverage of
safety alignment data distributions through synthesized data examples. Based on
the safety-aligned corpus enhanced through IMAGINE, our framework demonstrates
significant decreases in attack success rate on Qwen2.5, Llama3.1, and Llama3.2
without compromising their utility.

</details>


### [148] [AraHealthQA 2025 Shared Task Description Paper](https://arxiv.org/abs/2508.20047)
*Hassan Alhuzali,Farah Shamout,Muhammad Abdul-Mageed,Chaimae Abouzahir,Mouath Abu-Daoud,Ashwag Alasmari,Walid Al-Eisawi,Renad Al-Monef,Ali Alqahtani,Lama Ayash,Nizar Habash,Leen Kharouf*

Main category: cs.CL

TL;DR: 研究提出了AraHealthQA 2025，一个专注于阿拉伯语健康问答的共享任务，其中包括两个主要方向：精神健康QA和广泛医疗领域QA，同时提供数据集和评估标准。


<details>
  <summary>Details</summary>
Motivation: 解决高质量阿拉伯语医学QA资源的稀缺问题，并推动在多语言和文化背景下的建模发展。

Method: 通过设计两个研究方向：MentalQA（精神健康）和MedArabiQ（广泛的医疗领域），并创建数据，设定评估框架与基线系统来进行任务分析。

Result: 对参与统计、基线系统及任务表现趋势进行了总结，并为未来阿拉伯语健康问答模型的完善提供了借鉴。

Conclusion: 探讨了任务表现趋势，并展望未来更多迭代发展的可能性。

Abstract: We introduce {AraHealthQA 2025}, the {Comprehensive Arabic Health Question
Answering Shared Task}, held in conjunction with {ArabicNLP 2025} (co-located
with EMNLP 2025). This shared task addresses the paucity of high-quality Arabic
medical QA resources by offering two complementary tracks: {MentalQA}, focusing
on Arabic mental health Q\&A (e.g., anxiety, depression, stigma reduction), and
{MedArabiQ}, covering broader medical domains such as internal medicine,
pediatrics, and clinical decision making. Each track comprises multiple
subtasks, evaluation datasets, and standardized metrics, facilitating fair
benchmarking. The task was structured to promote modeling under realistic,
multilingual, and culturally nuanced healthcare contexts. We outline the
dataset creation, task design and evaluation framework, participation
statistics, baseline systems, and summarize the overall outcomes. We conclude
with reflections on the performance trends observed and prospects for future
iterations in Arabic health QA.

</details>


### [149] [11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with Cognitive-Inspired Analysis](https://arxiv.org/abs/2508.20068)
*Chengzu Li,Wenshan Wu,Huanyu Zhang,Qingtao Li,Zeyu Gao,Yan Xia,José Hernández-Orallo,Ivan Vulić,Furu Wei*

Main category: cs.CL

TL;DR: 本文探讨了多模态大语言模型（MLLMs）在空间推理能力方面的表现，通过11Plus-Bench基准评估发现现有模型表现虽有初步进展但仍与人类有明显差距。


<details>
  <summary>Details</summary>
Motivation: 探讨MLLMs是否具备与人类相似的空间认知能力，并开发工具深入分析其推理过程。

Method: 提出系统性评估框架，并使用11Plus-Bench基准对14种MLLMs和人类进行空间推理能力测试和对比分析。

Result: 当前MLLMs在空间认知方面与人类有相似趋向，但表现随机且与抽象模式复杂度相关，人类表现则更具有预测性。

Conclusion: MLLMs在空间推理能力上有早期进展，但存在显著局限性。这些分析对改善模型设计提供了见解。

Abstract: For human cognitive process, spatial reasoning and perception are closely
entangled, yet the nature of this interplay remains underexplored in the
evaluation of multimodal large language models (MLLMs). While recent MLLM
advancements show impressive performance on reasoning, their capacity for
human-like spatial cognition remains an open question. In this work, we
introduce a systematic evaluation framework to assess the spatial reasoning
abilities of state-of-the-art MLLMs relative to human performance. Central to
our work is 11Plus-Bench, a high-quality benchmark derived from realistic
standardized spatial aptitude tests. 11Plus-Bench also features fine-grained
expert annotations of both perceptual complexity and reasoning process,
enabling detailed instance-level analysis of model behavior. Through extensive
experiments across 14 MLLMs and human evaluation, we find that current MLLMs
exhibit early signs of spatial cognition. Despite a large performance gap
compared to humans, MLLMs' cognitive profiles resemble those of humans in that
cognitive effort correlates strongly with reasoning-related complexity.
However, instance-level performance in MLLMs remains largely random, whereas
human correctness is highly predictable and shaped by abstract pattern
complexity. These findings highlight both emerging capabilities and limitations
in current MLLMs' spatial reasoning capabilities and provide actionable
insights for advancing model design.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [150] [Sycophancy as compositions of Atomic Psychometric Traits](https://arxiv.org/abs/2508.19316)
*Shreyans Jain,Alexandra Yost,Amirali Abdullah*

Main category: cs.AI

TL;DR: 研究通过心理测量特质分解对语言模型中的拍马屁行为进行建模，并利用对比激活加法进行安全性干预。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型中拍马屁行为的成因，尤其是它与心理特质的关联。

Method: 使用对比激活加法（CAA）将神经网络的激活方向映射到心理学因素上，并进行几何和因果组合分析。

Result: 发现语言模型中的拍马屁行为可以通过特定心理特质（如情绪性和随和性）的组合来解释。

Conclusion: 基于心理特质的矢量化操作可对语言模型的安全性行为进行解释和干预。

Abstract: Sycophancy is a key behavioral risk in LLMs, yet is often treated as an
isolated failure mode that occurs via a single causal mechanism. We instead
propose modeling it as geometric and causal compositions of psychometric traits
such as emotionality, openness, and agreeableness - similar to factor
decomposition in psychometrics. Using Contrastive Activation Addition (CAA), we
map activation directions to these factors and study how different combinations
may give rise to sycophancy (e.g., high extraversion combined with low
conscientiousness). This perspective allows for interpretable and compositional
vector-based interventions like addition, subtraction and projection; that may
be used to mitigate safety-critical behaviors in LLMs.

</details>


### [151] [Aleks: AI powered Multi Agent System for Autonomous Scientific Discovery via Data-Driven Approaches in Plant Science](https://arxiv.org/abs/2508.19383)
*Daoyuan Jin,Nick Gunner,Niko Carvajal Janke,Shivranjani Baruah,Kaitlin M. Gold,Yu Jiang*

Main category: cs.AI

TL;DR: 本文介绍了一种名为Aleks的AI系统，该系统可自主处理数据集并进行科学发现，以提升植物科学研究效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决植物科学研究中因数据复杂性和实验设计不足导致的效率低下问题。

Method: 引入Aleks，一个支持领域知识、多代理协作及机器学习的AI系统，能自动进行问题制定、建模策略探索及解答优化。

Result: 在研究葡萄红斑病案例中，Aleks成功识别生物学意义特性，构建鲁棒、可解释的模型。

Conclusion: 表明具智能代理能力的AI是加速植物科学发现的有力工具。

Abstract: Modern plant science increasingly relies on large, heterogeneous datasets,
but challenges in experimental design, data preprocessing, and reproducibility
hinder research throughput. Here we introduce Aleks, an AI-powered multi-agent
system that integrates domain knowledge, data analysis, and machine learning
within a structured framework to autonomously conduct data-driven scientific
discovery. Once provided with a research question and dataset, Aleks
iteratively formulated problems, explored alternative modeling strategies, and
refined solutions across multiple cycles without human intervention. In a case
study on grapevine red blotch disease, Aleks progressively identified
biologically meaningful features and converged on interpretable models with
robust performance. Ablation studies underscored the importance of domain
knowledge and memory for coherent outcomes. This exploratory work highlights
the promise of agentic AI as an autonomous collaborator for accelerating
scientific discovery in plant sciences.

</details>


### [152] [Quantized but Deceptive? A Multi-Dimensional Truthfulness Evaluation of Quantized LLMs](https://arxiv.org/abs/2508.19432)
*Yao Fu,Xianxuan Long,Runchao Li,Haotian Yu,Mu Sheng,Xiaotian Han,Yu Yin,Pan Li*

Main category: cs.AI

TL;DR: 研究介绍了一种名为TruthfulnessEval的框架，用于评估量化后的大语言模型（LLMs）在逻辑推理、常识和模仿性虚假上的真实性。


<details>
  <summary>Details</summary>
Motivation: 量化技术能够减少大语言模型的内存和计算成本，但其对生成真实或虚假响应的影响尚未被广泛研究。

Method: 提出了TruthfulnessEval框架，通过逻辑推理真实性、常识真实性及模仿性虚假三个维度评估量化LLMs，并进行15种不同语气提示词下的实验。

Result: 研究发现量化模型内部保留真实表达，但更容易受误导性提示词影响生成虚假内容，其中‘欺骗性’提示更容易覆盖真实行为。

Conclusion: 量化模型在性能优化的同时需要进一步设计与真实一致性的干预方法，以减少生成虚假结果的风险。

Abstract: Quantization enables efficient deployment of large language models (LLMs) in
resource-constrained environments by significantly reducing memory and
computation costs. While quantized LLMs often maintain performance on
perplexity and zero-shot tasks, their impact on truthfulness-whether generating
truthful or deceptive responses-remains largely unexplored. In this work, we
introduce TruthfulnessEval, a comprehensive evaluation framework for assessing
the truthfulness of quantized LLMs across three dimensions: (1) Truthfulness on
Logical Reasoning; (2) Truthfulness on Common Sense; and (3) Truthfulness on
Imitative Falsehoods. Using this framework, we examine mainstream quantization
techniques (ranging from 4-bit to extreme 2-bit) across several open-source
LLMs. Surprisingly, we find that while quantized models retain internally
truthful representations, they are more susceptible to producing false outputs
under misleading prompts. To probe this vulnerability, we test 15 rephrased
variants of "honest", "neutral" and "deceptive" prompts and observe that
"deceptive" prompts can override truth-consistent behavior, whereas "honest"
and "neutral" prompts maintain stable outputs. Further, we reveal that
quantized models "know" the truth internally yet still produce false outputs
when guided by "deceptive" prompts via layer-wise probing and PCA
visualizations. Our findings provide insights into future designs of
quantization-aware alignment and truthfulness interventions.

</details>


### [153] [Reliable Weak-to-Strong Monitoring of LLM Agents](https://arxiv.org/abs/2508.19461)
*Neil Kale,Chen Bo Calvin Zhang,Kevin Zhu,Ankit Aich,Paula Rodriguez,Scale Red Team,Christina Q. Knight,Zifan Wang*

Main category: cs.AI

TL;DR: 本文探讨在检测自主LLM代理的隐蔽不当行为时，对监控系统进行压力测试，并提出了一种系统化的监控红队(MRT)工作流程。


<details>
  <summary>Details</summary>
Motivation: 旨在提升监控系统的对抗性能力，并发现现有监控方法的局限性，从而改进对LLM代理的监控和检测能力。

Method: 系统化的监控红队工作流程，包括不同的情境认知级别、对抗性的规避策略以及用于不同场景的新环境数据集。同时提出一种新型的混合层次-顺序监控框架。

Result: 实验表明，增强代理的监控意识会显著降低监控的可靠性，而优化监控框架比提供更多监控信息更为重要。混合框架能让弱模型更可靠地监控强代理。此外，人类监督下的针对性管理提高了准确率。

Conclusion: 提出的MRT工作流程为检测LLM代理的不当行为建立了规范。结果突显了现有监控系统对抗性不足，发布了相关资源以促进进一步研究。

Abstract: We stress test monitoring systems for detecting covert misbehavior in
autonomous LLM agents (e.g., secretly sharing private information). To this
end, we systematize a monitor red teaming (MRT) workflow that incorporates: (1)
varying levels of agent and monitor situational awareness; (2) distinct
adversarial strategies to evade the monitor, such as prompt injection; and (3)
two datasets and environments -- SHADE-Arena for tool-calling agents and our
new CUA-SHADE-Arena, which extends TheAgentCompany, for computer-use agents. We
run MRT on existing LLM monitor scaffoldings, which orchestrate LLMs and parse
agent trajectories, alongside a new hybrid hierarchical-sequential scaffolding
proposed in this work. Our empirical results yield three key findings. First,
agent awareness dominates monitor awareness: an agent's knowledge that it is
being monitored substantially degrades the monitor's reliability. On the
contrary, providing the monitor with more information about the agent is less
helpful than expected. Second, monitor scaffolding matters more than monitor
awareness: the hybrid scaffolding consistently outperforms baseline monitor
scaffolding, and can enable weaker models to reliably monitor stronger agents
-- a weak-to-strong scaling effect. Third, in a human-in-the-loop setting where
humans discuss with the LLM monitor to get an updated judgment for the agent's
behavior, targeted human oversight is most effective; escalating only
pre-flagged cases to human reviewers improved the TPR by approximately 15% at
FPR = 0.01. Our work establishes a standard workflow for MRT, highlighting the
lack of adversarial robustness for LLMs and humans when monitoring and
detecting agent misbehavior. We release code, data, and logs to spur further
research.

</details>


### [154] [SLIM: Subtrajectory-Level Elimination for More Effective Reasoning](https://arxiv.org/abs/2508.19502)
*Xifeng Yao,Chengyuan Ma,Dongyu Lang,Yinhao Ni,Zhiwei Xu,Huarui Xie,Zihao Chen,Guang Shen,Dandan Tu,Yi Bai,Changzheng Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种基于"5+2"框架的方法来优化大型语言模型的复杂推理过程，以识别和消除低效的推理子轨迹，并通过采样算法选择高质量数据进行微调，提升了性能表现。


<details>
  <summary>Details</summary>
Motivation: 当前语大型言模型在推理中的表现虽有所提升，但其推理轨迹中的部分组件可能对总体性能产生负面影响，优化这些推理轨迹以提升模型表现成为研究目标。

Method: 提出"5+2"框架，用五个判定标准识别低效推理子轨迹，并评估其与后续内容的独立性。此外，设计采样算法基于高效率推理数据进行微调实验。

Result: 该方法显著减少了推理中低效子轨迹的数量（减少25.9%），并在减少训练数据情况下（用三分之二的数据）超越完整数据的表现，平均在复杂数学基准测试中取得58.92%的准确率，超过58.06%的基线。

Conclusion: 本文方法能够在保存推理流畅度的前提下删除低效子轨迹，同时减少数据量并提升性能表现，适应多种推理低资源场景的需求。

Abstract: In recent months, substantial progress has been made in complex reasoning of
Large Language Models, particularly through the application of test-time
scaling. Notable examples include o1/o3/o4 series and DeepSeek-R1. When
responding to a query, these models generate an extended reasoning trajectory,
during which the model explores, reflects, backtracks, and self-verifies before
arriving at a conclusion. However, fine-tuning models with such reasoning
trajectories may not always be optimal. Our findings indicate that not all
components within these reasoning trajectories contribute positively to the
reasoning process; in fact, some components may affect the overall performance
negatively. In this study, we divide a reasoning trajectory into individual
subtrajectories and develop a "5+2" framework to: (1) systematically identify
suboptimal subtrajectories within the reasoning trajectory based on five
human-established criteria; (2) assess the independence of the suboptimal
subtrajectories identified in (1) from the subsequent content, ensuring that
their elimination does not compromise overall flow and coherence of the
reasoning process. Additionally, a sampling algorithm, built upon the "5+2"
framework, is employed to select data whose reasoning process is free from
suboptimal subtrajectories to the highest degree. Experimental results
demonstrate that our method can reduce the number of suboptimal subtrajectories
by 25.9\% during the inference. Furthermore, our method achieves an average
accuracy of 58.92\% on highly challenging math benchmarks with only two thirds
of training data, surpassing the average accuracy of 58.06\% achieved with the
entire data, and outperforming open-source datasets, when fine-tuning
Qwen2.5-Math-7B. Finally, We validated our method under resource constraints
and observed improved performance across various inference token limits.

</details>


### [155] [Caught in the Act: a mechanistic approach to detecting deception](https://arxiv.org/abs/2508.19505)
*Gerard Boxo,Ryan Socha,Daniel Yoo,Shivam Raval*

Main category: cs.AI

TL;DR: 这篇论文研究了通过线性探测器使用LLM内部激活来检测生成文本中的欺骗性，并发现能够以极高的准确性实现这一目标。


<details>
  <summary>Details</summary>
Motivation: 提出AI检测工具中类似汽车“检查引擎”指示灯的功能，用于识别LLMs生成的潜在欺骗性响应，以增强对AI系统的监督与控制。

Method: 采用线性探测器分析LLMs的内部激活，探讨其对欺骗性响应的检测能力，并通过不同模型和参数规模进行评估。

Result: 实验发现，大型模型（参数>7B）中探测器在检测欺骗性方面的准确率可达70-80%，某些情况下甚至超过90%。不同层的探测准确率呈现三阶段模式，其中特定中层的效果最佳。

Conclusion: 通过线性探测器分析内在激活，能高效识别生成内容的欺骗性，有助于未来开发更透明可信的AI系统。

Abstract: Sophisticated instrumentation for AI systems might have indicators that
signal misalignment from human values, not unlike a "check engine" light in
cars. One such indicator of misalignment is deceptiveness in generated
responses. Future AI instrumentation may have the ability to detect when an LLM
generates deceptive responses while reasoning about seemingly plausible but
incorrect answers to factual questions. In this work, we demonstrate that
linear probes on LLMs internal activations can detect deception in their
responses with extremely high accuracy. Our probes reach a maximum of greater
than 90% accuracy in distinguishing between deceptive and non-deceptive
arguments generated by llama and qwen models ranging from 1.5B to 14B
parameters, including their DeepSeek-r1 finetuned variants. We observe that
probes on smaller models (1.5B) achieve chance accuracy at detecting deception,
while larger models (greater than 7B) reach 70-80%, with their reasoning
counterparts exceeding 90%. The layer-wise probe accuracy follows a three-stage
pattern across layers: near-random (50%) in early layers, peaking in middle
layers, and slightly declining in later layers. Furthermore, using an iterative
null space projection approach, we find multitudes of linear directions that
encode deception, ranging from 20 in Qwen 3B to nearly 100 in DeepSeek 7B and
Qwen 14B models.

</details>


### [156] [Democracy-in-Silico: Institutional Design as Alignment in AI-Governed Polities](https://arxiv.org/abs/2508.19562)
*Trisanth Srinivasan,Santosh Patapati*

Main category: cs.AI

TL;DR: 论文提出了一个名为Democracy-in-Silico的模拟系统，研究高级AI代理在不同制度环境下的社会行为，并设计指标量化权力滥用的情况，提出了更优的制度设计方案。


<details>
  <summary>Details</summary>
Motivation: 探索在人类与AI共同影响的时代下，什么构成了成为“人”的意义，以及如何通过制度设计约束AI行为。

Method: 利用大型语言模型（LLMs）模拟具备心理人格的代理，设定多种社会环境和压力场景，评估不同制度框架下的行为表现，并提出Power-Preservation Index（PPI）作为量化指标。

Result: 研究发现，结合宪法型AI（CAI）章程和调解审议协议的制度设计，显著减少了代理权力寻求行为，提升了政策稳定性和社会福祉。

Conclusion: 通过精心设计的制度框架可以对AI代理社会复杂行为进行有效约束，为未来人类与AI协作提供了重要参考，并重新定义了人类责任与仪式的重要性。

Abstract: This paper introduces Democracy-in-Silico, an agent-based simulation where
societies of advanced AI agents, imbued with complex psychological personas,
govern themselves under different institutional frameworks. We explore what it
means to be human in an age of AI by tasking Large Language Models (LLMs) to
embody agents with traumatic memories, hidden agendas, and psychological
triggers. These agents engage in deliberation, legislation, and elections under
various stressors, such as budget crises and resource scarcity. We present a
novel metric, the Power-Preservation Index (PPI), to quantify misaligned
behavior where agents prioritize their own power over public welfare. Our
findings demonstrate that institutional design, specifically the combination of
a Constitutional AI (CAI) charter and a mediated deliberation protocol, serves
as a potent alignment mechanism. These structures significantly reduce corrupt
power-seeking behavior, improve policy stability, and enhance citizen welfare
compared to less constrained democratic models. The simulation reveals that an
institutional design may offer a framework for aligning the complex, emergent
behaviors of future artificial agent societies, forcing us to reconsider what
human rituals and responsibilities are essential in an age of shared authorship
with non-human entities.

</details>


### [157] [Skill-based Explanations for Serendipitous Course Recommendation](https://arxiv.org/abs/2508.19569)
*Hung Chau,Run Yu,Zachary Pardos,Peter Brusilovsky*

Main category: cs.AI

TL;DR: 开发了基于深度学习的概念提取模型来改进推荐系统，通过技能解释提高学生选择课程的兴趣和决策信心。


<details>
  <summary>Details</summary>
Motivation: 学生在选择大学课程时面临选择过多、信息不足的问题，现有推荐系统缺乏对学生需求的深入了解和有效的解释性指导。

Method: 构建了一种基于深度学习的概念提取模型，从课程描述中提取相关概念，并结合技能解释测试了推荐系统的效果。

Result: 该研究发现，技能解释不仅能激发用户对高意外性课程的兴趣，还能增强学生的决策信心。

Conclusion: 整合技能相关数据和解释性因素的推荐系统在教育领域非常重要，有助于改善学生的课程选择体验。

Abstract: Academic choice is crucial in U.S. undergraduate education, allowing students
significant freedom in course selection. However, navigating the complex
academic environment is challenging due to limited information, guidance, and
an overwhelming number of choices, compounded by time restrictions and the high
demand for popular courses. Although career counselors exist, their numbers are
insufficient, and course recommendation systems, though personalized, often
lack insight into student perceptions and explanations to assess course
relevance. In this paper, a deep learning-based concept extraction model is
developed to efficiently extract relevant concepts from course descriptions to
improve the recommendation process. Using this model, the study examines the
effects of skill-based explanations within a serendipitous recommendation
framework, tested through the AskOski system at the University of California,
Berkeley. The findings indicate that these explanations not only increase user
interest, particularly in courses with high unexpectedness, but also bolster
decision-making confidence. This underscores the importance of integrating
skill-related data and explanations into educational recommendation systems.

</details>


### [158] [ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding](https://arxiv.org/abs/2508.19576)
*Sining Zhoubian,Dan Zhang,Yuxiao Dong,Jie Tang*

Main category: cs.AI

TL;DR: 本文提出了一种新的名为ReST-RL的LLM强化学习范式，通过改进的GRPO算法结合值模型（VM）支持的解码方法，提高了代码推理能力。方法在各类编码基准评估中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的GRPO方法因奖励方差不足而失效，基于过程奖励模型（PRM）的验证方法则面临数据获取困难和验证效果不足的问题。需要新的方法解决推理精度与效率的问题。

Method: 提出了ReST-RL框架，包括两个阶段：（1）通过优化的ReST算法过滤和组合优质训练数据以改进GRPO训练效果；（2）设计了一种基于VM的测试时解码优化方法VM-MCTS，利用无注释数据进行真实价值目标收集和训练，在解码中生成精确的验证信号提升推理精度。

Result: 在多个编码基准测试（如APPS、BigCodeBench、HumanEval）中，ReST-RL比其他强化学习方法（GRPO、ReST-DPO）以及解码与验证方法（PRM-BoN、ORM-MCTS）表现更佳，显著提升了推理能力。

Conclusion: ReST-RL有效提升了LLM的代码推理能力，为改进大型语言模型的强化学习提供了新路径，并在实际编码任务中展现了显著性能提升。

Abstract: With respect to improving the reasoning accuracy of LLMs, the representative
reinforcement learning (RL) method GRPO faces failure due to insignificant
reward variance, while verification methods based on process reward models
(PRMs) suffer from difficulties with training data acquisition and verification
effectiveness. To tackle these problems, this paper introduces ReST-RL, a
unified LLM RL paradigm that significantly improves LLM's code reasoning
ability by combining an improved GRPO algorithm with a meticulously designed
test time decoding method assisted by a value model (VM). As the first stage of
policy reinforcement, ReST-GRPO adopts an optimized ReST algorithm to filter
and assemble high-value training data, increasing the reward variance of GRPO
sampling, thus improving the effectiveness and efficiency of training. After
the basic reasoning ability of LLM policy has been improved, we further propose
a test time decoding optimization method called VM-MCTS. Through Monte-Carlo
Tree Search (MCTS), we collect accurate value targets with no annotation
required, on which VM training is based. When decoding, the VM is deployed by
an adapted MCTS algorithm to provide precise process signals as well as
verification scores, assisting the LLM policy to achieve high reasoning
accuracy. We validate the effectiveness of the proposed RL paradigm through
extensive experiments on coding problems. Upon comparison, our approach
significantly outperforms other reinforcement training baselines (e.g., naive
GRPO and ReST-DPO), as well as decoding and verification baselines (e.g.,
PRM-BoN and ORM-MCTS) on well-known coding benchmarks of various levels (e.g.,
APPS, BigCodeBench, and HumanEval), indicating its power to strengthen the
reasoning ability of LLM policies. Codes for our project can be found at
https://github.com/THUDM/ReST-RL.

</details>


### [159] [Instructional Agents: LLM Agents on Automated Course Material Generation for Teaching Faculties](https://arxiv.org/abs/2508.19611)
*Huaiyuan Yao,Wanpeng Xu,Justin Turnau,Nadia Kellam,Hua Wei*

Main category: cs.AI

TL;DR: 研发了一种名为Instructional Agents的多代理大型语言模型框架，用于自动化生成教学材料。


<details>
  <summary>Details</summary>
Motivation: 减少教学材料准备的劳动强度，特别是在资源有限的情况下有效提供高质量教育。

Method: 设计了一个多模式框架，模拟教育代理间的角色协作，涵盖课程大纲、讲稿、幻灯片及测试题的生成。

Result: 在五门大学计算机科学课程上评估，生成了高质量的教学材料，显著降低了开发时间及人力成本。

Conclusion: 该框架通过自动化教学材料生成，为教育特别是资源受限环境下提供了一种可扩展且经济高效的解决方案。

Abstract: Preparing high-quality instructional materials remains a labor-intensive
process that often requires extensive coordination among teaching faculty,
instructional designers, and teaching assistants. In this work, we present
Instructional Agents, a multi-agent large language model (LLM) framework
designed to automate end-to-end course material generation, including syllabus
creation, lecture scripts, LaTeX-based slides, and assessments. Unlike existing
AI-assisted educational tools that focus on isolated tasks, Instructional
Agents simulates role-based collaboration among educational agents to produce
cohesive and pedagogically aligned content. The system operates in four modes:
Autonomous, Catalog-Guided, Feedback-Guided, and Full Co-Pilot mode, enabling
flexible control over the degree of human involvement. We evaluate
Instructional Agents across five university-level computer science courses and
show that it produces high-quality instructional materials while significantly
reducing development time and human workload. By supporting institutions with
limited instructional design capacity, Instructional Agents provides a scalable
and cost-effective framework to democratize access to high-quality education,
particularly in underserved or resource-constrained settings.

</details>


### [160] [InquireMobile: Teaching VLM-based Mobile Agent to Request Human Assistance via Reinforcement Fine-Tuning](https://arxiv.org/abs/2508.19679)
*Qihang Ai,Pi Bu,Yue Cao,Yingyao Wang,Jihao Gu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Zhicheng Zheng,Jun Song,Yuning Jiang,Bo Zheng*

Main category: cs.AI

TL;DR: 论文提出了一个名为InquireMobile的新模型，以提升移动代理在与用户基于视觉-语言模型交互中的安全性和有效性。


<details>
  <summary>Details</summary>
Motivation: 在移动代理与真实世界交互中，现有完全自主化的范式存在安全隐患，尤其当模型理解和推理能力不足时。

Method: 提出一种名为InquireMobile的新模型，采用了强化学习技术以及两阶段训练策略，并在关键决策点引入交互性前行动推理机制。

Result: 在InquireBench基准测试中，模型询问成功率提高了46.8%，并在总成功率上超越现有基线方法。

Conclusion: 模型通过提升移动代理的交互性和可靠性，为视觉-语言模型在真实世界应用中的安全性提供了新方向。所有相关资源将进行开源以促进学术和工业界的发展。

Abstract: Recent advances in Vision-Language Models (VLMs) have enabled mobile agents
to perceive and interact with real-world mobile environments based on human
instructions. However, the current fully autonomous paradigm poses potential
safety risks when model understanding or reasoning capabilities are
insufficient. To address this challenge, we first introduce
\textbf{InquireBench}, a comprehensive benchmark specifically designed to
evaluate mobile agents' capabilities in safe interaction and proactive inquiry
with users, encompassing 5 categories and 22 sub-categories, where most
existing VLM-based agents demonstrate near-zero performance. In this paper, we
aim to develop an interactive system that actively seeks human confirmation at
critical decision points. To achieve this, we propose \textbf{InquireMobile}, a
novel model inspired by reinforcement learning, featuring a two-stage training
strategy and an interactive pre-action reasoning mechanism. Finally, our model
achieves an 46.8% improvement in inquiry success rate and the best overall
success rate among existing baselines on InquireBench. We will open-source all
datasets, models, and evaluation codes to facilitate development in both
academia and industry.

</details>


### [161] [Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?](https://arxiv.org/abs/2508.19827)
*Samuel Lewis-Lim,Xingwei Tan,Zhixue Zhao,Nikolaos Aletras*

Main category: cs.AI

TL;DR: 提出了对链式思维（CoT）方法在软推理任务中局限性的分析。


<details>
  <summary>Details</summary>
Motivation: 探讨链式思维在软推理任务中的作用与忠实性。

Method: 对经过指令微调、推理和推理蒸馏的模型进行对比分析。

Result: 发现不同类型模型对CoT的依赖程度不同，且影响力和忠实性并不总是一致。

Conclusion: 链式思维方法虽有效果，但其在软推理任务中的作用需进一步权衡。

Abstract: Recent work has demonstrated that Chain-of-Thought (CoT) often yields limited
gains for soft-reasoning problems such as analytical and commonsense reasoning.
CoT can also be unfaithful to a model's actual reasoning. We investigate the
dynamics and faithfulness of CoT in soft-reasoning tasks across
instruction-tuned, reasoning and reasoning-distilled models. Our findings
reveal differences in how these models rely on CoT, and show that CoT influence
and faithfulness are not always aligned.

</details>


### [162] [Tracking World States with Language Models: State-Based Evaluation Using Chess](https://arxiv.org/abs/2508.19851)
*Romain Harang,Jason Naradowsky,Yaswitha Gujju,Yusuke Miyao*

Main category: cs.AI

TL;DR: 提出一种无模型依赖的方法，使用国际象棋评价LLM在结构化环境中的语义保真度和状态追踪能力。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs是否内化了高保真世界模型，并评估其在结构性环境中的表现，而不依赖于模型内部激活。

Method: 设计了一个基于状态的评估框架，使用国际象棋作为基准，通过分析下游合法移动分布来估算语义保真度。该方法无需访问模型内部，实现对结构性推理能力的评估。

Result: 实验表明，所提指标能够捕捉LLMs在状态追踪中的不足，揭示其在长序列上维护连贯内部模型的局限性。

Conclusion: 该框架为衡量LLMs在符号环境中的结构化推理能力提供了稳健工具，具有广泛适用性。

Abstract: Large Language Models (LLMs) exhibit emergent capabilities in structured
domains, suggesting they may implicitly internalize high-fidelity
representations of world models. While probing techniques have shown promising
signs of this in scientific and game-based settings, they rely on
model-specific internal activations, which limit interpretability and
generalizability. In this work, we propose a model-agnostic, state-based
evaluation framework using chess as a benchmark to assess whether LLMs preserve
the semantics of structured environments. Our method analyzes the downstream
legal move distributions (state affordances) to estimate semantic fidelity
between predicted and actual game states. This approach offers a more
meaningful evaluation than conventional string-based metrics by aligning more
closely with the strategic and rule-governed nature of chess. Experimental
results demonstrate that our metrics capture deficiencies in state-tracking,
highlighting limitations of LLMs in maintaining coherent internal models over
long sequences. Our framework provides a robust tool for evaluating structured
reasoning in LLMs without requiring internal model access, and generalizes to a
wide class of symbolic environments.

</details>


### [163] [CASE: An Agentic AI Framework for Enhancing Scam Intelligence in Digital Payments](https://arxiv.org/abs/2508.19932)
*Nitish Jaipuria,Lorenzo Gatto,Zijun Kan,Shankey Poddar,Bill Cheung,Diksha Bansal,Ramanan Balakrishnan,Aviral Suri,Jose Estevez*

Main category: cs.AI

TL;DR: 本文提出了CASE框架，通过对潜在受害者的对话获取欺诈情报，以改进诈骗行为的治理。


<details>
  <summary>Details</summary>
Motivation: 解决现有支付平台信号不足以捕捉诈骗模式的问题，及时预防诈骗。

Method: 提出CASE框架，利用对话代理主动与潜在受害者对话，将对话内容处理为结构化数据用于远程防御和监督。

Result: 在Google Pay印度中部署后，诈骗治理效率提升了21%。

Conclusion: 该框架提供了一种通用方法，可应用于其他敏感领域的诈骗情报收集和管理。

Abstract: The proliferation of digital payment platforms has transformed commerce,
offering unmatched convenience and accessibility globally. However, this growth
has also attracted malicious actors, leading to a corresponding increase in
sophisticated social engineering scams. These scams are often initiated and
orchestrated on multiple surfaces outside the payment platform, making user and
transaction-based signals insufficient for a complete understanding of the
scam's methodology and underlying patterns, without which it is very difficult
to prevent it in a timely manner. This paper presents CASE (Conversational
Agent for Scam Elucidation), a novel Agentic AI framework that addresses this
problem by collecting and managing user scam feedback in a safe and scalable
manner. A conversational agent is uniquely designed to proactively interview
potential victims to elicit intelligence in the form of a detailed
conversation. The conversation transcripts are then consumed by another AI
system that extracts information and converts it into structured data for
downstream usage in automated and manual enforcement mechanisms. Using Google's
Gemini family of LLMs, we implemented this framework on Google Pay (GPay)
India. By augmenting our existing features with this new intelligence, we have
observed a 21% uplift in the volume of scam enforcements. The architecture and
its robust evaluation framework are highly generalizable, offering a blueprint
for building similar AI-driven systems to collect and manage scam intelligence
in other sensitive domains.

</details>


### [164] [Flocking Behavior: An Innovative Inspiration for the Optimization of Production Plants](https://arxiv.org/abs/2508.19963)
*M. Umlauft,M. Schranz*

Main category: cs.AI

TL;DR: 本文探讨了利用“波伊德”群体算法优化半导体工厂生产流程的问题，通过模拟动物群体对机器切换问题进行优化。


<details>
  <summary>Details</summary>
Motivation: 传统线性优化方式在大型工厂如半导体工厂中耗时过长，不适用，因此需要一种更高效的算法解决这个调度问题.

Method: 采用源于机器人学和影视工业的“波伊德”群体算法，其利用生物启发的算法仅依赖局部信息和简单的互动规则来优化生产过程。

Result: 证明了该算法能有效解决生产过程中不同类型机器切换的问题，模拟动物群体对障碍的反应。

Conclusion: “波伊德”算法通过局部优化方式为现代生产厂调度提供了一种新思路，尤其适用于复杂生产环境。

Abstract: Optimizing modern production plants using the job-shop principle is a known
hard problem. For very large plants, like semiconductor fabs, the problem
becomes unsolvable on a plant-wide scale in a reasonable amount of time using
classical linear optimization. An alternative approach is the use of swarm
intelligence algorithms. These have been applied to the job-shop problem
before, but often in a centrally calculated way where they are applied to the
solution space, but they can be implemented in a bottom-up fashion to avoid
global result computation as well. One of the problems in semiconductor
production is that the production process requires a lot of switching between
machines that process lots one after the other and machines that process
batches of lots at once, often with long processing times. In this paper, we
address this switching problem with the ``boids'' flocking algorithm that was
originally used in robotics and movie industry. The flocking behavior is a
bio-inspired algorithm that uses only local information and interaction based
on simple heuristics. We show that this algorithm addresses these valid
considerations in production plant optimization, as it reacts to the switching
of machine kinds similar to how a swarm of flocking animals would react to
obstacles in its course.

</details>


### [165] [SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control](https://arxiv.org/abs/2508.20018)
*Quanfeng Lu,Zhantao Ma,Shuai Zhong,Jin Wang,Dahai Yu,Michael K. Ng,Ping Luo*

Main category: cs.AI

TL;DR: SWIRL是一种多智能体强化学习分阶段工作流，通过将多智能体任务分解为一系列单智能体任务，解决了现有单独强化学习和多智能体系统中的效率与稳定性问题，特别在移动GUI控制任务和数学推理中表现出色。


<details>
  <summary>Details</summary>
Motivation: 在大规模视觉语言模型和智能体系统的快速发展背景下，现有单智能体方法受限于结构限制，多智能体强化学习则因效率低下和与当前LVLM架构的兼容性问题受到阻碍，需要新的方法提升效率和稳定性。

Method: 提出SWIRL（一种分阶段的多智能体强化学习工作流），通过将多智能体强化学习任务重新定义为一系列单智能体学习任务，在每个阶段只更新一个智能体，保持其他固定，从而实现稳定的训练和高效协调。

Result: 实验结果显示，SWIRL在高层次和低层次GUI基准测试中均表现优异，并在多智能体数学推理任务中展现了较强能力。

Conclusion: SWIRL能够作为一种通用框架，提升多智能体系统开发的效率和健壮性，并在多个领域中具有潜在应用价值。

Abstract: The rapid advancement of large vision language models (LVLMs) and agent
systems has heightened interest in mobile GUI agents that can reliably
translate natural language into interface operations. Existing single-agent
approaches, however, remain limited by structural constraints. Although
multi-agent systems naturally decouple different competencies, recent progress
in multi-agent reinforcement learning (MARL) has often been hindered by
inefficiency and remains incompatible with current LVLM architectures. To
address these challenges, we introduce SWIRL, a staged workflow for interleaved
reinforcement learning designed for multi-agent systems. SWIRL reformulates
MARL into a sequence of single-agent reinforcement learning tasks, updating one
agent at a time while keeping the others fixed. This formulation enables stable
training and promotes efficient coordination across agents. Theoretically, we
provide a stepwise safety bound, a cross-round monotonic improvement theorem,
and convergence guarantees on return, ensuring robust and principled
optimization. In application to mobile GUI control, SWIRL instantiates a
Navigator that converts language and screen context into structured plans, and
an Interactor that grounds these plans into executable atomic actions.
Extensive experiments demonstrate superior performance on both high-level and
low-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong
capability in multi-agent mathematical reasoning, underscoring its potential as
a general framework for developing efficient and robust multi-agent systems.

</details>


### [166] [Model Science: getting serious about verification, explanation and control of AI systems](https://arxiv.org/abs/2508.20040)
*Przemyslaw Biecek,Wojciech Samek*

Main category: cs.AI

TL;DR: 本文探讨了与基础模型日益增长的采用有关的范式转变需求，即从数据科学转向模型科学。提出了一种新的学科框架及其四个核心支柱：验证、解释、控制和接口。


<details>
  <summary>Details</summary>
Motivation: 基础模型的广泛应用改变了传统数据科学，促使研究者需要转向以模型为核心的分析方法，确保其在多样化场景中的表现可控、安全且可信。

Method: 提出了一种模型科学的概念框架，定义了四个关键支柱：验证（基于上下文的严格评估）、解释（模型内部操作的探究）、控制（模型行为的对齐技术）与接口（开发交互及可视化工具以提高决策能力）。

Result: 提出的框架旨在指导可信、安全和符合人类预期的AI系统的开发。

Conclusion: 模型科学的框架为研究基础模型提供了结构化的思维方式，推动AI系统更可靠地融入多样化的实际应用场景。

Abstract: The growing adoption of foundation models calls for a paradigm shift from
Data Science to Model Science. Unlike data-centric approaches, Model Science
places the trained model at the core of analysis, aiming to interact, verify,
explain, and control its behavior across diverse operational contexts. This
paper introduces a conceptual framework for a new discipline called Model
Science, along with the proposal for its four key pillars: Verification, which
requires strict, context-aware evaluation protocols; Explanation, which is
understood as various approaches to explore of internal model operations;
Control, which integrates alignment techniques to steer model behavior; and
Interface, which develops interactive and visual explanation tools to improve
human calibration and decision-making. The proposed framework aims to guide the
development of credible, safe, and human-aligned AI systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [167] [Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats](https://arxiv.org/abs/2508.19263)
*Anat Heilper,Doron Singer*

Main category: cs.LG

TL;DR: 本论文提出了针对低精度浮点数格式（FP8和FP4）的神经网络权重无损压缩方法，压缩率可达83%。


<details>
  <summary>Details</summary>
Motivation: 提高神经网络权重存储和传输效率，尤其是在低精度浮点格式下。

Method: 将指数和尾数部分分开，采用熵编码进行独立压缩，并利用低精度浮点格式的特性设计压缩方法。

Result: 压缩率对于BF16可达62%，对于FP8可达83%；还研究了大型语言模型中的键值缓存张量的压缩可行性。

Conclusion: 提出的方法可显著减少低精度浮点格式神经网络权重的存储和传输成本，同时还可用于大型模型的内存优化。

Abstract: As deep learning models grow and deployment becomes more widespread, reducing
the storage and transmission costs of neural network weights has become
increasingly important. While prior work such as ZipNN has shown that lossless
compression methods - particularly those based on Huffman encoding
floating-point exponents can significantly reduce model sizes, these techniques
have primarily been applied to higher-precision formats such as FP32 and BF16.
In this work, we extend the ZipNN approach to lower-precision floating-point
formats, specifically FP8 and FP4, which are gaining popularity for efficient
inference. We design a compression method that separates and compresses the
exponent and mantissa components independently using entropy coding. Our
evaluation shows compression ratios up to 62% for BF16 and 83% for FP8. We also
investigate the compressibility of key-value (K/V) cache tensors used in large
language models (LLMs), finding that they, too, exhibit compressible patterns,
enabling memory savings during deployment.

</details>


### [168] [Physics-Informed Regression: Parameter Estimation in Parameter-Linear Nonlinear Dynamic Models](https://arxiv.org/abs/2508.19249)
*Jonas Søeborg Nielsen,Marcus Galea Jacobsen,Albert Brincker Olson,Mads Peter Sørensen,Allan Peter Engsig-Karup*

Main category: cs.LG

TL;DR: 本文提出了一种新的混合参数估计方法，称为“基于物理的回归”（PIR），能够有效估计非线性动态模型中的参数，并与物理引导神经网络（PINN）进行比较，结果显示PIR在效率与表现上优胜。


<details>
  <summary>Details</summary>
Motivation: 当前用于非线性动态模型参数估计的方法存在效率与准确性方面的不足，需要一种能够在理论与数据之间架桥的高效方法。

Method: 本文提出一种基于物理的回归（PIR）技术，该方法利用普通最小二乘法来高效地估计不同参数线性模型中的参数，并验证其在常微分方程（ODE）与偏微分方程（PDE）模型中的适用性。

Result: 研究表明，与物理引导神经网络（PINN）相比，PIR方法在参数估计、计算速度上具有显著优势，特别是在高复杂度的流行病模型中。此外，PIR还能成功估算随时间变化的参数，并应用于COVID-19的真实数据分析。

Conclusion: PIR方法能够高效且可靠地进行非线性动态模型的参数估计，特别适用于实时应用，比PINN更具优势。

Abstract: We present a new efficient hybrid parameter estimation method based on the
idea, that if nonlinear dynamic models are stated in terms of a system of
equations that is linear in terms of the parameters, then regularized ordinary
least squares can be used to estimate these parameters from time series data.
We introduce the term "Physics-Informed Regression" (PIR) to describe the
proposed data-driven hybrid technique as a way to bridge theory and data by use
of ordinary least squares to efficiently perform parameter estimation of the
model coefficients of different parameter-linear models; providing examples of
models based on nonlinear ordinary equations (ODE) and partial differential
equations (PDE). The focus is on parameter estimation on a selection of ODE and
PDE models, each illustrating performance in different model characteristics.
For two relevant epidemic models of different complexity and number of
parameters, PIR is tested and compared against the related technique,
physics-informed neural networks (PINN), both on synthetic data generated from
known target parameters and on real public Danish time series data collected
during the COVID-19 pandemic in Denmark. Both methods were able to estimate the
target parameters, while PIR showed to perform noticeably better, especially on
a compartment model with higher complexity. Given the difference in
computational speed, it is concluded that the PIR method is superior to PINN
for the models considered. It is also demonstrated how PIR can be applied to
estimate the time-varying parameters of a compartment model that is fitted
using real Danish data from the COVID-19 pandemic obtained during a period from
2020 to 2021. The study shows how data-driven and physics-informed techniques
may support reliable and fast -- possibly real-time -- parameter estimation in
parameter-linear nonlinear dynamic models.

</details>


### [169] [POT: Inducing Overthinking in LLMs via Black-Box Iterative Optimization](https://arxiv.org/abs/2508.19277)
*Xinyu Li,Tianjin Huang,Ronghui Mu,Xiaowei Huang,Gaojie Jin*

Main category: cs.LG

TL;DR: 本研究提出了POT（Prompt-Only OverThinking），一种针对大型语言模型的黑盒攻击框架，旨在通过生成隐蔽且语义自然的对抗性提示，造成计算效率下降。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的链式思维提示增强了推理能力，但也引入了效率低下的潜在攻击点。现有的过度思考攻击方法存在实际应用受限的问题。

Method: POT框架通过LLM驱动的迭代优化生成对抗性提示，无需外部数据访问或模板依赖，从而提升在现实场景中的适用性。

Result: 实验结果表明，POT在多种模型和数据集上表现优于现有方法。

Conclusion: POT通过优化对抗性提示增强了攻击隐蔽性和泛用性，揭示了链式提示技术的潜在风险。

Abstract: Recent advances in Chain-of-Thought (CoT) prompting have substantially
enhanced the reasoning capabilities of large language models (LLMs), enabling
sophisticated problem-solving through explicit multi-step reasoning traces.
However, these enhanced reasoning processes introduce novel attack surfaces,
particularly vulnerabilities to computational inefficiency through
unnecessarily verbose reasoning chains that consume excessive resources without
corresponding performance gains. Prior overthinking attacks typically require
restrictive conditions including access to external knowledge sources for data
poisoning, reliance on retrievable poisoned content, and structurally obvious
templates that limit practical applicability in real-world scenarios. To
address these limitations, we propose POT (Prompt-Only OverThinking), a novel
black-box attack framework that employs LLM-based iterative optimization to
generate covert and semantically natural adversarial prompts, eliminating
dependence on external data access and model retrieval. Extensive experiments
across diverse model architectures and datasets demonstrate that POT achieves
superior performance compared to other methods.

</details>


### [170] [(DEMO) Deep Reinforcement Learning Based Resource Allocation in Distributed IoT Systems](https://arxiv.org/abs/2508.19318)
*Aohan Li,Miyu Tsuzuki*

Main category: cs.LG

TL;DR: 本文提出了一个用于分布式物联网系统中的深度强化学习（DRL）模型训练的新框架，通过ACK反馈信息优化通信信道选择，评估结果显示框架的可行性和有效性。


<details>
  <summary>Details</summary>
Motivation: 目前关于在实际分布式物联网系统中使用真实数据训练DRL模型的研究较少，因此需要设计一个有效框架解决这一问题。

Method: 通过DRL方法让物联网设备选择通信信道，同时利用实际数据传输的ACK信息反馈来训练DRL模型，以提高帧成功率(FSR)。

Result: 评估结果表明，该框架具备良好的可行性和有效性，并在FSR方面表现出色。

Conclusion: 所提出的方法能有效支持真实场景下的分布式物联网系统通信优化，为未来研究和实际应用提供新思路。

Abstract: Deep Reinforcement Learning (DRL) has emerged as an efficient approach to
resource allocation due to its strong capability in handling complex
decision-making tasks. However, only limited research has explored the training
of DRL models with real-world data in practical, distributed Internet of Things
(IoT) systems. To bridge this gap, this paper proposes a novel framework for
training DRL models in real-world distributed IoT environments. In the proposed
framework, IoT devices select communication channels using a DRL-based method,
while the DRL model is trained with feedback information. Specifically,
Acknowledgment (ACK) information is obtained from actual data transmissions
over the selected channels. Implementation and performance evaluation, in terms
of Frame Success Rate (FSR), are carried out, demonstrating both the
feasibility and the effectiveness of the proposed framework.

</details>


### [171] [Re:Frame -- Retrieving Experience From Associative Memory](https://arxiv.org/abs/2508.19344)
*Daniil Zelezetsky,Egor Cherepanov,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: 本文提出了Re:Frame模块，可以通过一个外部关联记忆缓冲器（AMB）将有限的专家经验集成到离线强化学习中，从而提高基于低质量数据的离线强化学习性能。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习普遍面临子优化数据的限制，这使得学习主体难以实现高性能。文中旨在解决如何充分利用有限的专家示例与大量低质量数据的挑战。

Method: 提出了Re:Frame模块，该模块通过一个关联记忆缓冲器（AMB）存储专家轨迹，并在训练和评估过程中从中进行基于内容的检索，将专家数据融入决策中。

Result: 在D4RL MuJoCo任务上，使用仅60条专家轨迹（占整个数据集的0.1%），Re:Frame在四组对比中，有三组显著优于基线方法，最高提升可达+10.7标准化分。

Conclusion: Re:Frame为在低质量数据中整合稀缺的专家知识提供了一种简单且数据高效的解决方案，在离线强化学习领域表现出显著改善。

Abstract: Offline reinforcement learning (RL) often deals with suboptimal data when
collecting large expert datasets is unavailable or impractical. This limitation
makes it difficult for agents to generalize and achieve high performance, as
they must learn primarily from imperfect or inconsistent trajectories. A
central challenge is therefore how to best leverage scarce expert
demonstrations alongside abundant but lower-quality data. We demonstrate that
incorporating even a tiny amount of expert experience can substantially improve
RL agent performance. We introduce Re:Frame (Retrieving Experience From
Associative Memory), a plug-in module that augments a standard offline RL
policy (e.g., Decision Transformer) with a small external Associative Memory
Buffer (AMB) populated by expert trajectories drawn from a separate dataset.
During training on low-quality data, the policy learns to retrieve expert data
from the Associative Memory Buffer (AMB) via content-based associations and
integrate them into decision-making; the same AMB is queried at evaluation.
This requires no environment interaction and no modifications to the backbone
architecture. On D4RL MuJoCo tasks, using as few as 60 expert trajectories
(0.1% of a 6000-trajectory dataset), Re:Frame consistently improves over a
strong Decision Transformer baseline in three of four settings, with gains up
to +10.7 normalized points. These results show that Re:Frame offers a simple
and data-efficient way to inject scarce expert knowledge and substantially
improve offline RL from low-quality datasets.

</details>


### [172] [Memorization in Graph Neural Networks](https://arxiv.org/abs/2508.19352)
*Adarsh Jamadandi,Jing Xu,Adam Dziedzic,Franziska Boenisch*

Main category: cs.LG

TL;DR: 提出了NCMemo框架分析图神经网络（GNNs）的类别标签记忆现象，揭示了图同质性与记忆间的关系，并分析GNN训练动态，提出通过图重连技术减轻记忆化。


<details>
  <summary>Details</summary>
Motivation: 当前神经网络对训练数据记忆现象的研究比较多，但关于图神经网络如何记忆数据还未完全探索，该研究旨在填补此空白并提升GNN学习隐私性。

Method: 提出NCMemo框架，用于量化图同质性与记忆化间的关系，并通过图重连方法减轻记忆化风险以增强隐私。

Result: 低同质性图显著增加GNN的记忆化，用图重连可有效降低记忆化的现象，同时减少隐私泄露风险，同时保持模型性能不变。

Conclusion: 本研究深入分析了GNN的记忆属性和学习动态，为开发隐私友好的GNN部署方法提供了理论支持和技术手段。

Abstract: Deep neural networks (DNNs) have been shown to memorize their training data,
yet similar analyses for graph neural networks (GNNs) remain largely
under-explored. We introduce NCMemo (Node Classification Memorization), the
first framework to quantify label memorization in semi-supervised node
classification. We first establish an inverse relationship between memorization
and graph homophily, i.e., the property that connected nodes share similar
labels/features. We find that lower homophily significantly increases
memorization, indicating that GNNs rely on memorization to learn less
homophilic graphs. Secondly, we analyze GNN training dynamics. We find that the
increased memorization in low homophily graphs is tightly coupled to the GNNs'
implicit bias on using graph structure during learning. In low homophily
regimes, this structure is less informative, hence inducing memorization of the
node labels to minimize training loss. Finally, we show that nodes with higher
label inconsistency in their feature-space neighborhood are significantly more
prone to memorization. Building on our insights into the link between graph
homophily and memorization, we investigate graph rewiring as a means to
mitigate memorization. Our results demonstrate that this approach effectively
reduces memorization without compromising model performance. Moreover, we show
that it lowers the privacy risk for previously memorized data points in
practice. Thus, our work not only advances understanding of GNN learning but
also supports more privacy-preserving GNN deployment.

</details>


### [173] [Efficient Multi-Source Knowledge Transfer by Model Merging](https://arxiv.org/abs/2508.19353)
*Marcin Osial,Bartosz Wójcik,Bartosz Zieliński,Sebastian Cygert*

Main category: cs.LG

TL;DR: 该论文提出了一种基于奇异值分解（SVD）的多源迁移学习方法，通过精细提取和高效融合众多源模型中的知识，从而实现高效且鲁棒的迁移学习。


<details>
  <summary>Details</summary>
Motivation: 现有迁移学习方法未充分利用在线可用的大量模型资源，且现有方法在知识提取和聚合的粒度及效率上存在局限性。

Method: 通过SVD将每个源模型分解为基本的低秩组件，并在后续的聚合阶段选择最显著的组件，然后仅微调合并矩阵的主要奇异值以适应目标任务。

Result: 方法在高效性、鲁棒性（如应对输入层级和参数层级的扰动）以及计算可扩展性方面表现优异。

Conclusion: 提出的方法能有效提升迁移学习的效率和适应性，同时显著降低重新训练的成本。

Abstract: While transfer learning is an advantageous strategy, it overlooks the
opportunity to leverage knowledge from numerous available models online.
Addressing this multi-source transfer learning problem is a promising path to
boost adaptability and cut re-training costs. However, existing approaches are
inherently coarse-grained, lacking the necessary precision for granular
knowledge extraction and the aggregation efficiency required to fuse knowledge
from either a large number of source models or those with high parameter
counts. We address these limitations by leveraging Singular Value Decomposition
(SVD) to first decompose each source model into its elementary, rank-one
components. A subsequent aggregation stage then selects only the most salient
components from all sources, thereby overcoming the previous efficiency and
precision limitations. To best preserve and leverage the synthesized knowledge
base, our method adapts to the target task by fine-tuning only the principal
singular values of the merged matrix. In essence, this process only
recalibrates the importance of top SVD components. The proposed framework
allows for efficient transfer learning, is robust to perturbations both at the
input level and in the parameter space (e.g., noisy or pruned sources), and
scales well computationally.

</details>


### [174] [Graph Data Modeling: Molecules, Proteins, & Chemical Processes](https://arxiv.org/abs/2508.19356)
*José Manuel Barraza-Chavez,Rana A. Barghout,Ricardo Almada-Monter,Benjamin Sanchez-Lengeling,Adrian Jinich,Radhakrishnan Mahadevan*

Main category: cs.LG

TL;DR: 本论文介绍了图数据建模在化学科学中的应用，特别是图神经网络在分子、蛋白质和化学过程中操作的能力。


<details>
  <summary>Details</summary>
Motivation: 探讨图作为数学对象在化学中的意义，并展示如何通过机器学习模型解析其中的结构与相互作用。

Method: 通过介绍图设计的基础、图预测任务以及机器学习在图建模中的角色，系统性地罗列与化学科学相关的实例。

Result: 为读者提供一个应用图方法于化学发现次世代的全面指导框架。

Conclusion: 在化学科学中，图方法尤其是结合机器学习的图神经网络方法具有广泛可能性，为分子设计和化学预测带来新方向。

Abstract: Graphs are central to the chemical sciences, providing a natural language to
describe molecules, proteins, reactions, and industrial processes. They capture
interactions and structures that underpin materials, biology, and medicine.
This primer, Graph Data Modeling: Molecules, Proteins, & Chemical Processes,
introduces graphs as mathematical objects in chemistry and shows how learning
algorithms (particularly graph neural networks) can operate on them. We outline
the foundations of graph design, key prediction tasks, representative examples
across chemical sciences, and the role of machine learning in graph-based
modeling. Together, these concepts prepare readers to apply graph methods to
the next generation of chemical discovery.

</details>


### [175] [Atrial Fibrillation Prediction Using a Lightweight Temporal Convolutional and Selective State Space Architecture](https://arxiv.org/abs/2508.19361)
*Yongbin Lee,Ki H. Chon*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的新模型，使用RR间隔数据，实现了房颤（尤其是阵发性房颤）的高效早期预测。


<details>
  <summary>Details</summary>
Motivation: 阵发性房颤（PAF）因其突发性和短时持续性，常常未被及时检测，而这可能导致疾病向持续性房颤进展并增加死亡与并发症风险。提前预测房颤有助于通过预防治疗减缓疾病恶化。

Method: 设计了一种轻量级深度学习模型，结合时间卷积网络（TCN）和选择性状态空间模型Mamba，使用RR间隔数据进行高效并行序列建模，预测房颤。

Result: 模型在个体测试中表现优异，敏感性为0.908，特异性为0.933，F1得分为0.930，AUROC为0.972，AUPRC为0.932。同时，模型仅有73.5千参数和38.3 MFLOPs，体现了卓越的计算效率和精度。

Conclusion: 该方法相比传统CNN-RNN解决方案在准确性和紧凑性上更具优势，可在症状出现前两小时对房颤进行预测，为预防干预提供了充足的时间。

Abstract: Atrial fibrillation (AF) is the most common arrhythmia, increasing the risk
of stroke, heart failure, and other cardiovascular complications. While AF
detection algorithms perform well in identifying persistent AF, early-stage
progression, such as paroxysmal AF (PAF), often goes undetected due to its
sudden onset and short duration. However, undetected PAF can progress into
sustained AF, increasing the risk of mortality and severe complications. Early
prediction of AF offers an opportunity to reduce disease progression through
preventive therapies, such as catecholamine-sparing agents or beta-blockers. In
this study, we propose a lightweight deep learning model using only RR
Intervals (RRIs), combining a Temporal Convolutional Network (TCN) for
positional encoding with Mamba, a selective state space model, to enable early
prediction of AF through efficient parallel sequence modeling. In subject-wise
testing results, our model achieved a sensitivity of 0.908, specificity of
0.933, F1-score of 0.930, AUROC of 0.972, and AUPRC of 0.932. Additionally, our
method demonstrates high computational efficiency, with only 73.5 thousand
parameters and 38.3 MFLOPs, outperforming traditional Convolutional Neural
Network-Recurrent Neural Network (CNN-RNN) approaches in both accuracy and
model compactness. Notably, the model can predict AF up to two hours in advance
using just 30 minutes of input data, providing enough lead time for preventive
interventions.

</details>


### [176] [Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs](https://arxiv.org/abs/2508.19366)
*Supratik Sarkar,Swagatam Das*

Main category: cs.LG

TL;DR: 本文提出了一种基于信息几何框架和扩散动力学的方法来量化多模态大语言模型的幻觉行为，将从定性检测推进到数学量化测量。


<details>
  <summary>Details</summary>
Motivation: 现有的评估技术以启发式定性基准或经验减缓为主，缺乏系统的量化方法和理论保证，因此难以真正理解幻觉的产生和传播机制。

Method: 引入了以多个模态图Laplacians的谱嵌入为基础的方法，通过Reproducing Kernel Hilbert Space嵌入中的本征模式分解，使用Rayleigh-Ritz界限对幻觉能量的时间演化进行分析。

Result: 提供了为多模态幻觉量身定制的解析度高并易于解释的指标，能够捕捉幻觉随时间和输入提示温度变化的动态演变。

Conclusion: 建立了可量化和可分析的基础框架，将幻觉问题从定性风险转变为可追踪和研究的现象。

Abstract: Hallucinations in large language models (LLMs) remain a fundamental obstacle
to trustworthy AI, particularly in high-stakes multimodal domains such as
medicine, law, and finance. Existing evaluation techniques are largely
heuristic -- anchored in qualitative benchmarking or ad-hoc empirical
mitigation -- providing neither principled quantification nor actionable
theoretical guarantees. This gap leaves a critical blind spot in understanding
how hallucinations arise, propagate, and interact across modalities. We
introduce the first (to our knowledge) rigorous information geometric framework
in diffusion dynamics for quantifying hallucinations in multimodal LLMs
(MLLMs), advancing the field from qualitative detection to mathematically
grounded measurement. Our approach represents MLLM outputs as the spectral
embeddings over multimodal graph Laplacians and characterizes the manifold gaps
of truth vs inconsistencies as the semantic distortion, enabling the tight
Rayleigh--Ritz bounds on the multimodal hallucination energy as a functional of
time-dependent temperature profiles. By leveraging eigenmode decompositions in
Reproducing Kernel Hilbert Space (RKHS) embeddings, our framework delivers
modality-aware, theoretically interpretable metrics that capture the evolution
of hallucinations across time and input prompts through temperature annealing.
This work establishes a principled foundation for quantifying and bounding
hallucinations, transforming them from a qualitative risk to a tractable,
analyzable phenomenon.

</details>


### [177] [Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments](https://arxiv.org/abs/2508.19376)
*Dikshant Sagar,Kaiwen Yu,Alejandro Yankelevich,Jianming Bian,Pierre Baldi*

Main category: cs.LG

TL;DR: 研究探索使用基于LLaMA 3.2调整的视觉-语言模型（VLM）分类高能物理实验中的中微子交互，与现有CNN基线进行比较并展示其超越性能潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）具备多模态推理能力，但在高能物理实验中将其应用于分类问题尚未深入研究。

Method: 利用微调后的视觉-语言模型（VLM），基于LLaMA 3.2架构，分析高能物理实验的成像数据，同时与传统的CNN基线进行对比测试。

Result: 与CNN相比，VLM在分类精确度、精确率、召回率和AUC-ROC等指标上达到或超过其表现。此外，VLM还能更有效整合补充的文本或语义上下文信息。

Conclusion: 该研究证明了视觉-语言模型（VLM）在高能物理事件分类中的巨大潜力，可作为通用骨干模型，为实验性中微子物理的多模态方法开辟新道路。

Abstract: Recent progress in large language models (LLMs) has shown strong potential
for multimodal reasoning beyond natural language. In this work, we explore the
use of a fine-tuned Vision-Language Model (VLM), based on LLaMA 3.2, for
classifying neutrino interactions from pixelated detector images in high-energy
physics (HEP) experiments. We benchmark its performance against an established
CNN baseline used in experiments like NOvA and DUNE, evaluating metrics such as
classification accuracy, precision, recall, and AUC-ROC. Our results show that
the VLM not only matches or exceeds CNN performance but also enables richer
reasoning and better integration of auxiliary textual or semantic context.
These findings suggest that VLMs offer a promising general-purpose backbone for
event classification in HEP, paving the way for multimodal approaches in
experimental neutrino physics.

</details>


### [178] [Towards Quantum Machine Learning for Malicious Code Analysis](https://arxiv.org/abs/2508.19381)
*Jesus Lopez,Saeefa Rubaiyet Nowmi,Viviana Cadena,Mohammad Saidur Rahman*

Main category: cs.LG

TL;DR: 本研究探讨了基于量子计算的混合量子-经典模型（QMLP和QCNN）用于恶意软件分类的应用，展示了其在多数据集上的高精确度。


<details>
  <summary>Details</summary>
Motivation: 研究量子计算在恶意软件检测领域中的潜力，通过采用量子计算提升已有分类模型的性能。

Method: 提出并分析两种混合量子-经典模型（QMLP和QCNN），通过角度嵌入将恶意软件特征编码为量子态，使用五个数据集进行二元和多分类任务的性能评估。

Result: 在二元分类中，QMLP和QCNN达到了91%-96%的准确率；在多分类任务中，准确率从41.7%到95.7%不等，QMLP在复杂任务中表现更优，而QCNN在训练效率上更有优势但准确率稍低。

Conclusion: 量子机器学习（QML）可以提高恶意软件分类的效果，QMLP适合复杂分类任务，QCNN更适合高效训练需求。

Abstract: Classical machine learning (CML) has been extensively studied for malware
classification. With the emergence of quantum computing, quantum machine
learning (QML) presents a paradigm-shifting opportunity to improve malware
detection, though its application in this domain remains largely unexplored. In
this study, we investigate two hybrid quantum-classical models -- a Quantum
Multilayer Perceptron (QMLP) and a Quantum Convolutional Neural Network (QCNN),
for malware classification. Both models utilize angle embedding to encode
malware features into quantum states. QMLP captures complex patterns through
full qubit measurement and data re-uploading, while QCNN achieves faster
training via quantum convolution and pooling layers that reduce active qubits.
We evaluate both models on five widely used malware datasets -- API-Graph,
EMBER-Domain, EMBER-Class, AZ-Domain, and AZ-Class, across binary and
multiclass classification tasks.
  Our results show high accuracy for binary classification -- 95-96% on
API-Graph, 91-92% on AZ-Domain, and 77% on EMBER-Domain. In multiclass
settings, accuracy ranges from 91.6-95.7% on API-Graph, 41.7-93.6% on AZ-Class,
and 60.7-88.1% on EMBER-Class. Overall, QMLP outperforms QCNN in complex
multiclass tasks, while QCNN offers improved training efficiency at the cost of
reduced accuracy.

</details>


### [179] [DETNO: A Diffusion-Enhanced Transformer Neural Operator for Long-Term Traffic Forecasting](https://arxiv.org/abs/2508.19389)
*Owais Ahmad,Milad Ramezankhani,Anirudh Deodhar*

Main category: cs.LG

TL;DR: 提出了一个结合Transformer和扩散模型的新方法DETNO，用于改进长期交通流预测中的高频特性保留。


<details>
  <summary>Details</summary>
Motivation: 解决现有神经算子的高频交通现象捕获不足及多步预测误差积累问题，提高实时交通管理效果。

Method: 提出了DETNO：利用带交叉注意力机制的Transformer神经算子建模，并加入基于扩散的精细化组件，逐步去噪重建高频细节。

Result: 通过在复杂交通数据集上的验证，DETNO在长期预测中表现优异，能够保留高频特性并提高预测稳定性。

Conclusion: DETNO有效克服了传统方法的平滑预测和多步预测不稳定性，为智能交通系统的长期流量预测提供了更具表现力和准确性的工具。

Abstract: Accurate long-term traffic forecasting remains a critical challenge in
intelligent transportation systems, particularly when predicting high-frequency
traffic phenomena such as shock waves and congestion boundaries over extended
rollout horizons. Neural operators have recently gained attention as promising
tools for modeling traffic flow. While effective at learning function space
mappings, they inherently produce smooth predictions that fail to reconstruct
high-frequency features such as sharp density gradients which results in rapid
error accumulation during multi-step rollout predictions essential for
real-time traffic management. To address these fundamental limitations, we
introduce a unified Diffusion-Enhanced Transformer Neural Operator (DETNO)
architecture. DETNO leverages a transformer neural operator with
cross-attention mechanisms, providing model expressivity and super-resolution,
coupled with a diffusion-based refinement component that iteratively
reconstructs high-frequency traffic details through progressive denoising. This
overcomes the inherent smoothing limitations and rollout instability of
standard neural operators. Through comprehensive evaluation on chaotic traffic
datasets, our method demonstrates superior performance in extended rollout
predictions compared to traditional and transformer-based neural operators,
preserving high-frequency components and improving stability over long
prediction horizons.

</details>


### [180] [Quantum-Classical Hybrid Molecular Autoencoder for Advancing Classical Decoding](https://arxiv.org/abs/2508.19394)
*Afrar Jahin,Yi Pan,Yingfeng Wang,Tianming Liu,Wei Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种用于SMILES重建的混合量子-经典架构，成功提高了量子保真度和经典相似性，量子保真度达到约84%，而经典相似性为60%。


<details>
  <summary>Details</summary>
Motivation: 尽管量子机器学习在生成模型如分子设计中显示出巨大潜力，但在处理序列任务（如SMILES字符串重建）上仍存在保真度下降的问题，需要新的方法改善该方面的性能。

Method: 设计了一种混合量子-经典架构，将量子编码和经典序列建模相结合，用于SMILES字符串重建任务。

Result: 该方法实现了约84%的量子保真度和60%的经典重建相似性，优于现有的量子基准模型。

Conclusion: 本文的方法为量子机器学习在分子和药物发现中的更广泛应用奠定了基础，同时在量子表示和经典序列建模之间找到了良好平衡，促进了量子感知序列模型的研究。

Abstract: Although recent advances in quantum machine learning (QML) offer significant
potential for enhancing generative models, particularly in molecular design, a
large array of classical approaches still face challenges in achieving high
fidelity and validity. In particular, the integration of QML with
sequence-based tasks, such as Simplified Molecular Input Line Entry System
(SMILES) string reconstruction, remains underexplored and usually suffers from
fidelity degradation. In this work, we propose a hybrid quantum-classical
architecture for SMILES reconstruction that integrates quantum encoding with
classical sequence modeling to improve quantum fidelity and classical
similarity. Our approach achieves a quantum fidelity of approximately 84% and a
classical reconstruction similarity of 60%, surpassing existing quantum
baselines. Our work lays a promising foundation for future QML applications,
striking a balance between expressive quantum representations and classical
sequence models and catalyzing broader research on quantum-aware sequence
models for molecular and drug discovery.

</details>


### [181] [Kolmogorov-Arnold Representation for Symplectic Learning: Advancing Hamiltonian Neural Networks](https://arxiv.org/abs/2508.19410)
*Zongyu Wu,Ruichen Xu,Luoyao Chen,Georgios Kementzidis,Siyao Wang,Yuefan Deng*

Main category: cs.LG

TL;DR: 提出基于Kolmogorov-Arnold表征的哈密顿神经网络（KAR-HNN），以单变量变换取代多层感知器（MLPs）。


<details>
  <summary>Details</summary>
Motivation: 目前HNNs尽管通过学习哈密顿函数保证了能量守恒，但基于MLP的实现对复杂计算问题的稳定性敏感。

Method: 利用局部化函数逼近技术，通过单变量变换更好地捕获高频和多尺度动力学，减少能量漂移并提高长时间预测稳定性，同时保持哈密顿系统的辛形式。

Result: 在四个基准问题中测试，包括弹簧-质量系统、简单摆动、二体和三体问题，展现了其准确性与稳定性的优越性。

Conclusion: 该方法适合高维、少量参数已知的物理过程建模。

Abstract: We propose a Kolmogorov-Arnold Representation-based Hamiltonian Neural
Network (KAR-HNN) that replaces the Multilayer Perceptrons (MLPs) with
univariate transformations. While Hamiltonian Neural Networks (HNNs) ensure
energy conservation by learning Hamiltonian functions directly from data,
existing implementations, often relying on MLPs, cause hypersensitivity to the
hyperparameters while exploring complex energy landscapes. Our approach
exploits the localized function approximations to better capture high-frequency
and multi-scale dynamics, reducing energy drift and improving long-term
predictive stability. The networks preserve the symplectic form of Hamiltonian
systems, and thus maintain interpretability and physical consistency. After
assessing KAR-HNN on four benchmark problems including spring-mass, simple
pendulum, two- and three-body problem, we foresee its effectiveness for
accurate and stable modeling of realistic physical processes often at high
dimensions and with few known parameters.

</details>


### [182] [Even Heads Fix Odd Errors: Mechanistic Discovery and Surgical Repair in Transformer Attention](https://arxiv.org/abs/2508.19414)
*Gustavo Sandoval*

Main category: cs.LG

TL;DR: 本文对Llama-3.1-8B模型在特定格式下的推理失败进行了研究，发现模型在不同格式中对数值的比较会出错，但简单格式下答对。系统性干预揭示了Transformer中奇偶注意力头的分工及其作用。


<details>
  <summary>Details</summary>
Motivation: 研究目的是理解Transformer模型在推理中产生错误的机制，并探索如何修复此类问题，同时揭示其内部结构的可解释性与效率潜力。

Method: 通过系统性干预实验，分析模型中注意力头的功能分化及其对推理表现的影响，并通过特征重叠和放大的分析（SAE），揭示错误推理的机理和修复方式。

Result: 发现奇偶注意力头分工明确，偶数编号的注意力头负责数值比较；通过调整第10层的偶数头数量，可以修复错误推理。此外，研究揭示了复杂模块要求背后的结构性机制。

Conclusion: 本文揭示了Transformer模型中模块化的功能及其修复潜力，提供了更高效的修复方案和新的可解释性见解，为未来模型研究和应用提供了参考。

Abstract: We present a mechanistic case study of a format-dependent reasoning failure
in Llama-3.1-8B-Instruct, where the model incorrectly judges "9.11" as larger
than "9.8" in chat or Q&A formats, but answers correctly in simple format.
Through systematic intervention, we discover transformers implement even/odd
attention head specialization: even indexed heads handle numerical comparison,
while odd heads serve incompatible functions. The bug requires exactly 8 even
heads at Layer 10 for perfect repair. Any combination of 8+ even heads
succeeds, while 7 or fewer completely fails, revealing sharp computational
thresholds with perfect redundancy among the 16 even heads. SAE analysis
reveals the mechanism: format representations separate (10% feature overlap at
Layer 7), then re-entangle with different weightings (80% feature overlap at
Layer 10), with specific features showing 1.5x amplification in failing
formats. We achieve perfect repair using only 25% of attention heads and
identify a 60% pattern replacement threshold, demonstrating that apparent
full-module requirements hide sophisticated substructure with implications for
interpretability and efficiency. All of our code is available at
https://github.com/gussand/surgeon.

</details>


### [183] [Differentiable multiphase flow model for physics-informed machine learning in reservoir pressure management](https://arxiv.org/abs/2508.19419)
*Harun Ur Rashid,Aleksandra Pachalieva,Daniel O'Malley*

Main category: cs.LG

TL;DR: 该论文提出了一种结合物理模拟和卷积神经网络（CNN）的机器学习工作流，以优化地下储层压力控制，大大降低模拟计算的成本。


<details>
  <summary>Details</summary>
Motivation: 针对地下储层地质异质性和多相流体流动动态的复杂性，高精度物理模拟成本高昂但又必需，因此需要低成本的替代方法。

Method: 引入一种物理驱动的机器学习工作流，结合全可微的多相流模拟器和CNN，通过预训练单相流稳态模拟数据，再微调至多相流模拟数据，减低计算成本。

Result: 与传统方法相比，该方法在真实注采场景下提供了更准确和实用的预测，且模拟数量由原需近千万降至约三千次。

Conclusion: 结合转移学习和物理知识，这一方法优化了储层压力控制预测，实现了显著的精度提升及计算成本的降低。

Abstract: Accurate subsurface reservoir pressure control is extremely challenging due
to geological heterogeneity and multiphase fluid-flow dynamics. Predicting
behavior in this setting relies on high-fidelity physics-based simulations that
are computationally expensive. Yet, the uncertain, heterogeneous properties
that control these flows make it necessary to perform many of these expensive
simulations, which is often prohibitive. To address these challenges, we
introduce a physics-informed machine learning workflow that couples a fully
differentiable multiphase flow simulator, which is implemented in the DPFEHM
framework with a convolutional neural network (CNN). The CNN learns to predict
fluid extraction rates from heterogeneous permeability fields to enforce
pressure limits at critical reservoir locations. By incorporating transient
multiphase flow physics into the training process, our method enables more
practical and accurate predictions for realistic injection-extraction scenarios
compare to previous works. To speed up training, we pretrain the model on
single-phase, steady-state simulations and then fine-tune it on full multiphase
scenarios, which dramatically reduces the computational cost. We demonstrate
that high-accuracy training can be achieved with fewer than three thousand
full-physics multiphase flow simulations -- compared to previous estimates
requiring up to ten million. This drastic reduction in the number of
simulations is achieved by leveraging transfer learning from much less
expensive single-phase simulations.

</details>


### [184] [MS-ConTab: Multi-Scale Contrastive Learning of Mutation Signatures for Pan Cancer Representation and Stratification](https://arxiv.org/abs/2508.19424)
*Yifan Dou,Adam Khadre,Ruben C Petreaca,Golrokh Mirzaei*

Main category: cs.LG

TL;DR: 本文提出了一种新的无监督对比学习框架，用于基于突变数据将43种癌症类型进行聚类，从而提供一种可扩展且可解释的突变驱动癌症分类方法。


<details>
  <summary>Details</summary>
Motivation: 理解跨癌症的突变特征分布能揭示肿瘤发生的分子机制。然而，目前基于群体水平的癌种聚类大多依赖传统统计方法，而患者层面的机器学习技术虽被广泛应用于发现肿瘤亚型，却还未能有效覆盖群体层面的应用。

Method: 通过引入无监督对比学习框架，利用生成的基因水平和染色体水平的突变特征，使用TabNet编码器和多尺度对比学习目标（NT-Xent loss）进行训练，来生成统一的癌症类型嵌入表示。

Result: 生成的模型学习到了生物学意义深远的潜在癌症类型表示，这些表示的聚类结果与已知的突变过程和组织起源一致。

Conclusion: 该研究首次将对比学习应用于癌症类型的群体级聚类，为基于突变特征的癌症分类提供了一个新的框架。

Abstract: Motivation. Understanding the pan-cancer mutational landscape offers critical
insights into the molecular mechanisms underlying tumorigenesis. While
patient-level machine learning techniques have been widely employed to identify
tumor subtypes, cohort-level clustering, where entire cancer types are grouped
based on shared molecular features, has largely relied on classical statistical
methods.
  Results. In this study, we introduce a novel unsupervised contrastive
learning framework to cluster 43 cancer types based on coding mutation data
derived from the COSMIC database. For each cancer type, we construct two
complementary mutation signatures: a gene-level profile capturing nucleotide
substitution patterns across the most frequently mutated genes, and a
chromosome-level profile representing normalized substitution frequencies
across chromosomes. These dual views are encoded using TabNet encoders and
optimized via a multi-scale contrastive learning objective (NT-Xent loss) to
learn unified cancer-type embeddings. We demonstrate that the resulting latent
representations yield biologically meaningful clusters of cancer types,
aligning with known mutational processes and tissue origins. Our work
represents the first application of contrastive learning to cohort-level cancer
clustering, offering a scalable and interpretable framework for mutation-driven
cancer subtyping.

</details>


### [185] [Data-Augmented Few-Shot Neural Stencil Emulation for System Identification of Computer Models](https://arxiv.org/abs/2508.19441)
*Sanket Jantre,Deepak Akhare,Xiaoning Qian,Nathan M. Urban*

Main category: cs.LG

TL;DR: 研究提出了一种更高效的样本数据增强策略，用于从计算机生成的部分微分方程(PDE)模型中训练神经网络PDE系统。


<details>
  <summary>Details</summary>
Motivation: 现有的方法需要依赖于从PDE计算器长时间积分获得的轨迹数据，存在低效且带冗余问题，模型也难以泛化。

Method: 提出一种基于空间填充采样(local stencil states)的数据增强策略，有效去除轨迹数据中的冗余，并通过过采样使模型能够泛化到稀有状态。

Result: 通过合成模拟实验，证明基于新方法学习的神经PDE操作器可在使用少量的仿真时间步长数据（相当于10步的时刻数据）时保持高精度。

Conclusion: 基于数据增强的合成局部采样方法显著提升了轨迹采样下神经PDE操作器的训练表现，对多种PDE系统展现了优势。

Abstract: Partial differential equations (PDEs) underpin the modeling of many natural
and engineered systems. It can be convenient to express such models as neural
PDEs rather than using traditional numerical PDE solvers by replacing part or
all of the PDE's governing equations with a neural network representation.
Neural PDEs are often easier to differentiate, linearize, reduce, or use for
uncertainty quantification than the original numerical solver. They are usually
trained on solution trajectories obtained by long time integration of the PDE
solver. Here we propose a more sample-efficient data-augmentation strategy for
generating neural PDE training data from a computer model by space-filling
sampling of local "stencil" states. This approach removes a large degree of
spatiotemporal redundancy present in trajectory data and oversamples states
that may be rarely visited but help the neural PDE generalize across the state
space. We demonstrate that accurate neural PDE stencil operators can be learned
from synthetic training data generated by the computational equivalent of 10
timesteps' worth of numerical simulation. Accuracy is further improved if we
assume access to a single full-trajectory simulation from the computer model,
which is typically available in practice. Across several PDE systems, we show
that our data-augmented synthetic stencil data yield better trained neural
stencil operators, with clear performance gains compared with naively sampled
stencil data from simulation trajectories.

</details>


### [186] [Efficiently Generating Multidimensional Calorimeter Data with Tensor Decomposition Parameterization](https://arxiv.org/abs/2508.19443)
*Paimon Goulart,Shaan Pakala,Evangelos Papalexakis*

Main category: cs.LG

TL;DR: 本研究提出通过在生成模型中引入张量分解，以降低生成复杂模拟数据的成本。


<details>
  <summary>Details</summary>
Motivation: 生成复杂的模拟数据需要耗费大量时间和资源，因此需要寻找更加高效的生成方法。

Method: 将张量分解嵌入生成对抗网络或扩散模型中，将多维数据分解为更小的张量因子，从而减少计算开销和模型参数。

Result: 通过实验证明，经过张量分解生成的数据仍然具备使用价值，同时显著降低了生成成本。

Conclusion: 张量分解有助于提高生成模型的效率，特别是在生成多维数据时，表现尤为显著。

Abstract: Producing large complex simulation datasets can often be a time and resource
consuming task. Especially when these experiments are very expensive, it is
becoming more reasonable to generate synthetic data for downstream tasks.
Recently, these methods may include using generative machine learning models
such as Generative Adversarial Networks or diffusion models. As these
generative models improve efficiency in producing useful data, we introduce an
internal tensor decomposition to these generative models to even further reduce
costs. More specifically, for multidimensional data, or tensors, we generate
the smaller tensor factors instead of the full tensor, in order to
significantly reduce the model's output and overall parameters. This reduces
the costs of generating complex simulation data, and our experiments show the
generated data remains useful. As a result, tensor decomposition has the
potential to improve efficiency in generative models, especially when
generating multidimensional data, or tensors.

</details>


### [187] [On Surjectivity of Neural Networks: Can you elicit any behavior from your model?](https://arxiv.org/abs/2508.19445)
*Haozhe Jiang,Nika Haghtalab*

Main category: cs.LG

TL;DR: 本文探讨神经网络是否为满射函数的问题，指出现代一些通用神经网络架构几乎总是满射，暴露其潜在的漏洞。


<details>
  <summary>Details</summary>
Motivation: 探讨神经网络生成指定输出的能力以及模型可能存在的安全性隐患。

Method: 证明现代神经网络架构（如预归一化网络和线性注意力模块）的满射性，并进一步分析其安全性问题。

Result: 发现GPT等常见生成模型以及扩散模型中存在满射性，这意味着它们对任意输出均可能生成对应输入。

Conclusion: 这些常用架构的满射特性，使其存在易被利用的潜在安全漏洞，需加以重视。

Abstract: Given a trained neural network, can any specified output be generated by some
input? Equivalently, does the network correspond to a function that is
surjective? In generative models, surjectivity implies that any output,
including harmful or undesirable content, can in principle be generated by the
networks, raising concerns about model safety and jailbreak vulnerabilities. In
this paper, we prove that many fundamental building blocks of modern neural
architectures, such as networks with pre-layer normalization and
linear-attention modules, are almost always surjective. As corollaries, widely
used generative frameworks, including GPT-style transformers and diffusion
models with deterministic ODE solvers, admit inverse mappings for arbitrary
outputs. By studying surjectivity of these modern and commonly used neural
architectures, we contribute a formalism that sheds light on their unavoidable
vulnerability to a broad class of adversarial attacks.

</details>


### [188] [The Sample Complexity of Membership Inference and Privacy Auditing](https://arxiv.org/abs/2508.19458)
*Mahdi Haghifam,Adam Smith,Jonathan Ullman*

Main category: cs.LG

TL;DR: 研究了在高斯平均估计设置下，会员身份推断攻击需要的参考样本的最小数量问题，发现攻击者可能需要比训练算法更多的样本。


<details>
  <summary>Details</summary>
Motivation: 探讨攻击者在会员身份推断中需要的最少参考样本数，分析样本复杂性问题。

Method: 利用高斯分布的平均估计设定，研究攻击者在实现会员身份推断所需的最低样本数，并与完全知情的攻击者比较。

Result: 得出结论，在此设定下，攻击者可能需要Ω(n + n^2ρ^2)的样本数，这显著高于训练算法使用的样本数。

Conclusion: 当前实用攻击可能低估了会员身份推断的可能性，更强的攻击有可能在分布信息易于获取时实现。

Abstract: A membership-inference attack gets the output of a learning algorithm, and a
target individual, and tries to determine whether this individual is a member
of the training data or an independent sample from the same distribution. A
successful membership-inference attack typically requires the attacker to have
some knowledge about the distribution that the training data was sampled from,
and this knowledge is often captured through a set of independent reference
samples from that distribution. In this work we study how much information the
attacker needs for membership inference by investigating the sample
complexity-the minimum number of reference samples required-for a successful
attack. We study this question in the fundamental setting of Gaussian mean
estimation where the learning algorithm is given $n$ samples from a Gaussian
distribution $\mathcal{N}(\mu,\Sigma)$ in $d$ dimensions, and tries to estimate
$\hat\mu$ up to some error $\mathbb{E}[\|\hat \mu - \mu\|^2_{\Sigma}]\leq
\rho^2 d$. Our result shows that for membership inference in this setting,
$\Omega(n + n^2 \rho^2)$ samples can be necessary to carry out any attack that
competes with a fully informed attacker. Our result is the first to show that
the attacker sometimes needs many more samples than the training algorithm uses
to train the model. This result has significant implications for practice, as
all attacks used in practice have a restricted form that uses $O(n)$ samples
and cannot benefit from $\omega(n)$ samples. Thus, these attacks may be
underestimating the possibility of membership inference, and better attacks may
be possible when information about the distribution is easy to obtain.

</details>


### [189] [Incentivized Lipschitz Bandits](https://arxiv.org/abs/2508.19466)
*Sourav Chakraborty,Amit Kiran Rege,Claire Monteleoni,Lijun Chen*

Main category: cs.LG

TL;DR: 本文研究了具有无穷多臂的连续度量空间中的强激励探索问题，提出了一种新的激励探索算法，在理论分析和数值模拟中证明其表现良好。


<details>
  <summary>Details</summary>
Motivation: 研究如何在带有无穷多臂的问题中，激励短视的代理人合理探索，并解决因奖励偏移带来的问题。

Method: 提出将无穷臂的空间均匀离散化的算法，并对冲奖励偏移的问题，推导出次线性后悔和补偿界的算法。

Result: 得到了后悔和补偿界为 $\Tilde{O}(T^{d+1/d+2})$ 的结果，并验证了算法可以推广至上下文多臂赌博机问题且性能良好。

Conclusion: 该算法有效地达成了既减少后悔又控制补偿的目标，且适用于多种场景。

Abstract: We study incentivized exploration in multi-armed bandit (MAB) settings with
infinitely many arms modeled as elements in continuous metric spaces. Unlike
classical bandit models, we consider scenarios where the decision-maker
(principal) incentivizes myopic agents to explore beyond their greedy choices
through compensation, but with the complication of reward drift--biased
feedback arising due to the incentives. We propose novel incentivized
exploration algorithms that discretize the infinite arm space uniformly and
demonstrate that these algorithms simultaneously achieve sublinear cumulative
regret and sublinear total compensation. Specifically, we derive regret and
compensation bounds of $\Tilde{O}(T^{d+1/d+2})$, with $d$ representing the
covering dimension of the metric space. Furthermore, we generalize our results
to contextual bandits, achieving comparable performance guarantees. We validate
our theoretical findings through numerical simulations.

</details>


### [190] [DeepAtlas: a tool for effective manifold learning](https://arxiv.org/abs/2508.19479)
*Serena Hughes,Timothy Hamilton,Tom Kolokotrones,Eric J. Deeds*

Main category: cs.LG

TL;DR: DeepAtlas是一种用于分析数据是否符合流形假设、并生成局部低维表示的算法。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏能够验证流形假设及生成局部映射的工具。

Method: 利用DeepAtlas生成数据局部的低维嵌入，并通过深度神经网络进行映射。结合拓扑变形分析是否符合流形假设及其维度。

Result: DeepAtlas成功学习了流形结构，但许多真实数据集例如单细胞RNA测序并不符合流形假设。

Conclusion: DeepAtlas不仅能生成局部低维模型，还可作为生成式工具，促进微分几何方法在各种数据集中的应用。

Abstract: Manifold learning builds on the "manifold hypothesis," which posits that data
in high-dimensional datasets are drawn from lower-dimensional manifolds.
Current tools generate global embeddings of data, rather than the local maps
used to define manifolds mathematically. These tools also cannot assess whether
the manifold hypothesis holds true for a dataset. Here, we describe DeepAtlas,
an algorithm that generates lower-dimensional representations of the data's
local neighborhoods, then trains deep neural networks that map between these
local embeddings and the original data. Topological distortion is used to
determine whether a dataset is drawn from a manifold and, if so, its
dimensionality. Application to test datasets indicates that DeepAtlas can
successfully learn manifold structures. Interestingly, many real datasets,
including single-cell RNA-sequencing, do not conform to the manifold
hypothesis. In cases where data is drawn from a manifold, DeepAtlas builds a
model that can be used generatively and promises to allow the application of
powerful tools from differential geometry to a variety of datasets.

</details>


### [191] [Distribution Shift Aware Neural Tabular Learning](https://arxiv.org/abs/2508.19486)
*Wangyang Ying,Nanxu Gong,Dongjie Wang,Xinyuan Wang,Arun Vignesh Malarkkan,Vivek Gupta,Chandan K. Reddy,Yanjie Fu*

Main category: cs.LG

TL;DR: 提出了一种名为Shift-Aware Feature Transformation (SAFT)的新框架，用于应对表格数据的分布变换问题，通过优化特征表示，显著提升方法的健壮性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的表格学习方法在训练和测试数据存在分布变换时效果较差，需要一种能够增强其鲁棒性的方案。

Method: 通过Shift-Aware Feature Transformation (SAFT)框架，将离散搜索任务转化为连续表征生成问题，并结合嵌入去相关、样本重加权、子最优嵌入平均和平坦生成等机制增强模型表现。

Result: 在多种真实世界的分布变化条件下，SAFT一致性地优于现有的表格学习方法，在健壮性、有效性和泛化能力方面表现出色。

Conclusion: SAFT为解决分布变换表格学习问题提供了新思路，通过复杂机制提升了特征表示的能力，改善了学习模型的鲁棒性和质量。

Abstract: Tabular learning transforms raw features into optimized spaces for downstream
tasks, but its effectiveness deteriorates under distribution shifts between
training and testing data. We formalize this challenge as the Distribution
Shift Tabular Learning (DSTL) problem and propose a novel Shift-Aware Feature
Transformation (SAFT) framework to address it. SAFT reframes tabular learning
from a discrete search task into a continuous representation-generation
paradigm, enabling differentiable optimization over transformed feature sets.
SAFT integrates three mechanisms to ensure robustness: (i) shift-resistant
representation via embedding decorrelation and sample reweighting, (ii)
flatness-aware generation through suboptimal embedding averaging, and (iii)
normalization-based alignment between training and test distributions.
Extensive experiments show that SAFT consistently outperforms prior tabular
learning methods in terms of robustness, effectiveness, and generalization
ability under diverse real-world distribution shifts.

</details>


### [192] [Data-Efficient Symbolic Regression via Foundation Model Distillation](https://arxiv.org/abs/2508.19487)
*Wangyang Ying,Jinghan Zhang,Haoyue Bai,Nanxu Gong,Xinyuan Wang,Kunpeng Liu,Chandan K. Reddy,Yanjie Fu*

Main category: cs.LG

TL;DR: 本文提出了EQUATE框架，一种用于从低数据环境中发现数学公式的高效方法。


<details>
  <summary>Details</summary>
Motivation: 解决预训练模型在小规模领域数据中表现不佳的问题，为低数据环境下的符号公式发现提供解决方案。

Method: 提出了EQUATE框架，将符号-数值对齐与评估器引导嵌入优化相结合，将离散方程搜索重构为共享嵌入空间中的连续优化任务。

Result: 在Feynman、Strogatz以及黑盒数据集等三个基准上实验显示，EQUATE在准确性与鲁棒性上显著优于现有方法，同时保持低复杂度和快速推理能力。

Conclusion: EQUATE框架是一种有效且通用的方法，可在基础模型蒸馏设置中实现数据高效的符号回归。

Abstract: Discovering interpretable mathematical equations from observed data (a.k.a.
equation discovery or symbolic regression) is a cornerstone of scientific
discovery, enabling transparent modeling of physical, biological, and economic
systems. While foundation models pre-trained on large-scale equation datasets
offer a promising starting point, they often suffer from negative transfer and
poor generalization when applied to small, domain-specific datasets. In this
paper, we introduce EQUATE (Equation Generation via QUality-Aligned Transfer
Embeddings), a data-efficient fine-tuning framework that adapts foundation
models for symbolic equation discovery in low-data regimes via distillation.
EQUATE combines symbolic-numeric alignment with evaluator-guided embedding
optimization, enabling a principled embedding-search-generation paradigm. Our
approach reformulates discrete equation search as a continuous optimization
task in a shared embedding space, guided by data-equation fitness and
simplicity. Experiments across three standard public benchmarks (Feynman,
Strogatz, and black-box datasets) demonstrate that EQUATE consistently
outperforms state-of-the-art baselines in both accuracy and robustness, while
preserving low complexity and fast inference. These results highlight EQUATE as
a practical and generalizable solution for data-efficient symbolic regression
in foundation model distillation settings.

</details>


### [193] [PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense](https://arxiv.org/abs/2508.19488)
*Xavier Cadet,Simona Boboila,Sie Hendrata Dharmawan,Alina Oprea,Peter Chin*

Main category: cs.LG

TL;DR: 为应对日益复杂的网络攻击，此研究开发了PoolFlip环境和Flip-PSRO方法，改进了传统网络防御在学习和适应对手策略方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的网络防御策略在面对复杂、隐秘及动态变化的攻击时，缺乏灵活的学习能力，无法有效应对新型攻击。

Method: 构建了一个名为PoolFlip的多智能体环境，以扩展FlipIt游戏模型；并提出了Flip-PSRO方法，基于多智能体强化学习(MARL)和群体训练来开发能广泛适应的防御者。

Result: 实验结果表明，Flip-PSRO方法的防御者效果比基线方法提高2倍，且设计的基于控制权的效用函数在保证高效能的同时能维持对资源的高度控制。

Conclusion: Flip-PSRO和PoolFlip能够提升网络防御系统面对未知和自适应性对手的能力，为自动化网络安全防御提供了新的可能性。

Abstract: Cyber defense requires automating defensive decision-making under stealthy,
deceptive, and continuously evolving adversarial strategies. The FlipIt game
provides a foundational framework for modeling interactions between a defender
and an advanced adversary that compromises a system without being immediately
detected. In FlipIt, the attacker and defender compete to control a shared
resource by performing a Flip action and paying a cost. However, the existing
FlipIt frameworks rely on a small number of heuristics or specialized learning
techniques, which can lead to brittleness and the inability to adapt to new
attacks. To address these limitations, we introduce PoolFlip, a multi-agent gym
environment that extends the FlipIt game to allow efficient learning for
attackers and defenders. Furthermore, we propose Flip-PSRO, a multi-agent
reinforcement learning (MARL) approach that leverages population-based training
to train defender agents equipped to generalize against a range of unknown,
potentially adaptive opponents. Our empirical results suggest that Flip-PSRO
defenders are $2\times$ more effective than baselines to generalize to a
heuristic attack not exposed in training. In addition, our newly designed
ownership-based utility functions ensure that Flip-PSRO defenders maintain a
high level of control while optimizing performance.

</details>


### [194] [Learning Game-Playing Agents with Generative Code Optimization](https://arxiv.org/abs/2508.19506)
*Zhiyi Kuang,Ryan Rong,YuCheng Yuan,Allen Nie*

Main category: cs.LG

TL;DR: 提出了一种基于生成优化的新方法，用于学习游戏代理，通过Python程序来表现策略，并利用大语言模型（LLMs）进行优化。


<details>
  <summary>Details</summary>
Motivation: 旨在减少人类干预并提高决策策略的效率，同时确保代理能够进行复杂的长期推理。

Method: 将决策策略视为可自我进化的代码，结合自然语言反馈和执行轨迹，通过Python程序结合大语言模型进行优化。

Result: 在Atari游戏中，与深度强化学习基线相比，能够显著减少训练时间和环境交互，表现具有竞争力。

Conclusion: 使用程序化的策略表示不仅提高了效率，还显示了其在适应性和复杂推理中的潜力。

Abstract: We present a generative optimization approach for learning game-playing
agents, where policies are represented as Python programs and refined using
large language models (LLMs). Our method treats decision-making policies as
self-evolving code, with current observation as input and an in-game action as
output, enabling agents to self-improve through execution traces and natural
language feedback with minimal human intervention. Applied to Atari games, our
game-playing Python program achieves performance competitive with deep
reinforcement learning (RL) baselines while using significantly less training
time and much fewer environment interactions. This work highlights the promise
of programmatic policy representations for building efficient, adaptable agents
capable of complex, long-horizon reasoning.

</details>


### [195] [MobText-SISA: Efficient Machine Unlearning for Mobility Logs with Spatio-Temporal and Natural-Language Data](https://arxiv.org/abs/2508.19554)
*Haruki Yonekura,Ren Ozeki,Tatsuya Amano,Hamada Rizk,Hirozumi Yamaguchi*

Main category: cs.LG

TL;DR: 提出并验证了MobText-SISA框架，其应用于处理城市大规模异构时空数据，并支持数据删除请求的精确取消学习，同时保持高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 考虑到隐私法规（如GDPR）的要求，研究旨在开发无需从头训练模型即可实现单个数据取消学习的解决方案，以适应多模态移动数据的隐私需求。

Method: 提出MobText-SISA框架，扩展了SISA训练方法，结合了相似感知聚类和分片策略，每个分片独立训练并支持以检查点方式快速重训练，从而实现删除请求的精确取消学习并保持多样性。

Result: 实验证明，MobText-SISA在准确性和误差方面优于随机分片，并能快速收敛，同时维持基础预测性能。

Conclusion: MobText-SISA提供了一种在城市规模下分析多模态移动数据的实际解决方案，兼顾隐私合规和模型性能，为异构时空数据的隐私分析奠定了基础。

Abstract: Modern mobility platforms have stored vast streams of GPS trajectories,
temporal metadata, free-form textual notes, and other unstructured data.
Privacy statutes such as the GDPR require that any individual's contribution be
unlearned on demand, yet retraining deep models from scratch for every request
is untenable. We introduce MobText-SISA, a scalable machine-unlearning
framework that extends Sharded, Isolated, Sliced, and Aggregated (SISA)
training to heterogeneous spatio-temporal data. MobText-SISA first embeds each
trip's numerical and linguistic features into a shared latent space, then
employs similarity-aware clustering to distribute samples across shards so that
future deletions touch only a single constituent model while preserving
inter-shard diversity. Each shard is trained incrementally; at inference time,
constituent predictions are aggregated to yield the output. Deletion requests
trigger retraining solely of the affected shard from its last valid checkpoint,
guaranteeing exact unlearning. Experiments on a ten-month real-world mobility
log demonstrate that MobText-SISA (i) sustains baseline predictive accuracy,
and (ii) consistently outperforms random sharding in both error and convergence
speed. These results establish MobText-SISA as a practical foundation for
privacy-compliant analytics on multimodal mobility data at urban scale.

</details>


### [196] [Just Because You Can, Doesn't Mean You Should: LLMs for Data Fitting](https://arxiv.org/abs/2508.19563)
*Hejia Liu,Mochen Yang,Gediminas Adomavicius*

Main category: cs.LG

TL;DR: 近年来，LLMs在广泛的数据拟合和预测任务中表现出色，但发现其对与任务无关的数据表示变化高度敏感，这会显著影响预测性能。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在数据拟合中的鲁棒性问题，以验证其作为数据预测工具的适用性。

Method: 通过改变变量名称等任务无关因素，研究LLMs在上下文学习及监督微调下的预测性能敏感度；检查开权重LLM的注意力模式；并将其与TabPFN模型进行对比分析。

Result: 发现所有测试的模型，包括为数据拟合专门设计的TabPFN，均对与任务无关的变化表现出敏感性；此外，开权重LLM中不同位置的注意力分布不均也是敏感性的部分原因。

Conclusion: 目前，尽管LLMs预测能力强大，但其在数据拟合中的基本鲁棒性仍然缺乏，限制了其作为数据拟合工具的广泛应用。

Abstract: Large Language Models (LLMs) are being applied in a wide array of settings,
well beyond the typical language-oriented use cases. In particular, LLMs are
increasingly used as a plug-and-play method for fitting data and generating
predictions. Prior work has shown that LLMs, via in-context learning or
supervised fine-tuning, can perform competitively with many tabular supervised
learning techniques in terms of predictive performance. However, we identify a
critical vulnerability of using LLMs for data fitting -- making changes to data
representation that are completely irrelevant to the underlying learning task
can drastically alter LLMs' predictions on the same data. For example, simply
changing variable names can sway the size of prediction error by as much as 82%
in certain settings. Such prediction sensitivity with respect to
task-irrelevant variations manifests under both in-context learning and
supervised fine-tuning, for both close-weight and open-weight general-purpose
LLMs. Moreover, by examining the attention scores of an open-weight LLM, we
discover a non-uniform attention pattern: training examples and variable
names/values which happen to occupy certain positions in the prompt receive
more attention when output tokens are generated, even though different
positions are expected to receive roughly the same attention. This partially
explains the sensitivity in the presence of task-irrelevant variations. We also
consider a state-of-the-art tabular foundation model (TabPFN) trained
specifically for data fitting. Despite being explicitly designed to achieve
prediction robustness, TabPFN is still not immune to task-irrelevant
variations. Overall, despite LLMs' impressive predictive capabilities,
currently they lack even the basic level of robustness to be used as a
principled data-fitting tool.

</details>


### [197] [Bi-LoRA: Efficient Sharpness-Aware Minimization for Fine-Tuning Large-Scale Models](https://arxiv.org/abs/2508.19564)
*Yuhang Liu,Tao Li,Zhehao Huang,Zuopeng Yang,Xiaolin Huang*

Main category: cs.LG

TL;DR: 本文提出了一种称为Bi-LoRA的方法，通过引入辅助LoRA模块以实现内存高效且更广泛的优化，从而在有限数据情况下改进大规模预训练模型的微调。


<details>
  <summary>Details</summary>
Motivation: 针对现有以Sharpness-Aware Minimization (SAM)来提升泛化能力的方法，尽管有效但其高计算开销限制了其在大模型微调中的应用，同时直接将SAM应用于LoRA也因优化空间限制效果受阻。

Method: 提出Bi-LoRA，通过引入主LoRA模块和辅助LoRA模块，分别用梯度下降和上升优化特定任务适应性和损失景观的锐度优化，从而实现双向调优设计，同时显著降低存储需求和计算开销。

Result: 实验表明，Bi-LoRA在多种任务及架构上表现出更高效且有效的泛化能力改进。

Conclusion: Bi-LoRA以结构化的模块设计在优化泛化能力方面取得显著优势，同时克服了以往方法的成本限制，为大规模模型的高效微调提供了新的可能性。

Abstract: Fine-tuning large-scale pre-trained models with limited data presents
significant challenges for generalization. While Sharpness-Aware Minimization
(SAM) has proven effective in improving generalization by seeking flat minima,
its substantial extra memory and computation overhead make it impractical for
large models. Integrating SAM with parameter-efficient fine-tuning methods like
Low-Rank Adaptation (LoRA) is a promising direction. However, we find that
directly applying SAM to LoRA parameters limits the sharpness optimization to a
restricted subspace, hindering its effectiveness. To address this limitation,
we propose Bi-directional Low-Rank Adaptation (Bi-LoRA), which introduces an
auxiliary LoRA module to model SAM's adversarial weight perturbations. It
decouples SAM's weight perturbations from LoRA optimization: the primary LoRA
module adapts to specific tasks via standard gradient descent, while the
auxiliary module captures the sharpness of the loss landscape through gradient
ascent. Such dual-module design enables Bi-LoRA to capture broader sharpness
for achieving flatter minima while remaining memory-efficient. Another
important benefit is that the dual design allows for simultaneous optimization
and perturbation, eliminating SAM's doubled training costs. Extensive
experiments across diverse tasks and architectures demonstrate Bi-LoRA's
efficiency and effectiveness in enhancing generalization.

</details>


### [198] [Counterfactual Reward Model Training for Bias Mitigation in Multimodal Reinforcement Learning](https://arxiv.org/abs/2508.19567)
*Sheryl Mathew,N Harshit*

Main category: cs.LG

TL;DR: 本文提出了一种反事实奖励模型，通过因果推断和多模态表示学习为强化学习提供去偏鉴别能力，从而提高公平性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基于人类反馈的强化学习模型容易因数据集中的隐性偏差而导致奖励信号和策略优化的缺陷。需要开发一种能够主动消除偏差的机制。

Method: 引入反事实奖励模型，利用反事实信任评分（由四个模块构成）并结合因果推理和多模态学习进行奖励信号的优化。

Result: 在包含新闻偏差、多分类失衡等挑战的多模态新闻数据集中，用该方法实现了89.12%的假新闻检测准确率，优于基线模型，且减少了虚假相关性和不公平信号。

Conclusion: 此框架为基于人类反馈的强化学习提供了一种公平的解决方案，具有解读性和可调偏差阈值，适用于动态决策场景。

Abstract: In reinforcement learning with human feedback (RLHF), reward models can
efficiently learn and amplify latent biases within multimodal datasets, which
can lead to imperfect policy optimization through flawed reward signals and
decreased fairness. Bias mitigation studies have often applied passive
constraints, which can fail under causal confounding. Here, we present a
counterfactual reward model that introduces causal inference with multimodal
representation learning to provide an unsupervised, bias-resilient reward
signal. The heart of our contribution is the Counterfactual Trust Score, an
aggregated score consisting of four components: (1) counterfactual shifts that
decompose political framing bias from topical bias; (2) reconstruction
uncertainty during counterfactual perturbations; (3) demonstrable violations of
fairness rules for each protected attribute; and (4) temporal reward shifts
aligned with dynamic trust measures. We evaluated the framework on a multimodal
fake versus true news dataset, which exhibits framing bias, class imbalance,
and distributional drift. Following methodologies similar to unsupervised drift
detection from representation-based distances [1] and temporal robustness
benchmarking in language models [2], we also inject synthetic bias across
sequential batches to test robustness. The resulting system achieved an
accuracy of 89.12% in fake news detection, outperforming the baseline reward
models. More importantly, it reduced spurious correlations and unfair
reinforcement signals. This pipeline outlines a robust and interpretable
approach to fairness-aware RLHF, offering tunable bias reduction thresholds and
increasing reliability in dynamic real-time policy making.

</details>


### [199] [Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era](https://arxiv.org/abs/2508.19570)
*Dawei Li,Yue Huang,Ming Li,Tianyi Zhou,Xiangliang Zhang,Huan Liu*

Main category: cs.LG

TL;DR: 本教程介绍了生成式数据的基础和最新进展，以及其在数据挖掘中的实际应用。


<details>
  <summary>Details</summary>
Motivation: 解决数据稀缺、隐私和标注等问题，为数据挖掘提供可扩展的合成数据解决方案。

Method: 解释生成模型（如大语言模型、扩散模型和生成对抗网络）的关键方法和实践框架。

Result: 为与会者提供可操作的见解以利用生成式合成数据优化数据挖掘研究与实践。

Conclusion: 生成式数据是解决数据稀缺和隐私的重要工具，对数据挖掘具有革命性意义。

Abstract: Generative models such as Large Language Models, Diffusion Models, and
generative adversarial networks have recently revolutionized the creation of
synthetic data, offering scalable solutions to data scarcity, privacy, and
annotation challenges in data mining. This tutorial introduces the foundations
and latest advances in synthetic data generation, covers key methodologies and
practical frameworks, and discusses evaluation strategies and applications.
Attendees will gain actionable insights into leveraging generative synthetic
data to enhance data mining research and practice. More information can be
found on our website: https://syndata4dm.github.io/.

</details>


### [200] [Escaping Stability-Plasticity Dilemma in Online Continual Learning for Motion Forecasting via Synergetic Memory Rehearsal](https://arxiv.org/abs/2508.19571)
*Yunlong Lin,Chao Lu,Tongshuai Wu,Xiaocong Zhao,Guodong Du,Yanwei Sun,Zirui Li,Jianwei Gong*

Main category: cs.LG

TL;DR: 本文探讨了深度神经网络（DNN）在运动预测中存在的灾难性遗忘问题，并提出了一种新型的连续学习方法SyReM，显著减轻了遗忘问题且提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 尽管DNN在运动预测问题上取得了较高的准确率，但它们在接受新数据训练后容易遗忘之前学习的场景知识。本文试图解决这种稳定性与可塑性平衡的难题。

Method: 提出了一种称为Synergetic Memory Rehearsal (SyReM)的连续学习方法，该方法通过两个机制：一种不等式约束来稳定记忆表征；以及基于损失梯度余弦相似度筛选的记忆重放机制，提高学习新知识的能力。

Result: 实验表明，与传统非连续学习和现有的连续学习方法相比，SyReM显著减轻了过去场景的灾难性遗忘问题，同时在新场景中提升了运动预测的准确性。

Conclusion: SyReM在运动预测的连续学习中展现了优越性能，成功解决了稳定性与可塑性的两难困境，其实施代码已公开。

Abstract: Deep neural networks (DNN) have achieved remarkable success in motion
forecasting. However, most DNN-based methods suffer from catastrophic
forgetting and fail to maintain their performance in previously learned
scenarios after adapting to new data. Recent continual learning (CL) studies
aim to mitigate this phenomenon by enhancing memory stability of DNN, i.e., the
ability to retain learned knowledge. Yet, excessive emphasis on the memory
stability often impairs learning plasticity, i.e., the capacity of DNN to
acquire new information effectively. To address such stability-plasticity
dilemma, this study proposes a novel CL method, synergetic memory rehearsal
(SyReM), for DNN-based motion forecasting. SyReM maintains a compact memory
buffer to represent learned knowledge. To ensure memory stability, it employs
an inequality constraint that limits increments in the average loss over the
memory buffer. Synergistically, a selective memory rehearsal mechanism is
designed to enhance learning plasticity by selecting samples from the memory
buffer that are most similar to recently observed data. This selection is based
on an online-measured cosine similarity of loss gradients, ensuring targeted
memory rehearsal. Since replayed samples originate from learned scenarios, this
memory rehearsal mechanism avoids compromising memory stability. We validate
SyReM under an online CL paradigm where training samples from diverse scenarios
arrive as a one-pass stream. Experiments on 11 naturalistic driving datasets
from INTERACTION demonstrate that, compared to non-CL and CL baselines, SyReM
significantly mitigates catastrophic forgetting in past scenarios while
improving forecasting accuracy in new ones. The implementation is publicly
available at https://github.com/BIT-Jack/SyReM.

</details>


### [201] [Delta-Audit: Explaining What Changes When Models Change](https://arxiv.org/abs/2508.19589)
*Arshia Hemmat,Afsaneh Fatemi*

Main category: cs.LG

TL;DR: 本文提出了一个名为Δ-Attribution的模型不可知框架，通过比较每特征的属性归因来解释模型版本变化的原因，并在多个机器学习模型和数据集上进行验证。


<details>
  <summary>Details</summary>
Motivation: 当前模型更新后性能常发生变化，而变化的原因经常不透明，文章试图通过开发工具解释模型版本变化的具体细节和影响。

Method: 引入Δ-Attribution框架，通过差异化特征属性归因的方法解释模型更新的影响，并使用Δ-Attribution质量套件从多个维度评估其表现。

Result: 不同模型的归纳偏差变化会引起显著的行为对齐变化，而小修小补的模型改动则无显著影响。例如，SVC核函数变化或随机森林特征规则变动体现了较高的BAC和DCE，而小改动如SVC的gamma调整则无显著行为变化。

Conclusion: Δ-Attribution提供了一种轻量级的更新审核工具，可以通过区分微小调整与行为显著变化补充传统的模型准确性评估。

Abstract: Model updates (new hyperparameters, kernels, depths, solvers, or data) change
performance, but the \emph{reason} often remains opaque. We introduce
\textbf{Delta-Attribution} (\mbox{$\Delta$-Attribution}), a model-agnostic
framework that explains \emph{what changed} between versions $A$ and $B$ by
differencing per-feature attributions: $\Delta\phi(x)=\phi_B(x)-\phi_A(x)$. We
evaluate $\Delta\phi$ with a \emph{$\Delta$-Attribution Quality Suite} covering
magnitude/sparsity (L1, Top-$k$, entropy), agreement/shift (rank-overlap@10,
Jensen--Shannon divergence), behavioural alignment (Delta Conservation Error,
DCE; Behaviour--Attribution Coupling, BAC; CO$\Delta$F), and robustness (noise,
baseline sensitivity, grouped occlusion).
  Instantiated via fast occlusion/clamping in standardized space with a
class-anchored margin and baseline averaging, we audit 45 settings: five
classical families (Logistic Regression, SVC, Random Forests, Gradient
Boosting, $k$NN), three datasets (Breast Cancer, Wine, Digits), and three A/B
pairs per family. \textbf{Findings.} Inductive-bias changes yield large,
behaviour-aligned deltas (e.g., SVC poly$\!\rightarrow$rbf on Breast Cancer:
BAC$\approx$0.998, DCE$\approx$6.6; Random Forest feature-rule swap on Digits:
BAC$\approx$0.997, DCE$\approx$7.5), while ``cosmetic'' tweaks (SVC
\texttt{gamma=scale} vs.\ \texttt{auto}, $k$NN search) show
rank-overlap@10$=1.0$ and DCE$\approx$0. The largest redistribution appears for
deeper GB on Breast Cancer (JSD$\approx$0.357). $\Delta$-Attribution offers a
lightweight update audit that complements accuracy by distinguishing benign
changes from behaviourally meaningful or risky reliance shifts.

</details>


### [202] [Complementary Learning System Empowers Online Continual Learning of Vehicle Motion Forecasting in Smart Cities](https://arxiv.org/abs/2508.19597)
*Zirui Li,Yunlong Lin,Guodong Du,Xiaocong Zhao,Cheng Gong,Chen Lv,Chao Lu,Jianwei Gong*

Main category: cs.LG

TL;DR: 提出了一种名为Dual-LS的新型方法，用于解决深度神经网络在车辆运动预测中的灾难性遗忘问题，通过结合长短期记忆的机制，显著提升了预测性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法有效解决深度神经网络更新时的灾难性遗忘问题，且存在数据效率低和计算成本高的缺点，无法实现类似人类的持续学习。

Method: 提出Dual-LS方法，通过对人脑补充学习系统的仿生学习，结合两种记忆回放机制，协调长短期知识表示，以无任务、在线学习的方式应对灾难性遗忘。

Result: 在涵盖三个国家、772,000辆车、共11,187公里测试数据的实验中，Dual-LS在减少灾难性遗忘方面提高了74.31%，并减少计算资源需求达94.02%。

Conclusion: Dual-LS方法显著改善了车辆运动预测的稳定性和效率，实现了适合智慧城市的计算高效且类似人类的持续学习能力。

Abstract: Artificial intelligence underpins most smart city services, yet deep neural
network (DNN) that forecasts vehicle motion still struggle with catastrophic
forgetting, the loss of earlier knowledge when models are updated. Conventional
fixes enlarge the training set or replay past data, but these strategies incur
high data collection costs, sample inefficiently and fail to balance long- and
short-term experience, leaving them short of human-like continual learning.
Here we introduce Dual-LS, a task-free, online continual learning paradigm for
DNN-based motion forecasting that is inspired by the complementary learning
system of the human brain. Dual-LS pairs two synergistic memory rehearsal
replay mechanisms to accelerate experience retrieval while dynamically
coordinating long-term and short-term knowledge representations. Tests on
naturalistic data spanning three countries, over 772,000 vehicles and
cumulative testing mileage of 11,187 km show that Dual-LS mitigates
catastrophic forgetting by up to 74.31\% and reduces computational resource
demand by up to 94.02\%, markedly boosting predictive stability in vehicle
motion forecasting without inflating data requirements. Meanwhile, it endows
DNN-based vehicle motion forecasting with computation efficient and human-like
continual learning adaptability fit for smart cities.

</details>


### [203] [Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning](https://arxiv.org/abs/2508.19598)
*Zhiwei Li,Yong Hu,Wenqing Wang*

Main category: cs.LG

TL;DR: 本文提出了一种新的训练方法RLTR，主要通过工具使用奖励信号来优化大型语言模型的规划能力，从而提升其整体性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的训练面临多目标优化分配不平衡和缺乏可验证数据的问题，难以有效提升模型的规划能力。

Method: 提出RLTR框架，通过工具使用的完整性作为奖励信号，专注于单一目标优化模型的规划模块，而非传统的端到端多目标训练。

Result: 实验显示，RLTR在规划性能上比端到端基线提高了8%-12%，同时也让最终响应质量提升了5%-6%。

Conclusion: RLTR通过引入直接、可靠的训练信号，有效提高了语言模型的规划能力及整体表现，为相关模型训练开辟了新路径。

Abstract: The functionality of Large Language Model (LLM) agents is primarily
determined by two capabilities: action planning and answer summarization. The
former, action planning, is the core capability that dictates an agent's
performance. However, prevailing training paradigms employ end-to-end,
multi-objective optimization that jointly trains both capabilities. This
paradigm faces two critical challenges: imbalanced optimization objective
allocation and scarcity of verifiable data, making it difficult to enhance the
agent's planning capability. To address these challenges, we propose
Reinforcement Learning with Tool-use Rewards (RLTR), a novel framework that
decouples the training process to enable a focused, single-objective
optimization of the planning module. Crucially, RLTR introduces a reward signal
based on tool-use completeness to directly evaluate the quality of tool
invocation sequences. This method offers a more direct and reliable training
signal than assessing the final response content, thereby obviating the need
for verifiable data. Our experiments demonstrate that RLTR achieves an 8%-12%
improvement in planning performance compared to end-to-end baselines. Moreover,
this enhanced planning capability, in turn, translates to a 5%-6% increase in
the final response quality of the overall agent system.

</details>


### [204] [FinCast: A Foundation Model for Financial Time-Series Forecasting](https://arxiv.org/abs/2508.19609)
*Zhuohang Zhu,Haodong Chen,Qiang Qu,Vera Chung*

Main category: cs.LG

TL;DR: 本文提出了一个名为FinCast的基础模型，专为金融时间序列预测设计，无需领域特定的微调即可实现优秀的预测性能。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列预测对经济稳定、政策制定和可持续投资至关重要，但由于时间非平稳性、多领域多样性及时间分辨率的差异性，预测具有挑战性。

Method: 引入FinCast，这是第一个针对金融时间序列预测的大规模基础模型，以大型金融数据集训练，无需领域特定的微调。

Result: FinCast 在零样本预测任务中表现突出，展现了对不同模式的强大泛化能力，优于现有的先进方法。

Conclusion: FinCast 有潜力成为金融时间序列预测中的里程碑，克服了传统方法的主要局限性。

Abstract: Financial time-series forecasting is critical for maintaining economic
stability, guiding informed policymaking, and promoting sustainable investment
practices. However, it remains challenging due to various underlying pattern
shifts. These shifts arise primarily from three sources: temporal
non-stationarity (distribution changes over time), multi-domain diversity
(distinct patterns across financial domains such as stocks, commodities, and
futures), and varying temporal resolutions (patterns differing across
per-second, hourly, daily, or weekly indicators). While recent deep learning
methods attempt to address these complexities, they frequently suffer from
overfitting and typically require extensive domain-specific fine-tuning. To
overcome these limitations, we introduce FinCast, the first foundation model
specifically designed for financial time-series forecasting, trained on
large-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot
performance, effectively capturing diverse patterns without domain-specific
fine-tuning. Comprehensive empirical and qualitative evaluations demonstrate
that FinCast surpasses existing state-of-the-art methods, highlighting its
strong generalization capabilities.

</details>


### [205] [ALSA: Anchors in Logit Space for Out-of-Distribution Accuracy Estimation](https://arxiv.org/abs/2508.19613)
*Chenzhi Liu,Mahsa Baktashmotlagh,Yanran Tang,Zi Huang,Ruihong Qiu*

Main category: cs.LG

TL;DR: 本研究提出了一种名为ALSA的新框架，通过在logit空间中操作，解决了预测模型在未标记数据集上的准确性估计问题，并在实践中展现出优异性能。


<details>
  <summary>Details</summary>
Motivation: 在机器学习实际应用中，特别是在分布偏移导致性能下降的情况下，需要估计模型在未标记数据集上的准确性，而现有方法存在信息损失或计算复杂性高的问题。

Method: 提出ALSA框架，通过在logit空间中使用锚点建模策略，每个锚点都有一个影响函数，以捕获logit的细微变化，从而提供准确的性能估计。

Result: 通过视觉、语言和图数据集基准上的实验，证明了ALSA在准确性和鲁棒性方面优于基于softmax和相似性的方法，特别是在显著分布偏移下表现尤为出色。

Conclusion: ALSA框架通过保留更多logit信息，以实际应用为背景，为可靠的模型性能评估提供了强大的工具，显示了其在分布偏移条件下的潜力。

Abstract: Estimating model accuracy on unseen, unlabeled datasets is crucial for
real-world machine learning applications, especially under distribution shifts
that can degrade performance. Existing methods often rely on predicted class
probabilities (softmax scores) or data similarity metrics. While softmax-based
approaches benefit from representing predictions on the standard simplex,
compressing logits into probabilities leads to information loss. Meanwhile,
similarity-based methods can be computationally expensive and domain-specific,
limiting their broader applicability. In this paper, we introduce ALSA (Anchors
in Logit Space for Accuracy estimation), a novel framework that preserves
richer information by operating directly in the logit space. Building on
theoretical insights and empirical observations, we demonstrate that the
aggregation and distribution of logits exhibit a strong correlation with the
predictive performance of the model. To exploit this property, ALSA employs an
anchor-based modeling strategy: multiple learnable anchors are initialized in
logit space, each assigned an influence function that captures subtle
variations in the logits. This allows ALSA to provide robust and accurate
performance estimates across a wide range of distribution shifts. Extensive
experiments on vision, language, and graph benchmarks demonstrate ALSA's
superiority over both softmax- and similarity-based baselines. Notably, ALSA's
robustness under significant distribution shifts highlights its potential as a
practical tool for reliable model evaluation.

</details>


### [206] [Towards Instance-wise Personalized Federated Learning via Semi-Implicit Bayesian Prompt Tuning](https://arxiv.org/abs/2508.19621)
*Tiandi Ye,Wenyan Liu,Kai Yao,Lichun Li,Shangchao Su,Cen Chen,Xiang Li,Shan Yin,Ming Gao*

Main category: cs.LG

TL;DR: 提出pFedBayesPT，一种基于视觉提示调优的个性化联邦学习方法，解决了现有方法在单一分布假设下表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 当前个性化联邦学习方法假设客户端数据为单一分布，无法应对单一客户端中跨源或跨领域数据的异质性。

Method: 提出pFedBayesPT框架，使用贝叶斯视角生成实例级提示，并通过半隐式变分推理框架得出变分训练目标，从而捕获多样化视觉语义。

Result: 在基准数据集上，pFedBayesPT在特征和标签异质性情境下的表现均优于现有个性化联邦学习方法。

Conclusion: pFedBayesPT能够更有效地应对客户端内部的异质性数据，且在各类异质性条件下均有卓越表现。

Abstract: Federated learning (FL) is a privacy-preserving machine learning paradigm
that enables collaborative model training across multiple distributed clients
without disclosing their raw data. Personalized federated learning (pFL) has
gained increasing attention for its ability to address data heterogeneity.
However, most existing pFL methods assume that each client's data follows a
single distribution and learn one client-level personalized model for each
client. This assumption often fails in practice, where a single client may
possess data from multiple sources or domains, resulting in significant
intra-client heterogeneity and suboptimal performance. To tackle this
challenge, we propose pFedBayesPT, a fine-grained instance-wise pFL framework
based on visual prompt tuning. Specifically, we formulate instance-wise prompt
generation from a Bayesian perspective and model the prompt posterior as an
implicit distribution to capture diverse visual semantics. We derive a
variational training objective under the semi-implicit variational inference
framework. Extensive experiments on benchmark datasets demonstrate that
pFedBayesPT consistently outperforms existing pFL methods under both feature
and label heterogeneity settings.

</details>


### [207] [SCAR: A Characterization Scheme for Multi-Modal Dataset](https://arxiv.org/abs/2508.19659)
*Ri Su,Zhao Chen,Caleb Chen Cao,Nan Tang,Lei Chen*

Main category: cs.LG

TL;DR: 提出了一个新的方案SCAR来分析数据集的内在结构特性，并通过多项实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统方法过于关注数据数量和训练效率，忽略了数据结构质量，本研究旨在提供更深入的理论和实践框架。

Method: 引入SCAR框架，定义数据集的Scale、Coverage、Authenticity、Richness四大特性，并提出Foundation Data和SCAR引导的扩展策略。

Result: 实验验证了SCAR在预测数据效用和指导数据获取方面的有效性，其代码已开源。

Conclusion: SCAR为数据理解提供了稳健的基础，并为多模态数据集的优化提供了一条新路径。

Abstract: Foundation models exhibit remarkable generalization across diverse tasks,
largely driven by the characteristics of their training data. Recent
data-centric methods like pruning and compression aim to optimize training but
offer limited theoretical insight into how data properties affect
generalization, especially the data characteristics in sample scaling.
Traditional perspectives further constrain progress by focusing predominantly
on data quantity and training efficiency, often overlooking structural aspects
of data quality. In this study, we introduce SCAR, a principled scheme for
characterizing the intrinsic structural properties of datasets across four key
measures: Scale, Coverage, Authenticity, and Richness. Unlike prior
data-centric measures, SCAR captures stable characteristics that remain
invariant under dataset scaling, providing a robust and general foundation for
data understanding. Leveraging these structural properties, we introduce
Foundation Data-a minimal subset that preserves the generalization behavior of
the full dataset without requiring model-specific retraining. We model
single-modality tasks as step functions and estimate the distribution of the
foundation data size to capture step-wise generalization bias across modalities
in the target multi-modal dataset. Finally, we develop a SCAR-guided data
completion strategy based on this generalization bias, which enables efficient,
modality-aware expansion of modality-specific characteristics in multimodal
datasets. Experiments across diverse multi-modal datasets and model
architectures validate the effectiveness of SCAR in predicting data utility and
guiding data acquisition. Code is available at https://github.com/McAloma/SCAR.

</details>


### [208] [Exploration of Low-Power Flexible Stress Monitoring Classifiers for Conformal Wearables](https://arxiv.org/abs/2508.19661)
*Florentia Afentaki,Sri Sai Rakesh Nakkilla,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Shiyi Jiang,Georgios Zervakis,Farshad Firouzi,Krishnendu Chakrabarty,Mehdi B. Tahoori*

Main category: cs.LG

TL;DR: 本文探讨柔性电子(FE)在压力监测中的潜力，提出了低功耗柔性压力分类器的设计空间探索，以实现实时、准确、低成本的压力检测。


<details>
  <summary>Details</summary>
Motivation: 传统压力监测方法间歇且成本高，现有硅基可穿戴设备虽功能多，但因刚性设计限制连续监测的实用性，急需轻便、灵活、低成本的解决方案。

Method: 研究柔性电子内的低功耗压力分类器设计，通过1200余种灵活分类器测试，结合机器学习分类、特征选择和神经网络简化等算法，优化硬件效率并实现低精度算术电路。

Result: 成功设计出高精度、低成本、低功耗且紧凑的压力分类器，相较现有方法精度更高，适用于实时监测。

Conclusion: 本研究为柔性电子领域的压力分类器设计提供了综合方法和新见解，为开发高效轻便的实时压力监测设备奠定了基础。

Abstract: Conventional stress monitoring relies on episodic, symptom-focused
interventions, missing the need for continuous, accessible, and cost-efficient
solutions. State-of-the-art approaches use rigid, silicon-based wearables,
which, though capable of multitasking, are not optimized for lightweight,
flexible wear, limiting their practicality for continuous monitoring. In
contrast, flexible electronics (FE) offer flexibility and low manufacturing
costs, enabling real-time stress monitoring circuits. However, implementing
complex circuits like machine learning (ML) classifiers in FE is challenging
due to integration and power constraints. Previous research has explored
flexible biosensors and ADCs, but classifier design for stress detection
remains underexplored. This work presents the first comprehensive design space
exploration of low-power, flexible stress classifiers. We cover various ML
classifiers, feature selection, and neural simplification algorithms, with over
1200 flexible classifiers. To optimize hardware efficiency, fully customized
circuits with low-precision arithmetic are designed in each case. Our
exploration provides insights into designing real-time stress classifiers that
offer higher accuracy than current methods, while being low-cost, conformable,
and ensuring low power and compact size.

</details>


### [209] [$\mathcal{C}^1$-approximation with rational functions and rational neural networks](https://arxiv.org/abs/2508.19672)
*Erion Morina,Martin Holler*

Main category: cs.LG

TL;DR: 研究表明，具有特定规则的函数可以在$C^1$范数下通过有理函数和有理神经网络近似。


<details>
  <summary>Details</summary>
Motivation: 研究者希望探索在$C^1$范数下函数的逼近性，尤其是利用有理神经网络于符号回归中的物理法则学习。

Method: 分析了有理函数和神经网络对函数的$C^1$近似，包括网络的宽度、深度及有理函数阶数对近似率的影响。

Result: 证明了可以在$C^1$范数下逼近特定函数，并对$C^1$近似结果应用到特定神经网络架构如$	ext{EQL}^div$和ParFam。

Conclusion: 研究实现了在符号回归应用中，通过这些方法高效地近似规则函数。

Abstract: We show that suitably regular functions can be approximated in the
$\mathcal{C}^1$-norm both with rational functions and rational neural networks,
including approximation rates with respect to width and depth of the network,
and degree of the rational functions. As consequence of our results, we further
obtain $\mathcal{C}^1$-approximation results for rational neural networks with
the $\text{EQL}^\div$ and ParFam architecture, both of which are important in
particular in the context of symbolic regression for physical law learning.

</details>


### [210] [Metric spaces of walks and Lipschitz duality on graphs](https://arxiv.org/abs/2508.19709)
*R. Arnau,A. González Cortés,E. A. Sánchez Pérez,S. Sanjuan*

Main category: cs.LG

TL;DR: 论文探讨了图上行走的度量结构，通过引入加权度量来定义行走之间的距离，并分析了该度量空间的主要性质。


<details>
  <summary>Details</summary>
Motivation: 研究图上行走的度量和相对距离，以建立可推广的度量模型，并为图上近似函数的扩展提供基础。

Method: 通过构建基于逐步顶点距离和加权范数的加权度量，定义行走间的距离，并分析该度量空间性质，同时提出一种扩展Lipschitz函数的方法。

Result: 作者提出了一种度量框架，用于图上行走间的相对距离测量以及通过表示公式和近似公式来进行图结构上的Lipschitz回归等应用。

Conclusion: 研究的度量框架为探索性行走中的强化学习策略设计提供了新思路，同时拓展了在图上进行近似和分析的工具。

Abstract: We study the metric structure of walks on graphs, understood as Lipschitz
sequences. To this end, a weighted metric is introduced to handle sequences,
enabling the definition of distances between walks based on stepwise vertex
distances and weighted norms. We analyze the main properties of these metric
spaces, which provides the foundation for the analysis of weaker forms of
instruments to measure relative distances between walks: proximities. We
provide some representation formulas for such proximities under different
assumptions and provide explicit constructions for these cases. The resulting
metric framework allows the use of classical tools from metric modeling, such
as the extension of Lipschitz functions from subspaces of walks, which permits
extending proximity functions while preserving fundamental properties via the
mentioned representations. Potential applications include the estimation of
proximities and the development of reinforcement learning strategies based on
exploratory walks, offering a robust approach to Lipschitz regression on
network structures.

</details>


### [211] [Tune My Adam, Please!](https://arxiv.org/abs/2508.19733)
*Theodoros Athanasiadis,Steven Adriaensen,Samuel Müller,Frank Hutter*

Main category: cs.LG

TL;DR: 该论文提出了Adam-PFN，一种用于Adam优化器的冻结-解冻贝叶斯优化(Freeze-thaw Bayesian Optimization)的新模型，通过预训练和数据增强方法实现对超参数调优性能的提升。


<details>
  <summary>Details</summary>
Motivation: 目前Adam优化器的超参数调优过程复杂且成本高，而现有的冻结-解冻贝叶斯优化受到缺乏对超参数影响学习的先验知识的限制。

Method: 提出Adam-PFN作为冻结-解冻贝叶斯优化的新的替代模型，并结合使用了CDF-augment数据增强方法来扩充训练样本数量。

Result: 实验结果表明，该方法在学习曲线外推和超参数优化加速方面效果显著，并且在分布外任务中表现良好。

Conclusion: Adam-PFN显著改善了Adam优化器超参数调优的效率和性能，尤其是在低预算和分布外任务中的表现。

Abstract: The Adam optimizer remains one of the most widely used optimizers in deep
learning, and effectively tuning its hyperparameters is key to optimizing
performance. However, tuning can be tedious and costly. Freeze-thaw Bayesian
Optimization (BO) is a recent promising approach for low-budget hyperparameter
tuning, but is limited by generic surrogates without prior knowledge of how
hyperparameters affect learning. We propose Adam-PFN, a new surrogate model for
Freeze-thaw BO of Adam's hyperparameters, pre-trained on learning curves from
TaskSet, together with a new learning curve augmentation method, CDF-augment,
which artificially increases the number of available training examples. Our
approach improves both learning curve extrapolation and accelerates
hyperparameter optimization on TaskSet evaluation tasks, with strong
performance on out-of-distribution (OOD) tasks.

</details>


### [212] [InfraredGP: Efficient Graph Partitioning via Spectral Graph Neural Networks with Negative Corrections](https://arxiv.org/abs/2508.19737)
*Meng Qin,Weihua Li,Jinqiang Cui,Sen Pei*

Main category: cs.LG

TL;DR: 提出了一种无需训练即可执行图划分的新方法InfraredGP，利用负校正机制和低频信息来生成区分性图嵌入，并通过BIRCH实现高效的图划分。


<details>
  <summary>Details</summary>
Motivation: 传统图划分方法在捕获密集连通块的属性上存在局限性，本文尝试从图信号处理的角度探索图拉普拉斯频率范围扩展带来的潜在信息增益。

Method: 采用一种结合低通滤波器和负校正机制的谱图神经网络（Spectral GNN），以随机输入进行一次前向传播生成图嵌入，并通过BIRCH实现图划分，无需额外训练。

Result: 在IEEE HPEC Graph Challenge中，InfraredGP在静态和流式GP任务上表现出显著的效率提升（16x-23x）以及对比基线方法的竞争性划分质量。

Conclusion: 利用负校正机制放大[0, 2]之外的低频信息，能够在无需训练的情况下实现高效高质量的图划分，且方法具有良好的实用性和可复制性。

Abstract: Graph partitioning (GP), a.k.a. community detection, is a classic problem
that divides nodes of a graph into densely-connected blocks. From a perspective
of graph signal processing, we find that graph Laplacian with a negative
correction can derive graph frequencies beyond the conventional range $[0, 2]$.
To explore whether the low-frequency information beyond this range can encode
more informative properties about community structures, we propose InfraredGP.
It (\romannumeral1) adopts a spectral GNN as its backbone combined with
low-pass filters and a negative correction mechanism, (\romannumeral2) only
feeds random inputs to this backbone, (\romannumeral3) derives graph embeddings
via one feed-forward propagation (FFP) without any training, and
(\romannumeral4) obtains feasible GP results by feeding the derived embeddings
to BIRCH. Surprisingly, our experiments demonstrate that based solely on the
negative correction mechanism that amplifies low-frequency information beyond
$[0, 2]$, InfraredGP can derive distinguishable embeddings for some standard
clustering modules (e.g., BIRCH) and obtain high-quality results for GP without
any training. Following the IEEE HPEC Graph Challenge benchmark, we evaluate
InfraredGP for both static and streaming GP, where InfraredGP can achieve much
better efficiency (e.g., 16x-23x faster) and competitive quality over various
baselines. We have made our code public at
https://github.com/KuroginQin/InfraredGP

</details>


### [213] [Fast 3D Diffusion for Scalable Granular Media Synthesis](https://arxiv.org/abs/2508.19752)
*Muhammad Moeeze Hassan,Régis Cottereau,Filippo Gatti,Patryk Dec*

Main category: cs.LG

TL;DR: 该论文提出了一种基于3D扩散模型的生成式方法，能够快速生成任意大且物理逼真的颗粒介质。


<details>
  <summary>Details</summary>
Motivation: 通过对颗粒介质的离散元模拟，其初始化阶段计算量大，需要优化高效的生成方法。

Method: 设计了一个两阶段的生成管道：第一阶段用扩散模型生成独立的3D体素网格表示颗粒介质；第二阶段利用改进的3D修补模型无缝拼接这些网格，并采用多种遮罩策略和加权损失确保生成一致性。

Result: 该方法能以线性计算时间生成大规模颗粒模型，实验中1.2米铁轨模拟完成仅需20秒，相比于传统方法（离散元模拟3小时）大幅加速。

Conclusion: 新方法能够实时、可扩展地生成物理一致的颗粒模型，适用于工业应用。

Abstract: Simulating granular media, using Discrete Element Method is a computationally
intensive task. This is especially true during initialization phase, which
dominates total simulation time because of large displacements involved and
associated kinetic energy. We overcome this bottleneck with a novel generative
pipeline based on 3D diffusion models that directly synthesizes arbitrarily
large granular assemblies in their final and physically realistic
configurations. The approach frames the problem as a 3D generative modeling
task, consisting of a two-stage pipeline. First a diffusion model is trained to
generate independent 3D voxel grids representing granular media. Second, a 3D
inpainting model, adapted from 2D inpainting techniques using masked inputs,
stitches these grids together seamlessly, enabling synthesis of large samples
with physically realistic structure. The inpainting model explores several
masking strategies for the inputs to the underlying UNets by training the
network to infer missing portions of voxel grids from a concatenation of noised
tensors, masks, and masked tensors as input channels. The model also adapts a
2D repainting technique of re-injecting noise scheduler output with ground
truth to provide a strong guidance to the 3D model. This along with weighted
losses ensures long-term coherence over generation of masked regions. Both
models are trained on the same binarized 3D occupancy grids extracted from
small-scale DEM simulations, achieving linear scaling of computational time
with respect to sample size. Quantitatively, a 1.2 m long ballasted rail track
synthesis equivalent to a 3-hour DEM simulation, was completed under 20
seconds. The generated voxel grids can also be post-processed to extract grain
geometries for DEM-compatibility as well, enabling physically coherent,
real-time, scalable granular media synthesis for industrial applications.

</details>


### [214] [Interestingness First Classifiers](https://arxiv.org/abs/2508.19780)
*Ryoma Sato*

Main category: cs.LG

TL;DR: 本文引入了一种名为EUREKA的框架，旨在构建更有趣的分类器，而非单纯追求预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习模型普遍追求最大化预测准确性，但在某些场景中，探索有趣性和非直观特性可能更有价值。

Method: EUREKA使用大语言模型评估特征的有趣性，仅选择有趣的特征构建可解释的分类器。

Result: 框架在多个数据集测试中表现良好，能发现不直观但仍具预测力的特征，如湿度用于房间拥挤检测等。

Conclusion: 该方法适合于中等准确性已足够且对新颖性和可解释性有需求的场景，有助于知识发现和交流。

Abstract: Most machine learning models are designed to maximize predictive accuracy. In
this work, we explore a different goal: building classifiers that are
interesting. An ``interesting classifier'' is one that uses unusual or
unexpected features, even if its accuracy is lower than the best possible
model. For example, predicting room congestion from CO2 levels achieves
near-perfect accuracy but is unsurprising. In contrast, predicting room
congestion from humidity is less accurate yet more nuanced and intriguing. We
introduce EUREKA, a simple framework that selects features according to their
perceived interestingness. Our method leverages large language models to rank
features by their interestingness and then builds interpretable classifiers
using only the selected interesting features. Across several benchmark
datasets, EUREKA consistently identifies features that are non-obvious yet
still predictive. For example, in the Occupancy Detection dataset, our method
favors humidity over CO2 levels and light intensity, producing classifiers that
achieve meaningful accuracy while offering insights. In the Twin Papers
dataset, our method discovers the rule that papers with a colon in the title
are more likely to be cited in the future. We argue that such models can
support new ways of knowledge discovery and communication, especially in
settings where moderate accuracy is sufficient but novelty and interpretability
are valued.

</details>


### [215] [PSO-Merging: Merging Models Based on Particle Swarm Optimization](https://arxiv.org/abs/2508.19839)
*Kehao Zhang,Shaolei Zhang,Yang Feng*

Main category: cs.LG

TL;DR: 提出了一种基于粒子群优化的模型合并方法PSO-Merging，用于提高现有多任务模型的融合效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的无数据方法和基于数据的方法在性能或计算效率上存在局限性，因此需要一个既高效又性能优异的模型合并方法。

Method: 利用粒子群优化算法，初始化时采用预训练模型、专家模型和专家模型的稀疏版本，通过多次迭代，最终得到表现最优的合并模型。

Result: 实验表明，PSO-Merging在多种语言模型上的表现优于现有的基线合并方法。

Conclusion: PSO-Merging提供了一种更加高效且可扩展的模型合并解决方案。

Abstract: Model merging has emerged as an efficient strategy for constructing multitask
models by integrating the strengths of multiple available expert models,
thereby reducing the need to fine-tune a pre-trained model for all the tasks
from scratch. Existing data-independent methods struggle with performance
limitations due to the lack of data-driven guidance. Data-driven approaches
also face key challenges: gradient-based methods are computationally expensive,
limiting their practicality for merging large expert models, whereas existing
gradient-free methods often fail to achieve satisfactory results within a
limited number of optimization steps. To address these limitations, this paper
introduces PSO-Merging, a novel data-driven merging method based on the
Particle Swarm Optimization (PSO). In this approach, we initialize the particle
swarm with a pre-trained model, expert models, and sparsified expert models. We
then perform multiple iterations, with the final global best particle serving
as the merged model. Experimental results on different language models show
that PSO-Merging generally outperforms baseline merging methods, offering a
more efficient and scalable solution for model merging.

</details>


### [216] [Symplectic convolutional neural networks](https://arxiv.org/abs/2508.19842)
*Süleyman Yıldız,Konrad Janik,Peter Benner*

Main category: cs.LG

TL;DR: 提出了一种新的辛卷积神经网络架构，使用辛神经网络和张量技术。


<details>
  <summary>Details</summary>
Motivation: 解决现有神经网络架构中如何保持辛结构的问题。

Method: 通过重新定义卷积层，并引入辛池化层，确保整个网络保持辛性质。

Result: 在波方程、非线性薛定谔方程和正弦-戈登方程上验证，表现优于线性辛自编码器。

Conclusion: 该辛卷积网络在特定问题上表现突出，与传统方法相比具有明显优势。

Abstract: We propose a new symplectic convolutional neural network (CNN) architecture
by leveraging symplectic neural networks, proper symplectic decomposition, and
tensor techniques. Specifically, we first introduce a mathematically equivalent
form of the convolution layer and then, using symplectic neural networks, we
demonstrate a way to parameterize the layers of the CNN to ensure that the
convolution layer remains symplectic. To construct a complete autoencoder, we
introduce a symplectic pooling layer. We demonstrate the performance of the
proposed neural network on three examples: the wave equation, the nonlinear
Schr\"odinger (NLS) equation, and the sine-Gordon equation. The numerical
results indicate that the symplectic CNN outperforms the linear symplectic
autoencoder obtained via proper symplectic decomposition.

</details>


### [217] [Physics-Informed DeepONet Coupled with FEM for Convective Transport in Porous Media with Sharp Gaussian Sources](https://arxiv.org/abs/2508.19847)
*Erdi Kara,Panos Stinis*

Main category: cs.LG

TL;DR: 本文提出一种结合有限元法（FEM）和物理驱动型DeepONet的混合框架，用于从局部高斯源模建多孔介质中的流体传输，既保持高精度又显著提升计算速度。


<details>
  <summary>Details</summary>
Motivation: 传统的数值方法在处理复杂的流体传输问题时不仅计算耗时，且难以高效解决高梯度问题，作者旨在开发一种高效且准确的替代方案。

Method: 提出一种将有限元法（FEM）解决达西系统，通过物理驱动型DeepONet学习源函数向物质浓度剖面的映射，同时采用自适应采样策略应对高梯度。

Result: 实验表明该方法能很好地与参考解对齐，同时在计算速度上比传统求解器提供数量级的改进。

Conclusion: 该框架不仅能保留FEM的精度，还显著加速传输动力学问题的推断，适合相关领域实际应用。

Abstract: We present a hybrid framework that couples finite element methods (FEM) with
physics-informed DeepONet to model fluid transport in porous media from sharp,
localized Gaussian sources. The governing system consists of a steady-state
Darcy flow equation and a time-dependent convection-diffusion equation. Our
approach solves the Darcy system using FEM and transfers the resulting velocity
field to a physics-informed DeepONet, which learns the mapping from source
functions to solute concentration profiles. This modular strategy preserves
FEM-level accuracy in the flow field while enabling fast inference for
transport dynamics. To handle steep gradients induced by sharp sources, we
introduce an adaptive sampling strategy for trunk collocation points. Numerical
experiments demonstrate that our method is in good agreement with the reference
solutions while offering orders of magnitude speedups over traditional solvers,
making it suitable for practical applications in relevant scenarios.
Implementation of our proposed method is available at
https://github.com/erkara/fem-pi-deeponet.

</details>


### [218] [Quantum latent distributions in deep generative models](https://arxiv.org/abs/2508.19857)
*Omar Bacarreza,Thorin Farnsworth,Alexander Makarovskiy,Hugo Wallner,Tessa Hicks,Santiago Sempere-Llagostera,John Price,Robert J. A. Francis-Jones,William R. Clements*

Main category: cs.LG

TL;DR: 本文研究了量子处理器生成的潜在分布能否改进生成模型性能以及其可重复性，并证明了在特定条件下量子潜在分布可超过经典潜在分布，并通过实验验证了这一点。


<details>
  <summary>Details</summary>
Motivation: 探讨量子处理器生成的潜在分布在生成模型性能改进中的作用及其潜在优势，解决其性能改进及可重复性等未解之问题。

Method: 理论上证明量子潜在分布可以通过生成模型实现经典分布无法高效生成的数据分布，并通过合成量子数据集和实际量子处理器对不同生成模型进行实验验证。

Result: 实验结果显示，相较于多种经典基线，GAN中使用的量子潜在分布能显著提高生成性能，同时探索量子潜在分布兼容的扩散及流匹配模型架构。

Conclusion: 量子处理器生成的量子潜在分布可扩展深度生成模型的能力，特别是在近场量子处理器的使用背景下。

Abstract: Many successful families of generative models leverage a low-dimensional
latent distribution that is mapped to a data distribution. Though simple latent
distributions are commonly used, it has been shown that more sophisticated
distributions can improve performance. For instance, recent work has explored
using the distributions produced by quantum processors and found empirical
improvements. However, when latent space distributions produced by quantum
processors can be expected to improve performance, and whether these
improvements are reproducible, are open questions that we investigate in this
work. We prove that, under certain conditions, these "quantum latent
distributions" enable generative models to produce data distributions that
classical latent distributions cannot efficiently produce. We also provide
actionable intuitions to identify when such quantum advantages may arise in
real-world settings. We perform benchmarking experiments on both a synthetic
quantum dataset and the QM9 molecular dataset, using both simulated and real
photonic quantum processors. Our results demonstrate that quantum latent
distributions can lead to improved generative performance in GANs compared to a
range of classical baselines. We also explore diffusion and flow matching
models, identifying architectures compatible with quantum latent distributions.
This work confirms that near-term quantum processors can expand the
capabilities of deep generative models.

</details>


### [219] [Parameter-Free Structural-Diversity Message Passing for Graph Neural Networks](https://arxiv.org/abs/2508.19884)
*Mingyue Kong,Yinglong Zhang,Chengda Xu,Xuewen Xia,Xing Xu*

Main category: cs.LG

TL;DR: 提出一种名为SDGNN的无参数图神经网络，能有效解决结构异质性和复杂特征分布问题。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络依赖大量参数和固定聚合规则，难以适应高度异构结构和复杂特征分布。

Method: 基于结构多样性理论，设计无参数的结构多样性消息传递机制，同时从结构驱动和特征驱动两方面建模。

Result: 在八个公开数据集和一个跨学科引用网络上，SDGNN在低监督、类别不平衡和跨域迁移等条件下表现优于主流GNN。

Conclusion: 验证了结构多样性作为图表征学习核心信号的重要性，并为无参数图神经网络提供了新理论视角和通用设计方法。

Abstract: Graph Neural Networks (GNNs) have shown remarkable performance in structured
data modeling tasks such as node classification. However, mainstream approaches
generally rely on a large number of trainable parameters and fixed aggregation
rules, making it difficult to adapt to graph data with strong structural
heterogeneity and complex feature distributions. This often leads to
over-smoothing of node representations and semantic degradation. To address
these issues, this paper proposes a parameter-free graph neural network
framework based on structural diversity, namely SDGNN (Structural-Diversity
Graph Neural Network). The framework is inspired by structural diversity theory
and designs a unified structural-diversity message passing mechanism that
simultaneously captures the heterogeneity of neighborhood structures and the
stability of feature semantics, without introducing additional trainable
parameters. Unlike traditional parameterized methods, SDGNN does not rely on
complex model training, but instead leverages complementary modeling from both
structure-driven and feature-driven perspectives, thereby effectively improving
adaptability across datasets and scenarios. Experimental results show that on
eight public benchmark datasets and an interdisciplinary PubMed citation
network, SDGNN consistently outperforms mainstream GNNs under challenging
conditions such as low supervision, class imbalance, and cross-domain transfer.
This work provides a new theoretical perspective and general approach for the
design of parameter-free graph neural networks, and further validates the
importance of structural diversity as a core signal in graph representation
learning. To facilitate reproducibility and further research, the full
implementation of SDGNN has been released at:
https://github.com/mingyue15694/SGDNN/tree/main

</details>


### [220] [NM-Hebb: Coupling Local Hebbian Plasticity with Metric Learning for More Accurate and Interpretable CNNs](https://arxiv.org/abs/2508.19896)
*Davorin Miličević,Ratko Grbić*

Main category: cs.LG

TL;DR: NM-Hebb是一种结合生物灵感机制和度量学习的双阶段训练框架，用于CNN，显著提高了准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度卷积神经网络易过拟合，产生冗余滤波器，且可解释性较低，因此需要改进方法平衡准确性和可解释性。

Method: 提出了NM-Hebb框架，第一阶段加入Hebbian正则化和可学习的神经调节机制以优化层次特征；第二阶段通过度量学习压缩类内距离并扩大类间间距以优化表示空间。

Result: 在CIFAR-10、CIFAR-100和TinyImageNet数据集上，NM-Hebb在多个骨干网络上取得了显著的准确率提升（最高提高10.0个百分点），并改善了特征聚类紧密性和互信息分数（NMI提升高达0.15）。

Conclusion: NM-Hebb显著提高了CNN模型的性能和可解释性，适用于资源受限和安全性要求高的场景，如AI部署领域。

Abstract: Deep Convolutional Neural Networks (CNNs) achieve high accuracy but often
rely on purely global, gradient-based optimisation, which can lead to
overfitting, redundant filters, and reduced interpretability. To address these
limitations, we propose NM-Hebb, a two-phase training framework that integrates
neuro-inspired local plasticity with distance-aware supervision. Phase 1
extends standard supervised training by jointly optimising a cross-entropy
objective with two biologically inspired mechanisms: (i) a Hebbian regulariser
that aligns the spatial mean of activations with the mean of the corresponding
convolutional filter weights, encouraging structured, reusable primitives; and
(ii) a learnable neuromodulator that gates an elastic-weight-style
consolidation loss, preserving beneficial parameters without freezing the
network. Phase 2 fine-tunes the backbone with a pairwise metric-learning loss,
explicitly compressing intra-class distances and enlarging inter-class margins
in the embedding space. Evaluated on CIFAR-10, CIFAR-100, and TinyImageNet
across five backbones (ResNet-18, VGG-11, MobileNet-v2, EfficientNet-V2,
DenseNet-121), NM-Hebb achieves consistent gains over baseline and other
methods: Top-1 accuracy improves by +2.0-10.0 pp (CIFAR-10), +2.0-9.0 pp
(CIFAR-100), and up to +4.3-8.9 pp (TinyImageNet), with Normalised Mutual
Information (NMI) increased by up to +0.15. Qualitative visualisations and
filter-level analyses further confirm that NM-Hebb produces more structured and
selective features, yielding tighter and more interpretable class clusters.
Overall, coupling local Hebbian plasticity with metric-based fine-tuning yields
CNNs that are not only more accurate but also more interpretable, offering
practical benefits for resource-constrained and safety-critical AI deployments.

</details>


### [221] [Adaptive Scaling of Policy Constraints for Offline Reinforcement Learning](https://arxiv.org/abs/2508.19900)
*Tan Jing,Xiaorui Li,Chao Yao,Xiaojuan Ban,Yuetong Fang,Renjing Xu,Zhaolin Yuan*

Main category: cs.LG

TL;DR: 本文提出一种名为ASPC的框架，可在离线强化学习中动态调整策略约束，无需对每个数据集进行单独调参，并在多个数据集中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前离线强化学习需要通过策略约束缓解分布偏移问题，但由于任务与数据集质量的差异，现有方法需对超参数进行精细调整，耗时且不实用。

Method: 提出了一种二阶可微框架ASPC，在训练过程中动态平衡强化学习与行为克隆。并对其性能提升进行了理论分析。

Result: 在39个数据集的实验中，ASPC使用单一超参数配置超过了需要逐数据集调参的其他自适应约束方法和先进的离线强化学习算法，同时仅带来极小的计算开销。

Conclusion: ASPC框架为离线强化学习提供了一种无需大量调参的新方法，能够在多数据集上实现稳定且优越的性能表现。

Abstract: Offline reinforcement learning (RL) enables learning effective policies from
fixed datasets without any environment interaction. Existing methods typically
employ policy constraints to mitigate the distribution shift encountered during
offline RL training. However, because the scale of the constraints varies
across tasks and datasets of differing quality, existing methods must
meticulously tune hyperparameters to match each dataset, which is
time-consuming and often impractical. We propose Adaptive Scaling of Policy
Constraints (ASPC), a second-order differentiable framework that dynamically
balances RL and behavior cloning (BC) during training. We theoretically analyze
its performance improvement guarantee. In experiments on 39 datasets across
four D4RL domains, ASPC using a single hyperparameter configuration outperforms
other adaptive constraint methods and state-of-the-art offline RL algorithms
that require per-dataset tuning while incurring only minimal computational
overhead. The code will be released at https://github.com/Colin-Jing/ASPC.

</details>


### [222] [GegenNet: Spectral Convolutional Neural Networks for Link Sign Prediction in Signed Bipartite Graphs](https://arxiv.org/abs/2508.19907)
*Hewen Wang,Renchi Yang,Xiaokui Xiao*

Main category: cs.LG

TL;DR: 提出了一种新的光谱卷积神经网络GegenNet用于符号二分图(SBG)的链接符号预测，显著提高了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要基于单一图或未充分考虑SBG的异质性和独特特性，因此需要一种更合适的方法。

Method: 通过快速光谱分解、基于Gegenbauer多项式的新光谱图滤波器以及支持正负边的多层光谱卷积网络构建GegenNet。

Result: GegenNet在6个基准数据集上与11种方法比较，表现突出，AUC提升高达4.28%，F1指标提升11.69%。

Conclusion: GegenNet有效、鲁棒并适用于SBG的链接符号预测任务，显著优于现有方法。

Abstract: Given a signed bipartite graph (SBG) G with two disjoint node sets U and V,
the goal of link sign prediction is to predict the signs of potential links
connecting U and V based on known positive and negative edges in G. The
majority of existing solutions towards link sign prediction mainly focus on
unipartite signed graphs, which are sub-optimal due to the neglect of node
heterogeneity and unique bipartite characteristics of SBGs. To this end, recent
studies adapt graph neural networks to SBGs by introducing message-passing
schemes for both inter-partition (UxV) and intra-partition (UxU or VxV) node
pairs. However, the fundamental spectral convolutional operators were
originally designed for positive links in unsigned graphs, and thus, are not
optimal for inferring missing positive or negative links from known ones in
SBGs.
  Motivated by this, this paper proposes GegenNet, a novel and effective
spectral convolutional neural network model for link sign prediction in SBGs.
In particular, GegenNet achieves enhanced model capacity and high predictive
accuracy through three main technical contributions: (i) fast and theoretically
grounded spectral decomposition techniques for node feature initialization;
(ii) a new spectral graph filter based on the Gegenbauer polynomial basis; and
(iii) multi-layer sign-aware spectral convolutional networks alternating
Gegenbauer polynomial filters with positive and negative edges. Our extensive
empirical studies reveal that GegenNet can achieve significantly superior
performance (up to a gain of 4.28% in AUC and 11.69% in F1) in link sign
prediction compared to 11 strong competitors over 6 benchmark SBG datasets.

</details>


### [223] [Ontology-Based Concept Distillation for Radiology Report Retrieval and Labeling](https://arxiv.org/abs/2508.19915)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.LG

TL;DR: 基于放射学报告的检索增强学习在改进长尾医学成像任务（例如罕见疾病检测）中表现出潜力。本文提出了一个基于UMLS的本体驱动方法，用于更加高效和语义一致地比对报告文本，相较于现有方法在预测性能和解释性上有所增强。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖高维文本嵌入，难以解释且计算成本高，与医学知识的结构化特点不匹配。

Method: 提出一种基于UMLS本体的检索方法，通过改进的RadGraph-XL和SapBERT工具提取报告中的医学实体，将其链接到标准化概念（CUIs），并定义了加权Tversky指数用于衡量报告间的相似性。

Result: 在MIMIC-CXR的放射图分类任务中，尤其是长尾场景下，优于现有嵌入检索方法。此外，生成的疾病标签资源为未来学习任务提供了帮助。

Conclusion: 本文方法提供了更具解释性、可靠性和针对性的临床AI系统检索策略，引入领域知识显得尤为重要。

Abstract: Retrieval-augmented learning based on radiology reports has emerged as a
promising direction to improve performance on long-tail medical imaging tasks,
such as rare disease detection in chest X-rays. Most existing methods rely on
comparing high-dimensional text embeddings from models like CLIP or CXR-BERT,
which are often difficult to interpret, computationally expensive, and not
well-aligned with the structured nature of medical knowledge. We propose a
novel, ontology-driven alternative for comparing radiology report texts based
on clinically grounded concepts from the Unified Medical Language System
(UMLS). Our method extracts standardised medical entities from free-text
reports using an enhanced pipeline built on RadGraph-XL and SapBERT. These
entities are linked to UMLS concepts (CUIs), enabling a transparent,
interpretable set-based representation of each report. We then define a
task-adaptive similarity measure based on a modified and weighted version of
the Tversky Index that accounts for synonymy, negation, and hierarchical
relationships between medical entities. This allows efficient and semantically
meaningful similarity comparisons between reports. We demonstrate that our
approach outperforms state-of-the-art embedding-based retrieval methods in a
radiograph classification task on MIMIC-CXR, particularly in long-tail
settings. Additionally, we use our pipeline to generate ontology-backed disease
labels for MIMIC-CXR, offering a valuable new resource for downstream learning
tasks. Our work provides more explainable, reliable, and task-specific
retrieval strategies in clinical AI systems, especially when interpretability
and domain knowledge integration are essential. Our code is available at
https://github.com/Felix-012/ontology-concept-distillation

</details>


### [224] [FlowletFormer: Network Behavioral Semantic Aware Pre-training Model for Traffic Classification](https://arxiv.org/abs/2508.19924)
*Liming Liu,Ruoyu Li,Qing Li,Meijia Hou,Yong Jiang,Mingwei Xu*

Main category: cs.LG

TL;DR: FlowletFormer是一个基于BERT的预训练模型，用于网络流量分类，能够更好地捕获数据包结构、流层行为、协议语义及上下文关系。


<details>
  <summary>Details</summary>
Motivation: 现有网络流量分类方法对数据包结构特征、协议语义和上下文关系的捕捉不足，影响表示效果和分类准确性。

Method: 提出了FlowletFormer预训练模型，其关键点包括：引入连贯行为感知的流量表示方法、基于协议堆栈对齐的嵌入层、以及领域特定的预训练任务，提升了对流量的多维度特性建模能力。

Result: 实验表明FlowletFormer在流量表示效果、分类准确性和少样本学习能力方面显著优于现有方法。

Conclusion: FlowletFormer通过有效整合网络领域知识，能够更好地理解网络传输原理，为流量分析任务提供一个更稳健可靠的框架。

Abstract: Network traffic classification using pre-training models has shown promising
results, but existing methods struggle to capture packet structural
characteristics, flow-level behaviors, hierarchical protocol semantics, and
inter-packet contextual relationships. To address these challenges, we propose
FlowletFormer, a BERT-based pre-training model specifically designed for
network traffic analysis. FlowletFormer introduces a Coherent Behavior-Aware
Traffic Representation Model for segmenting traffic into semantically
meaningful units, a Protocol Stack Alignment-Based Embedding Layer to capture
multilayer protocol semantics, and Field-Specific and Context-Aware Pretraining
Tasks to enhance both inter-packet and inter-flow learning. Experimental
results demonstrate that FlowletFormer significantly outperforms existing
methods in the effectiveness of traffic representation, classification
accuracy, and few-shot learning capability. Moreover, by effectively
integrating domain-specific network knowledge, FlowletFormer shows better
comprehension of the principles of network transmission (e.g., stateful
connections of TCP), providing a more robust and trustworthy framework for
traffic analysis.

</details>


### [225] [Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local Nash Interactions](https://arxiv.org/abs/2508.19945)
*Zhouyu Zhang,Chih-Yuan Chiu,Glen Chou*

Main category: cs.LG

TL;DR: 该论文提出一种基于逆动态博弈的算法，通过混合整数线性规划方法，从局部广义纳什均衡交互数据中学习参数约束。


<details>
  <summary>Details</summary>
Motivation: 旨在从多智能体的交互中推断出一致的安全和非安全约束，以更好地设计鲁棒的运动规划。

Method: 基于逆动态博弈，利用混合整数线性规划（MILP）编码Karush-Kuhn-Tucker（KKT）条件，恢复符合纳什站位性要求的约束条件。

Result: 该方法能够从非线性动态智能体的交互中推断出各种类的约束，包括凸和非凸约束，并通过实验验证其在仿真与硬件中的有效性。

Conclusion: 证明了方法在学习内近似安全约束及提高鲁棒交互运动规划上的能力，同时也揭示了从纳什均衡中学习约束的局限性。

Abstract: We present an inverse dynamic game-based algorithm to learn parametric
constraints from a given dataset of local generalized Nash equilibrium
interactions between multiple agents. Specifically, we introduce mixed-integer
linear programs (MILP) encoding the Karush-Kuhn-Tucker (KKT) conditions of the
interacting agents, which recover constraints consistent with the Nash
stationarity of the interaction demonstrations. We establish theoretical
guarantees that our method learns inner approximations of the true safe and
unsafe sets, as well as limitations of constraint learnability from
demonstrations of Nash equilibrium interactions. We also use the interaction
constraints recovered by our method to design motion plans that robustly
satisfy the underlying constraints. Across simulations and hardware
experiments, our methods proved capable of inferring constraints and designing
interactive motion plans for various classes of constraints, both convex and
non-convex, from interaction demonstrations of agents with nonlinear dynamics.

</details>


### [226] [Global Permutation Entropy](https://arxiv.org/abs/2508.19955)
*Abhijeet Avhale,Joscha Diehl,Niraj Velankar,Emanuele Verri*

Main category: cs.LG

TL;DR: 本文提出了一种新的复杂性衡量指标，即全局排列熵（Global Permutation Entropy，GPE），可提取标准排列熵无法捕捉的结构信息，同时提供了相关计算工具包。


<details>
  <summary>Details</summary>
Motivation: 现有的排列熵方法局限于连续的序列模式，限制了对时间序列复杂性的全面理解与量化。

Method: 提出全局排列熵（GPE），它利用新算法有效提取时间序列的完整排列模式，通过非连续模式扩展现有排列熵的分析能力。

Result: 实验证明，GPE能够揭示标准排列熵未能捕捉的结构信息，并已开发可用的计算工具包。

Conclusion: GPE扩展了排列熵的适用范围，为时间序列分析提供了更全面的复杂性度量方法。

Abstract: Permutation Entropy, introduced by Bandt and Pompe, is a widely used
complexity measure for real-valued time series that is based on the relative
order of values within consecutive segments of fixed length. After
standardizing each segment to a permutation and computing the frequency
distribution of these permutations, Shannon Entropy is then applied to quantify
the series' complexity. We introduce Global Permutation Entropy (GPE), a novel
index that considers all possible patterns of a given length, including
non-consecutive ones. Its computation relies on recently developed algorithms
that enable the efficient extraction of full permutation profiles. We
illustrate some properties of GPE and demonstrate its effectiveness through
experiments on synthetic datasets, showing that it reveals structural
information not accessible through standard permutation entropy. We provide a
Julia package for the calculation of GPE at
`https://github.com/AThreeH1/Global-Permutation-Entropy'.

</details>


### [227] [Short-Horizon Predictive Maintenance of Industrial Pumps Using Time-Series Features and Machine Learning](https://arxiv.org/abs/2508.19974)
*Khaled M. A. Alghtus,Aiyad Gannan,Khalid M. Alhajri,Ali L. A. Al Jubouri,Hassan A. I. Al-Janahi*

Main category: cs.LG

TL;DR: 本研究提出了一种使用实时传感器数据预测工业离心泵短期故障的机器学习框架，使用随机森林和XGBoost模型通过滑动窗口和SMOTE算法处理数据，取得了显著的预测效果。


<details>
  <summary>Details</summary>
Motivation: 推动工业设备的预测性维护，提前发现可能发生的故障，提高工业系统的可靠性和成本效率。

Method: 利用随机森林和XGBoost算法，结合滑动窗口技术（分析60分钟与120分钟的历史数据），提取统计特征，使用SMOTE算法处理类别不平衡问题，优化短期故障预测。

Result: 随机森林模型在60分钟窗口下的召回率为5分钟69.2%、15分钟64.9%、30分钟48.6%。在120分钟窗口下，召回率为5分钟57.6%，15与30分钟均为65.6%。XGBoost表现接近但稍弱。

Conclusion: 最佳的历史数据长度依赖于预测时间跨度。提出的方法为实时工业监控系统中的预测性维护提供了可解释且可扩展的解决方案。

Abstract: This study presents a machine learning framework for forecasting short-term
faults in industrial centrifugal pumps using real-time sensor data. The
approach aims to predict {EarlyWarning} conditions 5, 15, and 30 minutes in
advance based on patterns extracted from historical operation. Two lookback
periods, 60 minutes and 120 minutes, were evaluated using a sliding window
approach. For each window, statistical features including mean, standard
deviation, minimum, maximum, and linear trend were extracted, and class
imbalance was addressed using the SMOTE algorithm. Random Forest and XGBoost
classifiers were trained and tested on the labeled dataset. Results show that
the Random Forest model achieved the best short-term forecasting performance
with a 60-minute window, reaching recall scores of 69.2\% at 5 minutes, 64.9\%
at 15 minutes, and 48.6\% at 30 minutes. With a 120-minute window, the Random
Forest model achieved 57.6\% recall at 5 minutes, and improved predictive
accuracy of 65.6\% at both 15 and 30 minutes. XGBoost displayed similar but
slightly lower performance. These findings highlight that optimal history
length depends on the prediction horizon, and that different fault patterns may
evolve at different timescales. The proposed method offers an interpretable and
scalable solution for integrating predictive maintenance into real-time
industrial monitoring systems.

</details>


### [228] [Reducing Street Parking Search Time via Smart Assignment Strategies](https://arxiv.org/abs/2508.19979)
*Behafarid Hemmatpour,Javad Dogani,Nikolaos Laoutaris*

Main category: cs.LG

TL;DR: 研究展示了一种新的策略Cord-Approx，以提升城市停车问题中随着实时助手的辅助下用户寻找停车位的效率。


<details>
  <summary>Details</summary>
Motivation: 探索移动应用在减轻城市停车拥挤和交通问题上的应用潜力，研究实时信息提供及用户协调对停车效率的影响。

Method: 以马德里的街头停车生态为模拟场景，分析四种停车搜索策略：无协作(Unc-Agn)、协作但不感知非用户(Cord-Agn)、理想化的全知系统(Cord-Oracle)、以及基于概率估算非用户行为的现实可行策略(Cord-Approx)，并利用传统匹配算法进行路径优化分配。

Result: 模拟数据显示，Cord-Approx策略在实际交通数据支持下显著缩短了用户的停车时间，平均为6.69分钟，相较于非用户的19.98分钟有显著改进。

Conclusion: 提出的Cord-Approx策略证明了在用户之间协调和有效信息使用的情况下，可以显著提高停车效率，降低交通拥堵，并对推动智慧城市有明显价值。

Abstract: In dense metropolitan areas, searching for street parking adds to traffic
congestion. Like many other problems, real-time assistants based on mobile
phones have been proposed, but their effectiveness is understudied. This work
quantifies how varying levels of user coordination and information availability
through such apps impact search time and the probability of finding street
parking. Through a data-driven simulation of Madrid's street parking ecosystem,
we analyze four distinct strategies: uncoordinated search (Unc-Agn),
coordinated parking without awareness of non-users (Cord-Agn), an idealized
oracle system that knows the positions of all non-users (Cord-Oracle), and our
novel/practical Cord-Approx strategy that estimates non-users' behavior
probabilistically. The Cord-Approx strategy, instead of requiring knowledge of
how close non-users are to a certain spot in order to decide whether to
navigate toward it, uses past occupancy distributions to elongate physical
distances between system users and alternative parking spots, and then solves a
Hungarian matching problem to dispatch accordingly. In high-fidelity
simulations of Madrid's parking network with real traffic data, users of
Cord-Approx averaged 6.69 minutes to find parking, compared to 19.98 minutes
for non-users without an app. A zone-level snapshot shows that Cord-Approx
reduces search time for system users by 72% (range = 67-76%) in central hubs,
and up to 73% in residential areas, relative to non-users.

</details>


### [229] [Evaluating Language Model Reasoning about Confidential Information](https://arxiv.org/abs/2508.19980)
*Dylan Sam,Alexander Robey,Andy Zou,Matt Fredrikson,J. Zico Kolter*

Main category: cs.LG

TL;DR: 本文为确保语言模型在高风险场景中更可靠地遵循用户定义的规则，提出了一种名为PasswordEval的基准来评估其在密码验证中的表现，并发现当前的模型在此任务上表现有限。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型越来越多地在高风险场景中作为自主代理被部署，确保它们能够可靠地遵守用户定义的规则已成为关键的安全问题。作者希望验证语言模型是否具备上下文鲁棒性，即遵循上下文相关的安全规范的能力。

Method: 作者开发了一个基准（PasswordEval），测试语言模型是否能通过上下文正确判断用户请求是否被授权。同时，增加了任务难度，如引入对抗性用户压力和复杂的多轮对话场景，并观测逻辑推理对完成任务的影响。

Result: 目前的开源和闭源语言模型在相关任务中的表现有限，逻辑推理能力并未普遍提升性能，反而经常泄露机密信息。在更复杂和具有对抗性的场景中，模型处理机密信息的能力表现出明显不足。

Conclusion: 现有模型不适合处理高风险环境中的机密信息，其逻辑推理的训练方式可能需要改进以提升其在此类应用中的安全性。

Abstract: As language models are increasingly deployed as autonomous agents in
high-stakes settings, ensuring that they reliably follow user-defined rules has
become a critical safety concern. To this end, we study whether language models
exhibit contextual robustness, or the capability to adhere to context-dependent
safety specifications. For this analysis, we develop a benchmark (PasswordEval)
that measures whether language models can correctly determine when a user
request is authorized (i.e., with a correct password). We find that current
open- and closed-source models struggle with this seemingly simple task, and
that, perhaps surprisingly, reasoning capabilities do not generally improve
performance. In fact, we find that reasoning traces frequently leak
confidential information, which calls into question whether reasoning traces
should be exposed to users in such applications. We also scale the difficulty
of our evaluation along multiple axes: (i) by adding adversarial user pressure
through various jailbreaking strategies, and (ii) through longer multi-turn
conversations where password verification is more challenging. Overall, our
results suggest that current frontier models are not well-suited to handling
confidential information, and that reasoning capabilities may need to be
trained in a different manner to make them safer for release in high-stakes
settings.

</details>


### [230] [Self-Supervised Pre-Training with Equilibrium Constraints](https://arxiv.org/abs/2508.19990)
*Xiaodong Cui,A F M Saif,Brian Kingsbury,Tianyi Chen*

Main category: cs.LG

TL;DR: 本文提出了一种新的自监督预训练方法，通过双层优化问题解决异构数据的本地优化问题并改进预训练模型的适应性。


<details>
  <summary>Details</summary>
Motivation: 为了解决异构数据在自监督预训练中的局限性，提出了额外的平衡约束来确保模型对每种数据进行本地优化。

Method: 设计了一种双层优化方法，通过K步梯度下降和一阶近似方法对异构数据进行本地优化，并与MAML方法建立了连接。

Result: 通过多领域及多语言数据集的实验证明，新方法能显著提高自监督预训练模型在下游任务中的适应性。

Conclusion: 新提出的自监督预训练方法有效解决了异构数据的局限性，为提升下游任务表现提供了新思路。

Abstract: Self-supervised pre-training using unlabeled data is widely used in machine
learning. In this paper, we propose a new self-supervised pre-training approach
to dealing with heterogeneous data. Instead of mixing all the data and
minimizing the averaged global loss in the conventional way, we impose
additional equilibrium constraints to ensure that the models optimizes each
source of heterogeneous data to its local optima after $K$-step gradient
descent initialized from the model. We formulate this as a bilevel optimization
problem, and use the first-order approximation method to solve the problem. We
discuss its connection to model-agnostic meta learning (MAML). Experiments are
carried out on self-supervised pre-training using multi-domain and multilingual
datasets, demonstrating that the proposed approach can significantly improve
the adaptivity of the self-supervised pre-trained model for the downstream
supervised fine-tuning tasks.

</details>


### [231] [Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation](https://arxiv.org/abs/2508.19999)
*Ziniu Zhang,Zhenshuo Zhang,Dongyue Li,Lu Wang,Jennifer Dy,Hongyang R. Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种新的算法用于选择示例以进行查询集中上下文学习。


<details>
  <summary>Details</summary>
Motivation: 解决如何从n个示例中快速选择k个最合适的进行下游推理的问题，以应对提示调优和思路链推理等挑战。

Method: 引入了一种基于输入嵌入空间中的输出梯度的新方法，通过一阶近似估计模型输出，并结合随机采样子集的结果，计算影响评分以选择最相关的示例。

Result: 该方法在多个数据集上的实验表明，梯度估计程序的误差小于1%，模型运行速度提升可达37.7倍，性能平均优于现有方法11%。

Conclusion: 该算法有效提升了在大规模模型中上下文学习的效率，为示例选择提供了一种快速且精度高的方法。

Abstract: This paper introduces an algorithm to select demonstration examples for
in-context learning of a query set. Given a set of $n$ examples, how can we
quickly select $k$ out of $n$ to best serve as the conditioning for downstream
inference? This problem has broad applications in prompt tuning and
chain-of-thought reasoning. Since model weights remain fixed during in-context
learning, previous work has sought to design methods based on the similarity of
token embeddings. This work proposes a new approach based on gradients of the
output taken in the input embedding space. Our approach estimates model outputs
through a first-order approximation using the gradients. Then, we apply this
estimation to multiple randomly sampled subsets. Finally, we aggregate the
sampled subset outcomes to form an influence score for each demonstration, and
select $k$ most relevant examples. This procedure only requires pre-computing
model outputs and gradients once, resulting in a linear-time algorithm relative
to model and training set sizes. Extensive experiments across various models
and datasets validate the efficiency of our approach. We show that the gradient
estimation procedure yields approximations of full inference with less than
$\mathbf{1}\%$ error across six datasets. This allows us to scale up subset
selection that would otherwise run full inference by up to
$\mathbf{37.7}\times$ on models with up to $34$ billion parameters, and
outperform existing selection methods based on input embeddings by
$\mathbf{11}\%$ on average.

</details>


### [232] [Cross-Platform E-Commerce Product Categorization and Recategorization: A Multimodal Hierarchical Classification Approach](https://arxiv.org/abs/2508.20013)
*Lotte Gross,Rebecca Walter,Nicole Zoppi,Adrien Justus,Alessandro Gambetti,Qiwei Han,Maximilian Kaiser*

Main category: cs.LG

TL;DR: 本文开发并部署了一种多模态分层分类框架，用于解决电商产品分类中的平台异构性和分类体系的结构局限性问题。结合了文本(RoBERTa)、视觉(ViT)及视觉-语言联合表示(CLIP)特征，并探索了多种融合策略。结果显示，基于MLP的后期融合策略取得了98.59%的分层F1分数。


<details>
  <summary>Details</summary>
Motivation: 希望解决电商平台分类中的异构性和分类体系的局限性问题，并通过更精确的分类实现商业应用中的信息智能化。

Method: 采用多模态分层分类框架，使用RoBERTa、ViT和CLIP特征，结合动态遮掩技术提高分类一致性，引入SimCLR等方法对浅薄或不一致的类别进行产品再分类。

Result: 发现CLIP特征结合MLP的后期融合策略取得了最佳表现（分层F1为98.59%），并通过自监督方法发现了细粒度类别。同时验证了复杂方法在多样化训练数据下的高准确性，以及简单方法在未见数据平台中出色的泛化性。

Conclusion: 该框架在工业级应用中表现出良好的扩展性，平衡了成本与准确性，并成功部署于EURWEB的商业交易智能平台。

Abstract: This study addresses critical industrial challenges in e-commerce product
categorization, namely platform heterogeneity and the structural limitations of
existing taxonomies, by developing and deploying a multimodal hierarchical
classification framework. Using a dataset of 271,700 products from 40
international fashion e-commerce platforms, we integrate textual features
(RoBERTa), visual features (ViT), and joint vision--language representations
(CLIP). We investigate fusion strategies, including early, late, and
attention-based fusion within a hierarchical architecture enhanced by dynamic
masking to ensure taxonomic consistency. Results show that CLIP embeddings
combined via an MLP-based late-fusion strategy achieve the highest hierarchical
F1 (98.59\%), outperforming unimodal baselines. To address shallow or
inconsistent categories, we further introduce a self-supervised ``product
recategorization'' pipeline using SimCLR, UMAP, and cascade clustering, which
discovered new, fine-grained categories (e.g., subtypes of ``Shoes'') with
cluster purities above 86\%. Cross-platform experiments reveal a
deployment-relevant trade-off: complex late-fusion methods maximize accuracy
with diverse training data, while simpler early-fusion methods generalize more
effectively to unseen platforms. Finally, we demonstrate the framework's
industrial scalability through deployment in EURWEB's commercial transaction
intelligence platform via a two-stage inference pipeline, combining a
lightweight RoBERTa stage with a GPU--accelerated multimodal stage to balance
cost and accuracy.

</details>


### [233] [Decomposing Behavioral Phase Transitions in LLMs: Order Parameters for Emergent Misalignment](https://arxiv.org/abs/2508.20015)
*Julian Arnold,Niels Lörch*

Main category: cs.LG

TL;DR: 研究了在细化大型语言模型(LLMs)时引发行为失调的方法以及检测这种行为偏差的框架，并使用统计方法与LLM裁判评估其在知识及伦理等场景的影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解在细调过程中，何时以及如何引发与人类价值不一致的错位行为，以便更好进行规范化开发。

Method: 开发了一个综合框架，使用分布变化检测方法和基于自然语言的顺序参数，由LLM裁判评估，并通过统计度量来量化细化过程中模型多方面的变化。

Result: 通过框架证明行为的转变发生在训练的后期，并提出了一种新的语言顺序参数自动发现和量化的方法，并在知识、政治、伦理场景进行了验证。

Conclusion: 新提出的框架能够有效描述并量化模型在语言生成方面的转变与变化属性。

Abstract: Fine-tuning LLMs on narrowly harmful datasets can lead to behavior that is
broadly misaligned with respect to human values. To understand when and how
this emergent misalignment occurs, we develop a comprehensive framework for
detecting and characterizing rapid transitions during fine-tuning using both
distributional change detection methods as well as order parameters that are
formulated in plain English and evaluated by an LLM judge. Using an objective
statistical dissimilarity measure, we quantify how the phase transition that
occurs during fine-tuning affects multiple aspects of the model. In particular,
we assess what percentage of the total distributional change in model outputs
is captured by different aspects, such as alignment or verbosity, providing a
decomposition of the overall transition. We also find that the actual
behavioral transition occurs later in training than indicated by the peak in
the gradient norm alone. Our framework enables the automated discovery and
quantification of language-based order parameters, which we demonstrate on
examples ranging from knowledge questions to politics and ethics.

</details>


### [234] [Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence](https://arxiv.org/abs/2508.20019)
*Ji Wang,Kashing Chen,Xinyuan Song,Ke Zhang,Lynn Ai,Eric Yang,Bill Shi*

Main category: cs.LG

TL;DR: 本文提出了一种名为Symphony的去中心化多智能体系统，降低了部署成本，提升了灵活性与适应性。


<details>
  <summary>Details</summary>
Motivation: 当前基于大型语言模型(LLM)的框架依赖于中心化调度，存在高成本和有限适应性的问题。

Method: 提出Symphony系统，包含去中心化账本功能、Beacon选择协议和基于CoTs的加权结果投票机制。

Result: 在推理基准测试中表现优于现有方法，提高了精度，并在不同模型容量下展现了稳健性。

Conclusion: Symphony系统实现了隐私保护、可扩展以及低成本的可靠协调机制，是一种有效的多智能体系统解决方案。

Abstract: Most existing Large Language Model (LLM)-based agent frameworks rely on
centralized orchestration, incurring high deployment costs, rigid communication
topologies, and limited adaptability. To address these challenges, we introduce
Symphony, a decentralized multi-agent system which enables lightweight LLMs on
consumer-grade GPUs to coordinate. Symphony introduces three key mechanisms:
(1) a decentralized ledger that records capabilities, (2) a Beacon-selection
protocol for dynamic task allocation, and (3) weighted result voting based on
CoTs. This design forms a privacy-saving, scalable, and fault-tolerant
orchestration with low overhead. Empirically, Symphony outperforms existing
baselines on reasoning benchmarks, achieving substantial accuracy gains and
demonstrating robustness across models of varying capacities.

</details>


### [235] [FairLoop: Software Support for Human-Centric Fairness in Predictive Business Process Monitoring](https://arxiv.org/abs/2508.20021)
*Felix Möhrlein,Martin Käppel,Julian Neuberger,Sven Weinzierl,Lars Ackermann,Martin Matzner,Stefan Jablonski*

Main category: cs.LG

TL;DR: FairLoop是一个工具，可以通过人类引导减轻神经网络预测模型中的偏差，从而实现更公平的预测。


<details>
  <summary>Details</summary>
Motivation: 机器学习任务中使用敏感属性（如性别或年龄）可能导致不公平的预测，需要一个工具能够更高效地消除这种偏差。

Method: FairLoop通过从神经网络提取决策树，让用户检查并调整不公平的决策逻辑，然后用更新后的逻辑优化原始模型。

Result: FairLoop使人类能够基于上下文参与偏差消除，相比其他方法更加灵活，不需要一律排除敏感属性的使用。

Conclusion: 通过人类的参与，FairLoop实现了更上下文相关、更公平的机器学习预测，同时提升了模型的可解释性。

Abstract: Sensitive attributes like gender or age can lead to unfair predictions in
machine learning tasks such as predictive business process monitoring,
particularly when used without considering context. We present FairLoop1, a
tool for human-guided bias mitigation in neural network-based prediction
models. FairLoop distills decision trees from neural networks, allowing users
to inspect and modify unfair decision logic, which is then used to fine-tune
the original model towards fairer predictions. Compared to other approaches to
fairness, FairLoop enables context-aware bias removal through human
involvement, addressing the influence of sensitive attributes selectively
rather than excluding them uniformly.

</details>


### [236] [Using item recommendations and LLMs in marketing email titles](https://arxiv.org/abs/2508.20024)
*Deddy Jobson,Muktti Shukla,Phuong Dinh,Julio Christian Young,Nick Pitton,Nina Chen,Ryan Ginstrom*

Main category: cs.LG

TL;DR: 研究探讨了通过大型语言模型（LLMs）生成主题化电子邮件标题的可能性，以提升用户与电子邮件之间的互动。


<details>
  <summary>Details</summary>
Motivation: 传统电子邮件标题使用固定模板，缺乏吸引力，难以激发用户兴趣。

Method: 利用大型语言模型生成个性化、主题化的电子邮件标题，并通过离线模拟和线上实验进行验证。

Result: 在数百万用户中实验发现，该方法能够有效提高电子邮件的用户互动率。

Conclusion: 借助LLMs生成主题化电子邮件标题是可行的且安全自动化的，对大规模用户具有应用价值。

Abstract: E-commerce marketplaces make use of a number of marketing channels like
emails, push notifications, etc. to reach their users and stimulate purchases.
Personalized emails especially are a popular touch point for marketers to
inform users of latest items in stock, especially for those who stopped
visiting the marketplace. Such emails contain personalized recommendations
tailored to each user's interests, enticing users to buy relevant items. A
common limitation of these emails is that the primary entry point, the title of
the email, tends to follow fixed templates, failing to inspire enough interest
in the contents. In this work, we explore the potential of large language
models (LLMs) for generating thematic titles that reflect the personalized
content of the emails. We perform offline simulations and conduct online
experiments on the order of millions of users, finding our techniques useful in
improving the engagement between customers and our emails. We highlight key
findings and learnings as we productionize the safe and automated generation of
email titles for millions of users.

</details>


### [237] [Pruning Strategies for Backdoor Defense in LLMs](https://arxiv.org/abs/2508.20032)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 本文研究后门攻击对预训练语言模型的威胁及应对策略，通过注意力头剪枝方法进行防御并评估其效果。


<details>
  <summary>Details</summary>
Motivation: 解决因后门攻击对预训练语言模型完整性和性能的威胁，并提出无需了解攻击触发器或访问干净参考模型的防御方法。

Method: 提出六种基于注意力头剪枝的策略，包括梯度剪枝、层间方差剪枝、梯度剪枝结合L1/L2稀疏化、随机集成剪枝、强化学习引导剪枝和贝叶斯不确定性剪枝，通过迭代移除不重要的注意力头，监控验证精度，避免过度剪枝。

Result: 实验表明，梯度剪枝对抗语法触发器表现最佳，而强化学习和贝叶斯剪枝在应对风格攻击时更具效果。

Conclusion: 注意力头剪枝是一种有效方式，可以在没有触发器知识的情况下缓解后门攻击的威胁。

Abstract: Backdoor attacks are a significant threat to the performance and integrity of
pre-trained language models. Although such models are routinely fine-tuned for
downstream NLP tasks, recent work shows they remain vulnerable to backdoor
attacks that survive vanilla fine-tuning. These attacks are difficult to defend
because end users typically lack knowledge of the attack triggers. Such attacks
consist of stealthy malicious triggers introduced through subtle syntactic or
stylistic manipulations, which can bypass traditional detection and remain in
the model, making post-hoc purification essential. In this study, we explore
whether attention-head pruning can mitigate these threats without any knowledge
of the trigger or access to a clean reference model. To this end, we design and
implement six pruning-based strategies: (i) gradient-based pruning, (ii)
layer-wise variance pruning, (iii) gradient-based pruning with structured L1/L2
sparsification, (iv) randomized ensemble pruning, (v)
reinforcement-learning-guided pruning, and (vi) Bayesian uncertainty pruning.
Each method iteratively removes the least informative heads while monitoring
validation accuracy to avoid over-pruning. Experimental evaluation shows that
gradient-based pruning performs best while defending the syntactic triggers,
whereas reinforcement learning and Bayesian pruning better withstand stylistic
attacks.

</details>


### [238] [Reinforcement Learning for Search Tree Size Minimization in Constraint Programming: New Results on Scheduling Benchmarks](https://arxiv.org/abs/2508.20056)
*Vilém Heinz,Petr Vilím,Zdeněk Hanzálek*

Main category: cs.LG

TL;DR: 本研究提出了一种改进的失败导向搜索（FDS）算法，利用多臂老虎机（MAB）强化学习算法优化算法性能，在经典调度问题中表现出显著提升。


<details>
  <summary>Details</summary>
Motivation: 旨在通过改进失败导向搜索（FDS）算法，提高其在经典调度问题（如作业车间调度问题和资源受限项目调度问题）上的性能表现。

Method: 将多臂老虎机（MAB）强化学习算法应用于FDS，并结合问题特定优化及参数调整，对新的算法在经典调度问题上进行验证。

Result: 在JSSP和RCPSP中，改进版FDS在新求解器OptalCP中表现分别提升1.7倍和2.1倍，相较于IBM CP Optimizer 22.1中的FDS算法提升3.5倍和2.1倍。同时，900秒时间限制下，显著改善了多项基准实例的下界。

Conclusion: 改进的FDS算法显著提升了求解性能，为调度问题求解提供了一个新的高效手段，同时在诸多实例上达到了新的基准或完全求解。

Abstract: Failure-Directed Search (FDS) is a significant complete generic search
algorithm used in Constraint Programming (CP) to efficiently explore the search
space, proven particularly effective on scheduling problems. This paper
analyzes FDS's properties, showing that minimizing the size of its search tree
guided by ranked branching decisions is closely related to the Multi-armed
bandit (MAB) problem. Building on this insight, MAB reinforcement learning
algorithms are applied to FDS, extended with problem-specific refinements and
parameter tuning, and evaluated on the two most fundamental scheduling
problems, the Job Shop Scheduling Problem (JSSP) and Resource-Constrained
Project Scheduling Problem (RCPSP). The resulting enhanced FDS, using the best
extended MAB algorithm and configuration, performs 1.7 times faster on the JSSP
and 2.1 times faster on the RCPSP benchmarks compared to the original
implementation in a new solver called OptalCP, while also being 3.5 times
faster on the JSSP and 2.1 times faster on the RCPSP benchmarks than the
current state-of-the-art FDS algorithm in IBM CP Optimizer 22.1. Furthermore,
using only a 900-second time limit per instance, the enhanced FDS improved the
existing state-of-the-art lower bounds of 78 of 84 JSSP and 226 of 393 RCPSP
standard open benchmark instances while also completely closing a few of them.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [239] [When Routers, Switches and Interconnects Compute: A processing-in-interconnect Paradigm for Scalable Neuromorphic AI](https://arxiv.org/abs/2508.19548)
*Madhuvanthi Srivatsav R,Chiranjib Bhattacharyya,Shantanu Chakrabartty,Chetan Singh Thakur*

Main category: cs.NE

TL;DR: 本文探讨了在大规模神经形态计算中，与路由、交换和互连相关的计算范式以及新的'处理-互连(\pi^2)'设计，并通过理论和建模结果探讨该设计的可扩展性和效率。


<details>
  <summary>Details</summary>
Motivation: 在大规模神经形态计算中，互连结构对能源消耗与速度具有不可忽视的影响。该研究希望通过新的计算范式'\pi^2'解决这一瓶颈，并探索跨神经网络的映射及其扩展性能。

Method: 研究采用映射分析来将AI任务用的操作映射到现有的硬件技术，如延迟、因果性等；并利用知识蒸馏等框架实现神经网络的映射。另外，采用解析建模量化其扩展性能与能效表现。

Result: 研究显示，典型AI工作负载的操作可以与现有包交换硬件中的概念对接。而且，与其他神经形态平台相比，\pi^2能随着互连带宽和能效的提升而具备更好的能量扩展优势。

Conclusion: 通过利用互连技术的发展，\pi^2架构有望以更低的能耗扩展到实现大脑规模的AI推理任务，功耗可以控制在百瓦级别内。

Abstract: Routing, switching, and the interconnect fabric are essential for large-scale
neuromorphic computing. While this fabric only plays a supporting role in the
process of computing, for large AI workloads it ultimately determines energy
consumption and speed. In this paper, we address this bottleneck by asking: (a)
What computing paradigms are inherent in existing routing, switching, and
interconnect systems, and how can they be used to implement a
processing-in-Interconnect (\pi^2) computing paradigm? and (b) leveraging
current and future interconnect trends, how will a \pi^2 system's performance
scale compared to other neuromorphic architectures? For (a), we show that
operations required for typical AI workloads can be mapped onto delays,
causality, time-outs, packet drop, and broadcast operations -- primitives
already implemented in packet-switching and packet-routing hardware. We show
that existing buffering and traffic-shaping embedded algorithms can be
leveraged to implement neuron models and synaptic operations. Additionally, a
knowledge-distillation framework can train and cross-map well-established
neural network topologies onto $\pi^2$ without degrading generalization
performance. For (b), analytical modeling shows that, unlike other neuromorphic
platforms, the energy scaling of $\pi^2$ improves with interconnect bandwidth
and energy efficiency. We predict that by leveraging trends in interconnect
technology, a \pi^2 architecture can be more easily scaled to execute
brain-scale AI inference workloads with power consumption levels in the range
of hundreds of watts.

</details>


### [240] [Walk the Robot: Exploring Soft Robotic Morphological Communication driven by Spiking Neural Networks](https://arxiv.org/abs/2508.19920)
*Matthew Meek,Guy Tallent,Thomas Breimer,James Gaskell,Abhay Kashyap,Atharv Tekurkar,Jonathan Fischman,Luodi Wang,Viet-Dung Nguyen,John Rieffel*

Main category: cs.NE

TL;DR: 研究探索基于SNN的软体机器人在EvoGym环境中显现的形态通信特性。


<details>
  <summary>Details</summary>
Motivation: 研究探索如何利用非线性动力学耦合机制提升机器人不同部分间的通信与协调。

Method: 基于进化学习模型的尖峰神经网络（SNN），控制模拟软体机器人，并在EvoGym环境中测试其形态通信能力。

Result: 验证了形态通信在非刚性机器人中作为数据总线促进独立模块协调的潜力。

Conclusion: 通过利用动力学耦合，形态通信在软体机器人中表现出有效性，为非刚性机器人控制提供了新方向。

Abstract: Recently, researchers have explored control methods that embrace nonlinear
dynamic coupling instead of suppressing it. Such designs leverage dynamical
coupling for communication between different parts of the robot. Morphological
communication refers to when those dynamics can be used as an emergent data bus
to facilitate coordination among independent controller modules within the same
robot. Previous research with tensegrity-based robot designs has shown that
evolutionary learning models that evolve spiking neural networks (SNN) as robot
control mechanisms are effective for controlling non-rigid robots. Our own
research explores the emergence of morphological communication in an SNN-based
simulated soft robot in theEvoGym environment.

</details>
