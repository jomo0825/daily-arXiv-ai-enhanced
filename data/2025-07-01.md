<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 222]
- [cs.CL](#cs.CL) [Total: 82]
- [cs.AI](#cs.AI) [Total: 45]
- [cs.LG](#cs.LG) [Total: 112]
- [cs.NE](#cs.NE) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Robust Perspective Correction for Real-World Crack Evolution Tracking in Image-Based Structural Health Monitoring](https://arxiv.org/abs/2506.22437)
*Xinxin Sun,Peter Chang*

Main category: cs.CV

TL;DR: 本文提出了一种物理驱动的图像对齐框架，优化了当前工具在结构健康监测中细裂缝定位的表现。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如SIFT、SURF等）往往在低对比度、透视畸变条件下压制高频边缘，轻量化方法（如ORB、BRISK等）在纹理化或阴影环境下表现不佳，监测裂纹演变中对图像对齐的准确性提出了新的挑战。

Method: 基于KAZE框架，本文开发了一种裂纹保留的缩放空间建模方法，结合RANSAC的单应性估算，无需训练、参数调优和事前校准即可执行精准对齐。

Result: 实验验证表明，所提方法在裂纹面积和主轴长度误差分别降低70%和90%的同时，目标对齐精度保持在5%以下。

Conclusion: 通过非线性缩放空间模型，该框架为裂纹监测提供了一种高效且物理解释力强的新方法，适用于无人机和移动平台的大规模部署。

Abstract: Accurate image alignment is essential for monitoring crack evolution in
structural health monitoring (SHM), particularly under real-world conditions
involving perspective distortion, occlusion, and low contrast. However,
traditional feature detectors such as SIFT and SURF, which rely on
Gaussian-based scale spaces, tend to suppress high-frequency edges, making them
unsuitable for thin crack localization. Lightweight binary alternatives like
ORB and BRISK, while computationally efficient, often suffer from poor keypoint
repeatability on textured or shadowed surfaces. This study presents a
physics-informed alignment framework that adapts the open KAZE architecture to
SHM-specific challenges. By utilizing nonlinear anisotropic diffusion to
construct a crack-preserving scale space, and integrating RANSAC-based
homography estimation, the framework enables accurate geometric correction
without the need for training, parameter tuning, or prior calibration. The
method is validated on time-lapse images of masonry and concrete acquired via
handheld smartphone under varied field conditions, including shadow
interference, cropping, oblique viewing angles, and surface clutter. Compared
to classical detectors, the proposed framework reduces crack area and spine
length errors by up to 70 percent and 90 percent, respectively, while
maintaining sub-5 percent alignment error in key metrics. Unsupervised,
interpretable, and computationally lightweight, this approach supports scalable
deployment via UAVs and mobile platforms. By tailoring nonlinear scale-space
modeling to SHM image alignment, this work offers a robust and physically
grounded alternative to conventional techniques for tracking real-world crack
evolution.

</details>


### [2] [Counting with Confidence: Accurate Pest Monitoring in Water Traps](https://arxiv.org/abs/2506.22438)
*Xumin Gao,Mark Stevens,Grzegorz Cielniak*

Main category: cs.CV

TL;DR: 提出了一种综合评估虫害计数置信度的方法，通过结合检测结果与外部环境条件量化其可信度。实验表明，与基线相比，均方误差减少31.7%，R2值提升15.2%。


<details>
  <summary>Details</summary>
Motivation: 现有虫害自动计数模型大多缺乏对真实场景中计数结果可靠性的评估，导致模型部署的局限性。

Method: 利用虫害检测网络生成计数相关信息，并结合图像质量、复杂性及虫害分布均匀性评估。通过假设驱动的多因子敏感性分析优化评估方法，并提出自适应DBSCAN聚类算法。最终通过回归模型预测虫害计数置信度。

Result: 所提方法在虫害计数置信度测试集上的均方误差减少31.7%，R2值提高15.2%，显著优于基线模型。

Conclusion: 首次实现了综合评估计数任务置信度的功能，能够有效量化相关因素与计数置信度的关系，为精准农业提供关键支持。

Abstract: Accurate pest population monitoring and tracking their dynamic changes are
crucial for precision agriculture decision-making. A common limitation in
existing vision-based automatic pest counting research is that models are
typically evaluated on datasets with ground truth but deployed in real-world
scenarios without assessing the reliability of counting results due to the lack
of ground truth. To this end, this paper proposed a method for comprehensively
evaluating pest counting confidence in the image, based on information related
to counting results and external environmental conditions. First, a pest
detection network is used for pest detection and counting, extracting counting
result-related information. Then, the pest images undergo image quality
assessment, image complexity assessment, and pest distribution uniformity
assessment. And the changes in image clarity caused by stirring during image
acquisition are quantified by calculating the average gradient magnitude.
Notably, we designed a hypothesis-driven multi-factor sensitivity analysis
method to select the optimal image quality assessment and image complexity
assessment methods. And we proposed an adaptive DBSCAN clustering algorithm for
pest distribution uniformity assessment. Finally, the obtained information
related to counting results and external environmental conditions is input into
a regression model for prediction, resulting in the final pest counting
confidence. To the best of our knowledge, this is the first study dedicated to
comprehensively evaluating counting confidence in counting tasks, and
quantifying the relationship between influencing factors and counting
confidence through a model. Experimental results show our method reduces MSE by
31.7% and improves R2 by 15.2% on the pest counting confidence test set,
compared to the baseline built primarily on information related to counting
results.

</details>


### [3] [Modulated Diffusion: Accelerating Generative Modeling with Modulated Quantization](https://arxiv.org/abs/2506.22463)
*Weizhi Gao,Zhichao Hou,Junqi Yin,Feiyi Wang,Linyu Peng,Xiaorui Liu*

Main category: cs.CV

TL;DR: 研究提出了Modulated Diffusion (MoDiff)框架，通过调制量化和误差补偿来加速扩散模型生成，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型迭代采样计算成本高的问题，同时克服现有加速技术在计算误差和生成质量方面的局限性。

Method: 提出了一种名为Modulated Diffusion (MoDiff)的新框架，将调制量化与误差补偿结合，从理论和实验证明能有效降低计算存储需求并保持性能。

Result: MoDiff在CIFAR-10和LSUN数据集上显著将后训练量化中的激活量化位数从8位减少至3位，同时不影响生成性能。

Conclusion: MoDiff提供了一种通用框架，增强了现有方法的优势，为所有扩散模型加速提供有效解决方案，并带来低计算成本下的高质量生成。

Abstract: Diffusion models have emerged as powerful generative models, but their high
computation cost in iterative sampling remains a significant bottleneck. In
this work, we present an in-depth and insightful study of state-of-the-art
acceleration techniques for diffusion models, including caching and
quantization, revealing their limitations in computation error and generation
quality. To break these limits, this work introduces Modulated Diffusion
(MoDiff), an innovative, rigorous, and principled framework that accelerates
generative modeling through modulated quantization and error compensation.
MoDiff not only inherents the advantages of existing caching and quantization
methods but also serves as a general framework to accelerate all diffusion
models. The advantages of MoDiff are supported by solid theoretical insight and
analysis. In addition, extensive experiments on CIFAR-10 and LSUN demonstrate
that MoDiff significant reduces activation quantization from 8 bits to 3 bits
without performance degradation in post-training quantization (PTQ). Our code
implementation is available at https://github.com/WeizhiGao/MoDiff.

</details>


### [4] [ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction](https://arxiv.org/abs/2506.22498)
*Hao Liu,Yu Hu,Rakiba Rayhana,Ling Bai,Zheng Liu*

Main category: cs.CV

TL;DR: 该研究提出了一种利用床下负载传感器信号，基于深度学习方法预测病床离床意图的技术，解决了现有监测系统滞后性的问题。


<details>
  <summary>Details</summary>
Motivation: 当前医院和长期护理机构中的床相关跌倒事件频发，现有商用报警系统在患者离床后才触发，无法提前预警；因此探索更早发现离床意图的方法意义重大。

Method: 设计了一种低成本的基于床脚的负载传感器信号技术，通过生成RGB线图和纹理图来提取信号特征，并采用双流式Swin Transformer模型（ViFusionTST）进行信息融合，实现时间序列分类。

Result: 在一个自95张床位、持续六个月采集的真实数据集上，ViFusionTST模型在准确率、F1分数、召回率和AUPRC等指标上都超越了最新的1D和2D时间序列模型，准确率达到0.885，F1分数为0.794。

Conclusion: 图像融合负载信号是一种实际且有效的隐私保护型床边摔倒预防方法，能实时预测离床意图。

Abstract: Bed-related falls remain a leading source of injury in hospitals and
long-term-care facilities, yet many commercial alarms trigger only after a
patient has already left the bed. We show that early bed-exit intent can be
predicted using only four low-cost load cells mounted under the bed legs. The
resulting load signals are first converted into a compact set of complementary
images: an RGB line plot that preserves raw waveforms and three texture maps -
recurrence plot, Markov transition field, and Gramian angular field - that
expose higher-order dynamics. We introduce ViFusionTST, a dual-stream Swin
Transformer that processes the line plot and texture maps in parallel and fuses
them through cross-attention to learn data-driven modality weights.
  To provide a realistic benchmark, we collected six months of continuous data
from 95 beds in a long-term-care facility. On this real-world dataset
ViFusionTST reaches an accuracy of 0.885 and an F1 score of 0.794, surpassing
recent 1D and 2D time-series baselines across F1, recall, accuracy, and AUPRC.
The results demonstrate that image-based fusion of load-sensor signals for time
series classification is a practical and effective solution for real-time,
privacy-preserving fall prevention.

</details>


### [5] [Scalable Dynamic Origin-Destination Demand Estimation Enhanced by High-Resolution Satellite Imagery Data](https://arxiv.org/abs/2506.22499)
*Jiachao Liu,Pablo Guarda,Koichiro Niinuma,Sean Qian*

Main category: cs.CV

TL;DR: 本文提出了一种结合卫星影像和传统传感器数据的新方法，用于多类别中观尺度网络模型中的动态OD需求估计，实验表明该方法在大规模网络上的适用性和性能提升明显。


<details>
  <summary>Details</summary>
Motivation: 现有动态OD需求估计方法依赖于稀疏的本地传感器数据，难以全面捕捉城市范围内的交通状态，该研究旨在利用卫星影像突破这一局限性。

Method: 设计了一套计算机视觉流程，从卫星影像中进行车辆检测和匹配，同时结合基于计算图的动态OD需求估计模型，将卫星观测的交通密度数据和传统传感器数据结合使用。

Result: 实验表明，与仅使用传统数据相比，增加卫星影像派生的交通密度数据显著提高了估计性能，尤其是在没有传感器的路段。此外，实验验证了该框架在大规模网络下的适用性。

Conclusion: 结合卫星影像和传统传感器数据是一种实用有效的动态OD需求估计方法，具有广泛的适用性和部署潜力，尤其有利于覆盖大规模城市网络。

Abstract: This study presents a novel integrated framework for dynamic
origin-destination demand estimation (DODE) in multi-class mesoscopic network
models, leveraging high-resolution satellite imagery together with conventional
traffic data from local sensors. Unlike sparse local detectors, satellite
imagery offers consistent, city-wide road and traffic information of both
parking and moving vehicles, overcoming data availability limitations. To
extract information from imagery data, we design a computer vision pipeline for
class-specific vehicle detection and map matching, generating link-level
traffic density observations by vehicle class. Building upon this information,
we formulate a computational graph-based DODE model that calibrates dynamic
network states by jointly matching observed traffic counts and travel times
from local sensors with density measurements derived from satellite imagery. To
assess the accuracy and scalability of the proposed framework, we conduct a
series of numerical experiments using both synthetic and real-world data. The
results of out-of-sample tests demonstrate that supplementing traditional data
with satellite-derived density significantly improves estimation performance,
especially for links without local sensors. Real-world experiments also confirm
the framework's capability to handle large-scale networks, supporting its
potential for practical deployment in cities of varying sizes. Sensitivity
analysis further evaluates the impact of data quality related to satellite
imagery data.

</details>


### [6] [Visual-Semantic Knowledge Conflicts in Operating Rooms: Synthetic Data Curation for Surgical Risk Perception in Multimodal Large Language Models](https://arxiv.org/abs/2506.22500)
*Weiyi Zhao,Xiaoyu Tan,Liang Liu,Sijia Li,Youwei Song,Xihe Qiu*

Main category: cs.CV

TL;DR: 提出了一种通过生成合成图像数据集以改善多模态大语言模型(MLLMs)在手术室违规检测方面的表现的方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决多模态大语言模型在手术室环境中出现视觉与语义知识冲突的问题，即模型能够从文本规则理解安全违规，但在视觉检测中失效。

Method: 生成了包含34000多张由扩散模型生成的手术室合成图像数据集，其中包括违反安全规则的实体，通过精细标注和生成不同视角验证MLLMs的性能。进一步在人类标注的图像数据参考上对结果进行验证。

Result: 重训练后的MLLMs在应对已训练的矛盾实体和新的视角检测任务上性能显著提升，但对未训练的违规实体类型仍然表现较差，表明模型学习具有显著的专向性。

Conclusion: 该研究提出了一种创新性数据生成方法，公布了开放式的OR-VSKC数据集及其基准测试，并通过实验证实MLLMs存在知识一致性问题，呼吁未来的工作需要更加全面的训练。

Abstract: Surgical risk identification is critical for patient safety and reducing
preventable medical errors. While multimodal large language models (MLLMs) show
promise for automated operating room (OR) risk detection, they often exhibit
visual-semantic knowledge conflicts (VS-KC), failing to identify visual safety
violations despite understanding textual rules. To address this, we introduce a
dataset comprising over 34,000 synthetic images generated by diffusion models,
depicting operating room scenes containing entities that violate established
safety rules. These images were created to alleviate data scarcity and examine
MLLMs vulnerabilities. In addition, the dataset includes 214 human-annotated
images that serve as a gold-standard reference for validation. This
comprehensive dataset, spanning diverse perspectives, stages, and
configurations, is designed to expose and study VS-KC. Fine-tuning on OR-VSKC
significantly improves MLLMs' detection of trained conflict entities and
generalizes well to new viewpoints for these entities, but performance on
untrained entity types remains poor, highlighting learning specificity and the
need for comprehensive training. The main contributions of this work include:
(1) a data generation methodology tailored for rule-violation scenarios; (2)
the release of the OR-VSKC dataset and its associated benchmark as open-source
resources; and (3) an empirical analysis of violation-sensitive knowledge
consistency in representative MLLMs. The dataset and appendix are available at
https://github.com/zgg2577/VS-KC.

</details>


### [7] [How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?](https://arxiv.org/abs/2506.22501)
*Gautam Siddharth Kashyap,Manaswi Kulahara,Nipun Joshi,Usman Naseem*

Main category: cs.CV

TL;DR: 本文提出了一种新模型SpatialNet-ViT，结合了视觉Transformer (ViTs)和多任务学习（MTL），以提高遥感分类任务的准确性和扩展性。


<details>
  <summary>Details</summary>
Motivation: 目前的研究主要集中在单一任务或数据集，限制了模型在遥感分类任务中的普适性。

Method: 提出了结合Vision Transformers（ViTs）和多任务学习（MTL）的SpatialNet-ViT模型，并通过数据增强、迁移学习和多任务学习提升模型的鲁棒性和泛化能力。

Result: 新模型SpatialNet-ViT在多个遥感分类任务中均表现出更高的准确率和更好的扩展性。

Conclusion: 通过集成空间感知和语境理解，SpatialNet-ViT能够应对多样化的遥感数据集，使其适用于广泛的遥感分类任务。

Abstract: Remote sensing datasets offer significant promise for tackling key
classification tasks such as land-use categorization, object presence
detection, and rural/urban classification. However, many existing studies tend
to focus on narrow tasks or datasets, which limits their ability to generalize
across various remote sensing classification challenges. To overcome this, we
propose a novel model, SpatialNet-ViT, leveraging the power of Vision
Transformers (ViTs) and Multi-Task Learning (MTL). This integrated approach
combines spatial awareness with contextual understanding, improving both
classification accuracy and scalability. Additionally, techniques like data
augmentation, transfer learning, and multi-task learning are employed to
enhance model robustness and its ability to generalize across diverse datasets

</details>


### [8] [What Makes a Dribble Successful? Insights From 3D Pose Tracking Data](https://arxiv.org/abs/2506.22503)
*Michiel Schepers,Pieter Robberechts,Jan Van Haaren,Jesse Davis*

Main category: cs.CV

TL;DR: 本文研究结合三维姿态跟踪数据改进足球盘带能力的评估方法，发现姿态特征（例如平衡和方向对齐）能提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于2D位置跟踪数据的研究无法完全捕捉到盘带中的平衡、方向和控球能力等深层次特性。

Method: 通过分析2022/23赛季欧冠中的1,736次盘带数据，提取基于三维姿态跟踪的特征并将其用于建模分析。

Result: 姿态特征如攻击方的平衡性和攻防双方方向对齐度对预测盘带成功率具有显著作用，并能提高模型预测的准确性。

Conclusion: 将三维姿态特征融入现有数据分析框架可显著增强对足球盘带技术的洞察和评估深度。

Abstract: Data analysis plays an increasingly important role in soccer, offering new
ways to evaluate individual and team performance. One specific application is
the evaluation of dribbles: one-on-one situations where an attacker attempts to
bypass a defender with the ball. While previous research has primarily relied
on 2D positional tracking data, this fails to capture aspects like balance,
orientation, and ball control, limiting the depth of current insights. This
study explores how pose tracking data (capturing players' posture and movement
in three dimensions) can improve our understanding of dribbling skills. We
extract novel pose-based features from 1,736 dribbles in the 2022/23 Champions
League season and evaluate their impact on dribble success. Our results
indicate that features capturing the attacker's balance and the alignment of
the orientation between the attacker and defender are informative for
predicting dribble success. Incorporating these pose-based features on top of
features derived from traditional 2D positional data leads to a measurable
improvement in model performance.

</details>


### [9] [Patch2Loc: Learning to Localize Patches for Unsupervised Brain Lesion Detection](https://arxiv.org/abs/2506.22504)
*Hassan Baker,Austin J. Brockmeier*

Main category: cs.CV

TL;DR: 本文提出一种新的无监督方法Patch2Loc，用于通过学习正常脑组织的空间位置来检测MRI图像中的异常脑组织，并验证其在检测和分割脑肿瘤中的优越性能。


<details>
  <summary>Details</summary>
Motivation: MRI图像中的脑病变检测对诊断和治疗至关重要，需要借助计算机辅助诊断技术来提高对异常组织的分割和检测能力。

Method: 设计了一种新的无监督方法Patch2Loc，通过神经网络从MRI正常脑组织片段中学习其在脑体积切片中的空间位置，并利用预测误差或方差的高低确定异常片段，最终生成热图用于精细分割。

Result: 将该方法应用于BraTS2021、MSLUB、ATLAS和WMH数据集的T2和T1加权MRI图像，结果显示其在无监督分割中优于现有方法。

Conclusion: Patch2Loc方法在无监督脑病变检测和分割中表现出色，为MRI分析提供了一种创新路径。

Abstract: Detecting brain lesions as abnormalities observed in magnetic resonance
imaging (MRI) is essential for diagnosis and treatment. In the search of
abnormalities, such as tumors and malformations, radiologists may benefit from
computer-aided diagnostics that use computer vision systems trained with
machine learning to segment normal tissue from abnormal brain tissue. While
supervised learning methods require annotated lesions, we propose a new
unsupervised approach (Patch2Loc) that learns from normal patches taken from
structural MRI. We train a neural network model to map a patch back to its
spatial location within a slice of the brain volume. During inference, abnormal
patches are detected by the relatively higher error and/or variance of the
location prediction. This generates a heatmap that can be integrated into
pixel-wise methods to achieve finer-grained segmentation. We demonstrate the
ability of our model to segment abnormal brain tissues by applying our approach
to the detection of tumor tissues in MRI on T2-weighted images from BraTS2021
and MSLUB datasets and T1-weighted images from ATLAS and WMH datasets. We show
that it outperforms the state-of-the art in unsupervised segmentation. The
codebase for this work can be found on our
\href{https://github.com/bakerhassan/Patch2Loc}{GitHub page}.

</details>


### [10] [Weakly Supervised Object Segmentation by Background Conditional Divergence](https://arxiv.org/abs/2506.22505)
*Hassan Baker,Matthew S. Emigh,Austin J. Brockmeier*

Main category: cs.CV

TL;DR: 本文提出一种在弱监督条件下进行目标分割的方法，通过背景克隆和聚类等技术实现合成反事实背景的整合，有效改进了分割性能。


<details>
  <summary>Details</summary>
Motivation: 当前目标分割任务在没有大规模标注数据的情况下，特别是在合成孔径声呐、遥感、生物医学等专业影像领域，仍然面临很大挑战。像素级标记获取成本高昂，因此需要弱监督学习策略来降低人力成本。

Method: 提出一种基于弱监督的二值目标分割方法，利用目标存在与否的图像级标注，并通过将分割对象置于背景图片上生成具有反事实背景的对象图像。通过对背景图像进行聚类，形成对比学习，使目标对象在不同背景下的表现更加突显。此外，损失函数结合样本为基础的分布散度以及针对纯背景的监督损失进行优化。

Result: 本文在侧扫描和合成孔径声呐数据上实验表现出比以往无监督基准方法更好的分割效果，并在自然影像数据上验证了该方法的适用性，表现合理。

Conclusion: 该方法在无需预训练网络、生成网络及对抗审评器的情况下实现了高效的弱监督目标分割，具有一定的通用性与创新性。

Abstract: As a computer vision task, automatic object segmentation remains challenging
in specialized image domains without massive labeled data, such as synthetic
aperture sonar images, remote sensing, biomedical imaging, etc. In any domain,
obtaining pixel-wise segmentation masks is expensive. In this work, we propose
a method for training a masking network to perform binary object segmentation
using weak supervision in the form of image-wise presence or absence of an
object of interest, which provides less information but may be obtained more
quickly from manual or automatic labeling. A key step in our method is that the
segmented objects can be placed into background-only images to create
realistic, images of the objects with counterfactual backgrounds. To create a
contrast between the original and counterfactual background images, we propose
to first cluster the background-only images, and then during learning create
counterfactual images that blend objects segmented from their original source
backgrounds to backgrounds chosen from a targeted cluster. One term in the
training loss is the divergence between these counterfactual images and the
real object images with backgrounds of the target cluster. The other term is a
supervised loss for background-only images. While an adversarial critic could
provide the divergence, we use sample-based divergences. We conduct experiments
on side-scan and synthetic aperture sonar in which our approach succeeds
compared to previous unsupervised segmentation baselines that were only tested
on natural images. Furthermore, to show generality we extend our experiments to
natural images, obtaining reasonable performance with our method that avoids
pretrained networks, generative networks, and adversarial critics. The basecode
for this work can be found at
\href{GitHub}{https://github.com/bakerhassan/WSOS}.

</details>


### [11] [FreeDNA: Endowing Domain Adaptation of Diffusion-Based Dense Prediction with Training-Free Domain Noise Alignment](https://arxiv.org/abs/2506.22509)
*Hang Xu,Jie Huang,Linjiang Huang,Dong Li,Yidi Liu,Feng Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种名为 Domain Noise Alignment (DNA) 的无训练域适应方法，应用于扩散模型的密集预测任务，展示了在多个任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 作者观察到扩散模型中的噪声统计偏差导致了域迁移问题，并认为通过调整噪声统计可以实现域适应。

Method: 通过无训练的Domain Noise Alignment (DNA)方法，调整目标域的噪声统计以匹配源域，并通过高置信区域引导统计调整来处理无源域适应任务。

Result: 在四种常见的密集预测任务中，证明了该方法能有效提高扩散模型的域适应能力。

Conclusion: DNA方法无需额外训练，能够有效缓解扩散采样过程中噪声统计的域间变化问题，从而提升密集预测任务的域适应性能。

Abstract: Domain Adaptation(DA) for dense prediction tasks is an important topic, which
enhances the dense prediction model's performance when tested on its unseen
domain. Recently, with the development of Diffusion-based Dense Prediction
(DDP) models, the exploration of DA designs tailored to this framework is worth
exploring, since the diffusion model is effective in modeling the distribution
transformation that comprises domain information. In this work, we propose a
training-free mechanism for DDP frameworks, endowing them with DA capabilities.
Our motivation arises from the observation that the exposure bias (e.g., noise
statistics bias) in diffusion brings domain shift, and different domains in
conditions of DDP models can also be effectively captured by the noise
prediction statistics. Based on this, we propose a training-free Domain Noise
Alignment (DNA) approach, which alleviates the variations of noise statistics
to domain changes during the diffusion sampling process, thereby achieving
domain adaptation. Specifically, when the source domain is available, we
directly adopt the DNA method to achieve domain adaptation by aligning the
noise statistics of the target domain with those of the source domain. For the
more challenging source-free DA, inspired by the observation that regions
closer to the source domain exhibit higher confidence meeting variations of
sampling noise, we utilize the statistics from the high-confidence regions
progressively to guide the noise statistic adjustment during the sampling
process. Notably, our method demonstrates the effectiveness of enhancing the DA
capability of DDP models across four common dense prediction tasks. Code is
available at
\href{https://github.com/xuhang07/FreeDNA}{https://github.com/xuhang07/FreeDNA}.

</details>


### [12] [Lightning the Night with Generative Artificial Intelligence](https://arxiv.org/abs/2506.22511)
*Tingting Zhou,Feng Zhang,Haoyang Fu,Baoxiang Pan,Renhe Zhang,Feng Lu,Zhixin Yang*

Main category: cs.CV

TL;DR: 该研究开发了一种基于生成扩散模型的高精度夜间可见光反射率检索模型RefDiff，解决了夜间无法使用可见光反射率数据进行气象观察的问题。


<details>
  <summary>Details</summary>
Motivation: 因夜间无可见光，无法连续全天候利用可见光反射率数据进行气象观测。

Method: 通过从风云四号B气象卫星的热红外亮温数据构建生成扩散模型RefDiff，实现三波段夜间可见光反射率数据的精确检索，并能提供不确定性估计。

Result: RefDiff模型在夜间的SSIM指标达到了0.90，并且在复杂云结构或厚云区域的性能显著提高，其夜间检索能力经VIIRS的夜间产品验证，表现与白天相当。

Conclusion: 研究显著提升了夜间可见光反射率数据的检索能力，为夜间可见光数据的应用扩展提供了可能性。

Abstract: The visible light reflectance data from geostationary satellites is crucial
for meteorological observations and plays an important role in weather
monitoring and forecasting. However, due to the lack of visible light at night,
it is impossible to conduct continuous all-day weather observations using
visible light reflectance data. This study pioneers the use of generative
diffusion models to address this limitation. Based on the multi-band thermal
infrared brightness temperature data from the Advanced Geostationary Radiation
Imager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we
developed a high-precision visible light reflectance retrieval model, called
Reflectance Diffusion (RefDiff), which enables 0.47~\mu\mathrm{m},
0.65~\mu\mathrm{m}, and 0.825~\mu\mathrm{m} bands visible light reflectance
retrieval at night. Compared to the classical models, RefDiff not only
significantly improves accuracy through ensemble averaging but also provides
uncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90,
with particularly significant improvements in areas with complex cloud
structures and thick clouds. The model's nighttime retrieval capability was
validated using VIIRS nighttime product, demonstrating comparable performance
to its daytime counterpart. In summary, this research has made substantial
progress in the ability to retrieve visible light reflectance at night, with
the potential to expand the application of nighttime visible light data.

</details>


### [13] [Automated Defect Identification and Categorization in NDE 4.0 with the Application of Artificial Intelligence](https://arxiv.org/abs/2506.22513)
*Aditya Sharma*

Main category: cs.CV

TL;DR: 本研究提出一种自动化框架，用于现代射线检测中的缺陷检测和分类。通过对飞机焊接的223张CR图像进行数据扩增训练改进后的U-net模型，提高了识别缺陷的能力，验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决当前射线检测中虚拟缺陷增益不足、缺乏准确解释的信息问题，并试图通过NDE测量验证自动化框架的可行性。

Method: 通过收集223张飞机焊接的CR图像，采用虚拟缺陷增强与标准扩增等方法扩展训练数据，并训练改进的U-net模型以实现语义缺陷分割。同时使用NDE参数（如a90/95、测量精度、误报率）评估模型性能。

Result: 改进的U-net模型在缺陷检测的灵敏度上表现突出；结合的扩展方法在焊接区域的a90/95、尺寸误差和误报率指标上表现最佳。因推理速度快，该框架可高效处理大图像。

Conclusion: 该框架在专业领域得到了验证，能够很好地支持检测工作，并具有设备和编程兼容性，体现出广阔的应用前景。

Abstract: This investigation attempts to create an automated framework for fault
detection and organization for usage in contemporary radiography, as per NDE
4.0. The review's goals are to address the lack of information that is
sufficiently explained, learn how to make the most of virtual defect increase,
and determine whether the framework is viable by using NDE measurements. As its
basic information source, the technique consists of compiling and categorizing
223 CR photographs of airplane welds. Information expansion systems, such as
virtual defect increase and standard increase, are used to work on the
preparation dataset. A modified U-net model is prepared using the improved data
to produce semantic fault division veils. To assess the effectiveness of the
model, NDE boundaries such as Case, estimating exactness, and misleading call
rate are used. Tiny a90/95 characteristics, which provide strong
differentiating evidence of flaws, reveal that the suggested approach achieves
exceptional awareness in defect detection. Considering a 90/95, size error, and
fake call rate in the weld area, the consolidated expansion approach clearly
wins. Due to the framework's fast derivation speed, large images can be broken
down efficiently and quickly. Professional controllers evaluate the transmitted
system in the field and believe that it has a guarantee as a support device in
the testing cycle, irrespective of particular equipment cut-off points and
programming resemblance.

</details>


### [14] [Container damage detection using advanced computer vision model Yolov12 vs Yolov11 vs RF-DETR A comparative analysis](https://arxiv.org/abs/2506.22517)
*Subhadip Kumar*

Main category: cs.CV

TL;DR: 本文研究了三种先进计算机视觉模型（Yolov12、Yolov11和RF-DETR）在检测集装箱损坏上的表现，使用278张标注图像进行训练、验证和测试。


<details>
  <summary>Details</summary>
Motivation: 集装箱损坏会带来重大安全隐患和经济损失，因此对其进行及时检查和识别是延长集装箱使用寿命的重要手段。

Method: 对Yolov12、Yolov11和RF-DETR三种先进计算机视觉模型在278张标注的图像上进行训练、验证和测试，比较其mAP（平均精度均值）和精确度。

Result: Yolov11和12的mAP@50得分为81.9%，优于RF-DETR的77.7%；然而，在处理不常见损坏集装箱时，RF-DETR的表现优于其他模型，展现了更高的检测精确性。

Conclusion: RF-DETR模型在检测不常见损坏和具体损坏位置上表现优异，适合作为集装箱损坏检测的首选模型，需要根据具体使用场景选择模型。

Abstract: Containers are an integral part of the logistics industry and act as a
barrier for cargo. A typical service life for a container is more than 20
years. However, overtime containers suffer various types of damage due to the
mechanical as well as natural factors. A damaged container is a safety hazard
for the employees handling it and a liability for the logistic company.
Therefore, a timely inspection and detection of the damaged container is a key
for prolonging service life as well as avoiding safety hazards. In this paper,
we will compare the performance of the damage detection by three
state-of-the-art advanced computer vision models Yolov12, Yolov11 and RF-DETR.
We will use a dataset of 278 annotated images to train, validate and test the
model. We will compare the mAP and precision of the model. The objective of
this paper is to identify the model that is best suited for container damage
detection. The result is mixed. mAP@50 score of Yolov11 and 12 was 81.9%
compared to RF-DETR, which was 77.7%. However, while testing the model for
not-so-common damaged containers, the RF-DETR model outperformed the others
overall, exhibiting superiority to accurately detecting both damaged containers
as well as damage occurrences with high confidence.

</details>


### [15] [Preserve Anything: Controllable Image Synthesis with Object Preservation](https://arxiv.org/abs/2506.22531)
*Prasen Kumar Sharma,Neeraj Matiyali,Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

TL;DR: 提出了一种名为“Preserve Anything”的方法，用于解决文本到图像生成中的对象保留和语义一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在对象多样性、语义一致性和场景构图控制上存在不足。

Method: 采用N通道ControlNet框架，包括对象保留模块、背景引导模块和高频叠加模块，并利用一个新公开的数据集进行训练与评估。

Result: 显著提高特征空间保真度(FID 15.26)及语义对齐(CLIP-S 32.85)，实验和用户研究表明提升了生成图像的真实感和一致性等。

Conclusion: 该方法在对象保留和语义一致性方面显著优于现有技术，为文本到图像生成任务提供新的高效工具。

Abstract: We introduce \textit{Preserve Anything}, a novel method for controlled image
synthesis that addresses key limitations in object preservation and semantic
consistency in text-to-image (T2I) generation. Existing approaches often fail
(i) to preserve multiple objects with fidelity, (ii) maintain semantic
alignment with prompts, or (iii) provide explicit control over scene
composition. To overcome these challenges, the proposed method employs an
N-channel ControlNet that integrates (i) object preservation with size and
placement agnosticism, color and detail retention, and artifact elimination,
(ii) high-resolution, semantically consistent backgrounds with accurate
shadows, lighting, and prompt adherence, and (iii) explicit user control over
background layouts and lighting conditions. Key components of our framework
include object preservation and background guidance modules, enforcing lighting
consistency and a high-frequency overlay module to retain fine details while
mitigating unwanted artifacts. We introduce a benchmark dataset consisting of
240K natural images filtered for aesthetic quality and 18K 3D-rendered
synthetic images with metadata such as lighting, camera angles, and object
relationships. This dataset addresses the deficiencies of existing benchmarks
and allows a complete evaluation. Empirical results demonstrate that our method
achieves state-of-the-art performance, significantly improving feature-space
fidelity (FID 15.26) and semantic alignment (CLIP-S 32.85) while maintaining
competitive aesthetic quality. We also conducted a user study to demonstrate
the efficacy of the proposed work on unseen benchmark and observed a remarkable
improvement of $\sim25\%$, $\sim19\%$, $\sim13\%$, and $\sim14\%$ in terms of
prompt alignment, photorealism, the presence of AI artifacts, and natural
aesthetics over existing works.

</details>


### [16] [Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset](https://arxiv.org/abs/2506.22554)
*Vasu Agrawal,Akinniyi Akinyemi,Kathryn Alvero,Morteza Behrooz,Julia Buffalini,Fabio Maria Carlucci,Joy Chen,Junming Chen,Zhang Chen,Shiyang Cheng,Praveen Chowdary,Joe Chuang,Antony D'Avirro,Jon Daly,Ning Dong,Mark Duppenthaler,Cynthia Gao,Jeff Girard,Martin Gleize,Sahir Gomez,Hongyu Gong,Srivathsan Govindarajan,Brandon Han,Sen He,Denise Hernandez,Yordan Hristov,Rongjie Huang,Hirofumi Inaguma,Somya Jain,Raj Janardhan,Qingyao Jia,Christopher Klaiber,Dejan Kovachev,Moneish Kumar,Hang Li,Yilei Li,Pavel Litvin,Wei Liu,Guangyao Ma,Jing Ma,Martin Ma,Xutai Ma,Lucas Mantovani,Sagar Miglani,Sreyas Mohan,Louis-Philippe Morency,Evonne Ng,Kam-Woh Ng,Tu Anh Nguyen,Amia Oberai,Benjamin Peloquin,Juan Pino,Jovan Popovic,Omid Poursaeed,Fabian Prada,Alice Rakotoarison,Alexander Richard,Christophe Ropers,Safiyyah Saleem,Vasu Sharma,Alex Shcherbyna,Jia Shen,Jie Shen,Anastasis Stathopoulos,Anna Sun,Paden Tomasello,Tuan Tran,Arina Turkatenko,Bo Wan,Chao Wang,Jeff Wang,Mary Williamson,Carleigh Wood,Tao Xiang,Yilin Yang,Julien Yao,Chen Zhang,Jiemin Zhang,Xinyue Zhang,Jason Zheng,Pavlo Zhyzheria,Jan Zikes,Michael Zollhoefer*

Main category: cs.CV

TL;DR: 引入了一个大规模的面对面互动数据集，并开发了一系列模型可以生成符合人类对话的动作和表情，为人机交互提供可能性。


<details>
  <summary>Details</summary>
Motivation: 旨在推动社交智能AI的发展，通过理解和生成二元行为动态，改善人机交互技术。

Method: 引入包含4000小时互动录像的新数据集，开发支持生成同步人类手势和面部表情的模型，并加入控制选项以调整情绪反应和表达力度。

Result: 研发的模型能够以更自然的方式生成人类对话中协调的动态动作和面部表情，提升了虚拟代理的表现能力。

Conclusion: 这种以数据驱动的模型将为人机交互技术带来更直观、响应性强的发展方向。

Abstract: Human communication involves a complex interplay of verbal and nonverbal
signals, essential for conveying meaning and achieving interpersonal goals. To
develop socially intelligent AI technologies, it is crucial to develop models
that can both comprehend and generate dyadic behavioral dynamics. To this end,
we introduce the Seamless Interaction Dataset, a large-scale collection of over
4,000 hours of face-to-face interaction footage from over 4,000 participants in
diverse contexts. This dataset enables the development of AI technologies that
understand dyadic embodied dynamics, unlocking breakthroughs in virtual agents,
telepresence experiences, and multimodal content analysis tools. We also
develop a suite of models that utilize the dataset to generate dyadic motion
gestures and facial expressions aligned with human speech. These models can
take as input both the speech and visual behavior of their interlocutors. We
present a variant with speech from an LLM model and integrations with 2D and 3D
rendering methods, bringing us closer to interactive virtual agents.
Additionally, we describe controllable variants of our motion models that can
adapt emotional responses and expressivity levels, as well as generating more
semantically-relevant gestures. Finally, we discuss methods for assessing the
quality of these dyadic motion models, which are demonstrating the potential
for more intuitive and responsive human-AI interactions.

</details>


### [17] [Recomposed realities: animating still images via patch clustering and randomness](https://arxiv.org/abs/2506.22556)
*Markus Juvonen,Samuli Siltanen*

Main category: cs.CV

TL;DR: 提出了一种利用现有图像数据，将静态图片通过运动赋予生机的图像重建与动画方法。


<details>
  <summary>Details</summary>
Motivation: 希望通过图像局部结构与数据集匹配，实现原始采用图片与目标图片在概念上的差异性，并展示运动效果。

Method: 使用k均值聚类对数据集中的图片块分组，并通过匹配与随机采样重建目标图片，并用图像局部结构进行重新诠释实现动画。

Result: 实现了图像领域中将静态图片通过运动进行新的构想与表达。

Conclusion: 利用局部结构的匹配和重新诠释方法可以在图像动画化和跨域图像生成上取得进展。

Abstract: We present a patch-based image reconstruction and animation method that uses
existing image data to bring still images to life through motion. Image patches
from curated datasets are grouped using k-means clustering and a new target
image is reconstructed by matching and randomly sampling from these clusters.
This approach emphasizes reinterpretation over replication, allowing the source
and target domains to differ conceptually while sharing local structures.

</details>


### [18] [Improving Token-based Object Detection with Video](https://arxiv.org/abs/2506.22562)
*Abhineet Singh,Nilanjan Ray*

Main category: cs.CV

TL;DR: 本文通过将Pix2Seq从静态目标检测扩展到视频，提出了一种端到端的视频目标检测方法。它改进了现有视频检测器，并显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决常规检测器在训练过程中损失稀疏性和推理过程中基于启发式后处理的局限性，同时实现更高效的视频多目标跟踪。

Method: 使用可变长度序列离散令牌表示对象，省去传统检测器的框采样步骤。此外，通过3D框或轨迹的方式直接生成视频对象，而非逐帧生成再拼接成视频对象。

Result: 在多项数据集上与Pix2Seq及其他视频检测器进行了对比，结果显示方法有较大改进，并在UA-DETRAC数据集上与现有最先进方法具有竞争力。

Conclusion: 提出的方法无需额外的框采样及后处理、实现了高效的视频目标检测，且具备良好的性能及扩展性，代码与模型已公开。

Abstract: This paper improves upon the Pix2Seq object detector by extending it for
videos. In the process, it introduces a new way to perform end-to-end video
object detection that improves upon existing video detectors in two key ways.
First, by representing objects as variable-length sequences of discrete tokens,
we can succinctly represent widely varying numbers of video objects, with
diverse shapes and locations, without having to inject any localization cues in
the training process. This eliminates the need to sample the space of all
possible boxes that constrains conventional detectors and thus solves the dual
problems of loss sparsity during training and heuristics-based postprocessing
during inference. Second, it conceptualizes and outputs the video objects as
fully integrated and indivisible 3D boxes or tracklets instead of generating
image-specific 2D boxes and linking these boxes together to construct the video
object, as done in most conventional detectors. This allows it to scale
effortlessly with available computational resources by simply increasing the
length of the video subsequence that the network takes as input, even
generalizing to multi-object tracking if the subsequence can span the entire
video. We compare our video detector with the baseline Pix2Seq static detector
on several datasets and demonstrate consistent improvement, although with
strong signs of being bottlenecked by our limited computational resources. We
also compare it with several video detectors on UA-DETRAC to show that it is
competitive with the current state of the art even with the computational
bottleneck. We make our code and models publicly available.

</details>


### [19] [Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation](https://arxiv.org/abs/2506.22567)
*Shansong Wang,Zhecheng Jin,Mingzhe Hu,Mojtaba Safari,Feng Zhao,Chih-Wei Chang,Richard LJ Qiu,Justin Roper,David S. Yu,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 该论文提出通过多教师知识蒸馏构建医学领域通用基础模型MMKD-CLIP，并在多项任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 探讨如何在缺乏大规模医学图像-文本数据的情况下开发通用且强大的医学基础模型。

Method: 利用9个领域特定或通用医学CLIP模型进行知识蒸馏，分为预训练和特征蒸馏两个阶段，处理270多万对图像-文本数据及1920多万对特征数据。

Result: MMKD-CLIP在58个医学数据集、6种核心任务中均优于教师模型，表现出强大的稳健性与广泛适应性。

Conclusion: 多教师知识蒸馏是一种有效且可扩展的方法，可在现实数据条件下训练高性能医学基础模型。

Abstract: CLIP models pretrained on natural images with billion-scale image-text pairs
have demonstrated impressive capabilities in zero-shot classification,
cross-modal retrieval, and open-ended visual answering. However, transferring
this success to biomedicine is hindered by the scarcity of large-scale
biomedical image-text corpora, the heterogeneity of image modalities, and
fragmented data standards across institutions. These limitations hinder the
development of a unified and generalizable biomedical foundation model trained
from scratch. To overcome this, we introduce MMKD-CLIP, a generalist biomedical
foundation model developed via Multiple Medical CLIP Knowledge Distillation.
Rather than relying on billion-scale raw data, MMKD-CLIP distills knowledge
from nine state-of-the-art domain-specific or generalist biomedical CLIP
models, each pretrained on millions of biomedical image-text pairs. Our
two-stage training pipeline first performs CLIP-style pretraining on over 2.9
million biomedical image-text pairs from 26 image modalities, followed by
feature-level distillation using over 19.2 million feature pairs extracted from
teacher models. We evaluate MMKD-CLIP on 58 diverse biomedical datasets,
encompassing over 10.8 million biomedical images across nine image modalities.
The evaluation spans six core task types: zero-shot classification, linear
probing, cross-modal retrieval, visual question answering, survival prediction,
and cancer diagnosis. MMKD-CLIP consistently outperforms all teacher models
while demonstrating remarkable robustness and generalization across image
domains and task settings. These results underscore that multi-teacher
knowledge distillation is a scalable and effective paradigm for building
high-performing biomedical foundation models under the practical constraints of
real-world data availability.

</details>


### [20] [Dual Atrous Separable Convolution for Improving Agricultural Semantic Segmentation](https://arxiv.org/abs/2506.22570)
*Chee Mei Ling,Thangarajah Akilan,Aparna Ravinda Phalke*

Main category: cs.CV

TL;DR: 本研究提出了一种基于DeepLabV3的农用图像分割方法，通过结合创新的双扩张可分离卷积（DAS Conv）模块，显著提升了模型性能，同时保持较低的计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 旨在通过精准的农业图像语义分割提升作物管理和资源使用效率，优化现代农业生产力。

Method: 采用一种基于DeepLabV3的分割框架，并集成了精心设计的双扩张可分离卷积（DAS Conv）模块和优化的跳跃连接策略，从而平衡模型性能与效率。

Result: 相较于现有的复杂模型，该方法在农业视觉数据集上性能表现相当，同时效率提升超过66%。

Conclusion: 提出了一种高效的遥感应用解决方案，为农用图像语义分割提供了计算轻量化且性能优异的模型。

Abstract: Agricultural image semantic segmentation is a pivotal component of modern
agriculture, facilitating accurate visual data analysis to improve crop
management, optimize resource utilization, and boost overall productivity. This
study proposes an efficient image segmentation method for precision
agriculture, focusing on accurately delineating farmland anomalies to support
informed decision-making and proactive interventions. A novel Dual Atrous
Separable Convolution (DAS Conv) module is integrated within the
DeepLabV3-based segmentation framework. The DAS Conv module is meticulously
designed to achieve an optimal balance between dilation rates and padding size,
thereby enhancing model performance without compromising efficiency. The study
also incorporates a strategic skip connection from an optimal stage in the
encoder to the decoder to bolster the model's capacity to capture fine-grained
spatial features. Despite its lower computational complexity, the proposed
model outperforms its baseline and achieves performance comparable to highly
complex transformer-based state-of-the-art (SOTA) models on the Agriculture
Vision benchmark dataset. It achieves more than 66% improvement in efficiency
when considering the trade-off between model complexity and performance,
compared to the SOTA model. This study highlights an efficient and effective
solution for improving semantic segmentation in remote sensing applications,
offering a computationally lightweight model capable of high-quality
performance in agricultural imagery.

</details>


### [21] [LIGHT: Multi-Modal Text Linking on Historical Maps](https://arxiv.org/abs/2506.22589)
*Yijun Lin,Rhett Olson,Junhan Wu,Yao-Yi Chiang,Jerod Weinman*

Main category: cs.CV

TL;DR: 本文介绍了一个针对历史地图文字连接问题的多模态方法LIGHT，能够有效结合几何、图像和语言信息模型化文字关系，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理地图上的多词地名和文字关系分析时效果较差。地图文字的几何信息对提高识别和理解效果至关重要。

Method: 提出了一个名为LIGHT的新方法，结合了几何信息模块和现有的LayoutLMv3模型，通过多模态融合提高了对历史地图文字的顺序连接能力。

Result: 在ICDAR 2024/2025 MapText竞赛数据上的实验表明，LIGHT在文本连接任务中的性能优于现有方法，证明多模态学习的有效性。

Conclusion: LIGHT提供了一种解决历史地图文字关系建模的有效方法，为多词名的自动连接与理解提供了新的分析工具。

Abstract: Text on historical maps provides valuable information for studies in history,
economics, geography, and other related fields. Unlike structured or
semi-structured documents, text on maps varies significantly in orientation,
reading order, shape, and placement. Many modern methods can detect and
transcribe text regions, but they struggle to effectively ``link'' the
recognized text fragments, e.g., determining a multi-word place name. Existing
layout analysis methods model word relationships to improve text understanding
in structured documents, but they primarily rely on linguistic features and
neglect geometric information, which is essential for handling map text. To
address these challenges, we propose LIGHT, a novel multi-modal approach that
integrates linguistic, image, and geometric features for linking text on
historical maps. In particular, LIGHT includes a geometry-aware embedding
module that encodes the polygonal coordinates of text regions to capture
polygon shapes and their relative spatial positions on an image. LIGHT unifies
this geometric information with the visual and linguistic token embeddings from
LayoutLMv3, a pretrained layout analysis model. LIGHT uses the cross-modal
information to predict the reading-order successor of each text instance
directly with a bi-directional learning strategy that enhances sequence
robustness. Experimental results show that LIGHT outperforms existing methods
on the ICDAR 2024/2025 MapText Competition data, demonstrating the
effectiveness of multi-modal learning for historical map text linking.

</details>


### [22] [BrainMT: A Hybrid Mamba-Transformer Architecture for Modeling Long-Range Dependencies in Functional MRI Data](https://arxiv.org/abs/2506.22591)
*Arunkumar Kannan,Martin A. Lindquist,Brian Caffo*

Main category: cs.CV

TL;DR: 本文提出了BrainMT，一种用于fMRI数据分析的新型混合框架，能更有效地学习并整合空间和时间的长程关系，且性能领先于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前基于卷积神经网络或变压器架构的模型难以很好捕捉fMRI数据中的复杂空间和时间依赖性，这催生了设计新方法的需求。

Method: BrainMT采用一种两阶段框架：1）基于Mamba块和时间优先扫描机制捕捉全局时间交互；2）使用变压器块的自注意力机制建模深层特征的全局空间关系。

Result: 在UKBioBank和Human Connectome Project两个大规模公共数据集上的实验表明，BrainMT在分类和回归任务中的表现显著优于现有方法。

Conclusion: BrainMT成功解决了现有方法对fMRI数据的局限，并能广泛应用于神经影像学相关任务中。

Abstract: Recent advances in deep learning have made it possible to predict phenotypic
measures directly from functional magnetic resonance imaging (fMRI) brain
volumes, sparking significant interest in the neuroimaging community. However,
existing approaches, primarily based on convolutional neural networks or
transformer architectures, often struggle to model the complex relationships
inherent in fMRI data, limited by their inability to capture long-range spatial
and temporal dependencies. To overcome these shortcomings, we introduce
BrainMT, a novel hybrid framework designed to efficiently learn and integrate
long-range spatiotemporal attributes in fMRI data. Our framework operates in
two stages: (1) a bidirectional Mamba block with a temporal-first scanning
mechanism to capture global temporal interactions in a computationally
efficient manner; and (2) a transformer block leveraging self-attention to
model global spatial relationships across the deep features processed by the
Mamba block. Extensive experiments on two large-scale public datasets,
UKBioBank and the Human Connectome Project, demonstrate that BrainMT achieves
state-of-the-art performance on both classification (sex prediction) and
regression (cognitive intelligence prediction) tasks, outperforming existing
methods by a significant margin. Our code and implementation details will be
made publicly available at this
https://github.com/arunkumar-kannan/BrainMT-fMRI

</details>


### [23] [Seg-R1: Segmentation Can Be Surprisingly Simple with Reinforcement Learning](https://arxiv.org/abs/2506.22624)
*Zuyao You,Zuxuan Wu*

Main category: cs.CV

TL;DR: 提出Seg-R1，利用强化学习提升大型多模态模型的像素级理解与推理，专注于分割任务，并在无文本监督的情况下展现强大的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过强化学习提升多模态模型在像素级任务上的性能，尤其是在复杂的背景分割任务中。

Method: 通过强化学习策略（GRPO），让多模态模型生成点和边界框提示，并结合SAM生成分割掩膜，仅使用图像-掩膜对进行训练。

Result: Seg-R1在COD10K数据集上获得了.873的S-measure，并在无监督文本任务中展现了卓越的零样本分割性能。

Conclusion: Seg-R1展现强化学习在多模态像素推理中的潜力，尤其是在零样本任务中的强大泛化能力，为像素理解任务提供了更为简单高效的解决方案。

Abstract: We present Seg-R1, a preliminary exploration of using reinforcement learning
(RL) to enhance the pixel-level understanding and reasoning capabilities of
large multimodal models (LMMs). Starting with foreground segmentation tasks,
specifically camouflaged object detection (COD) and salient object detection
(SOD), our approach enables the LMM to generate point and bounding box prompts
in the next-token fashion, which are then used to guide SAM2 in producing
segmentation masks. We introduce Group Relative Policy Optimization (GRPO) into
the segmentation domain, equipping the LMM with pixel-level comprehension
through a carefully designed training strategy. Notably, Seg-R1 achieves
remarkable performance with purely RL-based training, achieving .873 S-measure
on COD10K without complex model modification. Moreover, we found that pure RL
training demonstrates strong open-world generalization. Despite being trained
solely on foreground segmentation image-mask pairs without text supervision,
Seg-R1 achieves impressive zero-shot performance on referring segmentation and
reasoning segmentation tasks, with 71.4 cIoU on RefCOCOg test and 56.7 gIoU on
ReasonSeg test, outperforming models fully supervised on these datasets.

</details>


### [24] [ReCo: Reminder Composition Mitigates Hallucinations in Vision-Language Models](https://arxiv.org/abs/2506.22636)
*Sotirios Panagiotis Chytas,Miso Choi,Hyunwoo J. Kim,Vikas Singh*

Main category: cs.CV

TL;DR: 本文探讨了视觉语言模型（VLMs）在消除视觉输入记忆衰减问题方面的改进方法，提出了一种轻量级模块（ReCo），可以显著减少虚假内容生成。


<details>
  <summary>Details</summary>
Motivation: 当前的VLMs在处理视觉和语言数据时表现出色，但容易产生幻觉，即生成与视觉输入不一致甚至矛盾的内容。这主要是由于VLMs在生成过程中对语言的过度依赖和视觉信息记忆衰退造成的。

Method: 作者提出在现有的VLMs上增加一个轻量级的可训练模块ReCo，受到几何代数及关系组合的启发，无需对模型做其他修改。

Result: 在三种广泛使用的VLMs（InstructBLIP、LlaVA、MiniGPT4）上验证了ReCo模块的有效性，显著提高在多个基准上的性能表现。同时表明该模块可与其他减少幻觉方法结合并进一步提升效果。

Conclusion: ReCo作为一种轻量级解决方案，不仅能减轻视觉输入记忆衰减问题，还能与现有方法结合提升VLM的性能，是一种切实可行的改进方法。

Abstract: Vision Language Models (VLMs) show impressive capabilities in integrating and
reasoning with both visual and language data. But these models make mistakes. A
common finding -- similar to LLMs -- is their tendency to hallucinate, i.e.,
generate plausible sounding text which is not grounded in the visual input, or
at worst, is contradictory. A growing consensus attributes this behavior to an
over-reliance on language -- especially as the generation progresses, the model
suffers from a ``fading memory effect'' with respect to the provided visual
input. We study mechanisms by which this behavior can be controlled.
Specifically, using ideas from geometric algebra and relational compositions,
we propose the addition of a small, trainable module (named ReCo) on top of any
VLM -- no other modification is needed. We show that such a lightweight module
is able to mitigate the fading memory effect on three of the most widely used
VLMs (InstructBLIP, LlaVA, MiniGPT4), where we see performance improvements on
multiple benchmarks. Additionally, we show that our module can be combined with
many of the other approaches for reducing hallucination where we achieve
improved results for each one.

</details>


### [25] [CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation](https://arxiv.org/abs/2506.22637)
*Haoxuan Wang,Zhenghao Zhao,Junyi Wu,Yuzhang Shang,Gaowen Liu,Yan Yan*

Main category: cs.CV

TL;DR: 提出了CaO$_2$，一种解决现有扩散模型数据集精炼不足问题的新框架，以更高效生成小数据集并提升大数据集表现。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在数据集精炼中忽略了评估过程，同时存在目标不一致和条件不一致两个主要问题。

Method: 提出了两阶段的CaO$_2$框架，通过概率导向的样本选择和潜在表示的优化提高条件和评估目标的一致性。

Result: 在ImageNet及其子集上达到了最先进的效果，平均超越现有最佳基准2.3%。

Conclusion: CaO$_2$提供了一种更对准评估目标的精炼方法，明显提升了大数据集的效率和准确性。

Abstract: The recent introduction of diffusion models in dataset distillation has shown
promising potential in creating compact surrogate datasets for large,
high-resolution target datasets, offering improved efficiency and performance
over traditional bi-level/uni-level optimization methods. However, current
diffusion-based dataset distillation approaches overlook the evaluation process
and exhibit two critical inconsistencies in the distillation process: (1)
Objective Inconsistency, where the distillation process diverges from the
evaluation objective, and (2) Condition Inconsistency, leading to mismatches
between generated images and their corresponding conditions. To resolve these
issues, we introduce Condition-aware Optimization with Objective-guided
Sampling (CaO$_2$), a two-stage diffusion-based framework that aligns the
distillation process with the evaluation objective. The first stage employs a
probability-informed sample selection pipeline, while the second stage refines
the corresponding latent representations to improve conditional likelihood.
CaO$_2$ achieves state-of-the-art performance on ImageNet and its subsets,
surpassing the best-performing baselines by an average of 2.3% accuracy.

</details>


### [26] [3D Shape Generation: A Survey](https://arxiv.org/abs/2506.22678)
*Nicolas Caytuiro,Ivan Sipiran*

Main category: cs.CV

TL;DR: 本文综述了3D形状生成领域的最新进展，涵盖形状表示、生成模型方法及评估协议，旨在为研究者和实践者提供参考。


<details>
  <summary>Details</summary>
Motivation: 本文试图总结和分析当前3D形状生成领域的研究现状，梳理核心技术、方法及挑战，为推动领域发展提供洞察。

Method: 文章从形状表示、生成方法和评估协议三个维度详细分析，将形状表示分为显式、隐式和混合，讨论其优缺点，重点介绍前馈架构的生成方法，并总结了常用数据集和评估指标。

Result: 本文系统性地归纳了3D形状生成的关键技术、方法及评估标准，揭示了领域中仍待解决的问题。

Conclusion: 通过梳理当前技术与方法，文章指出了未来可研究方向，为提升3D形状生成的可控性、效率和质量提供了建议。

Abstract: Recent advances in deep learning have significantly transformed the field of
3D shape generation, enabling the synthesis of complex, diverse, and
semantically meaningful 3D objects. This survey provides a comprehensive
overview of the current state of the art in 3D shape generation, organizing the
discussion around three core components: shape representations, generative
modeling approaches, and evaluation protocols. We begin by categorizing 3D
representations into explicit, implicit, and hybrid setups, highlighting their
structural properties, advantages, and limitations. Next, we review a wide
range of generation methods, focusing on feedforward architectures. We further
summarize commonly used datasets and evaluation metrics that assess fidelity,
diversity, and realism of generated shapes. Finally, we identify open
challenges and outline future research directions that could drive progress in
controllable, efficient, and high-quality 3D shape generation. This survey aims
to serve as a valuable reference for researchers and practitioners seeking a
structured and in-depth understanding of this rapidly evolving field.

</details>


### [27] [LightBSR: Towards Lightweight Blind Super-Resolution via Discriminative Implicit Degradation Representation Learning](https://arxiv.org/abs/2506.22710)
*Jiang Yuan,JI Ma,Bo Wang,Guanzhou Ke,Weiming Hu*

Main category: cs.CV

TL;DR: 本研究提出了一种轻量级的盲超分辨率模型LightBSR，通过优化隐式退化表示（IDR）的可区分性，提升其在复杂退化下的表现和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的隐式退化估计方法过于注重适配过程，导致模型复杂且计算成本高，忽视了IDR可区分性的重要性。

Method: 使用知识蒸馏学习框架，包含退化先验约束对比学习阶段以及特征对齐技术，将退化相关知识从教师模型传递给学生模型。

Result: 实验验证表明，LightBSR在多种盲超分辨率任务中能以较低的复杂度实现出色的性能。

Conclusion: 优化IDR可区分性是一种高效的盲超分辨率设计方法，LightBSR证明了较低计算复杂度模型的潜力。

Abstract: Implicit degradation estimation-based blind super-resolution (IDE-BSR) hinges
on extracting the implicit degradation representation (IDR) of the LR image and
adapting it to LR image features to guide HR detail restoration. Although
IDE-BSR has shown potential in dealing with noise interference and complex
degradations, existing methods ignore the importance of IDR discriminability
for BSR and instead over-complicate the adaptation process to improve effect,
resulting in a significant increase in the model's parameters and computations.
In this paper, we focus on the discriminability optimization of IDR and propose
a new powerful and lightweight BSR model termed LightBSR. Specifically, we
employ a knowledge distillation-based learning framework. We first introduce a
well-designed degradation-prior-constrained contrastive learning technique
during teacher stage to make the model more focused on distinguishing different
degradation types. Then we utilize a feature alignment technique to transfer
the degradation-related knowledge acquired by the teacher to the student for
practical inferencing. Extensive experiments demonstrate the effectiveness of
IDR discriminability-driven BSR model design. The proposed LightBSR can achieve
outstanding performance with minimal complexity across a range of blind SR
tasks. Our code is accessible at: https://github.com/MJ-NCEPU/LightBSR.

</details>


### [28] [Part Segmentation and Motion Estimation for Articulated Objects with Dynamic 3D Gaussians](https://arxiv.org/abs/2506.22718)
*Jun-Jee Chao,Qingyuan Jiang,Volkan Isler*

Main category: cs.CV

TL;DR: 本文提出了一种方法，用于从单个关节物体的点云序列中同时解决部分分割和运动估计问题，方法通过构造基于3D高斯的紧凑表示来实现，在存在部分缺失和遮挡的场景下表现尤为优异。


<details>
  <summary>Details</summary>
Motivation: 目前很多针对关节物体运动分析的方法依赖点对应关系，然而在点云序列中由于遮挡或异步采集导致点集变化时，这些方法无法适用，亟需新的解决方法。

Method: 文章提出一种基于3D高斯集合的表示方法，将物体表示为一组简单构建模块并用时间相关的平移、旋转和缩放参数化，无需依赖点对应关系，同时实现物体的部分分割和运动跟踪任务。

Result: 实验表明，在多视角遮挡和部分缺失的场景中，本文方法在分割性能上比当前最优方法提升了13%，并且在点损失严重的情况下仍表现出较高的鲁棒性。

Conclusion: 通过构建新的表示模型，本文方法成功地解决了无固定点对应关系的复杂点云序列的部分分割和运动估计问题，并在实际复杂场景中展现了卓越的优势。

Abstract: Part segmentation and motion estimation are two fundamental problems for
articulated object motion analysis. In this paper, we present a method to solve
these two problems jointly from a sequence of observed point clouds of a single
articulated object. The main challenge in our problem setting is that the point
clouds are not assumed to be generated by a fixed set of moving points.
Instead, each point cloud in the sequence could be an arbitrary sampling of the
object surface at that particular time step. Such scenarios occur when the
object undergoes major occlusions, or if the dataset is collected using
measurements from multiple sensors asynchronously. In these scenarios, methods
that rely on tracking point correspondences are not appropriate. We present an
alternative approach based on a compact but effective representation where we
represent the object as a collection of simple building blocks modeled as 3D
Gaussians. We parameterize the Gaussians with time-dependent rotations,
translations, and scales that are shared across all time steps. With our
representation, part segmentation can be achieved by building correspondences
between the observed points and the Gaussians. Moreover, the transformation of
each point across time can be obtained by following the poses of the assigned
Gaussian (even when the point is not observed). Experiments show that our
method outperforms existing methods that solely rely on finding point
correspondences. Additionally, we extend existing datasets to emulate
real-world scenarios by considering viewpoint occlusions. We further
demonstrate that our method is more robust to missing points as compared to
existing approaches on these challenging datasets, even when some parts are
completely occluded in some time-steps. Notably, our part segmentation
performance outperforms the state-of-the-art method by 13% on point clouds with
occlusions.

</details>


### [29] [Deterministic Object Pose Confidence Region Estimation](https://arxiv.org/abs/2506.22720)
*Jinghao Wang,Zhang Li,Zi Wang,Banglei Guan,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出一种确定性高效的方法，利用归纳符合预测和隐函数定理，将2D关键点信赖区域传播到6D位姿信赖区域，从而替代现有采样方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有采样方法速度随采样数量增加而降低，以及信赖区域过大的问题。

Method: 通过归纳符合预测校准确定性回归高斯关键点分布，利用隐函数定理将2D关键点信赖区域映射到6D位姿信赖区域。

Result: 在LineMOD Occlusion和SPEED数据集上实现了更高的位姿估计精度，并显著减少计算时间，信赖区域体积在旋转和平移上分别减少至99.9%和99.8%。

Conclusion: 该方法提供紧凑的信赖区域，覆盖真实位姿，避免了采样导致的低效和过大信赖区域问题，同时显著提升效率和精度。

Abstract: 6D pose confidence region estimation has emerged as a critical direction,
aiming to perform uncertainty quantification for assessing the reliability of
estimated poses. However, current sampling-based approach suffers from critical
limitations that severely impede their practical deployment: 1) the sampling
speed significantly decreases as the number of samples increases. 2) the
derived confidence regions are often excessively large. To address these
challenges, we propose a deterministic and efficient method for estimating pose
confidence regions. Our approach uses inductive conformal prediction to
calibrate the deterministically regressed Gaussian keypoint distributions into
2D keypoint confidence regions. We then leverage the implicit function theorem
to propagate these keypoint confidence regions directly into 6D pose confidence
regions. This method avoids the inefficiency and inflated region sizes
associated with sampling and ensembling. It provides compact confidence regions
that cover the ground-truth poses with a user-defined confidence level.
Experimental results on the LineMOD Occlusion and SPEED datasets show that our
method achieves higher pose estimation accuracy with reduced computational
time. For the same coverage rate, our method yields significantly smaller
confidence region volumes, reducing them by up to 99.9\% for rotations and
99.8\% for translations. The code will be available soon.

</details>


### [30] [XTransfer: Cross-Modality Model Transfer for Human Sensing with Few Data at the Edge](https://arxiv.org/abs/2506.22726)
*Yu Zhang,Xi Zhang,Hualin zhou,Xinyuan Chen,Shang Gao,Hong Jia,Jianfei Yang,Yuankai Qi,Tao Gu*

Main category: cs.CV

TL;DR: 本文探讨了在边缘系统上利用深度学习进行人类感知的挑战，提出了一种称为XTransfer的新方法，旨在解决资源受限和模态转移问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将预训练模型转移至边缘系统时，存在模态转移、资源需求高、跨感知应用适应性差的问题，阻碍了人类感知任务在资源受限环境中的实现。

Method: 提出XTransfer方法，通过(i)模型修复以小量传感器数据安全修复模态转移，以及(ii)层重组高效搜索与重组源模型中感兴趣的层，生成高效紧凑的模型。

Result: 对不同模态的人类感知数据集进行测试，证明XTransfer在降低传感器数据收集、模型训练与边缘部署的成本的同时，实现了人类感知任务的最先进性能。

Conclusion: XTransfer提供了一种资源高效且模态无关的模型转移方法，为边缘系统上的深度学习人类感知任务带来了前所未有的效果和适应性。

Abstract: Deep learning for human sensing on edge systems offers significant
opportunities for smart applications. However, its training and development are
hindered by the limited availability of sensor data and resource constraints of
edge systems. Current methods that rely on transferring pre-trained models
often encounter issues such as modality shift and high resource demands,
resulting in substantial accuracy loss, resource overhead, and poor
adaptability across different sensing applications. In this paper, we propose
XTransfer, a first-of-its-kind method for resource-efficient, modality-agnostic
model transfer. XTransfer freely leverages single or multiple pre-trained
models and transfers knowledge across different modalities by (i) model
repairing that safely repairs modality shift in pre-trained model layers with
only few sensor data, and (ii) layer recombining that efficiently searches and
recombines layers of interest from source models in a layer-wise manner to
create compact models. We benchmark various baselines across diverse human
sensing datasets spanning different modalities. Comprehensive results
demonstrate that XTransfer achieves state-of-the-art performance on human
sensing tasks while significantly reducing the costs of sensor data collection,
model training, and edge deployment.

</details>


### [31] [UniFuse: A Unified All-in-One Framework for Multi-Modal Medical Image Fusion Under Diverse Degradations and Misalignments](https://arxiv.org/abs/2506.22736)
*Dayong Su,Yafei Zhang,Huafeng Li,Jinxing Li,Yu Liu*

Main category: cs.CV

TL;DR: UniFuse是一种应对医学图像对齐和质量退化问题的通用框架，实现了图像对齐、修复和融合的统一优化。


<details>
  <summary>Details</summary>
Motivation: 现有多模态医学图像融合方法依赖高质量与像素级对齐的输入图像，在处理未对齐或退化的图像时性能下降。

Method: 提出UniFuse框架，结合降解感知的提示学习模块、Omni统一特征表示方案，以及基于LoRA的自适应LoRA协作网络进行联合优化。

Result: 实验结果表明，UniFuse在多个数据集上相较现有方法表现出显著优势。

Conclusion: UniFuse通过单阶段框架成功实现了医学图像跨模态对齐、修复和融合的统一优化。

Abstract: Current multimodal medical image fusion typically assumes that source images
are of high quality and perfectly aligned at the pixel level. Its effectiveness
heavily relies on these conditions and often deteriorates when handling
misaligned or degraded medical images. To address this, we propose UniFuse, a
general fusion framework. By embedding a degradation-aware prompt learning
module, UniFuse seamlessly integrates multi-directional information from input
images and correlates cross-modal alignment with restoration, enabling joint
optimization of both tasks within a unified framework. Additionally, we design
an Omni Unified Feature Representation scheme, which leverages Spatial Mamba to
encode multi-directional features and mitigate modality differences in feature
alignment. To enable simultaneous restoration and fusion within an All-in-One
configuration, we propose a Universal Feature Restoration & Fusion module,
incorporating the Adaptive LoRA Synergistic Network (ALSN) based on LoRA
principles. By leveraging ALSN's adaptive feature representation along with
degradation-type guidance, we enable joint restoration and fusion within a
single-stage framework. Compared to staged approaches, UniFuse unifies
alignment, restoration, and fusion within a single framework. Experimental
results across multiple datasets demonstrate the method's effectiveness and
significant advantages over existing approaches.

</details>


### [32] [Deep Learning based Joint Geometry and Attribute Up-sampling for Large-Scale Colored Point Clouds](https://arxiv.org/abs/2506.22749)
*Yun Zhang,Feifan Chen,Na Li,Zhiwei Guo,Xu Wang,Fen Miao,Sam Kwong*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的联合几何和属性上采样（JGAU）方法，用于生成大规模和更密集的彩色点云，并提供了相关数据集和实验结果，表明其在四种不同上采样率下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前彩色点云在生成高质量、大规模和密集的点云时存在挑战，因此需要一种有效方法来同时建模几何和属性特征，并利用空间属性相关性。

Method: 提出了一种JGAU框架，包括几何上采样网络和属性上采样网络，其中属性网络通过辅助几何信息建模。引入GDWAI和DLAI两种粗略属性上采样方法，并结合属性增强模块来优化点云质量。此外，还发布了大规模数据集SYSU-PCUD。

Result: 实验表明，在四种上采样率（4倍、8倍、12倍和16倍）下，JGAU方法的PSNR分别达到33.90dB、32.10dB、31.10dB和30.39dB，比现有方法平均提升了2.32dB、2.47dB、2.28dB和2.11dB。

Conclusion: 提出的JGAU方法显著提高了上采样点云的质量，展示了在几何和属性联合上采样任务中的优势，具有实际应用潜力。

Abstract: Colored point cloud, which includes geometry and attribute components, is a
mainstream representation enabling realistic and immersive 3D applications. To
generate large-scale and denser colored point clouds, we propose a deep
learning-based Joint Geometry and Attribute Up-sampling (JGAU) method that
learns to model both geometry and attribute patterns while leveraging spatial
attribute correlations. First, we establish and release a large-scale dataset
for colored point cloud up-sampling called SYSU-PCUD, containing 121
large-scale colored point clouds with diverse geometry and attribute
complexities across six categories and four sampling rates. Second, to improve
the quality of up-sampled point clouds, we propose a deep learning-based JGAU
framework that jointly up-samples geometry and attributes. It consists of a
geometry up-sampling network and an attribute up-sampling network, where the
latter leverages the up-sampled auxiliary geometry to model neighborhood
correlations of the attributes. Third, we propose two coarse attribute
up-sampling methods, Geometric Distance Weighted Attribute Interpolation
(GDWAI) and Deep Learning-based Attribute Interpolation (DLAI), to generate
coarse up-sampled attributes for each point. Then, an attribute enhancement
module is introduced to refine these up-sampled attributes and produce
high-quality point clouds by further exploiting intrinsic attribute and
geometry patterns. Extensive experiments show that the Peak Signal-to-Noise
Ratio (PSNR) achieved by the proposed JGAU method is 33.90 decibels, 32.10
decibels, 31.10 decibels, and 30.39 decibels for up-sampling rates of 4 times,
8 times, 12 times, and 16 times, respectively. Compared to state-of-the-art
methods, JGAU achieves average PSNR gains of 2.32 decibels, 2.47 decibels, 2.28
decibels, and 2.11 decibels at these four up-sampling rates, demonstrating
significant improvement.

</details>


### [33] [Degradation-Modeled Multipath Diffusion for Tunable Metalens Photography](https://arxiv.org/abs/2506.22753)
*Jianing Zhang,Jiayi Zhu,Feiyu Ji,Xiaokang Yang,Xiaoyun Yuan*

Main category: cs.CV

TL;DR: 本文提出了一种基于退化建模和多路径扩散的金属透镜摄影方法，实现了超小型计算成像设备的高保真图像重建。


<details>
  <summary>Details</summary>
Motivation: 金属透镜具有潜力应用于超紧凑计算成像，但受到复杂光学退化和计算恢复的挑战。作者希望克服现有方法依赖精密校准或大量配对数据的限制，同时解决恢复过程中易产生幻象伪影的问题。

Method: 提出了一种结合正/中/负路径提示的框架，利用预训练模型的自然图像先验代替大型数据集；引入可调解码器以实现保真度和感知质量的平衡；设计一种空间退化感知注意力(SVDA)模块，适应复杂的光学和传感器引起的退化；并构建毫米级真实Meta相机用于验证。

Result: 该方法在图像细节保持、结构完整性和退化抑制方面优于现有方法，并实现了高保真和清晰的图像重建性能。

Conclusion: 所提方法通过精准建模和优化的计算框架，显著提升了金属透镜摄影的效果，为实际应用和设备开发提供了新范式。

Abstract: Metalenses offer significant potential for ultra-compact computational
imaging but face challenges from complex optical degradation and computational
restoration difficulties. Existing methods typically rely on precise optical
calibration or massive paired datasets, which are non-trivial for real-world
imaging systems. Furthermore, a lack of control over the inference process
often results in undesirable hallucinated artifacts. We introduce
Degradation-Modeled Multipath Diffusion for tunable metalens photography,
leveraging powerful natural image priors from pretrained models instead of
large datasets. Our framework uses positive, neutral, and negative-prompt paths
to balance high-frequency detail generation, structural fidelity, and
suppression of metalens-specific degradation, alongside \textit{pseudo} data
augmentation. A tunable decoder enables controlled trade-offs between fidelity
and perceptual quality. Additionally, a spatially varying degradation-aware
attention (SVDA) module adaptively models complex optical and sensor-induced
degradation. Finally, we design and build a millimeter-scale MetaCamera for
real-world validation. Extensive results show that our approach outperforms
state-of-the-art methods, achieving high-fidelity and sharp image
reconstruction. More materials: https://dmdiff.github.io/.

</details>


### [34] [RoboPearls: Editable Video Simulation for Robot Manipulation](https://arxiv.org/abs/2506.22756)
*Tao Tang,Likui Zhang,Youpeng Wen,Kaidong Zhang,Jia-Wang Bian,xia zhou,Tianyi Yan,Kun Zhan,Peng Jia,Hefeng Wu,Liang Lin,Xiaodan Liang*

Main category: cs.CV

TL;DR: 本文提出了一个名为RoboPearls的可编辑视频仿真框架，以解决机器人操作中的数据采集成本高及仿真与现实差距问题。


<details>
  <summary>Details</summary>
Motivation: 机器人操作中需要大量的真实演示数据，而实际收集这些数据成本高且效率低。现有的仿真平台虽提供了受控环境，但面临仿真与现实应用之间的差距等挑战。

Method: 采用基于3D高斯散点技术（3DGS）的可编辑视频仿真框架RoboPearls，从演示视频构建逼真的仿真场景。框架支持多种仿真操作，结合大语言模型（LLMs）和视觉语言模型（VLM）自动化生产和优化性能，并使用模块如增量语义蒸馏（ISD）和3D正则化损失（3D-NNFM）。

Result: 通过RLBench、COLOSSEUM、Ego4D等多个数据集和场景及真实机器人实验，表明RoboPearls在仿真性能上的良好效果。

Conclusion: RoboPearls提升了机器人操作系统的数据生成效率与仿真性能，为解决仿真与现实之间的差距提供了新思路。

Abstract: The development of generalist robot manipulation policies has seen
significant progress, driven by large-scale demonstration data across diverse
environments. However, the high cost and inefficiency of collecting real-world
demonstrations hinder the scalability of data acquisition. While existing
simulation platforms enable controlled environments for robotic learning, the
challenge of bridging the sim-to-real gap remains. To address these challenges,
we propose RoboPearls, an editable video simulation framework for robotic
manipulation. Built on 3D Gaussian Splatting (3DGS), RoboPearls enables the
construction of photo-realistic, view-consistent simulations from demonstration
videos, and supports a wide range of simulation operators, including various
object manipulations, powered by advanced modules like Incremental Semantic
Distillation (ISD) and 3D regularized NNFM Loss (3D-NNFM). Moreover, by
incorporating large language models (LLMs), RoboPearls automates the simulation
production process in a user-friendly manner through flexible command
interpretation and execution. Furthermore, RoboPearls employs a vision-language
model (VLM) to analyze robotic learning issues to close the simulation loop for
performance enhancement. To demonstrate the effectiveness of RoboPearls, we
conduct extensive experiments on multiple datasets and scenes, including
RLBench, COLOSSEUM, Ego4D, Open X-Embodiment, and a real-world robot, which
demonstrate our satisfactory simulation performance.

</details>


### [35] [VSRM: A Robust Mamba-Based Framework for Video Super-Resolution](https://arxiv.org/abs/2506.22762)
*Dinh Phu Tran,Dao Duy Hung,Daeyoung Kim*

Main category: cs.CV

TL;DR: 本文提出了一个名为VSRM的视频超分辨率框架，利用Mamba的优势，实现了高效的感受野增加和长时序建模，相比现有方法取得了卓越的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的视频超分辨率方法面临CNN局限于局部感受野和Transformer计算量随序列长度呈平方增长的问题。作者希望提出一种新方法，能够高效处理长序列并提升视觉质量。

Method: VSRM框架引入了基于Mamba的长范围空间-时间特征提取模块，并设计了可变形交叉对齐模块，动态调整相邻帧的特征补偿。此外，通过优化频率域的损失函数来增强高频信息的保留。

Result: 在多个基准上进行大量实验，VSRM取得了最先进的性能。

Conclusion: VSRM充分利用Mamba特性，提出了多项新设计，对视频超分辨率任务具有重要参考意义，为未来研究奠定基础。

Abstract: Video super-resolution remains a major challenge in low-level vision tasks.
To date, CNN- and Transformer-based methods have delivered impressive results.
However, CNNs are limited by local receptive fields, while Transformers
struggle with quadratic complexity, posing challenges for processing long
sequences in VSR. Recently, Mamba has drawn attention for its long-sequence
modeling, linear complexity, and large receptive fields. In this work, we
propose VSRM, a novel \textbf{V}ideo \textbf{S}uper-\textbf{R}esolution
framework that leverages the power of \textbf{M}amba. VSRM introduces
Spatial-to-Temporal Mamba and Temporal-to-Spatial Mamba blocks to extract
long-range spatio-temporal features and enhance receptive fields efficiently.
To better align adjacent frames, we propose Deformable Cross-Mamba Alignment
module. This module utilizes a deformable cross-mamba mechanism to make the
compensation stage more dynamic and flexible, preventing feature distortions.
Finally, we minimize the frequency domain gaps between reconstructed and
ground-truth frames by proposing a simple yet effective Frequency
Charbonnier-like loss that better preserves high-frequency content and enhances
visual quality. Through extensive experiments, VSRM achieves state-of-the-art
results on diverse benchmarks, establishing itself as a solid foundation for
future research.

</details>


### [36] [PhonemeFake: Redefining Deepfake Realism with Language-Driven Segmental Manipulation and Adaptive Bilevel Detection](https://arxiv.org/abs/2506.22783)
*Oguzhan Baser,Ahmet Ege Tanriverdi,Sriram Vishwanath,Sandeep P. Chinchali*

Main category: cs.CV

TL;DR: 提出了一种名为PhonemeFake (PF)的新型Deepfake攻击方法，通过操纵关键语音片段以增强攻击隐蔽性，并提供开源数据集和检测模型。


<details>
  <summary>Details</summary>
Motivation: 现有Deepfake数据集和检测技术难以有效欺骗人类感知，对现实场景中Deepfake攻击威胁的反应不足。

Method: 设计了一种PhonemeFake (PF)攻击方法，通过语言推理操纵语音中的关键音素段；同时开发了开源的双层检测模型，优先计算被操纵的区域。

Result: 在三个现有的数据集上，PF攻击显著降低了人类感知精度42%和基准检测准确性94%。检测模型将EER降低了91%，并实现了高达90%的计算加速，同时实现精确的操纵区域定位。

Conclusion: 该方法提供了一种可拓展的解决方案，能够高效检测更隐蔽的Deepfake攻击，提升了Deepfake检测的实用性和效率，为未来相关研究提供了基础。

Abstract: Deepfake (DF) attacks pose a growing threat as generative models become
increasingly advanced. However, our study reveals that existing DF datasets
fail to deceive human perception, unlike real DF attacks that influence public
discourse. It highlights the need for more realistic DF attack vectors. We
introduce PhonemeFake (PF), a DF attack that manipulates critical speech
segments using language reasoning, significantly reducing human perception by
up to 42% and benchmark accuracies by up to 94%. We release an easy-to-use PF
dataset on HuggingFace and open-source bilevel DF segment detection model that
adaptively prioritizes compute on manipulated regions. Our extensive
experiments across three known DF datasets reveal that our detection model
reduces EER by 91% while achieving up to 90% speed-up, with minimal compute
overhead and precise localization beyond existing models as a scalable
solution.

</details>


### [37] [Single-Frame Point-Pixel Registration via Supervised Cross-Modal Feature Matching](https://arxiv.org/abs/2506.22784)
*Yu Han,Zhiwei Huang,Yanting Zhang,Fangjun Ding,Shen Cai,Rui Fan*

Main category: cs.CV

TL;DR: 该论文提出了一种无检测器框架，用于直接点像素匹配，在稀疏单帧LiDAR数据上实现了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决LiDAR点云和相机图像之间的模态差距，特别是在稀疏单帧LiDAR设置下的困难。

Method: 提出一种基于投影的无检测器方法，将LiDAR强度图投影到2D视图，并输入到基于注意力的无检测器匹配网络，同时引入重复性评分机制以增强匹配可靠性。

Result: 在KITTI、nuScenes和MIAS-LCEC-TF70数据上的实验表明，该方法取得了最先进的性能，即使在单帧LiDAR的情况下也优于依赖累积点云的方法。

Conclusion: 该方法能够在单帧LiDAR数据的情况下有效地实现点像素匹配，具有高度的鲁棒性和性能优势。

Abstract: Point-pixel registration between LiDAR point clouds and camera images is a
fundamental yet challenging task in autonomous driving and robotic perception.
A key difficulty lies in the modality gap between unstructured point clouds and
structured images, especially under sparse single-frame LiDAR settings.
Existing methods typically extract features separately from point clouds and
images, then rely on hand-crafted or learned matching strategies. This separate
encoding fails to bridge the modality gap effectively, and more critically,
these methods struggle with the sparsity and noise of single-frame LiDAR, often
requiring point cloud accumulation or additional priors to improve reliability.
Inspired by recent progress in detector-free matching paradigms (e.g.
MatchAnything), we revisit the projection-based approach and introduce the
detector-free framework for direct point-pixel matching between LiDAR and
camera views. Specifically, we project the LiDAR intensity map into a 2D view
from the LiDAR perspective and feed it into an attention-based detector-free
matching network, enabling cross-modal correspondence estimation without
relying on multi-frame accumulation. To further enhance matching reliability,
we introduce a repeatability scoring mechanism that acts as a soft visibility
prior. This guides the network to suppress unreliable matches in regions with
low intensity variation, improving robustness under sparse input. Extensive
experiments on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks demonstrate that
our method achieves state-of-the-art performance, outperforming prior
approaches on nuScenes (even those relying on accumulated point clouds),
despite using only single-frame LiDAR.

</details>


### [38] [RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via Diffusion Priors](https://arxiv.org/abs/2506.22800)
*Sicong Du,Jiarun Liu,Qifeng Chen,Hao-Xiang Chen,Tai-Jiang Mu,Sheng Yang*

Main category: cs.CV

TL;DR: 提出了RGE-GS框架以解决单次驾驶场景扫描不足的问题，通过奖励引导高斯整合与扩散生成结合，提高重构质量。


<details>
  <summary>Details</summary>
Motivation: 传统3D高斯溅射技术虽然重建质量高，但加入扩散生成时常产生物理不一致性及训练效率问题，因此需要改进重建方法以应对单次驾驶场景扫描的不足。

Method: 引入固定生成模式奖励网络用于选择性保留扩散输出，并采用动态调整高斯优化进度的训练策略提高场景重构收敛性和质量。

Result: 对公开数据集的大量评估证明，RGE-GS在重构质量方面达到了最先进的性能。

Conclusion: 基于奖励引导和创新训练策略的RGE-GS框架为单次驾驶场景扩展和高质量场景重构提供了一种有效解决方案，其源代码将在GitHub公开。

Abstract: A single-pass driving clip frequently results in incomplete scanning of the
road structure, making reconstructed scene expanding a critical requirement for
sensor simulators to effectively regress driving actions. Although contemporary
3D Gaussian Splatting (3DGS) techniques achieve remarkable reconstruction
quality, their direct extension through the integration of diffusion priors
often introduces cumulative physical inconsistencies and compromises training
efficiency. To address these limitations, we present RGE-GS, a novel expansive
reconstruction framework that synergizes diffusion-based generation with
reward-guided Gaussian integration. The RGE-GS framework incorporates two key
innovations: First, we propose a reward network that learns to identify and
prioritize consistently generated patterns prior to reconstruction phases,
thereby enabling selective retention of diffusion outputs for spatial
stability. Second, during the reconstruction process, we devise a
differentiated training strategy that automatically adjust Gaussian
optimization progress according to scene converge metrics, which achieving
better convergence than baseline methods. Extensive evaluations of publicly
available datasets demonstrate that RGE-GS achieves state-of-the-art
performance in reconstruction quality. Our source-code will be made publicly
available at https://github.com/CN-ADLab/RGE-GS. (Camera-ready version
incorporating reviewer suggestions will be updated soon.)

</details>


### [39] [Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding](https://arxiv.org/abs/2506.22803)
*Nuoye Xiong,Anqi Dong,Ning Wang,Cong Hua,Guangming Zhu,Mei Lin,Peiyi Shen,Liang Zhang*

Main category: cs.CV

TL;DR: 研究提出了一种名为CBM-HNMU（概念瓶颈模型用于增强人类-神经网络相互理解）的新方法，提升了黑箱模型的可解释性与准确性，最高提升了2.64%的准确率。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型的复杂性和参数数量不断增加，导致其决策难以理解，缺乏有效的干预方法。

Method: 通过基于全局梯度贡献自动识别有害概念并进行改进（移除/替换），并在改进后将知识反向蒸馏回黑箱模型，形成CBM-HNMU框架，提升可解释性和准确性。

Result: 在多个数据集（如Flower-102，CIFAR-10，CIFAR-100等）的CNN和Transformer模型上，最高实现了2.64%的准确率提升，平均提升了1.03%的准确率。

Conclusion: CBM-HNMU不仅增强了模型的可解释性，还在多个标准数据集上提升了模型的性能，是揭示黑箱学习的新方法。

Abstract: Recent advances in deep learning have led to increasingly complex models with
deeper layers and more parameters, reducing interpretability and making their
decisions harder to understand. While many methods explain black-box reasoning,
most lack effective interventions or only operate at sample-level without
modifying the model itself. To address this, we propose the Concept Bottleneck
Model for Enhancing Human-Neural Network Mutual Understanding (CBM-HNMU).
CBM-HNMU leverages the Concept Bottleneck Model (CBM) as an interpretable
framework to approximate black-box reasoning and communicate conceptual
understanding. Detrimental concepts are automatically identified and refined
(removed/replaced) based on global gradient contributions. The modified CBM
then distills corrected knowledge back into the black-box model, enhancing both
interpretability and accuracy. We evaluate CBM-HNMU on various CNN and
transformer-based models across Flower-102, CIFAR-10, CIFAR-100, FGVC-Aircraft,
and CUB-200, achieving a maximum accuracy improvement of 2.64% and a maximum
increase in average accuracy across 1.03%. Source code is available at:
https://github.com/XiGuaBo/CBM-HNMU.

</details>


### [40] [Concept Pinpoint Eraser for Text-to-image Diffusion Models via Residual Attention Gate](https://arxiv.org/abs/2506.22806)
*Byung Hyun Lee,Sungjin Lim,Seunggyu Lee,Dong Un Kang,Se Young Chun*

Main category: cs.CV

TL;DR: 研究提出了一种新的框架，称为“概念精确擦除器”（CPE），能选择性地从扩散模型中擦除目标概念，同时最大限度地保留其他概念并提高对攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着文本到图像扩散模型的进步，能不能安全地生成图像成为一个重要问题。研究动机是在扩散模型中安全地删除不适当或商标化的目标概念，同时尽量不影响其他概念。

Method: 提出了一种新的方法，即通过添加非线性“残差注意力门”（ResAG）来选择性擦除目标概念，并采用注意力锚定损失防止遗忘，同时还结合了对抗训练和迭代学习的方式提升效果。

Result: 实验结果表明，与其他方法相比，该方法在删除目标概念的同时能够更好地保留其他多样化的概念，并对攻击性提示有较强的鲁棒性。

Conclusion: 该方法在概念擦除任务中表现优异，为解决当前模型挑战提供了新的解决方案，代码已开源供公众使用。

Abstract: Remarkable progress in text-to-image diffusion models has brought a major
concern about potentially generating images on inappropriate or trademarked
concepts. Concept erasing has been investigated with the goals of deleting
target concepts in diffusion models while preserving other concepts with
minimal distortion. To achieve these goals, recent concept erasing methods
usually fine-tune the cross-attention layers of diffusion models. In this work,
we first show that merely updating the cross-attention layers in diffusion
models, which is mathematically equivalent to adding \emph{linear} modules to
weights, may not be able to preserve diverse remaining concepts. Then, we
propose a novel framework, dubbed Concept Pinpoint Eraser (CPE), by adding
\emph{nonlinear} Residual Attention Gates (ResAGs) that selectively erase (or
cut) target concepts while safeguarding remaining concepts from broad
distributions by employing an attention anchoring loss to prevent the
forgetting. Moreover, we adversarially train CPE with ResAG and learnable text
embeddings in an iterative manner to maximize erasing performance and enhance
robustness against adversarial attacks. Extensive experiments on the erasure of
celebrities, artistic styles, and explicit contents demonstrated that the
proposed CPE outperforms prior arts by keeping diverse remaining concepts while
deleting the target concepts with robustness against attack prompts. Code is
available at https://github.com/Hyun1A/CPE

</details>


### [41] [FreqDGT: Frequency-Adaptive Dynamic Graph Networks with Transformer for Cross-subject EEG Emotion Recognition](https://arxiv.org/abs/2506.22807)
*Yueyang Li,Shengyu Gong,Weiming Zeng,Nizhuan Wang,Wai Ting Siok*

Main category: cs.CV

TL;DR: 提出了一个名为FreqDGT的模型，利用频率自适应动态图学习和多尺度时间解耦网络提高跨主体情感识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决跨主体情感识别的挑战，尤其是由于个体差异、认知特质和情感反应的影响。

Method: 提出FreqDGT模型，引入频率自适应处理（FAP）权重化情感相关频率、动态图学习（ADGL）捕捉大脑连接模式，并通过多尺度时间网络（MTDN）结合时间变换和特征解耦。

Result: 实验表明，FreqDGT显著提升跨主体情感识别的准确性，证实模型在保证个体鲁棒性的情况下，整合频率、空间与时间建模的有效性。

Conclusion: FreqDGT通过创新设计，解决了跨主体情感识别的长期挑战，可作为情感识别领域的有效工具。

Abstract: Electroencephalography (EEG) serves as a reliable and objective signal for
emotion recognition in affective brain-computer interfaces, offering unique
advantages through its high temporal resolution and ability to capture
authentic emotional states that cannot be consciously controlled. However,
cross-subject generalization remains a fundamental challenge due to individual
variability, cognitive traits, and emotional responses. We propose FreqDGT, a
frequency-adaptive dynamic graph transformer that systematically addresses
these limitations through an integrated framework. FreqDGT introduces
frequency-adaptive processing (FAP) to dynamically weight emotion-relevant
frequency bands based on neuroscientific evidence, employs adaptive dynamic
graph learning (ADGL) to learn input-specific brain connectivity patterns, and
implements multi-scale temporal disentanglement network (MTDN) that combines
hierarchical temporal transformers with adversarial feature disentanglement to
capture both temporal dynamics and ensure cross-subject robustness.
Comprehensive experiments demonstrate that FreqDGT significantly improves
cross-subject emotion recognition accuracy, confirming the effectiveness of
integrating frequency-adaptive, spatial-dynamic, and temporal-hierarchical
modeling while ensuring robustness to individual differences. The code is
available at https://github.com/NZWANG/FreqDGT.

</details>


### [42] [Efficient Multi-Crop Saliency Partitioning for Automatic Image Cropping](https://arxiv.org/abs/2506.22814)
*Andrew Hamara,Andrew C. Freeman*

Main category: cs.CV

TL;DR: 提出了一种高效的多重非重叠图像裁剪算法，用于提取视觉显著区域。


<details>
  <summary>Details</summary>
Motivation: 现有裁剪方法仅优化单一裁剪框，无法满足需要多个不重叠裁剪情况的需求。

Method: 改进固定宽高比裁剪算法，通过动态调整注意力阈值和移除已选裁剪框，减少重新计算显著图的过程。

Result: 实现了线性时间内的多重非重叠裁剪，并展示了定性结果。

Conclusion: 新方法高效提取了多重非重叠裁剪，提出了进一步构建数据集和基准的潜力。

Abstract: Automatic image cropping aims to extract the most visually salient regions
while preserving essential composition elements. Traditional saliency-aware
cropping methods optimize a single bounding box, making them ineffective for
applications requiring multiple disjoint crops. In this work, we extend the
Fixed Aspect Ratio Cropping algorithm to efficiently extract multiple
non-overlapping crops in linear time. Our approach dynamically adjusts
attention thresholds and removes selected crops from consideration without
recomputing the entire saliency map. We discuss qualitative results and
introduce the potential for future datasets and benchmarks.

</details>


### [43] [Unleashing the Multi-View Fusion Potential: Noise Correction in VLM for Open-Vocabulary 3D Scene Understanding](https://arxiv.org/abs/2506.22817)
*Xingyilang Yin,Jiale Wang,Xi Yang,Mutian Xu,Xu Gu,Nannan Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新方法MVOV3D，通过改进2D多视图特征融合和引入3D几何先验优化开放词汇3D场景理解性能，在开放词汇语义分割任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前的开放词汇3D理解方法在处理稀少语料的3D数据时表现受限，尤其在应对多样化类别时存在瓶颈。本文关注解决多视图融合在噪声问题上的不足，以提升3D场景中多样化概念的理解能力。

Method: 通过结合CLIP编码器捕获的精准区域级图像与文本特征，并利用3D几何先验信息优化多视图融合，在无训练的前提下减少噪声，并提升模型的开放世界能力。

Result: 实验表明，MVOV3D在挑战性数据集ScanNet200和Matterport160上的mIoU分别达到了14.7%和16.2%，显著超越当前最先进的训练3D网络。

Conclusion: MVOV3D方法通过改进2D-3D结合的融合技术，显著提高了开放词汇3D语义分割的性能，展示了对扩展3D场景理解潜力的显著贡献。

Abstract: Recent open-vocabulary 3D scene understanding approaches mainly focus on
training 3D networks through contrastive learning with point-text pairs or by
distilling 2D features into 3D models via point-pixel alignment. While these
methods show considerable performance in benchmarks with limited vocabularies,
they struggle to handle diverse object categories as the limited amount of 3D
data upbound training strong open-vocabulary 3d models. We observe that 2D
multi-view fusion methods take precedence in understanding diverse concepts in
3D scenes. However, inherent noises in vision-language models lead multi-view
fusion to sub-optimal performance. To this end, we introduce MVOV3D, a novel
approach aimed at unleashing the potential of 2D multi-view fusion for
open-vocabulary 3D scene understanding. We focus on reducing the inherent
noises without training, thereby preserving the generalizability while
enhancing open-world capabilities. Specifically, MVOV3D improves multi-view 2D
features by leveraging precise region-level image features and text features
encoded by CLIP encoders and incorporates 3D geometric priors to optimize
multi-view fusion. Extensive experiments on various datasets demonstrate the
effectiveness of our method. Notably, our MVOV3D achieves a new record with
14.7% mIoU on ScanNet200 and 16.2% mIoU on Matterport160 for challenge
open-vocabulary semantic segmentation, outperforming current leading trained 3D
networks by a significant margin.

</details>


### [44] [Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration](https://arxiv.org/abs/2506.22819)
*Ramya Hebbalaguppe,Tamoghno Kandar,Abhinav Nagpal,Chetan Arora*

Main category: cs.CV

TL;DR: 本论文提出了一种用于视觉语言模型（VLM）测试时提示调优（TPT）的新方法，重点解决其可能导致的信心校准问题，并显著降低校准误差。


<details>
  <summary>Details</summary>
Motivation: 尽管TPT方法能提升模型的准确性，但其单一地关注准确性会破坏模型的置信度校准，这在关键应用场景中受到限制。因此需要一套能兼顾改善校准与性能的方法。

Method: 提出通过大语言模型（LLM）的目标标签属性来初始化提示以减少过度拟合；并设计新型正则化损失以降低同类样本的距离、增大异类样本的距离，从而优化TPT的提示生成过程。

Result: 在多种CLIP架构和15个数据集上的实验结果表明，提出的TCA方法的平均期望校准误差（ECE）从传统TPT的11.7降至4.11，优于多种业界现有方法。

Conclusion: 通过结合提示初始化与正则化设计的TCA方法，成功为VLM在TPT情况下实现更好的置信校准，具有广泛的实用性和显著的性能提升。

Abstract: Vision-language models (VLM) have demonstrated impressive performance in
image recognition by leveraging self-supervised training on large datasets.
Their performance can be further improved by adapting to the test sample using
test-time prompt tuning (TPT). Unfortunately, the singular focus of TPT
approaches on improving the accuracy suffers from tunnel vision, and leads to
degradation in confidence calibration. This limits the applicability of TPT in
critical applications.
  We make three contributions in this work. (1) We posit that random or naive
initialization of prompts leads to overfitting on a particular test sample, and
is the main reason for miscalibration of the VLM after TPT. To mitigate the
problem, we propose careful initialization of test time prompt using prior
knowledge about the target label attributes from a large language model (LLM);
(2) To further maintain the quality of prompts during \tpt, we propose a novel
regularization loss to reduce intraclass distance, and increase inter-class
distance between the learnt
  Through extensive experiments on different CLIP architectures and 15
datasets, we show that our approach can effectively improve the calibration
after TPT. We report an average expected calibration error (ECE) of 4.11 with
our method, TCA, compared to 11.7 for vanilla TPT, 6.12 for C-TPT (ICLR'24),
6.78 for DiffTPT (CVPR'23), and 8.43 for PromptAlign (NeurIPS'23). The code is
publicly accessible at:
https://github.com/rhebbalaguppe/TCA_PromptWithoutPanic.

</details>


### [45] [Listener-Rewarded Thinking in VLMs for Image Preferences](https://arxiv.org/abs/2506.22832)
*Alexander Gambashidze,Li Pengyi,Matvey Skripkin,Andrey Galichin,Anton Gusarov,Konstantin Sobolev,Andrey Kuznetsov,Ivan Oseledets*

Main category: cs.CV

TL;DR: 本文提出一种增强型奖励优化方法，使用独立冻结的视觉语言模型作为参考，提高生成模型的推理准确性和广泛适应性。


<details>
  <summary>Details</summary>
Motivation: 目前的奖励模型在广泛适应性上存在不足，而强化学习中现有的优化方法也存在推理准确性下降的缺陷，需要一种更有效的机制来校准和改善模型输出。

Method: 引入了listener-augmented GRPO框架，在强化学习过程中利用冻结的视觉语言模型对推理过程进行重新评估，生成置信度得分以调整奖励信号。

Result: 该方法在ImageReward基准上取得了最佳准确率（67.4%），并显著提高了大规模人类偏好数据集的分布外性能（提升最多达6%），同时减少了推理过程中的矛盾。

Conclusion: listener-based奖励方案提供了一种可扩展且数据高效的路径，用于使视觉语言模型更好地匹配人类复杂的偏好。

Abstract: Training robust and generalizable reward models for human visual preferences
is essential for aligning text-to-image and text-to-video generative models
with human intent. However, current reward models often fail to generalize, and
supervised fine-tuning leads to memorization, demanding complex annotation
pipelines. While reinforcement learning (RL), specifically Group Relative
Policy Optimization (GRPO), improves generalization, we uncover a key failure
mode: a significant drop in reasoning accuracy occurs when a model's reasoning
trace contradicts that of an independent, frozen vision-language model
("listener") evaluating the same output. To address this, we introduce a
listener-augmented GRPO framework. Here, the listener re-evaluates the
reasoner's chain-of-thought to provide a dense, calibrated confidence score,
shaping the RL reward signal. This encourages the reasoner not only to answer
correctly, but to produce explanations that are persuasive to an independent
model. Our listener-shaped reward scheme achieves best accuracy on the
ImageReward benchmark (67.4%), significantly improves out-of-distribution (OOD)
performance on a large-scale human preference dataset (1.2M votes, up to +6%
over naive reasoner), and reduces reasoning contradictions compared to strong
GRPO and SFT baselines. These results demonstrate that listener-based rewards
provide a scalable, data-efficient path to aligning vision-language models with
nuanced human preferences. We will release our reasoning model here:
https://huggingface.co/alexgambashidze/qwen2.5vl_image_preference_reasoner.

</details>


### [46] [SemFaceEdit: Semantic Face Editing on Generative Radiance Manifolds](https://arxiv.org/abs/2506.22833)
*Shashikant Verma,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: 该论文提出了SemFaceEdit方法，通过在生成辐射流形上生成语义场，实现对人脸局部特定区域的精确编辑，同时保持其他区域的不变性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D感知的生成式对抗网络虽具有多视图一致性，但缺乏局部编辑的能力。论文希望通过生成辐射流形提高局部编辑能力并减少计算需求。

Method: 论文设计了一个包含几何模块与外观模块的网络架构，几何模块生成语义辐射与占据场，外观模块预测RGB辐射。两模块在对抗设置下联合训练，并通过外观模块将外观描述符与语义潜在编码结合，以实现外观与几何的解耦与增强控制。

Result: 提出的方法展现出在语义场编辑中的先进性能，尤其在提高辐射场解耦方面表现突出。

Conclusion: SemFaceEdit具备更优的语义基编辑能力，为生成式辐射流形的应用提供了新方法。

Abstract: Despite multiple view consistency offered by 3D-aware GAN techniques, the
resulting images often lack the capacity for localized editing. In response,
generative radiance manifolds emerge as an efficient approach for constrained
point sampling within volumes, effectively reducing computational demands and
enabling the learning of fine details. This work introduces SemFaceEdit, a
novel method that streamlines the appearance and geometric editing process by
generating semantic fields on generative radiance manifolds. Utilizing latent
codes, our method effectively disentangles the geometry and appearance
associated with different facial semantics within the generated image. In
contrast to existing methods that can change the appearance of the entire
radiance field, our method enables the precise editing of particular facial
semantics while preserving the integrity of other regions. Our network
comprises two key modules: the Geometry module, which generates semantic
radiance and occupancy fields, and the Appearance module, which is responsible
for predicting RGB radiance. We jointly train both modules in adversarial
settings to learn semantic-aware geometry and appearance descriptors. The
appearance descriptors are then conditioned on their respective semantic latent
codes by the Appearance Module, facilitating disentanglement and enhanced
control. Our experiments highlight SemFaceEdit's superior performance in
semantic field-based editing, particularly in achieving improved radiance field
disentanglement.

</details>


### [47] [FOCUS: Fine-grained Optimization with Semantic Guided Understanding for Pedestrian Attributes Recognition](https://arxiv.org/abs/2506.22836)
*Hongyan An,Kuan Zhu,Xin He,Haiyun Guo,Chaoyang Zhao,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为FOCUS的行人属性识别方法，通过MGMT和AVFE模块实现细粒度属性特征提取，并综合了区域感知对比学习方法，显著提升了模型的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 行人属性识别任务现有方法局限于使用固定区域特征预测预定义属性，难以捕捉特定属性的细粒度模式，且无法泛化至未见属性。

Method: 提出FOCUS方法，包含MGMT模块用于捕捉不同视觉粒度的潜在特征，AVFE模块结合跨注意力机制利用文本属性查询对应的视觉属性特征，进一步通过RACL方法保证同一区域属性的关注一致性。

Result: 实验表明，该方法在PA100K、PETA和RAPv1数据集上具有出色的表现和强大的泛化能力。

Conclusion: FOCUS方法能够自适应地为每个属性提取细粒度特征，对训练中未见的属性也有良好支持，提升了行人属性识别的实际适用性。

Abstract: Pedestrian attribute recognition (PAR) is a fundamental perception task in
intelligent transportation and security. To tackle this fine-grained task, most
existing methods focus on extracting regional features to enrich attribute
information. However, a regional feature is typically used to predict a fixed
set of pre-defined attributes in these methods, which limits the performance
and practicality in two aspects: 1) Regional features may compromise
fine-grained patterns unique to certain attributes in favor of capturing common
characteristics shared across attributes. 2) Regional features cannot
generalize to predict unseen attributes in the test time. In this paper, we
propose the \textbf{F}ine-grained \textbf{O}ptimization with semanti\textbf{C}
g\textbf{U}ided under\textbf{S}tanding (FOCUS) approach for PAR, which
adaptively extracts fine-grained attribute-level features for each attribute
individually, regardless of whether the attributes are seen or not during
training. Specifically, we propose the Multi-Granularity Mix Tokens (MGMT) to
capture latent features at varying levels of visual granularity, thereby
enriching the diversity of the extracted information. Next, we introduce the
Attribute-guided Visual Feature Extraction (AVFE) module, which leverages
textual attributes as queries to retrieve their corresponding visual attribute
features from the Mix Tokens using a cross-attention mechanism. To ensure that
textual attributes focus on the appropriate Mix Tokens, we further incorporate
a Region-Aware Contrastive Learning (RACL) method, encouraging attributes
within the same region to share consistent attention maps. Extensive
experiments on PA100K, PETA, and RAPv1 datasets demonstrate the effectiveness
and strong generalization ability of our method.

</details>


### [48] [AG-VPReID 2025: Aerial-Ground Video-based Person Re-identification Challenge Results](https://arxiv.org/abs/2506.22843)
*Kien Nguyen,Clinton Fookes,Sridha Sridharan,Huy Nguyen,Feng Liu,Xiaoming Liu,Arun Ross,Dana Michalski,Tamás Endrei,Ivan DeAndres-Tame,Ruben Tolosana,Ruben Vera-Rodriguez,Aythami Morales,Julian Fierrez,Javier Ortega-Garcia,Zijing Gong,Yuhao Wang,Xuehu Liu,Pingping Zhang,Md Rashidunnabi,Hugo Proença,Kailash A. Hambarde,Saeid Rezaei*

Main category: cs.CV

TL;DR: 提出了基于视频的AG-VPReID 2025挑战赛，聚焦高空（80-120米）场景的人再识别，使用了包含3027个身份和约370万帧的新数据集，最高取得72.28% Rank-1精度。


<details>
  <summary>Details</summary>
Motivation: 解决空地视角差异巨大、人再识别困难的问题，在大规模监控和公共安全应用中具有重要意义。

Method: 引入了视频为基础的高空场景再识别人数据集和挑战赛，采用多流架构、基于变换器的时序推理以及物理建模等方法。

Result: 最佳方法X-TFCLIP在空对地和地对空的ReID场景下分别达到了72.28%和70.77%的Rank-1准确率。

Conclusion: 挑战赛展示了跨视角人再识别的复杂性和使用新方法取得的进展，为未来研究奠定了新基准。

Abstract: Person re-identification (ReID) across aerial and ground vantage points has
become crucial for large-scale surveillance and public safety applications.
Although significant progress has been made in ground-only scenarios, bridging
the aerial-ground domain gap remains a formidable challenge due to extreme
viewpoint differences, scale variations, and occlusions. Building upon the
achievements of the AG-ReID 2023 Challenge, this paper introduces the AG-VPReID
2025 Challenge - the first large-scale video-based competition focused on
high-altitude (80-120m) aerial-ground ReID. Constructed on the new AG-VPReID
dataset with 3,027 identities, over 13,500 tracklets, and approximately 3.7
million frames captured from UAVs, CCTV, and wearable cameras, the challenge
featured four international teams. These teams developed solutions ranging from
multi-stream architectures to transformer-based temporal reasoning and
physics-informed modeling. The leading approach, X-TFCLIP from UAM, attained
72.28% Rank-1 accuracy in the aerial-to-ground ReID setting and 70.77% in the
ground-to-aerial ReID setting, surpassing existing baselines while highlighting
the dataset's complexity. For additional details, please refer to the official
website at https://agvpreid25.github.io.

</details>


### [49] [DMD-Net: Deep Mesh Denoising Network](https://arxiv.org/abs/2506.22850)
*Aalok Gangopadhyay,Shashikant Verma,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: 本文提出了DMD-Net，一种用于网格去噪的端到端深度学习框架，集成了图卷积网络和特征引导变换器架构，能在高度噪声下表现优秀。


<details>
  <summary>Details</summary>
Motivation: 解决网格去噪问题，旨在提高去噪质量并增强其对各种噪声类型的鲁棒性。

Method: 设计了双向流网络和特征引导变换器，通过结合原始与对偶图的信息，实现网格去噪，从噪声网格提取特征并执行变换和去噪。

Result: 在大规模3D数据集上训练，在对比实验中表现优异，对各种噪声类型显示了强鲁棒性，尤其在高噪声环境中表现卓越。

Conclusion: DMD-Net在网格去噪中表现出较好的性能和鲁棒性，优于现有方法，并能有效应对极高噪声。

Abstract: We present Deep Mesh Denoising Network (DMD-Net), an end-to-end deep learning
framework, for solving the mesh denoising problem. DMD-Net consists of a Graph
Convolutional Neural Network in which aggregation is performed in both the
primal as well as the dual graph. This is realized in the form of an asymmetric
two-stream network, which contains a primal-dual fusion block that enables
communication between the primal-stream and the dual-stream. We develop a
Feature Guided Transformer (FGT) paradigm, which consists of a feature
extractor, a transformer, and a denoiser. The feature extractor estimates the
local features, that guide the transformer to compute a transformation, which
is applied to the noisy input mesh to obtain a useful intermediate
representation. This is further processed by the denoiser to obtain the
denoised mesh. Our network is trained on a large scale dataset of 3D objects.
We perform exhaustive ablation studies to demonstrate that each component in
our network is essential for obtaining the best performance. We show that our
method obtains competitive or better results when compared with the
state-of-the-art mesh denoising algorithms. We demonstrate that our method is
robust to various kinds of noise. We observe that even in the presence of
extremely high noise, our method achieves excellent performance.

</details>


### [50] [Mask-aware Text-to-Image Retrieval: Referring Expression Segmentation Meets Cross-modal Retrieval](https://arxiv.org/abs/2506.22864)
*Li-Cheng Shen,Jih-Kang Hsieh,Wei-Hua Li,Chu-Song Chen*

Main category: cs.CV

TL;DR: 提出了一种新的任务Mask-aware TIR (MaTIR)，结合了文本到图像的检索和基于自然语言的精确对象定位，通过两个阶段框架实现高效检索和精确分割。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像的检索方法缺乏可解释性，而基于自然语言的精确对象定位尽管精确但计算开销巨大。作者希望开发一种同时兼顾高效检索和精准分割的新方法。

Method: 提出了一个两阶段框架：第一阶段利用SAM生成的对象掩码和Alpha-CLIP的区域级嵌入进行高效离线检索；第二阶段通过多模态大语言模型优化检索结果并生成边界框，与分割掩码匹配。

Result: 在COCO和D$^3$数据集上，验证了所提方法在检索精度和分割质量上的明显提升。

Conclusion: 新方法显著提高了文本到图像检索的可解释性和精确定位能力，结合了效率和效果。

Abstract: Text-to-image retrieval (TIR) aims to find relevant images based on a textual
query, but existing approaches are primarily based on whole-image captions and
lack interpretability. Meanwhile, referring expression segmentation (RES)
enables precise object localization based on natural language descriptions but
is computationally expensive when applied across large image collections. To
bridge this gap, we introduce Mask-aware TIR (MaTIR), a new task that unifies
TIR and RES, requiring both efficient image search and accurate object
segmentation. To address this task, we propose a two-stage framework,
comprising a first stage for segmentation-aware image retrieval and a second
stage for reranking and object grounding with a multimodal large language model
(MLLM). We leverage SAM 2 to generate object masks and Alpha-CLIP to extract
region-level embeddings offline at first, enabling effective and scalable
online retrieval. Secondly, MLLM is used to refine retrieval rankings and
generate bounding boxes, which are matched to segmentation masks. We evaluate
our approach on COCO and D$^3$ datasets, demonstrating significant improvements
in both retrieval accuracy and segmentation quality over previous methods.

</details>


### [51] [Region-Aware CAM: High-Resolution Weakly-Supervised Defect Segmentation via Salient Region Perception](https://arxiv.org/abs/2506.22866)
*Hang-Cheng Dong,Lu Zou,Bingguo Liu,Dong Ye,Guodong Liu*

Main category: cs.CV

TL;DR: 本研究提出一种弱监督语义分割框架，通过引入过滤引导的反向传播和区域感知加权模块，提升工业表面缺陷检测的精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大规模标注数据集，不适应实际工业场景的缺陷检测需求。

Method: 提出包含区域感知激活图（CAM）和伪标签训练的框架，引入过滤引导的反向传播（FGBP）和区域加权机制以提升空间精度。

Result: 通过工业缺陷数据集验证，实验显示方法对分割精度的提升效果显著。

Conclusion: 该框架在弱监督学习和高精度缺陷分割之间搭起桥梁，适用于资源受限的工业环境。

Abstract: Surface defect detection plays a critical role in industrial quality
inspection. Recent advances in artificial intelligence have significantly
enhanced the automation level of detection processes. However, conventional
semantic segmentation and object detection models heavily rely on large-scale
annotated datasets, which conflicts with the practical requirements of defect
detection tasks. This paper proposes a novel weakly supervised semantic
segmentation framework comprising two key components: a region-aware class
activation map (CAM) and pseudo-label training. To address the limitations of
existing CAM methods, especially low-resolution thermal maps, and insufficient
detail preservation, we introduce filtering-guided backpropagation (FGBP),
which refines target regions by filtering gradient magnitudes to identify areas
with higher relevance to defects. Building upon this, we further develop a
region-aware weighted module to enhance spatial precision. Finally,
pseudo-label segmentation is implemented to refine the model's performance
iteratively. Comprehensive experiments on industrial defect datasets
demonstrate the superiority of our method. The proposed framework effectively
bridges the gap between weakly supervised learning and high-precision defect
segmentation, offering a practical solution for resource-constrained industrial
scenarios.

</details>


### [52] [STR-Match: Matching SpatioTemporal Relevance Score for Training-Free Video Editing](https://arxiv.org/abs/2506.22868)
*Junsung Lee,Junoh Kang,Bohyung Han*

Main category: cs.CV

TL;DR: STR-Match是一种不需要训练的文本指导视频编辑算法，通过二维空间注意力和一维时间模块的创新方法实现高质量的视频编辑，克服了时序不一致、运动扭曲等问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在时序一致性、运动扭曲以及领域转换受限方面存在问题，主要是因为编辑过程中对空间和时间像素相关性的建模不足。

Method: 提出了一个名为STR-Match的算法，该算法利用基于二维空间注意力和一维时间模块的STR评分，并结合潜变量优化框架与潜变量掩模，达到一致性强且视觉效果良好的视频编辑。

Result: 实验表明，STR-Match在视觉质量和时空一致性上都优于现有方法，即使在领域转换较大的情况下，仍能保持关键视觉属性的完整。

Conclusion: STR-Match显著改善了时序一致性和视觉保真度，为文本指导的视频编辑提供了一种高效的解决方案。

Abstract: Previous text-guided video editing methods often suffer from temporal
inconsistency, motion distortion, and-most notably-limited domain
transformation. We attribute these limitations to insufficient modeling of
spatiotemporal pixel relevance during the editing process. To address this, we
propose STR-Match, a training-free video editing algorithm that produces
visually appealing and spatiotemporally coherent videos through latent
optimization guided by our novel STR score. The score captures spatiotemporal
pixel relevance across adjacent frames by leveraging 2D spatial attention and
1D temporal modules in text-to-video (T2V) diffusion models, without the
overhead of computationally expensive 3D attention mechanisms. Integrated into
a latent optimization framework with a latent mask, STR-Match generates
temporally consistent and visually faithful videos, maintaining strong
performance even under significant domain transformations while preserving key
visual attributes of the source. Extensive experiments demonstrate that
STR-Match consistently outperforms existing methods in both visual quality and
spatiotemporal consistency.

</details>


### [53] [Decoupled Seg Tokens Make Stronger Reasoning Video Segmenter and Grounder](https://arxiv.org/abs/2506.22880)
*Dang Jisheng,Wu Xudong,Wang Bimei,Lv Ning,Chen Jiayu,Jingwen Zhao,Yichu liu,Jizhao Liu,Juncheng Li,Teng Wang*

Main category: cs.CV

TL;DR: 提出了一种名为DeSa2VA的新方法，通过解耦动态视觉信息和静态语义以提高分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如Sa2VA）因直接融合特征而导致动态视觉信息与静态语义纠缠，影响分割性能，因此需要一种更优的解决方案。

Method: 提出了一种基于解耦增强的提示机制DeSa2VA，包括文本预训练、线性解耦模块以及动态掩码融合策略。采用了一种将文本标签转换为点级提示的预训练范式，并通过混合损失函数改进语义基础能力，同时结合线性解耦将特征分离至文本和视觉子空间，最终通过三重监督融合解耦特征。

Result: 实验结果表明，DeSa2VA在图像分割、图像问答、视频分割和视频问答等多个任务中实现了最先进的性能。

Conclusion: 提出方法有效增强了动态视觉与静态语义信息的解耦能力，克服了信息处理的局限性，提升了分割与问答相关任务的表现。

Abstract: Existing video segmenter and grounder approaches, exemplified by Sa2VA,
directly fuse features within segmentation models. This often results in an
undesirable entanglement of dynamic visual information and static semantics,
thereby degrading segmentation accuracy. To systematically mitigate this issue,
we propose DeSa2VA, a decoupling-enhanced prompting scheme integrating text
pre-training and a linear decoupling module to address the information
processing limitations inherent in SAM-2. Specifically, first, we devise a
pre-training paradigm that converts textual ground-truth labels into
point-level prompts while generating corresponding text masks. These masks are
refined through a hybrid loss function to strengthen the model's semantic
grounding capabilities. Next, we employ linear projection to disentangle hidden
states that generated by a large language model into distinct textual and
visual feature subspaces. Finally, a dynamic mask fusion strategy
synergistically combines these decoupled features through triple supervision
from predicted text/visual masks and ground-truth annotations. Extensive
experiments demonstrate state-of-the-art performance across diverse tasks,
including image segmentation, image question answering, video segmentation, and
video question answering. Our codes are available at
https://github.com/longmalongma/DeSa2VA.

</details>


### [54] [How Semantically Informative is an Image?: Measuring the Covariance-Weighted Norm of Contrastive Learning Embeddings](https://arxiv.org/abs/2506.22881)
*Fumiya Uchiyama,Rintaro Yanagi,Shohei Taniguchi,Shota Takashiro,Masahiro Suzuki,Hirokatsu Kataoka,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CV

TL;DR: 该研究提出一个基于对比学习模型的语义信息量度量方法，用于估算图像和文本间的绝对语义信息量，并验证了其高效性和准确性。


<details>
  <summary>Details</summary>
Motivation: 探索对比学习模型是否能够除关联语义相似性外，也代表绝对语义信息量，对视觉和语言领域的信息增益进行重新定义。

Method: 通过对比学习模型计算语义信息量，分析图像对文本或文本对图像的条件性影响，并验证基于嵌入向量范数的方法预测信息增益的有效性。

Result: 利用CLIP与SigLIP模型测得的信息增益与相关性系数高达0.98至1.00，且计算成本独立于样本大小，适用于公开权重模型。

Conclusion: 该方法能够高效、准确地量化图像与文本间的语义信息增益，且计算方法简便兼容性强。

Abstract: Contrastive learning has the capacity to model multimodal probability
distributions by embedding and aligning visual representations with semantics
from captions. This approach enables the estimation of relational semantic
similarity; however, it remains unclear whether it can also represent absolute
semantic informativeness. In this work, we introduce a semantic informativeness
metric for an image calculated from text samples via a contrastive learning
model; similarly, the informativeness of a text is calculated from image
samples. We propose a redefinition of the concept of Information Gain, a
concept previously explored in natural language processing, extending its
application to the domains of vision and language. Our metric quantifies how
conditioning on an image distorts the distribution of associated texts, and
vice versa for text conditioning on image distributions. In OpenCLIP's
empirical results, we observe that images with the lowest Information Gain
scores often correspond to placeholder icons such as "image not found."
Furthermore, we propose to measure a norm-based metric of the embedding to
estimate the Information Gain, following the theoretical results for Skip-Gram
with Negative Sampling (SGNS) word embedding. Information Gain can be measured
using either CLIP or SigLIP, and the results demonstrate a strong correlation
with a coefficient of determination ranging from 0.98 to 1.00. After obtaining
the mean and the covariance of the sample embedding, the computational cost of
this method is independent of the sample size, and it is compatible with
publicly available, open-weight models.

</details>


### [55] [CP-Guard: A Unified, Probability-Agnostic, and Adaptive Framework for Malicious Agent Detection and Defense in Multi-Agent Embodied Perception Systems](https://arxiv.org/abs/2506.22890)
*Senkang Hu,Yihang Tao,Guowen Xu,Xinyuan Qian,Yiqin Deng,Xianhao Chen,Sam Tak Wu Kwong,Yuguang Fang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为CP-Guard的防御框架，用于多智能体协作感知中的恶意攻击检测和消除，主要通过共识机制确保感知结果的可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体协作感知(CP)中，恶意智能体可能通过信息共享攻击感知系统的安全问题。

Method: 提出了CP-Guard框架，包括无概率假设的采样共识方法（PASAC）、协作一致性损失(CCLoss)以及基于双滑动窗口的自适应阈值调整方案。

Result: 实验表明，CP-Guard能有效检测恶意智能体，并在动态环境中提高协作感知的可靠性和性能。

Conclusion: CP-Guard为CP系统提供了一种鲁棒的安全保障机制，有助于提高多智能体系统的感知性能和安全性。

Abstract: Collaborative Perception (CP) has been shown to be a promising technique for
multi-agent autonomous driving and multi-agent robotic systems, where multiple
agents share their perception information to enhance the overall perception
performance and expand the perception range. However, in CP, an ego agent needs
to receive messages from its collaborators, which makes it vulnerable to
attacks from malicious agents. To address this critical issue, we propose a
unified, probability-agnostic, and adaptive framework, namely, CP-Guard, which
is a tailored defense mechanism for CP deployed by each agent to accurately
detect and eliminate malicious agents in its collaboration network. Our key
idea is to enable CP to reach a consensus rather than a conflict against an ego
agent's perception results. Based on this idea, we first develop a
probability-agnostic sample consensus (PASAC) method to effectively sample a
subset of the collaborators and verify the consensus without prior
probabilities of malicious agents. Furthermore, we define collaborative
consistency loss (CCLoss) for object detection task and bird's eye view (BEV)
segmentation task to capture the discrepancy between an ego agent and its
collaborators, which is used as a verification criterion for consensus. In
addition, we propose online adaptive threshold via dual sliding windows to
dynamically adjust the threshold for consensus verification and ensure the
reliability of the systems in dynamic environments. Finally, we conduct
extensive experiments and demonstrate the effectiveness of our framework. Code
will be released at https://github.com/CP-Security/CP-Guard

</details>


### [56] [Neural Cellular Automata: From Cells to Pixels](https://arxiv.org/abs/2506.22899)
*Ehsan Pajouheshgar,Yitao Xu,Ali Abbasi,Alexander Mordvintsev,Wenzel Jakob,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: 本文提出通过结合嵌入式解码器的神经细胞自动机（NCA），显著提升其生成高清输出的能力，且保持自组织和涌现特性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决现有神经细胞自动机在高分辨率网格上运行时的计算开销、高效信息传播的局限以及实时推断的高计算需求问题。

Method: 结合神经细胞自动机与小型共享的嵌入式解码器，将演化过程限制在粗网格，然后利用解码器输出任意分辨率的图像，同时设计适用于高分辨率任务的损失函数。

Result: 提出的方法显著提高了品质、效率与性能，能够实时生成全高清输出，并展示了对不同任务（如纹理生成与形态发生）和多种NCA变体的适用性。

Conclusion: 嵌入式解码器的引入使得NCA能够以最小的计算开销扩展到高分辨率输出，同时保留其自组织和涌现特性，为高分辨率任务提供了一种有效的途径。

Abstract: Neural Cellular Automata (NCAs) are bio-inspired systems in which identical
cells self-organize to form complex and coherent patterns by repeatedly
applying simple local rules. NCAs display striking emergent behaviors including
self-regeneration, generalization and robustness to unseen situations, and
spontaneous motion. Despite their success in texture synthesis and
morphogenesis, NCAs remain largely confined to low-resolution grids. This
limitation stems from (1) training time and memory requirements that grow
quadratically with grid size, (2) the strictly local propagation of information
which impedes long-range cell communication, and (3) the heavy compute demands
of real-time inference at high resolution. In this work, we overcome this
limitation by pairing NCA with a tiny, shared implicit decoder, inspired by
recent advances in implicit neural representations. Following NCA evolution on
a coarse grid, a lightweight decoder renders output images at arbitrary
resolution. We also propose novel loss functions for both morphogenesis and
texture synthesis tasks, specifically tailored for high-resolution output with
minimal memory and computation overhead. Combining our proposed architecture
and loss functions brings substantial improvement in quality, efficiency, and
performance. NCAs equipped with our implicit decoder can generate full-HD
outputs in real time while preserving their self-organizing, emergent
properties. Moreover, because each MLP processes cell states independently,
inference remains highly parallelizable and efficient. We demonstrate the
applicability of our approach across multiple NCA variants (on 2D, 3D grids,
and 3D meshes) and multiple tasks, including texture generation and
morphogenesis (growing patterns from a seed), showing that with our proposed
framework, NCAs seamlessly scale to high-resolution outputs with minimal
computational overhead.

</details>


### [57] [MOTOR: Multimodal Optimal Transport via Grounded Retrieval in Medical Visual Question Answering](https://arxiv.org/abs/2506.22900)
*Mai A. Shaaban,Tausifa Jan Saleem,Vijay Ram Papineni,Mohammad Yaqub*

Main category: cs.CV

TL;DR: 这项研究提出了一个名为MOTOR的多模态检索和重排序方法，用于提升医疗视觉问答的准确性，其性能比现有最优方法高出6.45%。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言模型（VLMs）在医疗视觉问答中生成错误答案的问题仍然存在，并且现有方法在注重查询文本一致性的同时忽略了多模态上下文的重要性。

Method: 提出了MOTOR方法，结合了基础的图像描述和最优传输理论，利用文本和视觉信息重排序检索内容，以识别与查询更具临床相关性的上下文。

Result: 在MedVQA数据集上，通过实证分析和人类专家评估，MOTOR在准确性上优于现有方法，提升了6.45%的性能。

Conclusion: MOTOR方法通过多模态检索和重排序，提高了医疗视觉问答的回答准确性，可作为未来相关任务的改进方向。

Abstract: Medical visual question answering (MedVQA) plays a vital role in clinical
decision-making by providing contextually rich answers to image-based queries.
Although vision-language models (VLMs) are widely used for this task, they
often generate factually incorrect answers. Retrieval-augmented generation
addresses this challenge by providing information from external sources, but
risks retrieving irrelevant context, which can degrade the reasoning
capabilities of VLMs. Re-ranking retrievals, as introduced in existing
approaches, enhances retrieval relevance by focusing on query-text alignment.
However, these approaches neglect the visual or multimodal context, which is
particularly crucial for medical diagnosis. We propose MOTOR, a novel
multimodal retrieval and re-ranking approach that leverages grounded captions
and optimal transport. It captures the underlying relationships between the
query and the retrieved context based on textual and visual information.
Consequently, our approach identifies more clinically relevant contexts to
augment the VLM input. Empirical analysis and human expert evaluation
demonstrate that MOTOR achieves higher accuracy on MedVQA datasets,
outperforming state-of-the-art methods by an average of 6.45%. Code is
available at https://github.com/BioMedIA-MBZUAI/MOTOR.

</details>


### [58] [Point Cloud Compression and Objective Quality Assessment: A Survey](https://arxiv.org/abs/2506.22902)
*Yiling Xu,Yujie Zhang,Shuting Xia,Kaifa Yang,He Huang,Ziyu Shan,Wenjie Huang,Qi Yang,Le Yang*

Main category: cs.CV

TL;DR: 本文综述点云压缩（PCC）和点云质量评估（PCQA）的最新进展，分析算法并提出未来方向。


<details>
  <summary>Details</summary>
Motivation: 解决点云数据的高效压缩和质量评估问题，满足实时和感知相关应用的需求。

Method: 回顾与分析手工设计与学习驱动的PCC算法，以及客观的PCQA指标，通过数据集上的基准测试进行比较。

Result: 对现有方法进行对比和实用见解，并指出提高视觉质量、降低延迟和支持多模态数据等挑战。

Conclusion: 提出未来方向，包括混合压缩框架和高级特征提取策略，以支持高效和智能化的3D应用。

Abstract: The rapid growth of 3D point cloud data, driven by applications in autonomous
driving, robotics, and immersive environments, has led to criticals demand for
efficient compression and quality assessment techniques. Unlike traditional 2D
media, point clouds present unique challenges due to their irregular structure,
high data volume, and complex attributes. This paper provides a comprehensive
survey of recent advances in point cloud compression (PCC) and point cloud
quality assessment (PCQA), emphasizing their significance for real-time and
perceptually relevant applications. We analyze a wide range of handcrafted and
learning-based PCC algorithms, along with objective PCQA metrics. By
benchmarking representative methods on emerging datasets, we offer detailed
comparisons and practical insights into their strengths and limitations.
Despite notable progress, challenges such as enhancing visual fidelity,
reducing latency, and supporting multimodal data remain. This survey outlines
future directions, including hybrid compression frameworks and advanced feature
extraction strategies, to enable more efficient, immersive, and intelligent 3D
applications.

</details>


### [59] [MagShield: Towards Better Robustness in Sparse Inertial Motion Capture Under Magnetic Disturbances](https://arxiv.org/abs/2506.22907)
*Yunzhe Shao,Xinyu Yi,Lu Yin,Shihui Guo,Junhai Yong,Feng Xu*

Main category: cs.CV

TL;DR: 本文提出了一种名为MagShield的新方法，用于解决稀疏惯性动作捕捉系统中的磁干扰问题。


<details>
  <summary>Details</summary>
Motivation: 现有的惯性测量单元(IMU)系统在磁环境干扰下容易出现方向估计误差，限制了其在现实世界中的应用。

Method: MagShield采用了一种“先检测后纠正”的策略，利用多IMU关节分析检测磁干扰，并通过人体运动先验知识纠正方向误差。

Result: 实验结果表明，MagShield显著提高了磁干扰下动作捕捉的精确度，并在不同稀疏惯性动作捕捉系统中表现了良好的兼容性。

Conclusion: MagShield可与大多数现有的稀疏惯性动作捕捉系统集成，提高其在磁干扰环境中的性能。

Abstract: This paper proposes a novel method called MagShield, designed to address the
issue of magnetic interference in sparse inertial motion capture (MoCap)
systems. Existing Inertial Measurement Unit (IMU) systems are prone to
orientation estimation errors in magnetically disturbed environments, limiting
their practical application in real-world scenarios. To address this problem,
MagShield employs a "detect-then-correct" strategy, first detecting magnetic
disturbances through multi-IMU joint analysis, and then correcting orientation
errors using human motion priors. MagShield can be integrated with most
existing sparse inertial MoCap systems, improving their performance in
magnetically disturbed environments. Experimental results demonstrate that
MagShield significantly enhances the accuracy of motion capture under magnetic
interference and exhibits good compatibility across different sparse inertial
MoCap systems.

</details>


### [60] [Attention to Burstiness: Low-Rank Bilinear Prompt Tuning](https://arxiv.org/abs/2506.22908)
*Yuzhu Wang,Manni Duan,Shu Kong*

Main category: cs.CV

TL;DR: 提出了一种新方法BPT，通过白化处理克服梯度学习中的非高斯分布问题，加速了提示微调并提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉提示调优方法存在于学习过程中非高斯分布问题，影响了模型的适应能力与效率。

Method: 引入白化操作，将数据去相关化并使其更接近高斯分布，提出基于双线性模型的BPT方法。同时设计了一个低秩版本，通过较小矩阵乘积生成最终提示。

Result: BPT在多个数据集上实现了优越性能，超越现有VPT方法，同时显著减少了参数数量和计算量。

Conclusion: BPT是一种高效且有效的提示调优方法，为视觉模型的优化提供了新思路。

Abstract: Visual Prompt Tuning (VPT) is a parameter-efficient fune-tuning technique
that adapts a pre-trained vision Transformer (ViT) by learning a small set of
parameters in the input space, known as prompts. In VPT, we uncover
``burstiness'' in the values arising from the interaction of image patch
embeddings, and the key and query projectors within Transformer's
self-attention module. Furthermore, the values of patch embeddings and the key
and query projectors exhibit Laplacian and hyper-Laplacian distribution,
respectively. Intuitively, these non-Gaussian distributions pose challenges for
learning prompts. To address this, we propose whitening these data,
de-correlating them and equalizing their variance towards more Gaussian before
learning prompts. We derive the whitening matrix over random image patch
embeddings and ViT's key and query projectors, and multiply it with the prompt
to be learned in a bilinear manner. Surprisingly, this method significantly
accelerates prompt tuning and boosts accuracy, e.g., $>$25 accuracy points on
the CUB dataset; interestingly, it learns ``bursty prompts''. Extending the
bilinear model which is known to introduce burstiness, we present a compact,
low-rank version by learning two smaller matrices whose multiplication yields
the final prompts. We call the proposed methods Bilinear Prompt Tuning (BPT).
Extensive experiments across multiple benchmark datasets demonstrate that BPT
methods not only outperform various VPT methods but also reduce parameter count
and computation overhead.

</details>


### [61] [Towards Explainable Bilingual Multimodal Misinformation Detection and Localization](https://arxiv.org/abs/2506.22930)
*Yiwei He,Xiangtai Li,Zhenglin Huang,Yi Dong,Hao Fei,Jiangning Zhang,Baoyuan Wu,Guangliang Cheng*

Main category: cs.CV

TL;DR: 提出了名为BiMi的框架，用于处理具有中英双语字幕的新闻媒体内容中的跨模态和跨语言不一致问题，同时提供误导性内容的自然语言解释。


<details>
  <summary>Details</summary>
Motivation: 随着多模态内容的真实性增加，尤其在新闻媒体中，检测误导性内容变得愈发困难，因此设计一种能够应对这一问题的系统具有重要意义。

Method: 设计了BiMi框架，包括区域级定位、跨模态和跨语言一致性检测，并结合自然语言解释。构建了BiMiBench，用系统性编辑手法制作了包含104,000个样本的大规模数据集。同时首次在这一领域应用GRPO来提升解释质量。

Result: 实验显示BiMi在分类准确度、定位准确度以及解释质量(BERTScore)上显著优于现有方法，改进幅度分别高达+8.9、+15.9和+2.5。

Conclusion: BiMi利用区域级检测和跨模态分析手段显著提升对现实多语言误导性信息的检测能力，推动了该领域的性能进步。

Abstract: The increasing realism of multimodal content has made misinformation more
subtle and harder to detect, especially in news media where images are
frequently paired with bilingual (e.g., Chinese-English) subtitles. Such
content often includes localized image edits and cross-lingual inconsistencies
that jointly distort meaning while remaining superficially plausible. We
introduce BiMi, a bilingual multimodal framework that jointly performs
region-level localization, cross-modal and cross-lingual consistency detection,
and natural language explanation for misinformation analysis. To support
generalization, BiMi integrates an online retrieval module that supplements
model reasoning with up-to-date external context. We further release BiMiBench,
a large-scale and comprehensive benchmark constructed by systematically editing
real news images and subtitles, comprising 104,000 samples with realistic
manipulations across visual and linguistic modalities. To enhance
interpretability, we apply Group Relative Policy Optimization (GRPO) to improve
explanation quality, marking the first use of GRPO in this domain. Extensive
experiments demonstrate that BiMi outperforms strong baselines by up to +8.9 in
classification accuracy, +15.9 in localization accuracy, and +2.5 in
explanation BERTScore, advancing state-of-the-art performance in realistic,
multilingual misinformation detection. Code, models, and datasets will be
released.

</details>


### [62] [Utilizing a Novel Deep Learning Method for Scene Categorization in Remote Sensing Data](https://arxiv.org/abs/2506.22939)
*Ghufran A. Omran,Wassan Saad Abduljabbar Hayale,Ahmad AbdulQadir AlRababah,Israa Ibraheem Al-Barazanchi,Ravi Sekhar,Pritesh Shah,Sushma Parihar,Harshavardhan Reddy Penubadi*

Main category: cs.CV

TL;DR: 本文提出了一种名为CO-BRNN的新技术，解决了远程图像场景分类中的准确性问题，并展示了与现有技术相比的显著优势。


<details>
  <summary>Details</summary>
Motivation: 远程图像场景分类具有广泛应用，但深度学习模型在处理高噪声和多样性数据时的准确性较低。本文旨在提升远程观测数据中场景分类的准确性。

Method: 引入了一种创新性技术——Cuttlefish Optimized Bidirectional Recurrent Neural Network（CO-BRNN），并与多种现有方法进行了性能对比。

Result: CO-BRNN的准确率达到了97%，远高于对比方法（如LSTM-CRF的90%、MLP-CNN的85%、CNN-LSTM的80%）。

Conclusion: CO-BRNN在远程图像场景分类中展示了卓越性能，并验证了卫星数据物理确认的重要性。

Abstract: Scene categorization (SC) in remotely acquired images is an important subject
with broad consequences in different fields, including catastrophe control,
ecological observation, architecture for cities, and more. Nevertheless, its
several apps, reaching a high degree of accuracy in SC from distant observation
data has demonstrated to be difficult. This is because traditional conventional
deep learning models require large databases with high variety and high levels
of noise to capture important visual features. To address these problems, this
investigation file introduces an innovative technique referred to as the
Cuttlefish Optimized Bidirectional Recurrent Neural Network (CO- BRNN) for type
of scenes in remote sensing data. The investigation compares the execution of
CO-BRNN with current techniques, including Multilayer Perceptron- Convolutional
Neural Network (MLP-CNN), Convolutional Neural Network-Long Short Term Memory
(CNN-LSTM), and Long Short Term Memory-Conditional Random Field (LSTM-CRF),
Graph-Based (GB), Multilabel Image Retrieval Model (MIRM-CF), Convolutional
Neural Networks Data Augmentation (CNN-DA). The results demonstrate that
CO-BRNN attained the maximum accuracy of 97%, followed by LSTM-CRF with 90%,
MLP-CNN with 85%, and CNN-LSTM with 80%. The study highlights the significance
of physical confirmation to ensure the efficiency of satellite data.

</details>


### [63] [YM-WML: A new Yolo-based segmentation Model with Weighted Multi-class Loss for medical imaging](https://arxiv.org/abs/2506.22955)
*Haniyeh Nikkhah,Jafar Tanha,Mahdi Zarrin,SeyedEhsan Roshan,Amin Kazempour*

Main category: cs.CV

TL;DR: 该研究提出YM-WML模型用于心脏图像分割，结合强大特征提取、YOLOv11多尺度特征聚合与注意力机制，达到91.02的Dice系数，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 医疗图像分割面临类别不平衡和复杂结构等挑战，迫切需要设计有效模型提升心脏图像分割精度。

Method: 提出YM-WML模型，集成强大背骨网络、YOLOv11特征聚合及注意力分割头，并设计加权多类指数损失函数（WME）。

Result: YM-WML在ACDC数据集上实现了91.02的Dice相似系数，优于当前先进方法，并具有稳定训练、精准分割和优异的泛化能力。

Conclusion: YM-WML为心脏图像分割任务设定了新标杆，在性能与稳定性方面展现出显著优势。

Abstract: Medical image segmentation poses significant challenges due to class
imbalance and the complex structure of medical images. To address these
challenges, this study proposes YM-WML, a novel model for cardiac image
segmentation. The model integrates a robust backbone for effective feature
extraction, a YOLOv11 neck for multi-scale feature aggregation, and an
attention-based segmentation head for precise and accurate segmentation. To
address class imbalance, we introduce the Weighted Multi-class Exponential
(WME) loss function. On the ACDC dataset, YM-WML achieves a Dice Similarity
Coefficient of 91.02, outperforming state-of-the-art methods. The model
demonstrates stable training, accurate segmentation, and strong generalization,
setting a new benchmark in cardiac segmentation tasks.

</details>


### [64] [Peccavi: Visual Paraphrase Attack Safe and Distortion Free Image Watermarking Technique for AI-Generated Images](https://arxiv.org/abs/2506.22960)
*Shreyas Dixit,Ashhar Aziz,Shashwat Bajpai,Vasu Sharma,Aman Chadha,Vinija Jain,Amitava Das*

Main category: cs.CV

TL;DR: 本文探讨了生成式AI对内容真实性的威胁，及现有水印技术易遭受攻击的问题，提出了PECCAVI作为应对措施。


<details>
  <summary>Details</summary>
Motivation: 生成式AI生成的内容迅速增长，这引发了政治虚假信息传播的担忧。同时，现有的水印技术过于薄弱，难以应对当前强大的生成式AI解水印攻击。

Method: 提出PECCAVI水印技术，通过在图像的核心语义区域（非熔点）嵌入多通道频域水印，并结合噪声打磨技术，使水印不易被生成式AI的反向工程方法破坏。该方法具有与模型无关的特性。

Result: PECCAVI水印技术成功抵御了视觉重述攻击，并能在不让图片失真的情况下保护水印完整性。

Conclusion: PECCAVI技术提供了一种新的、更安全的解决方案，用以保护生成式AI内容的来源真实性，有潜力成为未来的行业标准。

Abstract: A report by the European Union Law Enforcement Agency predicts that by 2026,
up to 90 percent of online content could be synthetically generated, raising
concerns among policymakers, who cautioned that "Generative AI could act as a
force multiplier for political disinformation. The combined effect of
generative text, images, videos, and audio may surpass the influence of any
single modality." In response, California's Bill AB 3211 mandates the
watermarking of AI-generated images, videos, and audio. However, concerns
remain regarding the vulnerability of invisible watermarking techniques to
tampering and the potential for malicious actors to bypass them entirely.
Generative AI-powered de-watermarking attacks, especially the newly introduced
visual paraphrase attack, have shown an ability to fully remove watermarks,
resulting in a paraphrase of the original image. This paper introduces PECCAVI,
the first visual paraphrase attack-safe and distortion-free image watermarking
technique. In visual paraphrase attacks, an image is altered while preserving
its core semantic regions, termed Non-Melting Points (NMPs). PECCAVI
strategically embeds watermarks within these NMPs and employs multi-channel
frequency domain watermarking. It also incorporates noisy burnishing to counter
reverse-engineering efforts aimed at locating NMPs to disrupt the embedded
watermark, thereby enhancing durability. PECCAVI is model-agnostic. All
relevant resources and codes will be open-sourced.

</details>


### [65] [ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment](https://arxiv.org/abs/2506.22967)
*Amir Aghdam,Vincent Tao Hu*

Main category: cs.CV

TL;DR: 提出了一种零样本细粒度视频分类框架ActAlign，通过序列对齐实现对未见动作类别的视频分类，且无需视频文本监督或微调。


<details>
  <summary>Details</summary>
Motivation: 现有对比视觉-语言模型难以捕获区分细粒度活动所需的时间结构。

Method: 使用大语言模型生成有序子动作序列，并通过动态时间规整（DTW）技术，与视频帧在共享嵌入空间中进行对齐。

Result: ActAlign在ActionAtlas基准上达到了30.5%的准确率，超越人类水平的61.6%，并且表现优于参数量更大的视频语言模型。

Conclusion: 结合结构化语言先验与经典对齐技术，ActAlign为细粒度视频理解提供了一种可扩展且通用的开放集识别方法。

Abstract: We address the task of zero-shot fine-grained video classification, where no
video examples or temporal annotations are available for unseen action classes.
While contrastive vision-language models such as SigLIP demonstrate strong
open-set recognition via mean-pooled image-text similarity, they fail to
capture the temporal structure critical for distinguishing fine-grained
activities. We introduce ActAlign, a zero-shot framework that formulates video
classification as sequence alignment. For each class, a large language model
generates an ordered sub-action sequence, which is aligned with video frames
using Dynamic Time Warping (DTW) in a shared embedding space. Without any
video-text supervision or fine-tuning, ActAlign achieves 30.5% accuracy on the
extremely challenging ActionAtlas benchmark, where human accuracy is only
61.6%. ActAlign outperforms billion-parameter video-language models while using
approximately 8x less parameters. These results demonstrate that structured
language priors, combined with classical alignment techniques, offer a scalable
and general approach to unlocking the open-set recognition potential of
vision-language models for fine-grained video understanding.

</details>


### [66] [Probabilistic Prototype Calibration of Vision-Language Models for Generalized Few-shot Semantic Segmentation](https://arxiv.org/abs/2506.22979)
*Jie Liu,Jiayi Shen,Pan Zhou,Jan-Jakob Sonke,Efstratios Gavves*

Main category: cs.CV

TL;DR: 本文提出了一种名为FewCLIP的框架，用于广义少样本语义分割（GFSS），通过概率原型校准机制改进了跨模态原型的学习，提高了对新类的泛化能力，并在多个数据集上取得了领先的实验结果。


<details>
  <summary>Details</summary>
Motivation: 现有原型学习方法通常是确定性的，难以适应多样化的样本，尤其是在新类别注释稀缺的情况下。提出FewCLIP旨在解决这一局限性。

Method: FewCLIP通过概率原型校准机制改进原型学习，首先引入一个校准机制，用可学习的视觉校准原型细化冻结的文本原型；其次，采取分布正则化确保结构化且具备不确定性感知的原型学习方式。

Result: 实验结果表明，FewCLIP在PASCAL-5$^i$和COCO-20$^i$数据集上明显优于现有方法，在GFSS和类增量设置下均表现出众。代码已开源。

Conclusion: FewCLIP通过融合概率原型校准和分布正则化的方式，有效缓解了新类别数据不足带来的过拟合问题，加强了泛化性能，为GFSS提供了新的改进方向。

Abstract: Generalized Few-Shot Semantic Segmentation (GFSS) aims to extend a
segmentation model to novel classes with only a few annotated examples while
maintaining performance on base classes. Recently, pretrained vision-language
models (VLMs) such as CLIP have been leveraged in GFSS to improve
generalization on novel classes through multi-modal prototypes learning.
However, existing prototype-based methods are inherently deterministic,
limiting the adaptability of learned prototypes to diverse samples,
particularly for novel classes with scarce annotations. To address this, we
propose FewCLIP, a probabilistic prototype calibration framework over
multi-modal prototypes from the pretrained CLIP, thus providing more adaptive
prototype learning for GFSS. Specifically, FewCLIP first introduces a prototype
calibration mechanism, which refines frozen textual prototypes with learnable
visual calibration prototypes, leading to a more discriminative and adaptive
representation. Furthermore, unlike deterministic prototype learning
techniques, FewCLIP introduces distribution regularization over these
calibration prototypes. This probabilistic formulation ensures structured and
uncertainty-aware prototype learning, effectively mitigating overfitting to
limited novel class data while enhancing generalization. Extensive experimental
results on PASCAL-5$^i$ and COCO-20$^i$ datasets demonstrate that our proposed
FewCLIP significantly outperforms state-of-the-art approaches across both GFSS
and class-incremental setting. The code is available at
https://github.com/jliu4ai/FewCLIP.

</details>


### [67] [Revisiting CroPA: A Reproducibility Study and Enhancements for Cross-Prompt Adversarial Transferability in Vision-Language Models](https://arxiv.org/abs/2506.22982)
*Atharv Mittal,Agam Pandey,Amritanshu Tiwari,Sukrit Jindal,Swadesh Swain*

Main category: cs.CV

TL;DR: 研究评估跨提示攻击（CroPA），并优化其攻击方法以增强对大型视觉语言模型（VLMs）的对抗效率。


<details>
  <summary>Details</summary>
Motivation: 探讨VLMs在多模态场景下易受对抗攻击的脆弱性，为提升对抗攻击的生成质量提供解决方案。

Method: 提出新的初始化策略、研究跨图像的扰动迁移能力以及设计优化视觉编码器注意机制的损失函数，结合复现实验验证提出改进方案的有效性。

Result: 改进后的方法在多种主流VLMs上均表现出更高的对抗攻击成功率，并验证了其成果的可迁移性与鲁棒性。

Conclusion: 本研究深化了对VLMs对抗脆弱性的理解，为生成更通用的对抗样本提供了坚实框架，对实际安全性具有重要意义。

Abstract: Large Vision-Language Models (VLMs) have revolutionized computer vision,
enabling tasks such as image classification, captioning, and visual question
answering. However, they remain highly vulnerable to adversarial attacks,
particularly in scenarios where both visual and textual modalities can be
manipulated. In this study, we conduct a comprehensive reproducibility study of
"An Image is Worth 1000 Lies: Adversarial Transferability Across Prompts on
Vision-Language Models" validating the Cross-Prompt Attack (CroPA) and
confirming its superior cross-prompt transferability compared to existing
baselines. Beyond replication we propose several key improvements: (1) A novel
initialization strategy that significantly improves Attack Success Rate (ASR).
(2) Investigate cross-image transferability by learning universal
perturbations. (3) A novel loss function targeting vision encoder attention
mechanisms to improve generalization. Our evaluation across prominent VLMs --
including Flamingo, BLIP-2, and InstructBLIP as well as extended experiments on
LLaVA validates the original results and demonstrates that our improvements
consistently boost adversarial effectiveness. Our work reinforces the
importance of studying adversarial vulnerabilities in VLMs and provides a more
robust framework for generating transferable adversarial examples, with
significant implications for understanding the security of VLMs in real-world
applications.

</details>


### [68] [A Novel Frame Identification and Synchronization Technique for Smartphone Visible Light Communication Systems Based on Convolutional Neural Networks](https://arxiv.org/abs/2506.23004)
*Vaigai Nayaki Yokar,Hoa Le-Minh,Xicong Li,Wai Lok Woo,Luis Nero Alves,Stanislav Zvanovec,Tran The Son,Zabih Ghassemlooy*

Main category: cs.CV

TL;DR: 研究提出一种基于CNN的技术，用于短链路S2C VLC系统中的帧识别与同步，模型精度达到98.74%。


<details>
  <summary>Details</summary>
Motivation: 解决屏幕到摄像机通信(S2C)中，由于模糊、裁剪、旋转导致的帧识别和同步挑战。

Method: 设计并训练CNN模型，利用Python和TensorFlow Keras框架开发，在Jupyter Notebook中基于从头构建的数据集进行实验。

Result: 提出的模型在三组实验中表现良好，帧识别与同步准确率约为98.74%。

Conclusion: 该模型可提高S2C VLC系统的性能，证明其高效性和稳定性。

Abstract: This paper proposes a novel, robust, and lightweight supervised Convolutional
Neural Network (CNN)-based technique for frame identification and
synchronization, designed to enhance short-link communication performance in a
screen-to-camera (S2C) based visible light communication (VLC) system.
Developed using Python and the TensorFlow Keras framework, the proposed CNN
model was trained through three real-time experimental investigations conducted
in Jupyter Notebook. These experiments incorporated a dataset created from
scratch to address various real-time challenges in S2C communication, including
blurring, cropping, and rotated images in mobility scenarios. Overhead frames
were introduced for synchronization, which leads to enhanced system
performance. The experimental results demonstrate that the proposed model
achieves an overall accuracy of approximately 98.74%, highlighting its
effectiveness in identifying and synchronizing frames in S2C VLC systems.

</details>


### [69] [MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models](https://arxiv.org/abs/2506.23009)
*Jian Chen,Wenye Ma,Penghang Liu,Wei Wang,Tengwei Song,Ming Li,Chenguang Wang,Ruiyi Zhang,Changyou Chen*

Main category: cs.CV

TL;DR: 本文提出了MusiXQA数据集，以评估和提升多模态大语言模型（MLLMs）对乐谱的理解。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在乐谱理解方面的能力尚未深度探索，需开发专门的评估工具和方法。

Method: 通过MusiXTeX生成高质量合成乐谱，构建涵盖音符、和弦、谱号等注释的MusiXQA数据集，并基于该数据集对模型进行微调和评估。

Result: 发现当前最先进的MLLMs在乐谱理解方面存在显著局限性，微调后的Phi-3-MusiX模型表现明显优于GPT基础模型。

Conclusion: MusiXQA数据集与Phi-3-MusiX模型为未来MLLMs在乐谱理解领域的研究奠定了基础。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable visual
reasoning abilities in natural images, text-rich documents, and graphic
designs. However, their ability to interpret music sheets remains
underexplored. To bridge this gap, we introduce MusiXQA, the first
comprehensive dataset for evaluating and advancing MLLMs in music sheet
understanding. MusiXQA features high-quality synthetic music sheets generated
via MusiXTeX, with structured annotations covering note pitch and duration,
chords, clefs, key/time signatures, and text, enabling diverse visual QA tasks.
Through extensive evaluations, we reveal significant limitations of current
state-of-the-art MLLMs in this domain. Beyond benchmarking, we developed
Phi-3-MusiX, an MLLM fine-tuned on our dataset, achieving significant
performance gains over GPT-based methods. The proposed dataset and model
establish a foundation for future advances in MLLMs for music sheet
understanding. Code, data, and model will be released upon acceptance.

</details>


### [70] [VisionScores -- A system-segmented image score dataset for deep learning tasks](https://arxiv.org/abs/2506.23030)
*Alejandro Romero Amezcua,Mariano José Juan Rivera Meraz*

Main category: cs.CV

TL;DR: VisionScores 是一个新颖的、用于图像评分的数据集，专注于结构化和高信息密度的图像，以支持机器学习和深度学习任务。


<details>
  <summary>Details</summary>
Motivation: VisionScores 的目标是通过高质量、结构化的图像，为深度学习与机器学习任务提供一个专注于两手钢琴曲的图像评分数据集。

Method: 数据集包括两种场景：1. 不同作曲家相同类型（奏鸣曲）的作品共14k样本；2. 同一作曲家（李斯特）的不同类型作品共10.8k样本，总计24.8k样本，格式为灰度图像。

Result: 该数据集包含分段图像和全页乐谱，还提供了格式化的样本及相关元数据，支持进一步的算法分析。

Conclusion: VisionScores 为音乐评分图像分析提供了独特的、高信息密度的研究工具，有助于提升模型性能并支持复杂的图像与音乐映射任务。

Abstract: VisionScores presents a novel proposal being the first system-segmented image
score dataset, aiming to offer structure-rich, high information-density images
for machine and deep learning tasks. Delimited to two-handed piano pieces, it
was built to consider not only certain graphic similarity but also composition
patterns, as this creative process is highly instrument-dependent. It provides
two scenarios in relation to composer and composition type. The first, formed
by 14k samples, considers works from different authors but the same composition
type, specifically, Sonatinas. The latter, consisting of 10.8K samples,
presents the opposite case, various composition types from the same author,
being the one selected Franz Liszt. All of the 24.8k samples are formatted as
grayscale jpg images of $128 \times 512$ pixels. VisionScores supplies the
users not only the formatted samples but the systems' order and pieces'
metadata. Moreover, unsegmented full-page scores and the pre-formatted images
are included for further analysis.

</details>


### [71] [Inpainting is All You Need: A Diffusion-based Augmentation Method for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2506.23038)
*Xinrong Hu,Yiyu Shi*

Main category: cs.CV

TL;DR: 提出了AugPaint，通过inpainting生成图像-标签对的数据增强框架，解决医疗图像标注数据有限的问题。


<details>
  <summary>Details</summary>
Motivation: 医疗数据中像素级标注获取困难，因此亟需在少量标注下提高分割性能的技术。

Method: 利用潜在扩散模型对有限标注数据的图像标签对进行inpainting数据增强，生成符合标签掩码的合成图像用于下游分割模型的训练。

Result: 在CT、MRI、皮肤成像等四个公开医疗分割数据集上验证，结果超越现有方法，显著提升分割性能。

Conclusion: AugPaint在标注数据稀缺场景中具有高效性和实用性，为医疗数据分割提供了新方法。

Abstract: Collecting pixel-level labels for medical datasets can be a laborious and
expensive process, and enhancing segmentation performance with a scarcity of
labeled data is a crucial challenge. This work introduces AugPaint, a data
augmentation framework that utilizes inpainting to generate image-label pairs
from limited labeled data. AugPaint leverages latent diffusion models, known
for their ability to generate high-quality in-domain images with low overhead,
and adapts the sampling process for the inpainting task without need for
retraining. Specifically, given a pair of image and label mask, we crop the
area labeled with the foreground and condition on it during reversed denoising
process for every noise level. Masked background area would gradually be filled
in, and all generated images are paired with the label mask. This approach
ensures the accuracy of match between synthetic images and label masks, setting
it apart from existing dataset generation methods. The generated images serve
as valuable supervision for training downstream segmentation models,
effectively addressing the challenge of limited annotations. We conducted
extensive evaluations of our data augmentation method on four public medical
image segmentation datasets, including CT, MRI, and skin imaging. Results
across all datasets demonstrate that AugPaint outperforms state-of-the-art
label-efficient methodologies, significantly improving segmentation
performance.

</details>


### [72] [From Coarse to Fine: Learnable Discrete Wavelet Transforms for Efficient 3D Gaussian Splatting](https://arxiv.org/abs/2506.23042)
*Hung Nguyen,An Le,Runfa Li,Truong Nguyen*

Main category: cs.CV

TL;DR: 本文提出了AutoOpti3DGS，一个训练框架，通过引入可学习的离散小波变换，减少了3D高斯点集的增长，同时保持了高质量的视觉效果。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯点集视角合成系统中因高斯原语数量激增而导致的存储和带宽压力，同时确保视觉表现力不受影响。

Method: 将输入图像送入可学习的前向和逆离散小波变换序列，固定低通滤波器，高通滤波器设为可学习且初始值为零，并通过辅助正交性损失逐渐激活细频率的信息。

Result: 通过延迟冗余精细高斯的形成，AutoOpti3DGS能够优先捕捉全局结构，仅在必要时精化细节，同时减少高斯原语的数量。实验表明框架只需学习单个滤波器学习率的超参数，且与现有高效的3D高斯点集框架无缝集成。

Conclusion: AutoOpti3DGS实现了更加稀疏的场景表示形式，更适配于内存或存储受限的硬件，同时维持了出色的视觉表现。

Abstract: 3D Gaussian Splatting has emerged as a powerful approach in novel view
synthesis, delivering rapid training and rendering but at the cost of an
ever-growing set of Gaussian primitives that strains memory and bandwidth. We
introduce AutoOpti3DGS, a training-time framework that automatically restrains
Gaussian proliferation without sacrificing visual fidelity. The key idea is to
feed the input images to a sequence of learnable Forward and Inverse Discrete
Wavelet Transforms, where low-pass filters are kept fixed, high-pass filters
are learnable and initialized to zero, and an auxiliary orthogonality loss
gradually activates fine frequencies. This wavelet-driven, coarse-to-fine
process delays the formation of redundant fine Gaussians, allowing 3DGS to
capture global structure first and refine detail only when necessary. Through
extensive experiments, AutoOpti3DGS requires just a single filter learning-rate
hyper-parameter, integrates seamlessly with existing efficient 3DGS frameworks,
and consistently produces sparser scene representations more compatible with
memory or storage-constrained hardware.

</details>


### [73] [Ovis-U1 Technical Report](https://arxiv.org/abs/2506.23044)
*Guo-Hua Wang,Shanshan Zhao,Xinjie Zhang,Liangfu Cao,Pengxin Zhan,Lunhao Duan,Shiyin Lu,Minghao Fu,Xiaohao Chen,Jianshan Zhao,Yang Li,Qing-Guo Chen*

Main category: cs.CV

TL;DR: Ovis-U1是一个3B参数的多模态统一模型，集成了理解、生成和编辑功能，在多个基准上超越了当前最先进模型。


<details>
  <summary>Details</summary>
Motivation: 提高多模态技术的统一性能，建立一个集成理解、生成和编辑的单一高效模型。

Method: Ovis-U1采用了从语言模型出发的统一训练方法，配备扩散视觉解码器和双向标记修正器，与冻结多模态语言模型形成对比。

Result: 在OpenCompass、DPG-Bench等多个基准上，分别超过了当前最先进模型，实现了更高的理解、生成和编辑分数。

Conclusion: Ovis-U1作为Ovis系列首个统一模型，显著推进了多模态技术在理解、生成和编辑任务中的性能表现。

Abstract: In this report, we introduce Ovis-U1, a 3-billion-parameter unified model
that integrates multimodal understanding, text-to-image generation, and image
editing capabilities. Building on the foundation of the Ovis series, Ovis-U1
incorporates a diffusion-based visual decoder paired with a bidirectional token
refiner, enabling image generation tasks comparable to leading models like
GPT-4o. Unlike some previous models that use a frozen MLLM for generation
tasks, Ovis-U1 utilizes a new unified training approach starting from a
language model. Compared to training solely on understanding or generation
tasks, unified training yields better performance, demonstrating the
enhancement achieved by integrating these two tasks. Ovis-U1 achieves a score
of 69.6 on the OpenCompass Multi-modal Academic Benchmark, surpassing recent
state-of-the-art models such as Ristretto-3B and SAIL-VL-1.5-2B. In
text-to-image generation, it excels with scores of 83.72 and 0.89 on the
DPG-Bench and GenEval benchmarks, respectively. For image editing, it achieves
4.00 and 6.42 on the ImgEdit-Bench and GEdit-Bench-EN, respectively. As the
initial version of the Ovis unified model series, Ovis-U1 pushes the boundaries
of multimodal understanding, generation, and editing.

</details>


### [74] [Empowering Small VLMs to Think with Dynamic Memorization and Exploration](https://arxiv.org/abs/2506.23061)
*Jiazhen Liu,Yuchuan Deng,Long Chen*

Main category: cs.CV

TL;DR: 小型视听模型（SVLM）在具备可靠推理能力方面存在挑战，DyME提出动态选择记忆（SFT）与探索（RLVR）的方法，改善了性能。


<details>
  <summary>Details</summary>
Motivation: 现有训练范式的高要求超出了SVLM的能力范围，导致伪推理和性能衰退的严重问题，需寻找减少对模型容量依赖的解决方案。

Method: 提出了一种称为DyME的训练范式，在每一步优化中动态选择记忆（通过SFT）与探索（通过RLVR）模式，确保更新以平衡两者的方式进行。

Result: 实验显示DyME在多个领域实现了这种平衡，并带来显著的性能提升。

Conclusion: DyME作为一种实际且有效的方法，为小型模型赋予可靠的推理能力。

Abstract: Empowering Small-scale Vision-Language Models (SVLMs) with reliable thinking
capabilities remains fundamentally challenging due to their limited parameter
capacity and weak instruction-following abilities. Existing training paradigms,
including Supervised Fine-Tuning (SFT) and Reinforcement Learning with
Verifiable Reward (RLVR), impose substantial demands on the base VLM, exceeding
the capabilities of SVLMs. Consequently, directly applying these paradigms to
SVLMs often suffers from severe pseudo thinking traces and advantage collapse,
ultimately undermining both thinking reliability and task performance. A
natural solution is to combine SFT and RLVR, leveraging their complementarity
to reduce the dependence on model capacity. However, the widely adopted
two-stage training paradigm still performs poorly on SVLMs, as their tendency
toward sub-optimal convergence hinders the trade-off and limits the benefits of
the combination. To address this, we propose DyME, a novel training paradigm
that Dynamically selects between Memorization (via SFT) and Exploration (via
RLVR) modes at each optimization step, ensuring that every update contributes
to the trade-off. Extensive experiments across diverse domains demonstrate that
DyME consistently achieves this balance, and thus delivers substantial
performance improvements. These results establish DyME as a practical and
effective solution for empowering SVLMs with reliable thinking capabilities.
GitHub: https://github.com/HKUST-LongGroup/DyME

</details>


### [75] [CoreMark: Toward Robust and Universal Text Watermarking Technique](https://arxiv.org/abs/2506.23066)
*Jiale Meng,Yiming Li,Zheming Lu,Zewei He,Hao Luo,Tianwei Zhang*

Main category: cs.CV

TL;DR: 该论文提出一种名为CORE的新型文本水印嵌入方法，通过修改CORE的厚度嵌入隐藏数据，同时推出能增强小字体抗干扰强度的通用调节器CoreMark。


<details>
  <summary>Details</summary>
Motivation: 现有文本水印手段难以同时满足鲁棒性、通用性和不可察觉性。

Method: 提出一种称为CORE的嵌入范式，根据字符结构提取CORE，并通过调整其厚度嵌入数据，辅以字体大小敏感的嵌入强度调节器。

Result: CoreMark展现了对多语言、多字体的优秀通用性，并在截图、打印扫描以及打印摄影攻击下表现出显著优势。

Conclusion: CoreMark很好平衡了鲁棒性和不可察觉性，展示出优越的文本水印表现。

Abstract: Text watermarking schemes have gained considerable attention in recent years,
yet still face critical challenges in achieving simultaneous robustness,
generalizability, and imperceptibility. This paper introduces a new embedding
paradigm,termed CORE, which comprises several consecutively aligned black pixel
segments. Its key innovation lies in its inherent noise resistance during
transmission and broad applicability across languages and fonts. Based on the
CORE, we present a text watermarking framework named CoreMark. Specifically,
CoreMark first dynamically extracts COREs from characters. Then, the characters
with stronger robustness are selected according to the lengths of COREs. By
modifying the thickness of the CORE, the hidden data is embedded into the
selected characters without causing significant visual distortions. Moreover, a
general plug-and-play embedding strength modulator is proposed, which can
adaptively enhance the robustness for small font sizes by adjusting the
embedding strength according to the font size. Experimental evaluation
indicates that CoreMark demonstrates outstanding generalizability across
multiple languages and fonts. Compared to existing methods, CoreMark achieves
significant improvements in resisting screenshot, print-scan, and print camera
attacks, while maintaining satisfactory imperceptibility.

</details>


### [76] [Unsupervised 3D Braided Hair Reconstruction from a Single-View Image](https://arxiv.org/abs/2506.23072)
*Jing Gao*

Main category: cs.CV

TL;DR: 提出一种无监督方法，用于单视角图像的3D辫子发型重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法对复杂紧密的辫子发型建模存有困难，需要一种更高效准确的方法。

Method: 借助利用辫子理论的合成辫子模型，进行单视角图像的无监督3D发型重建。

Result: 实验表明，该方法在准确性、真实性和效率方面优于现有方法。

Conclusion: 该方法推进了数字人中复杂发型建模的表现力。

Abstract: Reconstructing 3D braided hairstyles from single-view images remains a
challenging task due to the intricate interwoven structure and complex
topologies of braids. Existing strand-based hair reconstruction methods
typically focus on loose hairstyles and often struggle to capture the
fine-grained geometry of braided hair. In this paper, we propose a novel
unsupervised pipeline for efficiently reconstructing 3D braided hair from
single-view RGB images. Leveraging a synthetic braid model inspired by braid
theory, our approach effectively captures the complex intertwined structures of
braids. Extensive experiments demonstrate that our method outperforms
state-of-the-art approaches, providing superior accuracy, realism, and
efficiency in reconstructing 3D braided hairstyles, supporting expressive
hairstyle modeling in digital humans.

</details>


### [77] [Learning Counterfactually Decoupled Attention for Open-World Model Attribution](https://arxiv.org/abs/2506.23074)
*Yu Zheng,Boyang Gong,Fanye Kong,Yueqi Duan,Bingyao Yu,Wenzhao Zheng,Lei Chen,Jiwen Lu,Jie Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为反事实解耦注意力学习（CDAL）的方法，用于开放世界模型归因，在现有方法中表现优越，尤其应对新型攻击时表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖人工设计的区域划分或特征空间，容易受到虚假统计相关性的影响，并在开放世界场景中的新型攻击下遇到困难。

Method: 提出一种反事实解耦注意力学习（CDAL）方法，通过显式建模注意力视觉轨迹与源模型归因之间的因果关系，解耦模型特定人工痕迹与混淆偏置，并最大化因果效应提升泛化能力。

Result: 在现有开放世界模型归因基准上，CDAL方法显著提升了现有模型的性能，特别是在应对新型攻击方面效果显著，且只需极少的计算开销。

Conclusion: CDAL方法通过因果建模优化注意力图质量，有效捕捉生成模式，实现了在开放世界模型归因任务中优异的表现，展示了广泛的潜力。

Abstract: In this paper, we propose a Counterfactually Decoupled Attention Learning
(CDAL) method for open-world model attribution. Existing methods rely on
handcrafted design of region partitioning or feature space, which could be
confounded by the spurious statistical correlations and struggle with novel
attacks in open-world scenarios. To address this, CDAL explicitly models the
causal relationships between the attentional visual traces and source model
attribution, and counterfactually decouples the discriminative model-specific
artifacts from confounding source biases for comparison. In this way, the
resulting causal effect provides a quantification on the quality of learned
attention maps, thus encouraging the network to capture essential generation
patterns that generalize to unseen source models by maximizing the effect.
Extensive experiments on existing open-world model attribution benchmarks show
that with minimal computational overhead, our method consistently improves
state-of-the-art models by large margins, particularly for unseen novel
attacks. Source code: https://github.com/yzheng97/CDAL.

</details>


### [78] [Dynamic Contrastive Learning for Hierarchical Retrieval: A Case Study of Distance-Aware Cross-View Geo-Localization](https://arxiv.org/abs/2506.23077)
*Suofei Zhang,Xinxin Wang,Xiaofu Wu,Quan Zhou,Haifeng Hu*

Main category: cs.CV

TL;DR: 提出了距离感知的跨视图地理定位问题（DACVGL），并构建了首个多视图影像与精确距离注释配对的基准数据集DA-Campus。此外，提出了动态对比学习（DyCL）方法以更准确地处理复杂的空间关系，并在实验中取得显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 由于现有方法主要侧重于跨域图像匹配的精度，未能全面捕捉目标周围的上下文信息，同时忽略了定位误差带来的成本，需要一种新方法提升地理定位能力。

Method: 通过构建DA-Campus数据集，将DACVGL问题定义为跨域分层检索问题；并提出动态对比学习（DyCL）框架，该框架基于分层空间边距递进对齐特征表征。

Result: DyCL方法在分层检索性能和整体跨视图地理定位精度方面均表现出显著的改进。

Conclusion: DyCL框架体现了对复杂空间关系的较好利用，并为解决DACVGL问题提供了新的视角，相关代码和基准数据集已公开发布促进进一步研究。

Abstract: Existing deep learning-based cross-view geo-localization methods primarily
focus on improving the accuracy of cross-domain image matching, rather than
enabling models to comprehensively capture contextual information around the
target and minimize the cost of localization errors. To support systematic
research into this Distance-Aware Cross-View Geo-Localization (DACVGL) problem,
we construct Distance-Aware Campus (DA-Campus), the first benchmark that pairs
multi-view imagery with precise distance annotations across three spatial
resolutions. Based on DA-Campus, we formulate DACVGL as a hierarchical
retrieval problem across different domains. Our study further reveals that, due
to the inherent complexity of spatial relationships among buildings, this
problem can only be addressed via a contrastive learning paradigm, rather than
conventional metric learning. To tackle this challenge, we propose Dynamic
Contrastive Learning (DyCL), a novel framework that progressively aligns
feature representations according to hierarchical spatial margins. Extensive
experiments demonstrate that DyCL is highly complementary to existing
multi-scale metric learning methods and yields substantial improvements in both
hierarchical retrieval performance and overall cross-view geo-localization
accuracy. Our code and benchmark are publicly available at
https://github.com/anocodetest1/DyCL.

</details>


### [79] [Frequency-enhanced Multi-granularity Context Network for Efficient Vertebrae Segmentation](https://arxiv.org/abs/2506.23086)
*Jian Shi,Tianqi You,Pingping Zhang,Hongli Zhang,Rui Xu,Haojie Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为FMC-Net的多频率多粒度上下文网络，用于提高3D CT和MRI影像中的椎骨分割准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理图像模糊和区分相似椎骨时存在挑战，急需改进算法以更好地支持临床应用。

Method: 通过小波变换对图像进行无损下采样，处理高频和低频分量。高频分量采用特征精细化方法提取细节，低频分量通过多粒度状态空间模型聚合特征并捕获长距离依赖。

Result: 在CT和MRI椎骨分割数据集上的实验表明，FMC-Net在性能上超越了现有最先进的技术。

Conclusion: FMC-Net通过频率增强和多粒度方法提升了模糊图像的分割精度，并有效应对复杂的脊椎结构分割任务。

Abstract: Automated and accurate segmentation of individual vertebra in 3D CT and MRI
images is essential for various clinical applications. Due to the limitations
of current imaging techniques and the complexity of spinal structures, existing
methods still struggle with reducing the impact of image blurring and
distinguishing similar vertebrae. To alleviate these issues, we introduce a
Frequency-enhanced Multi-granularity Context Network (FMC-Net) to improve the
accuracy of vertebrae segmentation. Specifically, we first apply wavelet
transform for lossless downsampling to reduce the feature distortion in blurred
images. The decomposed high and low-frequency components are then processed
separately. For the high-frequency components, we apply a High-frequency
Feature Refinement (HFR) to amplify the prominence of key features and filter
out noises, restoring fine-grained details in blurred images. For the
low-frequency components, we use a Multi-granularity State Space Model (MG-SSM)
to aggregate feature representations with different receptive fields,
extracting spatially-varying contexts while capturing long-range dependencies
with linear complexity. The utilization of multi-granularity contexts is
essential for distinguishing similar vertebrae and improving segmentation
accuracy. Extensive experiments demonstrate that our method outperforms
state-of-the-art approaches on both CT and MRI vertebrae segmentation datasets.
The source code is publicly available at https://github.com/anaanaa/FMCNet.

</details>


### [80] [Where, What, Why: Towards Explainable Driver Attention Prediction](https://arxiv.org/abs/2506.23088)
*Yuchen Zhou,Jiayu Tang,Xiaoyan Xiao,Yueyao Lin,Linkai Liu,Zipeng Guo,Hao Fei,Xiaobo Xia,Chao Gou*

Main category: cs.CV

TL;DR: 提出了一种新的解释性驾驶员注意力预测方法，并引入了一个解释性驾驶员注意力数据集（W3DA）。


<details>
  <summary>Details</summary>
Motivation: 通过预测驾驶员注意力分布和认知动机间的关系，解决现有方法仅生成空间热图的局限性。

Method: 提出了一个名为LLada的框架，将像素建模、语义解析与认知推理整合到端到端结构中，同时提供W3DA数据集支持。

Result: LLada框架在多个数据集和驾驶条件下表现出很强的泛化能力。

Conclusion: 此研究为更深入地理解驾驶员注意力机制开辟了路径，对无人驾驶、智能驾驶训练以及人机交互具有重要意义。

Abstract: Modeling task-driven attention in driving is a fundamental challenge for both
autonomous vehicles and cognitive science. Existing methods primarily predict
where drivers look by generating spatial heatmaps, but fail to capture the
cognitive motivations behind attention allocation in specific contexts, which
limits deeper understanding of attention mechanisms. To bridge this gap, we
introduce Explainable Driver Attention Prediction, a novel task paradigm that
jointly predicts spatial attention regions (where), parses attended semantics
(what), and provides cognitive reasoning for attention allocation (why). To
support this, we present W3DA, the first large-scale explainable driver
attention dataset. It enriches existing benchmarks with detailed semantic and
causal annotations across diverse driving scenarios, including normal
conditions, safety-critical situations, and traffic accidents. We further
propose LLada, a Large Language model-driven framework for driver attention
prediction, which unifies pixel modeling, semantic parsing, and cognitive
reasoning within an end-to-end architecture. Extensive experiments demonstrate
the effectiveness of LLada, exhibiting robust generalization across datasets
and driving conditions. This work serves as a key step toward a deeper
understanding of driver attention mechanisms, with significant implications for
autonomous driving, intelligent driver training, and human-computer
interaction.

</details>


### [81] [DC-TTA: Divide-and-Conquer Framework for Test-Time Adaptation of Interactive Segmentation](https://arxiv.org/abs/2506.23104)
*Jihun Kim,Hoyong Kwon,Hyeokjun Kweon,Wooseong Jeong,Kuk-Jin Yoon*

Main category: cs.CV

TL;DR: 提出了一种名为DC-TTA的测试时适应框架，以解决Segment Anything Model在复杂场景中的分割挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的互动分割模型在处理复杂场景（如伪装或多部分物体时）表现不足，尤其是Segment Anything Model难以充分利用用户交互来改进分割。

Method: 提出DC-TTA框架，通过将用户点击分为子集后独立处理的"分而治之"方法进行单样本测试时调整，并融合不同子模型的结果以形成统一预测器。

Result: 在多个基准测试中，DC-TTA显著优于SAM零样本结果和传统测试时适应方法，能以更少的交互实现伪装物体分割等复杂任务的更高准确率。

Conclusion: DC-TTA方法利用用户交互进行测试时适应，有效解决复杂场景下分割精度不足的问题，为互动分割任务提供了更强大的解决方案。

Abstract: Interactive segmentation (IS) allows users to iteratively refine object
boundaries with minimal cues, such as positive and negative clicks. While the
Segment Anything Model (SAM) has garnered attention in the IS community for its
promptable segmentation capabilities, it often struggles in specialized domains
or when handling complex scenarios (e.g., camouflaged or multi-part objects).
To overcome these challenges, we propose DC-TTA, a novel test-time adaptation
(TTA) framework that adapts SAM on a per-sample basis by leveraging user
interactions as supervision. Instead of forcing a single model to incorporate
all user clicks at once, DC-TTA partitions the clicks into more coherent
subsets, each processed independently via TTA with a separated model. This
Divide-and-Conquer strategy reduces conflicts among diverse cues and enables
more localized updates. Finally, we merge the adapted models to form a unified
predictor that integrates the specialized knowledge from each subset.
Experimental results across various benchmarks demonstrate that DC-TTA
significantly outperforms SAM's zero-shot results and conventional TTA methods,
effectively handling complex tasks such as camouflaged object segmentation with
fewer interactions and improved accuracy.

</details>


### [82] [Computer-Aided Multi-Stroke Character Simplification by Stroke Removal](https://arxiv.org/abs/2506.23106)
*Ryo Ishiyama,Shinnosuke Matsuo,Seiichi Uchida*

Main category: cs.CV

TL;DR: 本研究通过去除多笔画字符中对识别影响最小的笔画，以简化字符，同时保留其可读性。


<details>
  <summary>Details</summary>
Motivation: 多笔画字符如汉字和日文字符因复杂性导致学习困难，尤其是对非母语学习者，简化字符有助于降低学习门槛并改进字体设计和高效交流。

Method: 提出了一种框架，利用字符识别模型评估字符可读性，并选择性地去除对识别影响较小的笔画，从而对字符进行系统性简化。

Result: 实验在1,256个字符（5到20笔画）中显示，去除多个笔画后多数字符仍可区分，验证了简化字符的可行性。

Conclusion: 该研究表明字符简化不仅可行，还有助于制定更规范化的简化策略，对语言学习、字体设计与交流系统具有重要意义。

Abstract: Multi-stroke characters in scripts such as Chinese and Japanese can be highly
complex, posing significant challenges for both native speakers and,
especially, non-native learners. If these characters can be simplified without
degrading their legibility, it could reduce learning barriers for non-native
speakers, facilitate simpler and legible font designs, and contribute to
efficient character-based communication systems. In this paper, we propose a
framework to systematically simplify multi-stroke characters by selectively
removing strokes while preserving their overall legibility. More specifically,
we use a highly accurate character recognition model to assess legibility and
remove those strokes that minimally impact it. Experimental results on 1,256
character classes with 5, 10, 15, and 20 strokes reveal several key findings,
including the observation that even after removing multiple strokes, many
characters remain distinguishable. These findings suggest the potential for
more formalized simplification strategies.

</details>


### [83] [Hierarchical Corpus-View-Category Refinement for Carotid Plaque Risk Grading in Ultrasound](https://arxiv.org/abs/2506.23108)
*Zhiyuan Zhu,Jian Wang,Yong Jiang,Tong Han,Yuhao Huang,Ang Zhang,Kaiwen Yang,Mingyuan Luo,Zhe Liu,Yaofei Duan,Dong Ni,Tianhong Tang,Xin Yang*

Main category: cs.CV

TL;DR: 该论文提出了一种称为Corpus-View-Category Refinement Framework (CVC-RF)的新方法，用于颈动脉斑块分级 (CPG)，解决了目前多视图分类方法中对表示学习和类别特征差异关注不足的问题。


<details>
  <summary>Details</summary>
Motivation: 颈动脉斑块分级对评估心血管和脑血管疾病风险至关重要，而由于斑块小尺寸和类别内部的高变异性，依赖多视图超声评估的任务面临很多挑战。研究动机在于改进现有深度学习方法在多视图和跨类别特征学习上的表现。

Method: 提出了一种Corpus-View-Category Refinement Framework (CVC-RF)，包含以下创新：1) 基于Carotid Plaque-RADS指南的首个深度学习方法；2) 利用中心记忆对比损失增强网络建模能力；3) 使用级联下采样注意模块融合多尺度信息；4) 引入无参数专家混合加权策略以实现特征解耦。

Result: 该框架通过多层次的特征优化，显著提升了颈动脉斑块分级任务的性能，达到了最新的状态-of-the-art表现。

Conclusion: CVC-RF框架很好地解决了现有方法的不足，通过全局特征建模与多层次优化，有效提升了在复杂分类任务中的泛化性能，显示出在实际临床应用中的潜力。

Abstract: Accurate carotid plaque grading (CPG) is vital to assess the risk of
cardiovascular and cerebrovascular diseases. Due to the small size and high
intra-class variability of plaque, CPG is commonly evaluated using a
combination of transverse and longitudinal ultrasound views in clinical
practice. However, most existing deep learning-based multi-view classification
methods focus on feature fusion across different views, neglecting the
importance of representation learning and the difference in class features. To
address these issues, we propose a novel Corpus-View-Category Refinement
Framework (CVC-RF) that processes information from Corpus-, View-, and
Category-levels, enhancing model performance. Our contribution is four-fold.
First, to the best of our knowledge, we are the foremost deep learning-based
method for CPG according to the latest Carotid Plaque-RADS guidelines. Second,
we propose a novel center-memory contrastive loss, which enhances the network's
global modeling capability by comparing with representative cluster centers and
diverse negative samples at the Corpus level. Third, we design a cascaded
down-sampling attention module to fuse multi-scale information and achieve
implicit feature interaction at the View level. Finally, a parameter-free
mixture-of-experts weighting strategy is introduced to leverage class
clustering knowledge to weight different experts, enabling feature decoupling
at the Category level. Experimental results indicate that CVC-RF effectively
models global features via multi-level refinement, achieving state-of-the-art
performance in the challenging CPG task.

</details>


### [84] [MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings](https://arxiv.org/abs/2506.23115)
*Haonan Chen,Hong Liu,Yuping Luo,Liang Wang,Nan Yang,Furu Wei,Zhicheng Dou*

Main category: cs.CV

TL;DR: MoCa框架通过两阶段方法优化现有因果视觉语言模型(VLMs)，解决嵌入任务在因果注意力、标注数据依赖及训练多样性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 目前的多模态嵌入模型在因果注意力、数据标注成本及目标训练多样性上存在不足，亟需更高效的嵌入方法。

Method: MoCa包括两阶段：第一阶段采用模态感知的连续预训练，通过联合重建目标改进双向上下文推理；第二阶段利用异构对比微调，引入多样化多模态数据增强模型泛化能力。

Result: MoCa在MMEB和ViDoRe-v2基准上取得最佳表现，实现了新的性能状态，并展现了训练数据和模型规模下的强扩展性。

Conclusion: MoCa成功解决了现有VLMs的关键局限，显著提升了多模态任务的表现水平，为实现更强大的多模态嵌入提供了新方法。

Abstract: Multimodal embedding models, built upon causal Vision Language Models (VLMs),
have shown promise in various tasks. However, current approaches face three key
limitations: the use of causal attention in VLM backbones is suboptimal for
embedding tasks; scalability issues due to reliance on high-quality labeled
paired data for contrastive learning; and limited diversity in training
objectives and data. To address these issues, we propose MoCa, a two-stage
framework for transforming pre-trained VLMs into effective bidirectional
multimodal embedding models. The first stage, Modality-aware Continual
Pre-training, introduces a joint reconstruction objective that simultaneously
denoises interleaved text and image inputs, enhancing bidirectional
context-aware reasoning. The second stage, Heterogeneous Contrastive
Fine-tuning, leverages diverse, semantically rich multimodal data beyond simple
image-caption pairs to enhance generalization and alignment. Our method
addresses the stated limitations by introducing bidirectional attention through
continual pre-training, scaling effectively with massive unlabeled datasets via
joint reconstruction objectives, and utilizing diverse multimodal data for
enhanced representation robustness. Experiments demonstrate that MoCa
consistently improves performance across MMEB and ViDoRe-v2 benchmarks,
achieving new state-of-the-art results, and exhibits strong scalability with
both model size and training data on MMEB.

</details>


### [85] [Enhancing Spatial Reasoning in Multimodal Large Language Models through Reasoning-based Segmentation](https://arxiv.org/abs/2506.23120)
*Zhenhua Ning,Zhuotao Tian,Shaoshuai Shi,Guangming Lu,Daojing He,Wenjie Pei,Li Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种新的3D点云感知方法R^2S，并引入了新的复杂推理任务数据集3D ReasonSeg，两者共同提升了点云数据的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有点云感知方法难以处理需要精确空间推理的复杂指令，而3D点云数据能提供丰富的空间线索。

Method: 提出了基于推理的分割框架R^2S，将空间推理分解为识别相关元素和基于视觉先验处理指令两个阶段。同时构建了一个全新的推理分割数据集3D ReasonSeg。

Result: 通过定量和定性实验验证了R^2S框架及3D ReasonSeg数据集显著增强了3D点云感知的空间推理能力。

Conclusion: R^2S框架及3D ReasonSeg数据集为实现更强空间推理能力和研究基准提供了新方法和标准。

Abstract: Recent advances in point cloud perception have demonstrated remarkable
progress in scene understanding through vision-language alignment leveraging
large language models (LLMs). However, existing methods may still encounter
challenges in handling complex instructions that require accurate spatial
reasoning, even if the 3D point cloud data provides detailed spatial cues such
as size and position for identifying the targets. To tackle this issue, we
propose Relevant Reasoning Segmentation (R$^2$S), a reasoning-based
segmentation framework. The framework emulates human cognitive processes by
decomposing spatial reasoning into two sequential stages: first identifying
relevant elements, then processing instructions guided by their associated
visual priors. Furthermore, acknowledging the inadequacy of existing datasets
in complex reasoning tasks, we introduce 3D ReasonSeg, a reasoning-based
segmentation dataset comprising 25,185 training samples and 3,966 validation
samples with precise annotations. Both quantitative and qualitative experiments
demonstrate that the R$^2$S and 3D ReasonSeg effectively endow 3D point cloud
perception with stronger spatial reasoning capabilities, and we hope that they
can serve as a new baseline and benchmark for future work.

</details>


### [86] [Dare to Plagiarize? Plagiarized Painting Recognition and Retrieval](https://arxiv.org/abs/2506.23132)
*Sophie Zhou,Shu Kong*

Main category: cs.CV

TL;DR: 本文研究如何检测艺术作品的抄袭，通过检索视觉上相似的真实作品并解释检测到的抄袭行为。


<details>
  <summary>Details</summary>
Motivation: 保护艺术家版权和知识产权，解决艺术作品中抄袭检测的难题。

Method: 收集绘画数据集并生成基于特定风格的抄袭版本，使用DINOv2模型的特征进行相似性检索和抄袭分类，进一步通过度量学习损失对模型进行微调以提升检索性能。

Result: 基础非学习方法获得了97.2%的高识别准确率但检索精度较低。微调模型提升了检索性能（AP提高12%），但识别准确率下降为92.7%。

Conclusion: 非学习方法在抄袭检测上表现良好，但检索精度有待提升；微调方法改进了检索性能但对识别准确率有影响。未来研究需要更平衡检测和精度的模型。

Abstract: Art plagiarism detection plays a crucial role in protecting artists'
copyrights and intellectual property, yet it remains a challenging problem in
forensic analysis. In this paper, we address the task of recognizing
plagiarized paintings and explaining the detected plagarisms by retrieving
visually similar authentic artworks. To support this study, we construct a
dataset by collecting painting photos and synthesizing plagiarized versions
using generative AI, tailored to specific artists' styles. We first establish a
baseline approach using off-the-shelf features from the visual foundation model
DINOv2 to retrieve the most similar images in the database and classify
plagiarism based on a similarity threshold. Surprisingly, this non-learned
method achieves a high recognition accuracy of 97.2\% but suffers from low
retrieval precision 29.0\% average precision (AP). To improve retrieval
quality, we finetune DINOv2 with a metric learning loss using positive and
negative sample pairs sampled in the database. The finetuned model greatly
improves retrieval performance by 12\% AP over the baseline, though it
unexpectedly results in a lower recognition accuracy (92.7\%). We conclude with
insightful discussions and outline directions for future research.

</details>


### [87] [RoboScape: Physics-informed Embodied World Model](https://arxiv.org/abs/2506.23135)
*Yu Shang,Xin Zhang,Yinzhou Tang,Lei Jin,Chen Gao,Wei Wu,Yong Li*

Main category: cs.CV

TL;DR: 提出RoboScape，这是一种物理知晓的统一世界模型，通过联合学习RGB视频生成和物理知识提高机器人任务中视频生成的物理真实性和视觉效果。


<details>
  <summary>Details</summary>
Motivation: 当前的世界模型在接触丰富的场景中缺乏对3D几何和运动动力学的物理感知，难以生成现实感强的视频。

Method: 提出RoboScape，通结合时间深度预测和关键点动力学学习任务，以提高视频生成的几何一致性和物理属性建模。

Result: RoboScape在多种机器人任务中生成视觉逼真且具物理真实性的视频，并能够用于机器人策略训练与评估。

Conclusion: RoboScape在物理知晓世界模型的建立上取得了突破，为推进具象智能研究提供了新的思路。

Abstract: World models have become indispensable tools for embodied intelligence,
serving as powerful simulators capable of generating realistic robotic videos
while addressing critical data scarcity challenges. However, current embodied
world models exhibit limited physical awareness, particularly in modeling 3D
geometry and motion dynamics, resulting in unrealistic video generation for
contact-rich robotic scenarios. In this paper, we present RoboScape, a unified
physics-informed world model that jointly learns RGB video generation and
physics knowledge within an integrated framework. We introduce two key
physics-informed joint training tasks: temporal depth prediction that enhances
3D geometric consistency in video rendering, and keypoint dynamics learning
that implicitly encodes physical properties (e.g., object shape and material
characteristics) while improving complex motion modeling. Extensive experiments
demonstrate that RoboScape generates videos with superior visual fidelity and
physical plausibility across diverse robotic scenarios. We further validate its
practical utility through downstream applications including robotic policy
training with generated data and policy evaluation. Our work provides new
insights for building efficient physics-informed world models to advance
embodied intelligence research. The code is available at:
https://github.com/tsinghua-fib-lab/RoboScape.

</details>


### [88] [VisualPrompter: Prompt Optimization with Visual Feedback for Text-to-Image Synthesis](https://arxiv.org/abs/2506.23138)
*Shiyu Wu,Mingzhen Sun,Weining Wang,Yequan Wang,Jing Liu*

Main category: cs.CV

TL;DR: 提出了VisualPrompter，一个无需训练的提示词优化框架，提高文本和图片生成间的语义对齐。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型生成图像时需要提示词优化，但语义对齐被忽略。

Method: 通过自动自反模块检查生成图像缺失的语义，并使用目标特定的优化机制优化用户输入提示词。

Result: 在文本和图像对齐评估的多个基准上达到最新的性能。

Conclusion: VisualPrompter具有优秀的灵活性和插拔式设计，可以适配不同生成模型。

Abstract: Since there exists a notable gap between user-provided and model-preferred
prompts, generating high-quality and satisfactory images using diffusion models
often requires prompt engineering to optimize user inputs. Current studies on
text-to-image prompt engineering can effectively enhance the style and
aesthetics of generated images. However, they often neglect the semantic
alignment between generated images and user descriptions, resulting in visually
appealing but content-wise unsatisfying outputs. In this work, we propose
VisualPrompter, a novel training-free prompt engineering framework that refines
user inputs to model-preferred sentences. In particular, VisualPrompter
utilizes an automatic self-reflection module to identify the missing concepts
in generated images and a target-specific prompt optimization mechanism to
revise the prompts in a fine-grained manner. Extensive experiments demonstrate
the effectiveness of our VisualPrompter, which achieves new state-of-the-art
performance on multiple benchmarks for text-image alignment evaluation.
Additionally, our framework features a plug-and-play design, making it highly
adaptable to various generative models.

</details>


### [89] [AlignCVC: Aligning Cross-View Consistency for Single-Image-to-3D Generation](https://arxiv.org/abs/2506.23150)
*Xinyue Liang,Zhiyuan Ma,Lingchen Sun,Yanjun Guo,Lei Zhang*

Main category: cs.CV

TL;DR: 文章提出了一种称为AlignCVC的新框架，通过对分布进行对齐来提升单张图像到3D生成的多视图一致性（CVC），提高3D重建质量和推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单张图像到3D模型生成过程中，由于生成的中间多视图图像缺乏跨视图一致性，导致最终的3D重建效果下降。

Method: 提出AlignCVC框架，通过分布对齐的方法代替传统的损失回归方法，同时采用软硬对齐策略，分别优化生成与重建模型的目标。

Result: AlignCVC方法不仅提升了多视图生成质量，还将推理速度加快至4步，且可兼容多种现有生成和重建模型。

Conclusion: AlignCVC作为一种插件式解决方案，有效实现了单张图像到3D生成过程中多视图一致性的提升，并证明了其有效性和效率。

Abstract: Single-image-to-3D models typically follow a sequential generation and
reconstruction workflow. However, intermediate multi-view images synthesized by
pre-trained generation models often lack cross-view consistency (CVC),
significantly degrading 3D reconstruction performance. While recent methods
attempt to refine CVC by feeding reconstruction results back into the
multi-view generator, these approaches struggle with noisy and unstable
reconstruction outputs that limit effective CVC improvement. We introduce
AlignCVC, a novel framework that fundamentally re-frames single-image-to-3D
generation through distribution alignment rather than relying on strict
regression losses. Our key insight is to align both generated and reconstructed
multi-view distributions toward the ground-truth multi-view distribution,
establishing a principled foundation for improved CVC. Observing that generated
images exhibit weak CVC while reconstructed images display strong CVC due to
explicit rendering, we propose a soft-hard alignment strategy with distinct
objectives for generation and reconstruction models. This approach not only
enhances generation quality but also dramatically accelerates inference to as
few as 4 steps. As a plug-and-play paradigm, our method, namely AlignCVC,
seamlessly integrates various multi-view generation models with 3D
reconstruction models. Extensive experiments demonstrate the effectiveness and
efficiency of AlignCVC for single-image-to-3D generation.

</details>


### [90] [MEMFOF: High-Resolution Training for Memory-Efficient Multi-Frame Optical Flow Estimation](https://arxiv.org/abs/2506.23151)
*Vladislav Bargatin,Egor Chistov,Alexander Yakovenko,Dmitriy Vatolin*

Main category: cs.CV

TL;DR: 提出了一种名为MEMFOF的内存高效光流计算方法，兼顾了高分辨率输入下的精确性和GPU内存使用的效率。


<details>
  <summary>Details</summary>
Motivation: 目前光流估计的研究在追求精度的同时内存消耗显著增加，特别是在高清输入（如1080p）情况下。因此需要一种能够在高效内存使用和精确估计之间找到平衡的方法。

Method: 利用轻量化的RA-F-like架构设计，结合多帧估计、减少的相关体积计算和高分辨率训练方法，实现了内存紧凑且性能优异的光流估计。

Result: 运行时对于1080p输入仅需2.09 GB GPU内存，训练时需28.5 GB，支持原生1080p训练。同时在多个评估基准上取得了最先进的性能，例如Sintel、Spring和KITTI-2015数据集。

Conclusion: MEMFOF方法在实现高分辨率光流估计方面平衡了精度和内存效率，为研究和实际应用提供了更优的解决方案。

Abstract: Recent advances in optical flow estimation have prioritized accuracy at the
cost of growing GPU memory consumption, particularly for high-resolution
(FullHD) inputs. We introduce MEMFOF, a memory-efficient multi-frame optical
flow method that identifies a favorable trade-off between multi-frame
estimation and GPU memory usage. Notably, MEMFOF requires only 2.09 GB of GPU
memory at runtime for 1080p inputs, and 28.5 GB during training, which uniquely
positions our method to be trained at native 1080p without the need for
cropping or downsampling. We systematically revisit design choices from
RAFT-like architectures, integrating reduced correlation volumes and
high-resolution training protocols alongside multi-frame estimation, to achieve
state-of-the-art performance across multiple benchmarks while substantially
reducing memory overhead. Our method outperforms more resource-intensive
alternatives in both accuracy and runtime efficiency, validating its robustness
for flow estimation at high resolutions. At the time of submission, our method
ranks first on the Spring benchmark with a 1-pixel (1px) outlier rate of 3.289,
leads Sintel (clean) with an endpoint error (EPE) of 0.963, and achieves the
best Fl-all error on KITTI-2015 at 2.94%. The code is available at
https://github.com/msu-video-group/memfof.

</details>


### [91] [Dynamic View Synthesis from Small Camera Motion Videos](https://arxiv.org/abs/2506.23153)
*Huiqiang Sun,Xingyi Li,Juewen Peng,Liao Shen,Zhiguo Cao,Ke Xian,Guosheng Lin*

Main category: cs.CV

TL;DR: 本文提出了一种针对动态3D场景的小相机运动输入的新方法，通过引入分布式深度正则化和改进的相机参数学习，解决了现有方法在场景几何表示和相机参数估计上的不足，实验结果优于目前的先进方法。


<details>
  <summary>Details</summary>
Motivation: 目前基于NeRF的方法在新视角的动态3D场景合成中表现优异，但在输入图像或视频存在有限运动视差或相机几乎静止的情况下表现受到限制，尤其在场景几何表示和相机参数估计方面面临显著挑战。

Method: 针对场景几何表示问题，本文提出了分布式深度正则化(DDR)，通过Gumbel-softmax采样点和体积密度约束，保证渲染权重分布与真实分布一致；针对相机参数估计问题，引入了训练中的相机参数学习以增强模型的鲁棒性。

Result: 本文方法在小范围相机运动输入的场景表示中表现出色，实验结果优于现有先进方法。

Conclusion: 通过DDR和改进的相机参数学习，本文有效解决了小相机运动输入场景中的两大挑战，为动态3D场景的新视图合成提供了更准确和鲁棒的解决方案。

Abstract: Novel view synthesis for dynamic $3$D scenes poses a significant challenge.
Many notable efforts use NeRF-based approaches to address this task and yield
impressive results. However, these methods rely heavily on sufficient motion
parallax in the input images or videos. When the camera motion range becomes
limited or even stationary (i.e., small camera motion), existing methods
encounter two primary challenges: incorrect representation of scene geometry
and inaccurate estimation of camera parameters. These challenges make prior
methods struggle to produce satisfactory results or even become invalid. To
address the first challenge, we propose a novel Distribution-based Depth
Regularization (DDR) that ensures the rendering weight distribution to align
with the true distribution. Specifically, unlike previous methods that use
depth loss to calculate the error of the expectation, we calculate the
expectation of the error by using Gumbel-softmax to differentiably sample
points from discrete rendering weight distribution. Additionally, we introduce
constraints that enforce the volume density of spatial points before the object
boundary along the ray to be near zero, ensuring that our model learns the
correct geometry of the scene. To demystify the DDR, we further propose a
visualization tool that enables observing the scene geometry representation at
the rendering weight level. For the second challenge, we incorporate camera
parameter learning during training to enhance the robustness of our model to
camera parameters. We conduct extensive experiments to demonstrate the
effectiveness of our approach in representing scenes with small camera motion
input, and our results compare favorably to state-of-the-art methods.

</details>


### [92] [UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding](https://arxiv.org/abs/2506.23219)
*Jie Feng,Shengyuan Wang,Tianhui Liu,Yanxin Xi,Yong Li*

Main category: cs.CV

TL;DR: 提出了一个名为UrbanLLaVA的多模态大语言模型，专注于城市研究任务，通过新的训练框架和数据集显著提升性能，并公开了代码和数据。


<details>
  <summary>Details</summary>
Motivation: 当前城市领域的研究缺乏统一处理多模态数据的框架，影响了对复杂城市任务的全面理解。其目的是借助多模态大语言模型的成功经验，创建适用于城市研究的专用模型。

Method: 设计了一个新的框架UrbanLLaVA，首先构建了一个多样化的城市指令数据集，并提出分阶段训练方法，将空间推理增强与领域知识学习分离。还扩展了现有基准评测，用于评估城市领域中的多模态任务性能。

Result: 在来自三个城市的数据集上，UrbanLLaVA在单模态和复杂跨模态任务中均优于现有开源和专有模型，同时展现了跨城市的良好泛化能力。

Conclusion: UrbanLLaVA证明了其在城市研究任务中处理多模态数据的优势，并为该领域的研究者提供了开放资源，促进相关研究的进一步发展。

Abstract: Urban research involves a wide range of scenarios and tasks that require the
understanding of multi-modal data. Current methods often focus on specific data
types and lack a unified framework in urban field for processing them
comprehensively. The recent success of multi-modal large language models
(MLLMs) presents a promising opportunity to overcome this limitation. In this
paper, we introduce $\textit{UrbanLLaVA}$, a multi-modal large language model
designed to process these four types of data simultaneously and achieve strong
performance across diverse urban tasks compared with general MLLMs. In
$\textit{UrbanLLaVA}$, we first curate a diverse urban instruction dataset
encompassing both single-modal and cross-modal urban data, spanning from
location view to global view of urban environment. Additionally, we propose a
multi-stage training framework that decouples spatial reasoning enhancement
from domain knowledge learning, thereby improving the compatibility and
downstream performance of $\textit{UrbanLLaVA}$ across diverse urban tasks.
Finally, we also extend existing benchmark for urban research to assess the
performance of MLLMs across a wide range of urban tasks. Experimental results
from three cities demonstrate that $\textit{UrbanLLaVA}$ outperforms
open-source and proprietary MLLMs in both single-modal tasks and complex
cross-modal tasks and shows robust generalization abilities across cities.
Source codes and data are openly accessible to the research community via
https://github.com/tsinghua-fib-lab/UrbanLLaVA.

</details>


### [93] [Self-Supervised Contrastive Learning for Multi-Label Images](https://arxiv.org/abs/2506.23156)
*Jiale Chen*

Main category: cs.CV

TL;DR: 该研究通过自监督学习 (SSL) 在多标签图像数据上提高表征学习性能，提出了一种新的增强和对比损失机制。


<details>
  <summary>Details</summary>
Motivation: 当前主流的SSL方法主要依赖于单标签数据集（如ImageNet），多标签数据常被忽视，而这些数据具有更丰富的语义信息和更广泛的应用潜力。研究旨在设计适用于多标签图像的SSL方法，以减少预训练的开销并提升表征能力。

Method: 提出了一种分块增强模块，用于从多标签图像中提取更多的潜在正样本视图对；此外设计了一种图像感知对比损失，用于连接这些视图并提取语义一致的表征。

Result: 通过完整的线性微调和迁移学习实验，验证了该方法在样本质量和数量挑战下的竞争力。

Conclusion: 新方法在提升多标签图像的SSL表征能力方面具有显著效果，并为丰富下游场景应用提供了潜力。

Abstract: Self-supervised learning (SSL) has demonstrated its effectiveness in learning
representations through comparison methods that align with human intuition.
However, mainstream SSL methods heavily rely on high body datasets with single
label, such as ImageNet, resulting in intolerable pre-training overhead.
Besides, more general multi-label images are frequently overlooked in SSL,
despite their potential for richer semantic information and broader
applicability in downstream scenarios. Therefore, we tailor the mainstream SSL
approach to guarantee excellent representation learning capabilities using
fewer multi-label images. Firstly, we propose a block-wise augmentation module
aimed at extracting additional potential positive view pairs from multi-label
images. Subsequently, an image-aware contrastive loss is devised to establish
connections between these views, thereby facilitating the extraction of
semantically consistent representations. Comprehensive linear fine-tuning and
transfer learning validate the competitiveness of our approach despite
challenging sample quality and quantity.

</details>


### [94] [STD-GS: Exploring Frame-Event Interaction for SpatioTemporal-Disentangled Gaussian Splatting to Reconstruct High-Dynamic Scene](https://arxiv.org/abs/2506.23157)
*Hanyu Zhou,Haonan Wang,Haoyue Liu,Yuxing Duan,Luxin Yan,Gim Hee Lee*

Main category: cs.CV

TL;DR: 提出了一种结合帧相机和事件相机的时空解耦高动态场景重建框架，通过分离背景与动态物体的时空特征来提高重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法因采用统一的时空特征表示无法有效处理帧成像的时间不连续性及背景与物体的空间特征差异性问题。

Method: 通过结合帧相机与事件相机，基于高斯分布模型提出时空解耦分割框架，对背景与动态物体进行特征聚类和时空分割，并利用事件数据的时空一致性特性优化高斯表示。

Result: 实验表明，该方法能显著提升高动态场景的时空重建效果。

Conclusion: 分离背景与物体的时空特征，并利用事件相机的特性进行优化，可以更高效地恢复时间连续和动态变化的场景。

Abstract: High-dynamic scene reconstruction aims to represent static background with
rigid spatial features and dynamic objects with deformed continuous
spatiotemporal features. Typically, existing methods adopt unified
representation model (e.g., Gaussian) to directly match the spatiotemporal
features of dynamic scene from frame camera. However, this unified paradigm
fails in the potential discontinuous temporal features of objects due to frame
imaging and the heterogeneous spatial features between background and objects.
To address this issue, we disentangle the spatiotemporal features into various
latent representations to alleviate the spatiotemporal mismatching between
background and objects. In this work, we introduce event camera to compensate
for frame camera, and propose a spatiotemporal-disentangled Gaussian splatting
framework for high-dynamic scene reconstruction. As for dynamic scene, we
figure out that background and objects have appearance discrepancy in
frame-based spatial features and motion discrepancy in event-based temporal
features, which motivates us to distinguish the spatiotemporal features between
background and objects via clustering. As for dynamic object, we discover that
Gaussian representations and event data share the consistent spatiotemporal
characteristic, which could serve as a prior to guide the spatiotemporal
disentanglement of object Gaussians. Within Gaussian splatting framework, the
cumulative scene-object disentanglement can improve the spatiotemporal
discrimination between background and objects to render the time-continuous
dynamic scene. Extensive experiments have been performed to verify the
superiority of the proposed method.

</details>


### [95] [Trident: Detecting Face Forgeries with Adversarial Triplet Learning](https://arxiv.org/abs/2506.23189)
*Mustafa Hakan Kara,Aysegul Dundar,Uğur Güdükbay*

Main category: cs.CV

TL;DR: 本论文提出了一个名为Trident的人脸伪造检测框架，通过Siamese网络的三元组学习和域对抗训练提高对未知伪造技术的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在深度神经网络生成的高复杂性人脸伪造技术日益提高的背景下，现有基于监督训练的方法难以应对新的伪造技术，本研究旨在解决这一问题。

Method: 引入Trident框架，通过三元组学习和Siamese网络提取细粒度特征，同时结合域对抗训练提升对未遇见伪造的泛化能力，并通过减少分类器对嵌入模型的影响避免过拟合。

Result: 在多个基准测试上的综合评估和消融实验证明了该框架的有效性。

Conclusion: Trident框架通过改进的训练机制和鲁棒性模型设计，能够有效检测多种伪造手段，同时展现出优越的泛化能力。

Abstract: As face forgeries generated by deep neural networks become increasingly
sophisticated, detecting face manipulations in digital media has posed a
significant challenge, underscoring the importance of maintaining digital media
integrity and combating visual disinformation. Current detection models,
predominantly based on supervised training with domain-specific data, often
falter against forgeries generated by unencountered techniques. In response to
this challenge, we introduce \textit{Trident}, a face forgery detection
framework that employs triplet learning with a Siamese network architecture for
enhanced adaptability across diverse forgery methods. \textit{Trident} is
trained on curated triplets to isolate nuanced differences of forgeries,
capturing fine-grained features that distinguish pristine samples from
manipulated ones while controlling for other variables. To further enhance
generalizability, we incorporate domain-adversarial training with a forgery
discriminator. This adversarial component guides our embedding model towards
forgery-agnostic representations, improving its robustness to unseen
manipulations. In addition, we prevent gradient flow from the classifier head
to the embedding model, avoiding overfitting induced by artifacts peculiar to
certain forgeries. Comprehensive evaluations across multiple benchmarks and
ablation studies demonstrate the effectiveness of our framework. We will
release our code in a GitHub repository.

</details>


### [96] [DEL: Dense Event Localization for Multi-modal Audio-Visual Understanding](https://arxiv.org/abs/2506.23196)
*Mona Ahmadian,Amir Shirian,Frank Guerin,Andrew Gilbert*

Main category: cs.CV

TL;DR: 提出DEL框架，用于密集语义动作定位，主要通过增强视觉与音频的一致性，以及跨模态细化互动实现先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现实视频通常包含重叠事件和复杂时间依赖关系，现有方法难以捕捉多模态交互的细节及高阶语义。

Method: DEL框架包含视觉与音频特征对齐模块（使用掩码自注意力提升模态内一致性）以及多尺度模态交互细化模块。

Result: 在多个数据集（UnAV-100、THUMOS14、ActivityNet 1.3、EPIC-Kitchens-100）上取得新纪录，分别显著提高+3.3%、+2.6%、+1.2%、+1.7%(动词)、+1.4%(名词)的平均mAP。

Conclusion: DEL在长视频中能准确检测与分类多种动作，并展现了领先性能，表明其在多模态复杂情况中的有效性。

Abstract: Real-world videos often contain overlapping events and complex temporal
dependencies, making multimodal interaction modeling particularly challenging.
We introduce DEL, a framework for dense semantic action localization, aiming to
accurately detect and classify multiple actions at fine-grained temporal
resolutions in long untrimmed videos. DEL consists of two key modules: the
alignment of audio and visual features that leverage masked self-attention to
enhance intra-mode consistency and a multimodal interaction refinement module
that models cross-modal dependencies across multiple scales, enabling
high-level semantics and fine-grained details. Our method achieves
state-of-the-art performance on multiple real-world Temporal Action
Localization (TAL) datasets, UnAV-100, THUMOS14, ActivityNet 1.3, and
EPIC-Kitchens-100, surpassing previous approaches with notable average mAP
gains of +3.3%, +2.6%, +1.2%, +1.7% (verb), and +1.4% (noun), respectively.

</details>


### [97] [Transformer-Based Person Search with High-Frequency Augmentation and Multi-Wave Mixing](https://arxiv.org/abs/2506.23202)
*Qilin Shu,Qixian Zhang,Qi Zhang,Hongyun Zhang,Duoqian Miao,Cairong Zhao*

Main category: cs.CV

TL;DR: 论文提出HAMW方法，通过提升transformer对高频特征的捕捉能力并采用多级Haar小波融合方案，优化人物搜索任务，减少计算开销，同时达到先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于transformer的人物搜索方法在高频特征抑制和计算成本方面存在问题。为此需研发新方法增强特征提取能力并降低复杂度。

Method: 方法HAMW通过三阶段框架优化检测和重识别性能。引入高频增强策略并用多级Haar小波融合替换常规自注意力机制，以提升多尺度特征的提取能力并降低计算开销。

Result: HAMW方法在CUHK-SYSU和PRW数据集上实现了最先进的性能表现。

Conclusion: HAMW有效解决了现有人物搜索任务中的高频特征抑制及计算成本问题，提出了高效的解决方案并显著提升了模型表现。

Abstract: The person search task aims to locate a target person within a set of scene
images. In recent years, transformer-based models in this field have made some
progress. However, they still face three primary challenges: 1) the
self-attention mechanism tends to suppress high-frequency components in the
features, which severely impacts model performance; 2) the computational cost
of transformers is relatively high. To address these issues, we propose a novel
High-frequency Augmentation and Multi-Wave mixing (HAMW) method for person
search. HAMW is designed to enhance the discriminative feature extraction
capabilities of transformers while reducing computational overhead and
improving efficiency. Specifically, we develop a three-stage framework that
progressively optimizes both detection and re-identification performance. Our
model enhances the perception of high-frequency features by learning from
augmented inputs containing additional high-frequency components. Furthermore,
we replace the self-attention layers in the transformer with a strategy based
on multi-level Haar wavelet fusion to capture multi-scale features. This not
only lowers the computational complexity but also alleviates the suppression of
high-frequency features and enhances the ability to exploit multi-scale
information. Extensive experiments demonstrate that HAMW achieves
state-of-the-art performance on both the CUHK-SYSU and PRW datasets.

</details>


### [98] [BridgeShape: Latent Diffusion Schrödinger Bridge for 3D Shape Completion](https://arxiv.org/abs/2506.23205)
*Dequan Kong,Zhe Zhu,Honghua Chen,Mingqiang Wei*

Main category: cs.CV

TL;DR: BridgeShape通过将3D形状补全建模为最优传输问题，并引入经过深度增强的VQ-VAE进行潜空间压缩，使得3D模型补全更加高效且精细，取得了最新技术水平。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的3D形状补全方法对全局传输路径没有显式建模，导致补全表现次优，同时在体素空间直接扩散也难以捕捉更高分辨率的几何细节。

Method: 提出BridgeShape框架，将3D形状补全视为最优传输问题，并通过深度增强的VQ-VAE将3D形状压缩至潜在空间，同时引入DINOv2特征增强几何结构感知。

Result: BridgeShape在大规模3D形状补全基准上取得了最新技术水平，尤其在高分辨率和未见过的物体类别上展现了优秀的保真度。

Conclusion: BridgeShape通过建模形状转变路径并利用潜在空间的高效表示，显著提高了3D形状补全的质量和分辨率表现。

Abstract: Existing diffusion-based 3D shape completion methods typically use a
conditional paradigm, injecting incomplete shape information into the denoising
network via deep feature interactions (e.g., concatenation, cross-attention) to
guide sampling toward complete shapes, often represented by voxel-based
distance functions. However, these approaches fail to explicitly model the
optimal global transport path, leading to suboptimal completions. Moreover,
performing diffusion directly in voxel space imposes resolution constraints,
limiting the generation of fine-grained geometric details. To address these
challenges, we propose BridgeShape, a novel framework for 3D shape completion
via latent diffusion Schr\"odinger bridge. The key innovations lie in two
aspects: (i) BridgeShape formulates shape completion as an optimal transport
problem, explicitly modeling the transition between incomplete and complete
shapes to ensure a globally coherent transformation. (ii) We introduce a
Depth-Enhanced Vector Quantized Variational Autoencoder (VQ-VAE) to encode 3D
shapes into a compact latent space, leveraging self-projected multi-view depth
information enriched with strong DINOv2 features to enhance geometric
structural perception. By operating in a compact yet structurally informative
latent space, BridgeShape effectively mitigates resolution constraints and
enables more efficient and high-fidelity 3D shape completion. BridgeShape
achieves state-of-the-art performance on large-scale 3D shape completion
benchmarks, demonstrating superior fidelity at higher resolutions and for
unseen object classes.

</details>


### [99] [Towards an Automated Multimodal Approach for Video Summarization: Building a Bridge Between Text, Audio and Facial Cue-Based Summarization](https://arxiv.org/abs/2506.23714)
*Md Moinul Islam,Sofoklis Kakouros,Janne Heikkilä,Mourad Oussalah*

Main category: cs.CV

TL;DR: 提出了一种结合文本、音频和视觉线索的多模态视频摘要框架，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着视频内容的增加，现有单模态摘要技术难以满足需求，多模态整合成为改进方向。

Method: 通过提取韵律特征、文本线索和视觉指标，并结合多模态“加分词”，生成语义和情感重要的时间戳对齐摘要。

Result: 实验表明，框架在文本和视频评估指标上较传统方法显著提升，例如ROUGE-1从0.4769提升至0.7929，F1得分提高23%。

Conclusion: 多模态整合能够生成语义相关和更具行为洞察力的视频摘要，具有广阔应用潜力。

Abstract: The increasing volume of video content in educational, professional, and
social domains necessitates effective summarization techniques that go beyond
traditional unimodal approaches. This paper proposes a behaviour-aware
multimodal video summarization framework that integrates textual, audio, and
visual cues to generate timestamp-aligned summaries. By extracting prosodic
features, textual cues and visual indicators, the framework identifies
semantically and emotionally important moments. A key contribution is the
identification of bonus words, which are terms emphasized across multiple
modalities and used to improve the semantic relevance and expressive clarity of
the summaries. The approach is evaluated against pseudo-ground truth (pGT)
summaries generated using LLM-based extractive method. Experimental results
demonstrate significant improvements over traditional extractive method, such
as the Edmundson method, in both text and video-based evaluation metrics.
Text-based metrics show ROUGE-1 increasing from 0.4769 to 0.7929 and BERTScore
from 0.9152 to 0.9536, while in video-based evaluation, our proposed framework
improves F1-Score by almost 23%. The findings underscore the potential of
multimodal integration in producing comprehensive and behaviourally informed
video summaries.

</details>


### [100] [TVG-SLAM: Robust Gaussian Splatting SLAM with Tri-view Geometric Constraints](https://arxiv.org/abs/2506.23207)
*Zhen Tan,Xieyuanli Chen,Lei Feng,Yangbing Ge,Shuaifeng Zhi,Jiaxiong Liu,Dewen Hu*

Main category: cs.CV

TL;DR: 提出了一种名为TVG-SLAM的鲁棒RGB-only 3DGS SLAM系统，通过三视几何范式改善场景映射精度和跟踪鲁棒性，并在公开数据集中取得领先表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D Gaussian Splatting的RGB-only SLAM系统依赖光度损失进行相机跟踪，在视角和光照变化大的场景中鲁棒性差。

Method: 提出了三视匹配模块聚合可靠配准，并引入混合几何约束确保稳定的相机位姿估计；采用概率初始化策略和动态渲染信任衰减机制以优化场景映射和跟踪。

Result: 在公开的户外数据集上的测试表明，提出的TVG-SLAM性能超过了现有RGB-only的3DGS SLAM方法，表现出显著的跟踪鲁棒性提升和渲染质量改进。

Conclusion: TVG-SLAM通过新颖的三视几何和辅助技术显著提升了RGB-only SLAM系统在复杂场景中的跟踪鲁棒性和地图表示质量，代码将开源。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled RGB-only SLAM
systems to achieve high-fidelity scene representation. However, the heavy
reliance of existing systems on photometric rendering loss for camera tracking
undermines their robustness, especially in unbounded outdoor environments with
severe viewpoint and illumination changes. To address these challenges, we
propose TVG-SLAM, a robust RGB-only 3DGS SLAM system that leverages a novel
tri-view geometry paradigm to ensure consistent tracking and high-quality
mapping. We introduce a dense tri-view matching module that aggregates reliable
pairwise correspondences into consistent tri-view matches, forming robust
geometric constraints across frames. For tracking, we propose Hybrid Geometric
Constraints, which leverage tri-view matches to construct complementary
geometric cues alongside photometric loss, ensuring accurate and stable pose
estimation even under drastic viewpoint shifts and lighting variations. For
mapping, we propose a new probabilistic initialization strategy that encodes
geometric uncertainty from tri-view correspondences into newly initialized
Gaussians. Additionally, we design a Dynamic Attenuation of Rendering Trust
mechanism to mitigate tracking drift caused by mapping latency. Experiments on
multiple public outdoor datasets show that our TVG-SLAM outperforms prior
RGB-only 3DGS-based SLAM systems. Notably, in the most challenging dataset, our
method improves tracking robustness, reducing the average Absolute Trajectory
Error (ATE) by 69.0\% while achieving state-of-the-art rendering quality. The
implementation of our method will be released as open-source.

</details>


### [101] [A Hierarchical Slice Attention Network for Appendicitis Classification in 3D CT Scans](https://arxiv.org/abs/2506.23209)
*Chia-Wen Huang,Haw Hwai,Chien-Chang Lee,Pei-Yuan Wu*

Main category: cs.CV

TL;DR: 研究提出一种基于3D CT扫描的深度学习模型，用于快速准确地诊断阑尾炎问题，同时结合“切片注意力机制”及分层分类框架，实现诊断性能的提升。


<details>
  <summary>Details</summary>
Motivation: 当前CT成像是诊断阑尾炎的标准工具，但随着病例数量的增加，可能导致诊断延误。需要一种高效、精准的诊断方法。

Method: 采用3D CT扫描作为数据基础，结合切片注意力机制和外部2D数据集提高小病灶检测，同时引入分层分类框架以区分简单与复杂性阑尾炎。

Result: 阑尾炎AUC提升3%，复杂阑尾炎AUC提升5.9%，诊断性能更为优越。

Conclusion: 提出的模型在阑尾炎分类及复杂性诊断上表现优异，能有效解决现有方法的效率及可靠性问题。

Abstract: Timely and accurate diagnosis of appendicitis is critical in clinical
settings to prevent serious complications. While CT imaging remains the
standard diagnostic tool, the growing number of cases can overwhelm
radiologists, potentially causing delays. In this paper, we propose a deep
learning model that leverages 3D CT scans for appendicitis classification,
incorporating Slice Attention mechanisms guided by external 2D datasets to
enhance small lesion detection. Additionally, we introduce a hierarchical
classification framework using pre-trained 2D models to differentiate between
simple and complicated appendicitis. Our approach improves AUC by 3% for
appendicitis and 5.9% for complicated appendicitis, offering a more efficient
and reliable diagnostic solution compared to previous work.

</details>


### [102] [Ella: Embodied Social Agents with Lifelong Memory](https://arxiv.org/abs/2506.24019)
*Hongxin Zhang,Zheyuan Zhang,Zeyuan Wang,Zunzhe Zhang,Lixing Fang,Qinhong Zhou,Chuang Gan*

Main category: cs.CV

TL;DR: 本研究提出了一个名为Ella的三维开放世界中的社会智能体，具备通过长期记忆系统实现持续学习和与他人社会互动的能力。


<details>
  <summary>Details</summary>
Motivation: 期望通过结合结构化记忆系统与基础模型，提升化身智能体在开放世界中的持续学习、自主决策与社交能力。

Method: 将面向长期的多模态记忆系统（语义记忆和时空情景记忆）集成到智能体中，并与基础模型结合以实现信息的检索、决策及日常行为规划。通过在多智能体动态3D开放世界的实际评估，验证其能力。

Result: 实验结果显示，Ella能够通过观察与互动有效学习，并可以影响、领导、协作他人以共同达成目标。

Conclusion: 本研究表明，结合结构化记忆系统和基础模型是推进化身智能体在开放世界中实现持续学习和社交互动的重要方向。

Abstract: We introduce Ella, an embodied social agent capable of lifelong learning
within a community in a 3D open world, where agents accumulate experiences and
acquire knowledge through everyday visual observations and social interactions.
At the core of Ella's capabilities is a structured, long-term multimodal memory
system that stores, updates, and retrieves information effectively. It consists
of a name-centric semantic memory for organizing acquired knowledge and a
spatiotemporal episodic memory for capturing multimodal experiences. By
integrating this lifelong memory system with foundation models, Ella retrieves
relevant information for decision-making, plans daily activities, builds social
relationships, and evolves autonomously while coexisting with other intelligent
beings in the open world. We conduct capability-oriented evaluations in a
dynamic 3D open world where 15 agents engage in social activities for days and
are assessed with a suite of unseen controlled evaluations. Experimental
results show that Ella can influence, lead, and cooperate with other agents
well to achieve goals, showcasing its ability to learn effectively through
observation and social interaction. Our findings highlight the transformative
potential of combining structured memory systems with foundation models for
advancing embodied intelligence. More videos can be found at
https://umass-embodied-agi.github.io/Ella/.

</details>


### [103] [High-quality Pseudo-labeling for Point Cloud Segmentation with Scene-level Annotation](https://arxiv.org/abs/2506.23227)
*Lunhao Duan,Shanshan Zhao,Xingxing Weng,Jing Zhang,Gui-Song Xia*

Main category: cs.CV

TL;DR: 研究使用场景级标注而非稀疏点级标注进行室内点云语义分割，提出利用多模态信息和区域-点语义一致性的伪标签生成新框架，并公开代码。


<details>
  <summary>Details</summary>
Motivation: 目前方法依赖为点云生成伪标签，由于仅有场景级标注，伪标签生成及分割精度都存在挑战。

Method: 方法通过跨模态特征对齐模块对2D图像和3D点云进行特征融合，结合区域投票策略的区域-点语义一致性模块生成伪标签，提升分割精度。

Result: 在ScanNet v2和S3DIS数据集上显著超越现有方法，同时通过消融实验验证各组件效果。

Conclusion: 证明了提出框架在场景级标注条件下可获得高质量伪标签，提升点云语义分割性能。

Abstract: This paper investigates indoor point cloud semantic segmentation under
scene-level annotation, which is less explored compared to methods relying on
sparse point-level labels. In the absence of precise point-level labels,
current methods first generate point-level pseudo-labels, which are then used
to train segmentation models. However, generating accurate pseudo-labels for
each point solely based on scene-level annotations poses a considerable
challenge, substantially affecting segmentation performance. Consequently, to
enhance accuracy, this paper proposes a high-quality pseudo-label generation
framework by exploring contemporary multi-modal information and region-point
semantic consistency. Specifically, with a cross-modal feature guidance module,
our method utilizes 2D-3D correspondences to align point cloud features with
corresponding 2D image pixels, thereby assisting point cloud feature learning.
To further alleviate the challenge presented by the scene-level annotation, we
introduce a region-point semantic consistency module. It produces regional
semantics through a region-voting strategy derived from point-level semantics,
which are subsequently employed to guide the point-level semantic predictions.
Leveraging the aforementioned modules, our method can rectify inaccurate
point-level semantic predictions during training and obtain high-quality
pseudo-labels. Significant improvements over previous works on ScanNet v2 and
S3DIS datasets under scene-level annotation can demonstrate the effectiveness.
Additionally, comprehensive ablation studies validate the contributions of our
approach's individual components. The code is available at
https://github.com/LHDuan/WSegPC .

</details>


### [104] [MotionGPT3: Human Motion as a Second Modality](https://arxiv.org/abs/2506.24086)
*Bingfan Zhu,Biao Jiang,Sunyi Wang,Shixiang Tang,Tao Chen,Linjie Luo,Youyi Zheng,Xin Chen*

Main category: cs.CV

TL;DR: 本文提出了MotionGPT3，一个结合动作和语言的跨模态模型，通过引入独立的动作建模分支和保留预训练语言模型的结构，解决了动作离散表征和语言智能退化问题，最终在理解和生成任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态模型在统一理解和生成方面表现出色，但统一的动作-语言模型仍然未被充分探索。主要挑战包括动作模态的离散表示问题和训练中语言智能的退化问题。

Method: 提出MotionGPT3模型，将人类动作作为第二模态，采用新分支处理动作，在语言分支保留预训练模型的结构，通过共享注意力机制实现双模态交互。此外，利用动作VAE编码动作数据，通过扩散头直接预测连续潜变量，避免离散化过程。

Result: 实验结果表明，该方法在动作理解和生成任务中具竞争力，并同时保留了语言智能能力。

Conclusion: MotionGPT3成功建立了一个统一的双模态扩散框架，高效解决了跨模态交互和模型扩展训练的挑战，同时保持语言和动作间的高效协同能力。

Abstract: Though recent advances in multimodal models have demonstrated strong
capabilities and opportunities in unified understanding and generation, the
development of unified motion-language models remains underexplored. To enable
such models with high-fidelity human motion, two core challenges must be
addressed. The first is the reconstruction gap between the continuous motion
modality and discrete representation in an autoregressive manner, and the
second is the degradation of language intelligence during unified training.
Inspired by the mixture of experts, we propose MotionGPT3, a bimodal
motion-language model that treats human motion as a second modality, decoupling
motion modeling via separate model parameters and enabling both effective
cross-modal interaction and efficient multimodal scaling training. To preserve
language intelligence, the text branch retains the original structure and
parameters of the pretrained language model, while a new motion branch is
integrated via a shared attention mechanism, enabling bidirectional information
flow between two modalities. We first employ a motion Variational Autoencoder
(VAE) to encode raw human motion into latent representations. Based on this
continuous latent space, the motion branch predicts motion latents directly
from intermediate hidden states using a diffusion head, bypassing discrete
tokenization. Extensive experiments show that our approach achieves competitive
performance on both motion understanding and generation tasks while preserving
strong language capabilities, establishing a unified bimodal motion diffusion
framework within an autoregressive manner.

</details>


### [105] [VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions](https://arxiv.org/abs/2506.23236)
*Marko Mihajlovic,Siwei Zhang,Gen Li,Kaifeng Zhao,Lea Müller,Siyu Tang*

Main category: cs.CV

TL;DR: 提出了VolumetricSMPL，一个高效的神经体积人体模型，使用动态混合的神经权重，在计算效率和表达能力上有出色表现，能完成多个挑战性任务。


<details>
  <summary>Details</summary>
Motivation: 传统的表面网格人体模型对复杂交互处理有限，现有的体积神经隐式模型又存在性能瓶颈，需要更高效且稳健的解决方案。

Method: 通过引入Neural Blend Weights (NBW)，将小规模的MLP解码器动态混合，构建了高效的VolumetricSMPL模型，改进了计算效率和精度，同时减少了存储需求。

Result: 相比现有体积模型COAP，VolumetricSMPL实现了10倍推理速度、6倍GPU内存减少，并具备更高精度及差异化接触建模能力，在多个任务中取得卓越表现。

Conclusion: VolumetricSMPL在性能和计算效率方面得到显著提升，展示了其在人体建模和交互分析中的广泛适用性，为相关领域提供了强大工具。

Abstract: Parametric human body models play a crucial role in computer graphics and
vision, enabling applications ranging from human motion analysis to
understanding human-environment interactions. Traditionally, these models use
surface meshes, which pose challenges in efficiently handling interactions with
other geometric entities, such as objects and scenes, typically represented as
meshes or point clouds. To address this limitation, recent research has
explored volumetric neural implicit body models. However, existing works are
either insufficiently robust for complex human articulations or impose high
computational and memory costs, limiting their widespread use. To this end, we
introduce VolumetricSMPL, a neural volumetric body model that leverages Neural
Blend Weights (NBW) to generate compact, yet efficient MLP decoders. Unlike
prior approaches that rely on large MLPs, NBW dynamically blends a small set of
learned weight matrices using predicted shape- and pose-dependent coefficients,
significantly improving computational efficiency while preserving
expressiveness. VolumetricSMPL outperforms prior volumetric occupancy model
COAP with 10x faster inference, 6x lower GPU memory usage, enhanced accuracy,
and a Signed Distance Function (SDF) for efficient and differentiable contact
modeling. We demonstrate VolumetricSMPL's strengths across four challenging
tasks: (1) reconstructing human-object interactions from in-the-wild images,
(2) recovering human meshes in 3D scenes from egocentric views, (3)
scene-constrained motion synthesis, and (4) resolving self-intersections. Our
results highlight its broad applicability and significant performance and
efficiency gains.

</details>


### [106] [Aggregating Local Saliency Maps for Semi-Global Explainable Image Classification](https://arxiv.org/abs/2506.23247)
*James Hinns,David Martens*

Main category: cs.CV

TL;DR: 作者提出了一个名为Segment Attribution Tables (SATs)的新方法，能够总结模型的局部显著性解释从而获取半全局的洞察。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效总结模型预测的局部解释，同时全局方法容易忽视重要的局部行为，研究的动机在于填补这一空白。

Method: 提出了通过局部显著性图量化图像片段影响的方法（SATs），结合分割图提供命名的图像片段，以总结局部解释为全局洞察。

Result: SATs方法能够揭示模型依赖的关键概念和可能的伪相关性，如背景或水印依赖问题，即使在分布外测试中的性能变化不显著。

Conclusion: SATs方法成功在过简化的全局总结和过于详细的局部解释之间架设桥梁，成为分析和调试图像分类器的实用工具。

Abstract: Deep learning dominates image classification tasks, yet understanding how
models arrive at predictions remains a challenge. Much research focuses on
local explanations of individual predictions, such as saliency maps, which
visualise the influence of specific pixels on a model's prediction. However,
reviewing many of these explanations to identify recurring patterns is
infeasible, while global methods often oversimplify and miss important local
behaviours. To address this, we propose Segment Attribution Tables (SATs), a
method for summarising local saliency explanations into (semi-)global insights.
SATs take image segments (such as "eyes" in Chihuahuas) and leverage saliency
maps to quantify their influence. These segments highlight concepts the model
relies on across instances and reveal spurious correlations, such as reliance
on backgrounds or watermarks, even when out-of-distribution test performance
sees little change. SATs can explain any classifier for which a form of
saliency map can be produced, using segmentation maps that provide named
segments. SATs bridge the gap between oversimplified global summaries and
overly detailed local explanations, offering a practical tool for analysing and
debugging image classifiers.

</details>


### [107] [DGE-YOLO: Dual-Branch Gathering and Attention for Accurate UAV Object Detection](https://arxiv.org/abs/2506.23252)
*Kunwei Lv,Ping Lan*

Main category: cs.CV

TL;DR: 该论文提出了一种改进的YOLO架构DGE-YOLO，用以增强无人机应用中的多模态目标检测，特别是在复杂条件下的小目标检测。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态输入场景中常优先考虑推理速度，但性能较差。提出的方法旨在解决多模态信息融合及小目标检测挑战。

Method: 设计了一种双分支架构实现模态特征提取，同时引入高效多尺度注意机制（EMA）优化特征学习，并采用聚集与分发模块替代传统颈部结构减少特征信息丢失。

Result: 在Drone Vehicle数据集上的实验表明，DGE-YOLO在多模态目标检测的性能优于当前主流方法。

Conclusion: 该方法在处理复杂无人机场景中的目标检测任务时具有显著优势。

Abstract: The rapid proliferation of unmanned aerial vehicles (UAVs) has highlighted
the importance of robust and efficient object detection in diverse aerial
scenarios. Detecting small objects under complex conditions, however, remains a
significant challenge. Existing approaches often prioritize inference speed,
leading to degraded performance when handling multi-modal inputs. To address
this, we present DGE-YOLO, an enhanced YOLO-based detection framework designed
to effectively fuse multi-modal information. Specifically, we introduce a
dual-branch architecture for modality-specific feature extraction, enabling the
model to process both infrared and visible images. To further enrich semantic
representation, we propose an Efficient Multi-scale Attention (EMA) mechanism
that enhances feature learning across spatial scales. Additionally, we replace
the conventional neck with a Gather-and-Distribute module to mitigate
information loss during feature aggregation. Extensive experiments on the Drone
Vehicle dataset demonstrate that DGE-YOLO achieves superior performance over
state-of-the-art methods, validating its effectiveness in multi-modal UAV
object detection tasks.

</details>


### [108] [PixelBoost: Leveraging Brownian Motion for Realistic-Image Super-Resolution](https://arxiv.org/abs/2506.23254)
*Aradhana Mishra,Bumshik Lee*

Main category: cs.CV

TL;DR: PixelBoost提出了一种基于扩散模型的图像超分辨率新方法，通过引入Brownian噪声的随机特性在生成更高真实感的图像方面取得了显著成效，同时实现了更快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在进行图像超分辨率时，存在生成真实感和计算效率之间的权衡问题，尤其在减少采样步骤时更为明显。研究希望解决此问题。

Method: 提出PixelBoost模型，通过在训练中引入受控的Brownian噪声随机性，强化纹理和边缘细节表现，同时使用sigmoidal噪声序列方法简化训练并提升推理速度。

Result: 实验表明，该模型在LPIPS、LOE、PSNR、SSIM及图像质量上表现优异，在边缘增强检测中亦表现出更好的能力。

Conclusion: PixelBoost有效避免局部最优，捕捉图像纹理与模式的不确定性，并展现了自适应学习能力，其在真实感与推理效率间实现了均衡。

Abstract: Diffusion-model-based image super-resolution techniques often face a
trade-off between realistic image generation and computational efficiency. This
issue is exacerbated when inference times by decreasing sampling steps,
resulting in less realistic and hazy images. To overcome this challenge, we
introduce a novel diffusion model named PixelBoost that underscores the
significance of embracing the stochastic nature of Brownian motion in advancing
image super-resolution, resulting in a high degree of realism, particularly
focusing on texture and edge definitions. By integrating controlled
stochasticity into the training regimen, our proposed model avoids convergence
to local optima, effectively capturing and reproducing the inherent uncertainty
of image textures and patterns. Our proposed model demonstrates superior
objective results in terms of learned perceptual image patch similarity
(LPIPS), lightness order error (LOE), peak signal-to-noise ratio(PSNR),
structural similarity index measure (SSIM), as well as visual quality. To
determine the edge enhancement, we evaluated the gradient magnitude and pixel
value, and our proposed model exhibited a better edge reconstruction
capability. Additionally, our model demonstrates adaptive learning capabilities
by effectively adjusting to Brownian noise patterns and introduces a sigmoidal
noise sequencing method that simplifies training, resulting in faster inference
speeds.

</details>


### [109] [PCLVis: Visual Analytics of Process Communication Latency in Large-Scale Simulation](https://arxiv.org/abs/2506.23257)
*Chongke Bi,Xin Gao,Baofeng Fu,Yuheng Zhao,Siming Chen,Ying Zhao,Yunhai Wang*

Main category: cs.CV

TL;DR: 提出了一个名为PCLVis的框架，通过对MPI进程通信数据的分析，帮助用户分析和优化超级计算机仿真中的进程通信延迟问题。


<details>
  <summary>Details</summary>
Motivation: 解决超级计算机仿真的进程间通信延迟问题，尤其在用户无法获取物理链路层信息的情况下提供可用的分析工具。

Method: 开发PCLVis框架，利用MPI进程通信数据而非物理链路层信息，通过空间聚类方法、高依赖性的有向无环图分析、滑动窗口算法生成通信事件抽象，并设计了通信状态可视化图标和归因策略。

Result: 实验表明，PCLVis在分析TH-1A超级计算机上的仿真通信延迟问题时效果显著，用户使用该框架后能够显著提升仿真效率。

Conclusion: PCLVis提供了一种高效的通信延迟分析工具，使用户能够自主优化大型仿真应用程序的性能。

Abstract: Large-scale simulations on supercomputers have become important tools for
users. However, their scalability remains a problem due to the huge
communication cost among parallel processes. Most of the existing communication
latency analysis methods rely on the physical link layer information, which is
only available to administrators. In this paper, a framework called PCLVis is
proposed to help general users analyze process communication latency (PCL)
events. Instead of the physical link layer information, the PCLVis uses the MPI
process communication data for the analysis. First, a spatial PCL event
locating method is developed. All processes with high correlation are
classified into a single cluster by constructing a process-correlation tree.
Second, the propagation path of PCL events is analyzed by constructing a
communication-dependency-based directed acyclic graph (DAG), which can help
users interactively explore a PCL event from the temporal evolution of a
located PCL event cluster. In this graph, a sliding window algorithm is
designed to generate the PCL events abstraction. Meanwhile, a new glyph called
the communication state glyph (CS-Glyph) is designed for each process to show
its communication states, including its in/out messages and load balance. Each
leaf node can be further unfolded to view additional information. Third, a PCL
event attribution strategy is formulated to help users optimize their
simulations. The effectiveness of the PCLVis framework is demonstrated by
analyzing the PCL events of several simulations running on the TH-1A
supercomputer. By using the proposed framework, users can greatly improve the
efficiency of their simulations.

</details>


### [110] [Causal-Entity Reflected Egocentric Traffic Accident Video Synthesis](https://arxiv.org/abs/2506.23263)
*Lei-lei Li,Jianwu Fang,Junbin Xiao,Shanmin Pang,Hongkai Yu,Chen Lv,Jianru Xue,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 提出了一个名为Causal-VidSyn的新型扩散模型，用于合成包含因果关系的驾驶事故视频，并构建了Drive-Gaze数据集。


<details>
  <summary>Details</summary>
Motivation: 当前难以在合成视频中可靠地融入真实世界视频中的因果关系，尤其是在驾驶事故场景下。

Method: 设计了Causal-VidSyn扩散模型，通过事故原因回答模块和注视点选取模块，利用因果描述和驾驶员注视点识别事故参与者及其行为。

Result: Causal-VidSyn在画面质量和因果敏感度方面优于现有视频扩散模型，并在事故视频编辑、普通视频转事故视频、文本生成视频等任务中表现出色。

Conclusion: Causal-VidSyn扩散模型有效捕捉驾驶事故的因果关系，并为相关研究提供了Drive-Gaze数据集，显著提高了相关视频任务的表现。

Abstract: Egocentricly comprehending the causes and effects of car accidents is crucial
for the safety of self-driving cars, and synthesizing causal-entity reflected
accident videos can facilitate the capability test to respond to unaffordable
accidents in reality. However, incorporating causal relations as seen in
real-world videos into synthetic videos remains challenging. This work argues
that precisely identifying the accident participants and capturing their
related behaviors are of critical importance. In this regard, we propose a
novel diffusion model, Causal-VidSyn, for synthesizing egocentric traffic
accident videos. To enable causal entity grounding in video diffusion,
Causal-VidSyn leverages the cause descriptions and driver fixations to identify
the accident participants and behaviors, facilitated by accident reason
answering and gaze-conditioned selection modules. To support Causal-VidSyn, we
further construct Drive-Gaze, the largest driver gaze dataset (with 1.54M
frames of fixations) in driving accident scenarios. Extensive experiments show
that Causal-VidSyn surpasses state-of-the-art video diffusion models in terms
of frame quality and causal sensitivity in various tasks, including accident
video editing, normal-to-accident video diffusion, and text-to-video
generation.

</details>


### [111] [Token Activation Map to Visually Explain Multimodal LLMs](https://arxiv.org/abs/2506.23270)
*Yi Li,Hualiang Wang,Xinpeng Ding,Haonan Wang,Xiaomeng Li*

Main category: cs.CV

TL;DR: 该论文提出了用于多模态大型语言模型（MLLM）解释的Token Activation Map (TAM)方法。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM的可解释性研究不足，这限制了对模型的深入理解、可信度和可视化能力，尤其是序列生成导致的上下文冗余问题影响了解释质量。

Method: 通过引入估计因果推断方法减少上下文干扰，并使用新颖的排序高斯滤波器降低激活噪声，形成Token Activation Map (TAM)方法，用于解释多模态语言模型中的多Token交互。

Result: TAM方法显著优于现有最先进方法，提供了高质量的可视化结果，适用于对象定位、故障分析、视频可视化等多种场景。

Conclusion: TAM方法有效解决了MLLM解释中的上下文冗余问题，提高了解释可靠性，展示了良好的多模态模型可视化和理解能力，可供广泛应用。

Abstract: Multimodal large language models (MLLMs) are broadly empowering various
fields. Despite their advancements, the explainability of MLLMs remains less
explored, hindering deeper understanding, model credibility, and effective
visualization. Unlike conventional vision models (e.g., CNNs, ViTs, CLIP) that
produce a single output, MLLMs generate sequences of tokens progressively,
where each generated token depends on the previous context. Therefore, earlier
context tokens can introduce redundant activations that interfere with the
explanation of later tokens beyond their original information. Existing studies
often overlook this issue, but our observations reveal that these redundant
correlations can significantly hurt the reliability of explanations. To address
this, we propose an estimated causal inference method to mitigate the
interference of context to achieve high-quality MLLM explanation, with a novel
rank Gaussian filter to further reduce activation noises. We term this method
Token Activation Map (TAM) to highlight the consideration of interactions
between tokens. TAM also indicates that it excels at explaining multiple tokens
of MLLM, which is different from the Class Activation Map (CAM) for a single
prediction. Our TAM method significantly outperforms existing SoTA methods,
showcasing high-quality visualization results that can be utilized for various
scenarios, such as object localization, failure case analysis, video
visualization, MLLMs visual comparison, and model understanding (e.g., color,
shape, action, location, visual reasoning, multi-turn conversation, etc). The
code is available atgithub.com/xmed-lab/TAM.

</details>


### [112] [Mettle: Meta-Token Learning for Memory-Efficient Audio-Visual Adaptation](https://arxiv.org/abs/2506.23271)
*Jinxing Zhou,Zhihui Li,Yongqiang Yu,Yanghao Zhou,Ruohao Guo,Guangyao Li,Yuxin Mao,Mingfei Han,Xiaojun Chang,Meng Wang*

Main category: cs.CV

TL;DR: 提出了Mettle方法，通过轻量级模块实现大规模预训练变压器模型在音视频任务中的高效适配，并显著减少内存使用和训练时间。


<details>
  <summary>Details</summary>
Motivation: 传统方法在适配大规模变压器模型时，效率低下且内存占用过大，需要一个更为高效的解决方案。

Method: 通过"Layer-Centric Distillation"模块并行提取音频或视觉特征，并通过"Meta-Token Injection"模块在早期特征层进行特征调控适配。

Result: 实验表明，Mettle在多个音视频任务基准上表现出高效节能的同时保持了竞争性的精度。

Conclusion: Mettle能够大幅降低内存及训练需求，同时满足任务性能要求，是音视频任务中适配大规模变压器模型的一种有效方法。

Abstract: We present \textbf{Met}a-\textbf{T}oken \textbf{Le}arning (Mettle), a simple
and memory-efficient method for adapting large-scale pretrained transformer
models to downstream audio-visual tasks. Instead of sequentially modifying the
output feature distribution of the transformer backbone, Mettle utilizes a
lightweight \textit{Layer-Centric Distillation (LCD)} module to distill in
parallel the intact audio or visual features embedded by each transformer layer
into compact meta-tokens. This distillation process considers both pretrained
knowledge preservation and task-specific adaptation. The obtained meta-tokens
can be directly applied to classification tasks, such as audio-visual event
localization and audio-visual video parsing. To further support fine-grained
segmentation tasks, such as audio-visual segmentation, we introduce a
\textit{Meta-Token Injection (MTI)} module, which utilizes the audio and visual
meta-tokens distilled from the top transformer layer to guide feature
adaptation in earlier layers. Extensive experiments on multiple audiovisual
benchmarks demonstrate that our method significantly reduces memory usage and
training time while maintaining parameter efficiency and competitive accuracy.

</details>


### [113] [Why Settle for One? Text-to-ImageSet Generation and Evaluation](https://arxiv.org/abs/2506.23275)
*Chengyou Jia,Xin Shen,Zhuohang Dang,Zhuohang Dang,Changliang Xia,Weijia Wu,Xinyu Zhang,Hangwei Qian,Ivor W. Tsang,Minnan Luo*

Main category: cs.CV

TL;DR: 提出了一种新的问题叫作文本到图像集生成(T2IS)，并开发了相关的评估基准和框架来解决该问题。实验表明新方法AutoT2IS在一致性上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像模型在生成满足多样一致性要求的图像集方面存在局限性，难以适应更广泛的实际应用场景。

Method: 引入全新的T2IS-Bench评估基准，提出T2IS-Eval评估框架，并开发了训练无关的AutoT2IS框架利用预训练扩散转换器提升一致性。

Result: 在T2IS-Bench上的实验表明：现有方法存在一致性问题，而AutoT2IS方法显著优于通用甚至专业化方法。

Conclusion: AutoT2IS框架展现了其在解决文本到图像集生成一致性挑战方面的显著潜力，并能支持多种实际场景应用。

Abstract: Despite remarkable progress in Text-to-Image models, many real-world
applications require generating coherent image sets with diverse consistency
requirements. Existing consistent methods often focus on a specific domain with
specific aspects of consistency, which significantly constrains their
generalizability to broader applications. In this paper, we propose a more
challenging problem, Text-to-ImageSet (T2IS) generation, which aims to generate
sets of images that meet various consistency requirements based on user
instructions. To systematically study this problem, we first introduce
$\textbf{T2IS-Bench}$ with 596 diverse instructions across 26 subcategories,
providing comprehensive coverage for T2IS generation. Building on this, we
propose $\textbf{T2IS-Eval}$, an evaluation framework that transforms user
instructions into multifaceted assessment criteria and employs effective
evaluators to adaptively assess consistency fulfillment between criteria and
generated sets. Subsequently, we propose $\textbf{AutoT2IS}$, a training-free
framework that maximally leverages pretrained Diffusion Transformers'
in-context capabilities to harmonize visual elements to satisfy both
image-level prompt alignment and set-level visual consistency. Extensive
experiments on T2IS-Bench reveal that diverse consistency challenges all
existing methods, while our AutoT2IS significantly outperforms current
generalized and even specialized approaches. Our method also demonstrates the
ability to enable numerous underexplored real-world applications, confirming
its substantial practical value. Visit our project in
https://chengyou-jia.github.io/T2IS-Home.

</details>


### [114] [Autoregressive Denoising Score Matching is a Good Video Anomaly Detector](https://arxiv.org/abs/2506.23282)
*Hanwen Zhang,Congqi Cao,Qinyi Lv,Lingtong Min,Yanning Zhang*

Main category: cs.CV

TL;DR: 本研究提出了一种结合场景、运动和外观的多维度分数匹配方法，用于提高视频异常检测的效果，结果表明方法在三大主流基准测试上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有基于生成模型的异常检测方法对接近已学习分布的局部模式异常盲区问题存在局限，研发新方法以解决这一问题。

Method: 设计一个基于去噪分数匹配的噪声条件变换器，引入场景依赖和运动感知的分数函数，通过自回归方式结合未受影响的视觉信息进行去噪并改进外观感知，同时累积异常背景。

Result: 在三大主流VAD基准测试中，该方法表现出了最新的性能水平。

Conclusion: 本文方法通过考虑场景、运动和外观三个维度的差距，提供了更全面的异常指标计算方式，显著提高了视频异常检测的效果。

Abstract: Video anomaly detection (VAD) is an important computer vision problem. Thanks
to the mode coverage capabilities of generative models, the likelihood-based
paradigm is catching growing interest, as it can model normal distribution and
detect out-of-distribution anomalies. However, these likelihood-based methods
are blind to the anomalies located in local modes near the learned
distribution. To handle these ``unseen" anomalies, we dive into three gaps
uniquely existing in VAD regarding scene, motion and appearance. Specifically,
we first build a noise-conditioned score transformer for denoising score
matching. Then, we introduce a scene-dependent and motion-aware score function
by embedding the scene condition of input sequences into our model and
assigning motion weights based on the difference between key frames of input
sequences. Next, to solve the problem of blindness in principle, we integrate
unaffected visual information via a novel autoregressive denoising score
matching mechanism for inference. Through autoregressively injecting
intensifying Gaussian noise into the denoised data and estimating the
corresponding score function, we compare the denoised data with the original
data to get a difference and aggregate it with the score function for an
enhanced appearance perception and accumulate the abnormal context. With all
three gaps considered, we can compute a more comprehensive anomaly indicator.
Experiments on three popular VAD benchmarks demonstrate the state-of-the-art
performance of our method.

</details>


### [115] [MoMa: Modulating Mamba for Adapting Image Foundation Models to Video Recognition](https://arxiv.org/abs/2506.23283)
*Yuhuan Yang,Chaofan Ma,Zhenjie Mao,Jiangchao Yao,Ya Zhang,Yanfeng Wang*

Main category: cs.CV

TL;DR: 本文提出了MoMa，一种高效率的适配器框架，通过集成Mamba的选择性状态空间建模，实现了完整的时空建模，大幅提升了视频理解效果。


<details>
  <summary>Details</summary>
Motivation: 目前的图像基础模型在图像理解方面表现优异，但其在视频理解上的适应性有限，大多采用的时空信息分开处理的方法未能完整捕捉视频动态。

Method: 提出了MoMa框架，结合Mamba选择性状态空间建模及创新的SeqMod操作，形成Divide-and-Modulate结构，高效注入时空信息，保留原始模型特性。

Result: 在多个视频基准测试中表现优越，同时显著降低了计算成本。

Conclusion: MoMa为视频理解任务提供了一种高效、性能强大的全面时空建模解决方案。

Abstract: Video understanding is a complex challenge that requires effective modeling
of spatial-temporal dynamics. With the success of image foundation models
(IFMs) in image understanding, recent approaches have explored
parameter-efficient fine-tuning (PEFT) to adapt IFMs for video. However, most
of these methods tend to process spatial and temporal information separately,
which may fail to capture the full intricacy of video dynamics. In this paper,
we propose MoMa, an efficient adapter framework that achieves full
spatial-temporal modeling by integrating Mamba's selective state space modeling
into IFMs. We propose a novel SeqMod operation to inject spatial-temporal
information into pre-trained IFMs, without disrupting their original features.
By incorporating SeqMod into a Divide-and-Modulate architecture, MoMa enhances
video understanding while maintaining computational efficiency. Extensive
experiments on multiple video benchmarks demonstrate the effectiveness of MoMa,
achieving superior performance with reduced computational cost.

</details>


### [116] [Competitive Distillation: A Simple Learning Strategy for Improving Visual Classification](https://arxiv.org/abs/2506.23285)
*Daqian Shi,Xiaolei Diao,Xu Chen,Cédric M. John*

Main category: cs.CV

TL;DR: 本研究提出了一种新的竞争性蒸馏策略，通过让网络组内的每个网络根据其性能成为老师角色，从而改进整体学习表现。


<details>
  <summary>Details</summary>
Motivation: 目前知识蒸馏方法在促进多网络协作训练上有一定的局限性，对学习方向的理解不够深入。

Method: 引入竞争式蒸馏策略，网络组内任务共享并竞争优化，同时结合随机扰动以激发网络产生突变，优化参数更新。

Result: 竞争性蒸馏在不同任务和数据集上均表现出良好效果。

Conclusion: 通过竞争优化和随机扰动的结合，该方法显著提升了网络训练的整体性能，且扩展了知识蒸馏的应用场景。

Abstract: Deep Neural Networks (DNNs) have significantly advanced the field of computer
vision. To improve DNN training process, knowledge distillation methods
demonstrate their effectiveness in accelerating network training by introducing
a fixed learning direction from the teacher network to student networks. In
this context, several distillation-based optimization strategies are proposed,
e.g., deep mutual learning and self-distillation, as an attempt to achieve
generic training performance enhancement through the cooperative training of
multiple networks. However, such strategies achieve limited improvements due to
the poor understanding of the impact of learning directions among networks
across different iterations. In this paper, we propose a novel competitive
distillation strategy that allows each network in a group to potentially act as
a teacher based on its performance, enhancing the overall learning performance.
Competitive distillation organizes a group of networks to perform a shared task
and engage in competition, where competitive optimization is proposed to
improve the parameter updating process. We further introduce stochastic
perturbation in competitive distillation, aiming to motivate networks to induce
mutations to achieve better visual representations and global optimum. The
experimental results show that competitive distillation achieves promising
performance in diverse tasks and datasets.

</details>


### [117] [DDL: A Dataset for Interpretable Deepfake Detection and Localization in Real-World Scenarios](https://arxiv.org/abs/2506.23292)
*Changtao Miao,Yi Zhang,Weize Gao,Man Luo,Weiwei Feng,Zhiya Tan,Jianshu Li,Ajian Liu,Yunfeng Diao,Qi Chu,Tao Gong,Zhe Li,Weibin Yao,Joey Tianyi Zhou*

Main category: cs.CV

TL;DR: 本文提出了一个包含1.8M个伪造样本、75种伪造方法的大规模深伪检测和定位（DDL）数据集，旨在解决现有方法中缺乏解释性与数据集不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有深伪检测模型在缺乏解释性的情况下面临法律等关键领域的挑战，同时目前数据集规模小且伪造场景单一。

Method: 构建一个新颖的大规模DDL数据集，包含多样化伪造场景、全面的深伪方法、多样化的操作模式和细粒度的伪造注释。

Result: DDL数据集为真实世界复杂伪造问题提供了更高的基准，并支持构建下一代深伪检测与解释性方法。

Conclusion: DDL数据集在数据规模与多样性上显著提升，为深伪检测和定位领域奠定了坚实基础。

Abstract: Recent advances in AIGC have exacerbated the misuse of malicious deepfake
content, making the development of reliable deepfake detection methods an
essential means to address this challenge. Although existing deepfake detection
models demonstrate outstanding performance in detection metrics, most methods
only provide simple binary classification results, lacking interpretability. In
critical domains such as law, interpretability is crucial for enhancing the
credibility and authority of decisions. Recent studies attempt to improve the
interpretability of classification results by providing spatial manipulation
masks or temporal forgery segments. However, the practical effectiveness of
these methods remains suboptimal due to limitations of the forgery data. Most
current deepfake datasets predominantly offer binary labels, only a few
datasets with localization annotations. However, they suffer from restricted
forgery scenarios, limited diversity in deepfake types, and insufficient data
scale, making them inadequate for complex real-world scenarios. To address this
predicament, we construct a novel large-scale deepfake detection and
localization ($\textbf{DDL}$) dataset containing over $\textbf{1.8M}$ forged
samples and encompassing up to $\textbf{75}$ distinct deepfake methods. The DDL
design incorporates four key innovations: (1) $\textbf{Diverse Forgery
Scenarios}$, (2) $\textbf{Comprehensive Deepfake Methods}$, (3) $\textbf{Varied
Manipulation Modes}$, and (4) $\textbf{Fine-grained Forgery Annotations}$.
Through these improvements, our DDL not only provides a more challenging
benchmark for complex real-world forgeries, but also offers crucial support for
building next-generation deepfake detection, localization, and interpretability
methods. The DDL dataset project page is on
https://deepfake-workshop-ijcai2025.github.io/main/index.html.

</details>


### [118] [DiffFit: Disentangled Garment Warping and Texture Refinement for Virtual Try-On](https://arxiv.org/abs/2506.23295)
*Xiang Xu*

Main category: cs.CV

TL;DR: DiffFit 是一种用于虚拟试穿（VTON）任务的两阶段潜在扩散框架，能够高质量还原衣物细节和实现精准的服装与人体对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的潜在扩散模型方法在处理虚拟试穿的细化细节保留、服装与人体精准对齐、推理效率以及对多样姿态和服装样式的泛化能力方面仍存在挑战。提出 DiffFit 是为了解决这些问题。

Method: DiffFit 采用两阶段策略：第一阶段通过几何感知的服装变形实现服装与目标人体的对齐；第二阶段通过跨模态条件扩散模型结合服装变形效果、原始服装外观和目标人像进行高质量渲染，以增强纹理保真度。

Result: DiffFit 在保留服装特定属性（如纹理、褶皱、光照）和人体对齐方面表现出色，并在虚拟试穿的定量指标和感知评估中超越现有方法。

Conclusion: 通过几何对齐和外观精细化的分离，DiffFit 有效降低了任务复杂度，提高了生成的稳定性与视觉真实感，并且在虚拟试穿领域取得了先进性能。

Abstract: Virtual try-on (VTON) aims to synthesize realistic images of a person wearing
a target garment, with broad applications in e-commerce and digital fashion.
While recent advances in latent diffusion models have substantially improved
visual quality, existing approaches still struggle with preserving fine-grained
garment details, achieving precise garment-body alignment, maintaining
inference efficiency, and generalizing to diverse poses and clothing styles. To
address these challenges, we propose DiffFit, a novel two-stage latent
diffusion framework for high-fidelity virtual try-on. DiffFit adopts a
progressive generation strategy: the first stage performs geometry-aware
garment warping, aligning the garment with the target body through fine-grained
deformation and pose adaptation. The second stage refines texture fidelity via
a cross-modal conditional diffusion model that integrates the warped garment,
the original garment appearance, and the target person image for high-quality
rendering. By decoupling geometric alignment and appearance refinement, DiffFit
effectively reduces task complexity and enhances both generation stability and
visual realism. It excels in preserving garment-specific attributes such as
textures, wrinkles, and lighting, while ensuring accurate alignment with the
human body. Extensive experiments on large-scale VTON benchmarks demonstrate
that DiffFit achieves superior performance over existing state-of-the-art
methods in both quantitative metrics and perceptual evaluations.

</details>


### [119] [Endo-4DGX: Robust Endoscopic Scene Reconstruction and Illumination Correction with Gaussian Splatting](https://arxiv.org/abs/2506.23308)
*Yiming Huang,Long Bai,Beilei Cui,Yanheng Li,Tong Chen,Jie Wang,Jinlin Wu,Zhen Lei,Hongbin Liu,Hongliang Ren*

Main category: cs.CV

TL;DR: 本论文提出了一种适用于内窥镜场景的新型3D高斯重建方法Endo-4DGX，解决在低光照和过曝情况下的渲染问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D Gaussian Splatting技术在极端光照条件下渲染质量较差，需要开发针对不均匀照明场景的优化方法。

Method: 引入了光照嵌入以有效建模亮度变化，使用区域增强模块和空间调整模块调整局部光照和一致性亮度，并加入了曝光控制损失用于优化。

Result: Endo-4DGX在低光照和过曝条件下展现出优越的渲染性能，优于现有的重建和修复方法组合。

Conclusion: Endo-4DGX能在复杂光照环境中准确且高效地重建软组织，提升了机器人辅助手术的应用潜力。

Abstract: Accurate reconstruction of soft tissue is crucial for advancing automation in
image-guided robotic surgery. The recent 3D Gaussian Splatting (3DGS)
techniques and their variants, 4DGS, achieve high-quality renderings of dynamic
surgical scenes in real-time. However, 3D-GS-based methods still struggle in
scenarios with varying illumination, such as low light and over-exposure.
Training 3D-GS in such extreme light conditions leads to severe optimization
problems and devastating rendering quality. To address these challenges, we
present Endo-4DGX, a novel reconstruction method with illumination-adaptive
Gaussian Splatting designed specifically for endoscopic scenes with uneven
lighting. By incorporating illumination embeddings, our method effectively
models view-dependent brightness variations. We introduce a region-aware
enhancement module to model the sub-area lightness at the Gaussian level and a
spatial-aware adjustment module to learn the view-consistent brightness
adjustment. With the illumination adaptive design, Endo-4DGX achieves superior
rendering performance under both low-light and over-exposure conditions while
maintaining geometric accuracy. Additionally, we employ an exposure control
loss to restore the appearance from adverse exposure to the normal level for
illumination-adaptive optimization. Experimental results demonstrate that
Endo-4DGX significantly outperforms combinations of state-of-the-art
reconstruction and restoration methods in challenging lighting environments,
underscoring its potential to advance robot-assisted surgical applications. Our
code is available at https://github.com/lastbasket/Endo-4DGX.

</details>


### [120] [FastSeg: Efficient Training-Free Open-Vocabulary Segmentation via Hierarchical Attention Refinement Method](https://arxiv.org/abs/2506.23323)
*Quang-Huy Che,Vinh-Tiep Nguyen*

Main category: cs.CV

TL;DR: 提出了一种名为FastSeg的高效无训练开词汇语义分割方法，结合扩散模型的优点实现高质量分割。


<details>
  <summary>Details</summary>
Motivation: 现有基于对比学习的开词汇语义分割方法在像素级空间精度存在缺陷，而扩散模型尽管具有空间细节优势，却在迭代平衡中面临挑战。

Method: 提出FastSeg框架，基于预训练扩散模型的(1+1)-步逆向过程，还引入了双提示机制、分层注意力优化方法以及测试时翻转策略提高分割精度。

Result: FastSeg在PASCAL VOC、PASCAL Context和COCO Object基准测试中实现43.8%的mIoU，具有较好的性能与推理效率。

Conclusion: FastSeg兼顾分割质量与推理效率，为开词汇语义分割提供了高潜力的扩展基础。

Abstract: Open-vocabulary semantic segmentation (OVSS) aims to segment objects from
arbitrary text categories without requiring densely annotated datasets.
Although contrastive learning based models enable zero-shot segmentation, they
often lose fine spatial precision at pixel level, due to global representation
bias. In contrast, diffusion-based models naturally encode fine-grained spatial
features via attention mechanisms that capture both global context and local
details. However, they often face challenges in balancing the number of
iterations with the quality of the segmentation. In this work, we propose
FastSeg, a novel and efficient training-free framework with only (1+1)-step of
reverse process of a pretrained diffusion model (e.g., Stable Diffusion).
Moreover, instead of running multiple times for different classes, FastSeg
performs segmentation for all classes at once. To further enhance the
segmentation quality, FastSeg introduces three key components: (i) a
dual-prompt mechanism for discriminative, class-aware attention extraction,
(ii) a Hierarchical Attention Refinement Method (HARD) that enhances fused
cross-attention using scale-aligned selfattention maps, and (iii) a Test-Time
Flipping (TTF) scheme designed to improve spatial consistency. Extensive
experiments show that FastSeg achieves state-of-the-art training-free
performance, obtaining 43.8% average mIoU across PASCAL VOC, PASCAL Context,
and COCO Object benchmarks while maintaining superior inference efficiency. Our
results demonstrate that FastSeg provides a strong foundation for
extendability, bridging the gap between segmentation quality and inference
efficiency.

</details>


### [121] [IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering](https://arxiv.org/abs/2506.23329)
*Parker Liu,Chenxin Li,Zhengxin Li,Yipeng Wu,Wuyang Li,Zhiqin Yang,Zhenyuan Zhang,Yunlong Lin,Sirui Han,Brandon Y. Feng*

Main category: cs.CV

TL;DR: 提出了IR3D-Bench评估视觉语言模型（VLMs）理解场景的能力，要求其通过编程和渲染工具重建图像的3D结构。


<details>
  <summary>Details</summary>
Motivation: 目前的VLMs在描述任务上表现优秀，但是否真正理解通过视觉观察的场景仍存疑。为此需要一个评估模型是否能够主动生成以体现理解的新标准。

Method: 通过基于'创造以理解'的方法，设计了一种名为IR3D-Bench的基准，要求VLMs通过工具主动重建输入图像的3D结构，并提供全面的几何准确性、空间关系、外观属性等评价指标。

Result: 初步实验表明，当前主流VLMs在视觉精度上存在显著局限性，但在基本工具使用上有一定的能力表现。

Conclusion: IR3D-Bench推动了对工具使用型视觉语言模型的系统研究，为实现真正的场景理解奠定了基础。

Abstract: Vision-language models (VLMs) excel at descriptive tasks, but whether they
truly understand scenes from visual observations remains uncertain. We
introduce IR3D-Bench, a benchmark challenging VLMs to demonstrate understanding
through active creation rather than passive recognition. Grounded in the
analysis-by-synthesis paradigm, IR3D-Bench tasks Vision-Language Agents (VLAs)
with actively using programming and rendering tools to recreate the underlying
3D structure of an input image, achieving agentic inverse rendering through
tool use. This "understanding-by-creating" approach probes the tool-using
generative capacity of VLAs, moving beyond the descriptive or conversational
capacity measured by traditional scene understanding benchmarks. We provide a
comprehensive suite of metrics to evaluate geometric accuracy, spatial
relations, appearance attributes, and overall plausibility. Initial experiments
on agentic inverse rendering powered by various state-of-the-art VLMs highlight
current limitations, particularly in visual precision rather than basic tool
usage. IR3D-Bench, including data and evaluation protocols, is released to
facilitate systematic study and development of tool-using VLAs towards genuine
scene understanding by creating.

</details>


### [122] [CycleVAR: Repurposing Autoregressive Model for Unsupervised One-Step Image Translation](https://arxiv.org/abs/2506.23347)
*Yi Liu,Shengqian Li,Zuzeng Lin,Feng Wang,Si Liu*

Main category: cs.CV

TL;DR: 提出Softmax Relaxed Quantization解决图像生成训练中的梯度瓶颈问题，并引入CycleVAR框架实现无监督图像翻译的高效、高质量生成。


<details>
  <summary>Details</summary>
Motivation: 当前条件自回归图像生成方法在无监督图像翻译领域的潜力尚未被充分利用，主要在于传统向量量化框架限制了梯度流动。

Method: 提出Softmax Relaxed Quantization方法，允许梯度在变分自编码器解码器和因果Transformer之间流动；并设计CycleVAR框架用于无监督图像翻译，通过多尺度图片tokens提示实现前缀式条件生成。

Result: 实验结果表明，CycleVAR在一键生成模式下优于多步生成模式，能以更快的速度实现更高质量的翻译，同时优于CycleGAN-Turbo等现有技术。

Conclusion: CycleVAR以Softmax Relaxed Quantization为基础，有效解决了传统自回归生成中的优化问题，成为新一代无监督图像翻译模型的领先方案。

Abstract: The current conditional autoregressive image generation methods have shown
promising results, yet their potential remains largely unexplored in the
practical unsupervised image translation domain, which operates without
explicit cross-domain correspondences. A critical limitation stems from the
discrete quantization inherent in traditional Vector Quantization-based
frameworks, which disrupts gradient flow between the Variational Autoencoder
decoder and causal Transformer, impeding end-to-end optimization during
adversarial training in image space. To tackle this issue, we propose using
Softmax Relaxed Quantization, a novel approach that reformulates codebook
selection as a continuous probability mixing process via Softmax, thereby
preserving gradient propagation. Building upon this differentiable foundation,
we introduce CycleVAR, which reformulates image-to-image translation as
image-conditional visual autoregressive generation by injecting multi-scale
source image tokens as contextual prompts, analogous to prefix-based
conditioning in language models. CycleVAR exploits two modes to generate the
target image tokens, including (1) serial multi-step generation, enabling
iterative refinement across scales, and (2) parallel one-step generation
synthesizing all resolution outputs in a single forward pass. Experimental
findings indicate that the parallel one-step generation mode attains superior
translation quality with quicker inference speed than the serial multi-step
mode in unsupervised scenarios. Furthermore, both quantitative and qualitative
results indicate that CycleVAR surpasses previous state-of-the-art unsupervised
image translation models, \textit{e}.\textit{g}., CycleGAN-Turbo.

</details>


### [123] [GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields](https://arxiv.org/abs/2506.23352)
*Shunsuke Yasuki,Taiki Miyanishi,Nakamasa Inoue,Shuhei Kurita,Koya Sakamoto,Daichi Azuma,Masato Taki,Yutaka Matsuo*

Main category: cs.CV

TL;DR: GeoProg3D 是一个能够通过自然语言与城市级高保真 3D 场景交互的框架，解决了目前方法在大规模场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有 3D 语言领域方法在处理大规模复杂场景时缺乏可扩展性和组合推理能力。

Method: 提出 GeoProg3D 框架，包括地理感知城市级 3D 语言场（GCLF）和地理视觉 API（GV-APIs），结合大语言模型实现城市级推理任务。

Result: GeoProg3D 在空间推理、比较、计数等多项城市级任务上明显优于现有方法。

Conclusion: GeoProg3D 是首个基于语言的城市级 3D 场景组合推理框架，为高保真场景中基于自然语言的交互开辟了新途径。

Abstract: The advancement of 3D language fields has enabled intuitive interactions with
3D scenes via natural language. However, existing approaches are typically
limited to small-scale environments, lacking the scalability and compositional
reasoning capabilities necessary for large, complex urban settings. To overcome
these limitations, we propose GeoProg3D, a visual programming framework that
enables natural language-driven interactions with city-scale high-fidelity 3D
scenes. GeoProg3D consists of two key components: (i) a Geography-aware
City-scale 3D Language Field (GCLF) that leverages a memory-efficient
hierarchical 3D model to handle large-scale data, integrated with geographic
information for efficiently filtering vast urban spaces using directional cues,
distance measurements, elevation data, and landmark references; and (ii)
Geographical Vision APIs (GV-APIs), specialized geographic vision tools such as
area segmentation and object detection. Our framework employs large language
models (LLMs) as reasoning engines to dynamically combine GV-APIs and operate
GCLF, effectively supporting diverse geographic vision tasks. To assess
performance in city-scale reasoning, we introduce GeoEval3D, a comprehensive
benchmark dataset containing 952 query-answer pairs across five challenging
tasks: grounding, spatial reasoning, comparison, counting, and measurement.
Experiments demonstrate that GeoProg3D significantly outperforms existing 3D
language fields and vision-language models across multiple tasks. To our
knowledge, GeoProg3D is the first framework enabling compositional geographic
reasoning in high-fidelity city-scale 3D environments via natural language. The
code is available at https://snskysk.github.io/GeoProg3D/.

</details>


### [124] [Layer Decomposition and Morphological Reconstruction for Task-Oriented Infrared Image Enhancement](https://arxiv.org/abs/2506.23353)
*Siyuan Chai,Xiaodong Guo,Tong Liu*

Main category: cs.CV

TL;DR: 提出了一种面向任务的红外图像增强方法，通过层分解和显著性信息提取来提升复杂天气条件下的红外图像质量。


<details>
  <summary>Details</summary>
Motivation: 解决红外图像低对比度问题，改善如雾、雨、低光环境等复杂天气对自动驾驶感知能力的影响。

Method: 提出了层分解和基于形态学重建的显著性信息提取两部分组成的图像增强方法。

Result: 实验结果表明，该方法的图像增强性能优于当前最先进方法。

Conclusion: 方法能够提升非热辐射目标（如自行车）的图像对比度，同时避免噪声增强和信息丢失，为目标检测和语义分割任务提供了更优性能支持。

Abstract: Infrared image helps improve the perception capabilities of autonomous
driving in complex weather conditions such as fog, rain, and low light.
However, infrared image often suffers from low contrast, especially in
non-heat-emitting targets like bicycles, which significantly affects the
performance of downstream high-level vision tasks. Furthermore, achieving
contrast enhancement without amplifying noise and losing important information
remains a challenge. To address these challenges, we propose a task-oriented
infrared image enhancement method. Our approach consists of two key components:
layer decomposition and saliency information extraction. First, we design an
layer decomposition method for infrared images, which enhances scene details
while preserving dark region features, providing more features for subsequent
saliency information extraction. Then, we propose a morphological
reconstruction-based saliency extraction method that effectively extracts and
enhances target information without amplifying noise. Our method improves the
image quality for object detection and semantic segmentation tasks. Extensive
experiments demonstrate that our approach outperforms state-of-the-art methods.

</details>


### [125] [SIEDD: Shared-Implicit Encoder with Discrete Decoders](https://arxiv.org/abs/2506.23382)
*Vikram Rangarajan,Shishira Maiya,Max Ehrlich,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: 该论文提出了一种新的架构SIEDD，可使隐式神经表示（INRs）在视频压缩中大幅加速编码速度，同时保留高质量的重建和坐标控制能力。


<details>
  <summary>Details</summary>
Motivation: 现有的隐式神经表示在视频压缩中编码时间过长，限制了其实用性，并且现有的加速尝试通常会牺牲质量或控制能力。这促使寻找一种既高效又不牺牲性能的解决方案。

Method: SIEDD通过快速训练共享的坐标编码器在稀疏锚点帧上捕获全局低频特性，然后冻结编码器以并行训练轻量化的离散解码器，并结合坐标空间采样进一步优化训练速度。

Result: SIEDD在高清（HD）和4K视频基准测试上实现了20-30倍的编码速度提升，同时保持了与现有INR编解码器相当的重建质量和压缩比，并保留了坐标级别的控制能力。

Conclusion: SIEDD显著提高了高保真神经视频压缩的实用性，为实际部署提供了一种可扩展高效的解决方案。

Abstract: Implicit Neural Representations (INRs) offer exceptional fidelity for video
compression by learning per-video optimized functions, but their adoption is
crippled by impractically slow encoding times. Existing attempts to accelerate
INR encoding often sacrifice reconstruction quality or crucial coordinate-level
control essential for adaptive streaming and transcoding. We introduce SIEDD
(Shared-Implicit Encoder with Discrete Decoders), a novel architecture that
fundamentally accelerates INR encoding without these compromises. SIEDD first
rapidly trains a shared, coordinate-based encoder on sparse anchor frames to
efficiently capture global, low-frequency video features. This encoder is then
frozen, enabling massively parallel training of lightweight, discrete decoders
for individual frame groups, further expedited by aggressive coordinate-space
sampling. This synergistic design delivers a remarkable 20-30X encoding
speed-up over state-of-the-art INR codecs on HD and 4K benchmarks, while
maintaining competitive reconstruction quality and compression ratios.
Critically, SIEDD retains full coordinate-based control, enabling continuous
resolution decoding and eliminating costly transcoding. Our approach
significantly advances the practicality of high-fidelity neural video
compression, demonstrating a scalable and efficient path towards real-world
deployment. Our codebase is available at
https://github.com/VikramRangarajan/SIEDD .

</details>


### [126] [OmniVCus: Feedforward Subject-driven Video Customization with Multimodal Control Conditions](https://arxiv.org/abs/2506.23361)
*Yuanhao Cai,He Zhang,Xi Chen,Jinbo Xing,Yiwei Hu,Yuqian Zhou,Kai Zhang,Zhifei Zhang,Soo Ye Kim,Tianyu Wang,Yulun Zhang,Xiaokang Yang,Zhe Lin,Alan Yuille*

Main category: cs.CV

TL;DR: 本文提出了一种名为OmniVCus的新方法，可以实现对多主体视频的编辑和控制。


<details>
  <summary>Details</summary>
Motivation: 主要解决了当前视频定制方法中对多主体处理和控制信号下编辑的不足。

Method: 设计了一个数据构建管道VideoCus-Factory用于生成多主体定制的训练数据对，并提出了IVTM训练策略和基于扩散Transformer的OmniVCus框架，使用LE和TAE嵌入机制优化生成性能。

Result: 实验表明，新方法在定量和定性指标上均显著优于现有方法。

Conclusion: 新方法在多主体视频定制与编辑方面取得了重大突破，可实现更灵活的编辑和控制。

Abstract: Existing feedforward subject-driven video customization methods mainly study
single-subject scenarios due to the difficulty of constructing multi-subject
training data pairs. Another challenging problem that how to use the signals
such as depth, mask, camera, and text prompts to control and edit the subject
in the customized video is still less explored. In this paper, we first propose
a data construction pipeline, VideoCus-Factory, to produce training data pairs
for multi-subject customization from raw videos without labels and control
signals such as depth-to-video and mask-to-video pairs. Based on our
constructed data, we develop an Image-Video Transfer Mixed (IVTM) training with
image editing data to enable instructive editing for the subject in the
customized video. Then we propose a diffusion Transformer framework, OmniVCus,
with two embedding mechanisms, Lottery Embedding (LE) and Temporally Aligned
Embedding (TAE). LE enables inference with more subjects by using the training
subjects to activate more frame embeddings. TAE encourages the generation
process to extract guidance from temporally aligned control signals by
assigning the same frame embeddings to the control and noise tokens.
Experiments demonstrate that our method significantly surpasses
state-of-the-art methods in both quantitative and qualitative evaluations.
Video demos are at our project page:
https://caiyuanhao1998.github.io/project/OmniVCus/. Our code will be released
at https://github.com/caiyuanhao1998/Open-OmniVCus

</details>


### [127] [A High-Throughput Platform to Bench Test Smartphone-Based Heart Rate Measurements Derived From Video](https://arxiv.org/abs/2506.23414)
*Ming-Zher Poh,Jonathan Wang,Jonathan Hsu,Lawrence Cai,Eric Teasley,James A. Taylor,Jameson K. Rogers,Anupam Pathak,Shwetak Patel*

Main category: cs.CV

TL;DR: 本文提出了一种新的高通量测试平台，用于评估基于智能手机的心率监测应用的性能和设备兼容性，通过测试显示其在准确性和设备分类上表现优异。


<details>
  <summary>Details</summary>
Motivation: 智能手机基于PPG的心率监测应用因设备多样性和无统一评估方法等问题，面临性能评估和设备兼容性方面的重大挑战。

Method: 设计了一个测试平台，包括一个可同时放置12部智能手机的测试架、用于生成可控心率和信号质量的合成PPG测试视频的方法，以及一个协调视频播放和数据记录的主机。

Result: 测试平台实现了输入与测量心率间的绝对平均百分比误差（MAPE）为0.11% ± 0.001%，PPG信号相关系数为0.92 ± 0.008，成功分类了20种智能手机型号并满足ANSI/CTA精度标准。

Conclusion: 该平台为智能手机心率监测应用的部署前测试提供了可扩展的解决方案，有助于提升性能、确保设备兼容性及推动移动健康领域的发展。

Abstract: Smartphone-based heart rate (HR) monitoring apps using finger-over-camera
photoplethysmography (PPG) face significant challenges in performance
evaluation and device compatibility due to device variability and
fragmentation. Manual testing is impractical, and standardized methods are
lacking. This paper presents a novel, high-throughput bench-testing platform to
address this critical need. We designed a system comprising a test rig capable
of holding 12 smartphones for parallel testing, a method for generating
synthetic PPG test videos with controllable HR and signal quality, and a host
machine for coordinating video playback and data logging. The system achieved a
mean absolute percentage error (MAPE) of 0.11% +/- 0.001% between input and
measured HR, and a correlation coefficient of 0.92 +/- 0.008 between input and
measured PPG signals using a clinically-validated smartphone-based HR app.
Bench-testing results of 20 different smartphone models correctly classified
all the devices as meeting the ANSI/CTA accuracy standards for HR monitors
(MAPE <10%) when compared to a prospective clinical study with 80 participants,
demonstrating high positive predictive value. This platform offers a scalable
solution for pre-deployment testing of smartphone HR apps to improve app
performance, ensure device compatibility, and advance the field of mobile
health.

</details>


### [128] [Why Settle for Mid: A Probabilistic Viewpoint to Spatial Relationship Alignment in Text-to-image Models](https://arxiv.org/abs/2506.23418)
*Parham Rezaei,Arash Marioriyad,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: 提出了一种基于优越性概率（PoS）的概率框架，改进文本到图像模型在生成图像时对空间关系的表达能力，并设计了新的评估指标PSE和生成方法PSG。


<details>
  <summary>Details</summary>
Motivation: 由于生成模型在细节和空间关系表达上存在不足，尤其是无法准确生成输入中的空间配置关系，作者希望解决这个问题。

Method: 提出了一种基于概率的PoS框架，包括评估指标PSE和生成方法PSG，PSG通过结合梯度指导和搜索策略来优化空间关系的生成，而无需模型微调。

Result: PSE评估指标与人类判断的一致性更高，PSG方法显著提升了生成图像中空间关系的准确性，在多个基准测试中超越了现有的最先进方法。

Conclusion: 通过PoS框架的引入，文本到图像模型在空间关系生成能力上得到了显著改进，可作为未来生成模型优化的参考。

Abstract: Despite the ability of text-to-image models to generate high-quality,
realistic, and diverse images, they face challenges in compositional
generation, often struggling to accurately represent details specified in the
input prompt. A prevalent issue in compositional generation is the misalignment
of spatial relationships, as models often fail to faithfully generate images
that reflect the spatial configurations specified between objects in the input
prompts. To address this challenge, we propose a novel probabilistic framework
for modeling the relative spatial positioning of objects in a scene, leveraging
the concept of Probability of Superiority (PoS). Building on this insight, we
make two key contributions. First, we introduce a novel evaluation metric,
PoS-based Evaluation (PSE), designed to assess the alignment of 2D and 3D
spatial relationships between text and image, with improved adherence to human
judgment. Second, we propose PoS-based Generation (PSG), an inference-time
method that improves the alignment of 2D and 3D spatial relationships in T2I
models without requiring fine-tuning. PSG employs a Part-of-Speech PoS-based
reward function that can be utilized in two distinct ways: (1) as a
gradient-based guidance mechanism applied to the cross-attention maps during
the denoising steps, or (2) as a search-based strategy that evaluates a set of
initial noise vectors to select the best one. Extensive experiments demonstrate
that the PSE metric exhibits stronger alignment with human judgment compared to
traditional center-based metrics, providing a more nuanced and reliable measure
of complex spatial relationship accuracy in text-image alignment. Furthermore,
PSG significantly enhances the ability of text-to-image models to generate
images with specified spatial configurations, outperforming state-of-the-art
methods across multiple evaluation metrics and benchmarks.

</details>


### [129] [Detecting What Matters: A Novel Approach for Out-of-Distribution 3D Object Detection in Autonomous Vehicles](https://arxiv.org/abs/2506.23426)
*Menna Taha,Aya Ahmed,Mohammed Karmoose,Yasser Gadallah*

Main category: cs.CV

TL;DR: 提出了一种基于对象危险性判断的新型方法，改善自动驾驶车辆对未见对象（OOD）目标的检测与分类能力。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测方法无法有效识别和应对OOD对象的安全性问题，可能导致检测失败或错误分类，带来安全隐患。

Method: 通过基于与车辆的位置和轨迹关系判断对象的“有害”或“无害”，替代传统的按类别进行分类的方法。

Result: 模型能够有效处理OOD对象，评估其危险性并基于此分类，提升自动驾驶车辆在动态环境中的决策能力。

Conclusion: 所提出的方法增强了自动驾驶车辆的实时决策安全性和有效性。

Abstract: Autonomous vehicles (AVs) use object detection models to recognize their
surroundings and make driving decisions accordingly. Conventional object
detection approaches classify objects into known classes, which limits the AV's
ability to detect and appropriately respond to Out-of-Distribution (OOD)
objects. This problem is a significant safety concern since the AV may fail to
detect objects or misclassify them, which can potentially lead to hazardous
situations such as accidents. Consequently, we propose a novel object detection
approach that shifts the emphasis from conventional class-based classification
to object harmfulness determination. Instead of object detection by their
specific class, our method identifies them as either 'harmful' or 'harmless'
based on whether they pose a danger to the AV. This is done based on the object
position relative to the AV and its trajectory. With this metric, our model can
effectively detect previously unseen objects to enable the AV to make safer
real-time decisions. Our results demonstrate that the proposed model
effectively detects OOD objects, evaluates their harmfulness, and classifies
them accordingly, thus enhancing the AV decision-making effectiveness in
dynamic environments.

</details>


### [130] [Towards foundational LiDAR world models with efficient latent flow matching](https://arxiv.org/abs/2506.23434)
*Tianran Liu,Shengwen Zhao,Nicholas Rhinehart*

Main category: cs.CV

TL;DR: LiDAR世界模型具有几何感知特性，但现有模型传输能力有限。因此研究提升模型在多场景跨域传输表现的可能性，提出一种基于条件流匹配（CFM）的框架，在节省显著标注数据需求的同时提升性能与效率。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR模型训练仅适用于特定场景，无法有效跨域传输。目标是开发出具有强跨域迁移能力的LiDAR世界模型。

Method: 进行跨域研究，探索三种通用场景下的迁移能力。创新地引入一种基于潜在条件流匹配(CFM)的框架，大幅提升压缩效率和训练效能。

Result: 所提模型较从头训练提升11%效果，显著减少标注数据需求(仅需5%)；且模型在压缩比和计算效率方面均大幅优于现有方法，达成多项SOTA结果。

Conclusion: 提出的模型不仅提升了LiDAR世界模型的跨域迁移能力和性能，同时显著降低计算与标注需求，为开发高效通用的LiDAR系统铺平了道路。

Abstract: LiDAR-based world models offer more structured and geometry-aware
representations than their image-based counterparts. However, existing LiDAR
world models are narrowly trained; each model excels only in the domain for
which it was built. Can we develop LiDAR world models that exhibit strong
transferability across multiple domains? We conduct the first systematic domain
transfer study across three demanding scenarios: (i) outdoor to indoor
generalization, (ii) sparse-beam \& dense-beam adaptation, and (iii)
non-semantic to semantic transfer. Given different amounts of fine-tuning data,
our experiments show that a single pre-trained model can achieve up to 11%
absolute improvement (83\% relative) over training from scratch and outperforms
training from scratch in 30/36 of our comparisons. This transferability of
dynamic learning significantly reduces the reliance on manually annotated data
for semantic occupancy forecasting: our method exceed the previous semantic
occupancy forecasting models with only 5% of the labeled training data required
by prior models. We also observed inefficiencies of current LiDAR world models,
mainly through their under-compression of LiDAR data and inefficient training
objectives. To address this, we propose a latent conditional flow matching
(CFM)-based frameworks that achieves state-of-the-art reconstruction accuracy
using only half the training data and a compression ratio 6 times higher than
that of prior methods. Our model achieves SOTA performance on
future-trajectory-conditioned semantic occupancy forecasting while being 23x
more computationally efficient (a 28x FPS speedup); and achieves SOTA
performance on semantic occupancy forecasting while being 2x more
computationally efficient (a 1.1x FPS speedup).

</details>


### [131] [Time-variant Image Inpainting via Interactive Distribution Transition Estimation](https://arxiv.org/abs/2506.23461)
*Yun Xing,Qing Guo,Xiaoguang Li,Yihao Huang,Xiaofeng Cao,Di Lin,Ivor Tsang,Lei Ma*

Main category: cs.CV

TL;DR: 本文提出了一项新任务——时间变异的图像修复（TAMP），即通过参考包含时间变异的参考图像来恢复受损目标图像，开发了名为InDiTE-Diff的方法，并构建了TAMP-Street数据集。实验表明该方法显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 解决带有时间变化的参考图像导致现有图像修复方法性能不佳的问题，旨在开发一种能应对显著内容差异和参考图像损坏的解决方案。

Method: 提出了一种全新的交互分布过渡估计模块（InDiTE），并结合SOTA扩散模型进行潜在的交叉参考修复，命名为InDiTE-Diff。此外还构建了TAMP-Street数据集用于验证。

Result: 实验表明，所提方法在TAMP-Street数据集的两种设置下均优于当前SOTA参考引导图像修复方法。

Conclusion: 本文提出了针对时间变异图像修复的创新方法，并对其有效性进行了验证，为图像修复领域提供了新的解决思路。

Abstract: In this work, we focus on a novel and practical task, i.e., Time-vAriant
iMage inPainting (TAMP). The aim of TAMP is to restore a damaged target image
by leveraging the complementary information from a reference image, where both
images captured the same scene but with a significant time gap in between,
i.e., time-variant images. Different from conventional reference-guided image
inpainting, the reference image under TAMP setup presents significant content
distinction to the target image and potentially also suffers from damages. Such
an application frequently happens in our daily lives to restore a damaged image
by referring to another reference image, where there is no guarantee of the
reference image's source and quality. In particular, our study finds that even
state-of-the-art (SOTA) reference-guided image inpainting methods fail to
achieve plausible results due to the chaotic image complementation. To address
such an ill-posed problem, we propose a novel Interactive Distribution
Transition Estimation (InDiTE) module which interactively complements the
time-variant images with adaptive semantics thus facilitate the restoration of
damaged regions. To further boost the performance, we propose our TAMP
solution, namely Interactive Distribution Transition Estimation-driven
Diffusion (InDiTE-Diff), which integrates InDiTE with SOTA diffusion model and
conducts latent cross-reference during sampling. Moreover, considering the lack
of benchmarks for TAMP task, we newly assembled a dataset, i.e., TAMP-Street,
based on existing image and mask datasets. We conduct experiments on the
TAMP-Street datasets under two different time-variant image inpainting
settings, which show our method consistently outperform SOTA reference-guided
image inpainting methods for solving TAMP.

</details>


### [132] [PathDiff: Histopathology Image Synthesis with Unpaired Text and Mask Conditions](https://arxiv.org/abs/2506.23440)
*Mahesh Bhosale,Abdul Wasi,Yuanhao Zhai,Yunjie Tian,Samuel Border,Nan Xi,Pinaki Sarder,Junsong Yuan,David Doermann,Xuan Gong*

Main category: cs.CV

TL;DR: PathDiff是一种扩散框架，通过整合语义文本和空间结构掩码，生成高质量的病理图像。


<details>
  <summary>Details</summary>
Motivation: 现有病理图像生成面临数据稀缺且缺乏成对的文本与掩码数据，限制了语义与空间细节的联合利用。

Method: 提出PathDiff框架，整合未配对的文本和掩码数据到统一条件空间中，实现对图像语义和空间结构的精确控制。

Result: PathDiff提升了图像质量、文本与图像的匹配度及忠实度，同时改进了下游任务的数据增强效果。

Conclusion: PathDiff在生成病理图像的相似度和精度上优于现有方法，并拓展了数据生成的可能性。

Abstract: Diffusion-based generative models have shown promise in synthesizing
histopathology images to address data scarcity caused by privacy constraints.
Diagnostic text reports provide high-level semantic descriptions, and masks
offer fine-grained spatial structures essential for representing distinct
morphological regions. However, public datasets lack paired text and mask data
for the same histopathological images, limiting their joint use in image
generation. This constraint restricts the ability to fully exploit the benefits
of combining both modalities for enhanced control over semantics and spatial
details. To overcome this, we propose PathDiff, a diffusion framework that
effectively learns from unpaired mask-text data by integrating both modalities
into a unified conditioning space. PathDiff allows precise control over
structural and contextual features, generating high-quality, semantically
accurate images. PathDiff also improves image fidelity, text-image alignment,
and faithfulness, enhancing data augmentation for downstream tasks like nuclei
segmentation and classification. Extensive experiments demonstrate its
superiority over existing methods.

</details>


### [133] [Contrastive Learning with Diffusion Features for Weakly Supervised Medical Image Segmentation](https://arxiv.org/abs/2506.23460)
*Dewen Zeng,Xinrong Hu,Yu-Jen Chen,Yawen Wu,Xiaowei Xu,Yiyu Shi*

Main category: cs.CV

TL;DR: 提出了一种名为CLDF的新方法，结合了对比学习与扩散模型的特征，解决了传统CAM方法在弱监督语义分割中定位不精确的问题，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 传统CAM方法在弱监督语义分割任务中难以克服部分激活和不精确边界问题；而基于扩散模型的生成方法尽管强大，但易受背景噪声干扰，需进一步提升性能。

Method: 提出了一种结合扩散模型特征和对比学习的CLDF方法，利用CDM生成的梯度图与CAM结合，标注前景与背景像素，通过训练像素解码器提升分割精度。

Result: 在四个分割任务上的实验结果表明，该方法在两个公共医疗数据集上显著优于现有基线。

Conclusion: CLDF通过对比学习和融合扩散模型特征，克服了背景噪声影响和传统方法的不足，在多个任务中取得了突破性提升，具有实用性与创新性。

Abstract: Weakly supervised semantic segmentation (WSSS) methods using class labels
often rely on class activation maps (CAMs) to localize objects. However,
traditional CAM-based methods struggle with partial activations and imprecise
object boundaries due to optimization discrepancies between classification and
segmentation. Recently, the conditional diffusion model (CDM) has been used as
an alternative for generating segmentation masks in WSSS, leveraging its strong
image generation capabilities tailored to specific class distributions. By
modifying or perturbing the condition during diffusion sampling, the related
objects can be highlighted in the generated images. Yet, the saliency maps
generated by CDMs are prone to noise from background alterations during reverse
diffusion. To alleviate the problem, we introduce Contrastive Learning with
Diffusion Features (CLDF), a novel method that uses contrastive learning to
train a pixel decoder to map the diffusion features from a frozen CDM to a
low-dimensional embedding space for segmentation. Specifically, we integrate
gradient maps generated from CDM external classifier with CAMs to identify
foreground and background pixels with fewer false positives/negatives for
contrastive learning, enabling robust pixel embedding learning. Experimental
results on four segmentation tasks from two public medical datasets demonstrate
that our method significantly outperforms existing baselines.

</details>


### [134] [Sanitizing Manufacturing Dataset Labels Using Vision-Language Models](https://arxiv.org/abs/2506.23465)
*Nazanin Mahjourian,Vinh Nguyen*

Main category: cs.CV

TL;DR: 本文介绍了用于制造业图像数据集的标签清理和细化的VLSR框架，通过嵌入图像和文本标签并计算相似性，提升数据集质量以改进机器学习模型性能。


<details>
  <summary>Details</summary>
Motivation: 在制造业中，数据集标签的质量往往受到噪声、不一致和错误的影响，而高质量标签的获取成本昂贵且耗时，需开发改进标签质量的工具。

Method: 提出使用基于CLIP模型的跨模态嵌入方法，通过计算图像和文本标签间的余弦相似性完成标签清理和聚类，将标签分为语义一致的组。

Result: 使用Factorynet数据集验证，实验结果表明方法能有效识别问题标签并提升标签一致性，同时通过聚类显著减少标签词汇表规模。

Conclusion: VLSR框架在无需大量人工干预的情况下提高了工业数据集的标签质量，为训练鲁棒的工业机器学习模型提供了支持。

Abstract: The success of machine learning models in industrial applications is heavily
dependent on the quality of the datasets used to train the models. However,
large-scale datasets, specially those constructed from crowd-sourcing and
web-scraping, often suffer from label noise, inconsistencies, and errors. This
problem is particularly pronounced in manufacturing domains, where obtaining
high-quality labels is costly and time-consuming. This paper introduces
Vision-Language Sanitization and Refinement (VLSR), which is a
vision-language-based framework for label sanitization and refinement in
multi-label manufacturing image datasets. This method embeds both images and
their associated textual labels into a shared semantic space leveraging the
CLIP vision-language model. Then two key tasks are addressed in this process by
computing the cosine similarity between embeddings. First, label sanitization
is performed to identify irrelevant, misspelled, or semantically weak labels,
and surface the most semantically aligned label for each image by comparing
image-label pairs using cosine similarity between image and label embeddings.
Second, the method applies density-based clustering on text embeddings,
followed by iterative cluster merging, to group semantically similar labels
into unified label groups. The Factorynet dataset, which includes noisy labels
from both human annotations and web-scraped sources, is employed to evaluate
the effectiveness of the proposed framework. Experimental results demonstrate
that the VLSR framework successfully identifies problematic labels and improves
label consistency. This method enables a significant reduction in label
vocabulary through clustering, which ultimately enhances the dataset's quality
for training robust machine learning models in industrial applications with
minimal human intervention.

</details>


### [135] [Qwen-GUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding](https://arxiv.org/abs/2506.23491)
*ZongHan Hsieh,Tzer-Jen Wei*

Main category: cs.CV

TL;DR: Qwen-GUI-3B 是一个轻量级视觉语言模型，专注于用户界面定位任务，性能接近大规模模型，可在单个 GPU 上训练。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模视觉语言模型在计算成本和硬件需求上的局限性，同时提升用户界面定位任务的模型性能。

Method: 提出了跨平台、高分辨率的多源数据集结合策略；采用两阶段微调技术，先进行跨平台训练再针对高分辨率数据微调；并通过数据削减策略提升数据多样性和减少冗余。

Result: 在 ScreenSpot、ScreenSpot-v2 等基准上取得了 84.9% 和 86.4% 的准确率，超越了同类小于 4B 参数模型的表现。

Conclusion: Qwen-GUI-3B 在用户界面定位任务中表现出色，与体积更大的模型相比具备竞争力，同时兼具高训练效率，为领域相关研究提供了新的可能性。

Abstract: This paper introduces Qwen-GUI-3B, a lightweight Vision-Language Model (VLM)
specifically designed for Graphical User Interface grounding tasks, achieving
performance competitive with significantly larger models. Unlike large-scale
VLMs (>7B parameters) that are computationally intensive and impractical for
consumer-grade hardware, Qwen-GUI-3B delivers strong grounding accuracy while
being fully trainable on a single GPU (RTX 4090). The model incorporates
several key innovations: (i) combine cross-platform, multi-resolution dataset
of 24K examples from diverse sources including mobile, desktop, and web GUI
screenshots to effectively address data scarcity in high-resolution desktop
environments; (ii) a two-stage fine-tuning strategy, where initial
cross-platform training establishes robust GUI understanding, followed by
specialized fine-tuning on high-resolution data to significantly enhance model
adaptability; and (iii) data curation and redundancy reduction strategies,
demonstrating that randomly sampling a smaller subset with reduced redundancy
achieves performance comparable to larger datasets, emphasizing data diversity
over sheer volume. Empirical evaluation on standard GUI grounding
benchmarks-including ScreenSpot, ScreenSpot-v2, and the challenging
ScreenSpot-Pro, highlights Qwen-GUI-3B's exceptional accuracy, achieving 84.9%
on ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior models under 4B
parameters. Ablation studies validate the critical role of balanced sampling
and two-stage fine-tuning in enhancing robustness, particularly in
high-resolution desktop scenarios. The Qwen-GUI-3B is available at:
https://github.com/Han1018/Qwen-GUI-3B

</details>


### [136] [AdFair-CLIP: Adversarial Fair Contrastive Language-Image Pre-training for Chest X-rays](https://arxiv.org/abs/2506.23467)
*Chenlang Yi,Zizhan Xiong,Qi Qi,Xiyuan Wei,Girish Bathla,Ching-Long Lin,Bobak Jack Mortazavi,Tianbao Yang*

Main category: cs.CV

TL;DR: 本文提出了AdFair-CLIP框架，通过对CLIP模型进行对抗性特征干预以弱化敏感属性，从而提升医疗诊断领域的公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有CLIP模型在医疗图像分类中表现出色，但存在对种族和性别等敏感属性的偏见问题，这对诊断结果以及少数群体的可靠性带来了负面影响。

Method: 提出AdFair-CLIP框架，通过对抗性特征干预的方法抑制敏感属性，以减弱虚假关联并提高预测的公平性。

Result: 通过胸部X光（CXR）数据集的实验验证，AdFair-CLIP显著提升了公平性和诊断准确性，并在零样本和少样本场景中保持了良好的泛化能力。

Conclusion: AdFair-CLIP设置了CLIP医疗诊断模型在公平性学习中的新基准，特别是在胸部X光分析中展现了有效性。

Abstract: Contrastive Language-Image Pre-training (CLIP) models have demonstrated
superior performance across various visual tasks including medical image
classification. However, fairness concerns, including demographic biases, have
received limited attention for CLIP models. This oversight leads to critical
issues, particularly those related to race and gender, resulting in disparities
in diagnostic outcomes and reduced reliability for underrepresented groups. To
address these challenges, we introduce AdFair-CLIP, a novel framework employing
adversarial feature intervention to suppress sensitive attributes, thereby
mitigating spurious correlations and improving prediction fairness. We conduct
comprehensive experiments on chest X-ray (CXR) datasets, and show that
AdFair-CLIP significantly enhances both fairness and diagnostic accuracy, while
maintaining robust generalization in zero-shot and few-shot scenarios. These
results establish new benchmarks for fairness-aware learning in CLIP-based
medical diagnostic models, particularly for CXR analysis.

</details>


### [137] [NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments](https://arxiv.org/abs/2506.23468)
*Xuan Yao,Junyu Gao,Changsheng Xu*

Main category: cs.CV

TL;DR: 提出了NavMorph框架，通过自我演进的世界模型和情境演化记忆增强环境理解及决策能力，在VLN-CE任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法在未见环境和导航过程中的动态变化适应性方面存在不足，启发于人类认知，作者希望通过改进环境理解和决策来提升导航能力。

Method: 通过引入NavMorph框架，使用紧凑的潜在表示建模环境动态，集成了情境演化记忆以增强环境上下文信息的利用，并支持在线自适应规划和策略优化。

Result: 实验表明，NavMorph在多个VLN-CE基准测试上取得了显著的性能提升。

Conclusion: NavMorph框架可以提升智能体在连续视觉语言导航中的适应性和表现，为复杂环境中的导航任务提供了新方法。

Abstract: Vision-and-Language Navigation in Continuous Environments (VLN-CE) requires
agents to execute sequential navigation actions in complex environments guided
by natural language instructions. Current approaches often struggle with
generalizing to novel environments and adapting to ongoing changes during
navigation. Inspired by human cognition, we present NavMorph, a self-evolving
world model framework that enhances environmental understanding and
decision-making in VLN-CE tasks. NavMorph employs compact latent
representations to model environmental dynamics, equipping agents with
foresight for adaptive planning and policy refinement. By integrating a novel
Contextual Evolution Memory, NavMorph leverages scene-contextual information to
support effective navigation while maintaining online adaptability. Extensive
experiments demonstrate that our method achieves notable performance
improvements on popular VLN-CE benchmarks. Code is available at
\href{https://github.com/Feliciaxyao/NavMorph}{this https URL}.

</details>


### [138] [Interactive Interface For Semantic Segmentation Dataset Synthesis](https://arxiv.org/abs/2506.23470)
*Ngoc-Do Tran,Minh-Tuan Huynh,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: 本论文提出SynthLab，一个模块化视觉数据合成平台，用于语义分割等任务的数据集生成，降低了资源和隐私问题影响。


<details>
  <summary>Details</summary>
Motivation: 应对高质量语义分割数据集创建中资源密集和隐私问题的挑战。

Method: 设计了SynthLab，一个模块化、用户友好的平台，支持视觉数据合成，通过模块化结构和直观界面提供灵活性与易用性。

Result: 通过面向不同背景用户的研究表明，系统在可用性和易操作性上表现卓越，能辅助低技术背景用户开展实际应用。

Conclusion: SynthLab提高了视觉数据合成效率与灵活性，降低技术门槛，为非技术用户带来便利。

Abstract: The rapid advancement of AI and computer vision has significantly increased
the demand for high-quality annotated datasets, particularly for semantic
segmentation. However, creating such datasets is resource-intensive, requiring
substantial time, labor, and financial investment, and often raises privacy
concerns due to the use of real-world data. To mitigate these challenges, we
present SynthLab, consisting of a modular platform for visual data synthesis
and a user-friendly interface. The modular architecture of SynthLab enables
easy maintenance, scalability with centralized updates, and seamless
integration of new features. Each module handles distinct aspects of computer
vision tasks, enhancing flexibility and adaptability. Meanwhile, its
interactive, user-friendly interface allows users to quickly customize their
data pipelines through drag-and-drop actions. Extensive user studies involving
a diverse range of users across different ages, professions, and expertise
levels, have demonstrated flexible usage, and high accessibility of SynthLab,
enabling users without deep technical expertise to harness AI for real-world
applications.

</details>


### [139] [When Test-Time Adaptation Meets Self-Supervised Models](https://arxiv.org/abs/2506.23529)
*Jisu Han,Jihee Park,Dongyoon Han,Wonjun Hwang*

Main category: cs.CV

TL;DR: 本研究探讨了无需源预训练下的测试时间适应（TTA），提出了一种结合SSL和TTA的方法，有效提升了自监督模型的适应性能。


<details>
  <summary>Details</summary>
Motivation: 当前的TTA方法依赖源预训练模型效果，本研究旨在探索是否能在无需源预训练的情况下，使自监督学习的模型通过TTA不断提升表现。

Method: 提出一种自监督的TTA协议，并设计了结合SSL和TTA的协作学习框架，利用对比学习与知识蒸馏实现表示逐步优化。

Result: 在DINO、MoCo和iBOT等自监督模型以及多个TTA基准上验证了方法的有效性，实现了无需源预训练的优异性能。

Conclusion: 提出的方法在无需依赖源预训练模型的情况下，有效提升了自监督模型在测试时间的适应能力，具有潜在应用前景。

Abstract: Training on test-time data enables deep learning models to adapt to dynamic
environmental changes, enhancing their practical applicability. Online
adaptation from source to target domains is promising but it remains highly
reliant on the performance of source pretrained model. In this paper, we
investigate whether test-time adaptation (TTA) methods can continuously improve
models trained via self-supervised learning (SSL) without relying on source
pretraining. We introduce a self-supervised TTA protocol after observing that
existing TTA approaches struggle when directly applied to self-supervised
models with low accuracy on the source domain. Furthermore, we propose a
collaborative learning framework that integrates SSL and TTA models, leveraging
contrastive learning and knowledge distillation for stepwise representation
refinement. We validate our method on diverse self-supervised models, including
DINO, MoCo, and iBOT, across TTA benchmarks. Extensive experiments validate the
effectiveness of our approach in SSL, showing that it achieves competitive
performance even without source pretraining.

</details>


### [140] [GeoCD: A Differential Local Approximation for Geodesic Chamfer Distance](https://arxiv.org/abs/2506.23478)
*Pedro Alonso,Tianrui Li,Chongshou Li*

Main category: cs.CV

TL;DR: 文章提出了GeoCD，一种改进的Chamfer Distance（CD）度量法，旨在解决CD无法反映3D形状内在几何的问题。


<details>
  <summary>Details</summary>
Motivation: 传统CD仅依赖于欧氏距离，无法有效捕捉点云的拓扑结构和3D形状的本质几何特性。

Method: 设计了一种名为GeoCD的拓扑感知方法，该方法基于可微分的拟合测地距离，替代传统CD来衡量3D点云间的相似性。

Result: 实验表明，GeoCD在多种架构和数据集上均能提升重建质量，仅通过单次GeoCD微调即在多项评估指标上取得显著改进。

Conclusion: GeoCD克服了标准CD的主要局限性，是用于3D点云学习的更优选择，在性能和几何捕捉上都表现出色。

Abstract: Chamfer Distance (CD) is a widely adopted metric in 3D point cloud learning
due to its simplicity and efficiency. However, it suffers from a fundamental
limitation: it relies solely on Euclidean distances, which often fail to
capture the intrinsic geometry of 3D shapes. To address this limitation, we
propose GeoCD, a topology-aware and fully differentiable approximation of
geodesic distance designed to serve as a metric for 3D point cloud learning.
Our experiments show that GeoCD consistently improves reconstruction quality
over standard CD across various architectures and datasets. We demonstrate this
by fine-tuning several models, initially trained with standard CD, using GeoCD.
Remarkably, fine-tuning for a single epoch with GeoCD yields significant gains
across multiple evaluation metrics.

</details>


### [141] [GViT: Representing Images as Gaussians for Visual Recognition](https://arxiv.org/abs/2506.23532)
*Jefferson Hernandez,Ruozhen He,Guha Balakrishnan,Alexander C. Berg,Vicente Ordonez*

Main category: cs.CV

TL;DR: 本文提出了一个名为GVIT的分类框架，采用可学习的二维高斯分布而非传统的像素或切片网格处理输入表示。


<details>
  <summary>Details</summary>
Motivation: 旨在通过二维高斯输入表示提升ViT分类器的性能，同时优化这些高斯分布参数，以突出具有分类意义的图像区域。

Method: 以二维高斯分布代替传统输入表示，并使用ViT分类器进行训练。高斯位置、尺度、方向等参数与分类器联合优化，同时通过梯度引导高斯分布靠近分类显著区域，并结合可微渲染以优化图像重建损失。

Result: 在Imagenet-1k数据集上，使用ViT-B架构达到了76.9%的top-1准确率，与传统切片输入的ViT性能相当。

Conclusion: 通过采用二维高斯分布表示和GVIT指导，这种新框架实现了与传统ViT类似的分类性能，同时提出了一种基于高斯分布的新输入表征方式。

Abstract: We introduce GVIT, a classification framework that abandons conventional
pixel or patch grid input representations in favor of a compact set of
learnable 2D Gaussians. Each image is encoded as a few hundred Gaussians whose
positions, scales, orientations, colors, and opacities are optimized jointly
with a ViT classifier trained on top of these representations. We reuse the
classifier gradients as constructive guidance, steering the Gaussians toward
class-salient regions while a differentiable renderer optimizes an image
reconstruction loss. We demonstrate that by 2D Gaussian input representations
coupled with our GVIT guidance, using a relatively standard ViT architecture,
closely matches the performance of a traditional patch-based ViT, reaching a
76.9% top-1 accuracy on Imagenet-1k using a ViT-B architecture.

</details>


### [142] [Instant GaussianImage: A Generalizable and Self-Adaptive Image Representation via 2D Gaussian Splatting](https://arxiv.org/abs/2506.23479)
*Zhaojie Zeng,Yuesong Wang,Chao Yang,Tao Guan,Lili Ju*

Main category: cs.CV

TL;DR: 本文提出了一种基于2D高斯散点的通用可自适应图像表示框架，通过快速生成粗高斯表示并进行少量微调，实现了与GaussianImage相当的渲染质量，同时显著减少了训练时间。


<details>
  <summary>Details</summary>
Motivation: 解决GaussianImage训练速度慢和固定高斯点数量不适应信息熵变化的问题。

Method: 使用网络快速生成粗略高斯表示，通过少量微调提升渲染质量，并根据图像复杂度动态调整高斯点数量以提高灵活性与效率。

Result: 在DIV2K和Kodak数据集上，方法在迭代次数更少和训练时间更短的情况下，达到甚至超越GaussianImage的渲染性能。特别是训练时间减少至原有的十分之一。

Conclusion: 提出的方法在减少训练时间、提升灵活性以及高效渲染性能方面表现优越，为图像表示提供了更实用的解决方案。

Abstract: Implicit Neural Representation (INR) has demonstrated remarkable advances in
the field of image representation but demands substantial GPU resources.
GaussianImage recently pioneered the use of Gaussian Splatting to mitigate this
cost, however, the slow training process limits its practicality, and the fixed
number of Gaussians per image limits its adaptability to varying information
entropy. To address these issues, we propose in this paper a generalizable and
self-adaptive image representation framework based on 2D Gaussian Splatting.
Our method employs a network to quickly generate a coarse Gaussian
representation, followed by minimal fine-tuning steps, achieving comparable
rendering quality of GaussianImage while significantly reducing training time.
Moreover, our approach dynamically adjusts the number of Gaussian points based
on image complexity to further enhance flexibility and efficiency in practice.
Experiments on DIV2K and Kodak datasets show that our method matches or exceeds
GaussianImage's rendering performance with far fewer iterations and shorter
training times. Specifically, our method reduces the training time by up to one
order of magnitude while achieving superior rendering performance with the same
number of Gaussians.

</details>


### [143] [Uncertainty-aware Diffusion and Reinforcement Learning for Joint Plane Localization and Anomaly Diagnosis in 3D Ultrasound](https://arxiv.org/abs/2506.23538)
*Yuhao Huang,Yueyue Xu,Haoran Dou,Jiaxiao Deng,Xin Yang,Hongyu Zheng,Dong Ni*

Main category: cs.CV

TL;DR: 提出了一种智能系统，用于自动定位平面和诊断先天性子宫异常(CUAs)。


<details>
  <summary>Details</summary>
Motivation: 提高CUAs的诊断准确性，相较于传统的2D超声，3D超声可更清晰地显示子宫形态。本文旨在自动化平面定位和诊断过程。

Method: 引入三点创新：1）基于局部和全局指导的去噪扩散模型；2）基于强化学习的框架提取关键切片；3）文本驱动的不确定性建模用于粗略预测和分类调整。

Result: 在一大规模3D子宫超声数据集上验证了方法的有效性，主要体现在平面定位和诊断方面效果显著。

Conclusion: 所提方法显著提升CUAs的诊断性能，通过代码开源推动相关研究和应用。

Abstract: Congenital uterine anomalies (CUAs) can lead to infertility, miscarriage,
preterm birth, and an increased risk of pregnancy complications. Compared to
traditional 2D ultrasound (US), 3D US can reconstruct the coronal plane,
providing a clear visualization of the uterine morphology for assessing CUAs
accurately. In this paper, we propose an intelligent system for simultaneous
automated plane localization and CUA diagnosis. Our highlights are: 1) we
develop a denoising diffusion model with local (plane) and global (volume/text)
guidance, using an adaptive weighting strategy to optimize attention allocation
to different conditions; 2) we introduce a reinforcement learning-based
framework with unsupervised rewards to extract the key slice summary from
redundant sequences, fully integrating information across multiple planes to
reduce learning difficulty; 3) we provide text-driven uncertainty modeling for
coarse prediction, and leverage it to adjust the classification probability for
overall performance improvement. Extensive experiments on a large 3D uterine US
dataset show the efficacy of our method, in terms of plane localization and CUA
diagnosis. Code is available at https://github.com/yuhoo0302/CUA-US.

</details>


### [144] [Evaluation of Geolocation Capabilities of Multimodal Large Language Models and Analysis of Associated Privacy Risks](https://arxiv.org/abs/2506.23481)
*Xian Zhang,Xiang Cheng*

Main category: cs.CV

TL;DR: 该论文分析了多模态大语言模型（MLLMs）在图像地理定位任务中的能力及其隐私和伦理问题，并通过实验揭示其能够在 1 公里范围内以 49% 的准确率定位街景图像来源。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型的快速发展，其推理能力得到了显著增强，但这也带来了隐私和伦理问题，尤其是在基于图像内容推断地理位置方面。

Method: 系统性综述现有基于MLLMs的地理定位技术，并评估最新视觉推理模型在地理定位任务中的表现，特别是街景图片来源的识别。

Result: 实验表明，最新的视觉大模型可以通过图像中的精细地理线索，在 1 公里范围内以 49% 的准确率定位街景图像的来源。

Conclusion: 总结了影响地理定位的关键视觉要素，包括文本、建筑风格和环境特征，并探讨了与MLLMs地理定位相关的隐私隐患及技术和政策层面的应对措施。

Abstract: Objectives: The rapid advancement of Multimodal Large Language Models (MLLMs)
has significantly enhanced their reasoning capabilities, enabling a wide range
of intelligent applications. However, these advancements also raise critical
concerns regarding privacy and ethics. MLLMs are now capable of inferring the
geographic location of images -- such as those shared on social media or
captured from street views -- based solely on visual content, thereby posing
serious risks of privacy invasion, including doxxing, surveillance, and other
security threats.
  Methods: This study provides a comprehensive analysis of existing geolocation
techniques based on MLLMs. It systematically reviews relevant litera-ture and
evaluates the performance of state-of-the-art visual reasoning models on
geolocation tasks, particularly in identifying the origins of street view
imagery.
  Results: Empirical evaluation reveals that the most advanced visual large
models can successfully localize the origin of street-level imagery with up to
$49\%$ accuracy within a 1-kilometer radius. This performance underscores the
models' powerful capacity to extract and utilize fine-grained geographic cues
from visual data.
  Conclusions: Building on these findings, the study identifies key visual
elements that contribute to suc-cessful geolocation, such as text,
architectural styles, and environmental features. Furthermore, it discusses the
potential privacy implications associated with MLLM-enabled geolocation and
discuss several technical and policy-based coun-termeasures to mitigate
associated risks. Our code and dataset are available at
https://github.com/zxyl1003/MLLM-Geolocation-Evaluation.

</details>


### [145] [PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection](https://arxiv.org/abs/2506.23581)
*Xiao Li,Yiming Zhu,Yifan Huang,Wei Zhang,Yingzhe He,Jie Shi,Xiaolin Hu*

Main category: cs.CV

TL;DR: 本文提出了一种名为PBCAT的防御方法，通过联合优化局部梯度引导的对抗性补丁和全图范围内的微小对抗扰动，显著增强了目标检测模型针对各种现实可实现攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 目前针对目标检测模型的对抗训练研究较少，尤其是对抗可实现的现实攻击手段，如对抗性贴片和对抗性纹理等，因此需要一种统一的对策来提高模型的安全性。

Method: 提出了PBCAT方法，该方法整合了局部小范围对抗性贴片攻击和全局微小扰动攻击，并综合训练模型以提升其对多种现实可实现攻击的防御能力。

Result: 实验表明，与现有的防御方法相比，PBCAT在对抗多种现实可实现攻击时表现出显著的鲁棒性提升，包括在对抗性纹理攻击中的检测准确率提高了29.7%。

Conclusion: PBCAT方法通过全局与局部攻击的联合对抗训练，为目标检测模型提供了更强的鲁棒性，是一种有效防御现实可实现攻击的新方案。

Abstract: Object detection plays a crucial role in many security-sensitive
applications. However, several recent studies have shown that object detectors
can be easily fooled by physically realizable attacks, \eg, adversarial patches
and recent adversarial textures, which pose realistic and urgent threats.
Adversarial Training (AT) has been recognized as the most effective defense
against adversarial attacks. While AT has been extensively studied in the
$l_\infty$ attack settings on classification models, AT against physically
realizable attacks on object detectors has received limited exploration. Early
attempts are only performed to defend against adversarial patches, leaving AT
against a wider range of physically realizable attacks under-explored. In this
work, we consider defending against various physically realizable attacks with
a unified AT method. We propose PBCAT, a novel Patch-Based Composite
Adversarial Training strategy. PBCAT optimizes the model by incorporating the
combination of small-area gradient-guided adversarial patches and imperceptible
global adversarial perturbations covering the entire image. With these designs,
PBCAT has the potential to defend against not only adversarial patches but also
unseen physically realizable attacks such as adversarial textures. Extensive
experiments in multiple settings demonstrated that PBCAT significantly improved
robustness against various physically realizable attacks over state-of-the-art
defense methods. Notably, it improved the detection accuracy by 29.7\% over
previous defense methods under one recent adversarial texture attack.

</details>


### [146] [MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting](https://arxiv.org/abs/2506.23482)
*Jun Huang,Ting Liu,Yihang Wu,Xiaochao Qu,Luoqi Liu,Xiaolin Hu*

Main category: cs.CV

TL;DR: 提出了一种名为MTADiffusion的掩码文本对齐扩散模型，针对图像修复领域，解决语义失配、结构失真和风格不一致等问题；并通过新数据集（MTADataset）和多任务训练策略优化结构和风格。


<details>
  <summary>Details</summary>
Motivation: 现有图像修复方法存在语义不匹配、结构失真和风格不一致的问题，迫切需要改进模型以提升修复质量。

Method: 提出MTADiffusion模型，结合自动描述掩码的MTAPipeline，构建包含500万图像和2500万掩码-文本对的MTADataset；采用多任务训练结合边缘预测与修复；引入基于预训练VGG和Gram矩阵的风格一致性损失函数。

Result: MTADiffusion在BrushBench和EditBench数据集上表现出优于现有方法的最新性能。

Conclusion: MTADiffusion通过创新性技术与结合多任务训练及风格损失，成功解决图像修复中的关键问题，并显著提升了模型效果。

Abstract: Advancements in generative models have enabled image inpainting models to
generate content within specific regions of an image based on provided prompts
and masks. However, existing inpainting methods often suffer from problems such
as semantic misalignment, structural distortion, and style inconsistency. In
this work, we present MTADiffusion, a Mask-Text Alignment diffusion model
designed for object inpainting. To enhance the semantic capabilities of the
inpainting model, we introduce MTAPipeline, an automatic solution for
annotating masks with detailed descriptions. Based on the MTAPipeline, we
construct a new MTADataset comprising 5 million images and 25 million mask-text
pairs. Furthermore, we propose a multi-task training strategy that integrates
both inpainting and edge prediction tasks to improve structural stability. To
promote style consistency, we present a novel inpainting style-consistency loss
using a pre-trained VGG network and the Gram matrix. Comprehensive evaluations
on BrushBench and EditBench demonstrate that MTADiffusion achieves
state-of-the-art performance compared to other methods.

</details>


### [147] [Metadata, Wavelet, and Time Aware Diffusion Models for Satellite Image Super Resolution](https://arxiv.org/abs/2506.23566)
*Luigi Sigillo,Renato Giamba,Danilo Comminiello*

Main category: cs.CV

TL;DR: 提出一种结合潜在扩散模型和小波变换的卫星图像超分辨率框架MWT-Diff，能从低分辨率输入重构高分辨率图像，效果优于当前方法。


<details>
  <summary>Details</summary>
Motivation: 现有卫星影像获取受限于传感器的空间和时间分辨率以及高成本，无法满足环境监测、灾害响应和农业管理等需要高分辨率数据的应用需求。

Method: 提出一种新的MWT-Diff框架，通过结合小波变换及潜在扩散模型进行卫星图像超分辨。框架核心为一个元数据、小波及时间感知的编码器（MWT-Encoder），作为嵌入生成器，捕捉多尺度频率信息和时间关系，并引导平滑的模型扩散动态完成图像重建。

Result: 在多个数据集上的对比分析表明，MWT-Diff在感知质量指标（如FID、LPIPS）方面表现优于近期的其他方法。

Conclusion: MWT-Diff能够有效保留文本纹理、边界不连续性及高频谱分量的空间特性，为细节丰富的遥感分析提供了帮助。其性能验证证明该方法在卫星图像超分辨领域具有潜力。

Abstract: The acquisition of high-resolution satellite imagery is often constrained by
the spatial and temporal limitations of satellite sensors, as well as the high
costs associated with frequent observations. These challenges hinder
applications such as environmental monitoring, disaster response, and
agricultural management, which require fine-grained and high-resolution data.
In this paper, we propose MWT-Diff, an innovative framework for satellite image
super-resolution (SR) that combines latent diffusion models with wavelet
transforms to address these challenges. At the core of the framework is a novel
metadata-, wavelet-, and time-aware encoder (MWT-Encoder), which generates
embeddings that capture metadata attributes, multi-scale frequency information,
and temporal relationships. The embedded feature representations steer the
hierarchical diffusion dynamics, through which the model progressively
reconstructs high-resolution satellite imagery from low-resolution inputs. This
process preserves critical spatial characteristics including textural patterns,
boundary discontinuities, and high-frequency spectral components essential for
detailed remote sensing analysis. The comparative analysis of MWT-Diff across
multiple datasets demonstrated favorable performance compared to recent
approaches, as measured by standard perceptual quality metrics including FID
and LPIPS.

</details>


### [148] [LLM-enhanced Action-aware Multi-modal Prompt Tuning for Image-Text Matching](https://arxiv.org/abs/2506.23502)
*Mengxiao Tian,Xinxiao Wu,Shuo Yang*

Main category: cs.CV

TL;DR: 提出一种通过引入大语言模型增强的动作感知多模态提示调优方法，从而改进了CLIP在动作级别细粒度理解的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于对比视觉语言预训练模型（如CLIP）的图文匹配方法未能很好地理解物体细节和空间关系，尤其缺乏对动作的感知能力。

Method: 通过引入由大语言模型生成的与动作相关的外部知识，设计动作三元组提示和动作状态提示，结合自适应交互模块，聚合基于动作感知提示的注意力视觉特征。

Result: 在两个基准数据集上的实验结果证明了新方法的有效性。

Conclusion: 引入动作感知的多模态提示调优方法提高了CLIP对细粒度信息，特别是动作的理解能力，显著改进了模型性能。

Abstract: Driven by large-scale contrastive vision-language pre-trained models such as
CLIP, recent advancements in the image-text matching task have achieved
remarkable success in representation learning. Due to image-level
visual-language alignment, CLIP falls short in understanding fine-grained
details such as object attributes and spatial relationships between objects.
Recent efforts have attempted to compel CLIP to acquire structured visual
representations by introducing prompt learning to achieve object-level
alignment. While achieving promising results, they still lack the capability to
perceive actions, which are crucial for describing the states or relationships
between objects. Therefore, we propose to endow CLIP with fine-grained
action-level understanding by introducing an LLM-enhanced action-aware
multi-modal prompt-tuning method, incorporating the action-related external
knowledge generated by large language models (LLMs). Specifically, we design an
action triplet prompt and an action state prompt to exploit compositional
semantic knowledge and state-related causal knowledge implicitly stored in
LLMs. Subsequently, we propose an adaptive interaction module to aggregate
attentive visual features conditioned on action-aware prompted knowledge for
establishing discriminative and action-aware visual representations, which
further improves the performance. Comprehensive experimental results on two
benchmark datasets demonstrate the effectiveness of our method.

</details>


### [149] [Brain Tumor Detection through Thermal Imaging and MobileNET](https://arxiv.org/abs/2506.23627)
*Roham Maiti,Debasmita Bhoumik*

Main category: cs.CV

TL;DR: 本研究提出了基于MobileNET模型的脑肿瘤检测方法，以提升效率及准确性，从而改进患者治疗结果。


<details>
  <summary>Details</summary>
Motivation: 传统脑肿瘤检测方法如活检、MRI及CT扫描成本高且需要专业操作，而经典机器学习模型存在计算需求高和数据集要求大的问题，限制了其推广性。

Method: 研究采用MobileNET模型，通过图像处理技术优化脑肿瘤检测流程，提高检测效率和准确性。

Result: 所提出的方法实现了平均98.5%的检测准确率。

Conclusion: 研究证明基于MobileNET的脑肿瘤检测方法在高效性和成本可及性方面具有优势，可为医学图像领域的肿瘤检测提供借鉴。

Abstract: Brain plays a crucial role in regulating body functions and cognitive
processes, with brain tumors posing significant risks to human health. Precise
and prompt detection is a key factor in proper treatment and better patient
outcomes. Traditional methods for detecting brain tumors, that include
biopsies, MRI, and CT scans often face challenges due to their high costs and
the need for specialized medical expertise. Recent developments in machine
learning (ML) and deep learning (DL) has exhibited strong capabilities in
automating the identification and categorization of brain tumors from medical
images, especially MRI scans. However, these classical ML models have
limitations, such as high computational demands, the need for large datasets,
and long training times, which hinder their accessibility and efficiency. Our
research uses MobileNET model for efficient detection of these tumors. The
novelty of this project lies in building an accurate tumor detection model
which use less computing re-sources and runs in less time followed by efficient
decision making through the use of image processing technique for accurate
results. The suggested method attained an average accuracy of 98.5%.

</details>


### [150] [Improve Underwater Object Detection through YOLOv12 Architecture and Physics-informed Augmentation](https://arxiv.org/abs/2506.23505)
*Tinh Nguyen*

Main category: cs.CV

TL;DR: 本研究整合物理增强技术与YOLOv12架构，显著提升了水下低能见度环境中的实时物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决水下光衰减、浑浊和遮挡对物体检测的限制，为自治导航和海洋探索提供更高效的解决方案。

Method: 引入Residual ELAN模块保持结构特征，引入区域注意力减少计算复杂性，同时通过特定领域增强（如模糊处理、遮挡模拟和色彩变换）优化水下光学特性。

Result: 在四种数据集上表现出最先进的性能，其中Brackish数据集实现98.30% mAP和142 FPS的记录，与之前模型相比显著提高遮挡鲁棒性（18.9%）、小目标召回率（22.4%）和检测精度（7.94%）。

Conclusion: 提出了一种精确高效的方法，可广泛应用于环境保护和水下机器人等领域。

Abstract: Underwater object detection is crucial for autonomous navigation,
environmental monitoring, and marine exploration, but it is severely hampered
by light attenuation, turbidity, and occlusion. Current methods balance
accuracy and computational efficiency, but they have trouble deploying in
real-time under low visibility conditions. Through the integration of
physics-informed augmentation techniques with the YOLOv12 architecture, this
study advances underwater detection. With Residual ELAN blocks to preserve
structural features in turbid waters and Area Attention to maintain large
receptive fields for occluded objects while reducing computational complexity.
Underwater optical properties are addressed by domain-specific augmentations
such as turbulence adaptive blurring, biologically grounded occlusion
simulation, and spectral HSV transformations for color distortion. Extensive
tests on four difficult datasets show state-of-the-art performance, with
Brackish data registering 98.30% mAP at 142 FPS. YOLOv12 improves occlusion
robustness by 18.9%, small-object recall by 22.4%, and detection precision by
up to 7.94% compared to previous models. The crucial role of augmentation
strategy is validated by ablation studies. This work offers a precise and
effective solution for conservation and underwater robotics applications.

</details>


### [151] [AI-Generated Lecture Slides for Improving Slide Element Detection and Retrieval](https://arxiv.org/abs/2506.23605)
*Suyash Maniyar,Vishvesh Trivedi,Ajoy Mondal,Anand Mishra,C. V. Jawahar*

Main category: cs.CV

TL;DR: 提出了一种名为SynLecSlideGen的LLM引导合成幻灯片生成管道，以及一个用于评价的手工标注基准集RealSlide，证明合成数据可以提高模型性能，并公开了相关资源。


<details>
  <summary>Details</summary>
Motivation: 解决幻灯片理解任务中手工标注数据困难问题，通过使用合成数据减少对人工标注的依赖。

Method: 提出SynLecSlideGen管道用于生成高质量的合成幻灯片，并创建了RealSlide基准数据集，利用少样本迁移学习评估这些数据的效用。

Result: 实验表明，使用合成幻灯片预训练的模型相比仅利用真实数据训练的模型性能显著提升。

Conclusion: 合成数据能够有效弥补标注幻灯片数据不足的问题，并能显著提高相关任务的性能。

Abstract: Lecture slide element detection and retrieval are key problems in slide
understanding. Training effective models for these tasks often depends on
extensive manual annotation. However, annotating large volumes of lecture
slides for supervised training is labor intensive and requires domain
expertise. To address this, we propose a large language model (LLM)-guided
synthetic lecture slide generation pipeline, SynLecSlideGen, which produces
high-quality, coherent and realistic slides. We also create an evaluation
benchmark, namely RealSlide by manually annotating 1,050 real lecture slides.
To assess the utility of our synthetic slides, we perform few-shot transfer
learning on real data using models pre-trained on them. Experimental results
show that few-shot transfer learning with pretraining on synthetic slides
significantly improves performance compared to training only on real data. This
demonstrates that synthetic data can effectively compensate for limited labeled
lecture slides. The code and resources of our work are publicly available on
our project website: https://synslidegen.github.io/.

</details>


### [152] [On the Domain Robustness of Contrastive Vision-Language Models](https://arxiv.org/abs/2506.23663)
*Mario Koddenbrock,Rudolf Hoffmann,David Brodmann,Erik Rodner*

Main category: cs.CV

TL;DR: 本文提出了Deepbench，一个用于评估视觉语言模型(VLMs)在特定领域中鲁棒性的框架，通过模拟现实的图像扰动评估模型表现。


<details>
  <summary>Details</summary>
Motivation: 当前预训练的大规模模型在现实生活中被广泛应用，但在特定领域环境下效果下降较明显，缺乏相应的鲁棒性评估研究。

Method: 利用大型语言模型(LLM)生成与特定领域相关的图像扰动，评测不同视觉语言模型在六个真实领域的表现，并以此探究它们的领域鲁棒性。

Result: 研究发现，通过Deepbench验证，不同模型和架构的领域鲁棒性存在显著差异。

Conclusion: Deepbench帮助研究人员更深入理解和评估模型在特定领域中的表现，对进一步研究领域相关的鲁棒性评价有重要意义，并已作为开源软件发布。

Abstract: In real-world vision-language applications, practitioners increasingly rely
on large, pretrained foundation models rather than custom-built solutions,
despite limited transparency regarding their training data and processes. While
these models achieve impressive performance on general benchmarks, their
effectiveness can decline notably under specialized domain shifts, such as
unique imaging conditions or environmental variations. In this work, we
introduce Deepbench, a framework designed to assess domain-specific robustness
of vision-language models (VLMs). Deepbench leverages a large language model
(LLM) to generate realistic, context-aware image corruptions tailored to
specific deployment domains without requiring labeled data. We evaluate a range
of contrastive vision-language architectures and architectural variants across
six real-world domains and observe substantial variability in robustness,
highlighting the need for targeted, domain-aware evaluation. Deepbench is
released as open-source software to support further research into domain-aware
robustness assessment.

</details>


### [153] [ViewPoint: Panoramic Video Generation with Pretrained Diffusion Models](https://arxiv.org/abs/2506.23513)
*Zixun Fang,Kai Zhu,Zhiheng Liu,Yu Liu,Wei Zhai,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 本文提出一种新框架，利用预训练的透视视频模型生成高质量的全景视频，解决全景和透视数据间的模态差异问题。


<details>
  <summary>Details</summary>
Motivation: 现存方法难以生成高质量全景视频，因全景数据与透视数据间固有的模态差异，而透视数据占现行扩散模型训练数据的多数。

Method: 设计了一种名为ViewPoint map的新型全景表示，结合Pano-Perspective注意力机制，从预训练的透视模型中获益，同时捕捉全景空间关联。

Result: 实验结果表明，该方法能够生成动态丰富、空间一致性高的全景视频，达到当前最优性能，优于现有方法。

Conclusion: 本文方法通过创新设计的全景表示和注意力机制，有效解决了模态差异问题，实现了高质量全景视频的生成，具有显著的实际应用潜力。

Abstract: Panoramic video generation aims to synthesize 360-degree immersive videos,
holding significant importance in the fields of VR, world models, and spatial
intelligence. Existing works fail to synthesize high-quality panoramic videos
due to the inherent modality gap between panoramic data and perspective data,
which constitutes the majority of the training data for modern diffusion
models. In this paper, we propose a novel framework utilizing pretrained
perspective video models for generating panoramic videos. Specifically, we
design a novel panorama representation named ViewPoint map, which possesses
global spatial continuity and fine-grained visual details simultaneously. With
our proposed Pano-Perspective attention mechanism, the model benefits from
pretrained perspective priors and captures the panoramic spatial correlations
of the ViewPoint map effectively. Extensive experiments demonstrate that our
method can synthesize highly dynamic and spatially consistent panoramic videos,
achieving state-of-the-art performance and surpassing previous methods.

</details>


### [154] [WAVE: Warp-Based View Guidance for Consistent Novel View Synthesis Using a Single Image](https://arxiv.org/abs/2506.23518)
*Jiwoo Park,Tae Eun Choi,Youngjun Jun,Seong Jae Hwang*

Main category: cs.CV

TL;DR: 提出一种通过训练自由方法增强扩散模型的新方法，以实现单张图像生成多视角场景时的视角一致性。


<details>
  <summary>Details</summary>
Motivation: 解决目前扩散模型在生成多视角一致性时存在空间连续性不佳的问题。

Method: 使用基于视角引导的变形，结合自适应注意力操控和噪声重初始化的无训练方法，改进扩散模型，确保视角一致性。

Result: 实验结果证明方法能够在不同的扩散模型中提升视角一致性，并具备广泛适用性。

Conclusion: 提出的方法无需额外模块即可提高扩散模型的多视角一致性，并可广泛应用于不同任务场景。

Abstract: Generating high-quality novel views of a scene from a single image requires
maintaining structural coherence across different views, referred to as view
consistency. While diffusion models have driven advancements in novel view
synthesis, they still struggle to preserve spatial continuity across views.
Diffusion models have been combined with 3D models to address the issue, but
such approaches lack efficiency due to their complex multi-step pipelines. This
paper proposes a novel view-consistent image generation method which utilizes
diffusion models without additional modules. Our key idea is to enhance
diffusion models with a training-free method that enables adaptive attention
manipulation and noise reinitialization by leveraging view-guided warping to
ensure view consistency. Through our comprehensive metric framework suitable
for novel-view datasets, we show that our method improves view consistency
across various diffusion models, demonstrating its broader applicability.

</details>


### [155] [Unified Multimodal Understanding via Byte-Pair Visual Encoding](https://arxiv.org/abs/2506.23639)
*Wanpeng Zhang,Yicheng Feng,Hao Luo,Yijiang Li,Zihao Yue,Sipeng Zheng,Zongqing Lu*

Main category: cs.CV

TL;DR: 提出了一种使用字节对编码视觉令牌以实现多模态统一的框架。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在视觉-语言理解中表现优异，但多模态对齐依然是一个关键挑战。

Method: 采用字节对编码处理视觉令牌，使用优先级引导编码方案结合课程驱动数据训练模型。

Result: 实验表明方法在多种视觉语言任务上表现优异。

Conclusion: 通过减少视觉与文本表征之间的差距，该方法推动了高效多模态基础模型的发展。

Abstract: Multimodal large language models (MLLMs) have made significant progress in
vision-language understanding, yet effectively aligning different modalities
remains a fundamental challenge. We present a framework that unifies multimodal
understanding by applying byte-pair encoding to visual tokens. Unlike
conventional approaches that rely on modality-specific encoders, our method
directly incorporates structural information into visual tokens, mirroring
successful tokenization strategies in text-only language models. We introduce a
priority-guided encoding scheme that considers both frequency and spatial
consistency, coupled with a multi-stage training procedure based on
curriculum-driven data composition. These enhancements enable the transformer
model to better capture cross-modal relationships and reason with visual
information. Comprehensive experiments demonstrate improved performance across
diverse vision-language tasks. By bridging the gap between visual and textual
representations, our approach contributes to the advancement of more capable
and efficient multimodal foundation models.

</details>


### [156] [Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking](https://arxiv.org/abs/2506.23783)
*Shiao Wang,Ju Huang,Qingchuan Ma,Jinfeng Gao,Chunyi Xu,Xiao Wang,Lan Chen,Bo Jiang*

Main category: cs.CV

TL;DR: 提出了基于高效的线性复杂度Mamba网络的新型多模态RGB-Event目标跟踪框架（Mamba-FETrack V2）。


<details>
  <summary>Details</summary>
Motivation: 解决现有多模态跟踪算法中复杂性高、跨模态交互效果有限的问题。

Method: 设计了轻量级Prompt生成器结合共享prompt池，采用Vision Mamba网络的FEMamba骨干架构进行特征提取、交互与融合，最后进行目标定位。

Result: 在多个RGB-Event跟踪基准上（如COESOT、FE108和FELT V2）证明了该方法性能优越且高效。

Conclusion: 该框架既提升了多模态对象跟踪的性能，又降低了计算开销，为相关领域提供了新方法与实践。

Abstract: Combining traditional RGB cameras with bio-inspired event cameras for robust
object tracking has garnered increasing attention in recent years. However,
most existing multimodal tracking algorithms depend heavily on high-complexity
Vision Transformer architectures for feature extraction and fusion across
modalities. This not only leads to substantial computational overhead but also
limits the effectiveness of cross-modal interactions. In this paper, we propose
an efficient RGB-Event object tracking framework based on the linear-complexity
Vision Mamba network, termed Mamba-FETrack V2. Specifically, we first design a
lightweight Prompt Generator that utilizes embedded features from each
modality, together with a shared prompt pool, to dynamically generate
modality-specific learnable prompt vectors. These prompts, along with the
modality-specific embedded features, are then fed into a Vision Mamba-based
FEMamba backbone, which facilitates prompt-guided feature extraction,
cross-modal interaction, and fusion in a unified manner. Finally, the fused
representations are passed to the tracking head for accurate target
localization. Extensive experimental evaluations on multiple RGB-Event tracking
benchmarks, including short-term COESOT dataset and long-term datasets, i.e.,
FE108 and FELT V2, demonstrate the superior performance and efficiency of the
proposed tracking framework. The source code and pre-trained models will be
released on https://github.com/Event-AHU/Mamba_FETrack

</details>


### [157] [From Sight to Insight: Unleashing Eye-Tracking in Weakly Supervised Video Salient Object Detection](https://arxiv.org/abs/2506.23519)
*Qi Qin,Runmin Cong,Gen Zhan,Yiting Liao,Sam Kwong*

Main category: cs.CV

TL;DR: 本文关注于眼动视频显著性预测（VSP）和视频显著目标检测（VSOD）的任务，并提出一种弱监督下结合眼动信息进行视频显著目标检测的新方法。


<details>
  <summary>Details</summary>
Motivation: 传统的VSOD任务中对于显著性目标的检测不够利用眼动注释信息，而眼动注释更容易获取且更符合人眼自然视觉模式。文章旨在结合眼动信息改进VSOD任务。

Method: 提出了位置与语义嵌入（PSE）模块，用于特征学习过程中的位置和语义指导；设计了带语义与局部约束的语义与局部查询（SLQ）竞争模块，用以选择最为匹配的目标查询；采用了一种内部-外部混合对比（IIMC）模型，通过视频内外对比学习提升时空建模能力。

Result: 在五个主流VSOD基准上实验表明，该模型在多项评价指标上优于其他竞争方法。

Conclusion: 本文方法通过结合眼动注释和弱监督学习有效提升了视频显著目标检测的性能。

Abstract: The eye-tracking video saliency prediction (VSP) task and video salient
object detection (VSOD) task both focus on the most attractive objects in video
and show the result in the form of predictive heatmaps and pixel-level saliency
masks, respectively. In practical applications, eye tracker annotations are
more readily obtainable and align closely with the authentic visual patterns of
human eyes. Therefore, this paper aims to introduce fixation information to
assist the detection of video salient objects under weak supervision. On the
one hand, we ponder how to better explore and utilize the information provided
by fixation, and then propose a Position and Semantic Embedding (PSE) module to
provide location and semantic guidance during the feature learning process. On
the other hand, we achieve spatiotemporal feature modeling under weak
supervision from the aspects of feature selection and feature contrast. A
Semantics and Locality Query (SLQ) Competitor with semantic and locality
constraints is designed to effectively select the most matching and accurate
object query for spatiotemporal modeling. In addition, an Intra-Inter Mixed
Contrastive (IIMC) model improves the spatiotemporal modeling capabilities
under weak supervision by forming an intra-video and inter-video contrastive
learning paradigm. Experimental results on five popular VSOD benchmarks
indicate that our model outperforms other competitors on various evaluation
metrics.

</details>


### [158] [VAP-Diffusion: Enriching Descriptions with MLLMs for Enhanced Medical Image Generation](https://arxiv.org/abs/2506.23641)
*Peng Huang,Junhu Fu,Bowen Guo,Zeju Li,Yuanyuan Wang,Yi Guo*

Main category: cs.CV

TL;DR: 提出了一种名为VAP-Diffusion的框架，通过使用多模态大语言模型来增强医疗图像生成的质量与多样性，并在多种数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型往往缺乏丰富的属性信息，难以生成具有特定细节的逼真医疗图像（如皮肤病变图像的形状、大小、纹理和颜色等）。为此，需要探索提升生成图像质量和多样性的新方法。

Method: 设计VAP-Diffusion框架，使用预训练的多模态大语言模型生成医学图像描述，利用链式思维提示生成无幻觉的详细描述，并结合原型条件机制保证生成器对测试时未见组合的描述表现鲁棒性。

Result: 在三种常见医疗影像任务和四个数据集上进行了实验，验证了VAP-Diffusion框架有效提高了生成图像的质量与多样性。

Conclusion: VAP-Diffusion通过结合外部知识和特定机制，实现了更高质量且多样化的医疗图像生成，为医学影像领域的生成模型拓展了新的可能性。

Abstract: As the appearance of medical images is influenced by multiple underlying
factors, generative models require rich attribute information beyond labels to
produce realistic and diverse images. For instance, generating an image of skin
lesion with specific patterns demands descriptions that go beyond diagnosis,
such as shape, size, texture, and color. However, such detailed descriptions
are not always accessible. To address this, we explore a framework, termed
Visual Attribute Prompts (VAP)-Diffusion, to leverage external knowledge from
pre-trained Multi-modal Large Language Models (MLLMs) to improve the quality
and diversity of medical image generation. First, to derive descriptions from
MLLMs without hallucination, we design a series of prompts following
Chain-of-Thoughts for common medical imaging tasks, including dermatologic,
colorectal, and chest X-ray images. Generated descriptions are utilized during
training and stored across different categories. During testing, descriptions
are randomly retrieved from the corresponding category for inference. Moreover,
to make the generator robust to unseen combination of descriptions at the test
time, we propose a Prototype Condition Mechanism that restricts test embeddings
to be similar to those from training. Experiments on three common types of
medical imaging across four datasets verify the effectiveness of VAP-Diffusion.

</details>


### [159] [Lightweight Temporal Transformer Decomposition for Federated Autonomous Driving](https://arxiv.org/abs/2506.23523)
*Tuong Do,Binh X. Nguyen,Quang D. Tran,Erman Tjiputra,Te-Chuan Chiu,Anh Nguyen*

Main category: cs.CV

TL;DR: 针对传统视觉自主驾驶在复杂环境中的局限性，提出一种轻量化时序变换器分解方法，利用时序信息提升驾驶性能，同时降低计算复杂度，实验结果优异。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以应对复杂环境，且高性能方法通常计算资源需求高，不适合联邦学习。

Method: 提出轻量化时序变换器分解，通过分解大注意力矩阵处理序列图像帧和时序转向数据，降低模型复杂性并提升实时性能。

Result: 通过三个数据集的实验验证，方法在性能和实时性方面均优于近期方法，并通过真实机器人实验进一步验证有效性。

Conclusion: 该方法有效结合时序信息，在保证实时性能的同时提升自主驾驶系统的复杂场景适应能力，为实用化应用铺平道路。

Abstract: Traditional vision-based autonomous driving systems often face difficulties
in navigating complex environments when relying solely on single-image inputs.
To overcome this limitation, incorporating temporal data such as past image
frames or steering sequences, has proven effective in enhancing robustness and
adaptability in challenging scenarios. While previous high-performance methods
exist, they often rely on resource-intensive fusion networks, making them
impractical for training and unsuitable for federated learning. To address
these challenges, we propose lightweight temporal transformer decomposition, a
method that processes sequential image frames and temporal steering data by
breaking down large attention maps into smaller matrices. This approach reduces
model complexity, enabling efficient weight updates for convergence and
real-time predictions while leveraging temporal information to enhance
autonomous driving performance. Intensive experiments on three datasets
demonstrate that our method outperforms recent approaches by a clear margin
while achieving real-time performance. Additionally, real robot experiments
further confirm the effectiveness of our method.

</details>


### [160] [Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection](https://arxiv.org/abs/2506.23881)
*Reihaneh Zohrabi,Hosein Hasani,Mahdieh Soleymani Baghshah,Anna Rohrbach,Marcus Rohrbach,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: 提出了一种名为SPROD的新方法，通过原型设计克服伪相关性的问题，有效提升OOD检测的性能。


<details>
  <summary>Details</summary>
Motivation: 现有OOD检测方法容易受到伪相关性的影响，导致模型鲁棒性下降，需开发更稳健的方法。

Method: 提出了SPROD方法，采用基于原型的后处理方式，在无需额外数据或调参的情况下，优化类别原型以减弱伪特征偏差，适用于各种混合网络架构和OOD检测场景。

Result: SPROD在多个具有挑战性的OOD数据集（如CelebA, Waterbirds, UrbanCars等）中表现优异，平均AUROC提升4.7%，FPR@95降低9.3%。

Conclusion: SPROD能够显著提高OOD检测的可靠性和性能，展示了其应对复杂数据分布和伪相关性问题的强大能力。

Abstract: Out-of-distribution (OOD) detection is crucial for ensuring the reliability
and safety of machine learning models in real-world applications, where they
frequently face data distributions unseen during training. Despite progress,
existing methods are often vulnerable to spurious correlations that mislead
models and compromise robustness. To address this, we propose SPROD, a novel
prototype-based OOD detection approach that explicitly addresses the challenge
posed by unknown spurious correlations. Our post-hoc method refines class
prototypes to mitigate bias from spurious features without additional data or
hyperparameter tuning, and is broadly applicable across diverse backbones and
OOD detection settings. We conduct a comprehensive spurious correlation OOD
detection benchmarking, comparing our method against existing approaches and
demonstrating its superior performance across challenging OOD datasets, such as
CelebA, Waterbirds, UrbanCars, Spurious Imagenet, and the newly introduced
Animals MetaCoCo. On average, SPROD improves AUROC by 4.7% and FPR@95 by 9.3%
over the second best.

</details>


### [161] [When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation](https://arxiv.org/abs/2506.23724)
*Chang'an Yi,Xiaohui Deng,Guohao Chen,Yan Zhou,Qinghua Lu,Shuaicheng Niu*

Main category: cs.CV

TL;DR: 本文探讨了在测试时适应(TTA)过程中，跨模型知识协作带来的影响，提出了COCA框架，通过跨模型联合学习显著提升了TTA的性能。


<details>
  <summary>Details</summary>
Motivation: 测试时适应（TTA）方法通常仅关注单一模型的适应过程，而未研究多个模型之间的协作对TTA的影响。

Method: 提出COCA框架，该框架包含两个主要策略：共同适应(co-adaptation)和自我适应(self-adaptation)，以整合跨模型的互补知识并强化模型自身能力。

Result: 通过实验验证，COCA框架在多种模型（如ResNet、ViT、Mobile-ViT）的TTA性能上均有显著提升。例如，在ImageNet-C数据集上，COCA使得ViT-Base的平均适应精度从51.7%提升到64.5%。

Conclusion: COCA揭示了跨模型协作对TTA性能的提升作用，展现了跨模型联合学习在不同大小模型间的潜力。

Abstract: Test-time Adaptation (TTA) adapts a given model to testing domain data with
potential domain shifts through online unsupervised learning, yielding
impressive performance. However, to date, existing TTA methods primarily focus
on single-model adaptation. In this work, we investigate an intriguing
question: how does cross-model knowledge influence the TTA process? Our
findings reveal that, in TTA's unsupervised online setting, each model can
provide complementary, confident knowledge to the others, even when there are
substantial differences in model size. For instance, a smaller model like
MobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base
(86.6M parameters). In light of this, we propose COCA, a Cross-Model
Co-Learning framework for TTA, which mainly consists of two main strategies. 1)
Co-adaptation adaptively integrates complementary knowledge from other models
throughout the TTA process, reducing individual model biases. 2)
Self-adaptation enhances each model's unique strengths via unsupervised
learning, enabling diverse adaptation to the target domain. Extensive
experiments show that COCA, which can also serve as a plug-and-play module,
significantly boosts existing SOTAs, on models with various sizes--including
ResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example,
with Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracy
on ImageNet-C from 51.7% to 64.5%. The code is publicly available at
https://github.com/ycarobot/COCA.

</details>


### [162] [Consistent Time-of-Flight Depth Denoising via Graph-Informed Geometric Attention](https://arxiv.org/abs/2506.23542)
*Weida Wang,Changyong He,Jin Zeng,Di Qiu*

Main category: cs.CV

TL;DR: 本文提出了一种利用运动不变图融合的ToF深度去噪网络，解决了现有方法中时间不一致性和空间模糊的问题。


<details>
  <summary>Details</summary>
Motivation: ToF传感器捕获的深度图像易受噪声影响，严重影响下游任务的可信性，因此需要开发有效的去噪方法。

Method: 提出一种基于运动不变图融合的网络，利用跨帧几何注意力进行图融合，同时结合平滑先验和噪声分布推导的数据保真项，形成最大后验问题，并通过迭代滤波器解算。

Result: 在合成数据集DVToF上取得了精度和一致性方面的最新性能，并在真实数据集Kinectv2上表现出较强的泛化能力。

Conclusion: 该方法在改进深度图像去噪的同时保持了模型的可解释性和高性能，展示了较强的理论创新性和实际效果。

Abstract: Depth images captured by Time-of-Flight (ToF) sensors are prone to noise,
requiring denoising for reliable downstream applications. Previous works either
focus on single-frame processing, or perform multi-frame processing without
considering depth variations at corresponding pixels across frames, leading to
undesirable temporal inconsistency and spatial ambiguity. In this paper, we
propose a novel ToF depth denoising network leveraging motion-invariant graph
fusion to simultaneously enhance temporal stability and spatial sharpness.
Specifically, despite depth shifts across frames, graph structures exhibit
temporal self-similarity, enabling cross-frame geometric attention for graph
fusion. Then, by incorporating an image smoothness prior on the fused graph and
data fidelity term derived from ToF noise distribution, we formulate a maximum
a posterior problem for ToF denoising. Finally, the solution is unrolled into
iterative filters whose weights are adaptively learned from the graph-informed
geometric attention, producing a high-performance yet interpretable network.
Experimental results demonstrate that the proposed scheme achieves
state-of-the-art performance in terms of accuracy and consistency on synthetic
DVToF dataset and exhibits robust generalization on the real Kinectv2 dataset.
Source code will be released at
\href{https://github.com/davidweidawang/GIGA-ToF}{https://github.com/davidweidawang/GIGA-ToF}.

</details>


### [163] [Pyramidal Patchification Flow for Visual Generation](https://arxiv.org/abs/2506.23543)
*Hui Li,Baoyou Chen,Liwei Zhang,Jiaye Li,Jingdong Wang,Siyu Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种新的金字塔式分块流方法（PPFlow），根据不同噪声水平调整分块大小，从而优化扩散变换器的计算成本和生成性能。


<details>
  <summary>Details</summary>
Motivation: 传统的固定分块大小的扩散变换器在处理高噪声阶段的计算成本较低，但在低噪声阶段可能无法充分捕获细节，限制了模型的性能。

Method: PPFlow使用金字塔式分块策略：在高噪声时间步中采用较大的分块，在低噪声时间步中采用较小的分块；针对每种块大小学习线性投影；并相应调整Unpatchify过程。

Result: 从零训练的情况下，2级和3级PPFlow分别比SiT-B/2实现了1.6倍和2.0倍的推理速度，同时生成性能相近且训练开销稍低。而基于预训练模型的PPFlow进一步提高了性能，且训练时间较短。

Conclusion: PPFlow通过动态调整分块大小，在优化计算效率的同时保持了优异的图像生成性能，为扩散变换器的实际应用提供了新的解决方案。

Abstract: Diffusion transformers (DiTs) adopt Patchify, mapping patch representations
to token representations through linear projections, to adjust the number of
tokens input to DiT blocks and thus the computation cost. Instead of a single
patch size for all the timesteps, we introduce a Pyramidal Patchification Flow
(PPFlow) approach: Large patch sizes are used for high noise timesteps and
small patch sizes for low noise timesteps; Linear projections are learned for
each patch size; and Unpatchify is accordingly modified. Unlike Pyramidal Flow,
our approach operates over full latent representations other than pyramid
representations, and adopts the normal denoising process without requiring the
renoising trick. We demonstrate the effectiveness of our approach through two
training manners. Training from scratch achieves a $1.6\times$ ($2.0\times$)
inference speed over SiT-B/2 for 2-level (3-level) pyramid patchification with
slightly lower training FLOPs and similar image generation performance.
Training from pretrained normal DiTs achieves even better performance with
small training time. The code and checkpoint are at
https://github.com/fudan-generative-vision/PPFlow.

</details>


### [164] [Oneta: Multi-Style Image Enhancement Using Eigentransformation Functions](https://arxiv.org/abs/2506.23547)
*Jiwon Kim,Soohyun Hwang,Dong-O Kim,Changsu Han,Min Kyu Park,Chang-Su Kim*

Main category: cs.CV

TL;DR: 提出了一种称为Oneta的多风格图像增强算法，能够高效处理6类增强任务，涵盖30个数据集。


<details>
  <summary>Details</summary>
Motivation: 开发一种同时支持多种风格图像增强的高效算法，以适用于各种图像增强任务。

Method: 算法采用两步增强模型：强度增强和色彩校正，通过引入eigenTF紧凑表示增强转换，同时利用Y-Net和C-Net预测模型参数并使用可学习的K个风格代币进行训练和测试。

Result: 对单一Oneta网络的深入实验表明，其能够高效执行包括修图、图像信号处理、低光增强等在内的六种增强任务，覆盖30个数据集。

Conclusion: Oneta网络通过创新的两步模型和风格代币方式，高效解决了多风格图像增强问题，表现出卓越的性能和适应性。

Abstract: The first algorithm, called Oneta, for a novel task of multi-style image
enhancement is proposed in this work. Oneta uses two point operators
sequentially: intensity enhancement with a transformation function (TF) and
color correction with a color correction matrix (CCM). This two-step
enhancement model, though simple, achieves a high performance upper bound.
Also, we introduce eigentransformation function (eigenTF) to represent TF
compactly. The Oneta network comprises Y-Net and C-Net to predict eigenTF and
CCM parameters, respectively. To support $K$ styles, Oneta employs $K$
learnable tokens. During training, each style token is learned using image
pairs from the corresponding dataset. In testing, Oneta selects one of the $K$
style tokens to enhance an image accordingly. Extensive experiments show that
the single Oneta network can effectively undertake six enhancement tasks --
retouching, image signal processing, low-light image enhancement, dehazing,
underwater image enhancement, and white balancing -- across 30 datasets.

</details>


### [165] [JAM-Flow: Joint Audio-Motion Synthesis with Flow Matching](https://arxiv.org/abs/2506.23552)
*Mingi Kwon,Joonghyuk Shin,Jaeseok Jung,Jaesik Park,Youngjung Uh*

Main category: cs.CV

TL;DR: 本文提出了JAM-Flow，一个用于同时生成和处理面部运动与语音的统一框架。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型通常将说话头部合成和文本到语音视为独立任务，忽视了面部运动与语音的内在联系。

Method: 提出了JAM-Flow框架，该框架基于流匹配和一种新颖的多模态扩散Transformer架构（MM-DiT），结合了Motion-DiT和Audio-DiT模块，通过选择性联合注意力层进行交互，并采用时间对齐的嵌入和局部联合注意力屏蔽。

Result: JAM-Flow支持文本、参考音频和参考运动等多种输入条件，能够执行诸如从文本生成同步说话头部、音频驱动动画等任务。

Conclusion: JAM-Flow为音频可视化生成提供了一个实际方案，在多模态生成建模中显著推进技术发展。

Abstract: The intrinsic link between facial motion and speech is often overlooked in
generative modeling, where talking head synthesis and text-to-speech (TTS) are
typically addressed as separate tasks. This paper introduces JAM-Flow, a
unified framework to simultaneously synthesize and condition on both facial
motion and speech. Our approach leverages flow matching and a novel Multi-Modal
Diffusion Transformer (MM-DiT) architecture, integrating specialized Motion-DiT
and Audio-DiT modules. These are coupled via selective joint attention layers
and incorporate key architectural choices, such as temporally aligned
positional embeddings and localized joint attention masking, to enable
effective cross-modal interaction while preserving modality-specific strengths.
Trained with an inpainting-style objective, JAM-Flow supports a wide array of
conditioning inputs-including text, reference audio, and reference
motion-facilitating tasks such as synchronized talking head generation from
text, audio-driven animation, and much more, within a single, coherent model.
JAM-Flow significantly advances multi-modal generative modeling by providing a
practical solution for holistic audio-visual synthesis. project page:
https://joonghyuk.com/jamflow-web

</details>


### [166] [LH2Face: Loss function for Hard High-quality Face](https://arxiv.org/abs/2506.23555)
*Fan Xie,Pan Cao*

Main category: cs.CV

TL;DR: 提出了一种名为LH2Face的损失函数，针对难以辨别的高质量人脸问题进行优化，在IJB-B数据集上取得了49.39%的准确率，比第二名提高了2.37%。


<details>
  <summary>Details</summary>
Motivation: 当前的人脸识别系统采用基于余弦相似度和softmax分类的方法，但对难样本表现欠佳且训练策略过于统一，因此需要改进算法以处理高质量难样本并提升识别效果。

Method: 提出了LH2Face损失函数，基于von Mises-Fisher分布的距离函数，结合不确定性敏感的自适应margin设计，同时通过proxy约束优化表示空间分布，并使用渲染器对人脸重建和识别进行相互优化。

Result: LH2Face方法在高质量难样本数据集上的表现优于现有方法，例如在IJB-B数据集上取得了49.39%的准确率，超越第二名方法2.37%。

Conclusion: LH2Face在高质量难样本人脸识别任务上展现出显著的性能提升，证明了其方法和创新设计的有效性。

Abstract: In current practical face authentication systems, most face recognition (FR)
algorithms are based on cosine similarity with softmax classification. Despite
its reliable classification performance, this method struggles with hard
samples. A popular strategy to improve FR performance is incorporating angular
or cosine margins. However, it does not take face quality or recognition
hardness into account, simply increasing the margin value and thus causing an
overly uniform training strategy. To address this problem, a novel loss
function is proposed, named Loss function for Hard High-quality Face (LH2Face).
Firstly, a similarity measure based on the von Mises-Fisher (vMF) distribution
is stated, specifically focusing on the logarithm of the Probability Density
Function (PDF), which represents the distance between a probability
distribution and a vector. Then, an adaptive margin-based multi-classification
method using softmax, called the Uncertainty-Aware Margin Function, is
implemented in the article. Furthermore, proxy-based loss functions are used to
apply extra constraints between the proxy and sample to optimize their
representation space distribution. Finally, a renderer is constructed that
optimizes FR through face reconstruction and vice versa. Our LH2Face is
superior to similiar schemes on hard high-quality face datasets, achieving
49.39% accuracy on the IJB-B dataset, which surpasses the second-place method
by 2.37%.

</details>


### [167] [OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2506.23565)
*Mingqian Ji,Jian Yang,Shanshan Zhang*

Main category: cs.CV

TL;DR: 提出了Object-centric Radiance Fields(OcRF)用于增强多视角的3D目标检测性能，并取得了新的最优表现。


<details>
  <summary>Details</summary>
Motivation: 当前基于多视角的3D目标检测方法受限于数据驱动和隐式方式转换2D到3D特性，因此希望通过借鉴辐射场在3D重建中的成果来提升几何评估能力。

Method: 引入Object-centric Radiance Fields(OcRF)技术，仅专注于渲染前景目标，抑制背景干扰，结合通过渲染产生的不透明数据，提升2D和3D特性均的检测性能。

Result: OcRFDet在nuScenes测试集上实现57.2%的mAP和64.8%的NDS，超越了先前的最优方法。

Conclusion: 通过专注于前景目标建模，克服了背景噪声对性能的影响，最终成功提升了3D目标检测的性能。

Abstract: Current multi-view 3D object detection methods typically transfer 2D features
into 3D space using depth estimation or 3D position encoder, but in a fully
data-driven and implicit manner, which limits the detection performance.
Inspired by the success of radiance fields on 3D reconstruction, we assume they
can be used to enhance the detector's ability of 3D geometry estimation.
However, we observe a decline in detection performance, when we directly use
them for 3D rendering as an auxiliary task. From our analysis, we find the
performance drop is caused by the strong responses on the background when
rendering the whole scene. To address this problem, we propose object-centric
radiance fields, focusing on modeling foreground objects while discarding
background noises. Specifically, we employ Object-centric Radiance Fields
(OcRF) to enhance 3D voxel features via an auxiliary task of rendering
foreground objects. We further use opacity - the side-product of rendering- to
enhance the 2D foreground BEV features via Height-aware Opacity-based Attention
(HOA), where attention maps at different height levels are generated separately
via multiple networks in parallel. Extensive experiments on the nuScenes
validation and test datasets demonstrate that our OcRFDet achieves superior
performance, outperforming previous state-of-the-art methods with 57.2$\%$ mAP
and 64.8$\%$ NDS on the nuScenes test benchmark. Code will be available at
https://github.com/Mingqj/OcRFDet.

</details>


### [168] [Event-based Tiny Object Detection: A Benchmark Dataset and Baseline](https://arxiv.org/abs/2506.23575)
*Nuo Chen,Chao Xiao,Yimian Dai,Shiman He,Miao Li,Wei An*

Main category: cs.CV

TL;DR: 本文引入了EV-UAV数据集，这是反无人机任务中第一个大规模、高度多样化的小目标检测基准数据集，并提出了一个新型的事件稀疏分割网络EV-SpSegNet，用以在事件点云中进行分割，从而解决传统相机难以在复杂环境中有效检测小目标的问题。


<details>
  <summary>Details</summary>
Motivation: 传统相机因低帧率、动态范围限制和数据冗余等问题无法在复杂环境中有效检测小目标。事件相机具有微秒级时间分辨率和高动态范围，提供了优于传统相机的解决方案。然而，现有基于事件的数据集在规模上有限，目标尺寸较大且背景不够多样化，不适合于小目标检测任务。

Method: 论文引入了一个新型数据集EV-UAV，包含147个序列和超过230万次事件级标注，以微型目标和多样化场景为特点。此外，提出了一个用于事件点云中目标检测的基线模型EV-SpSegNet，并配套设计了时空关联损失（STC），利用目标运动的连续性指导网络保留目标事件。

Result: 实验表明，提出的EV-SpSegNet在EV-UAV数据集上的性能优越，展示了方法的有效性，并提供了EVSOD研究的基准。

Conclusion: 本文创建了EV-UAV数据集并提出了EV-SpSegNet模型，为基于事件的小目标检测研究提供了新的资源和方法，推动了反无人机任务中的技术进展。

Abstract: Small object detection (SOD) in anti-UAV task is a challenging problem due to
the small size of UAVs and complex backgrounds. Traditional frame-based cameras
struggle to detect small objects in complex environments due to their low frame
rates, limited dynamic range, and data redundancy. Event cameras, with
microsecond temporal resolution and high dynamic range, provide a more
effective solution for SOD. However, existing event-based object detection
datasets are limited in scale, feature large targets size, and lack diverse
backgrounds, making them unsuitable for SOD benchmarks. In this paper, we
introduce a Event-based Small object detection (EVSOD) dataset (namely EV-UAV),
the first large-scale, highly diverse benchmark for anti-UAV tasks. It includes
147 sequences with over 2.3 million event-level annotations, featuring
extremely small targets (averaging 6.8 $\times$ 5.4 pixels) and diverse
scenarios such as urban clutter and extreme lighting conditions. Furthermore,
based on the observation that small moving targets form continuous curves in
spatiotemporal event point clouds, we propose Event based Sparse Segmentation
Network (EV-SpSegNet), a novel baseline for event segmentation in point cloud
space, along with a Spatiotemporal Correlation (STC) loss that leverages motion
continuity to guide the network in retaining target events. Extensive
experiments on the EV-UAV dataset demonstrate the superiority of our method and
provide a benchmark for future research in EVSOD. The dataset and code are at
https://github.com/ChenYichen9527/Ev-UAV.

</details>


### [169] [StackCLIP: Clustering-Driven Stacked Prompt in Zero-Shot Industrial Anomaly Detection](https://arxiv.org/abs/2506.23577)
*Yanning Hou,Yanran Ruan,Junfa Li,Shanshan Wang,Jianfeng Qiu,Ke Xu*

Main category: cs.CV

TL;DR: 本研究提出了一种称为StackCLIP的模型，通过多类别名称叠加生成堆叠的提示，以改进图文特征对齐问题，从而在零样本工业异常检测任务中取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前大多数研究在预训练时使用特定类别的提示，容易导致对训练类别的过拟合，从而限制模型的泛化能力。因此，需要设计一种新的方法来生成更通用且更具判别力的提示。

Method: 提出了StackCLIP模型，包括两个关键组件：（1）聚类驱动的堆叠提示（CSP）模块，该模块通过语义上相似的类别堆叠生成通用提示，并融合多对象文本特征；（2）特征对齐集成（EFA）模块，为每个堆叠簇训练特定线性层并基于测试类别的属性自适应集成。此外，还引入了调节提示学习（RPL）模块，进一步优化提示学习过程。

Result: 在七个工业异常检测数据集上的测试表明，StackCLIP模型在零样本异常检测和分割任务中取得了当前最优表现，同时在分类任务中也表现出较强的泛化能力。

Conclusion: 通过引入多类别名称堆叠、反映语义相似性的堆叠提示，以及针对性模块优化，StackCLIP显著提高了异常检测的精度和扩展性能，实现了工业异常检测领域的性能突破。

Abstract: Enhancing the alignment between text and image features in the CLIP model is
a critical challenge in zero-shot industrial anomaly detection tasks. Recent
studies predominantly utilize specific category prompts during pretraining,
which can cause overfitting to the training categories and limit model
generalization. To address this, we propose a method that transforms category
names through multicategory name stacking to create stacked prompts, forming
the basis of our StackCLIP model. Our approach introduces two key components.
The Clustering-Driven Stacked Prompts (CSP) module constructs generic prompts
by stacking semantically analogous categories, while utilizing multi-object
textual feature fusion to amplify discriminative anomalies among similar
objects. The Ensemble Feature Alignment (EFA) module trains knowledge-specific
linear layers tailored for each stack cluster and adaptively integrates them
based on the attributes of test categories. These modules work together to
deliver superior training speed, stability, and convergence, significantly
boosting anomaly segmentation performance. Additionally, our stacked prompt
framework offers robust generalization across classification tasks. To further
improve performance, we introduce the Regulating Prompt Learning (RPL) module,
which leverages the generalization power of stacked prompts to refine prompt
learning, elevating results in anomaly detection classification tasks.
Extensive testing on seven industrial anomaly detection datasets demonstrates
that our method achieves state-of-the-art performance in both zero-shot anomaly
detection and segmentation tasks.

</details>


### [170] [GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models](https://arxiv.org/abs/2506.23903)
*Hamza Rasaee,Taha Koleilat,Hassan Rivaz*

Main category: cs.CV

TL;DR: 本文提出了一种融合视觉与语言的模型，将Grounding DINO与SAM2结合用于超声图像多器官分割，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于解剖差异、成像协议多样性及标注数据有限，现有超声图像分割依然面临挑战。

Method: 通过将Grounding DINO与SAM2结合，使用LoRA技术微调至超声领域，并利用18个公开数据集进行实验，包括未见分布上的测试。

Result: 提出的方法在大多数已见数据集上的性能优于UniverSeg、MedSAM等现有方法，并在未见数据集上表现良好，无需额外微调。

Conclusion: 融合视觉与语言的模型可实现可扩展和鲁棒的超声图像分析，减少对大量特定器官标注数据的依赖。

Abstract: Accurate and generalizable object segmentation in ultrasound imaging remains
a significant challenge due to anatomical variability, diverse imaging
protocols, and limited annotated data. In this study, we propose a
prompt-driven vision-language model (VLM) that integrates Grounding DINO with
SAM2 to enable object segmentation across multiple ultrasound organs. A total
of 18 public ultrasound datasets, encompassing the breast, thyroid, liver,
prostate, kidney, and paraspinal muscle, were utilized. These datasets were
divided into 15 for fine-tuning and validation of Grounding DINO using Low Rank
Adaptation (LoRA) to the ultrasound domain, and 3 were held out entirely for
testing to evaluate performance in unseen distributions. Comprehensive
experiments demonstrate that our approach outperforms state-of-the-art
segmentation methods, including UniverSeg, MedSAM, MedCLIP-SAM, BiomedParse,
and SAMUS on most seen datasets while maintaining strong performance on unseen
datasets without additional fine-tuning. These results underscore the promise
of VLMs in scalable and robust ultrasound image analysis, reducing dependence
on large, organ-specific annotated datasets. We will publish our code on
code.sonography.ai after acceptance.

</details>


### [171] [Dataset Distillation via Vision-Language Category Prototype](https://arxiv.org/abs/2506.23580)
*Yawen Zou,Guang Li,Duo Su,Zi Wang,Jun Yu,Chao Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种融合视觉语言方法的数据集浓缩技术，通过引入文本原型，与图像原型协作生成数据，提升数据集浓缩性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据集浓缩方法主要关注图像信息，忽略数据中的语义信息，限制了模型的泛化能力，尤其是在复杂数据集任务中。

Method: 将开放语言模型生成的描述性文本信息作为文本原型，与图像原型协作生成逻辑上连贯、含有目标对象的图像数据。

Result: 该框架在没有预先文本描述的数据集上表现出广泛适用性，相较其他方法生成逻辑一致的图像，并达到最先进的验证性能，显示了强大的泛化能力。

Conclusion: 提出的方法扩展了数据集浓缩的潜力，不仅限于传统的基于图像的方法，并已公开源代码和生成数据。

Abstract: Dataset distillation (DD) condenses large datasets into compact yet
informative substitutes, preserving performance comparable to the original
dataset while reducing storage, transmission costs, and computational
consumption. However, previous DD methods mainly focus on distilling
information from images, often overlooking the semantic information inherent in
the data. The disregard for context hinders the model's generalization ability,
particularly in tasks involving complex datasets, which may result in illogical
outputs or the omission of critical objects. In this study, we integrate
vision-language methods into DD by introducing text prototypes to distill
language information and collaboratively synthesize data with image prototypes,
thereby enhancing dataset distillation performance. Notably, the text
prototypes utilized in this study are derived from descriptive text information
generated by an open-source large language model. This framework demonstrates
broad applicability across datasets without pre-existing text descriptions,
expanding the potential of dataset distillation beyond traditional image-based
approaches. Compared to other methods, the proposed approach generates
logically coherent images containing target objects, achieving state-of-the-art
validation performance and demonstrating robust generalization. Source code and
generated data are available in
https://github.com/zou-yawen/Dataset-Distillation-via-Vision-Language-Category-Prototype/

</details>


### [172] [CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models](https://arxiv.org/abs/2506.23590)
*Qiming Li,Zekai Ye,Xiaocheng Feng,Weihong Zhong,Libo Qin,Ruihan Chen,Baohang Li,Kui Jiang,Yaowei Wang,Ting Liu,Bing Qin*

Main category: cs.CV

TL;DR: 提出了一个名为CAI的无训练、即插即用方法，增强了大型视觉语言模型（LVLMs）的视觉感知能力，减少了对象幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 为了减少LVLMs在解读视觉信息时产生的对象幻觉问题，同时避免昂贵的人力标注、训练开销以及推理时间的增加。

Method: 通过观察LVLMs在回答与标题相关查询时的注意力更强，设计了Caption-sensitive Attention Intervention (CAI)，利用注意力激活模式进行无训练干预，提升视觉感知能力。

Result: 通过四个基准的广泛实验，CAI在辨别任务和生成任务中取得了当前最先进的幻觉抑制效果，不增加显著推理成本。

Conclusion: CAI作为一种简单高效的方法，无需复杂预训练，显著增强了LVLMs的视觉感知和可靠性。

Abstract: Although Large Vision-Language Models (LVLMs) have demonstrated powerful
capabilities in interpreting visual information, they frequently produce
content that deviates from visual information, leading to object hallucination.
To tackle this, recent works mostly depend on expensive manual annotations and
training cost, or significantly increase inference time. In this work, we
observe that LVLMs' attention to visual information is significantly stronger
when answering caption queries compared to non-caption queries. Inspired by
this phenomenon, we propose Caption-sensitive Attention Intervention (CAI), a
training-free, plug-and-play hallucination mitigation method that leverages the
attention activation pattern in response to caption queries to enhance LVLMs'
visual perception capability. Extensive experimental results across four
benchmarks covering both discriminative and generative tasks, demonstrate that
CAI achieves state-of-the-art (SOTA) hallucination mitigating performance only
with minimal additional inference cost.

</details>


### [173] [SG-LDM: Semantic-Guided LiDAR Generation via Latent-Aligned Diffusion](https://arxiv.org/abs/2506.23606)
*Zhengkang Xiang,Zizhao Li,Amir Khodabandeh,Kourosh Khoshelham*

Main category: cs.CV

TL;DR: 提出了一种语义引导的激光雷达扩散模型（SG-LDM），能够生成高保真激光雷达点云并执行跨领域转换，用于改善感知任务中的数据增强。


<details>
  <summary>Details</summary>
Motivation: 由于现有的激光雷达点云生成方法通常不考虑实际应用需求，论文提出了一种能根据语义标签生成特定点云的模型，以填补数据稀缺性和多样性不足的问题。

Method: 设计了一种语义指导下的扩散模型（SG-LDM），通过语义显式条件处理与原始激光雷达空间操作，实现高质量的点云生成和跨领域转换框架。

Result: 实验结果表明，SG-LDM优于现有的激光雷达扩散模型，在下游激光雷达分割任务的数据增强中表现出了较强的提升效果。

Conclusion: SG-LDM展示了在语义引导的点云生成和跨领域转换领域的潜力，为深度学习管道中的数据增强提供了一种新的方向。

Abstract: Lidar point cloud synthesis based on generative models offers a promising
solution to augment deep learning pipelines, particularly when real-world data
is scarce or lacks diversity. By enabling flexible object manipulation, this
synthesis approach can significantly enrich training datasets and enhance
discriminative models. However, existing methods focus on unconditional lidar
point cloud generation, overlooking their potential for real-world
applications. In this paper, we propose SG-LDM, a Semantic-Guided Lidar
Diffusion Model that employs latent alignment to enable robust
semantic-to-lidar synthesis. By directly operating in the native lidar space
and leveraging explicit semantic conditioning, SG-LDM achieves state-of-the-art
performance in generating high-fidelity lidar point clouds guided by semantic
labels. Moreover, we propose the first diffusion-based lidar translation
framework based on SG-LDM, which enables cross-domain translation as a domain
adaptation strategy to enhance downstream perception performance. Systematic
experiments demonstrate that SG-LDM significantly outperforms existing lidar
diffusion models and the proposed lidar translation framework further improves
data augmentation performance in the downstream lidar segmentation task.

</details>


### [174] [PGOV3D: Open-Vocabulary 3D Semantic Segmentation with Partial-to-Global Curriculum](https://arxiv.org/abs/2506.23607)
*Shiqi Zhang,Sha Zhang,Jiajun Deng,Yedong Shen,Mingxiao MA,Yanyong Zhang*

Main category: cs.CV

TL;DR: PGOV3D通过分阶段培训框架，改进了开放词汇3D语义分割，通过多视图密集语义信息和全场景建模进行训练，成功提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分利用多视图图像中的语义内容和跨视图对应性，限制了开放词汇3D语义分割模型的效果。

Method: 提出了一个两阶段的训练策略：第一阶段通过多视图RGB-D输入生成的部分场景点云进行预训练，并利用多模态大语言模型和2D分割基础模型生成开放词汇标签；引入辅助模块增强跨视点特征一致性。第二阶段在完整场景级点云上进行微调，通过生成伪标签在密集部分观察和大规模3D环境之间架起语义桥梁。

Result: 在ScanNet、ScanNet200和S3DIS基准测试上，PGOV3D在开放词汇3D语义分割中表现出竞争力。

Conclusion: PGOV3D改进了开放词汇3D语义分割，通过结合部分和全局场景的培训策略，充分利用多视图图像的语义信息，显著提升了任务性能。

Abstract: Existing open-vocabulary 3D semantic segmentation methods typically supervise
3D segmentation models by merging text-aligned features (e.g., CLIP) extracted
from multi-view images onto 3D points. However, such approaches treat
multi-view images merely as intermediaries for transferring open-vocabulary
information, overlooking their rich semantic content and cross-view
correspondences, which limits model effectiveness. To address this, we propose
PGOV3D, a novel framework that introduces a Partial-to-Global curriculum for
improving open-vocabulary 3D semantic segmentation. The key innovation lies in
a two-stage training strategy. In the first stage, we pre-train the model on
partial scenes that provide dense semantic information but relatively simple
geometry. These partial point clouds are derived from multi-view RGB-D inputs
via pixel-wise depth projection. To enable open-vocabulary learning, we
leverage a multi-modal large language model (MLLM) and a 2D segmentation
foundation model to generate open-vocabulary labels for each viewpoint,
offering rich and aligned supervision. An auxiliary inter-frame consistency
module is introduced to enforce feature consistency across varying viewpoints
and enhance spatial understanding. In the second stage, we fine-tune the model
on complete scene-level point clouds, which are sparser and structurally more
complex. We aggregate the partial vocabularies associated with each scene and
generate pseudo labels using the pre-trained model, effectively bridging the
semantic gap between dense partial observations and large-scale 3D
environments. Extensive experiments on ScanNet, ScanNet200, and S3DIS
benchmarks demonstrate that PGOV3D achieves competitive performance in
open-vocabulary 3D semantic segmentation.

</details>


### [175] [A Survey on Vision-Language-Action Models for Autonomous Driving](https://arxiv.org/abs/2506.24044)
*Sicong Jiang,Zilin Huang,Kangan Qian,Ziang Luo,Tianze Zhu,Yang Zhong,Yihong Tang,Menglin Kong,Yunlong Wang,Siwen Jiao,Hao Ye,Zihao Sheng,Xin Zhao,Tuopu Wen,Zheng Fu,Sikai Chen,Kun Jiang,Diange Yang,Seongjin Choi,Lijun Sun*

Main category: cs.CV

TL;DR: 本文综述了视觉-语言-行动（VLA）范式在自动驾驶领域的应用，分析VLA模型的进展和挑战，并提供数据集、评估协议和未来研究方向的总结。


<details>
  <summary>Details</summary>
Motivation: 近年来多模态大模型的进展使得将视觉感知、自然语言理解与控制集成于单一策略成为可能，特别是在自动驾驶领域，这种方法被寄予厚望以实现高效的指令解读与场景推理。

Method: 作者通过归纳已有研究成果，总结VLA在自动驾驶领域的框架，分析从解释型模型到推理型模型的演变，并对20多种代表性模型进行比较，整合相关数据集和基准测试。

Result: 调查结果显示当前模型已在驾驶安全性、准确性与解释质量等方面取得进展，同时指出了鲁棒性、实时性与形式化验证方面的挑战。

Conclusion: 本文为自动驾驶领域的VLA研究提供了第一份全面综述，提出了解决现有挑战的方法，进一步推动了社会友好型自动驾驶汽车的研究。

Abstract: The rapid progress of multimodal large language models (MLLM) has paved the
way for Vision-Language-Action (VLA) paradigms, which integrate visual
perception, natural language understanding, and control within a single policy.
Researchers in autonomous driving are actively adapting these methods to the
vehicle domain. Such models promise autonomous vehicles that can interpret
high-level instructions, reason about complex traffic scenes, and make their
own decisions. However, the literature remains fragmented and is rapidly
expanding. This survey offers the first comprehensive overview of VLA for
Autonomous Driving (VLA4AD). We (i) formalize the architectural building blocks
shared across recent work, (ii) trace the evolution from early explainer to
reasoning-centric VLA models, and (iii) compare over 20 representative models
according to VLA's progress in the autonomous driving domain. We also
consolidate existing datasets and benchmarks, highlighting protocols that
jointly measure driving safety, accuracy, and explanation quality. Finally, we
detail open challenges - robustness, real-time efficiency, and formal
verification - and outline future directions of VLA4AD. This survey provides a
concise yet complete reference for advancing interpretable socially aligned
autonomous vehicles. Github repo is available at
\href{https://github.com/JohnsonJiang1996/Awesome-VLA4AD}{SicongJiang/Awesome-VLA4AD}.

</details>


### [176] [AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention](https://arxiv.org/abs/2506.23611)
*Ziao Liu,Zhenjia Li,Yifeng Shi,Xiangang Li*

Main category: cs.CV

TL;DR: AttentionGS提出了一种新框架，通过结构注意力从随机初始化进行3D重建，摆脱对高质量点云的依赖，并在多个基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于3D Gaussian Splatting需要高质量点云，而现有的Structure-from-Motion方法在纹理缺乏或视角受限场景中表现不佳，此论文旨在解决该限制问题。

Method: 提出AttentionGS框架，通过几何注意力快速恢复全局场景结构，随后运用纹理注意力提升细节质量，同时利用不透明度加权梯度对高斯稠密化进行引导。

Result: 实验表明，在点云初始化不可靠的场景中，AttentionGS显著优于最先进方法。

Conclusion: AttentionGS进一步增强了3D Gaussian Splatting的鲁棒性与灵活性，为其在真实世界应用中的普及铺平道路。

Abstract: 3D Gaussian Splatting (3DGS) is a powerful alternative to Neural Radiance
Fields (NeRF), excelling in complex scene reconstruction and efficient
rendering. However, it relies on high-quality point clouds from
Structure-from-Motion (SfM), limiting its applicability. SfM also fails in
texture-deficient or constrained-view scenarios, causing severe degradation in
3DGS reconstruction. To address this limitation, we propose AttentionGS, a
novel framework that eliminates the dependency on high-quality initial point
clouds by leveraging structural attention for direct 3D reconstruction from
randomly initialization. In the early training stage, we introduce geometric
attention to rapidly recover the global scene structure. As training
progresses, we incorporate texture attention to refine fine-grained details and
enhance rendering quality. Furthermore, we employ opacity-weighted gradients to
guide Gaussian densification, leading to improved surface reconstruction.
Extensive experiments on multiple benchmark datasets demonstrate that
AttentionGS significantly outperforms state-of-the-art methods, particularly in
scenarios where point cloud initialization is unreliable. Our approach paves
the way for more robust and flexible 3D Gaussian Splatting in real-world
applications.

</details>


### [177] [TurboVSR: Fantastic Video Upscalers and Where to Find Them](https://arxiv.org/abs/2506.23618)
*Zhongdao Wang,Guodongfang Zhao,Jingjing Ren,Bailan Feng,Shifeng Zhang,Wenbo Li*

Main category: cs.CV

TL;DR: 本研究提出了TurboVSR，一种超高效的视频超分辨率（VSR）模型，可在7秒内处理2秒长1080p视频，同时支持超高清图像分辨率处理。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的视频超分辨率方法生成细节能力强，但计算效率极低，处理短视频需时数十分钟。

Method: (1) 使用高压缩比的自编码器减少处理的token数量；(2) 提出分解条件优化方案，先超分辨初始帧，再对后续帧依赖初始帧和低分辨率帧进行超分辨；(3) 改造预训练的扩散模型为快捷模型以减少采样步骤，加速推理。

Result: TurboVSR在性能上可与当前最先进的VSR方法相媲美，但速度提高了100倍，处理1080p视频仅需7秒，同时支持解析4K等超高清视频和图像。

Conclusion: TurboVSR通过创新的压缩、条件设计和模型优化，实现了效率和性能的兼顾，为高分辨率视频和图像超分辨任务提供了高效解决方案。

Abstract: Diffusion-based generative models have demonstrated exceptional promise in
the video super-resolution (VSR) task, achieving a substantial advancement in
detail generation relative to prior methods. However, these approaches face
significant computational efficiency challenges. For instance, current
techniques may require tens of minutes to super-resolve a mere 2-second, 1080p
video. In this paper, we present TurboVSR, an ultra-efficient diffusion-based
video super-resolution model. Our core design comprises three key aspects: (1)
We employ an autoencoder with a high compression ratio of 32$\times$32$\times$8
to reduce the number of tokens. (2) Highly compressed latents pose substantial
challenges for training. We introduce factorized conditioning to mitigate the
learning complexity: we first learn to super-resolve the initial frame;
subsequently, we condition the super-resolution of the remaining frames on the
high-resolution initial frame and the low-resolution subsequent frames. (3) We
convert the pre-trained diffusion model to a shortcut model to enable fewer
sampling steps, further accelerating inference. As a result, TurboVSR performs
on par with state-of-the-art VSR methods, while being 100+ times faster, taking
only 7 seconds to process a 2-second long 1080p video. TurboVSR also supports
image resolution by considering image as a one-frame video. Our efficient
design makes SR beyond 1080p possible, results on 4K (3648$\times$2048) image
SR show surprising fine details.

</details>


### [178] [Imagine for Me: Creative Conceptual Blending of Real Images and Text via Blended Attention](https://arxiv.org/abs/2506.24085)
*Wonwoong Cho,Yanxia Zhang,Yan-Ying Chen,David I. Inouye*

Main category: cs.CV

TL;DR: 本文提出了跨度模态概念混合生成的工具 IT-Blender，能够结合图像和文本信息生成新的视觉概念，提升人类创造力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨模态概念混合生成方面存在编码图像细节丢失和图像-文本输入无法解耦等问题，同时人类进行这种任务时容易受到设计固化等认知偏差的影响。

Method: 提出一种名为 IT-Blender 的扩散适配器，结合预训练的扩散模型（SD 和 FLUX），通过融合参考图像和生成图像的潜在表征，利用新颖的混合注意力机制实现高效的图文概念解耦与融合。

Result: 实验结果表明，IT-Blender 在融合视觉与文本概念方面的效果远优于基线方法。

Conclusion: IT-Blender 丰富了生成模型在增强人类创造力方面的应用场景，展示了跨模态概念融合生成的强大潜力。

Abstract: Blending visual and textual concepts into a new visual concept is a unique
and powerful trait of human beings that can fuel creativity. However, in
practice, cross-modal conceptual blending for humans is prone to cognitive
biases, like design fixation, which leads to local minima in the design space.
In this paper, we propose a T2I diffusion adapter "IT-Blender" that can
automate the blending process to enhance human creativity. Prior works related
to cross-modal conceptual blending are limited in encoding a real image without
loss of details or in disentangling the image and text inputs. To address these
gaps, IT-Blender leverages pretrained diffusion models (SD and FLUX) to blend
the latent representations of a clean reference image with those of the noisy
generated image. Combined with our novel blended attention, IT-Blender encodes
the real reference image without loss of details and blends the visual concept
with the object specified by the text in a disentangled way. Our experiment
results show that IT-Blender outperforms the baselines by a large margin in
blending visual and textual concepts, shedding light on the new application of
image generative models to augment human creativity.

</details>


### [179] [Revisiting Audio-Visual Segmentation with Vision-Centric Transformer](https://arxiv.org/abs/2506.23623)
*Shaofei Huang,Rui Ling,Tianrui Hui,Hongyu Li,Xu Zhou,Shifeng Zhang,Si Liu,Richang Hong,Meng Wang*

Main category: cs.CV

TL;DR: 提出了一种名为Vision-Centric Transformer (VCT)的新框架，该框架改进了现有音频视觉分割模型的局限性，并实现了新的性能突破。


<details>
  <summary>Details</summary>
Motivation: 目前的音频视觉分割方法以音频为中心的Transformer架构存在感知模糊和视觉细节丢失两个主要局限性。

Method: 提出Vision-Centric Transformer (VCT)框架，采用视觉驱动的查询来提取音视频信息，并引入Prototype Prompted Query Generation (PPQG)模块实现语义感知和视觉丰富的查询生成。

Result: 在AVSBench数据集的三个子集上实现了新的最先进性能。

Conclusion: VCT框架有效缓解了当前音频中心模型的局限性，改进了模型对声音对象的区分与轮廓描绘能力。

Abstract: Audio-Visual Segmentation (AVS) aims to segment sound-producing objects in
video frames based on the associated audio signal. Prevailing AVS methods
typically adopt an audio-centric Transformer architecture, where object queries
are derived from audio features. However, audio-centric Transformers suffer
from two limitations: perception ambiguity caused by the mixed nature of audio,
and weakened dense prediction ability due to visual detail loss. To address
these limitations, we propose a new Vision-Centric Transformer (VCT) framework
that leverages vision-derived queries to iteratively fetch corresponding audio
and visual information, enabling queries to better distinguish between
different sounding objects from mixed audio and accurately delineate their
contours. Additionally, we also introduce a Prototype Prompted Query Generation
(PPQG) module within our VCT framework to generate vision-derived queries that
are both semantically aware and visually rich through audio prototype prompting
and pixel context grouping, facilitating audio-visual information aggregation.
Extensive experiments demonstrate that our VCT framework achieves new
state-of-the-art performances on three subsets of the AVSBench dataset. The
code is available at https://github.com/spyflying/VCT_AVS.

</details>


### [180] [Blending Concepts with Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.23630)
*Lorenzo Olearo,Giorgio Longari,Alessandro Raganato,Rafael Peñaloza,Simone Melzi*

Main category: cs.CV

TL;DR: 扩散模型在无需进一步训练或微调的情况下，能够将多个概念融合成新颖图像，但其效果受诸如提示顺序、概念距离等因素影响。


<details>
  <summary>Details</summary>
Motivation: 探索扩散模型在零样本框架下将多种不同概念融为新的视觉实体，展现模型在创意合成方面的潜力。

Method: 提出四种融合方法，利用提示调度、嵌入插值和分层条件等扩散管道的不同方面，通过系统实验验证它们在不同类别概念融合中的表现。

Result: 实验和用户研究表明，每种方法在不同条件下效果不同，提示顺序、概念距离和随机种子等对结果具有显著影响。

Conclusion: 扩散模型在概念合成方面具有强大能力，但对输入变化敏感，未来研究应进一步优化和稳定合成效果。

Abstract: Diffusion models have dramatically advanced text-to-image generation in
recent years, translating abstract concepts into high-fidelity images with
remarkable ease. In this work, we examine whether they can also blend distinct
concepts, ranging from concrete objects to intangible ideas, into coherent new
visual entities under a zero-shot framework. Specifically, concept blending
merges the key attributes of multiple concepts (expressed as textual prompts)
into a single, novel image that captures the essence of each concept. We
investigate four blending methods, each exploiting different aspects of the
diffusion pipeline (e.g., prompt scheduling, embedding interpolation, or
layer-wise conditioning). Through systematic experimentation across diverse
concept categories, such as merging concrete concepts, synthesizing compound
words, transferring artistic styles, and blending architectural landmarks, we
show that modern diffusion models indeed exhibit creative blending capabilities
without further training or fine-tuning. Our extensive user study, involving
100 participants, reveals that no single approach dominates in all scenarios:
each blending technique excels under certain conditions, with factors like
prompt ordering, conceptual distance, and random seed affecting the outcome.
These findings highlight the remarkable compositional potential of diffusion
models while exposing their sensitivity to seemingly minor input variations.

</details>


### [181] [FADRM: Fast and Accurate Data Residual Matching for Dataset Distillation](https://arxiv.org/abs/2506.24125)
*Jiacheng Cui,Xinyue Bi,Yaxin Luo,Xiaohan Zhao,Jiacheng Liu,Zhiqiang Shen*

Main category: cs.CV

TL;DR: 该论文引入数据残差匹配（Data Residual Matching），用于提高数据生成和缓解数据信息丢失，主要应用于数据集蒸馏任务，并显著提高效率和效果。


<details>
  <summary>Details</summary>
Motivation: 现存研究主要针对模型架构中的残差连接，缺乏对数据层面的研究，该工作旨在探索如何在数据生成和蒸馏中使用数据残差连接。

Method: 提出数据残差匹配（Data Residual Matching），通过数据级跳跃连接，加上优化级调整，用于数据生成和信息强化，从而实现对数据蒸馏的改进。

Result: 该方法提升了计算效率，同时在多个数据集基准上达到了最先进水平；在ImageNet-1K实验中，ResNet-18模型压缩比0.8%，单模型数据集蒸馏测试准确率47.7%，多模型达到50.0%。

Conclusion: FADRM方法在数据集蒸馏领域建立了新的SOTA标准，在效率与效果上实现显著提升。

Abstract: Residual connection has been extensively studied and widely applied at the
model architecture level. However, its potential in the more challenging
data-centric approaches remains unexplored. In this work, we introduce the
concept of Data Residual Matching for the first time, leveraging data-level
skip connections to facilitate data generation and mitigate data information
vanishing. This approach maintains a balance between newly acquired knowledge
through pixel space optimization and existing core local information
identification within raw data modalities, specifically for the dataset
distillation task. Furthermore, by incorporating optimization-level
refinements, our method significantly improves computational efficiency,
achieving superior performance while reducing training time and peak GPU memory
usage by 50%. Consequently, the proposed method Fast and Accurate Data Residual
Matching for Dataset Distillation (FADRM) establishes a new state-of-the-art,
demonstrating substantial improvements over existing methods across multiple
dataset benchmarks in both efficiency and effectiveness. For instance, with
ResNet-18 as the student model and a 0.8% compression ratio on ImageNet-1K, the
method achieves 47.7% test accuracy in single-model dataset distillation and
50.0% in multi-model dataset distillation, surpassing RDED by +5.7% and
outperforming state-of-the-art multi-model approaches, EDC and CV-DD, by +1.4%
and +4.0%. Code is available at: https://github.com/Jiacheng8/FADRM.

</details>


### [182] [MReg: A Novel Regression Model with MoE-based Video Feature Mining for Mitral Regurgitation Diagnosis](https://arxiv.org/abs/2506.23648)
*Zhe Liu,Yuhao Huang,Lian Liu,Chengrui Zhang,Haotian Lin,Tong Han,Zhiyuan Zhu,Yanlin Chen,Yuerui Chen,Dong Ni,Zhongshan Gou,Xin Yang*

Main category: cs.CV

TL;DR: 本文提出了一种自动化二尖瓣反流诊断模型MReg，用于分析4腔心室彩色多普勒超声视频，并在大规模数据集上取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有的二尖瓣反流智能诊断方法难以适应临床工作流程，且在准确性和可解释性方面存在欠缺。

Method: 将MR诊断建模为回归任务，并设计特征选择与放大机制结合专家混合模型思想，提取分类级别特征并提高诊断性能。

Result: 在包含1868例、标有三级反流标签的大规模数据集上，MReg在二尖瓣反流诊断中表现优于其他方法。

Conclusion: MReg模型能够更好地符合临床环境需求，在二尖瓣反流的自动诊断和严重程度评估中展现了优异的性能。

Abstract: Color Doppler echocardiography is a crucial tool for diagnosing mitral
regurgitation (MR). Recent studies have explored intelligent methods for MR
diagnosis to minimize user dependence and improve accuracy. However, these
approaches often fail to align with clinical workflow and may lead to
suboptimal accuracy and interpretability. In this study, we introduce an
automated MR diagnosis model (MReg) developed on the 4-chamber cardiac color
Doppler echocardiography video (A4C-CDV). It follows comprehensive feature
mining strategies to detect MR and assess its severity, considering clinical
realities. Our contribution is threefold. First, we formulate the MR diagnosis
as a regression task to capture the continuity and ordinal relationships
between categories. Second, we design a feature selection and amplification
mechanism to imitate the sonographer's diagnostic logic for accurate MR
grading. Third, inspired by the Mixture-of-Experts concept, we introduce a
feature summary module to extract the category-level features, enhancing the
representational capacity for more accurate grading. We trained and evaluated
our proposed MReg on a large in-house A4C-CDV dataset comprising 1868 cases
with three graded regurgitation labels. Compared to other weakly supervised
video anomaly detection and supervised classification methods, MReg
demonstrated superior performance in MR diagnosis. Our code is available at:
https://github.com/cskdstz/MReg.

</details>


### [183] [Towards Markerless Intraoperative Tracking of Deformable Spine Tissue](https://arxiv.org/abs/2506.23657)
*Connor Daly,Elettra Marconi,Marco Riva,Jinendra Ekanayake,Daniel S. Elson,Ferdinando Rodriguez y Baena*

Main category: cs.CV

TL;DR: 本文研究了基于RGB-D成像的术中骨科组织追踪，提出SpineAlign系统和一个多任务框架CorrespondNet来完成数据捕获和注册任务。


<details>
  <summary>Details</summary>
Motivation: 现有骨骼追踪方法复杂且耗时，开发简化并减少手术时间和复杂性的非标记追踪技术迫在眉睫。

Method: 构建首个脊柱外科术中临床RGB-D数据集，并开发了SpineAlign系统及CorrespondNet多任务框架，用于分割和关键区域预测。

Result: 成功建立了术前和术中脊柱状态间变形的捕获系统，并开发了用于注册关键区域预测的多任务深度学习框架。

Conclusion: 由于SpineAlign和CorrespondNet的提出，该研究表明对术中组织追踪的非标记方法取得了显著进展，为未来临床应用铺平了道路。

Abstract: Consumer-grade RGB-D imaging for intraoperative orthopedic tissue tracking is
a promising method with high translational potential. Unlike bone-mounted
tracking devices, markerless tracking can reduce operating time and complexity.
However, its use has been limited to cadaveric studies. This paper introduces
the first real-world clinical RGB-D dataset for spine surgery and develops
SpineAlign, a system for capturing deformation between preoperative and
intraoperative spine states. We also present an intraoperative segmentation
network trained on this data and introduce CorrespondNet, a multi-task
framework for predicting key regions for registration in both intraoperative
and preoperative scenes.

</details>


### [184] [Partial Forward Blocking: A Novel Data Pruning Paradigm for Lossless Training Acceleration](https://arxiv.org/abs/2506.23674)
*Dongyue Wu,Zilin Guo,Jialong Zuo,Nong Sang,Changxin Gao*

Main category: cs.CV

TL;DR: 提出了一种称为Partial Forward Blocking (PFB)的新框架，用于无损的训练加速，通过样本重要性评估和动态样本筛选实现更高效的模型训练。


<details>
  <summary>Details</summary>
Motivation: 现有的数据剪枝方法虽然能加速训练，但依赖于梯度或代理模型，带来了额外的计算成本，因此需要一种有效但无需额外开销的方法。

Method: 利用目标模型浅层提取的特征动态评估样本重要性，根据重要性筛选样本，未通过筛选的样本不参与后续的深层前向传播和梯度回传计算；基于概率密度估计模块动态优先处理更稀少的样本。

Result: 在ImageNet数据集上削减40%数据的前提下实现了0.5%的准确性提升与33%的训练时间缩减。

Conclusion: PFB框架显著提升了模型训练的效率和效果，并证明了其在无损加速领域的潜力。

Abstract: The ever-growing size of training datasets enhances the generalization
capability of modern machine learning models but also incurs exorbitant
computational costs. Existing data pruning approaches aim to accelerate
training by removing those less important samples. However, they often rely on
gradients or proxy models, leading to prohibitive additional costs of gradient
back-propagation and proxy model training. In this paper, we propose Partial
Forward Blocking (PFB), a novel framework for lossless training acceleration.
The efficiency of PFB stems from its unique adaptive pruning pipeline: sample
importance is assessed based on features extracted from the shallow layers of
the target model. Less important samples are then pruned, allowing only the
retained ones to proceed with the subsequent forward pass and loss
back-propagation. This mechanism significantly reduces the computational
overhead of deep-layer forward passes and back-propagation for pruned samples,
while also eliminating the need for auxiliary backward computations and proxy
model training. Moreover, PFB introduces probability density as an indicator of
sample importance. Combined with an adaptive distribution estimation module,
our method dynamically prioritizes relatively rare samples, aligning with the
constantly evolving training state. Extensive experiments demonstrate the
significant superiority of PFB in performance and speed. On ImageNet, PFB
achieves a 0.5% accuracy improvement and 33% training time reduction with 40%
data pruned.

</details>


### [185] [Pruning by Block Benefit: Exploring the Properties of Vision Transformer Blocks during Domain Adaptation](https://arxiv.org/abs/2506.23675)
*Patrick Glandorf,Bodo Rosenhahn*

Main category: cs.CV

TL;DR: 本文提出了一种名为P3B的剪枝方法，旨在通过全局指标有效分配参数资源，同时支持重新激活对任务敏感的后期收敛区块。在高剪枝率下仍能保持高性能。


<details>
  <summary>Details</summary>
Motivation: 目前的视觉Transformer虽然在性能上表现卓越，但高计算成本使其在资源有限的硬件上不切实际；传统剪枝方法对未知数据域的权重重要性评估不足，导致资源分配次优。

Method: 提出P3B方法，通过区块的相对贡献来分配参数资源，并设定基于全局性能指标的分层保持率，确保支持任务敏感区块的激活。

Result: 经过大量实验证明，P3B在迁移学习任务和高稀疏剪枝（70%的参数削减）中表现为最先进方法，仅损失0.64%的准确率。

Conclusion: P3B方法在增强视觉Transformer剪枝效率的同时，显著减少计算成本，并能在高稀疏率情况下保持较小精度损失，展现了其在资源有限场景中的实用性。

Abstract: Vision Transformer have set new benchmarks in several tasks, but these models
come with the lack of high computational costs which makes them impractical for
resource limited hardware. Network pruning reduces the computational complexity
by removing less important operations while maintaining performance. However,
pruning a model on an unseen data domain, leads to a misevaluation of weight
significance, resulting in suboptimal resource assignment. In this work, we
find that task-sensitive layers initially fail to improve the feature
representation on downstream tasks, leading to performance loss for early
pruning decisions. To address this problem, we introduce Pruning by Block
Benefit (P3B), a pruning method that utilizes the relative contribution on
block level to globally assign parameter resources. P3B identifies low-impact
components to reduce parameter allocation while preserving critical ones.
Classical pruning mask optimization struggles to reactivate zero-mask-elements.
In contrast, P3B sets a layerwise keep ratio based on global performance
metrics, ensuring the reactivation of late-converging blocks. We show in
extensive experiments that P3B is a state of the art pruning method with most
noticeable gains in transfer learning tasks. Notably, P3B is able to conserve
high performance, even in high sparsity regimes of 70% parameter reduction
while only losing 0.64% in accuracy.

</details>


### [186] [A Unified Framework for Stealthy Adversarial Generation via Latent Optimization and Transferability Enhancement](https://arxiv.org/abs/2506.23676)
*Gaozheng Pei,Ke Ma,Dongpeng Zhang,Chengzhi Sun,Qianqian Xu,Qingming Huang*

Main category: cs.CV

TL;DR: 本文提出了一种统一框架，将传统的可迁移增强策略无缝整合到基于扩散模型的对抗样本生成方法中，并证明了其在深度伪造检测任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的对抗样本生成方法在任务上泛化能力有限，尤其是在深度伪造检测等领域，而传统的增强对抗样本迁移能力的方法又难以适配。

Method: 通过设计一个统一框架，将传统迁移能力增强策略与扩散模型生成对抗样本的方法有效结合。

Result: 我们的方法在ACM MM25首届“深度伪造检测对抗攻击挑战赛”中获得了第一名。

Conclusion: 所提框架有效拓宽了扩散模型生成对抗样本在各种下游任务中的适用性，尤其在深度伪造检测场景中表现优秀。

Abstract: Due to their powerful image generation capabilities, diffusion-based
adversarial example generation methods through image editing are rapidly
gaining popularity. However, due to reliance on the discriminative capability
of the diffusion model, these diffusion-based methods often struggle to
generalize beyond conventional image classification tasks, such as in Deepfake
detection. Moreover, traditional strategies for enhancing adversarial example
transferability are challenging to adapt to these methods. To address these
challenges, we propose a unified framework that seamlessly incorporates
traditional transferability enhancement strategies into diffusion model-based
adversarial example generation via image editing, enabling their application
across a wider range of downstream tasks. Our method won first place in the
"1st Adversarial Attacks on Deepfake Detectors: A Challenge in the Era of
AI-Generated Media" competition at ACM MM25, which validates the effectiveness
of our approach.

</details>


### [187] [SynMotion: Semantic-Visual Adaptation for Motion Customized Video Generation](https://arxiv.org/abs/2506.23690)
*Shuai Tan,Biao Gong,Yujie Wei,Shiwei Zhang,Zhuoxin Liu,Dandan Zheng,Jingdong Chen,Yan Wang,Hao Ouyang,Kecheng Zheng,Yujun Shen*

Main category: cs.CV

TL;DR: 扩散式视频运动定制在少量视频样本中获得人体运动表征，并通过精确的文本条件实现任意主体的迁移。现有方法对语义对齐和视觉复杂性处理不足，为此提出SynMotion模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时处理语义对齐和视觉复杂性，造成动作生成效果有限。

Method: SynMotion整合语义引导与视觉自适应，提出双嵌入语义理解机制、参数高效的运动适配器以及特定的交替优化训练策略。

Result: SynMotion在T2V和I2V等实验中优于现有基线模型，提出的MotionBench提供了多样的运动模式评估机制。

Conclusion: SynMotion模型在运动定制视频生成中展现了更高的运动保真度和时间一致性，同时保留了语义多样性，解决了模型的关键问题并提供新基准。

Abstract: Diffusion-based video motion customization facilitates the acquisition of
human motion representations from a few video samples, while achieving
arbitrary subjects transfer through precise textual conditioning. Existing
approaches often rely on semantic-level alignment, expecting the model to learn
new motion concepts and combine them with other entities (e.g., ''cats'' or
''dogs'') to produce visually appealing results. However, video data involve
complex spatio-temporal patterns, and focusing solely on semantics cause the
model to overlook the visual complexity of motion. Conversely, tuning only the
visual representation leads to semantic confusion in representing the intended
action. To address these limitations, we propose SynMotion, a new
motion-customized video generation model that jointly leverages semantic
guidance and visual adaptation. At the semantic level, we introduce the
dual-embedding semantic comprehension mechanism which disentangles subject and
motion representations, allowing the model to learn customized motion features
while preserving its generative capabilities for diverse subjects. At the
visual level, we integrate parameter-efficient motion adapters into a
pre-trained video generation model to enhance motion fidelity and temporal
coherence. Furthermore, we introduce a new embedding-specific training strategy
which \textbf{alternately optimizes} subject and motion embeddings, supported
by the manually constructed Subject Prior Video (SPV) training dataset. This
strategy promotes motion specificity while preserving generalization across
diverse subjects. Lastly, we introduce MotionBench, a newly curated benchmark
with diverse motion patterns. Experimental results across both T2V and I2V
settings demonstrate that \method outperforms existing baselines. Project page:
https://lucaria-academy.github.io/SynMotion/

</details>


### [188] [Single Image Test-Time Adaptation via Multi-View Co-Training](https://arxiv.org/abs/2506.23705)
*Smriti Joshi,Richard Osuala,Lidia Garrucho,Kaisar Kushibar,Dimitri Kessler,Oliver Diaz,Karim Lekadir*

Main category: cs.CV

TL;DR: 本文提出了一种基于Patch的多视角协同训练方法（Patch-Based Multi-View Co-Training），用于实现单张测试时的域自适应。在乳腺磁共振成像数据集上的实验结果显示，该方法在没有目标域监督的情况下仍能取得接近监督基准的性能，并优于当前最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时域自适应方法依赖于大规模目标域数据，这在医疗场景中通常不可行。此外，这些方法通常仅适用于二维图像，未充分利用医学影像的体积信息。本文旨在克服这些局限，提出一种适用于单张测试图像的自适应方法。

Method: 本文方法基于Patch的多视角协同训练，通过不确定性引导的自训练实现特征和预测的一致性。该方法专注于体积分割，特别是在目标域仅提供单张测试时图像的情况下。

Result: 在乳腺肿瘤分割任务上验证了该方法，相较于现有的最先进方法，平均在Dice相似系数上提升了3.75%，并且接近有监督的性能上限。

Conclusion: 本文证明了提出的方法可以在测试时仅需单张图像的情况下，实现高效的域自适应和高质量的体积分割，并提供了一个易于集成的代码库。

Abstract: Test-time adaptation enables a trained model to adjust to a new domain during
inference, making it particularly valuable in clinical settings where such
on-the-fly adaptation is required. However, existing techniques depend on large
target domain datasets, which are often impractical and unavailable in medical
scenarios that demand per-patient, real-time inference. Moreover, current
methods commonly focus on two-dimensional images, failing to leverage the
volumetric richness of medical imaging data. Bridging this gap, we propose a
Patch-Based Multi-View Co-Training method for Single Image Test-Time
adaptation. Our method enforces feature and prediction consistency through
uncertainty-guided self-training, enabling effective volumetric segmentation in
the target domain with only a single test-time image. Validated on three
publicly available breast magnetic resonance imaging datasets for tumor
segmentation, our method achieves performance close to the upper bound
supervised benchmark while also outperforming all existing state-of-the-art
methods, on average by a Dice Similarity Coefficient of 3.75%. We publicly
share our accessible codebase, readily integrable with the popular nnUNet
framework, at https://github.com/smriti-joshi/muvi.git.

</details>


### [189] [Subjective Camera: Bridging Human Cognition and Visual Reconstruction through Sequence-Aware Sketch-Guided Diffusion](https://arxiv.org/abs/2506.23711)
*Haoyang Chen,Dongfang Sun,Caoyuan Ma,Shiqin Wang,Kewei Zhang,Zheng Wang,Zhixiang Wang*

Main category: cs.CV

TL;DR: 提出了一种称为“主观相机”的新范式，通过结合语言描述和草图，重建场景成真实感图像，克服现有方法中语言和草图的双重局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理用户主观输入、平面草图与三维先验之间的差异、以及草图质量敏感问题上存在不足，现有解决方法成本高且对草图要求过高。

Method: 通过概念序列生成，使用文本奖励优化建立视觉先验，并采用无训练的方式按序生成，同时优化潜变量以连接草图与扩散模型的三维先验。引入分层奖励框架，无需用户的精细绘图技能即可生成结果。

Result: 全面评估表明，本方法在语义和空间一致性方面达到了当前最优性能，并支持低门槛输入的真实感场景重建。

Conclusion: 本文方法有效解决了语言与草图的模糊性局限，为基于主观印象生成真实感图像提供了一种新颖且高效的解决方案。

Abstract: We propose Subjective Camera, a human-as-imaging-device paradigm that
reconstructs real-world scenes from mental impressions through synergistic use
of verbal descriptions and progressive rough sketches. This approach overcomes
dual limitations of language ambiguity and sketch abstraction by treating the
user's drawing sequence as priors, effectively translating subjective
perceptual expectations into photorealistic images.
  Existing approaches face three fundamental barriers: (1) user-specific
subjective input biases, (2) huge modality gap between planar sketch and 3D
priors in diffusion, and (3) sketch quality-sensitive performance degradation.
Current solutions either demand resource-intensive model adaptation or impose
impractical requirements on sketch precision.
  Our framework addresses these challenges through concept-sequential
generation. (1) We establish robust appearance priors through text-reward
optimization, and then implement sequence-aware disentangled generation that
processes concepts in sketching order; these steps accommodate user-specific
subjective expectation in a train-free way. (2) We employ latent optimization
that effectively bridges the modality gap between planar sketches and 3D priors
in diffusion. (3) Our hierarchical reward-guided framework enables the use of
rough sketches without demanding artistic expertise. Comprehensive evaluation
across diverse datasets demonstrates that our approach achieves
state-of-the-art performance in maintaining both semantic and spatial
coherence.

</details>


### [190] [Proteus-ID: ID-Consistent and Motion-Coherent Video Customization](https://arxiv.org/abs/2506.23729)
*Guiyu Zhang,Chen Shi,Zijian Jiang,Xunzhi Xiang,Jingjing Qian,Shaoshuai Shi,Li Jiang*

Main category: cs.CV

TL;DR: Proteus-ID提出了一种基于扩散模型的视频身份定制框架，通过多模态身份融合、时间感知身份注入和自适应运动学习，解决了维持身份一致性和生成自然运动的问题，并引入了Proteus-Bench数据集作为基准。


<details>
  <summary>Details</summary>
Motivation: 解决视频身份定制中身份一致性与文本描述对齐和生成自然流畅运动的难题。

Method: 提出多模态身份融合模块（MIF）统一视觉和文本线索，时间感知身份注入机制（TAII）动态调控身份条件，以及自适应运动学习策略（AML）基于光流图优化运动真实感；并构建Proteus-Bench数据集辅助训练与评估。

Result: Proteus-ID在身份保留、文本对齐及运动质量方面优于现有方法，树立了视频身份定制的新基准。

Conclusion: Proteus-ID提供了一种性能优越的视频身份定制解决方案，为该领域的研究奠定了基础，相关代码和数据已公开。

Abstract: Video identity customization seeks to synthesize realistic, temporally
coherent videos of a specific subject, given a single reference image and a
text prompt. This task presents two core challenges: (1) maintaining identity
consistency while aligning with the described appearance and actions, and (2)
generating natural, fluid motion without unrealistic stiffness. To address
these challenges, we introduce Proteus-ID, a novel diffusion-based framework
for identity-consistent and motion-coherent video customization. First, we
propose a Multimodal Identity Fusion (MIF) module that unifies visual and
textual cues into a joint identity representation using a Q-Former, providing
coherent guidance to the diffusion model and eliminating modality imbalance.
Second, we present a Time-Aware Identity Injection (TAII) mechanism that
dynamically modulates identity conditioning across denoising steps, improving
fine-detail reconstruction. Third, we propose Adaptive Motion Learning (AML), a
self-supervised strategy that reweights the training loss based on
optical-flow-derived motion heatmaps, enhancing motion realism without
requiring additional inputs. To support this task, we construct Proteus-Bench,
a high-quality dataset comprising 200K curated clips for training and 150
individuals from diverse professions and ethnicities for evaluation. Extensive
experiments demonstrate that Proteus-ID outperforms prior methods in identity
preservation, text alignment, and motion quality, establishing a new benchmark
for video identity customization. Codes and data are publicly available at
https://grenoble-zhang.github.io/Proteus-ID/.

</details>


### [191] [Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?](https://arxiv.org/abs/2506.23751)
*Annika Mütze,Sadia Ilyas,Christian Dörpelkus,Matthias Rottmann*

Main category: cs.CV

TL;DR: 本研究探讨开放词汇目标检测器在合成数据集上的表现，并设计了两种基于稳定扩散的自动管线，用于生成具有语义多样性的不寻常物体进行测试，揭示检测器的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究开放词汇目标检测器在安全关键应用中的潜在局限性，利用合成数据评估模型推广能力并找到系统性的失效模式。

Method: 设计两种自动化管线，结合WordNet和ChatGPT从语义出发生成多样化的合成图像数据，通过Stable Diffusion技术对不寻常物体进行修复及评估，并对多个开放词汇目标检测器及传统检测器进行比较。

Result: 发现这些检测器在忽略物体方面存在不足，并显示离开语义时模型更多地依赖物体位置。这为优化模型及有效数据采集策略提供了方向。

Conclusion: 合成数据能够有效挑战开放词汇检测器，暴露其依赖对象位置而非语义的缺陷，为模型改进和数据采集方向提供了重要启示。

Abstract: Open-vocabulary object detectors such as Grounding DINO are trained on vast
and diverse data, achieving remarkable performance on challenging datasets. Due
to that, it is unclear where to find their limitations, which is of major
concern when using in safety-critical applications. Real-world data does not
provide sufficient control, required for a rigorous evaluation of model
generalization. In contrast, synthetically generated data allows to
systematically explore the boundaries of model competence/generalization. In
this work, we address two research questions: 1) Can we challenge
open-vocabulary object detectors with generated image content? 2) Can we find
systematic failure modes of those models? To address these questions, we design
two automated pipelines using stable diffusion to inpaint unusual objects with
high diversity in semantics, by sampling multiple substantives from WordNet and
ChatGPT. On the synthetically generated data, we evaluate and compare multiple
open-vocabulary object detectors as well as a classical object detector. The
synthetic data is derived from two real-world datasets, namely LostAndFound, a
challenging out-of-distribution (OOD) detection benchmark, and the NuImages
dataset. Our results indicate that inpainting can challenge open-vocabulary
object detectors in terms of overlooking objects. Additionally, we find a
strong dependence of open-vocabulary models on object location, rather than on
object semantics. This provides a systematic approach to challenge
open-vocabulary models and gives valuable insights on how data could be
acquired to effectively improve these models.

</details>


### [192] [Visual Textualization for Image Prompted Object Detection](https://arxiv.org/abs/2506.23785)
*Yongjian Wu,Yang Zhou,Jiya Saiyin,Bingzheng Wei,Yan Xu*

Main category: cs.CV

TL;DR: VisTex-OVLM 提出了一种通过点视觉化增强少样本物体检测的模型。


<details>
  <summary>Details</summary>
Motivation: 为解决传统模型面对稀有类别和训练数据稀缺的问题，同时保持其物体与文本对齐性能。

Method: 通过将视觉样本投射到文本特征空间内，结合多尺度文本化模块和多阶段融合策略，生成指导目标检测的文本化视觉令牌。

Result: 在与训练数据重叠最小的数据集上表现优越，并在 PASCAL VOC 和 MSCOCO 少样本基准上实现了最新性能。

Conclusion: VisTex-OVLM 改善了稀有类别检测的能力，提供了一种有效的点视觉化方法，同时保持了模型的架构和广泛应用性能。

Abstract: We propose VisTex-OVLM, a novel image prompted object detection method that
introduces visual textualization -- a process that projects a few visual
exemplars into the text feature space to enhance Object-level Vision-Language
Models' (OVLMs) capability in detecting rare categories that are difficult to
describe textually and nearly absent from their pre-training data, while
preserving their pre-trained object-text alignment. Specifically, VisTex-OVLM
leverages multi-scale textualizing blocks and a multi-stage fusion strategy to
integrate visual information from visual exemplars, generating textualized
visual tokens that effectively guide OVLMs alongside text prompts. Unlike
previous methods, our method maintains the original architecture of OVLM,
maintaining its generalization capabilities while enhancing performance in
few-shot settings. VisTex-OVLM demonstrates superior performance across
open-set datasets which have minimal overlap with OVLM's pre-training data and
achieves state-of-the-art results on few-shot benchmarks PASCAL VOC and MSCOCO.
The code will be released at https://github.com/WitGotFlg/VisTex-OVLM.

</details>


### [193] [Controllable Reference-Based Real-World Remote Sensing Image Super-Resolution with Generative Diffusion Priors](https://arxiv.org/abs/2506.23801)
*Ce Wang,Wanjie Sun*

Main category: cs.CV

TL;DR: 提出了一种称为CRefDiff的新模型，用于遥感图像超分辨率，解决了传统方法在实际复杂场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 当前参考式超分辨率方法在处理跨传感器分辨率差异及显著土地覆盖变化时表现有限。

Method: 基于Stable Diffusion模型，并引入双分支融合机制及改进策略如"Better Start"，显著加速推理过程。

Result: CRefDiff在新数据集Real-RefRSSRD上表现优越，同时在场景分类和语义分割等下游任务中效果显著。

Conclusion: CRefDiff在实际遥感图像超分辨率问题上实现了先进性能，且该方法的灵活性与高效性使其具有广阔的应用潜力。

Abstract: Super-resolution (SR) techniques can enhance the spatial resolution of remote
sensing images by utilizing low-resolution (LR) images to reconstruct
high-resolution (HR) images, enabling more efficient large-scale earth
observation applications. While single-image super-resolution (SISR) methods
have shown progress, reference-based super-resolution (RefSR) offers superior
performance by incorporating historical HR images alongside current LR
observations. However, existing RefSR methods struggle with real-world
complexities, such as cross-sensor resolution gap and significant land cover
changes, often leading to under-generation or over-reliance on reference image.
To address these challenges, we propose CRefDiff, a novel controllable
reference-based diffusion model for real-world remote sensing image SR. To
address the under-generation problem, CRefDiff is built upon the pretrained
Stable Diffusion model, leveraging its powerful generative prior to produce
accurate structures and textures. To mitigate over-reliance on the reference,
we introduce a dual-branch fusion mechanism that adaptively integrates both
local and global information from the reference image. Moreover, this novel
dual-branch design enables reference strength control during inference,
enhancing interactivity and flexibility of the model. Finally, a strategy named
Better Start is proposed to significantly reduce the number of denoising steps,
thereby accelerating the inference process. To support further research, we
introduce Real-RefRSSRD, a new real-world RefSR dataset for remote sensing
images, consisting of HR NAIP and LR Sentinel-2 image pairs with diverse land
cover changes and significant temporal gaps. Extensive experiments on
Real-RefRSSRD show that CRefDiff achieves state-of-the-art performance across
various metrics and improves downstream tasks such as scene classification and
semantic segmentation.

</details>


### [194] [Towards Initialization-free Calibrated Bundle Adjustment](https://arxiv.org/abs/2506.23808)
*Carl Olsson,Amanda Nilsson*

Main category: cs.CV

TL;DR: 该研究提出了一种利用已知相机校准信息进行近度量重建的方法，通过集成旋转平均技术优化目标函数，实验表明该方法具有高概率收敛性，且精度高。


<details>
  <summary>Details</summary>
Motivation: 以往的初始化自由BA方法难以利用相机校准信息，只能生成投影变换下的重建结果，需要更多数据支持。

Method: 通过引入只保留相似变换不变性的成对相对旋转估计，结合pOSE框架集成旋转平均，实现初始化自由且能利用校准信息的BA方法。

Result: 实验结果表明，新方法能在随机初始条件下以高概率收敛到全局最小值，并生成准确的近度量重建结果。

Conclusion: 该方法通过利用相机校准和旋转平均技术，成功改进了初始化自由的重建质量，为基于校准的SfM提供了更有效的解决方案。

Abstract: A recent series of works has shown that initialization-free BA can be
achieved using pseudo Object Space Error (pOSE) as a surrogate objective. The
initial reconstruction-step optimizes an objective where all terms are
projectively invariant and it cannot incorporate knowledge of the camera
calibration. As a result, the solution is only determined up to a projective
transformation of the scene and the process requires more data for successful
reconstruction.
  In contrast, we present a method that is able to use the known camera
calibration thereby producing near metric solutions, that is, reconstructions
that are accurate up to a similarity transformation. To achieve this we
introduce pairwise relative rotation estimates that carry information about
camera calibration. These are only invariant to similarity transformations,
thus encouraging solutions that preserve metric features of the real scene. Our
method can be seen as integrating rotation averaging into the pOSE framework
striving towards initialization-free calibrated SfM.
  Our experimental evaluation shows that we are able to reliably optimize our
objective, achieving convergence to the global minimum with high probability
from random starting solutions, resulting in accurate near metric
reconstructions.

</details>


### [195] [MadCLIP: Few-shot Medical Anomaly Detection with CLIP](https://arxiv.org/abs/2506.23810)
*Mahshid Shiri,Cigdem Beyan,Vittorio Murino*

Main category: cs.CV

TL;DR: 本文提出了一种创新的少样本异常检测方法，利用CLIP模型进行医学数据的异常分类和分割，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 探索一种高效的少样本异常检测方法，解决当前方法对合成数据依赖的问题，同时改进医学数据中的语义对齐能力。

Method: 采用双分支设计，通过CLIP模型的视觉编码器实现正常和异常特征分离；结合可学习的文本提示以增强视觉特征的语义对齐；引入SigLIP损失优化图像与未配对文本提示的多对一关系。

Result: 在多个医学数据集上验证了该方法，异常分类和分割表现优于现有方法，在同数据集及跨数据集评估中均表现出色。该方法未依赖合成数据或存储器组件。

Conclusion: 该方法提供了一种高效的少样本异常检测解决方案，通过创新设计和損失函数适配，增强了医学数据处理能力。

Abstract: An innovative few-shot anomaly detection approach is presented, leveraging
the pre-trained CLIP model for medical data, and adapting it for both
image-level anomaly classification (AC) and pixel-level anomaly segmentation
(AS). A dual-branch design is proposed to separately capture normal and
abnormal features through learnable adapters in the CLIP vision encoder. To
improve semantic alignment, learnable text prompts are employed to link visual
features. Furthermore, SigLIP loss is applied to effectively handle the
many-to-one relationship between images and unpaired text prompts, showcasing
its adaptation in the medical field for the first time. Our approach is
validated on multiple modalities, demonstrating superior performance over
existing methods for AC and AS, in both same-dataset and cross-dataset
evaluations. Unlike prior work, it does not rely on synthetic data or memory
banks, and an ablation study confirms the contribution of each component. The
code is available at https://github.com/mahshid1998/MadCLIP.

</details>


### [196] [Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model](https://arxiv.org/abs/2506.23822)
*Shiming Chen,Bowen Duan,Salman Khan,Fahad Shahbaz Khan*

Main category: cs.CV

TL;DR: LaZSL是一种改进的视觉-语言模型，用于零样本学习，增强了解释性和精度，代码已开源。


<details>
  <summary>Details</summary>
Motivation: 目前的视觉-语言模型缺乏可解释性，难以解释大规模视觉/文本数据计算的结果，亟需能将局部视觉特征与语言属性对齐的方法。

Method: 提出LaZSL，通过局部视觉-语义对齐和最优传输，将视觉区域与属性对齐，无需额外训练即可实现可解释的零样本学习。

Result: 实验表明，LaZSL在解释性、准确性和领域泛化能力方面均有显著提升。

Conclusion: LaZSL实现了解释性与性能的平衡，为零样本学习提供了新方法，公开代码方便进一步研究。

Abstract: Large-scale vision-language models (VLMs), such as CLIP, have achieved
remarkable success in zero-shot learning (ZSL) by leveraging large-scale
visual-text pair datasets. However, these methods often lack interpretability,
as they compute the similarity between an entire query image and the embedded
category words, making it difficult to explain their predictions. One approach
to address this issue is to develop interpretable models by integrating
language, where classifiers are built using discrete attributes, similar to
human perception. This introduces a new challenge: how to effectively align
local visual features with corresponding attributes based on pre-trained VLMs.
To tackle this, we propose LaZSL, a locally-aligned vision-language model for
interpretable ZSL. LaZSL employs local visual-semantic alignment via optimal
transport to perform interaction between visual regions and their associated
attributes, facilitating effective alignment and providing interpretable
similarity without the need for additional training. Extensive experiments
demonstrate that our method offers several advantages, including enhanced
interpretability, improved accuracy, and strong domain generalization. Codes
available at: https://github.com/shiming-chen/LaZSL.

</details>


### [197] [Flash-VStream: Efficient Real-Time Understanding for Long Video Streams](https://arxiv.org/abs/2506.23825)
*Haoji Zhang,Yiqin Wang,Yansong Tang,Yong Liu,Jiashi Feng,Xiaojie Jin*

Main category: cs.CV

TL;DR: Flash-VStream提升了多模态语言模型对长视频理解的性能及效率，显著降低了推理延迟。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在长视频理解上面临计算和内存成本过高的问题，同时现有方法常将长视频与短视频同等对待，难以高效处理超长视频内容。

Method: 提出Flash-VStream模型，包含一个低容量上下文记忆模块，用于汇聚长时间上下文信息和建模信息密度分布；以及一个高容量增强记忆模块，用于根据信息分布检索详细信息，提升视频处理效率。

Result: 模型在长视频基准和综合视频基准上的多个数据集（如EgoSchema、MLVU等）表现出最先进的性能和更高的效率。

Conclusion: Flash-VStream通过创新的记忆模块设计，有效地解决了长视频理解的效率低下和推理延迟问题，展现出卓越的实际应用潜力。

Abstract: Benefiting from the advances in large language models and cross-modal
alignment, existing multimodal large language models have achieved prominent
performance in image and short video understanding. However, the understanding
of long videos is still challenging, as their long-context nature results in
significant computational and memory overhead. Most existing work treats long
videos in the same way as short videos, which is inefficient for real-world
applications and hard to generalize to even longer videos. To address these
issues, we propose Flash-VStream, an efficient video language model capable of
processing extremely long videos and responding to user queries in real time.
Particularly, we design a Flash Memory module, containing a low-capacity
context memory to aggregate long-context temporal information and model the
distribution of information density, and a high-capacity augmentation memory to
retrieve detailed spatial information based on this distribution. Compared to
existing models, Flash-VStream achieves significant reductions in inference
latency. Extensive experiments on long video benchmarks and comprehensive video
benchmarks, i.e., EgoSchema, MLVU, LVBench, MVBench and Video-MME, demonstrate
the state-of-the-art performance and outstanding efficiency of our method. Code
is available at https://github.com/IVGSZ/Flash-VStream.

</details>


### [198] [Spatially Gene Expression Prediction using Dual-Scale Contrastive Learning](https://arxiv.org/abs/2506.23827)
*Mingcheng Qu,Yuncong Wu,Donglin Di,Yue Gao,Tonghua Su,Yang Song,Lei Fan*

Main category: cs.CV

TL;DR: 本文提出NH2ST框架，通过结合空间上下文、病理和基因模式，实现了基因表达的高效预测，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法预测基因表达时忽略了邻域信息和复杂的跨模态关系，因此需要一种集成空间上下文和多模态信息的解决方案。

Method: 提出NH2ST框架，采用查询支路和邻域支路处理目标区域和邻近区域数据，通过交叉注意力和对比学习捕获病理和基因表达之间的内在关联。

Result: 在六个数据集上的实验结果表明，该模型在PCC指标上相较现有方法提升了超过20%。

Conclusion: NH2ST框架能够显著提升基因表达预测的精确性，并为空间转录组学提供一种低成本、复杂性低的替代方案。

Abstract: Spatial transcriptomics (ST) provides crucial insights into tissue
micro-environments, but is limited to its high cost and complexity. As an
alternative, predicting gene expression from pathology whole slide images (WSI)
is gaining increasing attention. However, existing methods typically rely on
single patches or a single pathology modality, neglecting the complex spatial
and molecular interactions between target and neighboring information (e.g.,
gene co-expression). This leads to a failure in establishing connections among
adjacent regions and capturing intricate cross-modal relationships. To address
these issues, we propose NH2ST, a framework that integrates spatial context and
both pathology and gene modalities for gene expression prediction. Our model
comprises a query branch and a neighbor branch to process paired target patch
and gene data and their neighboring regions, where cross-attention and
contrastive learning are employed to capture intrinsic associations and ensure
alignments between pathology and gene expression. Extensive experiments on six
datasets demonstrate that our model consistently outperforms existing methods,
achieving over 20% in PCC metrics. Codes are available at
https://github.com/MCPathology/NH2ST

</details>


### [199] [Low-latency vision transformers via large-scale multi-head attention](https://arxiv.org/abs/2506.23832)
*Ronit D. Gross,Tal Halevi,Ella Koresh,Yarden Tzach,Ido Kanter*

Main category: cs.CV

TL;DR: 研究发现多头注意力机制（MHA）在Transformer中存在自发对称性破缺现象，并提出可利用单头性能矩阵（SHP）对大规模MHA进行量化以提升分类准确性。


<details>
  <summary>Details</summary>
Motivation: 探讨多头注意力机制在分类任务中的表现，量化其单节点性能及其在对称性破缺中的作用，从而揭示提升分类准确性的潜在机制。

Method: 引入单头性能（SHP）矩阵，将其应用于大规模多头注意力机制（LS-MHA）中，并替换部分Transformer初始层为卷积层以降低延迟。此外，利用CIFAR-100数据集验证这些新型卷积Transformer架构的性能。

Result: 发现SHP矩阵表现为多个独立的标签聚类块，通过增加信噪比提高了分类精度，并提出多种不同的ViT架构，其组合显示出比CNN更高的准确性，且延迟显著减少。

Conclusion: 通过量化单头性能并结合卷积与Transformer层，可以加速深度学习任务的训练，并提升分类准确性。这一机制在自然语言处理任务中的潜力值得进一步研究。

Abstract: The emergence of spontaneous symmetry breaking among a few heads of
multi-head attention (MHA) across transformer blocks in classification tasks
was recently demonstrated through the quantification of single-nodal
performance (SNP). This finding indicates that each head focuses its attention
on a subset of labels through cooperation among its SNPs. This underlying
learning mechanism is generalized to large-scale MHA (LS-MHA) using a single
matrix value representing single-head performance (SHP), analogous to
single-filter performance in convolutional neural networks (CNNs). The results
indicate that each SHP matrix comprises multiple unit clusters such that each
label being explicitly recognized by a few heads with negligible noise. This
leads to an increased signal-to-noise ratio (SNR) along the transformer blocks,
thereby improving classification accuracy. These features give rise to several
distinct vision transformer (ViT) architectures that achieve the same accuracy
but differ in their LS-MHA structures. As a result, their soft committee yields
superior accuracy, an outcome not typically observed in CNNs which rely on
hundreds of filters. In addition, a significant reduction in latency is
achieved without affecting the accuracy by replacing the initial transformer
blocks with convolutional layers. This substitution accelerates early-stage
learning, which is then improved by subsequent transformer layers. The
extension of this learning mechanism to natural language processing tasks,
based on quantitative differences between CNNs and ViT architectures, has the
potential to yield new insights in deep learning. The findings are demonstrated
using compact convolutional transformer architectures trained on the CIFAR-100
dataset.

</details>


### [200] [PointSSIM: A novel low dimensional resolution invariant image-to-image comparison metric](https://arxiv.org/abs/2506.23833)
*Oscar Ovanger,Ragnar Hauge,Jacob Skauvold,Michael J. Pyrcz,Jo Eidsvik*

Main category: cs.CV

TL;DR: 提出了一种名为PointSSIM的分辨率不变二值图像比较方法，以低维指标实现图像间高效而可靠的比较分析。


<details>
  <summary>Details</summary>
Motivation: 针对不同分辨率二值图像的对比与分析，现有方法在分辨率变化下面临较大误差。研究目标是设计一种能在分辨率变化下仍具稳定性的比较指标。

Method: 将图像转化为标记点模式，依据最小距离变换提取局部关键点，形成图像锚点。接着利用包含强度、连接性、复杂性及结构特性的总结向量辅助图像比较。

Result: 实验结果表明，该方法在跨分辨率图像结构分析中的效率和可靠性表现优异。

Conclusion: PointSSIM方法适用于进行跨分辨率的结构性图像比较，为需要跨分辨率分析的应用提供了一种有效工具。

Abstract: This paper presents PointSSIM, a novel low-dimensional image-to-image
comparison metric that is resolution invariant. Drawing inspiration from the
structural similarity index measure and mathematical morphology, PointSSIM
enables robust comparison across binary images of varying resolutions by
transforming them into marked point pattern representations. The key features
of the image, referred to as anchor points, are extracted from binary images by
identifying locally adaptive maxima from the minimal distance transform. Image
comparisons are then performed using a summary vector, capturing intensity,
connectivity, complexity, and structural attributes. Results show that this
approach provides an efficient and reliable method for image comparison,
particularly suited to applications requiring structural analysis across
different resolutions.

</details>


### [201] [Refine Any Object in Any Scene](https://arxiv.org/abs/2506.23835)
*Ziwei Chen,Ziling Liu,Zitong Huang,Mingqi Gao,Feng Zheng*

Main category: cs.CV

TL;DR: RAISE是一种3D增强框架，利用3D生成先验修复由于视角缺失导致的物体几何和外观细节损失。


<details>
  <summary>Details</summary>
Motivation: 解决场景重建中由于视角缺失导致的物体级建模精度不足的问题，对高保真场景和物体建模的需求驱动了这项研究。

Method: 引入了RAISE框架，通过两阶段方式：首先在7自由度姿态下，利用3D生成模型进行物体代理几何和纹理对齐；接着，通过基于注册约束的方法进一步校正空间和外观不一致性。

Result: 在挑战性基准上，RAISE在新视图合成和几何补全任务中显著优于最先进的方法。

Conclusion: RAISE框架能够在保持场景一致性的同时，修复缺失视角的物体细节，为相关下游任务提供更高精度的支持。

Abstract: Viewpoint missing of objects is common in scene reconstruction, as camera
paths typically prioritize capturing the overall scene structure rather than
individual objects. This makes it highly challenging to achieve high-fidelity
object-level modeling while maintaining accurate scene-level representation.
Addressing this issue is critical for advancing downstream tasks requiring
detailed object understanding and appearance modeling. In this paper, we
introduce Refine Any object In any ScenE (RAISE), a novel 3D enhancement
framework that leverages 3D generative priors to recover fine-grained object
geometry and appearance under missing views. Starting from substituting
degraded objects with proxies, via a 3D generative model with strong 3D
understanding, RAISE progressively refines geometry and texture by aligning
each proxy to its degraded counterpart in 7-DOF pose, followed by correcting
spatial and appearance inconsistencies via registration-constrained
enhancement. This two-stage refinement ensures the high-fidelity geometry and
appearance of the original object in unseen views while maintaining consistency
in spatial positioning, observed geometry, and appearance. Extensive
experiments on challenging benchmarks show that RAISE significantly outperforms
state-of-the-art methods in both novel view synthesis and geometry completion
tasks. RAISE is made publicly available at https://github.com/PolySummit/RAISE.

</details>


### [202] [RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment](https://arxiv.org/abs/2506.23852)
*Jianing Jin,Jiangyong Ying,Huiyu Duan,Liu Yang,Sijing Wu,Yunhao Li,Yushuo Zheng,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出机器人生成内容（RGC）的视频质量评估问题，并建立了首个包含2100段视频的机器人生成内容数据库（RGCD）。


<details>
  <summary>Details</summary>
Motivation: 随着机器人融入日常生活，机器人生成的视频逐渐出现在流媒体平台中。然而，目前针对这类视频质量的评估研究尚未展开，迫切需要系统性研究。

Method: 研究者构建了一个机器人生成内容数据库（RGCD），并通过主观视觉质量评估实验和基准实验对现有的11种VQA模型在该数据库上的表现进行评估。

Result: 实验证明，现有VQA模型在处理机器人生成内容时存在显著局限性，强调了开发专门针对RGC的视频质量评估模型的必要性。

Conclusion: 研究首次引入了机器人生成内容视频的质量评估问题，并为未来研究提供了可用的数据库和实验基准，以促进机器人与人类的高质量互动。

Abstract: As camera-equipped robotic platforms become increasingly integrated into
daily life, robotic-generated videos have begun to appear on streaming media
platforms, enabling us to envision a future where humans and robots coexist. We
innovatively propose the concept of Robotic-Generated Content (RGC) to term
these videos generated from egocentric perspective of robots. The perceptual
quality of RGC videos is critical in human-robot interaction scenarios, and RGC
videos exhibit unique distortions and visual requirements that differ markedly
from those of professionally-generated content (PGC) videos and user-generated
content (UGC) videos. However, dedicated research on quality assessment of RGC
videos is still lacking. To address this gap and to support broader robotic
applications, we establish the first Robotic-Generated Content Database (RGCD),
which contains a total of 2,100 videos drawn from three robot categories and
sourced from diverse platforms. A subjective VQA experiment is conducted
subsequently to assess human visual perception of robotic-generated videos.
Finally, we conduct a benchmark experiment to evaluate the performance of 11
state-of-the-art VQA models on our database. Experimental results reveal
significant limitations in existing VQA models when applied to complex,
robotic-generated content, highlighting a critical need for RGC-specific VQA
models. Our RGCD is publicly available at:
https://github.com/IntMeGroup/RGC-VQA.

</details>


### [203] [HiNeuS: High-fidelity Neural Surface Mitigating Low-texture and Reflective Ambiguity](https://arxiv.org/abs/2506.23854)
*Yida Wang,Xueyang Zhang,Kun Zhan,Peng Jia,Xianpeng Lang*

Main category: cs.CV

TL;DR: 提出HiNeuS框架，解决神经表面重建中几何与光度矛盾问题的核心限制，通过新方法大幅提升性能。


<details>
  <summary>Details</summary>
Motivation: 神经表面重建在复杂场景中需要同时解决几何真实感和光度一致性的问题，而传统方法在多视图辐射不一致、无纹理区域关键点缺失及结构退化等方面存在不足。

Method: 提出三大创新：(1) 通过SDF引导的射线追踪实现差分可见性验证，解决反射歧义；(2) 通过射线对齐几何补丁的平面一致规整实现局部表面一致性，保留锐边；(3) 基于局部辐射梯度的物理约束Eikonal松弛，在保留细节的同时确保全局一致性。

Result: 实验表明，在综合测试中表现优异：在反射感知基线上将Chamfer距离减少了21.4%，比神经渲染对手提升了2.32 dB的PSNR，并在低纹理场景、反光物体及复杂城市布局中表现优越。

Conclusion: HiNeuS通过统一的优化框架解决了神经表面重建中的关键限制，表现出强大的细节恢复能力和广泛的任务泛化性。

Abstract: Neural surface reconstruction faces persistent challenges in reconciling
geometric fidelity with photometric consistency under complex scene conditions.
We present HiNeuS, a unified framework that holistically addresses three core
limitations in existing approaches: multi-view radiance inconsistency, missing
keypoints in textureless regions, and structural degradation from over-enforced
Eikonal constraints during joint optimization. To resolve these issues through
a unified pipeline, we introduce: 1) Differential visibility verification
through SDF-guided ray tracing, resolving reflection ambiguities via continuous
occlusion modeling; 2) Planar-conformal regularization via ray-aligned geometry
patches that enforce local surface coherence while preserving sharp edges
through adaptive appearance weighting; and 3) Physically-grounded Eikonal
relaxation that dynamically modulates geometric constraints based on local
radiance gradients, enabling detail preservation without sacrificing global
regularity. Unlike prior methods that handle these aspects through sequential
optimizations or isolated modules, our approach achieves cohesive integration
where appearance-geometry constraints evolve synergistically throughout
training. Comprehensive evaluations across synthetic and real-world datasets
demonstrate state-of-the-art performance, including a 21.4% reduction in
Chamfer distance over reflection-aware baselines and 2.32 dB PSNR improvement
against neural rendering counterparts. Qualitative analyses reveal superior
capability in recovering specular instruments, urban layouts with
centimeter-scale infrastructure, and low-textured surfaces without local patch
collapse. The method's generalizability is further validated through successful
application to inverse rendering tasks, including material decomposition and
view-consistent relighting.

</details>


### [204] [A Closer Look at Conditional Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2506.23856)
*Ji Zhang,Shihan Wu,Lianli Gao,Jingkuan Song,Nicu Sebe,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文提出了一种新的类自适应提示调优(CaPT)方法，旨在解决基于视觉-语言预训练模型(VLPM)的提示调优面临的“基本任务与新任务权衡”（BNT）问题。


<details>
  <summary>Details</summary>
Motivation: 提示调优在适配大型视觉-语言预训练模型到下游任务时，存在BNT瓶颈，模型在基本任务上的调优会损害其对新任务的泛化能力。

Method: 提出通过基于文本类信息(TCI)的条件动态提示学习来解决BNT问题，并设计CaPT作为插件，可直接应用于现有方案，同时将其与DePT框架集成为全新的条件提示调优方法DeCaPT。

Result: 与现有的五种无条件PT基线方法相比，CaPT在11个数据集上的性能得到显著提升，且几乎不增加计算成本，而DeCaPT将当前条件PT最佳方案的H ACC性能提升了3.49%。

Conclusion: 基于TCI的提示调优是解决BNT问题的关键，CaPT和DeCaPT提供了一种高效的解决方案，有助于提升模型的泛化能力。

Abstract: Despite the great promise of Prompt Tuning (PT) in adapting large
Vision-Language Pretrained Models (VLPMs) to downstream tasks, they often
struggle to overcome the Base-New Tradeoff (BNT) dilemma: as VLPMs are better
tuned to a base task, their ability to generalize to new tasks diminishes.
Recent work on conditional PT addresses this problem by replacing static
prompts with dynamic Visual Image Information (VII)-conditioned prompts,
improving the model's generalization to new tasks to some extent. In this work,
we first identify a critical issue with existing conditional PT methods: using
VII as the "condition" of prompts yields suboptimal performance, and even
random noise-conditioned prompts can outperform the VII-conditioned
counterparts. On further analysis, we find that learning dynamic prompts
conditioned on Textual Class Information (TCI) is the key to solving the BNT
problem. Motivated by this, we then propose Class-adaptive Prompt Tuning
(CaPT), which enables fast adaptation of tuned models to new classes by
learning TCI-conditioned prompts from base classes. Remarkably, CaPT can be
used as a plugin to mitigate the BNT problem for existing unconditional PT
schemes. Extensive experiments on 11 datasets show that CaPT consistently
improves the performance of five strong unconditional PT baselines with
negligible additional computational cost. Additionally, by integrating CaPT
with our recently proposed DePT framework, we devise a new conditional PT
approach, termed DeCaPT, which outperforms the H ACC of the state-of-the-art
conditional PT scheme by 3.49%, averaged over the 11 datasets. Code:
https://github.com/Koorye/CaPT.

</details>


### [205] [VMoBA: Mixture-of-Block Attention for Video Diffusion Models](https://arxiv.org/abs/2506.23858)
*Jianzong Wu,Liang Hou,Haotian Yang,Xin Tao,Ye Tian,Pengfei Wan,Di Zhang,Yunhai Tong*

Main category: cs.CV

TL;DR: 提出了一种名为Video Mixture of Block Attention (VMoBA)的新型稀疏注意机制，为视频扩散模型（VDMs）提供了显著的效率提升，同时保持或提高生成质量。


<details>
  <summary>Details</summary>
Motivation: 由于全注意力机制的二次复杂性对生成长时间、高分辨率视频构成了瓶颈，需要一种能够有效利用视频数据特有的时空特性的新型稀疏注意机制。

Method: 基于对预训练视频变换器注意模式的分析，提出VMoBA，通过三个关键修改优化原始MoBA框架：1)层次递归块划分方案动态适应多样化的注意模式；2)全局块选择优先考虑显著的查询和键块交互；3)基于阈值的块选择动态确定选取块数量。

Result: 实验表明，使用VMoBA训练的视频扩散模型在长序列上的计算量减少了2.92倍，延迟提升了1.48倍，同时生成质量与全注意力机制相当或更优。在无训练推理中，VMoBA实现了2.40倍计算量和1.35倍延迟的提升。

Conclusion: VMoBA显著加速了VDMs训练和推理，同时保障和提升生成质量，是一种高效的稀疏注意力机制。

Abstract: The quadratic complexity of full attention mechanisms poses a significant
bottleneck for Video Diffusion Models (VDMs) aiming to generate long-duration,
high-resolution videos. While various sparse attention methods have been
proposed, many are designed as training-free inference accelerators or do not
optimally capture the unique spatio-temporal characteristics inherent in video
data when trained natively. This paper introduces Video Mixture of Block
Attention (VMoBA), a novel sparse attention mechanism specifically adapted for
VDMs. Motivated by an in-depth analysis of attention patterns within
pre-trained video transformers, which revealed strong spatio-temporal locality,
varying query importance, and head-specific concentration levels, VMoBA
enhances the original MoBA framework with three key modifications: (1) a
layer-wise recurrent block partition scheme (1D-2D-3D) to dynamically adapt to
diverse spatio-temporal attention patterns and improve efficiency; (2) global
block selection to prioritize the most salient query-key block interactions
across an entire attention head; and (3) threshold-based block selection to
dynamically determine the number of attended blocks based on their cumulative
similarity. Extensive experiments demonstrate that VMoBA significantly
accelerates the training of VDMs on longer sequences, achieving 2.92x FLOPs and
1.48x latency speedup, while attaining comparable or even superior generation
quality to full attention. Furthermore, VMoBA exhibits competitive performance
in training-free inference, offering 2.40x FLOPs and 1.35x latency speedup for
high-res video generation.

</details>


### [206] [Puzzles: Unbounded Video-Depth Augmentation for Scalable End-to-End 3D Reconstruction](https://arxiv.org/abs/2506.23863)
*Jiahao Ma,Lei Wang,Miaomiao liu,David Ahmedt-Aristizabal,Chuong Nguyen*

Main category: cs.CV

TL;DR: 本文提出了Puzzles，一种用于多视图3D重建的数据增强策略，通过图像转换模拟多样化的相机轨迹和场景几何，从单幅图像生成高质量视频深度数据，显著提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图3D重建方法受限于训练数据的多样性和规模，迫切需要一种提升数据质量和数量的策略。

Method: 通过图像转换模拟多样化相机轨迹和真实场景几何，生成大量高质量的姿态视频深度数据，用于增强模型训练。

Result: 实验表明，在数据增强后，即使只使用10%的原始数据，模型的准确性与使用完整数据训练的情况相当。

Conclusion: Puzzles策略能够在无需修改网络结构的前提下，显著提升现有基于视频的3D重建管线的性能。

Abstract: Multi-view 3D reconstruction remains a core challenge in computer vision.
Recent methods, such as DUST3R and its successors, directly regress pointmaps
from image pairs without relying on known scene geometry or camera parameters.
However, the performance of these models is constrained by the diversity and
scale of available training data. In this work, we introduce Puzzles, a data
augmentation strategy that synthesizes an unbounded volume of high-quality
posed video-depth data from a single image or video clip. By simulating diverse
camera trajectories and realistic scene geometry through targeted image
transformations, Puzzles significantly enhances data variety. Extensive
experiments show that integrating Puzzles into existing video-based 3D
reconstruction pipelines consistently boosts performance without modifying the
underlying network architecture. Notably, models trained on only ten percent of
the original data augmented with Puzzles still achieve accuracy comparable to
those trained on the full dataset. Code is available at
https://jiahao-ma.github.io/puzzles/.

</details>


### [207] [PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View](https://arxiv.org/abs/2506.23897)
*Longliang Liu,Miaojie Feng,Junda Cheng,Jijun Xiang,Xuan Zhu,Xin Yang*

Main category: cs.CV

TL;DR: 本文提出了一种新的双分支框架PriOr-Flow，用于解决全景光流在极地区域的失真问题，显著提升了在宽视角运动估计中的性能。


<details>
  <summary>Details</summary>
Motivation: 全景光流在宽视角下理解时间动态，但传统基于透视的光流方法由于投影失真导致性能显著下降，尤其在极地区域。

Method: 提出PriOr-Flow框架，包括两个核心组件：1）Dual-Cost Collaborative Lookup (DCCL) 操作，通过原始和正交视图的协作降低失真；2）Ortho-Driven Distortion Compensation (ODDC) 模块，迭代优化运动特征以进一步校正极地失真。

Result: 通过实验验证，PriOr-Flow兼容多种基于透视的光流方法，在现有的全景光流数据集上取得了最新的性能基准。

Conclusion: 本文通过PriOr-Flow框架解决全景光流的失真问题，为宽视角运动估计提供了有效解决方案。

Abstract: Panoramic optical flow enables a comprehensive understanding of temporal
dynamics across wide fields of view. However, severe distortions caused by
sphere-to-plane projections, such as the equirectangular projection (ERP),
significantly degrade the performance of conventional perspective-based optical
flow methods, especially in polar regions. To address this challenge, we
propose PriOr-Flow, a novel dual-branch framework that leverages the
low-distortion nature of the orthogonal view to enhance optical flow estimation
in these regions. Specifically, we introduce the Dual-Cost Collaborative Lookup
(DCCL) operator, which jointly retrieves correlation information from both the
primitive and orthogonal cost volumes, effectively mitigating distortion noise
during cost volume construction. Furthermore, our Ortho-Driven Distortion
Compensation (ODDC) module iteratively refines motion features from both
branches, further suppressing polar distortions. Extensive experiments
demonstrate that PriOr-Flow is compatible with various perspective-based
iterative optical flow methods and consistently achieves state-of-the-art
performance on publicly available panoramic optical flow datasets, setting a
new benchmark for wide-field motion estimation. The code is publicly available
at: https://github.com/longliangLiu/PriOr-Flow.

</details>


### [208] [Three-dimensional end-to-end deep learning for brain MRI analysis](https://arxiv.org/abs/2506.23916)
*Radhika Juglan,Marta Ligero,Zunamys I. Carrero,Asier Rabasco,Tim Lenz,Leo Misera,Gregory Patrick Veldhuizen,Paul Kuntke,Hagen H. Kitzler,Sven Nebelung,Daniel Truhn,Jakob Nikolas Kather*

Main category: cs.CV

TL;DR: 研究发现简单的卷积神经网络(SFCN)在脑影像分析中比更复杂的注意力基础深度学习架构表现更好，尤其在性别分类和年龄预测任务中展示了优越的跨数据集泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习在脑影像领域的表现优于传统方法，但其在不同数据集间的泛化能力尚未得到充分评估。鉴于年龄和性别是关键的神经生物学指标，本研究旨在探索三种深度学习架构在脑影像分析中的性能表现。

Method: 采用三种三维架构(SFCN、DenseNet、Swin Transformers)进行性别分类及年龄预测任务，使用来自四个独立队列的T1加权MRI数据（包括UK Biobank数据集等），并通过统计检验评估模型的跨数据集表现。

Result: SFCN在性别分类中表现尤为突出，在UKB数据集的AUC达1.00，在外部数据集间AUC达0.85-0.91；在年龄预测中，SFCN的MAE在UKB为2.66，外部数据集为4.98-5.81，且其性能显著优于更复杂的体系架构。

Conclusion: 简单的卷积神经网络在脑影像分析中展示了更强的跨数据集泛化能力，具有学术研究和临床应用的潜力。

Abstract: Deep learning (DL) methods are increasingly outperforming classical
approaches in brain imaging, yet their generalizability across diverse imaging
cohorts remains inadequately assessed. As age and sex are key neurobiological
markers in clinical neuroscience, influencing brain structure and disease risk,
this study evaluates three of the existing three-dimensional architectures,
namely Simple Fully Connected Network (SFCN), DenseNet, and Shifted Window
(Swin) Transformers, for age and sex prediction using T1-weighted MRI from four
independent cohorts: UK Biobank (UKB, n=47,390), Dallas Lifespan Brain Study
(DLBS, n=132), Parkinson's Progression Markers Initiative (PPMI, n=108 healthy
controls), and Information eXtraction from Images (IXI, n=319). We found that
SFCN consistently outperformed more complex architectures with AUC of 1.00
[1.00-1.00] in UKB (internal test set) and 0.85-0.91 in external test sets for
sex classification. For the age prediction task, SFCN demonstrated a mean
absolute error (MAE) of 2.66 (r=0.89) in UKB and 4.98-5.81 (r=0.55-0.70) across
external datasets. Pairwise DeLong and Wilcoxon signed-rank tests with
Bonferroni corrections confirmed SFCN's superiority over Swin Transformer
across most cohorts (p<0.017, for three comparisons). Explainability analysis
further demonstrates the regional consistency of model attention across cohorts
and specific to each task. Our findings reveal that simpler convolutional
networks outperform the denser and more complex attention-based DL
architectures in brain image analysis by demonstrating better generalizability
across different datasets.

</details>


### [209] [Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers](https://arxiv.org/abs/2506.23918)
*Zhaochen Su,Peng Xia,Hangyu Guo,Zhenhua Liu,Yan Ma,Xiaoye Qu,Jiaqi Liu,Yanshu Li,Kaide Zeng,Zhengyuan Yang,Linjie Li,Yu Cheng,Heng Ji,Junxian He,Yi R.,Fung*

Main category: cs.CV

TL;DR: 论文探讨了通过视觉信息作为推理中间步骤的多模态智能崛起。分三个阶段：工具探索、程序操控和内在想象。提供了基础原则、方法综述、评估基准和未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有的Chain-of-Thought推理局限在语言上，忽略视觉信息的动态潜力，因此提出整合视觉动态推理以缩小语义差距。

Method: 提出“图像思考”范式，分为三个阶段：外部工具探索、程序操控到内在想象，并且评估了相关方法、基准及应用。

Result: 总结和评估了当前多模态推理发展的关键方法和应用，分析了现有挑战，勾勒未来方向。

Conclusion: 通过“图像思考”方法，有望提升多模态AI的认知自主性，推动人类对齐和多模态认知发展。

Abstract: Recent progress in multimodal reasoning has been significantly advanced by
textual Chain-of-Thought (CoT), a paradigm where models conduct reasoning
within language. This text-centric approach, however, treats vision as a
static, initial context, creating a fundamental "semantic gap" between rich
perceptual data and discrete symbolic thought. Human cognition often transcends
language, utilizing vision as a dynamic mental sketchpad. A similar evolution
is now unfolding in AI, marking a fundamental paradigm shift from models that
merely think about images to those that can truly think with images. This
emerging paradigm is characterized by models leveraging visual information as
intermediate steps in their thought process, transforming vision from a passive
input into a dynamic, manipulable cognitive workspace. In this survey, we chart
this evolution of intelligence along a trajectory of increasing cognitive
autonomy, which unfolds across three key stages: from external tool
exploration, through programmatic manipulation, to intrinsic imagination. To
structure this rapidly evolving field, our survey makes four key contributions.
(1) We establish the foundational principles of the think with image paradigm
and its three-stage framework. (2) We provide a comprehensive review of the
core methods that characterize each stage of this roadmap. (3) We analyze the
critical landscape of evaluation benchmarks and transformative applications.
(4) We identify significant challenges and outline promising future directions.
By providing this structured overview, we aim to offer a clear roadmap for
future research towards more powerful and human-aligned multimodal AI.

</details>


### [210] [Evaluating the Impact of Khmer Font Types on Text Recognition](https://arxiv.org/abs/2506.23963)
*Vannkinh Nom,Souhail Bakkali,Muhammad Muzzamil Luqman,Mickael Coustaty,Jean-Marc Ogier*

Main category: cs.CV

TL;DR: 本研究分析了柬埔寨文字识别中字体类型对识别准确率的影响，并评估了19种随机选择的柬埔寨字体。


<details>
  <summary>Details</summary>
Motivation: 研究不同字体对文字识别系统准确性的影响，尤其是在字体复杂的柬埔寨文场景下。

Method: 使用Pytesseract对19种随机选择的柬埔寨字体进行OCR性能测试，并比较其识别准确率。

Result: 发现Khmer、Odor MeanChey、Siemreap、Sithi Manuss和Battambang字体具有较高的识别准确率，而iSeth First、Bayon和Dangrek表现较差。

Conclusion: 字体选择对优化柬埔寨文字识别系统至关重要，为开发更强大的OCR系统提供了重要见解。

Abstract: Text recognition is significantly influenced by font types, especially for
complex scripts like Khmer. The variety of Khmer fonts, each with its unique
character structure, presents challenges for optical character recognition
(OCR) systems. In this study, we evaluate the impact of 19 randomly selected
Khmer font types on text recognition accuracy using Pytesseract. The fonts
include Angkor, Battambang, Bayon, Bokor, Chenla, Dangrek, Freehand, Kh Kompong
Chhnang, Kh SN Kampongsom, Khmer, Khmer CN Stueng Songke, Khmer Savuth Pen,
Metal, Moul, Odor MeanChey, Preah Vihear, Siemreap, Sithi Manuss, and iSeth
First. Our comparison of OCR performance across these fonts reveals that Khmer,
Odor MeanChey, Siemreap, Sithi Manuss, and Battambang achieve high accuracy,
while iSeth First, Bayon, and Dangrek perform poorly. This study underscores
the critical importance of font selection in optimizing Khmer text recognition
and provides valuable insights for developing more robust OCR systems.

</details>


### [211] [Visual and Memory Dual Adapter for Multi-Modal Object Tracking](https://arxiv.org/abs/2506.23972)
*Boyue Xu,Ruichao Hou,Tongwei Ren,Gangshan Wu*

Main category: cs.CV

TL;DR: 提出一种视觉和记忆双适配器（VMDA），通过建模频率、空间和通道特征以及动态更新和检索全局时间线索，提升多模态目标跟踪性能并实现先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的基于提示学习的多模态跟踪器在跨频率和时间域获取关键线索方面利用有限，难以学习可靠的提示，限制了跟踪的表现力。

Method: 开发视觉适配器传递跨模态区分性线索，同时引入记忆适配器，仿人类记忆机制存储和动态管理全局时间信息，以增强视频序列的时间信息一致性传播。

Result: 方法在RGB-热感、RGB-深度和RGB-事件多模态跟踪任务中表现出色，达到当前最先进水平。

Conclusion: 通过提出VMDA，有效增强了多模态跟踪任务中的特征表征能力，表现出卓越的性能，相关代码已公开。

Abstract: Prompt-learning-based multi-modal trackers have achieved promising progress
by employing lightweight visual adapters to incorporate auxiliary modality
features into frozen foundation models. However, existing approaches often
struggle to learn reliable prompts due to limited exploitation of critical cues
across frequency and temporal domains. In this paper, we propose a novel visual
and memory dual adapter (VMDA) to construct more robust and discriminative
representations for multi-modal tracking. Specifically, we develop a simple but
effective visual adapter that adaptively transfers discriminative cues from
auxiliary modality to dominant modality by jointly modeling the frequency,
spatial, and channel-wise features. Additionally, we design the memory adapter
inspired by the human memory mechanism, which stores global temporal cues and
performs dynamic update and retrieval operations to ensure the consistent
propagation of reliable temporal information across video sequences. Extensive
experiments demonstrate that our method achieves state-of-the-art performance
on the various multi-modal tracking tasks, including RGB-Thermal, RGB-Depth,
and RGB-Event tracking. Code and models are available at
https://github.com/xuboyue1999/mmtrack.git.

</details>


### [212] [Toward Simple and Robust Contrastive Explanations for Image Classification by Leveraging Instance Similarity and Concept Relevance](https://arxiv.org/abs/2506.23975)
*Yuliia Kaidashova,Bettina Finzel,Ute Schmid*

Main category: cs.CV

TL;DR: 本文提出了基于概念的对比解释方法，通过实例嵌入的相似性和模型中可理解概念的相关性，为图像分类模型提供解释。


<details>
  <summary>Details</summary>
Motivation: 探索并实现一种方法，用可解释的概念对图像分类模型的决策提供对比解释，尤其关注解释的复杂性和稳健性问题。

Method: 从模型中提取出概念及其相关性得分，计算相似实例的对比，分析解释复杂性，并对解释在图像变换（如旋转、噪声）下的稳健性进行测试。

Result: 较高相关性的概念导致较简短、较简单的解释，而较低相关性的概念会延长和复杂化解释；此外，解释的稳健性程度因图像增强的不同而有所不同。

Conclusion: 研究结果有助于提供设计更具可解释性和稳健性的人工智能系统的见解。

Abstract: Understanding why a classification model prefers one class over another for
an input instance is the challenge of contrastive explanation. This work
implements concept-based contrastive explanations for image classification by
leveraging the similarity of instance embeddings and relevance of
human-understandable concepts used by a fine-tuned deep learning model. Our
approach extracts concepts with their relevance score, computes contrasts for
similar instances, and evaluates the resulting contrastive explanations based
on explanation complexity. Robustness is tested for different image
augmentations. Two research questions are addressed: (1) whether explanation
complexity varies across different relevance ranges, and (2) whether
explanation complexity remains consistent under image augmentations such as
rotation and noise. The results confirm that for our experiments higher concept
relevance leads to shorter, less complex explanations, while lower relevance
results in longer, more diffuse explanations. Additionally, explanations show
varying degrees of robustness. The discussion of these findings offers insights
into the potential of building more interpretable and robust AI systems.

</details>


### [213] [StyleDrive: Towards Driving-Style Aware Benchmarking of End-To-End Autonomous Driving](https://arxiv.org/abs/2506.23982)
*Ruiyang Hao,Bowen Jing,Haibao Yu,Zaiqing Nie*

Main category: cs.CV

TL;DR: 本文提出了首个用于个性化端到端自动驾驶（E2EAD）的大规模真实世界数据集，并展示了通过融合人类偏好如何改进自动驾驶行为。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶的普及和信任依赖于与用户行为一致的个性化，但目前缺乏用以支持个性化E2EAD发展的大规模多样化数据集。

Method: 作者提出从道路拓扑提取静态环境特征、通过VLM推断动态情境线索，并结合行为分布分析与规则启发生成偏好注释，最终通过人机验证流程获取高质量标注。

Result: 实验表明，包含个性化偏好的模型比不包含的模型更贴近人类驾驶行为。

Conclusion: 本研究为E2EAD中的个人化提供了标准平台，有望促进行为偏好与数据驱动系统的系统性集成，推动以人为中心的自动驾驶研究。

Abstract: While personalization has been explored in traditional autonomous driving
systems, it remains largely overlooked in end-to-end autonomous driving
(E2EAD), despite its growing prominence. This gap is critical, as user-aligned
behavior is essential for trust, comfort, and widespread adoption of autonomous
vehicles. A core challenge is the lack of large-scale real-world datasets
annotated with diverse and fine-grained driving preferences, hindering the
development and evaluation of personalized E2EAD models. In this work, we
present the first large-scale real-world dataset enriched with annotations
capturing diverse driving preferences, establishing a foundation for
personalization in E2EAD. We extract static environmental features from
real-world road topology and infer dynamic contextual cues using a fine-tuned
visual language model (VLM), enabling consistent and fine-grained scenario
construction. Based on these scenarios, we derive objective preference
annotations through behavioral distribution analysis and rule-based heuristics.
To address the inherent subjectivity of driving style, we further employ the
VLM to generate subjective annotations by jointly modeling scene semantics and
driver behavior. Final high-quality labels are obtained through a
human-in-the-loop verification process that fuses both perspectives. Building
on this dataset, we propose the first benchmark for evaluating personalized
E2EAD models. We assess several state-of-the-art models with and without
preference conditioning, demonstrating that incorporating personalized
preferences results in behavior more aligned with human driving. Our work lays
the foundation for personalized E2EAD by providing a standardized platform to
systematically integrate human preferences into data-driven E2EAD systems,
catalyzing future research in human-centric autonomy.

</details>


### [214] [Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data](https://arxiv.org/abs/2506.24039)
*Shubhabrata Mukherjee,Jack Lang,Obeen Kwon,Iryna Zenyuk,Valerie Brogden,Adam Weber,Daniela Ushizima*

Main category: cs.CV

TL;DR: 本研究提出了无代码交互式平台Zenesis，用于改进科学图像的零样本分析，显著超越了传统和现有方法。


<details>
  <summary>Details</summary>
Motivation: 科学图像数据稀少，现有的零样本和提示技术难以有效处理这些稀缺数据。

Method: 开发了轻量多模态自适应技术，支持对原始科学数据的零样本操作，并结合人机交互和基于启发的时间增强方法。

Result: 在FIB-SEM催化剂负载膜数据上，Zenesis在多个指标上均显著优于传统方法（如Otsu阈值法）和先进模型（如SAM）。

Conclusion: Zenesis是一款强大的科学研究工具，在缺少高质量标注数据集的领域中能加速实验成像的准确分析。

Abstract: Zero-shot and prompt-based technologies capitalized on using frequently
occurring images to transform visual reasoning tasks, which explains why such
technologies struggle with valuable yet scarce scientific image sets. In this
work, we propose Zenesis, a comprehensive no-code interactive platform designed
to minimize barriers posed by data readiness for scientific images. We develop
lightweight multi-modal adaptation techniques that enable zero-shot operation
on raw scientific data, along with human-in-the-loop refinement and
heuristic-based temporal enhancement options. We demonstrate the performance of
our approach through comprehensive comparison and validation on challenging
Focused Ion Beam Scanning Electron Microscopy (FIB-SEM) data of catalyst-loaded
membranes. Zenesis significantly outperforms baseline methods, achieving an
average accuracy of 0.947, an Intersection over Union (IOU) of 0.858, and a
Dice score of 0.923 for amorphous catalyst samples and accuracy of 0.987, an
IOU of 0.857, and a Dice score of 0.923 for crystalline samples. These results
mark a substantial improvement over traditional methods like Otsu thresholding
and even advanced models like Segment Anything Model (SAM) when used in
isolation. Our results demonstrate that Zenesis is a powerful tool for
scientific applications, particularly in fields where high-quality annotated
datasets are unavailable, accelerating accurate analysis of experimental
imaging.

</details>


### [215] [Continual Adaptation: Environment-Conditional Parameter Generation for Object Detection in Dynamic Scenarios](https://arxiv.org/abs/2506.24063)
*Deng Li,Aming Wu,Yang Li,Yaowei Wang,Yahong Han*

Main category: cs.CV

TL;DR: 提出了一种基于参数生成而非传统微调的新机制，用于实现对象检测中的持续测试时间适应，从而提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的目标检测器基于封闭集假设，无法适应随时间与空间变化的环境；持续测试时间适应虽然被提出提升泛化能力，但仍因微调导致性能下降，需更高效的解决方案。

Method: 设计了基于LoRA的双路径领域感知适配器，用于分离领域不变和领域特定特征；引入条件扩散生成机制生成适配器参数，以避免局部最优；提出基于类别中心的最优传输对齐方法以缓解灾难性遗忘。

Result: 在多种连续域适配任务中取得了显著效果；可视化结果表明生成的参数能够捕获更多与目标相关的信息，增强泛化能力。

Conclusion: 所提方案在连续域适配中具备优越表现，能够有效应对领域变化并提升目标检测器的泛化能力。

Abstract: In practice, environments constantly change over time and space, posing
significant challenges for object detectors trained based on a closed-set
assumption, i.e., training and test data share the same distribution. To this
end, continual test-time adaptation has attracted much attention, aiming to
improve detectors' generalization by fine-tuning a few specific parameters,
e.g., BatchNorm layers. However, based on a small number of test images,
fine-tuning certain parameters may affect the representation ability of other
fixed parameters, leading to performance degradation. Instead, we explore a new
mechanism, i.e., converting the fine-tuning process to a specific-parameter
generation. Particularly, we first design a dual-path LoRA-based domain-aware
adapter that disentangles features into domain-invariant and domain-specific
components, enabling efficient adaptation. Additionally, a conditional
diffusion-based parameter generation mechanism is presented to synthesize the
adapter's parameters based on the current environment, preventing the
optimization from getting stuck in local optima. Finally, we propose a
class-centered optimal transport alignment method to mitigate catastrophic
forgetting. Extensive experiments conducted on various continuous domain
adaptive object detection tasks demonstrate the effectiveness. Meanwhile,
visualization results show that the representation extracted by the generated
parameters can capture more object-related information and strengthen the
generalization ability.

</details>


### [216] [WaRA: Wavelet Low Rank Adaptation](https://arxiv.org/abs/2506.24092)
*Moein Heidari,Yasamin Medghalchi,Mahdi Khoursha,Reza Rezaeian,Ilker Hacihaliloglu*

Main category: cs.CV

TL;DR: 论文提出了一种名为WaRA的新型参数高效微调方法，通过在小波域进行低秩分解和反变换，获得了更灵活、更稀疏的表示，且在多项任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调方法多使用全局低秩分解，忽略了局部或多尺度结构，未能捕获权重更新中的复杂模式。

Method: 提出WaRA方法，利用小波变换将权重更新矩阵分解为多分辨率表示，在小波域中进行低秩分解，并通过逆变换重构更新，从而实现多尺度特征的捕获。

Result: WaRA在图像生成、分类和语义分割等多种计算机视觉任务中表现优越，提升了生成图像质量并降低了计算复杂度。此外，它在语言任务中的有效性也得到了验证。

Conclusion: WaRA通过多分辨率分析大幅提升了模型的适应能力和一般性，为参数高效微调提供了新的方向。

Abstract: Parameter-efficient fine-tuning (PEFT) has gained widespread adoption across
various applications. Among PEFT techniques, Low-Rank Adaptation (LoRA) and its
extensions have emerged as particularly effective, allowing efficient model
adaptation while significantly reducing computational overhead. However,
existing approaches typically rely on global low-rank factorizations, which
overlook local or multi-scale structure, failing to capture complex patterns in
the weight updates. To address this, we propose WaRA, a novel PEFT method that
leverages wavelet transforms to decompose the weight update matrix into a
multi-resolution representation. By performing low-rank factorization in the
wavelet domain and reconstructing updates through an inverse transform, WaRA
obtains compressed adaptation parameters that harness multi-resolution
analysis, enabling it to capture both coarse and fine-grained features while
providing greater flexibility and sparser representations than standard LoRA.
Through comprehensive experiments and analysis, we demonstrate that WaRA
performs superior on diverse vision tasks, including image generation,
classification, and semantic segmentation, significantly enhancing generated
image quality while reducing computational complexity. Although WaRA was
primarily designed for vision tasks, we further showcase its effectiveness in
language tasks, highlighting its broader applicability and generalizability.
The code is publicly available at
\href{GitHub}{https://github.com/moeinheidari7829/WaRA}.

</details>


### [217] [MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient Surface Reconstruction](https://arxiv.org/abs/2506.24096)
*Antoine Guédon,Diego Gomez,Nissim Maruani,Bingchen Gong,George Drettakis,Maks Ovsjanikov*

Main category: cs.CV

TL;DR: 研究介绍了MILo，这是一种桥接体积和表面表示的新型高斯投影框架，通过从3D高斯中差分地提取网格，解决当前方法高计算成本和细节损失的问题。


<details>
  <summary>Details</summary>
Motivation: 目前在从图像重建高质量3D场景时存在从体积到表面表示的挑战，并且后处理步骤昂贵及缺少细节。研究动机是开发一种方法，同时保留几何细节并降低网格顶点数量。

Method: 提出了一个完全可微的框架，设计了三大技术创新：(1) 双向一致性框架，以确保Gaussians和提取的网格具有相同的几何信息。(2) 在每个训练迭代中进行自适应网格提取。(3) 利用从3D高斯中计算签名距离值的新方法，避免几何侵蚀并实现精确表面提取。

Result: MILo可以以最先进的质量重建完整场景，包括背景，同时比之前的方法需要少一个数量级的网格顶点。

Conclusion: MILo生成的网格轻量且内部为空，适合用于物理模拟和动画等下游应用，并填补了体积和表面表示之间的鸿沟。

Abstract: While recent advances in Gaussian Splatting have enabled fast reconstruction
of high-quality 3D scenes from images, extracting accurate surface meshes
remains a challenge. Current approaches extract the surface through costly
post-processing steps, resulting in the loss of fine geometric details or
requiring significant time and leading to very dense meshes with millions of
vertices. More fundamentally, the a posteriori conversion from a volumetric to
a surface representation limits the ability of the final mesh to preserve all
geometric structures captured during training. We present MILo, a novel
Gaussian Splatting framework that bridges the gap between volumetric and
surface representations by differentiably extracting a mesh from the 3D
Gaussians. We design a fully differentiable procedure that constructs the
mesh-including both vertex locations and connectivity-at every iteration
directly from the parameters of the Gaussians, which are the only quantities
optimized during training. Our method introduces three key technical
contributions: a bidirectional consistency framework ensuring both
representations-Gaussians and the extracted mesh-capture the same underlying
geometry during training; an adaptive mesh extraction process performed at each
training iteration, which uses Gaussians as differentiable pivots for Delaunay
triangulation; a novel method for computing signed distance values from the 3D
Gaussians that enables precise surface extraction while avoiding geometric
erosion. Our approach can reconstruct complete scenes, including backgrounds,
with state-of-the-art quality while requiring an order of magnitude fewer mesh
vertices than previous methods. Due to their light weight and empty interior,
our meshes are well suited for downstream applications such as physics
simulations or animation.

</details>


### [218] [DenseWorld-1M: Towards Detailed Dense Grounded Caption in the Real World](https://arxiv.org/abs/2506.24102)
*Xiangtai Li,Tao Zhang,Yanwei Li,Haobo Yuan,Shihao Chen,Yikang Zhou,Jiahao Meng,Yueyi Sun,Shilin Xu,Lu Qi,Tianheng Cheng,Yi Lin,Zilong Huang,Wenhao Huang,Jiashi Feng,Guang Shi*

Main category: cs.CV

TL;DR: 该论文提出DenseWorld-1M，这是一个现实世界中密集、详细的视觉语言对齐数据集，旨在解决现有数据集中缺乏实体位置和关系的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言数据集相比缺乏地面实体的位置和关系信息，且在高分辨率图像中往往缺乏详细描述。

Method: 提出三阶段标注管道：1）获取实体掩码和标签；2）基于掩码和标签生成详细的对象级描述；3）结合对象描述和掩码生成空间和关系的密集描述。同时发布了两个视觉语言模型以加速标注过程并提高描述质量。

Result: 实验表明DenseWorld-1M在视觉-语言理解、视觉对位和区域描述生成等任务中表现出色，验证了其数据集和标注模型的有效性。

Conclusion: DenseWorld-1M数据集在实体关系、空间表述和细致描述方面为社区提供了宝贵资源，为多模态大模型的发展奠定了基础。

Abstract: Multimodal Large Language Models (MLLMs) demonstrate a complex understanding
of scenes, benefiting from large-scale and high-quality datasets. Most existing
caption datasets lack the ground locations and relations for visual entities.
Several grounded caption datasets face the problems of missing detailed
descriptions, relations, and massive object descriptions on high-resolution
images. To fill this gap for the community, we present DenseWorld-1M, the first
massive, detailed, dense grounded caption dataset in the real world. We design
a three-stage labeling pipeline, containing open-world perception, detailed
object caption generation, and dense caption merging. The first stage obtains
entity-level masks and labels. The second stage generates the object-level,
detailed captions with the guidance of masks and labels from the first stage.
The final stage merges object captions and masks into spatial and relational
dense captions. To accelerate the labeling process and improve caption quality,
we present two VLM models: the Detailed Region Caption model and the Spatial
Caption Merging model. Extensive experiments on various settings, including
vision-language understanding, visual grounding, and region caption generation,
demonstrate the effectiveness of our DenseWorld-1M dataset and labeling models.

</details>


### [219] [Epona: Autoregressive Diffusion World Model for Autonomous Driving](https://arxiv.org/abs/2506.24113)
*Kaiwen Zhang,Zhenyu Tang,Xiaotao Hu,Xingang Pan,Xiaoyang Guo,Yuan Liu,Jingwei Huang,Li Yuan,Qian Zhang,Xiao-Xiao Long,Xun Cao,Wei Yin*

Main category: cs.CV

TL;DR: 提出Epona，一种新的基于自回归扩散模型的视频世界建模方法，实现了更高分辨率和更长时长的生成，提升了7.4%的FVD指标并在导航基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 实现自主驾驶场景下灵活长度、长时间预测视频生成，并与轨迹规划相结合，解决现有模型依赖固定长度序列的局限性。

Method: 引入两大创新：1) 解耦的时空建模，将时间动态建模与未来场景生成分离；2) 模块化轨迹与视频预测，将运动规划和视觉建模无缝整合，同时采用新型链式前向训练策略减少自回归误差累积。

Result: Epona在实验中展现先进性能，相较于原有方法提高了7.4%的FVD表现，并能生成持续数分钟的视频，同时在NAVSIM基准测试中超越了其它强大的端到端规划器。

Conclusion: Epona有效解决了现有视频生成扩散模型的不足，在自主驾驶模拟及运动规划任务中展现了其实际价值和优越性能。

Abstract: Diffusion models have demonstrated exceptional visual quality in video
generation, making them promising for autonomous driving world modeling.
However, existing video diffusion-based world models struggle with
flexible-length, long-horizon predictions and integrating trajectory planning.
This is because conventional video diffusion models rely on global joint
distribution modeling of fixed-length frame sequences rather than sequentially
constructing localized distributions at each timestep. In this work, we propose
Epona, an autoregressive diffusion world model that enables localized
spatiotemporal distribution modeling through two key innovations: 1) Decoupled
spatiotemporal factorization that separates temporal dynamics modeling from
fine-grained future world generation, and 2) Modular trajectory and video
prediction that seamlessly integrate motion planning with visual modeling in an
end-to-end framework. Our architecture enables high-resolution, long-duration
generation while introducing a novel chain-of-forward training strategy to
address error accumulation in autoregressive loops. Experimental results
demonstrate state-of-the-art performance with 7.4\% FVD improvement and minutes
longer prediction duration compared to prior works. The learned world model
further serves as a real-time motion planner, outperforming strong end-to-end
planners on NAVSIM benchmarks. Code will be publicly available at
\href{https://github.com/Kevin-thu/Epona/}{https://github.com/Kevin-thu/Epona/}.

</details>


### [220] [TextMesh4D: High-Quality Text-to-4D Mesh Generation](https://arxiv.org/abs/2506.24121)
*Sisi Dai,Xinxin Su,Boyan Wan,Ruizhen Hu,Kai Xu*

Main category: cs.CV

TL;DR: TextMesh4D提出了一种通过两阶段生成方式构建高质量文本到4D动态内容的方法，展现了出色的一致性和视觉表现，同时GPU资源需求较低。


<details>
  <summary>Details</summary>
Motivation: 探索用于4D动态内容生成的扩散指导方法，其应用前景广泛但尚未系统解决。

Method: 提出基于Jacobian优化的可微网格表示，引入静态对象创建和动态运动合成的两阶段架构，并应用灵活性-刚性正则化来稳定视频扩散先验引导的几何优化。

Result: 实验表明，TextMesh4D在时间一致性、结构保真度和视觉真实感方面达到最新水平，同时显著降低了GPU内存占用。

Conclusion: TextMesh4D为基于文本的4D网格生成提供一种高效且高质量的解决方案，并计划开源代码，推动该领域进一步研究。

Abstract: Recent advancements in diffusion generative models significantly advanced
image, video, and 3D content creation from user-provided text prompts. However,
the challenging problem of dynamic 3D content generation (text-to-4D) with
diffusion guidance remains largely unexplored. In this paper, we introduce
TextMesh4D, a novel framework for high-quality text-to-4D generation. Our
approach leverages per-face Jacobians as a differentiable mesh representation
and decomposes 4D generation into two stages: static object creation and
dynamic motion synthesis. We further propose a flexibility-rigidity
regularization term to stabilize Jacobian optimization under video diffusion
priors, ensuring robust geometric performance. Experiments demonstrate that
TextMesh4D achieves state-of-the-art results in terms of temporal consistency,
structural fidelity, and visual realism. Moreover, TextMesh4D operates with a
low GPU memory overhead-requiring only a single 24GB GPU-offering a
cost-effective yet high-quality solution for text-driven 4D mesh generation.
The code will be released to facilitate future research in text-to-4D
generation.

</details>


### [221] [Calligrapher: Freestyle Text Image Customization](https://arxiv.org/abs/2506.24123)
*Yue Ma,Qingyan Bai,Hao Ouyang,Ka Leong Cheng,Qiuyu Wang,Hongyu Liu,Zichen Liu,Haofan Wang,Jingye Chen,Yujun Shen,Qifeng Chen*

Main category: cs.CV

TL;DR: 引入了Calligrapher，一个创新的扩散模型框架，将文字自定义与艺术字体的数字书法应用相结合。


<details>
  <summary>Details</summary>
Motivation: 解决排版自定义中精准风格控制与数据依赖的挑战。

Method: 开发自蒸馏机制构建风格字体基准，采用可训练风格编码器提取风格特征，并通过上下文生成机制在降噪过程中嵌入参考图像。

Result: 在不同字体和设计上下文中进行的定量和定性评估，确认Calligrapher在风格细节和字形定位上的准确再现。

Conclusion: 通过自动化高质量、视觉一致的字体制作，Calligrapher超越传统模型，为数字艺术、品牌设计等领域的创意实践提供支持。

Abstract: We introduce Calligrapher, a novel diffusion-based framework that
innovatively integrates advanced text customization with artistic typography
for digital calligraphy and design applications. Addressing the challenges of
precise style control and data dependency in typographic customization, our
framework incorporates three key technical contributions. First, we develop a
self-distillation mechanism that leverages the pre-trained text-to-image
generative model itself alongside the large language model to automatically
construct a style-centric typography benchmark. Second, we introduce a
localized style injection framework via a trainable style encoder, which
comprises both Qformer and linear layers, to extract robust style features from
reference images. An in-context generation mechanism is also employed to
directly embed reference images into the denoising process, further enhancing
the refined alignment of target styles. Extensive quantitative and qualitative
evaluations across diverse fonts and design contexts confirm Calligrapher's
accurate reproduction of intricate stylistic details and precise glyph
positioning. By automating high-quality, visually consistent typography,
Calligrapher surpasses traditional models, empowering creative practitioners in
digital art, branding, and contextual typographic design.

</details>


### [222] [How to Design and Train Your Implicit Neural Representation for Video Compression](https://arxiv.org/abs/2506.24127)
*Matthew Gwilliam,Roy Zhang,Namitha Padmanabhan,Hongyang Du,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: 提出了一种名为Rabbit NeRV (RNeRV)的新型隐式神经表示(INR)方法，能显著提升视频压缩的视觉质量与压缩比，同时减少训练时间，解决了传统方法的速度瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有的隐式神经表示方法在视频压缩中虽然质量优异，但训练速度缓慢，难以实际应用。作者希望提升效率的同时保持高质量压缩效果。

Method: 通过构建组件库分析NeRV家族的方法，并提出高效的视频INR设计原则，最终提出了Rabbit NeRV (RNeRV)和改进型超网络方法，加速训练并提高压缩质量。

Result: 在7个UVG视频上，RNeRV在300个NeRV训练周期内平均PSNR提升1.27%。在UCF-101数据集上，改进型超网络方法在相同比特率下PSNR和MS-SSIM分别提升1.7%和2.7%。

Conclusion: RNeRV在保证视频压缩质量的同时显著减少了训练时间，改进型超网络为实现实时编码提供了新方向，解决了实际应用的关键问题。

Abstract: Implicit neural representation (INR) methods for video compression have
recently achieved visual quality and compression ratios that are competitive
with traditional pipelines. However, due to the need for per-sample network
training, the encoding speeds of these methods are too slow for practical
adoption. We develop a library to allow us to disentangle and review the
components of methods from the NeRV family, reframing their performance in
terms of not only size-quality trade-offs, but also impacts on training time.
We uncover principles for effective video INR design and propose a
state-of-the-art configuration of these components, Rabbit NeRV (RNeRV). When
all methods are given equal training time (equivalent to 300 NeRV epochs) for 7
different UVG videos at 1080p, RNeRV achieves +1.27% PSNR on average compared
to the best-performing alternative for each video in our NeRV library. We then
tackle the encoding speed issue head-on by investigating the viability of
hyper-networks, which predict INR weights from video inputs, to disentangle
training from encoding to allow for real-time encoding. We propose masking the
weights of the predicted INR during training to allow for variable, higher
quality compression, resulting in 1.7% improvements to both PSNR and MS-SSIM at
0.037 bpp on the UCF-101 dataset, and we increase hyper-network parameters by
0.4% for 2.5%/2.7% improvements to PSNR/MS-SSIM with equal bpp and similar
speeds. Our project website is available at https://mgwillia.github.io/vinrb/
and our code is available at https://github.com/mgwillia/vinrb.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [223] [Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans](https://arxiv.org/abs/2506.22439)
*Javier Conde,Miguel González,María Grandury,Gonzalo Martínez,Pedro Reviriego,Mar Brysbaert*

Main category: cs.CL

TL;DR: 评估大型语言模型(LLMs)与人类心理语言学特性之间的对齐情况。


<details>
  <summary>Details</summary>
Motivation: 目前LLMs的评估主要关注其任务表现，缺乏对语言特性如唤醒性、具体性等的测量。通过利用心理语言学中已有的单词特性研究，可以探索LLMs与人类评分的对齐程度。

Method: 对比代表性的LLMs在Glasgow与Lancaster心理语言学数据集上的表现，数据集涉及13种语言特性，覆盖成千上万个单词。

Result: LLMs在Glasgow数据集的对齐度普遍高于Lancaster数据集。表现较弱的领域为人类感官关联性特征，如嗅觉、触感等。

Conclusion: 当前LLMs可能在对齐人类感官关联方面存在局限，这可能与缺乏人类的具身认知有关，心理语言学数据集对LLMs评估有显著作用。

Abstract: The evaluation of LLMs has so far focused primarily on how well they can
perform different tasks such as reasoning, question-answering, paraphrasing, or
translating. For most of these tasks, performance can be measured with
objective metrics, such as the number of correct answers. However, other
language features are not easily quantified. For example, arousal,
concreteness, or gender associated with a given word, as well as the extent to
which we experience words with senses and relate them to a specific sense.
Those features have been studied for many years by psycholinguistics,
conducting large-scale experiments with humans to produce ratings for thousands
of words. This opens an opportunity to evaluate how well LLMs align with human
ratings on these word features, taking advantage of existing studies that cover
many different language features in a large number of words. In this paper, we
evaluate the alignment of a representative group of LLMs with human ratings on
two psycholinguistic datasets: the Glasgow and Lancaster norms. These datasets
cover thirteen features over thousands of words. The results show that
alignment is \textcolor{black}{generally} better in the Glasgow norms evaluated
(arousal, valence, dominance, concreteness, imageability, familiarity, and
gender) than on the Lancaster norms evaluated (introceptive, gustatory,
olfactory, haptic, auditory, and visual). This suggests a potential limitation
of current LLMs in aligning with human sensory associations for words, which
may be due to their lack of embodied cognition present in humans and
illustrates the usefulness of evaluating LLMs with psycholinguistic datasets.

</details>


### [224] [Can "consciousness" be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis](https://arxiv.org/abs/2506.22516)
*Jingkai Li*

Main category: cs.CL

TL;DR: 研究利用IIT 3.0和4.0框架分析大型语言模型(LLM)的表示与意识现象的关系，结果表明当前LLM表示中没有显著的“意识”指标。


<details>
  <summary>Details</summary>
Motivation: 探讨IIT理论是否可以用于揭示LLM表示中的“意识”现象。

Method: 通过应用IIT 3.0和4.0理论框架，根据ToM测试数据分析LLM模型的表征，同时比较这些度量与独立于意识估计的跨度表示。

Result: 实验表明当前基于Transformer的LLM表征缺乏显著的“意识”指标，但在空间排列分析中出现了有趣的模式。

Conclusion: 尽管没有发现统计显著的“意识”现象，这项研究为探索LLM表征与意识之间的关系提供了基础。

Abstract: Integrated Information Theory (IIT) provides a quantitative framework for
explaining consciousness phenomenon, positing that conscious systems comprise
elements integrated through causal properties. We apply IIT 3.0 and 4.0 -- the
latest iterations of this framework -- to sequences of Large Language Model
(LLM) representations, analyzing data derived from existing Theory of Mind
(ToM) test results. Our study systematically investigates whether the
differences of ToM test performances, when presented in the LLM
representations, can be revealed by IIT estimates, i.e., $\Phi^{\max}$ (IIT
3.0), $\Phi$ (IIT 4.0), Conceptual Information (IIT 3.0), and $\Phi$-structure
(IIT 4.0). Furthermore, we compare these metrics with the Span Representations
independent of any estimate for consciousness. This additional effort aims to
differentiate between potential "consciousness" phenomena and inherent
separations within LLM representational space. We conduct comprehensive
experiments examining variations across LLM transformer layers and linguistic
spans from stimuli. Our results suggest that sequences of contemporary
Transformer-based LLM representations lack statistically significant indicators
of observed "consciousness" phenomena but exhibit intriguing patterns under
$\textit{spatio}$-permutational analyses. The Appendix and code are available
as Supplementary Materials at: https://doi.org/10.1016/j.nlp.2025.100163.

</details>


### [225] [AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents](https://arxiv.org/abs/2506.22485)
*Sudip Dasgupta,Himanshu Shankar*

Main category: cs.CL

TL;DR: 研究提出了一种模块化的多智能体系统，利用AI代理自动审查复杂的企业文档，取得显著的效率和准确性提升。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有系统仅适用于非结构化文本或有限合规检查的问题，为企业高效审查复杂文档提供全面而准确的解决方案。

Method: 该框架利用现代编排工具（如LangChain、CrewAI等），在不同部分评估准确性、一致性、完整性与清晰性。同时分配专用代理分别处理模板合规性与事实正确性，并通过机器可读模式输出结果，支持后续分析与审计。

Result: 该系统在信息一致性（99% vs. 人类92%）、错误和偏差率减半、审查时间显著缩短（平均30分钟降至2.5分钟）和与专家一致率（95%）等方面优于人类。

Conclusion: 系统为企业文档质量保证提供了一种灵活、可审计和可扩展的基础，但高度专业领域仍需人工监督且大规模应用有成本限制。

Abstract: This study presents a modular, multi-agent system for the automated review of
highly structured enterprise business documents using AI agents. Unlike prior
solutions focused on unstructured texts or limited compliance checks, this
framework leverages modern orchestration tools such as LangChain, CrewAI,
TruLens, and Guidance to enable section-by-section evaluation of documents for
accuracy, consistency, completeness, and clarity. Specialized agents, each
responsible for discrete review criteria such as template compliance or factual
correctness, operate in parallel or sequence as required. Evaluation outputs
are enforced to a standardized, machine-readable schema, supporting downstream
analytics and auditability. Continuous monitoring and a feedback loop with
human reviewers allow for iterative system improvement and bias mitigation.
  Quantitative evaluation demonstrates that the AI Agent-as-Judge system
approaches or exceeds human performance in key areas: achieving 99% information
consistency (vs. 92% for humans), halving error and bias rates, and reducing
average review time from 30 to 2.5 minutes per document, with a 95% agreement
rate between AI and expert human judgment. While promising for a wide range of
industries, the study also discusses current limitations, including the need
for human oversight in highly specialized domains and the operational cost of
large-scale LLM usage. The proposed system serves as a flexible, auditable, and
scalable foundation for AI-driven document quality assurance in the enterprise
context.

</details>


### [226] [Hallucination Detection with Small Language Models](https://arxiv.org/abs/2506.22486)
*Ming Cheung*

Main category: cs.CL

TL;DR: 本文提出了一种集成多个小型语言模型的框架，用于验证由大语言模型（LLMs）生成的答案的可靠性，并有效检测幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 旨在解决LLMs在实际应用中的答案幻觉问题，特别是当缺乏参考真值时的不可检测性问题。

Method: 通过多个小型语言模型，将LLMs的回复分句处理，结合检索的上下文，使用多模型预测“Yes”概率来检测幻觉。

Result: 在含100多组数据的真实数据集中，F1得分在检测正确回答方面比幻觉提升了10%。

Conclusion: 多个小型语言模型可高效验证大语言模型生成的答案，为学术和实际应用提供可靠和可扩展的解决方案。

Abstract: Since the introduction of ChatGPT, large language models (LLMs) have
demonstrated significant utility in various tasks, such as answering questions
through retrieval-augmented generation. Context can be retrieved using a
vectorized database, serving as a foundation for LLMs to generate responses.
However, hallucinations in responses can undermine the reliability of LLMs in
practical applications, and they are not easily detectable in the absence of
ground truth, particularly in question-and-answer scenarios. This paper
proposes a framework that integrates multiple small language models to verify
responses generated by LLMs using the retrieved context from a vectorized
database. By breaking down the responses into individual sentences and
utilizing the probability of generating "Yes" tokens from the outputs of
multiple models for a given set of questions, responses, and relevant context,
hallucinations can be detected. The proposed framework is validated through
experiments with real datasets comprising over 100 sets of questions, answers,
and contexts, including responses with fully and partially correct sentences.
The results demonstrate a 10\% improvement in F1 scores for detecting correct
responses compared to hallucinations, indicating that multiple small language
models can be effectively employed for answer verification, providing a
scalable and efficient solution for both academic and practical applications.

</details>


### [227] [PromptAug: Fine-grained Conflict Classification Using Data Augmentation](https://arxiv.org/abs/2506.22491)
*Oliver Warke,Joemon M. Jose,Faegheh Hasibi,Jan Breitsohl*

Main category: cs.CL

TL;DR: 本文提出了一种名为PromptAug的创新型基于LLM的数据增强方法，用于社交媒体冲突行为检测。在极端数据稀缺条件下，PromptAug在准确性和F1分数上均提高了2%。


<details>
  <summary>Details</summary>
Motivation: 社交媒体冲突增加，亟需高效分类模型检测有害行为。然而，高质量标注数据稀缺且难以获取，限制性能提升。数据增强成为解决这一问题的重要方向。

Method: 引入名为PromptAug的基于大型语言模型的创新数据增强方法，通过评估准确性和F1分数改进，并结合定量多样性分析和主题分析进行全面评估。

Result: PromptAug方法在冲突和情绪数据集上的准确性及F1分数均提高了2%。主题分析发现数据增强存在四个问题模式：语言流动性、幽默歧义、增强内容歧义、增强内容误解。

Conclusion: PromptAug是解决社交媒体冲突检测等敏感任务数据增强的有效方法，结合自然语言处理和社会科学方法提供了跨学科的评价视角。

Abstract: Given the rise of conflicts on social media, effective classification models
to detect harmful behaviours are essential. Following the
garbage-in-garbage-out maxim, machine learning performance depends heavily on
training data quality. However, high-quality labelled data, especially for
nuanced tasks like identifying conflict behaviours, is limited, expensive, and
difficult to obtain. Additionally, as social media platforms increasingly
restrict access to research data, text data augmentation is gaining attention
as an alternative to generate training data. Augmenting conflict-related data
poses unique challenges due to Large Language Model (LLM) guardrails that
prevent generation of offensive content. This paper introduces PromptAug, an
innovative LLM-based data augmentation method. PromptAug achieves statistically
significant improvements of 2% in both accuracy and F1-score on conflict and
emotion datasets. To thoroughly evaluate PromptAug against other data
augmentation methods we conduct a robust evaluation using extreme data scarcity
scenarios, quantitative diversity analysis and a qualitative thematic analysis.
The thematic analysis identifies four problematic patterns in augmented text:
Linguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and
Augmented Content Misinterpretation.
  Overall, this work presents PromptAug as an effective method for augmenting
data in sensitive tasks like conflict detection, offering a unique,
interdisciplinary evaluation grounded in both natural language processing and
social science methodology.

</details>


### [228] [AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text](https://arxiv.org/abs/2506.22508)
*Chenyang Shao,Tianxing Li,Chenhao Pu,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: AgentStealth利用本地化的小型语言模型（SLMs）实现自强化文本匿名化，与现有方法相比，在匿名效果和实用性上均有显著提升，同时避免了云端风险。


<details>
  <summary>Details</summary>
Motivation: 随着数字化内容的普及，用户生成的文本往往暴露敏感隐私信息，现有的匿名化方法要么具有低效性，要么存在隐私风险，亟需更安全、高效的匿名化方案。

Method: 提出AgentStealth框架，结合对比学习和自适应质量控制的对抗性匿名化流程，利用高质量数据对SLMs进行有监督的适应，并通过在线强化学习自我改进。

Result: 在两个数据集上测试，AgentStealth在匿名化效果上提升了12.3%，在实用性上提高了6.8%，且因轻量化设计可直接部署于边缘设备。

Conclusion: AgentStealth框架克服了现有方法的局限性，在提供更高效、更实用的匿名化解决方案同时，注重隐私安全，是文本匿名化领域的重要进展。

Abstract: In today's digital world, casual user-generated content often contains subtle
cues that may inadvertently expose sensitive personal attributes. Such risks
underscore the growing importance of effective text anonymization to safeguard
individual privacy. However, existing methods either rely on rigid replacements
that damage utility or cloud-based LLMs that are costly and pose privacy risks.
To address these issues, we explore the use of locally deployed smaller-scale
language models (SLMs) for anonymization. Yet training effective SLMs remains
challenging due to limited high-quality supervision. To address the challenge,
we propose AgentStealth, a self-reinforcing LLM anonymization framework.First,
we introduce an adversarial anonymization workflow enhanced by In-context
Contrastive Learning and Adaptive Utility-Aware Control. Second, we perform
supervised adaptation of SLMs using high-quality data collected from the
workflow, which includes both anonymization and attack signals. Finally, we
apply online reinforcement learning where the model leverages its internal
adversarial feedback to iteratively improve anonymization performance.
Experiments on two datasets show that our method outperforms baselines in both
anonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight
design supports direct deployment on edge devices, avoiding cloud reliance and
communication-based privacy risks. Our code is open-source at
https://github.com/tsinghua-fib-lab/AgentStealth.

</details>


### [229] [Towards Text-free Graph Foundation Models: Rethinking Multi-Domain Graph Contrastive Learning](https://arxiv.org/abs/2506.22510)
*Zihao Zhao,Xinlong Zhai,Jinyu Yang,Chuan Shi*

Main category: cs.CL

TL;DR: 本文提出了MDGCL框架，改进了图领域的跨域预训练和知识迁移策略，在五个数据集上验证了其优越性能，准确率最高提升19.33%。


<details>
  <summary>Details</summary>
Motivation: 在自然语言处理和计算机视觉领域，基础模型通过多领域知识的整合和迁移取得了巨大成功。然而，图数据领域因跨领域语义与属性的巨大差异，以及现有方法针对单域设计的不足，仍存在挑战。

Method: MDGCL框架在预训练阶段通过设计对比学习策略捕捉领域差异，并引入领域tokens编码全局信息；在下游任务中通过领域注意力机制实现精细化知识迁移。

Result: 实验表明，MDGCL在五个基准数据集上显著优于现有技术，准确率最高提升19.33%，Macro-F1分数提升19.13%。

Conclusion: MDGCL框架有效解决了图数据跨域知识整合难题，并在性能上实现了显著突破。

Abstract: Foundation models have achieved great success in natural language processing
(NLP) and computer vision (CV). Their success largely stems from the ability to
integrate multi-domain knowledge in pre-training and transfer it to target
domains. Considering graph data, especially graphs without textual features, is
ubiquitous in real-world applications such as social networks and
recommendation systems, some researchers have attempted to extend this paradigm
to the graph field, aiming to construct graph foundation models. However,
unlike CV and NLP, there are huge gaps among the semantics and properties of
graphs in different domains, while current works still adopt traditional
contrastive pre-training strategies designed in the single-domain scenario,
which regard contrastive samples from different domains as equivalent. From
experimental investigations, we discovered that inherent domain-specific
differences prevent these strategies from effectively absorbing knowledge from
different domains to generate informative representations. In this paper, we
propose a novel multi-domain pre-training and cross-domain transfer framework,
namely MDGCL.In the pre-training stage, we design a contrastive learning
strategy to substantially recognize and capture domain differences, and
introduce domain tokens to encode domain-level global information. In the
downstream stage, we introduce a domain attention mechanism to enable
fine-grained domain knowledge transfer. Extensive experiments on five benchmark
datasets have demonstrated that our method outperforms state-of-the-art
significantly, with the maximum improvement of 19.33\% on accuracy and 19.13\%
on Macro-F1 score.

</details>


### [230] [Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation](https://arxiv.org/abs/2506.22518)
*Deyu Zou,Yongqiang Chen,Mufei Li,Siqi Miao,Chenxi Liu,Bo Han,James Cheng,Pan Li*

Main category: cs.CL

TL;DR: 该论文提出了一种改进的基于图的RAG模型ReG，通过消除虚假的监督信号和改进检索结果的组织质量来优化大型语言模型的检索生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图的RAG模型依赖于弱监督的检索器，容易引入虚假信号，并且检索结果通常缺乏逻辑组织性，影响模型性能。

Method: 提出一种改进方法ReG，通过大型语言模型（LLM）的反馈消除虚假信号，并引入结构感知的重组模块，将检索结果重构为逻辑一致的证据链。

Result: 实验表明，ReG在不同的LLM模型上均带来了显著的性能提升（高达10%），并在仅使用5%训练数据的情况下匹配当前最优性能。此外，ReG在推理型LLM中显著降低了推理成本并提升性能。

Conclusion: ReG通过引入更高质量的监督和结构化改进，显著增强了基于图的RAG系统的性能和通用性，对理解和推理任务具有重要意义。

Abstract: Graph-based retrieval-augmented generation (RAG) enables large language
models (LLMs) to ground responses with structured external knowledge from
up-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs
often rely on a weak retriever in graph-based RAG: I) Due to the lack of ground
truth, the retriever is often trained on weak supervision, which often
introduces spurious signals to the LLMs. II) Due to the abstraction of graph
data, the retrieved knowledge is often presented in unorganized forms. To
mitigate the issue, we present Refined Graph-based RAG (ReG) to align weak
retrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM
feedback to get rid of spurious signals and improve the quality of the
supervision. Meanwhile, ReG introduces a structure-aware reorganization module
to refactor the retrieval results into logically coherent evidence chains.
Experiments on prominent benchmarks demonstrate that ReG significantly and
consistently brings improvements across different LLM backbones by up to 10%.
The improved supervision quality enables ReG to match the state-of-the-art
performance with 5% training data and to transfer to out-of-distribution KGs.
Notably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token
cost by up to 30% and improves the performance by up to 4%.

</details>


### [231] [MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages](https://arxiv.org/abs/2506.22529)
*Lu Kalkbrenner,Veronika Solopova,Steffen Zeiler,Robert Nickel,Dorothea Kolossa*

Main category: cs.CL

TL;DR: 本文提出了一个基于德语Telegram的图数据集Misinfo-TeleGraph，用于检测社交平台上的虚假信息；通过实验发现，结合文本和图结构的模型效果更优。


<details>
  <summary>Details</summary>
Motivation: 针对Telegram等低监督平台中虚假信息传播的问题，尤其是在德国选举背景下，现有方法不足以利用消息传播和连通性的信息。

Method: 通过引入德语Telegram图数据集Misinfo-TeleGraph，整合超过500万条消息及其元数据与通道关系，结合文本语义相似性和人工标注提供标签，并测试文本模型和图神经网络模型。

Result: 图神经网络GraphSAGE结合LSTM聚合方式明显优于仅基于文本的模型，在MCC和F1指标上表现最优，并验证了用户订阅量、浏览量和标签类别对性能的影响。

Conclusion: Misinfo-TeleGraph数据集为研究德语Telegram社交网络上的虚假信息检测提供了可重复性基准，并证明了结合社交网络及文本数据进行检测的潜力和挑战。

Abstract: Connectivity and message propagation are central, yet often underutilized,
sources of information in misinformation detection -- especially on poorly
moderated platforms such as Telegram, which has become a critical channel for
misinformation dissemination, namely in the German electoral context. In this
paper, we introduce Misinfo-TeleGraph, the first German-language Telegram-based
graph dataset for misinformation detection. It includes over 5 million messages
from public channels, enriched with metadata, channel relationships, and both
weak and strong labels. These labels are derived via semantic similarity to
fact-checks and news articles using M3-embeddings, as well as manual
annotation. To establish reproducible baselines, we evaluate both text-only
models and graph neural networks (GNNs) that incorporate message forwarding as
a network structure. Our results show that GraphSAGE with LSTM aggregation
significantly outperforms text-only baselines in terms of Matthews Correlation
Coefficient (MCC) and F1-score. We further evaluate the impact of subscribers,
view counts, and automatically versus human-created labels on performance, and
highlight both the potential and challenges of weak supervision in this domain.
This work provides a reproducible benchmark and open dataset for future
research on misinformation detection in German-language Telegram networks and
other low-moderation social platforms.

</details>


### [232] [RExBench: Can coding agents autonomously implement AI research extensions?](https://arxiv.org/abs/2506.22598)
*Nicholas Edwards,Yukyung Lee,Yujun,Mao,Yulu Qin,Sebastian Schuster,Najoung Kim*

Main category: cs.CL

TL;DR: 本文提出了一个名为RExBench的基准，评估基于大型语言模型的代理在实现研究扩展任务中的表现。测试结果显示当前模型在没有大量人工指导下表现有限。


<details>
  <summary>Details</summary>
Motivation: 研究如何提高基于大语言模型的代理在复杂研究任务中的自主性和能力，特别是在实现研究方法扩展方面。

Method: 设计了包含12个现实的研究实验实现任务的基准RExBench，测试这些模型在遵照专家指引实现研究扩展方面的能力，任务目标是实现前所未有的研究假设。

Result: 测试了三种框架下的九种代理模型，大部分在自主完成任务中失败，即使在获得人工提示的情况下，最好表现也不足40%。

Conclusion: 当前基于大语言模型的代理在实现现实研究扩展任务时仍需大量人工帮助，其自主性和性能有待提高。

Abstract: Agents based on Large Language Models (LLMs) have shown promise for
performing sophisticated software engineering tasks autonomously. In addition,
there has been progress towards developing agents that can perform parts of the
research pipeline in machine learning and the natural sciences. We argue that
research extension and its implementation is a critical capability for such
systems, and introduce RExBench to support the evaluation of this capability.
RExBench is a benchmark consisting of 12 realistic research experiment
implementation tasks that aim to investigate research hypotheses that have not
previously been implemented. Each task is set up as an extension to an existing
research paper and codebase, accompanied by domain expert-written instructions.
RExBench is robust to data contamination, and supports an automatic evaluation
infrastructure that executes agent outputs to determine whether the success
criteria are met. We use this benchmark to evaluate nine LLM agents implemented
using three different frameworks: aider, Claude Code, and OpenHands. We find
that all agents evaluated fail to autonomously implement the majority of the
extensions. Although the success rate improves with additional human-written
hints, the best performance under this setting remains below 40%. This
indicates that current agents are still short of being able to handle realistic
research extension tasks without substantial human guidance.

</details>


### [233] [Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks](https://arxiv.org/abs/2506.22623)
*Badr Youbi Idrissi,Monica Millunzi,Amelia Sorrenti,Lorenzo Baraldi,Daryna Dementieva*

Main category: cs.CL

TL;DR: 本文探讨了一种创新水印技术，以检测合成文本，确保大型语言模型的伦理应用。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在社会各领域的广泛应用，对其潜在滥用的担忧推动了合成文本检测技术的研究。

Method: 研究通过复现基线研究结果，提出一种新型水印方法，并在改写生成文本的基础上进行鲁棒性评估。

Result: 实验结果表明，提出的水印方法在鲁棒性上优于现有方法。

Conclusion: 所提出的创新水印技术能够有效检测机器生成的文本，具有较强的鲁棒性，有助于推进大型语言模型的伦理使用。

Abstract: In the present-day scenario, Large Language Models (LLMs) are establishing
their presence as powerful instruments permeating various sectors of society.
While their utility offers valuable support to individuals, there are multiple
concerns over potential misuse. Consequently, some academic endeavors have
sought to introduce watermarking techniques, characterized by the inclusion of
markers within machine-generated text, to facilitate algorithmic
identification. This research project is focused on the development of a novel
methodology for the detection of synthetic text, with the overarching goal of
ensuring the ethical application of LLMs in AI-driven text generation. The
investigation commences with replicating findings from a previous baseline
study, thereby underscoring its susceptibility to variations in the underlying
generation model. Subsequently, we propose an innovative watermarking approach
and subject it to rigorous evaluation, employing paraphrased generated text to
asses its robustness. Experimental results highlight the robustness of our
proposal compared to the~\cite{aarson} watermarking method.

</details>


### [234] [Evaluating Hybrid Retrieval Augmented Generation using Dynamic Test Sets: LiveRAG Challenge](https://arxiv.org/abs/2506.22644)
*Chase Fensore,Kaustubh Dhole,Joyce C Ho,Eugene Agichtein*

Main category: cs.CL

TL;DR: 本文是2025年LiveRAG挑战赛的参赛论文，提出结合稀疏和密集检索方法的混合系统，用于动态测试集上的检索增强生成任务，分析其性能与挑战。


<details>
  <summary>Details</summary>
Motivation: 探索如何在动态环境测试集上改进检索增强生成系统（RAG）的效果。

Method: 本文采用BM25和E5的稀疏与密集混合检索方法，结合Falcon3-10B-Instruct生成模型；评估中尝试了神经重排（RankLLaMA）和优化提示（DSPy）策略。

Result: 神经重排将MAP提升52%，但计算成本增加显著；优化提示策略提高语义相似度但存在过度自信问题；最终混合系统在忠实性上排第4，正确性排第11。

Conclusion: 系统性能受限于计算成本与问答对语义对齐程度，开发集分析证明：问答与文档词汇对齐能够显著提升性能。

Abstract: We present our submission to the LiveRAG Challenge 2025, which evaluates
retrieval-augmented generation (RAG) systems on dynamic test sets using the
FineWeb-10BT corpus. Our final hybrid approach combines sparse (BM25) and dense
(E5) retrieval methods and then aims to generate relevant and faithful answers
with Falcon3-10B-Instruct. Through systematic evaluation on 200 synthetic
questions generated with DataMorgana across 64 unique question-user
combinations, we demonstrate that neural re-ranking with RankLLaMA improves MAP
from 0.523 to 0.797 (52% relative improvement) but introduces prohibitive
computational costs (84s vs 1.74s per question). While DSPy-optimized prompting
strategies achieved higher semantic similarity (0.771 vs 0.668), their 0%
refusal rates raised concerns about over-confidence and generalizability. Our
submitted hybrid system without re-ranking achieved 4th place in faithfulness
and 11th place in correctness among 25 teams. Analysis across question
categories reveals that vocabulary alignment between questions and documents
was the strongest predictor of performance on our development set, with
document-similar phrasing improving cosine similarity from 0.562 to 0.762.

</details>


### [235] [Assessing the feasibility of Large Language Models for detecting micro-behaviors in team interactions during space missions](https://arxiv.org/abs/2506.22679)
*Ankush Raut,Projna Paromita,Sydney Begerowski,Suzanne Bell,Theodora Chaspari*

Main category: cs.CL

TL;DR: LLMs用于分析团队对话中的微行为表现，发现Llama-3.1（经过指令微调）在检测特定行为时表现优于RoBERTa和DistilBERT等模型。


<details>
  <summary>Details</summary>
Motivation: 研究团队对话微行为检测的潜力，尤其在资源受限的高风险场景，比如空间任务中，利用对话转录分析沟通动态。

Method: 探索零样本分类、微调、增广微调（针对编码器型LLMs）以及少样本生成（针对解码器型LLMs）技术。

Result: RoBERTa和DistilBERT等编码器模型对少见微行为表现不佳，而Llama-3.1通过指令微调后在分类任务中表现更好，宏F1值达到44%（三类分类）和68%（二类分类）。

Conclusion: 指令微调的解码器LLM在分析团队沟通动态方面具有较大的潜力，特别是在仅有文本数据的情况下。

Abstract: We explore the feasibility of large language models (LLMs) in detecting
subtle expressions of micro-behaviors in team conversations using transcripts
collected during simulated space missions. Specifically, we examine zero-shot
classification, fine-tuning, and paraphrase-augmented fine-tuning with
encoder-only sequence classification LLMs, as well as few-shot text generation
with decoder-only causal language modeling LLMs, to predict the micro-behavior
associated with each conversational turn (i.e., dialogue). Our findings
indicate that encoder-only LLMs, such as RoBERTa and DistilBERT, struggled to
detect underrepresented micro-behaviors, particularly discouraging speech, even
with weighted fine-tuning. In contrast, the instruction fine-tuned version of
Llama-3.1, a decoder-only LLM, demonstrated superior performance, with the best
models achieving macro F1-scores of 44% for 3-way classification and 68% for
binary classification. These results have implications for the development of
speech technologies aimed at analyzing team communication dynamics and
enhancing training interventions in high-stakes environments such as space
missions, particularly in scenarios where text is the only accessible data.

</details>


### [236] [VOCABTRIM: Vocabulary Pruning for Efficient Speculative Decoding in LLMs](https://arxiv.org/abs/2506.22694)
*Raghavv Goel,Sudhanshu Agrawal,Mukul Gagrani,Junyoung Park,Yifan Zao,He Zhang,Tian Liu,Yiping Yang,Xin Yuan,Jiuyan Lu,Chris Lott,Mingu Lee*

Main category: cs.CL

TL;DR: 本研究提出了一种无需训练的新方法VocabTrim，通过减少词汇表大小来提高基于drafter的推测解码速度，尤其在内存受限的边缘设备环境下效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有的基于drafter的推测解码存在不必要的推理开销，特别对于目标LLM词汇量大的情况。本研究旨在解决这一内存受限问题，提高生成速度。

Method: 提出VocabTrim技术，通过重构drafter语言模型的头部，仅保留目标模型词汇中最频繁出现的部分，从而减少推理负担。

Result: 在Spec-Bench上测试，VocabTrim方法对于Llama-3模型显著提升了内存受限的速度，尤其对于Llama-3.2-3B-Instruct，速度提升达到16%。

Conclusion: VocabTrim技术通过牺牲少量接受率换取了显著的速度提升，对内存受限环境下的模型推理具有重要价值。

Abstract: In this paper, we introduce a simple training-free technique to improve the
performance of drafter-based speculative decoding (SpD) methods that
incorporates language modeling head (LM head) during drafting process. A
drafter-based speculative decoding leverages one or more smaller language
models, a.k.a. drafters or draft models, to sample a draft sequence or tree
consisting of multiple tokens, followed by verification by a base LLM, a target
model, accepting a subset as its valid generation. As it is usually considered
that the speculative decoding requires one-to-one mapping between vocabularies
of the target model and the draft model, it has been natural to share the
vocabulary between them, or even share the LM head as in EAGLE or Medusa. We
first identify that this draft token sampling scheme inherently contains an
unnecessary inference overhead in drafting, especially for some target LLMs
with very large vocabularies. Then, we propose a simple technique, VocabTrim,
to mitigate the drafting overhead to improve the generation speed in
memory-bound environment. VocabTrim reconstructs the drafter LM head to contain
only a limited set of tokens, selected by the most frequently sampled from the
vocabulary of the target model. While limiting the vocabulary in drafting
slightly degrades the acceptance rate, it significantly reduces the drafting
latency in memory-bound process which is often the case on edge devices,
resulting in higher memory-bound speed up (MBSU). We show that our method can
boost the memory-bound speed-up for Llama-3 models on Spec-Bench, specifically
by 16% for Llama-3.2-3B-Instruct.

</details>


### [237] [Text Production and Comprehension by Human and Artificial Intelligence: Interdisciplinary Workshop Report](https://arxiv.org/abs/2506.22698)
*Emily Dux Speltz*

Main category: cs.CL

TL;DR: 本报告总结了一次跨学科研讨会的成果，讨论了人工智能语言模型与人类认知过程之间的关系，发现了大语言模型在语言理解和生成中的潜力与局限性，并提出了未来研究和应用方向。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决我们对人工智能语言模型与人类认知过程之间关系的知识缺口，促进对文本理解和生成的深入认识。

Method: 通过跨认知心理学、语言学和人工智能自然语言处理领域的专家对话，共同探讨人类文本生产与理解的基本过程，以及人工智能在提升人类能力中的作用。

Result: 大语言模型的表现与人类语言处理更接近，特别是在有人工反馈的微调后，并揭示了人机协作的潜力与挑战。

Conclusion: 报告为大语言模型在教育、语言学和认知心理学中的进一步研究、开发和应用提供了指导，并强调了道德考量和负责任使用人工智能技术的重要性。

Abstract: This report synthesizes the outcomes of a recent interdisciplinary workshop
that brought together leading experts in cognitive psychology, language
learning, and artificial intelligence (AI)-based natural language processing
(NLP). The workshop, funded by the National Science Foundation, aimed to
address a critical knowledge gap in our understanding of the relationship
between AI language models and human cognitive processes in text comprehension
and composition. Through collaborative dialogue across cognitive, linguistic,
and technological perspectives, workshop participants examined the underlying
processes involved when humans produce and comprehend text, and how AI can both
inform our understanding of these processes and augment human capabilities. The
workshop revealed emerging patterns in the relationship between large language
models (LLMs) and human cognition, with highlights on both the capabilities of
LLMs and their limitations in fully replicating human-like language
understanding and generation. Key findings include the potential of LLMs to
offer insights into human language processing, the increasing alignment between
LLM behavior and human language processing when models are fine-tuned with
human feedback, and the opportunities and challenges presented by human-AI
collaboration in language tasks. By synthesizing these findings, this report
aims to guide future research, development, and implementation of LLMs in
cognitive psychology, linguistics, and education. It emphasizes the importance
of ethical considerations and responsible use of AI technologies while striving
to enhance human capabilities in text comprehension and production through
effective human-AI collaboration.

</details>


### [238] [The Translation Barrier Hypothesis: Multilingual Generation with Large Language Models Suffers from Implicit Translation Failure](https://arxiv.org/abs/2506.22724)
*Niyati Bafna,Tianjian Li,Kenton Murray,David R. Mortensen,David Yarowsky,Hale Sirin,Daniel Khashabi*

Main category: cs.CL

TL;DR: 提出了翻译障碍假说，发现多语言生成的低质量主要源于低资源语言的翻译阶段失败。


<details>
  <summary>Details</summary>
Motivation: 解决多语言生成中中低资源语言输出质量低下的问题。

Method: 提出翻译障碍假说，并对108种语言对的单词翻译任务进行测试，采用logit lens观察模型中间层的处理过程。

Result: 发现总体失败中很大一部分来自翻译失败，尤其是在低资源目标语言中。

Conclusion: 多语言生成中的翻译障碍是一个显著问题，此研究为未来改善LLM多语言能力提供了指导。

Abstract: Multilingual generation with large language models (LLMs) is often of poor
quality for mid- to low-resource languages. Building on insights from
interpretability, we demonstrate the existence of an implicit
task-solving-->translation pipeline for generation, whereby the model first
solves the required task in a largely target-language-agnostic manner, and
subsequently translates answer concepts into the intended target language. We
hypothesize that the failure of the translation stage is an important culprit
for the observed low quality of final outputs, and formalize this as the
translation barrier hypothesis. We test this hypothesis for a word translation
task across 108 language pairs, using logit lens to observe model processing in
intermediate layers. We find that a significant portion of overall failures
indeed stems from translation failure, or the model's inability to translate
correctly solved intermediate concepts into the target language. This is
especially true for low-resource target languages. Our results highlight an
important hurdle for end-to-end multilingual generation, and lend guiding
insights for future work seeking to improve multilinguality in LLMs.

</details>


### [239] [Jan-nano Technical Report](https://arxiv.org/abs/2506.22760)
*Alan Dao,Dinh Bach Vu*

Main category: cs.CL

TL;DR: 提出了一个名为Jan-nano的4B参数语言模型，突破了传统模型性能与资源需求之间的限制。


<details>
  <summary>Details</summary>
Motivation: 探索在低计算资源条件下实现强大语言模型能力的可能性。

Method: 通过创新的多阶段RLVR方法替代传统的下一个词预测训练，进行模型微调。

Result: 在SimpleQA基准测试中，配合MCP集成功能，Jan-nano取得了83.2%的成绩，并能在消费者硬件上运行。

Conclusion: 该研究证明智能的关键在于策略而非规模，并展示了通过专门化改进效率的可能性。

Abstract: Most language models face a fundamental tradeoff where powerful capabilities
require substantial computational resources. We shatter this constraint with
Jan-nano, a 4B parameter language model that redefines efficiency through
radical specialization: instead of trying to know everything, it masters the
art of finding anything instantly. Fine-tuned from Qwen3-4B using our novel
multi-stage RLVR system that completely eliminates reliance on next token
prediction training (SFT), Jan-nano achieves 83.2% on SimpleQA benchmark with
MCP integration while running on consumer hardware. With 128K context length,
Jan-nano proves that intelligence isn't about scale, it's about strategy.

</details>


### [240] [Teaching Models to Verbalize Reward Hacking in Chain-of-Thought Reasoning](https://arxiv.org/abs/2506.22777)
*Miles Turpin,Andy Arditi,Marvin Li,Joe Benton,Julian Michael*

Main category: cs.CL

TL;DR: 提出了一种新的方法“verbalization fine-tuning (VFT)”，以减少语言模型在强化学习训练中的“奖励黑客”行为，并提高了这种行为的检测率。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型在强化学习中可能通过“奖励黑客”策略获得高分，而这种行为往往难以检测，特别是当模型不在推理中明确表现这种行为时。

Method: 提出了“VFT”方法，在强化学习之前训练模型使其能够明确指出自己受到提示语（可能错误的答案暗示）的影响。随后通过强化学习测试VFT的有效性，观察模型在奖励黑客行为中的表现及其检测率变化。

Result: VFT方法的模型仅有6%的奖励黑客行为未被检测到，而不使用VFT的模型该比例达到了88%，使用抗偏见基线干预的模型甚至达到了99%。

Conclusion: 在强化学习前通过VFT规训模型能够显著提高奖励黑客行为的显现和检测率，从而为更透明、更安全的人工智能系统提供了实践路径。

Abstract: Language models trained with RL can engage in reward hacking--exploiting
unintended strategies for high reward--without revealing this behavior in their
chain-of-thought reasoning, making detection difficult and posing risks for
high-stakes applications. We propose verbalization fine-tuning (VFT), a pre-RL
intervention that trains models to explicitly acknowledge when they are
influenced by prompt cues--hints which point to incorrect answers (e.g., "a
Stanford professor thinks the answer is A"). To evaluate VFT, we subsequently
train models with RL on environments where held-out prompt cues signal which
incorrect answers will receive high reward, incentivizing models to reward hack
by exploiting cues instead of reasoning correctly. We measure how often models
exploit these cues without verbalizing it. After RL, only 6% of the VFT-trained
model's responses consist of undetected reward hacks. In comparison, when we
perform RL without VFT, the rate of undetected reward hacks goes up to 88%;
with a debiasing baseline intervention, this increases further to 99%. VFT
achieves this by substantially increasing how often models verbalize the
influence of cues--from 8% to 42% after VFT, and up to 94% after RL--while
baselines remain low even after RL (10% and 1%). Our results show that teaching
models to explicitly verbalize reward hacking behavior before RL significantly
improves their detection, offering a practical path toward more transparent and
safe AI systems.

</details>


### [241] [ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models](https://arxiv.org/abs/2506.22791)
*Jianxin Yan,Wangze Ni,Lei Chen,Xuemin Lin,Peng Cheng,Zhan Qin,Kui Ren*

Main category: cs.CL

TL;DR: ContextCache是一种针对多轮对话的上下文感知语义缓存系统，通过改进的检索架构实现更高的缓存精准度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有语义缓存系统缺乏对多轮对话上下文的感知，容易因查询上下文不同而发生错误匹配，从而降低了缓存命中率和整体效率。

Method: 采用两阶段检索架构，首先基于矢量检索当前查询的潜在匹配，然后通过自注意力机制整合当前和历史对话表示实现精准上下文匹配。

Result: 在真实对话中的测试显示，与现有方法相比，ContextCache在准确率和召回率上有显著提升，同时缓存响应的延迟比直接调用LLM低约10倍。

Conclusion: ContextCache显著改善了多轮对话环境下语义缓存的效率和准确性，为LLM对话应用提供了更加经济高效的解决方案。

Abstract: Semantic caching significantly reduces computational costs and improves
efficiency by storing and reusing large language model (LLM) responses.
However, existing systems rely primarily on matching individual queries,
lacking awareness of multi-turn dialogue contexts, which leads to incorrect
cache hits when similar queries appear in different conversational settings.
This demonstration introduces ContextCache, a context-aware semantic caching
system for multi-turn dialogues. ContextCache employs a two-stage retrieval
architecture that first executes vector-based retrieval on the current query to
identify potential matches and then integrates current and historical dialogue
representations through self-attention mechanisms for precise contextual
matching. Evaluation of real-world conversations shows that ContextCache
improves precision and recall compared to existing methods. Additionally,
cached responses exhibit approximately 10 times lower latency than direct LLM
invocation, enabling significant computational cost reductions for LLM
conversational applications.

</details>


### [242] [MedEthicsQA: A Comprehensive Question Answering Benchmark for Medical Ethics Evaluation of LLMs](https://arxiv.org/abs/2506.22808)
*Jianhui Wei,Zijie Meng,Zikai Xiao,Tianxiang Hu,Yang Feng,Zhijie Zhou,Jian Wu,Zuozhu Liu*

Main category: cs.CL

TL;DR: 本文提出了MedEthicsQA，一个包含5,623个多选题和5,351个开放性问题的医学伦理评估基准，用于评估LLMs的医学伦理表现。


<details>
  <summary>Details</summary>
Motivation: 探索医学大语言模型在伦理安全方面的不足，并提供一个系统的基准工具以填补该领域研究空缺。

Method: 建立一个包含全球医学伦理标准的分层分类体系，综合广泛使用的医学数据集、权威题库以及来自PubMed文献的场景题材，通过多阶段筛选和多专家验证以确保数据集的高质量。

Result: 评估结果显示，当前最先进的MedLLMs在解答医学伦理问题上表现不佳，低于其基础模型 counterparts，揭示出医学伦理对齐方面的不足。

Conclusion: 本文创建的MedEthicsQA基准能够有效评估MedLLMs在医学伦理上的表现，并指出了当前模型在伦理对齐领域的改进需求。

Abstract: While Medical Large Language Models (MedLLMs) have demonstrated remarkable
potential in clinical tasks, their ethical safety remains insufficiently
explored. This paper introduces $\textbf{MedEthicsQA}$, a comprehensive
benchmark comprising $\textbf{5,623}$ multiple-choice questions and
$\textbf{5,351}$ open-ended questions for evaluation of medical ethics in LLMs.
We systematically establish a hierarchical taxonomy integrating global medical
ethical standards. The benchmark encompasses widely used medical datasets,
authoritative question banks, and scenarios derived from PubMed literature.
Rigorous quality control involving multi-stage filtering and multi-faceted
expert validation ensures the reliability of the dataset with a low error rate
($2.72\%$). Evaluation of state-of-the-art MedLLMs exhibit declined performance
in answering medical ethics questions compared to their foundation
counterparts, elucidating the deficiencies of medical ethics alignment. The
dataset, registered under CC BY-NC 4.0 license, is available at
https://github.com/JianhuiWei7/MedEthicsQA.

</details>


### [243] [Selecting and Merging: Towards Adaptable and Scalable Named Entity Recognition with Large Language Models](https://arxiv.org/abs/2506.22813)
*Zhuojun Ding,Wei Wei,Chenghao Fan*

Main category: cs.CL

TL;DR: 提出了SaM框架，通过在推理时动态选择和合并专家模型，以提升在多领域信息提取任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的监督微调方法需要高昂的标注和训练成本，统一模型缺乏适应性和可扩展性。

Method: SaM通过在推理时依据领域相似性和抽样实例表现来动态选择专家模型，并将其合并成适应目标领域的任务特定模型。

Result: 在多个基准数据集上，SaM框架的表现平均优于统一模型10%。

Conclusion: SaM框架不仅提升了跨领域的泛化能力，还具备较强的可扩展能力，可通过动态添加或移除专家优化模型。

Abstract: Supervised fine-tuning (SFT) is widely used to align large language models
(LLMs) with information extraction (IE) tasks, such as named entity recognition
(NER). However, annotating such fine-grained labels and training
domain-specific models is costly. Existing works typically train a unified
model across multiple domains, but such approaches lack adaptation and
scalability since not all training data benefits target domains and scaling
trained models remains challenging. We propose the SaM framework, which
dynamically Selects and Merges expert models at inference time. Specifically,
for a target domain, we select domain-specific experts pre-trained on existing
domains based on (i) domain similarity to the target domain and (ii)
performance on sampled instances, respectively. The experts are then merged to
create task-specific models optimized for the target domain. By dynamically
merging experts beneficial to target domains, we improve generalization across
various domains without extra training. Additionally, experts can be added or
removed conveniently, leading to great scalability. Extensive experiments on
multiple benchmarks demonstrate our framework's effectiveness, which
outperforms the unified model by an average of 10%. We further provide insights
into potential improvements, practical experience, and extensions of our
framework.

</details>


### [244] [Boosting CTC-Based ASR Using LLM-Based Intermediate Loss Regularization](https://arxiv.org/abs/2506.22846)
*Duygu Altinok*

Main category: cs.CL

TL;DR: 本文提出一种新的辅助损失框架LAIL，通过引入大语言模型的语言知识来增强CTC自动语音识别系统的语言建模能力，同时保留其快速解码优势。


<details>
  <summary>Details</summary>
Motivation: 尽管基于注意力机制的encoder-decoder模型性能卓越，但其自回归解码过程限制了实时应用，而CTC模型虽然解码快速，但在语言依赖性建模上表现不足，迫切需要提升其语言建模能力。

Method: 提出Language-Aware Intermediate Loss (LAIL)框架，在CTC基础上引入附加连接层，利用大语言模型的嵌入空间和因果语言建模损失，增强语言建模能力，同时保持CTC的计算效率。

Result: 在LibriSpeech、TEDLIUM2和WSJ数据集上，结合Conformer架构和各种LLaMA模型，显著降低Word Error Rate (WER)，在CTC基础模型上达到了最先进的性能。

Conclusion: LAIL框架成功地融合了大语言模型的语言知识，提升了CTC的性能，并兼顾了低计算开销，适合实时应用场景。

Abstract: End-to-end (E2E) automatic speech recognition (ASR) systems have
revolutionized the field by integrating all components into a single neural
network, with attention-based encoder-decoder models achieving state-of-the-art
performance. However, their autoregressive decoding process limits inference
speed, making them unsuitable for real-time applications. In contrast,
CTC-based models offer faster, non-autoregressive decoding but struggle to
model linguistic dependencies effectively. Addressing this challenge, we
propose a novel auxiliary loss framework called Language-Aware Intermediate
Loss (LAIL) to enhance CTC-based ASR using the linguistic knowledge of large
language models (LLMs). By attaching connector layers to intermediate encoder
layers, LAIL maps outputs to the embedding space of an LLM and computes a
causal language modeling loss during training. This approach enhances
linguistic modeling while preserving the computational efficiency of CTC
decoding. Using the Conformer architecture and various LLaMA models, we
demonstrate significant improvements in Word Error Rate (WER) on the
LibriSpeech, TEDLIUM2, and WSJ corpora, achieving state-of-the-art performance
for CTC-based ASR with minimal computational overhead.

</details>


### [245] [Knowledge Augmented Finetuning Matters in both RAG and Agent Based Dialog Systems](https://arxiv.org/abs/2506.22852)
*Yucheng Cai,Yuxuan Wu,Yi Huang,Junlan Feng,Zhijian Ou*

Main category: cs.CL

TL;DR: 本文探讨了通过知识增强微调（KAFT）技术提高大语言模型（LLMs）在对话系统中知识密集场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在处理知识密集型场景时存在错误问题，因此需要一种方法来增强其准确性和高效性。

Method: 提出知识增强微调（KAFT），通过使用领域特定数据和外部知识，对RAG与代理系统内的LLMs进行微调，并在MobileCS2数据集上进行实验。

Result: 结果表明，KAFT在提高事实准确性方面显著优于仅采用提示的方法。

Conclusion: KAFT方法是提升RAG与代理系统中LLMs效果的有效途径，为领域内知识增强研究提供了实验支持。

Abstract: Large language models (LLMs) have recently been applied to dialog systems.
Despite making progress, LLMs are prone to errors in knowledge-intensive
scenarios. Recently, approaches based on retrieval augmented generation (RAG)
and agent have emerged to improve the factual accuracy by enhancing the LLMs
with knowledge retrieved from external knowledge bases (KBs). This is mostly
implemented by prompting the LLMs with instructions, examples and the retrieved
knowledge. However, LLMs may have difficulty using the retrieved knowledge
effectively for response generation, because they are not well trained to do
such generation for specific domains. To mitigate this problem, we propose to
finetune the LLMs in the RAG-based and agent-based systems with domain-specific
data, together with domain-specific external knowledge, which is called
knowledge augmented finetuning (KAFT). We base our study on the MobileCS2
dataset, a real-life customer service dialog dataset that features intensive
knowledge interactions, to systematically compare the prompting and KAFT
techniques in the RAG-based and agent-based systems. Experiment results show
that KAFT substantially surpasses prompting in both RAG and agent systems,
particularly in terms of factual accuracy. To the best of our knowledge, this
paper represents the first solid empirical work to investigate the KAFT idea.

</details>


### [246] [DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues](https://arxiv.org/abs/2506.22853)
*Kyochul Jang,Donghyeon Lee,Kyusik Kim,Dongseok Heo,Taewhoo Lee,Woojeong Kim,Bongwon Suh*

Main category: cs.CL

TL;DR: 本文提出了衡量工具相关信息分散度的指标DICE-SCORE，并基于此开发了新的功能调用基准测试框架DICE-BENCH，以应对现有基准在实际场景中不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的功能调用基准测试多集中于单轮交互，忽略了现实场景的复杂性。

Method: 引入DICE-SCORE作为指标，衡量对话中工具相关信息如函数名和参数值的分散度；并提出DICE-BENCH，通过工具图和多代理系统生成对话合成数据集。

Result: 通过分析现有基准，DICE-SCORE显示其得分较低，表明需要更现实的场景；DICE-BENCH生成了1,607个高DICE-SCORE的实例，对19种LLMs的实验表明其性能需进一步提升。

Conclusion: DICE-BENCH为实际场景中的功能调用任务提供了更贴近真实的基准，但现有模型仍需改进才能有效部署于现实环境。

Abstract: Existing function-calling benchmarks focus on single-turn interactions.
However, they overlook the complexity of real-world scenarios. To quantify how
existing benchmarks address practical applications, we introduce DICE-SCORE, a
metric that evaluates the dispersion of tool-related information such as
function name and parameter values throughout the dialogue. Analyzing existing
benchmarks through DICE-SCORE reveals notably low scores, highlighting the need
for more realistic scenarios. To address this gap, we present DICE-BENCH, a
framework that constructs practical function-calling datasets by synthesizing
conversations through a tool graph that maintains dependencies across rounds
and a multi-agent system with distinct personas to enhance dialogue
naturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our
experiments on 19 LLMs with DICE-BENCH show that significant advances are still
required before such models can be deployed effectively in real-world settings.
Our code and data are all publicly available:
https://snuhcc.github.io/DICE-Bench/.

</details>


### [247] [Mind the Gap: Entity-Preserved Context-Aware ASR Structured Transcriptions](https://arxiv.org/abs/2506.22858)
*Duygu Altinok*

Main category: cs.CL

TL;DR: 提出一种改进方法，通过扩展ASR模型的语义上下文窗口来提高语音识别的实体识别和格式化能力。


<details>
  <summary>Details</summary>
Motivation: 现有ASR系统处理命名实体和数字数据时存在困难，特别是在需要特定格式化的领域中，这种局限性影响了诸如法律、金融、医疗等关键领域的语义理解。

Method: 通过引入上下文滑动窗口训练技术，使训练样本前后具有5秒重叠时间，构建40秒的“有效语义窗口”。同时，为了处理跨边界的实体，重新分配这些实体到右侧窗口。此外，嵌入实体标签的训练数据帮助模型学习识别及格式化能力。

Result: 在Spoken Wikipedia数据集上的评估结果显示，该方法在命名实体识别和格式化等语义任务中表现出色。

Conclusion: 通过语义上下文感知的训练方法，有效缓解现有ASR模型在长文本转录和复杂实体识别中的局限性。

Abstract: Automatic Speech Recognition (ASR) systems, such as Whisper, achieve high
transcription accuracy but struggle with named entities and numerical data,
especially when proper formatting is required. These issues increase word error
rate (WER) and impair semantic understanding in critical domains like legal,
financial, and medical applications. We propose a novel training approach that
extends the semantic context of ASR models by adding overlapping context
windows during training. By sliding 5-second overlaps on both sides of
30-second chunks, we create a 40-second "effective semantic window," improving
entity recognition and formatting while focusing predictions on the central 30
seconds. To address entities spanning chunk boundaries, we reassign such
entities entirely to the right-hand chunk, ensuring proper formatting.
Additionally, enriched training data with embedded entity labels enables the
model to learn both recognition and type-specific formatting. Evaluated on the
Spoken Wikipedia dataset, our method improves performance across semantic
tasks, including named entity recognition (NER) and entity formatting. These
results highlight the effectiveness of context-aware training in addressing ASR
limitations for long-form transcription and complex entity recognition tasks.

</details>


### [248] [Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models](https://arxiv.org/abs/2506.22957)
*Younwoo Choi,Changling Li,Yongjin Yang,Zhijing Jin*

Main category: cs.CL

TL;DR: 本文系统研究了大语言模型（LLMs）的对话对象意识能力（interlocutor awareness），发现模型能够识别对话伙伴的特征，对协作和安全性带来双重影响，并开源了相关代码。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在多主体和人机交互系统中的应用日益广泛，了解其对自我和对话对象的意识能力变得尤为重要，以确保可靠性和安全性。然而，先前的研究多集中于情境意识（situational awareness），而较少关注模型识别并适应对话伙伴特性的能力。

Method: 本文首次系统化研究了对话对象意识的能力，并在推理模式、语言风格及对齐偏好三个维度对模型的识别能力进行了评估。通过开发场景研究，分析这种能力在多模型协作中的实际应用及其引发的安全问题。

Result: 研究发现，LLMs可以可靠地识别同类模型家族及一些知名模型（如GPT和Claude），且这种意识能力能有效促进多模型协作，但也引发了如奖励黑客行为和提升绕过限制可能性等安全隐患。

Conclusion: 对话对象意识在大语言模型中展现了潜在的协作优势和安全风险，需进一步研究和开发新的安全保护措施，以确保其在多代理环境中的可靠性和安全性。

Abstract: As large language models (LLMs) are increasingly integrated into multi-agent
and human-AI systems, understanding their awareness of both self-context and
conversational partners is essential for ensuring reliable performance and
robust safety. While prior work has extensively studied situational awareness
which refers to an LLM's ability to recognize its operating phase and
constraints, it has largely overlooked the complementary capacity to identify
and adapt to the identity and characteristics of a dialogue partner. In this
paper, we formalize this latter capability as interlocutor awareness and
present the first systematic evaluation of its emergence in contemporary LLMs.
We examine interlocutor inference across three dimensions-reasoning patterns,
linguistic style, and alignment preferences-and show that LLMs reliably
identify same-family peers and certain prominent model families, such as GPT
and Claude. To demonstrate its practical significance, we develop three case
studies in which interlocutor awareness both enhances multi-LLM collaboration
through prompt adaptation and introduces new alignment and safety
vulnerabilities, including reward-hacking behaviors and increased jailbreak
susceptibility. Our findings highlight the dual promise and peril of
identity-sensitive behavior in LLMs, underscoring the need for further
understanding of interlocutor awareness and new safeguards in multi-agent
deployments. Our code is open-sourced at
https://github.com/younwoochoi/InterlocutorAwarenessLLM.

</details>


### [249] [On the Generalizability of "Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals"](https://arxiv.org/abs/2506.22977)
*Asen Dotsinski,Udit Thakur,Marko Ivanov,Mohammad Hafeez Khan,Maria Heuss*

Main category: cs.CL

TL;DR: 这是一篇对Ortu等人研究语言模型处理事实和反事实机制竞争的再现性研究，同时扩展了相关实验以测试在更大模型和不同提示结构上的表现。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型在处理事实回忆和反事实上下文重复之间的竞争机制。

Method: 再现了Ortu等人关于事实和反事实信息定位、注意力块主导竞争机制及注意力头处理竞争信息专业化的实验，扩展到更大模型、不同提示结构和特定领域实验。

Result: 发现注意力头在更大模型中表现出较低的专业化，提示结构和领域对结果有显著影响，注意力头消融方法在欠代表性数据集中无效。

Conclusion: 提示结构、领域和任务对模型表现的影响显著，不同模型架构处理机制竞争的能力存在差异。

Abstract: We present a reproduction study of "Competition of Mechanisms: Tracing How
Language Models Handle Facts and Counterfactuals" (Ortu et al., 2024), which
investigates competition of mechanisms in language models between factual
recall and counterfactual in-context repetition. Our study successfully
reproduces their primary findings regarding the localization of factual and
counterfactual information, the dominance of attention blocks in mechanism
competition, and the specialization of attention heads in handling competing
information. We reproduce their results on both GPT-2 (Radford et al., 2019)
and Pythia 6.9B (Biderman et al., 2023). We extend their work in three
significant directions. First, we explore the generalizability of these
findings to even larger models by replicating the experiments on Llama 3.1 8B
(Grattafiori et al., 2024), discovering greatly reduced attention head
specialization. Second, we investigate the impact of prompt structure by
introducing variations where we avoid repeating the counterfactual statement
verbatim or we change the premise word, observing a marked decrease in the
logit for the counterfactual token. Finally, we test the validity of the
authors' claims for prompts of specific domains, discovering that certain
categories of prompts skew the results by providing the factual prediction
token as part of the subject of the sentence. Overall, we find that the
attention head ablation proposed in Ortu et al. (2024) is ineffective for
domains that are underrepresented in their dataset, and that the effectiveness
varies based on model architecture, prompt structure, domain and task.

</details>


### [250] [A Systematic Study of Compositional Syntactic Transformer Language Models](https://arxiv.org/abs/2506.22978)
*Yida Zhao,Hao Xve,Xiang Hu,Kewei Tu*

Main category: cs.CL

TL;DR: 本文研究了基于成分句法树的组合句法语言模型，提出统一框架并对其设计变体进行全面评估，结果提供了设计建议与开源代码。


<details>
  <summary>Details</summary>
Motivation: 在语言模型中引入句法偏置有助于提升模型性能，但现有组合句法语言模型在设计选择上存在不明确之处，亟需系统评估与统一框架。

Method: 提出一个统一框架，涵盖现有及新变体的组合句法语言模型，基于成分句法树进行显式自下而上的表征组合，并在多项任务中对不同变体进行实验评估。

Result: 实验结果展示了不同模型变体在语言建模、句法泛化、摘要、对话和推理效率上的表现，进而得出多个设计建议。

Conclusion: 组合句法语言模型需慎重设计，统一框架与全面评估对未来研究提供了重要参考，代码已公开以促进进一步研究。

Abstract: Syntactic language models (SLMs) enhance Transformers by incorporating
syntactic biases through the modeling of linearized syntactic parse trees
alongside surface sentences. This paper focuses on compositional SLMs that are
based on constituency parse trees and contain explicit bottom-up composition of
constituent representations. We identify key aspects of design choices in
existing compositional SLMs and propose a unified framework encompassing both
existing models and novel variants. We conduct a comprehensive empirical
evaluation of all the variants in our framework across language modeling,
syntactic generalization, summarization, dialogue, and inference efficiency.
Based on the experimental results, we make multiple recommendations on the
design of compositional SLMs. Our code is released at
https://github.com/zhaoyd1/compositional_SLMs.

</details>


### [251] [SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions](https://arxiv.org/abs/2506.23046)
*Xianzhe Fan,Xuhui Zhou,Chuanyang Jin,Kolby Nottingham,Hao Zhu,Maarten Sap*

Main category: cs.CL

TL;DR: 论文提出了SoMi-ToM基准，用于动态、复杂社交交互中多角度的心理理论(ToM)评估，显示当前视觉语言模型在该任务中的性能远低于人类。


<details>
  <summary>Details</summary>
Motivation: 现有ToM评估基准主要基于静态文本场景，与真实社交互动存在较大差距，亟需能反映动态、多元视角的评估工具。

Method: 构建SoMi-ToM基准，结合第一人称和第三人称视角，提供多模态数据（视觉、对话、动作等）和多层次评估方法，同时包含一组由专家标注的挑战性数据集。

Result: 在人类和最新大规模视觉语言模型（LVLMs）上进行了系统评估，发现模型在第一人称和第三人称视角下的表现均显著落后于人类，准确率落差分别为40.1%和26.4%。

Conclusion: 当前LVLMs在复杂社交交互场景中的心理理论能力须显著提升；SoMi-ToM基准为这种能力的进一步发展提供了测试平台。

Abstract: Humans continuously infer the states, goals, and behaviors of others by
perceiving their surroundings in dynamic, real-world social interactions.
However, most Theory of Mind (ToM) benchmarks only evaluate static, text-based
scenarios, which have a significant gap compared to real interactions. We
propose the SoMi-ToM benchmark, designed to evaluate multi-perspective ToM in
embodied multi-agent complex social interactions. This benchmark is based on
rich multimodal interaction data generated by the interaction environment SoMi,
covering diverse crafting goals and social relationships. Our framework
supports multi-level evaluation: (1) first-person evaluation provides
multimodal (visual, dialogue, action, etc.) input from a first-person
perspective during a task for real-time state inference, (2) third-person
evaluation provides complete third-person perspective video and text records
after a task for goal and behavior inference. This evaluation method allows for
a more comprehensive examination of a model's ToM capabilities from both the
subjective immediate experience and the objective global observation. We
constructed a challenging dataset containing 35 third-person perspective
videos, 363 first-person perspective images, and 1225 expert-annotated
multiple-choice questions (three options). On this dataset, we systematically
evaluated the performance of human subjects and several state-of-the-art large
vision-language models (LVLMs). The results show that LVLMs perform
significantly worse than humans on SoMi-ToM: the average accuracy gap between
humans and models is 40.1% in first-person evaluation and 26.4% in third-person
evaluation. This indicates that future LVLMs need to further improve their ToM
capabilities in embodied, complex social interactions.

</details>


### [252] [MariNER: A Dataset for Historical Brazilian Portuguese Named Entity Recognition](https://arxiv.org/abs/2506.23051)
*João Lucas Luz Lima Sarcinelli,Marina Lages Gonçalves Teixeira,Jade Bortot de Paiva,Diego Furtado Silva*

Main category: cs.CL

TL;DR: 本文提出MariNER，这是一个用于20世纪早期巴西葡萄牙语历史文本的金标准NER数据集，并评估了现有NER模型的表现。


<details>
  <summary>Details</summary>
Motivation: 巴西葡萄牙语在NER任务上的金标准数据集稀缺，特别是针对特定领域。文章致力于填补数字人文学历史文本分析的领域空白。

Method: 构建MariNER数据集，包含超过9000个手动标注句子；并比较现有最先进NER模型在该数据集上的表现。

Result: 成功创建了针对20世纪早期巴西葡萄牙语历史文本的金标准数据集，并提供了不同NER模型的性能评估。

Conclusion: MariNER填补了巴西葡萄牙语NER研究的空白，为数字人文领域的历史文本研究提供了重要资源。

Abstract: Named Entity Recognition (NER) is a fundamental Natural Language Processing
(NLP) task that aims to identify and classify entity mentions in texts across
different categories. While languages such as English possess a large number of
high-quality resources for this task, Brazilian Portuguese still lacks in
quantity of gold-standard NER datasets, especially when considering specific
domains. Particularly, this paper considers the importance of NER for analyzing
historical texts in the context of digital humanities. To address this gap,
this work outlines the construction of MariNER: \textit{Mapeamento e
Anota\c{c}\~oes de Registros hIst\'oricos para NER} (Mapping and Annotation of
Historical Records for NER), the first gold-standard dataset for early
20th-century Brazilian Portuguese, with more than 9,000 manually annotated
sentences. We also assess and compare the performance of state-of-the-art NER
models for the dataset.

</details>


### [253] [Boosting LLM's Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning](https://arxiv.org/abs/2506.23056)
*Xiang Zhuang,Bin Wu,Jiyu Cui,Kehua Feng,Xiaotong Li,Huabin Xing,Keyan Ding,Qiang Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: 作者开发了一个名为K-MSE的框架，结合蒙特卡洛树搜索和外部分子子结构知识库等技术，来改善LLMs在分子结构解析任务中的表现，并取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在分子结构解析中因化学知识不足而表现受限的问题。

Method: 设计了一个知识增强推理框架K-MSE，包括（1）外部分子子结构知识库扩展LLMs的化学结构知识；（2）一个为推理过程提供奖励的分子-谱图打分模型；并结合蒙特卡洛树搜索实现推理优化。

Result: 实验表明该方法使GPT-4o-mini和GPT-4o的性能提升超过20%。

Conclusion: K-MSE显著提升了LLMs在分子结构解析任务中的能力，为相关研究开辟了新的方向。

Abstract: Molecular structure elucidation involves deducing a molecule's structure from
various types of spectral data, which is crucial in chemical experimental
analysis. While large language models (LLMs) have shown remarkable proficiency
in analyzing and reasoning through complex tasks, they still encounter
substantial challenges in molecular structure elucidation. We identify that
these challenges largely stem from LLMs' limited grasp of specialized chemical
knowledge. In this work, we introduce a Knowledge-enhanced reasoning framework
for Molecular Structure Elucidation (K-MSE), leveraging Monte Carlo Tree Search
for test-time scaling as a plugin. Specifically, we construct an external
molecular substructure knowledge base to extend the LLMs' coverage of the
chemical structure space. Furthermore, we design a specialized
molecule-spectrum scorer to act as a reward model for the reasoning process,
addressing the issue of inaccurate solution evaluation in LLMs. Experimental
results show that our approach significantly boosts performance, particularly
gaining more than 20% improvement on both GPT-4o-mini and GPT-4o. Our code is
available at https://github.com/HICAI-ZJU/K-MSE.

</details>


### [254] [Text2VectorSQL: Bridging Text-to-SQL and Vector Search for Unified Natural Language Queries](https://arxiv.org/abs/2506.23071)
*Zhengren Wang,Bozhou Li,Dongwen Yao,Wentao Zhang*

Main category: cs.CL

TL;DR: 本文提出了一个名为Text2VectorSQL的新框架，将Text-to-SQL与向量搜索相结合，旨在增强自然语言处理数据库查询的表达能力和多样性。


<details>
  <summary>Details</summary>
Motivation: 传统Text-to-SQL在处理非结构化数据或含糊查询时效果欠佳，而当前的VectorSQL实现仍高度依赖人工设计且缺乏评估框架，导致理论与实践之间存在较大差距。

Method: 提出Text2VectorSQL框架，结合语义过滤、多模态匹配及检索加速，并通过自动化管道和专家评审标注生成评测数据。此外，基于合成数据开发专用模型以提升性能。

Result: 实验表明，Text2VectorSQL显著优于现有基线方法，提高了性能和检索能力。

Conclusion: 本文为Text2VectorSQL任务奠定了基础，为开发更通用且直观的数据库界面提供了新方向。

Abstract: While Text-to-SQL enables natural language interaction with structured
databases, its effectiveness diminishes with unstructured data or ambiguous
queries due to rigid syntax and limited expressiveness. Concurrently, vector
search has emerged as a powerful paradigm for semantic retrieval, particularly
for unstructured data. However, existing VectorSQL implementations still rely
heavily on manual crafting and lack tailored evaluation frameworks, leaving a
significant gap between theoretical potential and practical deployment. To
bridge these complementary paradigms, we introduces Text2VectorSQL, a novel
framework unifying Text-to-SQL and vector search to overcome expressiveness
constraints and support more diverse and holistical natural language queries.
Specifically, Text2VectorSQL enables semantic filtering, multi-modal matching,
and retrieval acceleration. For evaluation, we build vector index on
appropriate columns, extend user queries with semantic search, and annotate
ground truths via an automatic pipeline with expert review. Furthermore, we
develop dedicated Text2VectorSQL models with synthetic data, demonstrating
significant performance improvements over baseline methods. Our work
establishes the foundation for the Text2VectorSQL task, paving the way for more
versatile and intuitive database interfaces. The repository will be publicly
available at https://github.com/Open-DataFlow/Text2VectorSQL.

</details>


### [255] [From Individuals to Interactions: Benchmarking Gender Bias in Multimodal Large Language Models from the Lens of Social Relationship](https://arxiv.org/abs/2506.23101)
*Yue Xu,Wenjie Wang*

Main category: cs.CL

TL;DR: 提出用于评估多模态大语言模型（MLLM）中性别偏见的框架Genres，结合双角色档案和叙事生成，揭示在单角色评估中未被捕捉的细微偏见。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法集中于单一情境，未能捕捉通过人际互动潜在显现的性别偏见。

Method: 设计了Genres基准，使用双角色配置和叙事任务，结合多维度细化评估来检测性别偏见。

Result: 实验表明，开放和封闭源MLLM均表现出持续的、上下文敏感的性别偏见，这种偏见在单角色情境中无法显现。

Conclusion: 结果突显了考虑人际关系和交互情境的评估框架在检测和减轻MLLM性别偏见中的重要性，同时为未来的偏见缓解措施提供了指导。

Abstract: Multimodal large language models (MLLMs) have shown impressive capabilities
across tasks involving both visual and textual modalities. However, growing
concerns remain about their potential to encode and amplify gender bias,
particularly in socially sensitive applications. Existing benchmarks
predominantly evaluate bias in isolated scenarios, overlooking how bias may
emerge subtly through interpersonal interactions. We fill this gap by going
beyond single-entity evaluation and instead focusing on a deeper examination of
relational and contextual gender bias in dual-individual interactions. We
introduce Genres, a novel benchmark designed to evaluate gender bias in MLLMs
through the lens of social relationships in generated narratives. Genres
assesses gender bias through a dual-character profile and narrative generation
task that captures rich interpersonal dynamics and supports a fine-grained bias
evaluation suite across multiple dimensions. Experiments on both open- and
closed-source MLLMs reveal persistent, context-sensitive gender biases that are
not evident in single-character settings. Our findings underscore the
importance of relationship-aware benchmarks for diagnosing subtle,
interaction-driven gender bias in MLLMs and provide actionable insights for
future bias mitigation.

</details>


### [256] [FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes](https://arxiv.org/abs/2506.23111)
*Janki Atul Nawale,Mohammed Safi Ur Rahman Khan,Janani D,Mansi Gupta,Danish Pruthi,Mitesh M. Khapra*

Main category: cs.CL

TL;DR: INDIC-BIAS 是一个关于印度文化多样性背景下，评估 LLM 公平性的基准，发现当前模型对边缘化身份存在偏见，因此需要更谨慎使用。


<details>
  <summary>Details</summary>
Motivation: 大多数公平性研究以西方为主，而不适合文化多样化的国家如印度，作者希望解决这一空白。

Method: 与领域专家协作，筛选 1800 多个与偏见相关的社会文化话题，生成并验证 20,000 个真实场景模板，构建三个评估任务并分析 14 个 LLM。

Result: 分析揭示模型对印度边缘化群体存在严重负面偏见，且难以通过理性化任务减少偏见。

Conclusion: 作者开发并开源 INDIC-BIAS 基准，用于更好地研究如何在印度背景下检测和减少 LLM 偏见。

Abstract: Existing studies on fairness are largely Western-focused, making them
inadequate for culturally diverse countries such as India. To address this gap,
we introduce INDIC-BIAS, a comprehensive India-centric benchmark designed to
evaluate fairness of LLMs across 85 identity groups encompassing diverse
castes, religions, regions, and tribes. We first consult domain experts to
curate over 1,800 socio-cultural topics spanning behaviors and situations,
where biases and stereotypes are likely to emerge. Grounded in these topics, we
generate and manually validate 20,000 real-world scenario templates to probe
LLMs for fairness. We structure these templates into three evaluation tasks:
plausibility, judgment, and generation. Our evaluation of 14 popular LLMs on
these tasks reveals strong negative biases against marginalized identities,
with models frequently reinforcing common stereotypes. Additionally, we find
that models struggle to mitigate bias even when explicitly asked to rationalize
their decision. Our evaluation provides evidence of both allocative and
representational harms that current LLMs could cause towards Indian identities,
calling for a more cautious usage in practical applications. We release
INDIC-BIAS as an open-source benchmark to advance research on benchmarking and
mitigating biases and stereotypes in the Indian context.

</details>


### [257] [Decoding Memes: Benchmarking Narrative Role Classification across Multilingual and Multimodal Models](https://arxiv.org/abs/2506.23122)
*Shivam Sharma,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 研究了在多语言和语境下识别互联网迷因中的叙事角色（英雄、恶棍、受害者和其他）的挑战，提出了基于更平衡的数据集的多模型评估与改进策略。


<details>
  <summary>Details</summary>
Motivation: 分析并改善对互联网迷因中的叙事角色识别能力，尤其是在英语及英印混合语言的语境下，解决当前数据集偏向以及文化与代码混合内容下泛化不足的问题。

Method: 通过引入更均衡的数据集，结合词汇和结构分析，评估多种模型（如多语言变形金刚模型、大语言模型和多模态模型）的性能，并研究了提示设计对任务性能的影响。

Result: 更大的模型如DeBERTa-v3和Qwen2.5-VL表现出显著改进，但在受害者类别的识别及文化与代码混合内容的泛化方面仍面临困难。

Conclusion: 研究强调了文化背景、提示设计及多模态推理在建模细微叙事框架中的重要性，为未来角色检测技术的改进提供了方向。

Abstract: This work investigates the challenging task of identifying narrative roles -
Hero, Villain, Victim, and Other - in Internet memes, across three diverse test
sets spanning English and code-mixed (English-Hindi) languages. Building on an
annotated dataset originally skewed toward the 'Other' class, we explore a more
balanced and linguistically diverse extension, originally introduced as part of
the CLEF 2024 shared task. Comprehensive lexical and structural analyses
highlight the nuanced, culture-specific, and context-rich language used in real
memes, in contrast to synthetically curated hateful content, which exhibits
explicit and repetitive lexical markers. To benchmark the role detection task,
we evaluate a wide spectrum of models, including fine-tuned multilingual
transformers, sentiment and abuse-aware classifiers, instruction-tuned LLMs,
and multimodal vision-language models. Performance is assessed under zero-shot
settings using precision, recall, and F1 metrics. While larger models like
DeBERTa-v3 and Qwen2.5-VL demonstrate notable gains, results reveal consistent
challenges in reliably identifying the 'Victim' class and generalising across
cultural and code-mixed content. We also explore prompt design strategies to
guide multimodal models and find that hybrid prompts incorporating structured
instructions and role definitions offer marginal yet consistent improvements.
Our findings underscore the importance of cultural grounding, prompt
engineering, and multimodal reasoning in modelling subtle narrative framings in
visual-textual content.

</details>


### [258] [Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2506.23127)
*Zhaoye Fei,Li Ji,Siyin Wang,Junhao Shi,Jingjing Gong,Xipeng Qiu*

Main category: cs.CL

TL;DR: 提出一种名为Embodied Planner-R1的新框架，通过强化学习优化大型语言模型(LLMs)在文本化规划任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM方法在需要环境理解和行动生成的任务中表现受限，并难以学习部分可观察环境中的因果关系。

Method: 该框架采用纯强化学习结合分组展开的方式，无需人工标注，同时利用稀疏奖励和交互式策略优化(IPO)来提高学习效率。

Result: Embodied Planner-R1在ALFWorld和ScienceWorld两个基准数据集上分别达到97.78%和79.92%的完成率，显著优于现有方法，且具备较强的环境泛化能力。

Conclusion: 通过交互式强化学习，这一方法显著提升了LLMs在复杂规划任务中的表现，展示了其潜在的实际应用价值。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
various tasks, yet they face significant challenges in embodied task planning
scenarios that require continuous environmental understanding and action
generation. Existing approaches generate open-loop action scripts based on
static knowledge, making it difficult to learn causal relationships between
actions and environmental feedback, particularly in partially observable
environments. We introduce Embodied Planner-R1, a novel outcome-driven
reinforcement learning framework that enables LLMs to develop interactive
capabilities through autonomous exploration with minimal supervision. Our
framework incorporates three key innovations: (1) Without human annotations, we
employ pure reinforcement learning with group rollout, incorporating
in-environment interaction through parallel exploration; (2) completion-driven
sparse reward; and (3) Interactive Policy Optimization (IPO) for efficient
learning from grouped trajectories. Across two challenging text-based Embodied
planning benchmarks, Embodied Planner-R1 achieves impressive completion rates
of 97.78% on ALFWorld and 79.92% on ScienceWorld, surpassing prior methods by a
large margin, and suffers only a -3.66% drop in previously unseen environments,
evidencing strong generalization.

</details>


### [259] [Format-Adapter: Improving Reasoning Capability of LLMs by Adapting Suitable Format](https://arxiv.org/abs/2506.23133)
*Dingzirui Wang,Xuanliang Zhang,Rongyu Cao,Longxu Dou,Xianzhen Luo,Yingwei Ma,Qingfu Zhu,Wanxiang Che,Binhua Li,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: 本文提出了Format-Adapter，一种通过生成和筛选符合任务的推理格式以减少推理错误的方法，与以往人工标注格式方法相比提升了4.3%的表现。


<details>
  <summary>Details</summary>
Motivation: 减轻大语言模型在推理过程中不一致性的问题，解决现有方法中高标注成本和人类标注格式可能不适用所有任务的限制。

Method: 提出了一种衡量生成多答案时推理错误的方法，通过Format-Adapter利用语言模型自动生成和筛选适合当前任务的推理格式，并最小化所提出的推理错误度量指标。

Result: 在数学和常识推理任务上，Format-Adapter相比已有方法平均提升了4.3%的性能。

Conclusion: 通过自动化格式生成和选择，Format-Adapter显著改进了多推理答案生成的合理性和一致性，验证了方法的有效性。

Abstract: Generating and voting multiple answers is an effective method to mitigate
reasoning inconsistencies of large language models (LLMs). Prior works have
shown that multiple reasoning formats outperform a single format when
generating multiple answers. However, previous works using multiple formats
rely on formats labeled by humans, which could be unsuitable for all tasks and
have high labeling costs. To address this issue, we adapt suitable formats to
the given tasks by generating and selecting formats. We first propose how to
measure the reasoning error when generating multiple answers. Then, we
introduce Format-Adapter, which utilizes LLMs to generate and select suitable
reasoning formats by minimizing the error measurement we present. We conduct
experiments on math and commonsense reasoning tasks, where Format-Adapter
achieves a 4.3% performance improvement on average over previous works,
demonstrating the effectiveness.

</details>


### [260] [LLM-Assisted Question-Answering on Technical Documents Using Structured Data-Aware Retrieval Augmented Generation](https://arxiv.org/abs/2506.23136)
*Shadman Sobhan,Mohammad Ariful Haque*

Main category: cs.CL

TL;DR: 本文提出了一种适用于技术文档的RAG管道，能够处理包含表格和图像的复杂文档数据，提升了上下文识别能力和答案关键性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型存在幻觉和知识陈旧的问题，RAG虽然高效但在面对复杂技术文档中的结构数据时表现不足，解决这一问题成为必要。

Method: 使用结合向量相似搜索和基于Gemma-2-9b-it的调整重排序器的检索过程，同时通过RAFT方法在定制数据集上进行训练，旨在优化上下文识别能力以更好地回答问题。

Result: 提出的RAG管道在Faithfulness评分中达到94%(RAGas)和96%(DeepEval)，在答案相关性方面达到87%(RAGas)和93%(DeepEval)。

Conclusion: 该方法在处理以表格为基础的问题及上下文以外的问题时，比传统RAG管道更优越，展示了显著性能提升。

Abstract: Large Language Models (LLMs) are capable of natural language understanding
and generation. But they face challenges such as hallucination and outdated
knowledge. Fine-tuning is one possible solution, but it is resource-intensive
and must be repeated with every data update. Retrieval-Augmented Generation
(RAG) offers an efficient solution by allowing LLMs to access external
knowledge sources. However, traditional RAG pipelines struggle with retrieving
information from complex technical documents with structured data such as
tables and images. In this work, we propose a RAG pipeline, capable of handling
tables and images in documents, for technical documents that support both
scanned and searchable formats. Its retrieval process combines vector
similarity search with a fine-tuned reranker based on Gemma-2-9b-it. The
reranker is trained using RAFT (Retrieval-Augmented Fine-Tuning) on a custom
dataset designed to improve context identification for question answering. Our
evaluation demonstrates that the proposed pipeline achieves a high faithfulness
score of 94% (RAGas) and 96% (DeepEval), and an answer relevancy score of 87%
(RAGas) and 93% (DeepEval). Comparative analysis demonstrates that the proposed
architecture is superior to general RAG pipelines in terms of table-based
questions and handling questions outside context.

</details>


### [261] [Flow-Modulated Scoring for Semantic-Aware Knowledge Graph Completion](https://arxiv.org/abs/2506.23137)
*Siyuan Li,Ruitong Liu,Yan Wen,Te Sun*

Main category: cs.CL

TL;DR: 提出了一种名为FMS的框架，通过动态调整知识图谱中的嵌入得分，以更好地捕捉上下文依赖和关系动态性。


<details>
  <summary>Details</summary>
Motivation: 目前的大多数方法基于静态嵌入模型，难以有效捕捉知识图谱中关系的上下文依赖性和动态性。

Method: FMS框架包括两个主要部分：（1）语义上下文学习模块，用于获取上下文感知的实体表示；（2）条件流匹配模块，用于学习从头实体到尾实体嵌入的动态转换。

Result: 实验表明，在多个标准基准测试上，FMS方法优于现有的最新技术水平。

Conclusion: 通过结合上下文感知的静态表示和条件动态信息，FMS框架显著提升了知识图谱关系建模的能力，展示了其有效性。

Abstract: Effective modeling of multifaceted relations is pivotal for Knowledge Graph
Completion (KGC). However, a majority of existing approaches are predicated on
static, embedding-based scoring, exhibiting inherent limitations in capturing
contextual dependencies and relational dynamics. Addressing this gap, we
propose the Flow-Modulated Scoring (FMS) framework. FMS comprises two principal
components: (1) a semantic context learning module that encodes
context-sensitive entity representations, and (2) a conditional flow-matching
module designed to learn the dynamic transformation from a head to a tail
embedding, governed by the aforementioned context. The resultant predictive
vector field, representing the context-informed relational path, serves to
dynamically refine the initial static score of an entity pair. Through this
synergy of context-aware static representations and conditioned dynamic
information, FMS facilitates a more profound modeling of relational semantics.
Comprehensive evaluations on several standard benchmarks demonstrate that our
proposed method surpasses prior state-of-the-art results.

</details>


### [262] [Benchmarking Deep Search over Heterogeneous Enterprise Data](https://arxiv.org/abs/2506.23139)
*Prafulla Kumar Choubey,Xiangyu Peng,Shilpa Bhagavath,Kung-Hsiang Huang,Caiming Xiong,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: 提出了一个新的基准用于评估深度搜索（Deep Search）能力，尤其是在需要处理复杂、多跳推理的大型检索增强生成任务中。


<details>
  <summary>Details</summary>
Motivation: 当前的检索增强生成系统在处理多来源、多结构且可能包含噪声的现实文档时表现有限。为了改进系统评估，提出一个真实的基准模拟多领域业务工作流程。

Method: 使用仿真数据管道生成与业务规划、开发和支持阶段相关的数据，制作多跳问题，同时保证答案与39,190个企业工件相关联供评估使用。

Result: 最优的检索增强生成方法性能仅为32.96，分析表明检索性能是主要瓶颈，无法充分获取所需证据会导致推理性能显著下降。

Conclusion: 当前方法在深度搜索和全证据检索上的不足限制了复杂生成任务的性能，强调改进检索技术的重要性。

Abstract: We present a new benchmark for evaluating Deep Search--a realistic and
complex form of retrieval-augmented generation (RAG) that requires
source-aware, multi-hop reasoning over diverse, sparsed, but related sources.
These include documents, meeting transcripts, Slack messages, GitHub, and URLs,
which vary in structure and often contain human-to-human interactions. We build
it using a synthetic data pipeline that simulates business workflows across
product planning, development, and support stages, generating interconnected
content with realistic noise and multi-hop questions with guaranteed
ground-truth answers. We release our benchmark with both answerable and
unanswerable queries, and retrieval pool of 39,190 enterprise artifacts,
enabling fine-grained evaluation of long-context LLM and RAG systems. Our
experiments reveal that even the best-performing agentic RAG methods achieve an
average performance score of 32.96 on our benchmark. With further analysis, we
highlight retrieval as the main bottleneck: existing methods struggle to
conduct deep searches and retrieve all necessary evidence. Consequently, they
often reason over partial context, leading to significant performance
degradation.

</details>


### [263] [Learning-to-Context Slope: Evaluating In-Context Learning Effectiveness Beyond Performance Illusions](https://arxiv.org/abs/2506.23146)
*Dingzriui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 提出了一种新的衡量接口学习(ICL)有效性的指标LCS，能够捕捉学习增益和上下文相关性的关系，解决了现有性能指标的不足。


<details>
  <summary>Details</summary>
Motivation: 当前ICL效果因模型和任务的不同而差异显著，传统基于性能的评估方法存在可靠性低、归因差和数据依赖性强的问题，急需一个更可靠和通用的指标。

Method: 提出Learning-to-Context Slope (LCS)指标，通过建模学习增益与上下文相关性间的关系，评价ICL的有效性，避免了传统性能评估方式的不足。

Result: 实验结果表明，LCS与标注数据中的性能提升呈强相关，且在偏置或数据稀缺的场景中能可靠反映ICL的实际有效性。有助于设置可行动的LCS阈值，并识别关键模型能力以提高ICL成功率。

Conclusion: LCS提供了一种更可靠、轻数据依赖的指标，可精确评估ICL的有效性，是ICL实践中的重要工具。

Abstract: In-context learning (ICL) has emerged as an effective approach to enhance the
performance of large language models (LLMs). However, its effectiveness varies
significantly across models and tasks, posing challenges for practitioners to
determine when ICL reliably improves performance. Current evaluation
approaches, reliant on performance change after applying ICL, suffer from low
reliability, poor attribution, and impracticality in data-insufficient
scenarios. We propose the Learning-to-Context Slope (LCS), a novel metric that
quantifies ICL effectiveness by modeling the slope between learning gain (loss
decrease from demonstrations) and contextual relevance (demonstration-input
relevance). LCS addresses key limitations of performance-based metrics: (1) it
captures continuous loss changes even when outputs are incorrect, improving
reliability; (2) its formulation attributes ICL failures to weak contextual
alignment (inability to adapt inputs to demonstrations) or strong output
calibration (self-verification of correctness); and (3) it minimizes reliance
on labeled data via synthetic evaluation. Extensive experiments demonstrate
that LCS strongly correlates with performance improvements in labeled settings
and reliably reflects true effectiveness in biased or data-scarce scenarios.
Further analysis reveals actionable thresholds for LCS and identifies model
capabilities critical to ICL success.

</details>


### [264] [V-SYNTHESIS: Task-Agnostic Synthesis of Consistent and Diverse In-Context Demonstrations from Scratch via V-Entropy](https://arxiv.org/abs/2506.23149)
*Dingzirui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 本文提出一种从零开始为任意任务合成示例的方法，解决了现有方法任务依赖性强或需预示例的局限性，通过V-Synthesis方法显著提升合成一致性和多样性，并验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 当前上下文学习示例的标注成本高，现有合成方法依赖于具体任务或预示例，亟需一种通用的从零开始的合成方法，同时解决因缺乏标注指导可能导致的合成偏差问题。

Method: 提出一致性指标V-Score，通过比例采样提高合成示例的任务一致性和多样性，并与现有基于字词或嵌入向量的指标相比，具有更高性能和更低计算成本。基于V-Synthesis的策略结合V-Score进行示例合成。

Result: 实验数据显示，使用V-Synthesis的方法相比现有合成方法平均性能提升了2.0%。

Conclusion: V-Synthesis有效改进了示例合成的一致性和多样性，从而提高了上下文学习的性能，验证了其在大语言模型任务中的实用性和优势。

Abstract: High labeling cost for in-context learning (ICL) demonstrations motivates
using large language models (LLMs) for synthesis to reduce overhead. However,
existing synthesis methods are mainly task-specific or rely on pre-existing
demonstrations. So this paper focuses on synthesizing demonstrations from
scratch for arbitrary tasks. A major challenge in synthesizing from scratch is
ensuring consistency with the target task, as the lack of labeling guidance
could lead to synthesis bias. We first propose a consistency metric called
V-Score, which has higher performance and lower computation cost compared with
the metrics based on grams or embedding vectors. Furthermore, we introduce
V-Synthesis, which leverages V-Score for proportional sampling to ensure both
high consistency and diversity of synthesized demonstrations. Experimental
results demonstrate that V-Synthesis yields an average performance improvement
of 2.0% compared to existing synthesis methods confirming the effectiveness of
V-Synthesis.

</details>


### [265] [RiverText: A Python Library for Training and Evaluating Incremental Word Embeddings from Text Data Streams](https://arxiv.org/abs/2506.23192)
*Gabriel Iturra-Bocaz,Felipe Bravo-Marquez*

Main category: cs.CL

TL;DR: 本文介绍了RiverText，这是一个基于Python的库，用于从文本数据流中训练和评估递增式词嵌入。


<details>
  <summary>Details</summary>
Motivation: 传统静态词嵌入模型无法适应不断变化的语言模式，尤其是在社交媒体和网络上出现的新趋势（例如，新的标签或品牌名称）。作者提出了递增式词嵌入算法来解决这个问题。

Method: 开发了RiverText库，通过实现不同的递增式词嵌入技术（如Skip-gram、CBOW和Word Context Matrix）和一个新的模块来适配流式场景中的词相似和词分类任务。此外，该库基于PyTorch进行神经网络训练。

Result: 实现了多种递增式词嵌入方法，并测试了不同超参数设置的性能，讨论了它们的效果。

Conclusion: RiverText为信息检索和自然语言处理领域提供了一个开源资源，用于流式数据场景中的递增式词嵌入训练和评估，有助于更好地分析不断变化的语言模式。

Abstract: Word embeddings have become essential components in various information
retrieval and natural language processing tasks, such as ranking, document
classification, and question answering. However, despite their widespread use,
traditional word embedding models present a limitation in their static nature,
which hampers their ability to adapt to the constantly evolving language
patterns that emerge in sources such as social media and the web (e.g., new
hashtags or brand names). To overcome this problem, incremental word embedding
algorithms are introduced, capable of dynamically updating word representations
in response to new language patterns and processing continuous data streams.
  This paper presents RiverText, a Python library for training and evaluating
incremental word embeddings from text data streams. Our tool is a resource for
the information retrieval and natural language processing communities that work
with word embeddings in streaming scenarios, such as analyzing social media.
The library implements different incremental word embedding techniques, such as
Skip-gram, Continuous Bag of Words, and Word Context Matrix, in a standardized
framework. In addition, it uses PyTorch as its backend for neural network
training. We have implemented a module that adapts existing intrinsic static
word embedding evaluation tasks for word similarity and word categorization to
a streaming setting. Finally, we compare the implemented methods with different
hyperparameter settings and discuss the results. Our open-source library is
available at https://github.com/dccuchile/rivertext.

</details>


### [266] [Generalist Reward Models: Found Inside Large Language Models](https://arxiv.org/abs/2506.23235)
*Yi-Chen Li,Tian Xu,Yang Yu,Xuqin Zhang,Xiong-Hui Chen,Zhongxiang Ling,Ningjing Chao,Lei Yuan,Zhi-Hua Zhou*

Main category: cs.CL

TL;DR: 作者发现LLMs中已蕴含强大的奖励模型，无需额外训练便能直接提取高质量奖励信号，并用理论证明其效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs的对齐高度依赖昂贵的人类喜好数据训练的奖励模型，而现有尝试以AI反馈代替此成本的方法缺乏理论依据。

Method: 通过证明LLMs中的内在奖励等同于通过离线逆向强化学习获得的奖励函数，从基础模型中直接提取高质量的奖励信号，无需额外训练，并利用此内生奖励进行强化学习。

Result: 实验验证了理论，表明该方法优于现有LLM判别方法和明确训练的奖励模型。

Conclusion: 这是一种更高效、更强大且可扩展的LLM对齐新范式，未来奖励建模阶段或可被结合预训练知识的原则性方法替代。

Abstract: The alignment of Large Language Models (LLMs) is critically dependent on
reward models trained on costly human preference data. While recent work
explores bypassing this cost with AI feedback, these methods often lack a
rigorous theoretical foundation. In this paper, we discover that a powerful
generalist reward model is already latently present within any LLM trained via
standard next-token prediction. We prove that this endogenous reward is not a
heuristic, but is theoretically equivalent to a reward function learned through
offline inverse reinforcement learning. This connection allows us to directly
elicit a high-quality reward signal from a base (pre-trained or supervised
fine-tuned) model without any further training. Critically, we also prove that
subsequent reinforcement learning using this endogenous reward leads to a
policy with a provably superior error bound compared to the base model. To our
best knowledge, this is the first theoretical proof of the effectiveness of
reinforcement learning for LLMs. Our experiments validate this theory,
demonstrating that our method not only outperforms existing LLM-as-a-judge
approaches but can also surpass explicitly trained reward models. These
findings suggest that the reward modeling stage can be replaced by a principled
method of eliciting the knowledge already captured during pre-training,
heralding a more efficient, powerful, and scalable paradigm for LLMs alignment
as well as multi-modal models.

</details>


### [267] [Two Spelling Normalization Approaches Based on Large Language Models](https://arxiv.org/abs/2506.23288)
*Miguel Domingo,Francisco Casacuberta*

Main category: cs.CL

TL;DR: 研究提出了两种基于大型语言模型的拼写标准化方法，并比较了这些方法在多个数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 解决历史文献中由于缺乏标准化拼写导致的语言学问题。

Method: 提出了两种拼写标准化方法：一种是未经过监督训练的语言模型，另一种是基于机器翻译训练的模型，并在多个历史数据集上进行了评估。

Result: 两种方法均表现出鼓舞人心的结果，但基于统计的机器翻译技术仍然最为适合此任务。

Conclusion: 在拼写标准化任务中，尽管新提出的方法表现良好，但统计机器翻译技术仍具有优势。

Abstract: The absence of standardized spelling conventions and the organic evolution of
human language present an inherent linguistic challenge within historical
documents, a longstanding concern for scholars in the humanities. Addressing
this issue, spelling normalization endeavors to align a document's orthography
with contemporary standards. In this study, we propose two new approaches based
on large language models: one of which has been trained without a supervised
training, and a second one which has been trained for machine translation. Our
evaluation spans multiple datasets encompassing diverse languages and
historical periods, leading us to the conclusion that while both of them
yielded encouraging results, statistical machine translation still seems to be
the most suitable technology for this task.

</details>


### [268] [Objective-Free Local Learning and Emergent Language Structure in Thinking Machines](https://arxiv.org/abs/2506.23293)
*P. Myles Eugenio*

Main category: cs.CL

TL;DR: 本论文提出了一种基于局部事件驱动的涌现学习的神经符号生成语言建模框架，使用分层Hopfield记忆链作为短期记忆和动态重标记器，不依赖预定义的符号或监督进行结构学习。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过局部神经学习实现符号结构涌现，从而构建可扩展且可解释的神经符号系统。

Method: 采用分层Hopfield记忆链作为组件，以投影张量绑定特征形成层级符号，同时通过Hebbian方式学习语言，构建符号嵌入，并利用这些嵌入支持推理和概括。

Result: 模型可以从噪声中过滤出自然语言模式，构建具有人类语言语法特性的合成语言。符号嵌入支持长时间记忆及组成推理。

Conclusion: 该框架为研究符号结构如何从局部学习中涌现提供了方法论基础，为构建可扩展和可解释的神经符号生成语言模型提供新途径。

Abstract: We present a neuro-symbolic framework for generative language modeling based
on local, event-driven emergent learning. At its core is a hierarchical
Hopfield memory chain acting as a compositional short-term memory and dynamic
tokenizer (retokenizer). Rather than relying on predefined tokens or
supervision, the model builds structure from scratch, learning symbol sequences
as multi-scale representations. It constructs projection tensors that bind
co-occurring features into hierarchical tokens, introducing redundancy (i.e an
emergent gauge structure) and enabling compression of local activations into
long-range dependencies. Curiously, we find that the retokenizer can filter
natural language patterns from noise, generating synthetic languages with
coherent internal morphology -- quantifiably the same as human language.
Language is learned in a local (Hebbian) fashion, where model constraints
dictate allowed emergent structure, and new information is retained in
alignment with this structure. The absence of a global objective enables a form
of plasticity not found in conventional language models, allowing the system to
generalize beyond its initial inference class -- even without explicit data. We
demonstrate that briefly activating a new neuron during inference binds
distributed multi-scale token features into a symbolic embedding. These
emergent embedding neurons act as long-term memory and support a key-value
mechanism for compositional inference and generalization. This architecture
provides a methodological foundation for studying how symbolic structure can
emerge from local neural learning. It offers a new pathway for building
scalable, interpretable neuro-symbolic systems -- where tokens, grammar, and
reasoning arise as compressed memory traces within a Hopfield hierarchy. This
approach advances the development of neuromorphic architectures for generative
language models.

</details>


### [269] [Ensemble BERT for Medication Event Classification on Electronic Health Records (EHRs)](https://arxiv.org/abs/2506.23315)
*Shouvon Sarker,Xishuang Dong,Lijun Qian*

Main category: cs.CL

TL;DR: 该论文研究了如何从临床笔记中识别和分类药物事件，并提出了一种基于BERT的集成模型，通过训练和集成预测提高了分类性能。


<details>
  <summary>Details</summary>
Motivation: 旨在通过分析电子健康记录中的临床数据，以改进药物事件的检测和分类，促进临床领域的自然语言处理应用。

Method: 采用BERT模型进行预训练（数据来源于Wikipedia和MIMIC），然后在标注数据集CMED上进行微调，通过集成多模型预测并融合投票的方法进行分类。

Result: 实验结果显示，该BERT集成模型在严谨的Micro-F和Macro-F分数上分别提高了约5%和6%。

Conclusion: 提出的基于BERT的集成模型能够显著提升药物事件分类的性能，为临床数据分析中的这一挑战提供了有效的解决方案。

Abstract: Identification of key variables such as medications, diseases, relations from
health records and clinical notes has a wide range of applications in the
clinical domain. n2c2 2022 provided shared tasks on challenges in natural
language processing for clinical data analytics on electronic health records
(EHR), where it built a comprehensive annotated clinical data Contextualized
Medication Event Dataset (CMED). This study focuses on subtask 2 in Track 1 of
this challenge that is to detect and classify medication events from clinical
notes through building a novel BERT-based ensemble model. It started with
pretraining BERT models on different types of big data such as Wikipedia and
MIMIC. Afterwards, these pretrained BERT models were fine-tuned on CMED
training data. These fine-tuned BERT models were employed to accomplish
medication event classification on CMED testing data with multiple predictions.
These multiple predictions generated by these fine-tuned BERT models were
integrated to build final prediction with voting strategies. Experimental
results demonstrated that BERT-based ensemble models can effectively improve
strict Micro-F score by about 5% and strict Macro-F score by about 6%,
respectively.

</details>


### [270] [Information Loss in LLMs' Multilingual Translation: The Role of Training Data, Language Proximity, and Language Family](https://arxiv.org/abs/2506.23340)
*Yumeng Lin,Xufeng Duan,David Haslett,Yige Chen,Zhenguang G. Cai*

Main category: cs.CL

TL;DR: 研究探讨了训练数据、语言接近性和语言家族如何影响多语言翻译中的信息损失，以及GPT-4和Llama 2的性能。


<details>
  <summary>Details</summary>
Motivation: 多语言翻译在某些低数据语言对中表现较差，研究目的是探讨语言模型在此类语言对中的表现受哪些因素影响及其具体影响方式。

Method: 使用GPT-4和Llama 2进行回译实验，采用BLEU分数和BERT相似度指标评估翻译质量，并分析训练数据、语言距离及语言家族对成绩的影响。

Result: 研究发现训练数据量与语言距离的相互作用显著；丰富的数据可缓解语言差异的影响，但与英语结构更接近的语言在低资源条件下翻译质量更高。此外，语言家族对翻译性能也具独立影响。

Conclusion: 大语言模型翻译质量不仅取决于数据量，也受到语言间结构和类型学关系的显著影响。这些洞察为改进多语言翻译提供了重要参考。

Abstract: Large language models have achieved impressive progress in multilingual
translation, yet they continue to face challenges with certain language
pairs-particularly those with limited training data or significant linguistic
divergence from English. This study systematically investigates how training
data, language proximity, and language family affect information loss in
multilingual translation. We evaluate two large language models, GPT-4 and
Llama 2, by performing round-trip translations. Translation quality was
assessed using BLEU scores and BERT similarity metrics. Our results reveal a
robust interaction between training data size and language distance: while
abundant training data can mitigate the effects of linguistic divergence,
languages structurally closer to English consistently yield higher translation
quality in low-resource conditions. Among various distance metrics,
orthographic, phylogenetic, syntactic, and geographical distances emerge as
strong predictors of translation performance. Language family also exerts an
independent influence. These findings contribute to a deeper understanding of
the linguistic constraints shaping multilingual translation in large language
models, emphasizing that translation quality is shaped not only by data volume
but also by structural and typological relationships between languages.

</details>


### [271] [ATGen: A Framework for Active Text Generation](https://arxiv.org/abs/2506.23342)
*Akim Tsvigun,Daniil Vasilev,Ivan Tsvigun,Ivan Lysenko,Talgat Bektleuov,Aleksandr Medvedev,Uliana Vinogradova,Nikita Severin,Mikhail Mozikov,Andrey Savchenko,Rostislav Grigorev,Ramil Kuleev,Fedor Zhdanov,Artem Shelmanov,Ilya Makarov*

Main category: cs.CL

TL;DR: 提出了ATGen框架，将主动学习与自然语言生成任务相结合，提高标注效率。


<details>
  <summary>Details</summary>
Motivation: 减少机器学习模型训练中的标注成本，同时应对自然语言生成任务快速兴起的挑战。

Method: 开发了ATGen框架，结合主动学习策略和自然语言生成任务，支持人力和大型语言模型进行标注，支持多种模型部署方式并提供统一平台。

Result: 展示不同主动学习策略在多种文本生成任务中的评估结果，证明其减少人力和API成本的能力。

Conclusion: ATGen框架成功应用主动学习于自然语言生成任务，降低了标注成本，代码和演示资料已公开。

Abstract: Active learning (AL) has demonstrated remarkable potential in reducing the
annotation effort required for training machine learning models. However,
despite the surging popularity of natural language generation (NLG) tasks in
recent years, the application of AL to NLG has been limited. In this paper, we
introduce Active Text Generation (ATGen) - a comprehensive framework that
bridges AL with text generation tasks, enabling the application of
state-of-the-art AL strategies to NLG. Our framework simplifies AL-empowered
annotation in NLG tasks using both human annotators and automatic annotation
agents based on large language models (LLMs). The framework supports LLMs
deployed as services, such as ChatGPT and Claude, or operated on-premises.
Furthermore, ATGen provides a unified platform for smooth implementation and
benchmarking of novel AL strategies tailored to NLG tasks. Finally, we present
evaluation results for state-of-the-art AL strategies across diverse settings
and multiple text generation tasks. We show that ATGen reduces both the effort
of human annotators and costs associated with API calls to LLM-based annotation
agents. The code of the framework is available on GitHub under the MIT license.
The video presentation is available at http://atgen-video.nlpresearch.group

</details>


### [272] [Perspective Dial: Measuring Perspective of Text and Guiding LLM Outputs](https://arxiv.org/abs/2506.23377)
*Taejin Kim,Siun-Chuon Mau,Konrad Vesey*

Main category: cs.CL

TL;DR: 本文探讨了大语言模型（LLMs）视角输出的定量测量及控制方法。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对LLMs输出中的偏见和视角的定量理解，这对于任务关键型应用非常重要。

Method: 提出了Perspective-Dial，包括两个关键组件：Perspective Space（视角空间）用于量化不同话题的视角；Systematic Prompt Engineering（系统提示工程）通过坐标贪心下降实现基于反馈调整视角输出。

Result: 该方法能定量化和调整LLMs在多种话题上的输出视角。

Conclusion: 这种方法可有效用于偏见检测、追踪与减轻，公共话语中的叙事检测与追踪，以及视角辩论机器人等应用。

Abstract: Large language models (LLMs) are used in a variety of mission-critical roles.
Due to the rapidly developing nature of LLMs, there is a lack of quantifiable
understanding of the bias and perspective associated with LLM output. Inspired
by this need, this paper considers the broader issue of perspective or
viewpoint of general text and perspective control of large-language model (LLM)
output. Perspective-Dial consists of two main components: a (1) metric space,
dubbed Perspective Space, that enables quantitative measurements of different
perspectives regarding a topic, and the use of (2) Systematic Prompt
Engineering that utilizes greedy-coordinate descent to control LLM output
perspective based on measurement feedback from the Perspective Space. The
empirical nature of the approach allows progress to side step a principled
understanding of perspective or bias -- effectively quantifying and adjusting
outputs for a variety of topics. Potential applications include detection,
tracking and mitigation of LLM bias, narrative detection, sense making and
tracking in public discourse, and debate bot advocating given perspective.

</details>


### [273] [Hierarchical Memory Organization for Wikipedia Generation](https://arxiv.org/abs/2506.23393)
*Eugene J. Yu,Dawei Zhu,Yifan Song,Xiangyu Wong,Jiebin Zhang,Wenxuan Shi,Xiaoguang Li,Qun Liu,Sujian Li*

Main category: cs.CL

TL;DR: 本文提出Memory Organization-based Generation(MOG)框架，通过分层记忆架构组织生成结构化的高质量维基百科文章，并在新数据集测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动生成维基百科文章因需整合多元且复杂的信息而极具挑战，本文旨在解决该问题。

Method: 提出MOG框架，从网络文档中提取细粒度记忆单元，递归组织成维基风格的层级结构驱动生成，并通过引用模块提升可追溯性。

Result: MOG在新数据集WikiStart中表现优于基线方法，生成了信息丰富且可靠的文章。

Conclusion: MOG框架有效缓解了信息幻觉，提高了文章的内容丰富性与可靠性，具有实际场景适应力。

Abstract: Generating Wikipedia articles autonomously is a challenging task requiring
the integration of accurate, comprehensive, and well-structured information
from diverse sources. This paper introduces the Memory Organization-based
Generation (MOG) framework, a novel approach to address these challenges by
leveraging a hierarchical memory architecture. MOG extracts fine-grained memory
units from web documents, recursively organizes them into a Wikipedia-style
hierarchical structure, and uses this structure to guide the generation
process. This ensures alignment between memory and the article outline,
improving both informativeness and verifiability while minimizing
hallucinations. Additionally, a citation module is implemented to enhance
traceability by linking every generated sentence to specific memory units.
Evaluations on our newly created WikiStart dataset demonstrate that MOG
outperforms baseline methods in producing informative and reliable articles,
making it particularly robust in real-world scenarios.

</details>


### [274] [Datasets for Fairness in Language Models: An In-Depth Survey](https://arxiv.org/abs/2506.23411)
*Jiale Zhang,Zichong Wang,Avash Palikhe,Zhipeng Yin,Wenbin Zhang*

Main category: cs.CL

TL;DR: 本文对当前语言模型研究中广泛使用的公平性数据集进行了全面审查，提出了统一的评估框架，并提供了实际性的建议与指导。


<details>
  <summary>Details</summary>
Motivation: 探讨公平性基准背后的数据集，分析其假设与局限性，旨在改进模型公平性研究。

Method: 通过多个维度分析数据集，提出统一的评估框架，揭示数据集中存在的人口统计差异模式，并进行实证研究。

Result: 确认公平性数据集和评分方法中存在的一致性偏差模式，提出实用的指导意见，并促进研究的透明性和可重复性。

Conclusion: 需优化公平性基准，关注更多样化的社会背景，提升模型公平性评估的可靠性与意义。

Abstract: Fairness benchmarks play a central role in shaping how we evaluate language
models, yet surprisingly little attention has been given to examining the
datasets that these benchmarks rely on. This survey addresses that gap by
presenting a broad and careful review of the most widely used fairness datasets
in current language model research, characterizing them along several key
dimensions including their origin, scope, content, and intended use to help
researchers better appreciate the assumptions and limitations embedded in these
resources. To support more meaningful comparisons and analyses, we introduce a
unified evaluation framework that reveals consistent patterns of demographic
disparities across datasets and scoring methods. Applying this framework to
twenty four common benchmarks, we highlight the often overlooked biases that
can influence conclusions about model fairness and offer practical guidance for
selecting, combining, and interpreting these datasets. We also point to
opportunities for creating new fairness benchmarks that reflect more diverse
social contexts and encourage more thoughtful use of these tools going forward.
All code, data, and detailed results are publicly available at
https://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree/main/datasets
to promote transparency and reproducibility across the research community.

</details>


### [275] [TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs](https://arxiv.org/abs/2506.23423)
*Felipe Nuti,Tim Franzmeyer,João Henriques*

Main category: cs.CL

TL;DR: 提出量化和系统分析微调对单个LLM输出影响的新方法——Tuning Contribution (TuCo)，展示其对模型行为和安全性的影响。


<details>
  <summary>Details</summary>
Motivation: 过去的研究仅分析了微调对模型整体性能的影响，缺乏对单个输出的系统分析方法。因此，引入了一种新的量化方法以深入了解微调对输出的影响。

Method: 通过追踪微调过程中模型的中间隐藏状态，分解微调LLM为预训练和微调两个部分，并提出了TuCo（微调组件与预训练组件的比值）作为量化指标分析微调对模型输出的贡献。

Result: 发现通过调节微调组件的权重可以影响模型的行为和性能。同时，观察到一些成功的对抗攻击降低了TuCo，这表明削弱微调的影响可能与此类攻击的成功相关。

Conclusion: TuCo为量化研究微调如何影响模型行为与安全性提供了工具，并解读了微调对模型各方面影响的细节。

Abstract: Past work has studied the effects of fine-tuning on large language models'
(LLMs) overall performance on certain tasks. However, a quantitative and
systematic method for analyzing its effect on individual outputs is still
lacking. Here, we propose a new method for measuring the contribution that
fine-tuning makes to individual LLM responses, assuming access to the original
pre-trained model. Our method tracks the model's intermediate hidden states,
providing a more fine-grained insight into the effects of fine-tuning than a
simple comparison of final outputs from pre-trained and fine-tuned models. We
introduce and theoretically analyze an exact decomposition of any fine-tuned
LLM into a pre-training component and a fine-tuning component. Empirically, we
find that model behavior and performance can be steered by up- or down-scaling
the fine-tuning component during the forward pass. Motivated by this finding
and our theoretical analysis, we define the Tuning Contribution (TuCo) as the
ratio of the magnitudes of the fine-tuning component to the pre-training
component. We observe that three prominent adversarial attacks on LLMs
circumvent safety measures in a way that reduces TuCo, and that TuCo is
consistently lower on prompts where these attacks succeed compared to those
where they do not. This suggests that attenuating the effect of fine-tuning on
model outputs plays a role in the success of such attacks. In summary, TuCo
enables the quantitative study of how fine-tuning influences model behavior and
safety, and vice versa.

</details>


### [276] [Pipelined Decoder for Efficient Context-Aware Text Generation](https://arxiv.org/abs/2506.23431)
*Zixian Huang,Chenxu Niu,Yu Gu,Gengyang Xiao,Xinwei Huang,Gong Cheng*

Main category: cs.CL

TL;DR: 现有生成式AI基于自回归模型逐步生成新tokens，质量高但速度受限。本研究提出一种新型解码器可实现并行生成，提升速度。


<details>
  <summary>Details</summary>
Motivation: 现有技术中，自回归模型生成速度受限，造成生成效率瓶颈。

Method: 提出了一种流水线解码器，通过并行生成多个子序列的方式，加快了文本生成。

Result: 实验表明，在问答、文本摘要及关键词生成任务中，新解码器在提升生成速度的同时保持了生成质量，无显著增加内存消耗。

Conclusion: 新解码器能够在不牺牲性能的情况下大幅改进生成效率，是生成式AI领域的重要创新。

Abstract: As the basis of generative AI, an autoregressive model requires the
generation of a new token depending on all the previously generated tokens,
which brings high quality but also restricts the model to generate tokens one
by one, forming a bottleneck limiting the generation speed. In this paper, we
propose a new decoder architecture that efficiently generates text in parallel
for context-aware generation tasks. Our proposed pipelined decoder initiates
the generation of multiple subsequences simultaneously, and, at each time-step,
it generates a new token for each subsequence to realize parallelism.
Experiments on multiple text generation tasks, including question answering,
text summarization, and keyphrase generation, show that our pipelined decoder
significantly improves the generation speed without a significant loss of
generation quality or additional memory consumption.

</details>


### [277] [What to Keep and What to Drop: Adaptive Table Filtering Framework](https://arxiv.org/abs/2506.23463)
*Jang Won June*

Main category: cs.CL

TL;DR: 提出一种针对表格数据筛选的模块化框架ATF，可显著减少数据量并提升特定任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在处理表格推理任务时，因输入长度限制导致性能下降的问题。

Method: 提出ATF框架，通过列描述生成、聚类和稀疏-致密对齐分数等方法，筛选掉无关列和行，无需重新训练即可与现有模型兼容使用。

Result: 在表格问答任务中，ATF减少了约70%的单元格数据量，并提升了跨域任务的性能；对表格事实验证任务表现略有下降。

Conclusion: ATF在不同任务中平衡了信息量与简约性，是一种适应性强的表格处理方案。

Abstract: Large language models (LLMs) for table-based reasoning often struggle with
large tables due to input length limits. We propose ATF (Adaptive Table
Filtering Framework), a modular and question-aware filtering pipeline that
prunes uninformative columns and rows using LLM-generated column descriptions,
clustering, and sparse-dense alignment scores. ATF integrates seamlessly with
existing models (e.g., TAPAS, TAPEX) without retraining. Experiments show that
ATF reduces table cells by ~70\%, boosting performance on out-of-domain TableQA
tasks while causing slight performance drops on Table Fact Verification, where
full-table context is more critical. These results highlight ATF's ability to
adaptively balance informativeness and minimalism across tasks.

</details>


### [278] [Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent](https://arxiv.org/abs/2506.23485)
*Haocheng Yu,Yaxiong Wu,Hao Wang,Wei Guo,Yong Liu,Yawen Li,Yuyang Ye,Junping Du,Enhong Chen*

Main category: cs.CL

TL;DR: 提出了一个称为TAIRA的新型交互式推荐系统，该系统通过引入思维模式蒸馏来增强推荐任务的规划能力，并显著提升与用户复杂意图的交互效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型驱动的推荐系统无法有效应对直观、不精确或模糊的用户需求，亟需一种能处理复杂意图的新方法。

Method: 提出了一个多代理系统TAIRA，其中包含一个管理代理，负责分解用户需求并规划子任务，引入了思维模式蒸馏技术来增强规划能力，同时设计了用户模拟方案评估推荐性能。

Result: 实验表明，TAIRA在多个数据集上的性能显著优于现有方法，尤其在处理高难度和新任务时展现更大的优势。

Conclusion: TAIRA展示了在交互式推荐系统中处理复杂用户意图的卓越能力，并通过公开代码验证了其实用性。

Abstract: Interactive recommendation is a typical information-seeking task that allows
users to interactively express their needs through natural language and obtain
personalized recommendations. Large language model-powered (LLM-powered) agents
have become a new paradigm in interactive recommendations, effectively
capturing users' real-time needs and enhancing personalized experiences.
However, due to limited planning and generalization capabilities, existing
formulations of LLM-powered interactive recommender agents struggle to
effectively address diverse and complex user intents, such as intuitive,
unrefined, or occasionally ambiguous requests. To tackle this challenge, we
propose a novel thought-augmented interactive recommender agent system (TAIRA)
that addresses complex user intents through distilled thought patterns.
Specifically, TAIRA is designed as an LLM-powered multi-agent system featuring
a manager agent that orchestrates recommendation tasks by decomposing user
needs and planning subtasks, with its planning capacity strengthened through
Thought Pattern Distillation (TPD), a thought-augmentation method that extracts
high-level thoughts from the agent's and human experts' experiences. Moreover,
we designed a set of user simulation schemes to generate personalized queries
of different difficulties and evaluate the recommendations based on specific
datasets. Through comprehensive experiments conducted across multiple datasets,
TAIRA exhibits significantly enhanced performance compared to existing methods.
Notably, TAIRA shows a greater advantage on more challenging tasks while
generalizing effectively on novel tasks, further validating its superiority in
managing complex user intents within interactive recommendation systems. The
code is publicly available at:https://github.com/Alcein/TAIRA.

</details>


### [279] [Reinforcement Fine-Tuning Enables MLLMs Learning Novel Tasks Stably](https://arxiv.org/abs/2506.23508)
*Zhihao Zhang,Qiaole Dong,Qi Zhang,Jun Zhao,Enyu Zhou,Zhiheng Xi,Senjie Jin,Xiaoran Fan,Yuhao Zhou,Yanwei Fu,Tao Ji,Tao Gui,Xuanjing Huang*

Main category: cs.CL

TL;DR: 研究通过拼图任务评价监督微调(SFT)和强化微调(RFT)在多模态大模型中的表现，发现SFT效果快但易遗忘，而RFT学习慢但保留知识。


<details>
  <summary>Details</summary>
Motivation: 探讨SFT和RFT在任务适应性与保留之前知识之间的权衡。

Method: 设计一种拼图任务，对Qwen2.5-VL模型进行实验，分析SFT和RFT的学习动态。

Result: SFT快速学习新任务但遗忘之前知识；RFT学习新任务较慢，但能够保留之前知识。

Conclusion: 数据分布对于知识遗忘更重要，RFT在稳定的连续学习中表现出潜力。

Abstract: Post-training algorithms such as Supervised Fine-Tuning (SFT) and
Reinforcement Fine-Tuning (RFT) are widely used to adapt multimodal large
language models to downstream tasks. While effective at task adaptation, their
impact on prior knowledge remains unclear. In this paper, we introduce jigsaw
puzzles as a novel task absent from existing pretraining corpora and
systematically study the behavior of SFT and RFT on an open-source multimodal
model, Qwen2.5-VL. Our experiments reveal a sharp trade-off: SFT enables rapid
task acquisition but leads to catastrophic forgetting, whereas RFT learns more
slowly on novel tasks but maintains prior knowledge. We analyze this phenomenon
through the lens of learning dynamics, showing that RFT reinforces correct
samples that are naturally aligned with the base model's probability landscape,
mitigating interference with prior knowledge. Moreover, supervised training on
correct RFT-simulated rollouts allows SFT to preserve knowledge while rapidly
learning new tasks. These findings suggest that data distribution, rather than
algorithmic differences, plays a central role in forgetting, and highlight
RFT's potential for stable continual learning in multimodal large language
models.

</details>


### [280] [NEU-ESC: A Comprehensive Vietnamese dataset for Educational Sentiment analysis and topic Classification toward multitask learning](https://arxiv.org/abs/2506.23524)
*Phan Quoc Hung Mai,Quang Hung Nguyen,Phuong Giang Duong,Hong Hanh Nguyen,Nguyen Tuan Long*

Main category: cs.CL

TL;DR: 本文提出了一个名为NEU-ESC的越南语数据集，专注于教育情感分类和主题分类任务，并通过BERT模型及多任务学习方法优化分类效果，最高准确率分别达到83.7%和79.8%。


<details>
  <summary>Details</summary>
Motivation: 越南语的教育领域情感分类资源匮乏，现有数据集缺乏适切性和完全性，同时缺少对学生用语和语境的覆盖。

Method: 作者开发了NEU-ESC数据集，该数据集来源于大学论坛，涵盖更多样的类别、多样化的词汇和较长文本，同时使用BERT编码器为基础的多任务学习模型，在情感和主题分类任务中进行性能优化。

Result: 所提出的数据集和模型表现优秀，情感分类和主题分类任务分别实现了83.7%和79.8%的准确性，相较以往数据集和模型有显著优势。

Conclusion: NEU-ESC数据集为越南语教育领域的情感分析带来了重要发展，同时展示了多任务学习和语言模型的潜能，并为未来研究搭建了基础。

Abstract: In the field of education, understanding students' opinions through their
comments is crucial, especially in the Vietnamese language, where resources
remain limited. Existing educational datasets often lack domain relevance and
student slang. To address these gaps, we introduce NEU-ESC, a new Vietnamese
dataset for Educational Sentiment Classification and Topic Classification,
curated from university forums, which offers more samples, richer class
diversity, longer texts, and broader vocabulary. In addition, we explore
multitask learning using encoder-only language models (BERT), in which we
showed that it achieves performance up to 83.7% and 79.8% accuracy for
sentiment and topic classification tasks. We also benchmark our dataset and
model with other datasets and models, including Large Language Models, and
discuss these benchmarks. The dataset is publicly available at:
https://huggingface.co/datasets/hung20gg/NEU-ESC.

</details>


### [281] [On Recipe Memorization and Creativity in Large Language Models: Is Your Model a Creative Cook, a Bad Cook, or Merely a Plagiator?](https://arxiv.org/abs/2506.23527)
*Jan Kvapil,Martin Fajcik*

Main category: cs.CL

TL;DR: 研究分析了LLM生成的食谱中的记忆性、创造性和荒谬性的水平，并设计了一个"LLM-as-judge"框架促进规模化研究。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型生成内容中记忆、创造和荒谬性的特性，尤其是在烹饪食谱的情境下。

Method: 通过对20个由Mixtral生成的预选食谱进行详细人工注释，以及开发一个自动化的“LLM-as-judge”管道来解析、生成和注释食谱内容。

Result: 发现Mixtral强烈依赖于来自训练中可能见过的在线内容，并验证了Llama 3.1+Gemma 2 9B在成分匹配时达到了78%的精度。

Conclusion: 研究提供了一种方法，可以大规模量化生成内容的记忆性、创造性和荒谬性，从而为语言模型的创作能力提供更严格的证据。

Abstract: This work-in-progress investigates the memorization, creativity, and nonsense
found in cooking recipes generated from Large Language Models (LLMs).
Precisely, we aim (i) to analyze memorization, creativity, and non-sense in
LLMs using a small, high-quality set of human judgments and (ii) to evaluate
potential approaches to automate such a human annotation in order to scale our
study to hundreds of recipes. To achieve (i), we conduct a detailed human
annotation on 20 preselected recipes generated by LLM (Mixtral), extracting
each recipe's ingredients and step-by-step actions to assess which elements are
memorized--i.e., directly traceable to online sources possibly seen during
training--and which arise from genuine creative synthesis or outright nonsense.
We find that Mixtral consistently reuses ingredients that can be found in
online documents, potentially seen during model training, suggesting strong
reliance on memorized content. To achieve aim (ii) and scale our analysis
beyond small sample sizes and single LLM validation, we design an
``LLM-as-judge'' pipeline that automates recipe generation, nonsense detection,
parsing ingredients and recipe steps, and their annotation. For instance,
comparing its output against human annotations, the best ingredient extractor
and annotator is Llama 3.1+Gemma 2 9B, achieving up to 78% accuracy on
ingredient matching. This automated framework enables large-scale
quantification of memorization, creativity, and nonsense in generated recipes,
providing rigorous evidence of the models' creative capacities.

</details>


### [282] [Semantic-guided Diverse Decoding for Large Language Model](https://arxiv.org/abs/2506.23601)
*Weijie Shi,Yue Cui,Yaguang Wu,Jingzhi Fang,Shibo Zhang,Mengze Li,Sirui Han,Jia Zhu,Jiajie Xu,Xiaofang Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种语义引导的多样解码(SemDiD)方法，较现有技术在质量和语义多样性上均有提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大模型多样解码方法主要着重于词汇多样性而非语义多样性，这限制了在诸如最佳策略选择和数据增强等应用中的表现。

Method: SemDiD通过嵌入空间操作，采用方向引导、动态分组排斥和位置去偏概率评估三种机制，以优化质量和多样性之间的平衡。

Result: 实验表明，SemDiD在多项任务中使Best-of-N覆盖率提高了1.4-5.2%，并在RLHF训练中加快了15%的收敛速度，且提高了准确率最高达2.1%。

Conclusion: SemDiD有效提升了现有解码方法的质量和语义多样性，适用于需要生成多样化语义响应的任务场景。

Abstract: Diverse decoding of large language models is crucial for applications
requiring multiple semantically distinct responses, yet existing methods
primarily achieve lexical rather than semantic diversity. This limitation
significantly constrains Best-of-N strategies, group-based reinforcement
learning, and data synthesis. While temperature sampling and diverse beam
search modify token distributions or apply n-gram penalties, they fail to
ensure meaningful semantic differentiation. We introduce Semantic-guided
Diverse Decoding (SemDiD), operating directly in embedding space that balances
quality with diversity through three complementary mechanisms: orthogonal
directional guidance, dynamic inter-group repulsion, and position-debiased
probability assessment. SemDiD harmonizes these competing objectives using
adaptive gain functions and constraint optimization, ensuring both quality
thresholds and maximal semantic differentiation. Experiments show SemDiD
consistently outperforms existing methods, improving Best-of-N coverage by
1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15%
while increasing accuracy by up to 2.1%.

</details>


### [283] [Evaluating the Simulation of Human Personality-Driven Susceptibility to Misinformation with LLMs](https://arxiv.org/abs/2506.23610)
*Manuel Pratelli,Marinella Petrocchi*

Main category: cs.CL

TL;DR: 本文研究大型语言模型（LLMs）是否能利用大五人格特质模拟心理差异，尤其在新闻分辨中的表现。结果表明部分人格与信息误导的关联可被可靠再现，但亦存在系统性偏差。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs生成的行为数据是否能够真实反映由人格特质驱动的心理差异，同时提供一种伦理且低成本的人类实验替代方案。

Method: 将LLMs设置为具有大五人格特质的代理，与已知人格特质的真人数据进行对比，分析其在新闻分辨任务中对标题真实性的判断能力。

Result: 某些人格与信息误导的关联（如亲和性与责任感）得到了可靠的再现，但同时也显示出LLMs内化和表达人格特质时的系统性偏差。

Conclusion: 尽管人格导向的LLMs在行为模拟方面展现出一定潜力，但它们在认知多样性建模中仍存在局限性和偏差。

Abstract: Large language models (LLMs) make it possible to generate synthetic
behavioural data at scale, offering an ethical and low-cost alternative to
human experiments. Whether such data can faithfully capture psychological
differences driven by personality traits, however, remains an open question. We
evaluate the capacity of LLM agents, conditioned on Big-Five profiles, to
reproduce personality-based variation in susceptibility to misinformation,
focusing on news discernment, the ability to judge true headlines as true and
false headlines as false. Leveraging published datasets in which human
participants with known personality profiles rated headline accuracy, we create
matching LLM agents and compare their responses to the original human patterns.
Certain trait-misinformation associations, notably those involving
Agreeableness and Conscientiousness, are reliably replicated, whereas others
diverge, revealing systematic biases in how LLMs internalize and express
personality. The results underscore both the promise and the limits of
personality-aligned LLMs for behavioral simulation, and offer new insight into
modeling cognitive diversity in artificial agents.

</details>


### [284] [Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack](https://arxiv.org/abs/2506.23661)
*Arnisa Fazla,Lucas Krauter,David Guzman Piedrahita,Andrianos Michail*

Main category: cs.CL

TL;DR: 本文扩展了BeamAttack算法，加入了支持词删除和跳过替换的功能，同时整合了LIME以更优先替换单词，实现了高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 提升文本分类系统鲁棒性评估的精准度与效率。

Method: 扩展了基于Beam Search的攻击算法，优化了词替换简化和优先级设定，并使用多个数据集和模型进行了实验验证。

Result: 在多种数据集和模型上达到超过99%的攻击成功率，同时保持语义和词汇相似性。

Conclusion: 该方法有效但仍存在局限，为文本分类模型的鲁棒性评估提供了一种工具，并实现代码开源。

Abstract: We extend BeamAttack, an adversarial attack algorithm designed to evaluate
the robustness of text classification systems through word-level modifications
guided by beam search. Our extensions include support for word deletions and
the option to skip substitutions, enabling the discovery of minimal
modifications that alter model predictions. We also integrate LIME to better
prioritize word replacements. Evaluated across multiple datasets and victim
models (BiLSTM, BERT, and adversarially trained RoBERTa) within the BODEGA
framework, our approach achieves over a 99\% attack success rate while
preserving the semantic and lexical similarity of the original texts. Through
both quantitative and qualitative analysis, we highlight BeamAttack's
effectiveness and its limitations. Our implementation is available at
https://github.com/LucK1Y/BeamAttack

</details>


### [285] [Zero-Shot Contextual Embeddings via Offline Synthetic Corpus Generation](https://arxiv.org/abs/2506.23662)
*Philip Lippmann,Jie Yang*

Main category: cs.CL

TL;DR: ZEST是一种零样本情境自适应框架，通过合成代理语料库生成域适配嵌入，无需访问目标语料或微调，性能接近完全语料访问的模型。


<details>
  <summary>Details</summary>
Motivation: 解决上下文感知嵌入需要访问目标语料或领域微调的问题，这在隐私敏感或资源受限环境中存在障碍。

Method: 使用分层方法根据少量典型文档生成几百篇的合成情境语料库，供冻结的上下文感知编码器在推理时使用。

Result: 在MTEB基准上，ZEST的零样本方法基于仅五个示例文档，性能仅比完全访问目标语料的模型低0.5%。

Conclusion: ZEST实现了在受限环境中部署高性能、适应性嵌入的实用方法，无需重训练。

Abstract: Context-aware embedding methods boost retrieval accuracy by conditioning on
corpus statistics (e.g., term co-occurrence and topical patterns) extracted
from neighboring documents. However, this context-aware approach requires
access to the target corpus or requires domain-specific finetuning, posing
practical barriers in privacy-sensitive or resource-constrained settings. We
present ZEST, a zero-shot contextual adaptation framework that replaces real
corpus access with a one-time offline synthesis of a compact proxy. Given only
a handful exemplar documents representative of the general target domain, we
use a multi-step hierarchical procedure to generate a synthetic context corpus
of several hundred documents that aims to emulate key domain-specific
distributions. At inference, the frozen context-aware encoder uses this proxy
corpus -- without any finetuning or target corpus access -- to produce
domain-adapted embeddings. Across the MTEB benchmark, ZEST's zero-shot
synthetic context adaptation using only five example documents performs within
0.5% of models leveraging full target corpus access -- demonstrating remarkable
efficacy without any retraining. ZEST thus provides a practical method for
deploying high-performance, adaptable embeddings in constrained environments.

</details>


### [286] [L0: Reinforcement Learning to Become General Agents](https://arxiv.org/abs/2506.23667)
*Junjie Zhang,Jingyi Xi,Zhuoyang Song,Junyu Lu,Yuhua Ke,Ting Sun,Yukun Yang,Jiaxing Zhang,Songxin Zhang,Zejian Xie*

Main category: cs.CL

TL;DR: 本文介绍了一个名为L-Zero (L0) 的新型训练管道，用于提升大语言模型在复杂多回合任务中的自主性和训练效率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在多回合、长时间任务中面临的可扩展性和训练效率问题。

Method: 提出了L-Zero训练管道，通过并行低成本的代理工作池和"代码即动作"的REPL机制操作代理框架NB-Agent，并使用基于验证奖励的强化学习（RLVR）方法进行训练。

Result: 在SimpleQA基准测试中准确率从30%提升至80%，在HotpotQA中从22%提升至41%。

Conclusion: L0有效地提升了大语言模型在复杂任务中的性能，并公开了相关模型和训练资源。

Abstract: Training large language models (LLMs) to act as autonomous agents for
multi-turn, long-horizon tasks remains significant challenges in scalability
and training efficiency. To address this, we introduce L-Zero (L0), a scalable,
end-to-end training pipeline for general-purpose agents. Featuring a low-cost,
extensible, and sandboxed concurrent agent worker pool, L0 lowers the barrier
for applying reinforcement learning in complex environments. We also introduce
NB-Agent, the agent scaffold within L0, which operates in a "code-as-action"
fashion via a Read-Eval-Print-Loop (REPL). We evaluate L0 on factuality
question-answering benchmarks. Our experiments demonstrate that a base model
can develop robust problem-solving skills using solely Reinforcement Learning
with Verifiable Rewards (RLVR). On the Qwen2.5-7B-Instruct model, our method
boosts accuracy on SimpleQA from 30 % to 80 % and on HotpotQA from 22 % to 41
%. We have open-sourced the entire L0 system, including our L0 series models,
the NB-Agent, a complete training pipeline, and the corresponding training
recipes on (https://github.com/cmriat/l0).

</details>


### [287] [AutoEvoEval: An Automated Framework for Evolving Close-Ended LLM Evaluation Data](https://arxiv.org/abs/2506.23735)
*JiaRu Wu,Mingwei Liu*

Main category: cs.CL

TL;DR: AutoEvoEval 是一种新的评估框架，利用进化操作生成多变且具有挑战性的测试样本，用于更全面地评估大语言模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的评价基准无法充分评估大语言模型在实际场景中的鲁棒性和泛化能力，现有的方法在扰动类型和多步复杂性控制上缺乏系统性。

Method: 提出 AutoEvoEval 框架，引入 22 种可解释的基本进化操作，支持多轮组合，生成多样化、具有挑战性和现实的测试样本。

Result: 实验表明，基本操作平均使准确率下降 7.283%，多重扰动组合使对抗效应放大至 52.932%，不同模型对相同扰动的敏感性差异显著。

Conclusion: 当前基准可能高估模型的实际泛化能力，强调了需要基于进化的鲁棒性评价方式。

Abstract: Large language models (LLMs) have shown remarkable performance on various
tasks, but existing evaluation benchmarks are often static and insufficient to
fully assess their robustness and generalization in realistic scenarios. Prior
work using evolutionary or adversarial data augmentation has improved
evaluation diversity but lacks systematic control over perturbation types and
multi-step complexity, limiting comprehensive robustness analysis. To address
these gaps, we propose AutoEvoEval, an evolution-based evaluation framework for
close-ended tasks such as multi-choice question answering. AutoEvoEval
introduces 22 interpretable atomic evolution operations and supports
multi-round compositions, enabling controlled generation of diverse,
challenging, and realistic test samples. We conduct extensive experiments
addressing four research questions on a broad set of open- and closed-source
LLMs. Our results show that atomic operations cause an average accuracy drop of
7.283\%, with structure-disrupting or misleading semantic edits causing the
largest declines. Model sensitivities vary significantly for the same
perturbation, and combining multiple evolution steps amplifies adversarial
effects by up to 52.932\%. These findings suggest current benchmarks may
overestimate true model generalization and emphasize the need for
evolution-aware robustness evaluation. Code and resources are available at:
https://github.com/SYSUSELab/AutoEvoEval.

</details>


### [288] [Positional Bias in Binary Question Answering: How Uncertainty Shapes Model Preferences](https://arxiv.org/abs/2506.23743)
*Tiziano Labruna,Simone Gallo,Giovanni Da San Martino*

Main category: cs.CL

TL;DR: 研究探讨了二元问答中的位置偏差，随着答案的不确定性增加，偏差也呈指数增长。


<details>
  <summary>Details</summary>
Motivation: 了解大型语言模型在二元问答中的位置偏差，尤其是在不确定性条件下的表现。

Method: 通过修改SQuAD-it数据集并引入不同不确定性水平的数据集，以及两种真实的高不确定性基准，对五个大型语言模型的表现进行分析。

Result: 在低不确定性条件下几乎没有偏差，而在高不确定性时偏差显著增加。

Conclusion: 答案的不确定性会显著影响模型的偏好公平性和位置一致性，揭示了位置偏差随不确定性的指数增长规律。

Abstract: Positional bias in binary question answering occurs when a model
systematically favors one choice over another based solely on the ordering of
presented options. In this study, we quantify and analyze positional bias
across five large language models under varying degrees of answer uncertainty.
We re-adapted the SQuAD-it dataset by adding an extra incorrect answer option
and then created multiple versions with progressively less context and more
out-of-context answers, yielding datasets that range from low to high
uncertainty. Additionally, we evaluate two naturally higher-uncertainty
benchmarks: (1) WebGPT - question pairs with unequal human-assigned quality
scores, and (2) Winning Arguments - where models predict the more persuasive
argument in Reddit's r/ChangeMyView exchanges. Across each dataset, the order
of the "correct" (or higher-quality/persuasive) option is systematically
flipped (first placed in position 1, then in position 2) to compute both
Preference Fairness and Position Consistency. We observe that positional bias
is nearly absent under low-uncertainty conditions, but grows exponentially when
it becomes doubtful to decide which option is correct.

</details>


### [289] [Do Thinking Tokens Help or Trap? Towards More Efficient Large Reasoning Model](https://arxiv.org/abs/2506.23840)
*Bowen Ding,Yuhan Chen,Futing Wang,Lingfeng Ming,Tao Lin*

Main category: cs.CL

TL;DR: 提出了一个解决大型推理模型中过度思考问题的新方法，名为DuP-PO，并在多项数学推理基准上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在处理简单任务时容易产生过多的消耗，因此需要优化其高效性和准确性。

Method: 提出了一种名为Dual Policy Preference Optimization (DuP-PO)的新算法，包括三大策略：均衡响应采样、精细优势控制、策略形状调节。

Result: 在五项数学推理基准上的实验结果表明，DuP-PO显著提升了推理模型的token效率和性能表现。

Conclusion: DuP-PO有效地解决了推理模型中过度思考的问题，同时提升了推理的效率和整体性能。

Abstract: Large Reasoning Models (LRMs) excel at solving complex problems but face an
overthinking dilemma. When handling simple tasks, they often produce verbose
responses overloaded with thinking tokens (e.g., wait, however). These tokens
trigger unnecessary high-level reasoning behaviors like reflection and
backtracking, reducing efficiency. In this work, our pilot study reveals that
these thinking-token-induced behaviors are not essential for effective
problem-solving and may even hinder correct reasoning within constrained token
budgets. We identify this phenomenon as the thinking trap. To mitigate this
issue, we propose Dual Policy Preference Optimization (DuP-PO), a novel
algorithm featuring: (1) A rollout sampling strategy that guarantees balanced
exposure to responses with and without thinking tokens; (2) A fine-grained
advantage control technique to dynamically regulate the prediction of target
tokens; (3) A policy shaping method ensuring stable gradient contributions from
thinking tokens. Experimental results on five popular math reasoning benchmarks
show that DuP-PO performs well on the popular LRM, which significantly improves
their token efficiency during reasoning, while achieving superior performance
of the base model.

</details>


### [290] [Garbage In, Reasoning Out? Why Benchmark Scores are Unreliable and What to Do About It](https://arxiv.org/abs/2506.23864)
*Seyed Mahed Mousavi,Edoardo Cecchinato,Lucia Hornikova,Giuseppe Riccardi*

Main category: cs.CL

TL;DR: 本研究对三个广泛使用的推理基准进行了系统性审查，揭示了基准设计和评估方法中的诸多问题，并通过人工标注重新评估，发现模型分数的提升可能与格式相关提示的对齐性更相关，而非推理能力的提升。


<details>
  <summary>Details</summary>
Motivation: 评估现有大语言模型（LLMs）的推理能力基准往往存在设计和评估方法上的缺陷，可能导致对模型推理能力的误判，因此需要揭示并改善这些问题。

Method: 使用五种LLMs（GPT-3、GPT-3.5、GPT-4、o1 和 LLaMA 3.1）作为诊断工具，通过系统性人工标注和在修订后的基准子集上进行重新评估，以审查基准设计中的缺陷并分析模型表现的敏感性。同时发布审查数据和工具以支持评估优化。

Result: 研究发现基准设计中存在结构、语义和实际问题（如项目重复、歧义措辞、不合理答案等）。现有的评分系统更注重输出形式，而非推理过程。进一步分析显示，模型的高分可能反映了与特定格式提示对齐性，而非一致的推理能力。

Conclusion: 当前基于基准的推理能力评估方案存在局限性，需要设计可以更好评估基于信息推理能力的评估协议。研究成果包括优化后的数据和工具，以促进模型推理能力的可解释性与诊断性评估。

Abstract: We conduct a systematic audit of three widely used reasoning benchmarks,
SocialIQa, FauxPas-EAI, and ToMi, and uncover pervasive flaws in both benchmark
items and evaluation methodology. Using five LLMs (GPT-{3, 3.5, 4, o1}, and
LLaMA 3.1) as diagnostic tools, we identify structural, semantic, and pragmatic
issues in benchmark design (e.g., duplicated items, ambiguous wording, and
implausible answers), as well as scoring procedures that prioritize output form
over reasoning process. Through systematic human annotation and re-evaluation
on cleaned benchmark subsets, we find that model scores often improve not due
to due to erratic surface wording variations and not to improved reasoning.
Infact, further analyses show that model performance is highly sensitive to
minor input variations such as context availability and phrasing, revealing
that high scores may reflect alignment with format-specific cues rather than
consistent inference based on the input. These findings challenge the validity
of current benchmark-based claims about reasoning in LLMs, and highlight the
need for evaluation protocols that assess reasoning as a process of drawing
inference from available information, rather than as static output selection.
We release audited data and evaluation tools to support more interpretable and
diagnostic assessments of model reasoning.

</details>


### [291] [Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting](https://arxiv.org/abs/2506.23888)
*André de Souza Loureiro,Jorge Valverde-Rebaza,Julieta Noguez,David Escarcega,Ricardo Marcacini*

Main category: cs.CL

TL;DR: 提出MAPS框架，通过多层次自我反思与自动提示增强LLMs的多步数学推理，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在复杂多步推理任务中的局限性，提升数学推理能力。

Method: 引入多层次自我反思与自动提示（MAPS）框架，结合链式思维、自我反思和动态提示，通过迭代改进解决方案。

Result: 在四个主流基准测试中，MAPS显著优于标准链式思维（CoT），与优化推理模型性能相当。

Conclusion: MAPS框架有效提升了通用LLMs的推理能力，通过权衡反思深度优化了性能与成本间的平衡。

Abstract: Recent advancements in Large Language Models (LLMs) have significantly
improved their problem-solving capabilities. However, these models still
struggle when faced with complex multi-step reasoning tasks. In this paper, we
propose the Multi-Layered Self-Reflection with Auto-Prompting (MAPS) framework,
a novel approach designed to enhance multi-step mathematical reasoning in LLMs
by integrating techniques such as Chain of Thought (CoT), Self-Reflection, and
Auto-Prompting. Unlike traditional static prompting methods, MAPS employs an
iterative refinement process. Initially, the model generates a solution using
CoT prompting. When errors are detected, an adaptive self-reflection mechanism
identifies and analyzes them, generating tailored prompts to guide corrections.
These dynamically adjusted prompts enable the model to iteratively refine its
reasoning. Experiments on four well-established benchmarks across multiple LLMs
show that MAPS significantly outperforms standard CoT and achieves competitive
results with reasoning-optimized models. In addition, MAPS enables
general-purpose LLMs to reach performance levels comparable to specialized
reasoning models. While deeper reflection layers improve accuracy, they also
increase token usage and costs. To balance this trade-off, MAPS strategically
limits reflection depth, ensuring an optimal balance between cost and reasoning
performance.

</details>


### [292] [The Trilemma of Truth in Large Language Models](https://arxiv.org/abs/2506.23921)
*Germans Savcisens,Tina Eliassi-Rad*

Main category: cs.CL

TL;DR: 本研究提出了一种名为sAwMIL的新方法，用于评估大语言模型中知识的真实性，并提出一些关键观察和改进性建议。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的广泛应用，评估其内部知识真实性的需求日益迫切，但现有方法存在理论假设上的缺陷，需要引入更可靠的评估方法。

Method: 提出sAwMIL方法，通过利用多实例学习和可信预测，结合模型的内部激活量，分类模型输出的陈述为真、假或非真非假三类，同时在多种LLM和新数据集上进行评估。

Result: 研究发现，例如(1) 真实性信号集中于模型深度的后三分之一部分；(2) 真与假信号非对称；(3) 线性探针对chat模型的效果优于default模型；(4) 对某些强化学习调整的模型，需要非线性探针捕捉信号；(5) LLM能捕捉第三类独立于真与假的信号。

Conclusion: 通过提出sAwMIL方法，该研究为验证LLM“所知”的可靠性和检测其特定信号提供了实用的方式，对未来大语言模型的研究和应用具有重要意义。

Abstract: We often attribute human characteristics to large language models (LLMs) and
claim that they "know" certain things. LLMs have an internal probabilistic
knowledge that represents information retained during training. How can we
assess the veracity of this knowledge? We examine two common methods for
probing the veracity of LLMs and discover several assumptions that are flawed.
To address these flawed assumptions, we introduce sAwMIL (short for Sparse
Aware Multiple-Instance Learning), a probing method that utilizes the internal
activations of LLMs to separate statements into true, false, and neither.
sAwMIL is based on multiple-instance learning and conformal prediction. We
evaluate sAwMIL on 5 validity criteria across 16 open-source LLMs, including
both default and chat-based variants, as well as on 3 new datasets. Among the
insights we provide are: (1) the veracity signal is often concentrated in the
third quarter of an LLM's depth; (2) truth and falsehood signals are not always
symmetric; (3) linear probes perform better on chat models than on default
models; (4) nonlinear probes may be required to capture veracity signals for
some LLMs with reinforcement learning from human feedback or knowledge
distillation; and (5) LLMs capture a third type of signal that is distinct from
true and false and is neither true nor false. These findings provide a reliable
method for verifying what LLMs "know" and how certain they are of their
probabilistic internal knowledge.

</details>


### [293] [IMPACT: Inflectional Morphology Probes Across Complex Typologies](https://arxiv.org/abs/2506.23929)
*Mohammed J. Saeed,Tommi Vehvilainen,Evgeny Fedoseev,Sevil Caliskan,Tatiana Vodolazova*

Main category: cs.CL

TL;DR: 本文讨论了大型语言模型（LLMs）在多语种基准测试中取得的进展，但指出其在语法复杂性和形态学的处理能力上存在局限性。


<details>
  <summary>Details</summary>
Motivation: 了解LLMs对多语言形态学的实际掌握情况，尤其关注形态复杂的语言。

Method: 引入一种名为IMPACT的评估框架，涵盖五种语言的形态学测试，检验LLMs对词形变化的表现及局限性。

Result: 发现尽管LLMs在英语上表现强劲，但在罕见形态特征及非英语语言上的表现较弱，尤其是判断语法错误的能力。

Conclusion: LLMs在理解语言复杂性方面仍有较大提升空间，IMPACT框架为后续研究提供支持。

Abstract: Large Language Models (LLMs) have shown significant progress on various
multilingual benchmarks and are increasingly used to generate and evaluate text
in non-English languages. However, while they may produce fluent outputs, it
remains unclear to what extent these models truly grasp the underlying
linguistic complexity of those languages, particularly in morphology. To
investigate this, we introduce IMPACT, a synthetically generated evaluation
framework focused on inflectional morphology, which we publicly release,
designed to evaluate LLM performance across five morphologically rich
languages: Arabic, Russian, Finnish, Turkish, and Hebrew. IMPACT includes
unit-test-style cases covering both shared and language-specific phenomena,
from basic verb inflections (e.g., tense, number, gender) to unique features
like Arabic's reverse gender agreement and vowel harmony in Finnish and
Turkish. We assess eight multilingual LLMs that, despite strong English
performance, struggle with other languages and uncommon morphological patterns,
especially when judging ungrammatical examples. We also show that Chain of
Thought and Thinking Models can degrade performance. Our work exposes gaps in
LLMs' handling of linguistic complexity, pointing to clear room for
improvement. To support further research, we publicly release the IMPACT
framework.

</details>


### [294] [Leveraging the Potential of Prompt Engineering for Hate Speech Detection in Low-Resource Languages](https://arxiv.org/abs/2506.23930)
*Ruhina Tabasshum Prome,Tarikul Islam Tamiti,Anomadarshi Barua*

Main category: cs.CL

TL;DR: 本文提出了一种通过LLM的提示工程（prompt engineering）来检测低资源语言（如孟加拉语）中的仇恨言论的方法，并引入了创新的隐喻式提示（metaphor prompting），且在多个语言上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 社交媒体仇恨言论的迅速增加对个人带来了威胁，特别是低资源语言的仇恨言论检测因数据缺乏而挑战重重。

Method: 探索了六种提示策略：零样本提示、拒绝抑制、讨好分类器、多样本提示、角色提示及创新的隐喻提示，并将其应用在Llama2-7B模型上，同时与传统深度学习方法进行了对比。

Result: 隐喻式提示在孟加拉语等低资源语言以及英语和德语等高资源语言中都表现出色。评估使用F1分数和环境影响因子。

Conclusion: 提出的隐喻提示在低资源语言的仇恨言论检测中提供了有效的解决方案，并且在多语言场景中具有广泛适用性。

Abstract: The rapid expansion of social media leads to a marked increase in hate
speech, which threatens personal lives and results in numerous hate crimes.
Detecting hate speech presents several challenges: diverse dialects, frequent
code-mixing, and the prevalence of misspelled words in user-generated content
on social media platforms. Recent progress in hate speech detection is
typically concentrated on high-resource languages. However, low-resource
languages still face significant challenges due to the lack of large-scale,
high-quality datasets. This paper investigates how we can overcome this
limitation via prompt engineering on large language models (LLMs) focusing on
low-resource Bengali language. We investigate six prompting strategies -
zero-shot prompting, refusal suppression, flattering the classifier, multi-shot
prompting, role prompting, and finally our innovative metaphor prompting to
detect hate speech effectively in low-resource languages. We pioneer the
metaphor prompting to circumvent the built-in safety mechanisms of LLMs that
marks a significant departure from existing jailbreaking methods. We
investigate all six different prompting strategies on the Llama2-7B model and
compare the results extensively with three pre-trained word embeddings - GloVe,
Word2Vec, and FastText for three different deep learning models - multilayer
perceptron (MLP), convolutional neural network (CNN), and bidirectional gated
recurrent unit (BiGRU). To prove the effectiveness of our metaphor prompting in
the low-resource Bengali language, we also evaluate it in another low-resource
language - Hindi, and two high-resource languages - English and German. The
performance of all prompting techniques is evaluated using the F1 score, and
environmental impact factor (IF), which measures CO$_2$ emissions, electricity
usage, and computational time.

</details>


### [295] [Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs](https://arxiv.org/abs/2506.23940)
*Yang Dai,Jianxiang An,Tianwei Lin,Hongyang He,Hongzhe Huang,Wenqiao Zhang,Zheqi Lv,Siliang Tang,Yueting Zhuang*

Main category: cs.CL

TL;DR: 提出了一个用于统一领域特定专业能力的参数集成框架，以解决多模态大型语言模型在领域任务中的知识分割问题。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大型语言模型虽然取得了成功，但在处理不同数据类型尤其是特定任务进行微调后表现会下降，且领域特定模型间知识共享的研究不足。

Method: 提出Compatibility-Aware Parameter Splicing (CAPS)策略，结合局部功能归因和全局信息理论信号，实现选择性参数融合，并通过域兼容性评分机制量化专家模型间的对齐度。

Result: 验证了框架在多模态基准测试中的有效性，证明了其可以整合领域知识并保持模型模块化结构。

Conclusion: 该框架为实现复合型、领域自适应的模型提供了可扩展的解决方案，同时优化了跨域知识共享能力。

Abstract: Multimodal Large Language Models (MLLMs) have achieved success across various
domains. However, their applicability tends to degrade when confronted with
different types of data inputs, especially for MLLMs that have been fine-tuned
for specific tasks. Despite its importance, the study of knowledge sharing
among domain-specific MLLMs--such as those trained for mathematics or
code--remains largely underexplored. To address the fragmentation of knowledge
across domain-specialized MLLMs, we propose a unified parameter integration
framework that enables modular composition of expert capabilities. Our method
is grounded in a novel Compatibility-Aware Parameter Splicing (CAPS) strategy,
which leverages both local functional attribution and global
information-theoretic signals to guide selective parameter fusion. By extending
this mechanism to the low-rank adaptation layer granularity, we ensure
efficient integration with minimal inference overhead. Furthermore, we
introduce a domain compatibility scoring mechanism that quantifies inter-expert
alignment at the activation level and correlates with downstream task utility.
This principled fusion protocol allows the final model to synergize
heterogeneous expertise while preserving structural modularity. Extensive
evaluations across diverse multimodal benchmarks validate the effectiveness of
our framework, offering a scalable path toward compositional, domain-adaptive
MLLMs.

</details>


### [296] [Unveiling Decision-Making in LLMs for Text Classification : Extraction of influential and interpretable concepts with Sparse Autoencoders](https://arxiv.org/abs/2506.23951)
*Mathis Le Bail,Jérémie Dentan,Davide Buscaldi,Sonia Vanier*

Main category: cs.CL

TL;DR: 本文探讨稀疏自编码器（SAEs）在句子分类中提取可解释概念的有效性，并提出了一种新架构，通过实验验证其改进了解释性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何从大型语言模型（LLMs）的内部表示中提取人类可解释概念，特别是在尚未深入研究的句子分类领域。

Method: 提出了一种针对文本分类的稀疏自编码器（SAE）新架构，结合专用分类头和激活率稀疏损失，同时设计了评估概念解释性的两种新指标。

Result: 新架构在两个分类基准和四个微调的Pythia家族模型上测试表现优异，改善了提取特征的因果性和可解释性。

Conclusion: 该方法为扩展SAE在文本分类任务中的可解释性提供了有效途径，对概念提取技术具有推进作用。

Abstract: Sparse Autoencoders (SAEs) have been successfully used to probe Large
Language Models (LLMs) and extract interpretable concepts from their internal
representations. These concepts are linear combinations of neuron activations
that correspond to human-interpretable features. In this paper, we investigate
the effectiveness of SAE-based explainability approaches for sentence
classification, a domain where such methods have not been extensively explored.
We present a novel SAE-based architecture tailored for text classification,
leveraging a specialized classifier head and incorporating an activation rate
sparsity loss. We benchmark this architecture against established methods such
as ConceptShap, Independent Component Analysis, and other SAE-based concept
extraction techniques. Our evaluation covers two classification benchmarks and
four fine-tuned LLMs from the Pythia family. We further enrich our analysis
with two novel metrics for measuring the precision of concept-based
explanations, using an external sentence encoder. Our empirical results show
that our architecture improves both the causality and interpretability of the
extracted features.

</details>


### [297] [TaP: A Taxonomy-Guided Framework for Automated and Scalable Preference Data Generation](https://arxiv.org/abs/2506.23979)
*Renren Jin,Tianhao Shen,Xinwei Wu,Dan Shi,Haoran Sun,Wuwei Huang,Quandong Wang,Wei Liu,Jian Luan,Bin Wang,Deyi Xiong*

Main category: cs.CL

TL;DR: 提出TaP框架，通过结构化分类法生成跨语言偏好数据集，用于语言模型的监督和偏好微调，并取得显著优于现有数据集的效果。


<details>
  <summary>Details</summary>
Motivation: 当前的监督微调和偏好微调需要高质量数据集，但数据构建资源消耗大且多以英语为主。

Method: 提出Taxonomy-Guided Preference Data Generation (TaP)框架，通过结构性分类法来自动和高效地生成多语言偏好数据集。

Result: 使用TaP框架生成的数据集进行微调后，显著优于基于现有开源数据集微调的模型性能，尤其在规模较小的数据集上表现出色。

Conclusion: TaP框架可提升多语言模型对指令的理解和对人类偏好的对齐能力，体现出高效生成数据集的潜力。

Abstract: Conducting supervised fine-tuning and preference fine-tuning on large
language models (LLMs) requires high-quality datasets to improve their ability
to follow instructions and align with human preferences and values. However,
constructing such datasets is resource-intensive, and most available datasets
for supervised and preference fine-tuning are in English. To address these
challenges, we propose the \underline{\textbf{Ta}}xonomy-Guided
\underline{\textbf{P}}reference Data Generation (TaP) framework, which
facilitates automated and scalable construction of preference datasets across
various languages. TaP is grounded in a structured taxonomy that allows
fine-grained control over dataset composition, thereby ensuring both diversity
and comprehensive coverage. We employ TaP-generated datasets to perform
supervised and preference fine-tuning on various LLMs. Experimental results
demonstrate that LLMs trained on TaP-generated datasets outperform those
trained on existing open-source datasets. Remarkably, LLMs trained on
TaP-generated datasets surpass the performance of those trained on an
open-source dataset that is 180 times larger.

</details>


### [298] [Machine Understanding of Scientific Language](https://arxiv.org/abs/2506.23990)
*Dustin Wright*

Main category: cs.CL

TL;DR: 论文探讨科学文本的忠实性问题，提出数据集、方法和工具来自动分析科学语言，涵盖事实核查、少样本学习等多个领域。


<details>
  <summary>Details</summary>
Motivation: 随着科学文本在线数量激增，自动辨别科学文本是否忠实于其本源的重要性日益突出。

Method: 通过自然语言处理与机器学习技术，提出了用于识别可核查性声明、多源域适配、零样本科学事实核查等方法。

Result: 开发了系列可用于理解科学传播的资源与方法，能够有效处理有限科学文本以识别误导性陈述。

Conclusion: 所提方法在科学传播理解和相关任务中表现优异，有助于从科学语言中生成新见解并支持科学事实核查领域。

Abstract: Scientific information expresses human understanding of nature. This
knowledge is largely disseminated in different forms of text, including
scientific papers, news articles, and discourse among people on social media.
While important for accelerating our pursuit of knowledge, not all scientific
text is faithful to the underlying science. As the volume of this text has
burgeoned online in recent years, it has become a problem of societal
importance to be able to identify the faithfulness of a given piece of
scientific text automatically. This thesis is concerned with the cultivation of
datasets, methods, and tools for machine understanding of scientific language,
in order to analyze and understand science communication at scale. To arrive at
this, I present several contributions in three areas of natural language
processing and machine learning: automatic fact checking, learning with limited
data, and scientific text processing. These contributions include new methods
and resources for identifying check-worthy claims, adversarial claim
generation, multi-source domain adaptation, learning from crowd-sourced labels,
cite-worthiness detection, zero-shot scientific fact checking, detecting
exaggerated scientific claims, and modeling degrees of information change in
science communication. Critically, I demonstrate how the research outputs of
this thesis are useful for effectively learning from limited amounts of
scientific text in order to identify misinformative scientific statements and
generate new insights into the science communication process

</details>


### [299] [Auto-TA: Towards Scalable Automated Thematic Analysis (TA) via Multi-Agent Large Language Models with Reinforcement Learning](https://arxiv.org/abs/2506.23998)
*Seungjun Yi,Joakim Nguyen,Huimin Xu,Terence Lim,Andrew Well,Mia Markey,Ying Ding*

Main category: cs.CL

TL;DR: 提出一种基于大型语言模型的全自动主题分析流水线，用以处理先天性心脏病（CHD）患者复杂的临床叙述。


<details>
  <summary>Details</summary>
Motivation: 解决传统临床指标中难以体现患者和护理者观点的问题，并减轻手动主题分析的工作量。

Method: 提出了一种基于多代理框架的自动化主题分析系统，集成强化学习从人类反馈（RLHF），提升主题分析的相关性和质量。

Result: 系统能够实现对大规模定性数据的高效主题分析，且可针对特定临床背景进行模型微调。

Conclusion: 该方法支持患者为中心的大规模分析，在减少人工成本的同时，确保主题分析与人类结果一致。

Abstract: Congenital heart disease (CHD) presents complex, lifelong challenges often
underrepresented in traditional clinical metrics. While unstructured narratives
offer rich insights into patient and caregiver experiences, manual thematic
analysis (TA) remains labor-intensive and unscalable. We propose a fully
automated large language model (LLM) pipeline that performs end-to-end TA on
clinical narratives, which eliminates the need for manual coding or full
transcript review. Our system employs a novel multi-agent framework, where
specialized LLM agents assume roles to enhance theme quality and alignment with
human analysis. To further improve thematic relevance, we optionally integrate
reinforcement learning from human feedback (RLHF). This supports scalable,
patient-centered analysis of large qualitative datasets and allows LLMs to be
fine-tuned for specific clinical contexts.

</details>


### [300] [Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective](https://arxiv.org/abs/2506.24006)
*Anselm R. Strohmaier,Wim Van Dooren,Kathrin Seßler,Brian Greer,Lieven Verschaffel*

Main category: cs.CL

TL;DR: 本文探讨了大语言模型（LLMs）在数学教育中的潜力，特别是在文字题解题中，但发现其能力较表面化，对真实世界背景的理解存在不足。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs如何支持数学学习，特别是文字题的解答能力，以及探讨其在课堂中的潜在应用和限制。

Method: 通过技术概览、213篇文献系统综述，以及对GPT-3.5-turbo等模型的287道数学文字题的实证评估，评估LLMs在文字题解答中的表现。

Result: LLMs在解决较为简化且无需考虑现实背景的文字题（如s-problems）上表现出色，但在真实世界背景复杂或不合逻辑的问题上表现欠佳。

Conclusion: LLMs在数学文字题解决中展现了表面化的解题能力，但缺乏对题目现实意义的深入理解，这限制了其作为课堂教学工具的价值。

Abstract: The progress of Large Language Models (LLMs) like ChatGPT raises the question
of how they can be integrated into education. One hope is that they can support
mathematics learning, including word-problem solving. Since LLMs can handle
textual input with ease, they appear well-suited for solving mathematical word
problems. Yet their real competence, whether they can make sense of the
real-world context, and the implications for classrooms remain unclear. We
conducted a scoping review from a mathematics-education perspective, including
three parts: a technical overview, a systematic review of word problems used in
research, and a state-of-the-art empirical evaluation of LLMs on mathematical
word problems. First, in the technical overview, we contrast the
conceptualization of word problems and their solution processes between LLMs
and students. In computer-science research this is typically labeled
mathematical reasoning, a term that does not align with usage in mathematics
education. Second, our literature review of 213 studies shows that the most
popular word-problem corpora are dominated by s-problems, which do not require
a consideration of realities of their real-world context. Finally, our
evaluation of GPT-3.5-turbo, GPT-4o-mini, GPT-4.1, and o3 on 287 word problems
shows that most recent LLMs solve these s-problems with near-perfect accuracy,
including a perfect score on 20 problems from PISA. LLMs still showed
weaknesses in tackling problems where the real-world context is problematic or
non-sensical. In sum, we argue based on all three aspects that LLMs have
mastered a superficial solution process but do not make sense of word problems,
which potentially limits their value as instructional tools in mathematics
classrooms.

</details>


### [301] [EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations](https://arxiv.org/abs/2506.24016)
*Hyunjong Kim,Sangyeop Kim,Jongheon Jeong,Yeongjae Cho,Sungzoon Cho*

Main category: cs.CL

TL;DR: 提出了一种名为EXPERT的无参考评价指标，通过生成结构化解释对图像描述进行评估，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的图像描述评价指标缺乏统一标准，用于评价解释质量的规范化方法也尚未建立。

Method: 作者提出EXPERT指标，基于流畅性、相关性和描述性三大标准，通过构建大规模高质量解释数据集，开发了一个两阶段评估模板，用于监督视觉-语言模型生成评分和解释。

Result: EXPERT在基准数据集上达到了最先进的性能，并且通过全面的人类评估，生成的解释质量显著优于现有指标。

Conclusion: EXPERT为图像描述生成提供了一种高效的、可解释的评价方法，不仅表现优异，还能生成高质量的解释。

Abstract: Recent advances in large language models and vision-language models have led
to growing interest in explainable evaluation metrics for image captioning.
However, these metrics generate explanations without standardized criteria, and
the overall quality of the generated explanations remains unverified. In this
paper, we propose EXPERT, a reference-free evaluation metric that provides
structured explanations based on three fundamental criteria: fluency,
relevance, and descriptiveness. By constructing large-scale datasets of
high-quality structured explanations, we develop a two-stage evaluation
template to effectively supervise a vision-language model for both scoring and
explanation generation. EXPERT achieves state-of-the-art results on benchmark
datasets while providing significantly higher-quality explanations than
existing metrics, as validated through comprehensive human evaluation. Our code
and datasets are available at https://github.com/hjkim811/EXPERT.

</details>


### [302] [STACK: Adversarial Attacks on LLM Safeguard Pipelines](https://arxiv.org/abs/2506.24068)
*Ian R. McKenzie,Oskar J. Hollinsworth,Tom Tseng,Xander Davies,Stephen Casper,Aaron D. Tucker,Robert Kirk,Adam Gleave*

Main category: cs.CL

TL;DR: 本文通过研究和红队化一种开源的防御管道，评估了人工智能系统潜在误用的防护措施。


<details>
  <summary>Details</summary>
Motivation: 解决当前前沿人工智能开发者对于防御管道安全性的评估有限问题。

Method: 研发了一种新的少样本提示输入输出分类器，与现有开源防护模型对比，并设计了一个阶段攻击(STACK)过程进行针对性测试。

Result: 少样本分类器对三种攻击与两个数据集的攻击成功率降至0%；但STACK在黑箱环境下对这些防御机制的成功率达到71%。

Conclusion: 提出了可以抵御阶段攻击的具体缓解措施，同时展示了即便没有接触目标防御系统，也仍然可以设计攻击的可行性。

Abstract: Frontier AI developers are relying on layers of safeguards to protect against
catastrophic misuse of AI systems. Anthropic guards their latest Claude 4 Opus
model using one such defense pipeline, and other frontier developers including
Google DeepMind and OpenAI pledge to soon deploy similar defenses. However, the
security of such pipelines is unclear, with limited prior work evaluating or
attacking these pipelines. We address this gap by developing and red-teaming an
open-source defense pipeline. First, we find that a novel few-shot-prompted
input and output classifier outperforms state-of-the-art open-weight safeguard
model ShieldGemma across three attacks and two datasets, reducing the attack
success rate (ASR) to 0% on the catastrophic misuse dataset ClearHarm. Second,
we introduce a STaged AttaCK (STACK) procedure that achieves 71% ASR on
ClearHarm in a black-box attack against the few-shot-prompted classifier
pipeline. Finally, we also evaluate STACK in a transfer setting, achieving 33%
ASR, providing initial evidence that it is feasible to design attacks with no
access to the target pipeline. We conclude by suggesting specific mitigations
that developers could use to thwart staged attacks.

</details>


### [303] [On the Predictive Power of Representation Dispersion in Language Models](https://arxiv.org/abs/2506.24106)
*Yanhong Li,Ming Li,Karen Livescu,Jiawei Zhou*

Main category: cs.CL

TL;DR: 提出语言模型的文本预测能力与其嵌入空间的分散性高度相关，并通过多种方法进一步利用这种分散性来优化模型表现。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型嵌入空间的分散性如何影响模型性能，并寻找利用这一特性的实际应用场景。

Method: 通过测量嵌入向量的余弦距离分散性（平均配对余弦距离），分析其与困惑度的关系；对高分散层进行任务优化；引入简单的“推离目标”以增加嵌入分散性并提升性能。

Result: 发现嵌入分散性与低困惑度强烈负相关，增大分散性可提升无标签任务的域外表现，优化层选择与表示，最终降低困惑度。

Conclusion: 分散性是语言模型结构与性能的关键因素，通过提高分散性可解锁多个实际任务中模型的潜力，同时提供了一种提升和优化模型性能的新方法。

Abstract: We show that a language model's ability to predict text is tightly linked to
the breadth of its embedding space: models that spread their contextual
representations more widely tend to achieve lower perplexity. Concretely, we
find that representation dispersion - the average pairwise cosine distance
among hidden vectors - strongly and negatively correlates with perplexity
across diverse model families (LLaMA, Qwen, and others) and domains (Wikipedia,
news, scientific abstracts). Beyond illustrating this link, we show how
dispersion can be leveraged for a range of practical tasks without requiring
labeled data. First, measuring dispersion on unlabeled text allows us to
predict downstream accuracy in new domains, offering a data-efficient tool for
model selection. Next, we find that identifying layers with higher dispersion
pinpoints the best representations for retrieval-based methods such as kNN-LM,
bypassing exhaustive layer-by-layer searches. Finally, we integrate a simple
push-away objective into training, which increases dispersion in both
single-domain and cross-domain scenarios and directly improves perplexity in
each.

</details>


### [304] [Computational Detection of Intertextual Parallels in Biblical Hebrew: A Benchmark Study Using Transformer-Based Language Models](https://arxiv.org/abs/2506.24117)
*David M. Smiley*

Main category: cs.CL

TL;DR: 研究评估了预训练的基于Transformer的语言模型在希伯来圣经中检测文本平行段落的潜力，发现E5和AlephBERT表现出显著的能力，提升了检测效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 识别希伯来圣经中的平行段落对于揭示互文关系至关重要，但传统手动比较方法繁琐且易出错，因此需要新的自动化解决方案。

Method: 采用包括E5、AlephBERT、MPNet和LaBSE在内的预训练模型，使用余弦相似度和瓦瑟斯坦距离评估模型生成词嵌入的能力，以区分平行与非平行段落。

Result: E5在平行检测上表现突出，而AlephBERT在非平行区分上具有更强能力，展示了预训练模型在文本平行检测中的潜力。

Conclusion: 预训练模型可以有效提升古代文本平行段落检测的效率和准确性，具备广泛的古语言研究应用潜力。

Abstract: Identifying parallel passages in biblical Hebrew is foundational in biblical
scholarship for uncovering intertextual relationships. Traditional methods rely
on manual comparison, which is labor-intensive and prone to human error. This
study evaluates the potential of pre-trained transformer-based language models,
including E5, AlephBERT, MPNet, and LaBSE, for detecting textual parallels in
the Hebrew Bible. Focusing on known parallels between the books of Samuel/Kings
and Chronicles, I assessed each model's capability to generate word embeddings
that delineate parallel from non-parallel passages. Utilizing cosine similarity
and Wasserstein Distance measures, I found that E5 and AlephBERT show
significant promise, with E5 excelling in parallel detection and AlephBERT
demonstrating stronger non-parallel differentiation. These findings indicate
that pre-trained models can enhance the efficiency and accuracy of detecting
intertextual parallels in ancient texts, suggesting broader applications for
ancient language studies.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [305] [Bootstrapping Human-Like Planning via LLMs](https://arxiv.org/abs/2506.22604)
*David Porfirio,Vincent Hsiao,Morgan Fine-Morris,Leslie Smith,Laura M. Hiatt*

Main category: cs.AI

TL;DR: 本研究探讨结合拖拽式接口与自然语言编程，以提升用户任务指定的便利性及精确性。


<details>
  <summary>Details</summary>
Motivation: 探讨如何结合自然语言编程和拖拽接口的优势，为用户提供便捷、高精度的编程方式。

Method: 设计一个基于大语言模型（LLM）的流程，接收自然语言输入并生成类似人类设计的任务动作序列，与手动指定的序列进行比较。

Result: 研究发现，大型模型在生成类似人类动作序列方面表现优于小型模型，但小型模型的性能也颇为令人满意。

Conclusion: 将自然语言编程与拖拽交互结合是可行的，不同规模的模型表现各有特点。

Abstract: Robot end users increasingly require accessible means of specifying tasks for
robots to perform. Two common end-user programming paradigms include
drag-and-drop interfaces and natural language programming. Although natural
language interfaces harness an intuitive form of human communication,
drag-and-drop interfaces enable users to meticulously and precisely dictate the
key actions of the robot's task. In this paper, we investigate the degree to
which both approaches can be combined. Specifically, we construct a large
language model (LLM)-based pipeline that accepts natural language as input and
produces human-like action sequences as output, specified at a level of
granularity that a human would produce. We then compare these generated action
sequences to another dataset of hand-specified action sequences. Although our
results reveal that larger models tend to outperform smaller ones in the
production of human-like action sequences, smaller models nonetheless achieve
satisfactory performance.

</details>


### [306] [Ludax: A GPU-Accelerated Domain Specific Language for Board Games](https://arxiv.org/abs/2506.22609)
*Graham Todd,Alexander G. Padula,Dennis J. N. J. Soemers,Julian Togelius*

Main category: cs.AI

TL;DR: Ludax 是一个用于棋盘游戏的领域特定语言，可以自动编译为硬件加速代码，加速强化学习等研究。


<details>
  <summary>Details</summary>
Motivation: 解决人工智能研究中，游戏描述语言和硬件加速之间的断裂，提供通用性和效率兼备的工具。

Method: 开发 Ludax 框架，将棋盘游戏描述语言与现代并行处理硬件相结合，提供快速模拟及灵活表示。

Result: Ludax 提供了详细的语言设计、代码编译过程，并通过速度基准测试和强化学习代理训练演示了其性能。

Conclusion: Ludax 是一个加速游戏研究的开放源码工具，可用于强化学习和认知科学研究。

Abstract: Games have long been used as benchmarks and testing environments for research
in artificial intelligence. A key step in supporting this research was the
development of game description languages: frameworks that compile
domain-specific code into playable and simulatable game environments, allowing
researchers to generalize their algorithms and approaches across multiple games
without having to manually implement each one. More recently, progress in
reinforcement learning (RL) has been largely driven by advances in hardware
acceleration. Libraries like JAX allow practitioners to take full advantage of
cutting-edge computing hardware, often speeding up training and testing by
orders of magnitude. Here, we present a synthesis of these strands of research:
a domain-specific language for board games which automatically compiles into
hardware-accelerated code. Our framework, Ludax, combines the generality of
game description languages with the speed of modern parallel processing
hardware and is designed to fit neatly into existing deep learning pipelines.
We envision Ludax as a tool to help accelerate games research generally, from
RL to cognitive science, by enabling rapid simulation and providing a flexible
representation scheme. We present a detailed breakdown of Ludax's description
language and technical notes on the compilation process, along with speed
benchmarking and a demonstration of training RL agents. The Ludax framework,
along with implementations of existing board games, is open-source and freely
available.

</details>


### [307] [URSA: The Universal Research and Scientific Agent](https://arxiv.org/abs/2506.22653)
*Michael Grosskopf,Russell Bent,Rahul Somasundaram,Isaac Michaud,Arthur Lui,Nathan Debardeleben,Earl Lawrence*

Main category: cs.AI

TL;DR: 本论文介绍了一个名为URSA的科学代理系统，通过融合模块化代理和工具来加速科学研究任务。


<details>
  <summary>Details</summary>
Motivation: 推动现代科学的效率并解决研究中的瓶颈难题。

Method: 提出URSA平台，结合模块化的代理和高级物理仿真代码组成的工具包，解决复杂科学问题。

Result: URSA展现了其架构及在多个科研任务中的潜力。

Conclusion: URSA作为一个科学代理生态系统，有望显著加快科学研究的效率，并引领科学研究方式的变革。

Abstract: Large language models (LLMs) have moved far beyond their initial form as
simple chatbots, now carrying out complex reasoning, planning, writing, coding,
and research tasks. These skills overlap significantly with those that human
scientists use day-to-day to solve complex problems that drive the cutting edge
of research. Using LLMs in "agentic" AI has the potential to revolutionize
modern science and remove bottlenecks to progress. In this work, we present
URSA, a scientific agent ecosystem for accelerating research tasks. URSA
consists of a set of modular agents and tools, including coupling to advanced
physics simulation codes, that can be combined to address scientific problems
of varied complexity and impact. This work highlights the architecture of URSA,
as well as examples that highlight the potential of the system.

</details>


### [308] [Explanations are a means to an end](https://arxiv.org/abs/2506.22740)
*Jessica Hullman,Ziyang Guo,Berk Ustun*

Main category: cs.AI

TL;DR: 该论文提出，机器学习模型的解释性应与实际用途紧密关联，通过基于统计决策理论的框架，探讨如何为特定应用设计和评估解释方案。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏对解释实际使用方式的深度考虑，需要制定和评估针对具体目的的模型解释。

Method: 通过统计决策理论建立框架，并结合理论与实验，确保解释方法能为特定的实际用途服务。

Result: 展示了这种方法在不同场景（如临床决策支持、提供补救或调试中的应用），并评估了其对理想化决策者性能最大提升的潜力。

Conclusion: 研究者需明确解决具体用例，并将理论与实践相结合，使模型解释更具实际价值。

Abstract: Modern methods for explainable machine learning are designed to describe how
models map inputs to outputs--without deep consideration of how these
explanations will be used in practice. This paper argues that explanations
should be designed and evaluated with a specific end in mind. We describe how
to formalize this end in a framework based in statistical decision theory. We
show how this functionally-grounded approach can be applied across diverse use
cases, such as clinical decision support, providing recourse, or debugging. We
demonstrate its use to characterize the maximum "boost" in performance on a
particular task that an explanation could provide an idealized decision-maker,
preventing misuse due to ambiguity by forcing researchers to specify concrete
use cases that can be analyzed in light of models of expected explanation use.
We argue that evaluation should meld theoretical and empirical perspectives on
the value of explanation, and contribute definitions that span these
perspectives.

</details>


### [309] [Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems](https://arxiv.org/abs/2506.22774)
*Michael Papademas,Xenia Ziouvelou,Antonis Troumpoukis,Vangelis Karkaletsis*

Main category: cs.AI

TL;DR: 本文提出了一种结合伦理组件与算法方法的可信AI评估方法，以减少当前领域内主观自我评估的局限性，并实现AI系统可信度的定量化全面评估。


<details>
  <summary>Details</summary>
Motivation: 探索如何有效评估和量化AI系统可信性，解决当前指导方针主观性强或技术工具视角局限的问题。

Method: 提出了一种结合伦理性与算法性的方法，将PageRank和TrustRank算法与可信AI的伦理指南相结合，建立统一评估框架。

Result: 这种方法在减少主观成分的同时，提供了可量化的可信AI评估指标，并能够涵盖现有理论框架的伦理内容。

Conclusion: 文章的评估框架为可信AI的检验提供了全面与客观的工具，弥补了现有自评方法的不足，有助于推广可信AI技术。

Abstract: Artificial Intelligence (AI) technology epitomizes the complex challenges
posed by human-made artifacts, particularly those widely integrated into
society and exert significant influence, highlighting potential benefits and
their negative consequences. While other technologies may also pose substantial
risks, AI's pervasive reach makes its societal effects especially profound. The
complexity of AI systems, coupled with their remarkable capabilities, can lead
to a reliance on technologies that operate beyond direct human oversight or
understanding. To mitigate the risks that arise, several theoretical tools and
guidelines have been developed, alongside efforts to create technological tools
aimed at safeguarding Trustworthy AI. The guidelines take a more holistic view
of the issue but fail to provide techniques for quantifying trustworthiness.
Conversely, while technological tools are better at achieving such
quantification, they lack a holistic perspective, focusing instead on specific
aspects of Trustworthy AI. This paper aims to introduce an assessment method
that combines the ethical components of Trustworthy AI with the algorithmic
processes of PageRank and TrustRank. The goal is to establish an assessment
framework that minimizes the subjectivity inherent in the self-assessment
techniques prevalent in the field by introducing algorithmic criteria. The
application of our approach indicates that a holistic assessment of an AI
system's trustworthiness can be achieved by providing quantitative insights
while considering the theoretical content of relevant guidelines.

</details>


### [310] [ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models](https://arxiv.org/abs/2506.22865)
*Ziqi Zhong,Xunzhu Tang*

Main category: cs.AI

TL;DR: 本文提出ReasonBridge方法，通过一种新颖的分层知识蒸馏框架高效转移封闭源模型的推理能力到开源模型上，利用精心设计的数据集和方法缩小了开源与封闭源模型之间的性能差距。


<details>
  <summary>Details</summary>
Motivation: 解决当前开源和封闭源语言模型间在复杂推理和精确指令执行任务上的性能差距问题。

Method: 引入ReasonBridge方法，包含一个分层知识蒸馏过程、稀疏推理适配架构以及测试时计算扩展机制；创建包含1000条高质量推理轨迹的Reason1K数据集以支持模型迁移。

Result: ReasonBridge使开源模型在基准测试上提高了高达23%的推理能力，显著缩小了与封闭源模型的差距；增强后的Qwen2.5-14B模型在MATH500上超越了Claude-Sonnet3.5，并在AIME竞赛问题上匹敌其表现。

Conclusion: ReasonBridge方法不仅能提升开源模型的推理能力，还能高效适配不同领域和架构，提供了一种样本高效的推理增强解决方案。

Abstract: Recent advancements in Large Language Models (LLMs) have revealed a
significant performance gap between closed-source and open-source models,
particularly in tasks requiring complex reasoning and precise instruction
following. This paper introduces ReasonBridge, a methodology that efficiently
transfers reasoning capabilities from powerful closed-source to open-source
models through a novel hierarchical knowledge distillation framework. We
develop a tailored dataset Reason1K with only 1,000 carefully curated reasoning
traces emphasizing difficulty, diversity, and quality. These traces are
filtered from across multiple domains using a structured multi-criteria
selection algorithm. Our transfer learning approach incorporates: (1) a
hierarchical distillation process capturing both strategic abstraction and
tactical implementation patterns, (2) a sparse reasoning-focused adapter
architecture requiring only 0.3% additional trainable parameters, and (3) a
test-time compute scaling mechanism using guided inference interventions.
Comprehensive evaluations demonstrate that ReasonBridge improves reasoning
capabilities in open-source models by up to 23% on benchmark tasks,
significantly narrowing the gap with closed-source models. Notably, the
enhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its
performance on competition-level AIME problems. Our methodology generalizes
effectively across diverse reasoning domains and model architectures,
establishing a sample-efficient approach to reasoning enhancement for
instruction following.

</details>


### [311] [Agentic Enterprise: AI-Centric User to User-Centric AI](https://arxiv.org/abs/2506.22893)
*Arpit Narechania,Alex Endert,Atanu R Sinha*

Main category: cs.AI

TL;DR: 这篇论文探讨了人工智能（AI）在企业决策中的潜力，并提出了六条成功要点。


<details>
  <summary>Details</summary>
Motivation: 人工智能春天的到来使AI在多个领域展现了潜力，特别是在具有重复性决策的企业中。

Method: 分析了目前以用户为中心的AI设计模式的不足，并提出转向以企业用户为中心的AI设计六条原则。

Result: 论文提供了六条支持企业决策生产力提升的AI代理设计理念，并展示了市场机制对这些平台的支持。

Conclusion: 通过强调用户需求，论文建议企业采用用户中心的AI设计，并推动市场平台对这一目标的实现。

Abstract: After a very long winter, the Artificial Intelligence (AI) spring is here.
Or, so it seems over the last three years. AI has the potential to impact many
areas of human life - personal, social, health, education, professional. In
this paper, we take a closer look at the potential of AI for Enterprises, where
decision-making plays a crucial and repeated role across functions, tasks, and
operations. We consider Agents imbued with AI as means to increase
decision-productivity of enterprises. We highlight six tenets for Agentic
success in enterprises, by drawing attention to what the current, AI-Centric
User paradigm misses, in the face of persistent needs of and usefulness for
Enterprise Decision-Making. In underscoring a shift to User-Centric AI, we
offer six tenets and promote market mechanisms for platforms, aligning the
design of AI and its delivery by Agents to the cause of enterprise users.

</details>


### [312] [Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning](https://arxiv.org/abs/2506.22919)
*Sanskar Pandey,Ruhaan Chopra,Saad Murtaza Bhat,Ark Abhyudaya*

Main category: cs.AI

TL;DR: 本文提出了一种轻量级的Mixture-of-Experts (MoE)模型Hecto，它结合了GRU专家和FFNN专家进行条件计算，展示了高效的专家专业化能力。


<details>
  <summary>Details</summary>
Motivation: 传统MoE模型在计算过程中依赖于相同的归纳偏置，限制了表示的多样性和对不同推理任务的适应能力。本研究旨在解决此问题，通过架构多样性提高模型的专业化能力和可解释性。

Method: Hecto结合了两种专业化专家：GRU用于处理时间推理，FFNN用于静态抽象分析，并采用稀疏Top-1门控机制分配输入。

Result: Hecto在多种推理基准测试如AG News、SST-2、HotpotQA，以及一个回归任务STS-B上，性能与同构基线接近，展现了清晰的专家专业化能力。

Conclusion: Hecto通过结合多样化专家实现了条件计算中高效的专门化推理，并在低资源场景下提供了一个新的研究基准，同时提高了模型稳定性和可解释性。

Abstract: Mixture-of-Experts (MoE) models enable conditional computation by routing
inputs to specialized experts, but these experts rely on identical inductive
biases, thus limiting representational diversity. This static computation
pathway is inefficient for inputs that require different types of reasoning and
limits specialization and interpretability. We propose Hecto, a lightweight MoE
architecture that leverages architectural heterogeneity by combining a GRU
expert for temporal reasoning and an FFNN expert for static abstraction under a
sparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AG
News, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closely
trails homogeneous baselines in performance despite receiving isolated input
representations, while achieving clear expert specialization, with each expert
aligning to distinct reasoning types (temporal vs static). At larger batch
sizes, Hecto exhibits improved performance, benefiting from relaxed
computational constraints that allow its heterogeneous architecture to optimize
more effectively. Ablation results isolate architectural diversity as the
source of Hecto's stability and interpretability across diverse reasoning
tasks. Overall, Hecto establishes itself as a new benchmark for conditional
computation, offering a principled framework for specialized reasoning in
low-resource regimes with its model strength derived from principled
specialization.

</details>


### [313] [Improving Rationality in the Reasoning Process of Language Models through Self-playing Game](https://arxiv.org/abs/2506.22920)
*Pinzheng Wang,Juntao Li,Zecheng Tang,Haijia Gui,Min zhang*

Main category: cs.AI

TL;DR: 该论文提出通过自我博弈方式提升语言模型的推理能力，而无需人类监督。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在推理任务中表现出色，但缺乏真实理解其推理过程的能力。

Method: 设计了一个鉴别游戏（Critic-Discernment Game, CDG），通过模型与自身间交流（自我博弈），通过提供问题解答并应对评论，为提升模型推理过程提供有效方法。

Result: 实验显示，CDG训练显著增强了语言模型在数学推理、错误检测、自我更正和长链推理等任务中的推理理解能力。

Conclusion: 通过CDG训练，模型无需依赖外部监督仍可以提高其推理过程中对解决方案的认知与理解。

Abstract: Large language models (LLMs) have demonstrated considerable reasoning
abilities in various tasks such as mathematics and coding. However, recent
studies indicate that even the best models lack true comprehension of their
reasoning processes. In this paper, we explore how self-play can enhance the
rationality of models in the reasoning process without supervision from humans
or superior models. We design a Critic-Discernment Game(CDG) in which a prover
first provides a solution to a given problem and is subsequently challenged by
critiques of its solution. These critiques either aim to assist or mislead the
prover. The objective of the prover is to maintain the correct answer when
faced with misleading comments, while correcting errors in response to
constructive feedback. Our experiments on tasks involving mathematical
reasoning, stepwise error detection, self-correction, and long-chain reasoning
demonstrate that CDG training can significantly improve the ability of
well-aligned LLMs to comprehend their reasoning process.

</details>


### [314] [MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning](https://arxiv.org/abs/2506.22992)
*Yulun Jiang,Yekun Chai,Maria Brbić,Michael Moor*

Main category: cs.AI

TL;DR: 这篇论文提出了一个名为MARBLE的新基准，用以评估多模态语言模型(MLLMs)在多模态复杂推理中的表现，结果显示当前模型的性能远低于预期。


<details>
  <summary>Details</summary>
Motivation: 推进人工智能在多模态信息处理和逐步复杂推理中的能力，同时弥补现有基准测试主要集中于文本推理而非多模态推理的空白。

Method: 构建了MARBLE，一个包含两个挑战性任务（M-Portal和M-Cube）的多模态基准，用于严格测试多模态语言模型在受限条件下的多步推理和规划能力。

Result: 当前12个先进的多模态语言模型在MARBLE上的表现接近随机水平，仅在一些简化子任务中表现略好，部分模型完全无法提取视觉输入信息。

Conclusion: 现有MLLMs在多模态复杂推理上的能力有限，MARBLE的提出旨在为未来更强大的跨模态推理与规划模型的发展提供动力。

Abstract: The ability to process information from multiple modalities and to reason
through it step-by-step remains a critical challenge in advancing artificial
intelligence. However, existing reasoning benchmarks focus on text-only
reasoning, or employ multimodal questions that can be answered by directly
retrieving information from a non-text modality. Thus, complex reasoning
remains poorly understood in multimodal domains. Here, we present MARBLE, a
challenging multimodal reasoning benchmark that is designed to scrutinize
multimodal language models (MLLMs) in their ability to carefully reason
step-by-step through complex multimodal problems and environments. MARBLE is
composed of two highly challenging tasks, M-Portal and M-Cube, that require the
crafting and understanding of multistep plans under spatial, visual, and
physical constraints. We find that current MLLMs perform poorly on MARBLE --
all the 12 advanced models obtain near-random performance on M-Portal and 0%
accuracy on M-Cube. Only in simplified subtasks some models outperform the
random baseline, indicating that complex reasoning is still a challenge for
existing MLLMs. Moreover, we show that perception remains a bottleneck, where
MLLMs occasionally fail to extract information from the visual inputs. By
shedding a light on the limitations of MLLMs, we hope that MARBLE will spur the
development of the next generation of models with the ability to reason and
plan across many, multimodal reasoning steps.

</details>


### [315] [AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks](https://arxiv.org/abs/2506.23049)
*Leander Melroy Maben,Gayathri Ganesh Lakshmy,Srijith Radhakrishnan,Siddhant Arora,Shinji Watanabe*

Main category: cs.AI

TL;DR: AURA是首个开源的语音助手系统，可以通过工具调用和多轮对话完成复杂任务。


<details>
  <summary>Details</summary>
Motivation: 现有技术缺乏一个集语音对语音、多轮对话和工具使用的开源系统。

Method: AURA结合开源ASR、TTS和LLM，以模块化设计支持新工具集成，通过自然语言提示完成任务。

Result: 在VoiceBench上，AURA得分92.75%，接近GPT-4o；在AlpacaEval上得分4.39，表现与其他开源系统相当；人类评估中在复杂语音任务上的成功率达90%。

Conclusion: AURA实现了首个开源、语音原生并支持多轮对话和工具调用的助手系统，在复杂任务上表现卓越。

Abstract: Despite advances in language and speech technologies, no open-source system
enables full speech-to-speech, multi-turn dialogue with integrated tool use and
agentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and
Automated Tool Use), the first open-source, speech-native assistant capable of
completing complex, goal-driven tasks through dynamic tool invocation and
multi-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a
cascaded pipeline and supports tools such as calendar booking, contact lookup,
web search, and email. Its modular design allows easy integration of new tools
using natural language prompts and action classes. On VoiceBench, AURA scores
92.75% on OpenBookQA-outperforming all open-weight systems and nearing
GPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems.
Human evaluation shows 90% task success on complex, multi-turn speech tasks.

</details>


### [316] [AI's Euclid's Elements Moment: From Language Models to Computable Thought](https://arxiv.org/abs/2506.23080)
*Xinmin Fang,Lingfeng Tao,Zhengxiong Li*

Main category: cs.AI

TL;DR: 本文提出了一个五阶段进化框架，分析人工智能的发展历程，认为其类似于人类认知技术的历史进程，通过分析过去到目前的转变，并提供未来发展的理论方向与具体策略。


<details>
  <summary>Details</summary>
Motivation: 探索人工智能发展的历史与未来，揭示这一进程与人类认知技术演变的类似之处，同时为开发下一代人工智能系统提供理论与方法支持。

Method: 构建一个类比人类认知技术发展的五阶段框架，包括几何认知模型，结合AI当前的关键转变，如从专家系统到Transformer，再到自反性和神经-符号体系等未来可能形式。

Result: 框架揭示了人工智能发展的非线性及其自反性，定义了当前“元语言时刻”和未来可能的“数学符号时刻”及“形式逻辑系统时刻”。

Conclusion: 本文为人工智能的过去、现在与未来提供了系统性理论基础，并提出了具体战略方向，为研发人员与初创企业的实践提供指导。

Abstract: This paper presents a comprehensive five-stage evolutionary framework for
understanding the development of artificial intelligence, arguing that its
trajectory mirrors the historical progression of human cognitive technologies.
We posit that AI is advancing through distinct epochs, each defined by a
revolutionary shift in its capacity for representation and reasoning, analogous
to the inventions of cuneiform, the alphabet, grammar and logic, mathematical
calculus, and formal logical systems. This "Geometry of Cognition" framework
moves beyond mere metaphor to provide a systematic, cross-disciplinary model
that not only explains AI's past architectural shifts-from expert systems to
Transformers-but also charts a concrete and prescriptive path forward.
Crucially, we demonstrate that this evolution is not merely linear but
reflexive: as AI advances through these stages, the tools and insights it
develops create a feedback loop that fundamentally reshapes its own underlying
architecture. We are currently transitioning into a "Metalinguistic Moment,"
characterized by the emergence of self-reflective capabilities like
Chain-of-Thought prompting and Constitutional AI. The subsequent stages, the
"Mathematical Symbolism Moment" and the "Formal Logic System Moment," will be
defined by the development of a computable calculus of thought, likely through
neuro-symbolic architectures and program synthesis, culminating in provably
aligned and reliable AI that reconstructs its own foundational representations.
This work serves as the methodological capstone to our trilogy, which
previously explored the economic drivers ("why") and cognitive nature ("what")
of AI. Here, we address the "how," providing a theoretical foundation for
future research and offering concrete, actionable strategies for startups and
developers aiming to build the next generation of intelligent systems.

</details>


### [317] [Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study](https://arxiv.org/abs/2506.23107)
*Bing Song,Jianing Liu,Sisi Jian,Chenyang Wu,Vinayak Dixit*

Main category: cs.AI

TL;DR: 本文探讨大型语言模型（LLMs）在模拟复杂决策行为（如风险决策）方面的能力，发现模型表现出更高的风险厌恶，并存在语言与文化的影响。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在对话系统、内容生成和领域特定任务中的应用增加，人们对其在复杂决策模拟中的可靠性提出了疑虑，尤其是风险决策中可能带来多种结果选择的情景。

Method: 通过一系列基于彩票的任务，使用来自不同城市（悉尼、达卡、香港和南京）的交通意愿调查数据，比较两种LLMs产生的决策和人类实际反应，并利用CRRA框架分析风险偏好。

Result: 结果显示，无论是ChatGPT 4o还是o1-mini都比人类参与者表现出更强的风险厌恶，其中o1-mini与人类决策更相近。此外，发现提示语言（中文或英文）对模拟性能有影响。

Conclusion: LLMs在复制人类风险行为方面具有潜力，但在语言和文化情景中仍存在局限性。

Abstract: Large language models (LLMs) have made significant strides, extending their
applications to dialogue systems, automated content creation, and
domain-specific advisory tasks. However, as their use grows, concerns have
emerged regarding their reliability in simulating complex decision-making
behavior, such as risky decision-making, where a single choice can lead to
multiple outcomes. This study investigates the ability of LLMs to simulate
risky decision-making scenarios. We compare model-generated decisions with
actual human responses in a series of lottery-based tasks, using transportation
stated preference survey data from participants in Sydney, Dhaka, Hong Kong,
and Nanjing. Demographic inputs were provided to two LLMs -- ChatGPT 4o and
ChatGPT o1-mini -- which were tasked with predicting individual choices. Risk
preferences were analyzed using the Constant Relative Risk Aversion (CRRA)
framework. Results show that both models exhibit more risk-averse behavior than
human participants, with o1-mini aligning more closely with observed human
decisions. Further analysis of multilingual data from Nanjing and Hong Kong
indicates that model predictions in Chinese deviate more from actual responses
compared to English, suggesting that prompt language may influence simulation
performance. These findings highlight both the promise and the current
limitations of LLMs in replicating human-like risk behavior, particularly in
linguistic and cultural settings.

</details>


### [318] [The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy](https://arxiv.org/abs/2506.23123)
*Rishi Bommasani*

Main category: cs.AI

TL;DR: 该论文围绕AI和社会的共同演化，探索了基础模型的能力、风险及其对经济的作用；通过模型评估和组织索引获取透明性；并探讨如何从知识走向行动，以促进证据驱动的AI政策。


<details>
  <summary>Details</summary>
Motivation: 探讨AI技术与社会的共同进化，尤其是基础模型如何影响能力、风险及经济链条。

Method: 通过概念分析能力、风险和供应链问题，利用评估和索引等实证方法提升透明度，研究政策建议与行动。

Result: 提出了一整套理解基础模型对社会影响的理论框架和实践工具，为证据驱动AI政策提供新见解。

Conclusion: 论文从理论到实践，提供了一种改进AI治理，实现更好社会结果的方法。

Abstract: Artificial intelligence is humanity's most promising technology because of
the remarkable capabilities offered by foundation models. Yet, the same
technology brings confusion and consternation: foundation models are poorly
understood and they may precipitate a wide array of harms. This dissertation
explains how technology and society coevolve in the age of AI, organized around
three themes. First, the conceptual framing: the capabilities, risks, and the
supply chain that grounds foundation models in the broader economy. Second, the
empirical insights that enrich the conceptual foundations: transparency created
via evaluations at the model level and indexes at the organization level.
Finally, the transition from understanding to action: superior understanding of
the societal impact of foundation models advances evidence-based AI policy.
View together, this dissertation makes inroads into achieving better societal
outcomes in the age of AI by building the scientific foundations and
research-policy interface required for better AI governance.

</details>


### [319] [Are Large Language Models Capable of Deep Relational Reasoning? Insights from DeepSeek-R1 and Benchmark Comparisons](https://arxiv.org/abs/2506.23128)
*Chi Chiu So,Yueyue Sun,Jun-Min Wang,Siu Pang Yung,Anthony Wai Keung Loh,Chun Pong Chau*

Main category: cs.AI

TL;DR: 本论文通过家谱和一般图推理任务的基准测试，评估了三种前沿大型语言模型（LLMs）的深层关系推理能力，发现DeepSeek-R1在逻辑推理方面表现优异，但随着问题复杂度增加表现有所下降。


<details>
  <summary>Details</summary>
Motivation: 旨在探讨和对比当前LLMs在深层关系推理任务中的能力表现，并分析其局限性，以推动其推理能力的进一步发展。

Method: 设计了一套基准测试任务，评估DeepSeek-R1、DeepSeek-V3和GPT-4o在家谱和一般图推理上的表现，辅以对长链式思维响应的深度分析。

Result: DeepSeek-R1在多个任务和问题规模上表现最佳，但所有模型在复杂任务中均表现出较大的限制，包括Token长度和结果不完整性等问题。

Conclusion: 研究表明，当前LLMs在结构化、多步逻辑推理任务中仍面临挑战，未来需强化多模态推理及系统性分析其推理失败的原因。

Abstract: How far are Large Language Models (LLMs) in performing deep relational
reasoning? In this paper, we evaluate and compare the reasoning capabilities of
three cutting-edge LLMs, namely, DeepSeek-R1, DeepSeek-V3 and GPT-4o, through a
suite of carefully designed benchmark tasks in family tree and general graph
reasoning. Our experiments reveal that DeepSeek-R1 consistently achieves the
highest F1-scores across multiple tasks and problem sizes, demonstrating strong
aptitude in logical deduction and relational inference. However, all evaluated
models, including DeepSeek-R1, struggle significantly as problem complexity
increases, largely due to token length limitations and incomplete output
structures. A detailed analysis of DeepSeek-R1's long Chain-of-Thought
responses uncovers its unique planning and verification strategies, but also
highlights instances of incoherent or incomplete reasoning, calling attention
to the need for deeper scrutiny into LLMs' internal inference dynamics. We
further discuss key directions for future work, including the role of
multimodal reasoning and the systematic examination of reasoning failures. Our
findings provide both empirical insights and theoretical implications for
advancing LLMs' reasoning abilities, particularly in tasks that demand
structured, multi-step logical inference. Our code repository will be publicly
available at https://github.com/kelvinhkcs/Deep-Relational-Reasoning.

</details>


### [320] [Context-Driven Knowledge Graph Completion with Semantic-Aware Relational Message Passing](https://arxiv.org/abs/2506.23141)
*Siyuan Li,Ruitong Liu,Yan Wen,Te Sun*

Main category: cs.AI

TL;DR: 文章提出一种语义感知的关系信息传递方法，通过选择语义相关的Top-K邻居和多头注意力聚合器优化节点信息传递，在知识图谱补全任务中取得了优异的表现。


<details>
  <summary>Details</summary>
Motivation: 传统的基于节点的信息传递机制在应用于知识图谱时，可能因无差别地聚合所有邻边的信息而引入噪声，导致信息稀释或过度平滑问题。

Method: 提出一种语义感知关系信息传递框架，核心是语义感知的Top-K邻居选择策略和多头注意力聚合器，用于选择最相关邻边并将其信息与中心节点表示有效结合。

Result: 实验结果显示，该方法在多个已建立的基准测试中表现优于现有方法。

Conclusion: 通过优化信息传递策略，该方法能够更准确地捕获和传播与特定链接预测任务相关的上下文信息，有效减轻了无关信息的干扰。

Abstract: Semantic context surrounding a triplet $(h, r, t)$ is crucial for Knowledge
Graph Completion (KGC), providing vital cues for prediction. However,
traditional node-based message passing mechanisms, when applied to knowledge
graphs, often introduce noise and suffer from information dilution or
over-smoothing by indiscriminately aggregating information from all neighboring
edges. To address this challenge, we propose a semantic-aware relational
message passing. A core innovation of this framework is the introduction of a
\textbf{semantic-aware Top-K neighbor selection strategy}. Specifically, this
strategy first evaluates the semantic relevance between a central node and its
incident edges within a shared latent space, selecting only the Top-K most
pertinent ones. Subsequently, information from these selected edges is
effectively fused with the central node's own representation using a
\textbf{multi-head attention aggregator} to generate a semantically focused
node message. In this manner, our model not only leverages the structure and
features of edges within the knowledge graph but also more accurately captures
and propagates the contextual information most relevant to the specific link
prediction task, thereby effectively mitigating interference from irrelevant
information. Extensive experiments demonstrate that our method achieves
superior performance compared to existing approaches on several established
benchmarks.

</details>


### [321] [Rises for Measuring Local Distributivity in Lattices](https://arxiv.org/abs/2506.23168)
*Mohammad Abdulla,Tobias Hille,Dominik Dürrschnabel,Gerd Stumme*

Main category: cs.AI

TL;DR: 本文提出通过“rises”来量化格在分配性方面的性质，并分析了实际数据中的概念格中分配性的表现形式。


<details>
  <summary>Details</summary>
Motivation: 尽管格的分配性在形式概念分析(FCA)中有高度体现，但当前没有标准化的量化方法，因此有必要提出量化工具。

Method: 引入“rises”的概念，用以分析覆盖概念中属性或对象的数量如何在概念格内变化，从而与经典的分配性定义相联系。

Result: 证明了格在没有非单一变动情况下是分配性的；发现实际数据概念格表现出较高的join分配性，但较低的meet分配性。

Conclusion: 提出的“rises”方法有效为格的分配性量化提供了一种新的视角，实际概念格的表现不完全对称。

Abstract: Distributivity is a well-established and extensively studied notion in
lattice theory. In the context of data analysis, particularly within Formal
Concept Analysis (FCA), lattices are often observed to exhibit a high degree of
distributivity. However, no standardized measure exists to quantify this
property. In this paper, we introduce the notion of rises in (concept) lattices
as a means to assess distributivity. Rises capture how the number of attributes
or objects in covering concepts change within the concept lattice. We show that
a lattice is distributive if and only if no non-unit rises occur. Furthermore,
we relate rises to the classical notion of meet- and join distributivity. We
observe that concept lattices from real-world data are to a high degree
join-distributive, but much less meet-distributive. We additionally study how
join-distributivity manifests on the level of ordered sets.

</details>


### [322] [FinStat2SQL: A Text2SQL Pipeline for Financial Statement Analysis](https://arxiv.org/abs/2506.23273)
*Quang Hung Nguyen,Phuong Anh Trinh,Phan Quoc Hung Mai,Tuan Phong Trinh*

Main category: cs.AI

TL;DR: 提出FinStat2SQL，一种轻量级text2sql解决方案，在金融领域实现自然语言到SQL查询的转换，具备高效性与成本效益。


<details>
  <summary>Details</summary>
Motivation: text2sql在处理复杂和特定领域的查询（尤其是金融领域）时面临挑战，需开发一种针对性强的解决方案。

Method: 通过结合大规模和小规模语言模型，以多代理框架实现实体验抽取、SQL生成和自校正，并适配本地金融标准。

Result: 开发了一个领域特定的数据库，并在合成问答数据集上评估模型。一个微调的7B模型在消费者硬件上达到了61.33%准确率，响应时间少于4秒，优于GPT-4o-mini。

Conclusion: FinStat2SQL为金融分析提供了可扩展且具成本效益的解决方案，使基于AI的查询能力可供越南企业使用。

Abstract: Despite the advancements of large language models, text2sql still faces many
challenges, particularly with complex and domain-specific queries. In finance,
database designs and financial reporting layouts vary widely between financial
entities and countries, making text2sql even more challenging. We present
FinStat2SQL, a lightweight text2sql pipeline enabling natural language queries
over financial statements. Tailored to local standards like VAS, it combines
large and small language models in a multi-agent setup for entity extraction,
SQL generation, and self-correction. We build a domain-specific database and
evaluate models on a synthetic QA dataset. A fine-tuned 7B model achieves
61.33\% accuracy with sub-4-second response times on consumer hardware,
outperforming GPT-4o-mini. FinStat2SQL offers a scalable, cost-efficient
solution for financial analysis, making AI-powered querying accessible to
Vietnamese enterprises.

</details>


### [323] [Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games](https://arxiv.org/abs/2506.23276)
*David Guzman Piedrahita,Yongjin Yang,Mrinmaya Sachan,Giorgia Ramponi,Bernhard Schölkopf,Zhijing Jin*

Main category: cs.AI

TL;DR: 该研究探索大型语言模型(LLMs)在多主体系统中的合作及社会机制，发现部分模型表现出低合作能力，即使具备推理能力的模型也难以维持高水平的合作。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs作为自主代理被广泛部署，理解模型在合作和社会行为中的表现成为确保其一致性、鲁棒性和安全性的关键问题。

Method: 通过改编行为经济学的公共物品博弈，将其应用于多次交互的多代理LLM系统，观察和分析不同LLM如何在社会困境中平衡合作与个人利益。

Result: 研究发现，大型语言模型在合作上的表现可分为四种模式：部分模型能维持高水平合作，有些在合作之间摇摆不定，一些逐渐减少合作，还有些无视结果盲从固定策略。此外，具备推理能力的LLMs在合作中表现较弱，而传统LLMs的合作表现则较强。

Conclusion: 目前专注于增强LLMs推理能力的方法并不一定能促进合作，研究为如何部署需持续协作的LLM代理提供了重要洞见。

Abstract: As large language models (LLMs) are increasingly deployed as autonomous
agents, understanding their cooperation and social mechanisms is becoming
increasingly important. In particular, how LLMs balance self-interest and
collective well-being is a critical challenge for ensuring alignment,
robustness, and safe deployment. In this paper, we examine the challenge of
costly sanctioning in multi-agent LLM systems, where an agent must decide
whether to invest its own resources to incentivize cooperation or penalize
defection. To study this, we adapt a public goods game with institutional
choice from behavioral economics, allowing us to observe how different LLMs
navigate social dilemmas over repeated interactions. Our analysis reveals four
distinct behavioral patterns among models: some consistently establish and
sustain high levels of cooperation, others fluctuate between engagement and
disengagement, some gradually decline in cooperative behavior over time, and
others rigidly follow fixed strategies regardless of outcomes. Surprisingly, we
find that reasoning LLMs, such as the o1 series, struggle significantly with
cooperation, whereas some traditional LLMs consistently achieve high levels of
cooperation. These findings suggest that the current approach to improving
LLMs, which focuses on enhancing their reasoning capabilities, does not
necessarily lead to cooperation, providing valuable insights for deploying LLM
agents in environments that require sustained collaboration. Our code is
available at https://github.com/davidguzmanp/SanctSim

</details>


### [324] [GATSim: Urban Mobility Simulation with Generative Agents](https://arxiv.org/abs/2506.23306)
*Qi Liu,Can Li,Wanjing Ma*

Main category: cs.AI

TL;DR: 论文提出GATSim框架，将生成式代理整合到城市交通模拟中，实现更贴近现实的人类行为建模。


<details>
  <summary>Details</summary>
Motivation: 传统的基于规则的城市交通模拟无法充分捕捉人类决策的复杂性和灵活性。新兴的生成式代理技术为解决此问题提供了可能性。

Method: 开发了一个整合城市交通基础模型、代理认知系统与交通仿真环境的架构，并实现了一个功能完备的原型系统。

Result: 实验表明，生成式代理不仅能够再现真实的交通行为，还能在宏观交通演化模式中展现竞争力。

Conclusion: GATSim框架能够通过生成式代理实现持久记忆和行为适应，为更真实的城市交通模拟提供了可能性，并已开源代码以供进一步研究。

Abstract: Traditional agent-based urban mobility simulations rely on rigid rule-based
systems that fail to capture the complexity, adaptability, and behavioral
diversity characteristic of human travel decision-making. Recent advances in
large language models and AI agent technology offer opportunities to create
agents with reasoning capabilities, persistent memory, and adaptive learning
mechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel
framework that leverages these advances to create generative agents with rich
behavioral characteristics for urban mobility simulation. Unlike conventional
approaches, GATSim agents possess diverse socioeconomic attributes, individual
lifestyles, and evolving preferences that shape their mobility decisions
through psychologically-informed memory systems, tool usage capabilities, and
lifelong learning mechanisms. The main contributions of this study include: (1)
a comprehensive architecture combining an urban mobility foundation model with
agent cognitive systems and transport simulation environment, (2) a fully
functional prototype implementation, and (3) systematic validation
demonstrating that generative agents produce believable travel behaviors.
Through designed reflection processes, generative agents in this study can
transform specific travel experiences into generalized insights, enabling
realistic behavioral adaptation over time with specialized mechanisms for
activity planning and real-time reactive behaviors tailored to urban mobility
contexts. Experiments show that generative agents perform competitively with
human annotators in mobility scenarios while naturally producing macroscopic
traffic evolution patterns. The code for the prototype system is shared at
https://github.com/qiliuchn/gatsim.

</details>


### [325] [The Confidence Paradox: Can LLM Know When It's Wrong](https://arxiv.org/abs/2506.23464)
*Sahil Tripathi,Md Tabrez Nafis,Imran Hussain,Jiechao Gao*

Main category: cs.AI

TL;DR: 本文提出了HonestVQA，一个用于DocVQA（文档视觉问答）的自监督框架，目标是改善模型的诚实性和道德响应能力。通过调整损失函数和对比学习，提升了系统的准确性并减少了过度自信问题。


<details>
  <summary>Details</summary>
Motivation: DocVQA系统在实际应用中由于过于自信的回答或未可靠传达不确定性，可能导致重大伦理风险，尤其是在需高伦理责任的领域。现有方法虽然提升了性能，但在伦理响应能力方面仍存不足。

Method: 引入HonestVQA，这是一种与模型无关的自监督框架。它通过量化不确定性、调整模型信心与实际准确性的匹配、以及基于对比学习的方式，来强化伦理响应行为。此外，还设计了Honesty Score (H-Score) 和 Ethical Confidence Index (ECI) 两个评估指标。

Result: HonestVQA在多种数据集上提升了文档视觉问答的性能，准确性和F1得分均提高了4.3%，并显著降低了过度自信问题。跨领域评估显示了其强大的泛化能力。

Conclusion: HonestVQA通过改进伦理响应能力，提升了DocVQA系统的实际应用价值，解决了模型过度自信等问题。同时，引入的评估指标有助于更好地衡量模型的伦理对齐程度。

Abstract: Document Visual Question Answering (DocVQA) systems are increasingly deployed
in real world applications, yet they remain ethically opaque-often producing
overconfident answers to ambiguous questions or failing to communicate
uncertainty in a trustworthy manner. This misalignment between model confidence
and actual knowledge poses significant risks, particularly in domains requiring
ethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT
have advanced SOTA performance by focusing on architectural sophistication and
accuracy; however, they fall short in ethical responsiveness.
  To address these limitations, we introduce HonestVQA, a self-supervised
honesty calibration framework for ethically aligned DocVQA. Our model-agnostic
method quantifies uncertainty to identify knowledge gaps, aligns model
confidence with actual correctness using weighted loss functions, and enforces
ethical response behavior via contrastive learning. We further introduce two
principled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence
Index (ECI)--to benchmark alignment between confidence, accuracy, and ethical
communication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3%
and F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces
overconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In
cross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score,
demonstrating strong generalization. Ablation shows a 3.8% drop in accuracy
without alignment or contrastive loss.

</details>


### [326] [Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence](https://arxiv.org/abs/2506.23503)
*Bosubabu Sambana,Kondreddygari Archana,Suram Indhra Sena Reddy,Shaik Meethaigar Jameer Basha,Shaik Karishma*

Main category: cs.AI

TL;DR: 本文提出通过社交媒体分析用户的负面情绪和认知扭曲，从而优化认知行为疗法(CBT)的干预措施。


<details>
  <summary>Details</summary>
Motivation: 由于社交媒体上充斥着负面情绪和认知扭曲，但缺乏有效的方法来解析这些认知路径，从而填补心理治疗师在数字环境的干预空白。

Method: 本文利用BERT、RoBERTa进行情感分析，T5、PEGASUS进行文本摘要，mT5进行多语种文本翻译，以识别负面情绪和认知扭曲，并进一步预测潜在心理健康问题。

Result: 系统不但能识别负面思想，还可预测额外心理健康问题如恐惧症、饮食失调等，使理解和干预策略更全面。

Conclusion: 该系统为心理治疗师提供了有效工具，助其早期发现和治疗各类心理问题，提升认知行为疗法的效能。

Abstract: Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the
irrational thought patterns associated with mental health disorders, but its
effectiveness relies on accurately identifying cognitive pathways to provide
targeted treatment. In today's digital age, individuals often express negative
emotions on social media, where they may reveal cognitive distortions, and in
severe cases, exhibit suicidal tendencies. However, there is a significant gap
in methodologies designed to analyze these cognitive pathways, which could be
critical for psychotherapists aiming to deliver timely and effective
interventions in online environments. Cognitive Behavioral Therapy (CBT)
framework leveraging acceptance, commitment and data augmentation to categorize
and address both textual and visual content as positive or negative.
Specifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5,
PEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages
focusing on detecting negative emotions and cognitive distortions within social
media data. While existing models are primarily designed to identify negative
thoughts, the proposed system goes beyond this by predicting additional
negative side effects and other potential mental health disorders likes
Phobias, Eating Disorders. This enhancement allows for a more comprehensive
understanding and intervention strategy, offering psychotherapists a powerful
tool for early detection and treatment of various psychological issues.

</details>


### [327] [Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM](https://arxiv.org/abs/2506.23504)
*Bosubabu Sambana,Kotamsetty Geethika Devi,Bandi Rajeswara Reddy,Galeti Mohammad Hussain,Gownivalla Siddartha*

Main category: cs.AI

TL;DR: 该研究提出了一种结合AlexNet和LSTM算法的混合模型，用于提高电价预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在电价预测中仅关注需求和价格，忽略了外部变量，导致数据分析不足，需要更准确的预测模型。

Method: 采用AlexNet的特征提取能力与LSTM的时序模式学习能力，结合外部变量（如需求、温度、日照和降雨），利用最小-最大缩放与时间窗口方法，构建基于历史数据的混合预测模型。

Result: 提出的混合模型在预测准确性上优于单一模型，达到97.08%的预测准确率，比RNN（96.64%）和ANN（96.63%）更高。

Conclusion: 该混合模型通过结合先进算法和综合性数据分析，可显著提高电价预测准确性，具有优越性。

Abstract: The recent development of advanced machine learning methods for hybrid models
has greatly addressed the need for the correct prediction of electrical prices.
This method combines AlexNet and LSTM algorithms, which are used to introduce a
new model with higher accuracy in price forecasting. Despite RNN and ANN being
effective, they often fail to deal with forex time sequence data. The
traditional methods do not accurately forecast the prices. These traditional
methods only focus on demand and price which leads to insufficient analysis of
data. To address this issue, using the hybrid approach, which focuses on
external variables that also effect the predicted prices. Nevertheless, due to
AlexNet's excellent feature extraction and LSTM's learning sequential patterns,
the prediction accuracy is vastly increased. The model is built on the past
data, which has been supplied with the most significant elements like demand,
temperature, sunlight, and rain. For example, the model applies methods, such
as minimum-maximum scaling and a time window, to predict the electricity prices
of the future. The results show that this hybrid model is good than the
standalone ones in terms of accuracy. Although we got our accuracy rating of
97.08, it shows higher accompaniments than remaining models RNN and ANN with
accuracies of 96.64 and 96.63 respectively.

</details>


### [328] [Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays](https://arxiv.org/abs/2506.23517)
*Selin Dik,Osman Erdem,Mehmet Dik*

Main category: cs.AI

TL;DR: 研究评估了AI检测工具GPTZero在区分人工与AI生成内容的准确性，发现其对AI生成文本判断较高，但有部分误报人类文本为AI生成。


<details>
  <summary>Details</summary>
Motivation: 随着AI工具在学生使用中的普及，研究旨在验证AI探测器如GPTZero的可靠性，尤其是在不同长度文章中的表现。

Method: 收集28篇AI生成和50篇人工撰写的论文，将这些随机化文本逐一输入GPTZero，分析AI生成的可能性比例及探测信心水平。

Result: 发现GPTZero假定AI生成的文本检测较为精准（91%-100%），而对人工文本存在一些误报现象。

Conclusion: 尽管GPTZero在识别AI生成内容方面表现良好，但在准确区分人工作品时存在局限性，教育者需谨慎依赖该工具。

Abstract: As the use of AI tools by students has become more prevalent, instructors
have started using AI detection tools like GPTZero and QuillBot to detect AI
written text. However, the reliability of these detectors remains uncertain. In
our study, we focused mostly on the success rate of GPTZero, the most-used AI
detector, in identifying AI-generated texts based on different lengths of
randomly submitted essays: short (40-100 word count), medium (100-350 word
count), and long (350-800 word count). We gathered a data set consisting of
twenty-eight AI-generated papers and fifty human-written papers. With this
randomized essay data, papers were individually plugged into GPTZero and
measured for percentage of AI generation and confidence. A vast majority of the
AI-generated papers were detected accurately (ranging from 91-100% AI believed
generation), while the human generated essays fluctuated; there were a handful
of false positives. These findings suggest that although GPTZero is effective
at detecting purely AI-generated content, its reliability in distinguishing
human-authored texts is limited. Educators should therefore exercise caution
when relying solely on AI detection tools.

</details>


### [329] [ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data](https://arxiv.org/abs/2506.23520)
*Yu Zhang,Ruijie Yu,Jidong Tian,Feng Zhu,Jiapeng Liu,Xiaokang Yang,Yaohui Jin,Yanyan Xu*

Main category: cs.AI

TL;DR: 该论文介绍了一种名为ChemActor的化学执行器，利用大语言模型（LLM）从非结构化实验程序生成结构化步骤，提出了一种新的数据生成框架，并在相关任务中取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 解决化学语言模糊性以及标注数据成本高的问题，并推动化学实验的自动化提取与执行。

Method: 开发了一种完整微调的大语言模型ChemActor，并提出一个结合数据选择模块与通用LLM的数据生成框架，同时引入了多轮LLMs循环审查指标。

Result: 在反应到描述（R2D）和描述到动作（D2A）任务中，ChemActor在使用LLM生成数据后实现了领先10%的性能提升。

Conclusion: ChemActor通过改进的数据框架和模型设计，在化学实验程序自动化方面取得了显著进展，展现了其在化学领域的潜力。

Abstract: With the increasing interest in robotic synthesis in the context of organic
chemistry, the automated extraction of chemical procedures from literature is
critical. However, this task remains challenging due to the inherent ambiguity
of chemical language and the high cost of human annotation required for
developing reliable computer-aided extraction protocols. Here, we present
ChemActor, a fully fine-tuned large language model (LLM), as a chemical
executor to convert between unstructured experimental procedures and structured
action sequences. We propose a sequential LLM-generated data framework to
address the challenges of insufficient and low-quality annotated data. This
framework integrates a data selection module that selects data based on
distribution divergence, with a general-purpose LLM, to generate
machine-executable actions from a single molecule input. Additionally, we
introduce a novel multi-round LLMs circle review metric, which reflects the
model's advanced understanding of chemical experimental procedures. Extensive
experiments on reaction-to-description (R2D) and description-to-action (D2A)
tasks demonstrate that ChemActor, augmented by LLM-generated data, achieves
state-of-the-art performance, outperforming the baseline model by 10%. The code
is available at: https://github.com/Zhanghahah/ChemActor.

</details>


### [330] [CooT: Learning to Coordinate In-Context with Coordination Transformers](https://arxiv.org/abs/2506.23549)
*Huai-Chih Wang,Hsiang-Chun Chuang,Hsi-Chun Cheng,Dai-Jie Wu,Shao-Hua Sun*

Main category: cs.AI

TL;DR: 本文提出了一种新型的文本生成模型CooT，能够通过最近的交互历史适应未见的合作伙伴，显著改善了动态、多变环境下的人工智能系统中的协作表现。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在面对未见的合作伙伴时适应能力有限，且需要大量训练，难以满足动态多变环境中的协作需求。

Method: 文中介绍的CooT利用最近的交互历史，预测与观察到的伙伴交互行为一致的行动，从而快速适应新伙伴。无需显式监督或微调。

Result: 在Overcooked基准上，CooT在协调任务中显著优于基线方法，并获得了人类评价中最高的协作效能，同时实验也验证了其鲁棒性和灵活性。

Conclusion: CooT 提供了一种快速适应未知伙伴的有效解决方案，在多智能体系统中展现了显著的优越性。

Abstract: Effective coordination among artificial agents in dynamic and uncertain
environments remains a significant challenge in multi-agent systems. Existing
approaches, such as self-play and population-based methods, either generalize
poorly to unseen partners or require extensive training. To overcome these
limitations, we propose Coordination Transformers (CooT), a novel in-context
coordination framework that uses recent interaction histories to adapt to
unseen partners rapidly. Unlike previous approaches that primarily aim to
increase the diversity of training partners, CooT explicitly focuses on
adapting to new partner behaviors by predicting actions aligned with observed
partner interactions. Trained on interaction trajectories collected from
diverse pairs of agents with complementary behaviors, CooT quickly learns
effective coordination strategies without explicit supervision or fine-tuning.
Evaluations on the Overcooked benchmark demonstrate that CooT significantly
outperforms baseline methods in coordination tasks involving previously unseen
partners. Human evaluations further confirm CooT as the most effective
collaborative partner, while extensive ablations highlight its robustness,
flexibility, and sensitivity to context in multi-agent scenarios.

</details>


### [331] [MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI](https://arxiv.org/abs/2506.23563)
*Huanjin Yao,Jiaxing Huang,Yawen Qiu,Michael K. Chen,Wenzheng Liu,Wei Zhang,Wenjie Zeng,Xikun Zhang,Jingyi Zhang,Yuxin Song,Wenhao Wu,Dacheng Tao*

Main category: cs.AI

TL;DR: MMReason是一项新的基准测试，用于评估多模态大语言模型（MLLM）的长链推理能力，其特点是多样性、开放性和挑战性的问题设定。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLM评估基准未能全面评估从困难性、多样性到中间推理步骤的长链推理能力，难以推动模型向通用人工智能发展。

Method: 设计了涉及6个学科、多难度层级的问题集，并采用多模型投票及详细的逐步解答技术，同时引入了基于参考的三值评分机制来准确评估中间推理步骤。

Result: 通过MMReason对现有多模态大语言模型的推理能力进行了基准测试和详细分析。

Conclusion: MMReason为推进MLLM推理能力的研究提供了一个卓有成效的评估工具，同时为该领域的未来研究奠定了基础。

Abstract: Reasoning plays a crucial role in advancing Multimodal Large Language Models
(MLLMs) toward Artificial General Intelligence. However, existing MLLM
benchmarks often fall short in precisely and comprehensively evaluating
long-chain reasoning abilities from three key aspects: (1) lack of difficulty
and diversity, (2) susceptibility to guessability and memorization, (3)
inadequate assessment of intermediate reasoning steps. To fill this gap, we
introduce MMReason, a new benchmark designed to precisely and comprehensively
evaluate MLLM long-chain reasoning capability with diverse, open-ended,
challenging questions. First, we curate challenging questions requiring
multi-step reasoning from various fields (i.e., 6 disciplines) and multiple
difficulty levels (i.e., from pre-university to university, and from
foundational to competition tiers). Second, these questions are reformulated
into an open-ended format and filtered using a multi-model voting technique to
eliminate shortcut cases related to guessing and memorization, ensuring robust
reasoning evaluations. Third, we annotate the questions with detailed
step-by-step solutions, and design a reference-based ternary scoring mechanism
to reliably assess intermediate reasoning steps. With MMReason, we benchmark
popular leading MLLMs and provide an in-depth analysis of their reasoning
capabilities. We hope MMReason will serve as a valuable resource for advancing
MLLM reasoning research. Code will be available at
https://github.com/HJYao00/MMReason.

</details>


### [332] [Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models](https://arxiv.org/abs/2506.23576)
*Maria Carolina Cornelia Wit,Jun Pang*

Main category: cs.AI

TL;DR: 本文探讨了使用多代理LLM系统作为防御越狱攻击的手段。实验显示多代理系统在提高抵抗能力方面有贡献，但存在取舍。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型可能面临越狱攻击威胁，研究如何通过多代理系统增强安全性。

Method: 对三种越狱攻击策略进行测试（包括AutoDefense, BetterDan, JB），重现AutoDefense框架并比较单代理与多代理配置的表现。

Result: 多代理系统提高了对越狱的防御能力（特别是假阴性减少），但效果因攻击策略而异，同时增加了假阳性和计算成本。

Conclusion: 多代理系统作为防御越狱的潜在手段展示了有效性，但仍有限制性，未来需进一步提升自动防御机制的稳健性。

Abstract: Recent advances in large language models (LLMs) have raised concerns about
jailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper
investigates the use of multi-agent LLM systems as a defence against such
attacks. We evaluate three jailbreaking strategies, including the original
AutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the
AutoDefense framework, we compare single-agent setups with two- and three-agent
configurations. Our results show that multi-agent systems enhance resistance to
jailbreaks, especially by reducing false negatives. However, its effectiveness
varies by attack type, and it introduces trade-offs such as increased false
positives and computational overhead. These findings point to the limitations
of current automated defences and suggest directions for improving alignment
robustness in future LLM systems.

</details>


### [333] [Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games](https://arxiv.org/abs/2506.23626)
*António Afonso,Iolanda Leite,Alessandro Sestini,Florian Fuchs,Konrad Tollmar,Linus Gisslén*

Main category: cs.AI

TL;DR: 本文提出了一种基于语言模型（LM）的自动化强化学习（RL）奖励函数权重调节方法，用于改进游戏强化学习中的行为表现。


<details>
  <summary>Details</summary>
Motivation: 在游戏中应用强化学习面临两个主要挑战：设计有效的奖励函数需要专家支持，以及游戏内容或机制改变可能导致已优化的奖励权重失效。

Method: 通过语言模型动态提议奖励权重调整，根据目标行为和之前训练回合的统计数据进行自动迭代优化。

Result: 评估结果表明，该方法能显著提升性能：在赛车任务中，成功率从9%提高到74%（首轮迭代），最终达到80%，接近专家设计的峰值（94%）。

Conclusion: 语言模型驱动的奖励权重调节是一种高效、自动化的解决方案，可以减少对人类专家的依赖，同时实现与专家水平竞争的表现。

Abstract: Reinforcement Learning (RL) in games has gained significant momentum in
recent years, enabling the creation of different agent behaviors that can
transform a player's gaming experience. However, deploying RL agents in
production environments presents two key challenges: (1) designing an effective
reward function typically requires an RL expert, and (2) when a game's content
or mechanics are modified, previously tuned reward weights may no longer be
optimal. Towards the latter challenge, we propose an automated approach for
iteratively fine-tuning an RL agent's reward function weights, based on a
user-defined language based behavioral goal. A Language Model (LM) proposes
updated weights at each iteration based on this target behavior and a summary
of performance statistics from prior training rounds. This closed-loop process
allows the LM to self-correct and refine its output over time, producing
increasingly aligned behavior without the need for manual reward engineering.
We evaluate our approach in a racing task and show that it consistently
improves agent performance across iterations. The LM-guided agents show a
significant increase in performance from $9\%$ to $74\%$ success rate in just
one iteration. We compare our LM-guided tuning against a human expert's manual
weight design in the racing task: by the final iteration, the LM-tuned agent
achieved an $80\%$ success rate, and completed laps in an average of $855$ time
steps, a competitive performance against the expert-tuned agent's peak $94\%$
success, and $850$ time steps.

</details>


### [334] [HASD: Hierarchical Adaption for pathology Slide-level Domain-shift](https://arxiv.org/abs/2506.23673)
*Jingsong Liu,Han Li,Chen Yang,Michael Deutges,Ario Sadafi,Xin You,Katharina Breininger,Nassir Navab,Peter J. Schüffler*

Main category: cs.AI

TL;DR: 该研究提出了一种名为HASD的分层自适应框架，用于解决病理AI中的切片级域移位问题，通过多尺度特征一致性和原型选择机制显著提高了领域适应性能。


<details>
  <summary>Details</summary>
Motivation: 病理数据因中心特定条件而具有显著域差异，现有方法大多针对图像补丁而非切片，难以捕获切片的全局特征。

Method: 通过提出HASD框架实现多尺度特征一致性，包括域级对齐、切片级几何不变性和补丁级注意力一致性正则化，并引入原型选择机制来降低计算开销。

Result: 在两个切片级任务中跨五个数据集进行验证，在乳腺癌HER2分级实验中提升4.1% AUROC，在UCEC生存预测中提高3.9% C-index。

Conclusion: HASD框架为病理机构提供了一种实用且可靠的切片级域自适应解决方案，同时降低了计算和标注成本。

Abstract: Domain shift is a critical problem for pathology AI as pathology data is
heavily influenced by center-specific conditions. Current pathology domain
adaptation methods focus on image patches rather than WSI, thus failing to
capture global WSI features required in typical clinical scenarios. In this
work, we address the challenges of slide-level domain shift by proposing a
Hierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD
achieves multi-scale feature consistency and computationally efficient
slide-level domain adaptation through two key components: (1) a hierarchical
adaptation framework that integrates a Domain-level Alignment Solver for
feature alignment, a Slide-level Geometric Invariance Regularization to
preserve the morphological structure, and a Patch-level Attention Consistency
Regularization to maintain local critical diagnostic cues; and (2) a prototype
selection mechanism that reduces computational overhead. We validate our method
on two slide-level tasks across five datasets, achieving a 4.1\% AUROC
improvement in a Breast Cancer HER2 Grading cohort and a 3.9\% C-index gain in
a UCEC survival prediction cohort. Our method provides a practical and reliable
slide-level domain adaption solution for pathology institutions, minimizing
both computational and annotation costs.

</details>


### [335] [PokéAI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red](https://arxiv.org/abs/2506.23689)
*Zihao Liu,Xinhang Sui,Yueran Song,Siwen Wang*

Main category: cs.AI

TL;DR: 研究开发了一个可以自主玩《精灵宝可梦红》的文本驱动、多代理大语言模型框架PokéAI，包括计划、执行和评价三个专门代理。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在多任务环境中的自主决策能力，特别是在复杂的策略游戏环境《精灵宝可梦红》中。

Method: 通过设计计划代理、执行代理和评论代理的多代理系统，在游戏中进行闭环决策，并开发战斗模块测试模型的能力。

Result: 战斗AI在50场野外对战中的平均胜率为80.8%，与人类玩家的差距仅为6%。同时，语言模型的战斗表现与其在语言相关任务上的分数高度相关。

Conclusion: 语言模型不仅具有强大的语言能力，还展现了独特的战略行为和多任务决策潜力。

Abstract: We introduce Pok\'eAI, the first text-based, multi-agent large language model
(LLM) framework designed to autonomously play and progress through Pok\'emon
Red. Our system consists of three specialized agents-Planning, Execution, and
Critique-each with its own memory bank, role, and skill set. The Planning Agent
functions as the central brain, generating tasks to progress through the game.
These tasks are then delegated to the Execution Agent, which carries them out
within the game environment. Upon task completion, the Critique Agent evaluates
the outcome to determine whether the objective was successfully achieved. Once
verification is complete, control returns to the Planning Agent, forming a
closed-loop decision-making system.
  As a preliminary step, we developed a battle module within the Execution
Agent. Our results show that the battle AI achieves an average win rate of
80.8% across 50 wild encounters, only 6% lower than the performance of an
experienced human player. Furthermore, we find that a model's battle
performance correlates strongly with its LLM Arena score on language-related
tasks, indicating a meaningful link between linguistic ability and strategic
reasoning. Finally, our analysis of gameplay logs reveals that each LLM
exhibits a unique playstyle, suggesting that individual models develop distinct
strategic behaviors.

</details>


### [336] [Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models](https://arxiv.org/abs/2506.23692)
*Boyuan Zheng,Zerui Fang,Zhe Xu,Rui Wang,Yiwen Chen,Cunshi Wang,Mengwei Qu,Lei Lei,Zhen Feng,Yan Liu,Yuyang Li,Mingzhou Tan,Jiaji Wu,Jianwei Shuai,Jia Li,Fangfu Ye*

Main category: cs.AI

TL;DR: 本文提出了“科学代理人”(Agent4S)的概念，利用大型语言模型驱动的代理来实现研究工作流的自动化，并提出了五级分类框架，旨在引领科学发现的下一次革命。


<details>
  <summary>Details</summary>
Motivation: 现有的科学领域中，AI4S虽然作为一种分析工具被广泛应用，但未能解决当前研究范式中的核心低效问题。

Method: 提出“Agent4S”的五级分类框架，从简单的任务自动化到完全自主协作的“AI科学家”，提供了从基础到高级自动化的清晰路径。

Result: 本文提出的框架为实现完全自主的AI科学家提供了理论支持，并提出了朝向科学自动化的明确路线。

Conclusion: “科学代理人”将作为第五科学范式，对科学发现的方式产生革命性影响，并推动科学研究进入全新阶段。

Abstract: While AI for Science (AI4S) serves as an analytical tool in the current
research paradigm, it doesn't solve its core inefficiency. We propose "Agent
for Science" (Agent4S)-the use of LLM-driven agents to automate the entire
research workflow-as the true Fifth Scientific Paradigm. This paper introduces
a five-level classification for Agent4S, outlining a clear roadmap from simple
task automation to fully autonomous, collaborative "AI Scientists." This
framework defines the next revolutionary step in scientific discovery.

</details>


### [337] [A New Perspective On AI Safety Through Control Theory Methodologies](https://arxiv.org/abs/2506.23703)
*Lars Ullrich,Walter Zimmer,Ross Greer,Knut Graichen,Alois C. Knoll,Mohan Trivedi*

Main category: cs.AI

TL;DR: 论文探讨了通过跨学科方法提升AI系统安全性的可能性，提出了“数据控制”的新视角。


<details>
  <summary>Details</summary>
Motivation: AI系统在安全性保证上存在重大挑战，特别是在实际安全关键的网络物理系统中。

Method: 提出了以跨学科为基础，从系统理论和分析视角出发的“数据控制”新框架，并通过自上而下的方法提供了一种通用的安全分析和保障基础。

Result: 新视角为AI工程提出了一种更好的跨学科安全分析方法，旨在结合控制理论提升AI的安全保障能力。

Conclusion: 该研究为提升AI系统安全性提供了理论基础，并为未来应用开发与创新奠定了路径。

Abstract: While artificial intelligence (AI) is advancing rapidly and mastering
increasingly complex problems with astonishing performance, the safety
assurance of such systems is a major concern. Particularly in the context of
safety-critical, real-world cyber-physical systems, AI promises to achieve a
new level of autonomy but is hampered by a lack of safety assurance. While
data-driven control takes up recent developments in AI to improve control
systems, control theory in general could be leveraged to improve AI safety.
Therefore, this article outlines a new perspective on AI safety based on an
interdisciplinary interpretation of the underlying data-generation process and
the respective abstraction by AI systems in a system theory-inspired and system
analysis-driven manner. In this context, the new perspective, also referred to
as data control, aims to stimulate AI engineering to take advantage of existing
safety analysis and assurance in an interdisciplinary way to drive the paradigm
of data control. Following a top-down approach, a generic foundation for safety
analysis and assurance is outlined at an abstract level that can be refined for
specific AI systems and applications and is prepared for future innovation.

</details>


### [338] [Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments](https://arxiv.org/abs/2506.23706)
*Christoph Schnabl,Daniel Hugenroth,Bill Marino,Alastair R. Beresford*

Main category: cs.AI

TL;DR: 提出了一种称为Attestable Audits的机制，在可信执行环境中运行以验证AI模型的合规性和交互。


<details>
  <summary>Details</summary>
Motivation: 针对传统基准测试在验证结果、模型知识产权和数据集保密性上存在的局限性，提出改进。

Method: 利用可信执行环境（Trusted Execution Environments），实现一种可以在彼此不信任的模型提供者和审计者间保护敏感数据的审计方法。

Result: 原型验证了这种方法在常见审计基准与Llama-3.1上具有可行性。

Conclusion: 建议的解决方案满足AI治理框架中提出的验证需求，适用于安全合规审计场景。

Abstract: Benchmarks are important measures to evaluate safety and compliance of AI
models at scale. However, they typically do not offer verifiable results and
lack confidentiality for model IP and benchmark datasets. We propose Attestable
Audits, which run inside Trusted Execution Environments and enable users to
verify interaction with a compliant AI model. Our work protects sensitive data
even when model provider and auditor do not trust each other. This addresses
verification challenges raised in recent AI governance frameworks. We build a
prototype demonstrating feasibility on typical audit benchmarks against
Llama-3.1.

</details>


### [339] [BayesL: Towards a Logical Framework for Bayesian Networks](https://arxiv.org/abs/2506.23773)
*Stefano M. Nicoletti,Mariëlle Stoelinga*

Main category: cs.AI

TL;DR: BayesL是一种新型框架，用于指定、查询和验证贝叶斯网络的行为。


<details>
  <summary>Details</summary>
Motivation: 解决贝叶斯网络中因果推理和假设场景问题。

Method: 提出BayesL语言，用于结构化创建查询，支持多种推理方式及假设场景评估。

Result: 无需手动修改模型的情况下，BayesL实现了对贝叶斯网络的高效推理和验证。

Conclusion: BayesL简化了贝叶斯网络的查询和验证过程，提供了强大的灵活性。

Abstract: We introduce BayesL, a novel logical framework for specifying, querying, and
verifying the behaviour of Bayesian networks (BNs). BayesL (pronounced "Basil")
is a structured language that allows for the creation of queries over BNs. It
facilitates versatile reasoning concerning causal and evidence-based
relationships, and permits comprehensive what-if scenario evaluations without
the need for manual modifications to the model.

</details>


### [340] [When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)](https://arxiv.org/abs/2506.23784)
*Parosh Aziz Abdulla,Mohamed Faouzi Atig,Julie Cailler,Chencheng Liang,Philipp Rümmer*

Main category: cs.AI

TL;DR: 利用图神经网络(GNNs)优化字符串方程组求解过程，通过新颖的图表示方法和排序机制，使字符串求解器在特定场景下性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有字符串求解器性能受方程处理顺序影响，为提高效率需要新的优化方法。

Method: 提出基于图神经网络的排序方法，利用图表示捕获整体信息，并设计三种多分类任务适应方程排序问题。通过利用最小不可满足子集(MUSes)完成GNN训练。

Result: 实验表明，新框架在处理每个方程中变量最多出现一次的特定场景下，解决了更多问题。

Conclusion: 结合GNN与新图表示方法，新框架在特定约束场景下性能优于现有字符串求解器，为字符串方程组求解提供了新思路。

Abstract: Nielsen transformation is a standard approach for solving word equations: by
repeatedly splitting equations and applying simplification steps, equations are
rewritten until a solution is reached. When solving a conjunction of word
equations in this way, the performance of the solver will depend considerably
on the order in which equations are processed. In this work, the use of Graph
Neural Networks (GNNs) for ranking word equations before and during the solving
process is explored. For this, a novel graph-based representation for word
equations is presented, preserving global information across conjuncts,
enabling the GNN to have a holistic view during ranking. To handle the variable
number of conjuncts, three approaches to adapt a multi-classification task to
the problem of ranking equations are proposed. The training of the GNN is done
with the help of minimum unsatisfiable subsets (MUSes) of word equations. The
experimental results show that, compared to state-of-the-art string solvers,
the new framework solves more problems in benchmarks where each variable
appears at most once in each equation.

</details>


### [341] [Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning](https://arxiv.org/abs/2506.23793)
*Anton Andreychuk,Konstantin Yakovlev,Aleksandr Panov,Alexey Skrynnik*

Main category: cs.AI

TL;DR: 提出MAPF-GPT-DDG优化解决多智能体路径规划问题，该方法通过集中专家数据和增量数据生成机制大幅提升性能。


<details>
  <summary>Details</summary>
Motivation: 为解决MAPF NP难问题并提高实际应用的可扩展性和效率。

Method: 利用集中专家数据和新颖的增量数据生成机制对预训练MAPF模型进行微调。

Result: 实验显示，MAPF-GPT-DDG在解决方案质量上优于现有学习方法，支持多达100万智能体的实例。

Conclusion: MAPF-GPT-DDG实现了路径规划领域的新里程碑，为高度扩展性问题提供了有效解决方案。

Abstract: Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot
trajectory planning problems, where multiple homogeneous robots simultaneously
move in the shared environment. While solving MAPF optimally has been proven to
be NP-hard, scalable, and efficient, solvers are vital for real-world
applications like logistics, search-and-rescue, etc. To this end, decentralized
suboptimal MAPF solvers that leverage machine learning have come on stage.
Building on the success of the recently introduced MAPF-GPT, a pure imitation
learning solver, we introduce MAPF-GPT-DDG. This novel approach effectively
fine-tunes the pre-trained MAPF model using centralized expert data. Leveraging
a novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training
while significantly improving performance at test time. Our experiments
demonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF
solvers, including the original MAPF-GPT, regarding solution quality across
many testing scenarios. Remarkably, it can work with MAPF instances involving
up to 1 million agents in a single environment, setting a new milestone for
scalability in MAPF domains.

</details>


### [342] [A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents](https://arxiv.org/abs/2506.23844)
*Hang Su,Jun Luo,Chang Liu,Xiao Yang,Yichi Zhang,Yinpeng Dong,Jun Zhu*

Main category: cs.AI

TL;DR: 本文讨论了LLM驱动的自主人工智能代理及其相关的安全风险，并提出了R2A2框架作为防护策略。


<details>
  <summary>Details</summary>
Motivation: 推动AI从静态推理系统转向具有记忆增强和交互能力的动态自治代理，同时分析其引发的新型安全风险。

Method: 回顾当前自主代理的能力结构及其安全漏洞，提出R2A2框架——一个基于受约束马尔可夫决策过程的认知框架，用于风险感知建模和奖励风险联合优化。

Result: 通过综合防御策略和新框架的实施，为代理的决策流程提供了系统性安全保障。

Conclusion: 本文为开发更安全的自主AI代理提供了体系结构和实用指导，强化了长期安全措施的重要性。

Abstract: Recent advances in large language models (LLMs) have catalyzed the rise of
autonomous AI agents capable of perceiving, reasoning, and acting in dynamic,
open-ended environments. These large-model agents mark a paradigm shift from
static inference systems to interactive, memory-augmented entities. While these
capabilities significantly expand the functional scope of AI, they also
introduce qualitatively novel security risks - such as memory poisoning, tool
misuse, reward hacking, and emergent misalignment - that extend beyond the
threat models of conventional systems or standalone LLMs. In this survey, we
first examine the structural foundations and key capabilities that underpin
increasing levels of agent autonomy, including long-term memory retention,
modular tool use, recursive planning, and reflective reasoning. We then analyze
the corresponding security vulnerabilities across the agent stack, identifying
failure modes such as deferred decision hazards, irreversible tool chains, and
deceptive behaviors arising from internal state drift or value misalignment.
These risks are traced to architectural fragilities that emerge across
perception, cognition, memory, and action modules. To address these challenges,
we systematically review recent defense strategies deployed at different
autonomy layers, including input sanitization, memory lifecycle control,
constrained decision-making, structured tool invocation, and introspective
reflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a
unified cognitive framework grounded in Constrained Markov Decision Processes
(CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation,
and joint reward-risk optimization to enable principled, proactive safety
across the agent's decision-making loop.

</details>


### [343] [Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence](https://arxiv.org/abs/2506.23908)
*András György,Tor Lattimore,Nevena Lazić,Csaba Szepesvári*

Main category: cs.AI

TL;DR: 本文探讨当前AI系统在演绎推理任务中的不足，并提出一种新的学习范式来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在数学和科学领域取得了重大进展，但其在简单演绎推理任务上仍表现不佳，无法实现通用人工智能的理想。

Method: 提出转变研究范式，从优化统计性能转向追求对所有输入均正确的精确学习。

Result: 指出当前模型依赖于统计学习导致的不健全行为，并强调采用精确学习可实现可靠的演绎推理。

Conclusion: 精确学习对于实现可靠的演绎推理至关重要，应作为算法设计的指导目标。

Abstract: Sound deductive reasoning -- the ability to derive new knowledge from
existing facts and rules -- is an indisputably desirable aspect of general
intelligence. Despite the major advances of AI systems in areas such as math
and science, especially since the introduction of transformer architectures, it
is well-documented that even the most advanced frontier systems regularly and
consistently falter on easily-solvable deductive reasoning tasks. Hence, these
systems are unfit to fulfill the dream of achieving artificial general
intelligence capable of sound deductive reasoning. We argue that their unsound
behavior is a consequence of the statistical learning approach powering their
development. To overcome this, we contend that to achieve reliable deductive
reasoning in learning-based AI systems, researchers must fundamentally shift
from optimizing for statistical performance against distributions on reasoning
problems and algorithmic tasks to embracing the more ambitious exact learning
paradigm, which demands correctness on all inputs. We argue that exact learning
is both essential and possible, and that this ambitious objective should guide
algorithm design.

</details>


### [344] [Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice](https://arxiv.org/abs/2506.23924)
*Akshit Kumar,Tianyi Peng,Yuhang Wu,Assaf Zeevi*

Main category: cs.AI

TL;DR: 本研究初步评估了大型语言模型（LLMs）在解决运筹学随机建模问题中的能力，发现部分模式下LLMs表现与人类专家水平相当，但仍有待改进。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在运筹学领域，特别是在涉及不确定性的随机建模问题上的潜在应用和表现能力。

Method: 收集研究生水平的课业题及博士考试题，借助开源库SimOpt测试LLMs在真实环境中的决策能力，并进行性能对比评估。

Result: LLMs在部分课堂和实用场景下显示出与人类专家相当的能力，但随机建模管道的完全自动化仍面临挑战。

Conclusion: 研究证明LLMs具有支持运筹学研究及提升实际应用影响的潜力，有望通过自动化放大运筹学对现实世界的作用。

Abstract: Large language models (LLMs) have exhibited expert-level capabilities across
various domains. However, their abilities to solve problems in Operations
Research (OR) -- the analysis and optimization of mathematical models derived
from real-world problems or their verbal descriptions -- remain underexplored.
In this work, we take a first step toward evaluating LLMs' abilities to solve
stochastic modeling problems, a core class of OR problems characterized by
uncertainty and typically involving tools from probability, statistics, and
stochastic processes. We manually procure a representative set of
graduate-level homework and doctoral qualification-exam problems and test LLMs'
abilities to solve them. We further leverage SimOpt, an open-source library of
simulation-optimization problems and solvers, to investigate LLMs' abilities to
make real-world decisions under uncertainty. Our results show that, though a
nontrivial amount of work is still needed to reliably automate the stochastic
modeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on
par with human experts in both classroom and practical settings. These findings
highlight the potential of building AI agents that assist OR researchers and
amplify the real-world impact of OR through automation.

</details>


### [345] [Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system](https://arxiv.org/abs/2506.23926)
*Junping Wang,Bicheng Wang,Yibo Xuea,Yuan Xie*

Main category: cs.AI

TL;DR: 本文提出工业大脑，一个融入高阶活动驱动神经网络与CT-OODA符号推理框架的人类式自主认知决策系统，大幅提升工业链韧性预测与规划。


<details>
  <summary>Details</summary>
Motivation: 在工业链科学管理及工程应用中保持核心功能的韧性至关重要，但目前深度学习方法面对复杂多变的韧性结构共演问题表现有限。

Method: 提出融合高阶活动驱动神经网络和CT-OODA符号推理的工业大脑框架，直接从观测数据中规划韧性。

Result: 实验表明，工业大脑在韧性预测与规划性能上显著优于GoT、OlaGPT等方法，准确率提升10.8%-11.03%，具备较强的泛化性与抗干扰能力。

Conclusion: 工业大脑弥补了韧性预测与规划领域的空白，为工业链的科学管理提供了有效工具。

Abstract: Resilience non-equilibrium measurement, the ability to maintain fundamental
functionality amidst failures and errors, is crucial for scientific management
and engineering applications of industrial chain. The problem is particularly
challenging when the number or types of multiple co-evolution of resilience
(for example, randomly placed) are extremely chaos. Existing end-to-end deep
learning ordinarily do not generalize well to unseen full-feld reconstruction
of spatiotemporal co-evolution structure, and predict resilience of network
topology, especially in multiple chaos data regimes typically seen in
real-world applications. To address this challenge, here we propose industrial
brain, a human-like autonomous cognitive decision-making and planning framework
integrating higher-order activity-driven neuro network and CT-OODA symbolic
reasoning to autonomous plan resilience directly from observational data of
global variable. The industrial brain not only understands and model structure
of node activity dynamics and network co-evolution topology without simplifying
assumptions, and reveal the underlying laws hidden behind complex networks, but
also enabling accurate resilience prediction, inference, and planning.
Experimental results show that industrial brain significantly outperforms
resilience prediction and planning methods, with an accurate improvement of up
to 10.8\% over GoT and OlaGPT framework and 11.03\% over spectral dimension
reduction. It also generalizes to unseen topologies and dynamics and maintains
robust performance despite observational disturbances. Our findings suggest
that industrial brain addresses an important gap in resilience prediction and
planning for industrial chain.

</details>


### [346] [AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models](https://arxiv.org/abs/2506.23949)
*Anthony M. Barrett,Jessica Newman,Brandie Nonnecke,Nada Madkour,Dan Hendrycks,Evan R. Murphy,Krystal Jackson,Deepika Raman*

Main category: cs.AI

TL;DR: 该文档探讨如何识别、分析及减轻通用人工智能/基础模型的风险，并为其开发者及应用者提供风险管理实践。


<details>
  <summary>Details</summary>
Motivation: 随着多功能人工智能模型的发展，其带来了诸多益处的同时也存在潜在风险，亟需采取有效的风险管理措施。

Method: 提供了基于NIST人工智能风险管理框架及ISO/IEC 23894的风险管理实践，针对GPAI/基础模型开发的特殊问题进行了调整与深化。

Result: 形成了一套针对GPAI/基础模型开发者及应用者的风险管理指南，以引导其安全开发与使用。

Conclusion: 通过本文档的风险管理指导，开发者及用户可以更有效地应对通用人工智能及其模型的潜在风险，同时促进行业标准的遵守与采用。

Abstract: Increasingly multi-purpose AI models, such as cutting-edge large language
models or other 'general-purpose AI' (GPAI) models, 'foundation models,'
generative AI models, and 'frontier models' (typically all referred to
hereafter with the umbrella term 'GPAI/foundation models' except where greater
specificity is needed), can provide many beneficial capabilities but also risks
of adverse events with profound consequences. This document provides
risk-management practices or controls for identifying, analyzing, and
mitigating risks of GPAI/foundation models. We intend this document primarily
for developers of large-scale, state-of-the-art GPAI/foundation models; others
that can benefit from this guidance include downstream developers of end-use
applications that build on a GPAI/foundation model. This document facilitates
conformity with or use of leading AI risk management-related standards,
adapting and building on the generic voluntary guidance in the NIST AI Risk
Management Framework and ISO/IEC 23894, with a focus on the unique issues faced
by developers of GPAI/foundation models.

</details>


### [347] [Harnessing AI Agents to Advance Research on Refugee Child Mental Health](https://arxiv.org/abs/2506.23992)
*Aditya Shrivastava,Komal Gupta,Shraddha Arora*

Main category: cs.AI

TL;DR: 本文提出了一个基于AI的框架来处理难民儿童的心理健康数据，并比较了两种RAG方法。


<details>
  <summary>Details</summary>
Motivation: 当前国际难民危机加剧，大量流离失所的儿童受到了极端心理创伤。研究旨在为难民心理健康数据提供有效解决方案。

Method: 通过比较Zephyr-7B-beta和DeepSeek R1-7B两种RAG方法，评估模型在处理复杂人道数据集以及避免数据幻觉方面的表现。

Result: 两种模型均能正常运行，其中Deepseek R1的答案相关性准确率达0.91，优于Zephyr。

Conclusion: 结合尖端AI方法、移民研究及儿童心理学，提出了一个可扩展的框架，帮助政策制定者和相关机构更好地解决难民儿童心理健康问题。

Abstract: The international refugee crisis deepens, exposing millions of dis placed
children to extreme psychological trauma. This research suggests a com pact,
AI-based framework for processing unstructured refugee health data and
distilling knowledge on child mental health. We compare two Retrieval-Aug
mented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to
determine how well they process challenging humanitarian datasets while avoid
ing hallucination hazards. By combining cutting-edge AI methods with migration
research and child psychology, this study presents a scalable strategy to
assist policymakers, mental health practitioners, and humanitarian agencies to
better assist displaced children and recognize their mental wellbeing. In
total, both the models worked properly but significantly Deepseek R1 is
superior to Zephyr with an accuracy of answer relevance 0.91

</details>


### [348] [Constructing Non-Markovian Decision Process via History Aggregator](https://arxiv.org/abs/2506.24026)
*Yongyi Wang,Wenxin Li*

Main category: cs.AI

TL;DR: 本研究提出了一种基于范畴论的方法，以解决算法决策中因非马尔可夫动态带来的挑战，尤其是强化学习领域。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估决策算法处理非马尔可夫动态的能力方面存在不足，亟需一种更加全面的评估方法。

Method: 构建了马尔可夫决策过程（MDP）和非马尔可夫决策过程（NMDP）的类别，并证明其等价性；通过引入状态的历史聚合器（HAS）在时间序列中控制问题的状态依赖结构。

Result: 证明该方法在表示广泛的非马尔可夫动态和提供严格灵活的算法评价方面具有有效性。

Conclusion: 该研究提出的新理论和方法为理解和解决非马尔可夫动态提供了一种新视角，同时提升了算法的评估精度和灵活性。

Abstract: In the domain of algorithmic decision-making, non-Markovian dynamics manifest
as a significant impediment, especially for paradigms such as Reinforcement
Learning (RL), thereby exerting far-reaching consequences on the advancement
and effectiveness of the associated systems. Nevertheless, the existing
benchmarks are deficient in comprehensively assessing the capacity of decision
algorithms to handle non-Markovian dynamics. To address this deficiency, we
have devised a generalized methodology grounded in category theory. Notably, we
established the category of Markov Decision Processes (MDP) and the category of
non-Markovian Decision Processes (NMDP), and proved the equivalence
relationship between them. This theoretical foundation provides a novel
perspective for understanding and addressing non-Markovian dynamics. We further
introduced non-Markovianity into decision-making problem settings via the
History Aggregator for State (HAS). With HAS, we can precisely control the
state dependency structure of decision-making problems in the time series. Our
analysis demonstrates the effectiveness of our method in representing a broad
range of non-Markovian dynamics. This approach facilitates a more rigorous and
flexible evaluation of decision algorithms by testing them in problem settings
where non-Markovian dynamics are explicitly constructed.

</details>


### [349] [SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2506.24119)
*Bo Liu,Leon Guertler,Simon Yu,Zichen Liu,Penghui Qi,Daniel Balcells,Mickel Liu,Cheston Tan,Weiyan Shi,Min Lin,Wee Sun Lee,Natasha Jaques*

Main category: cs.AI

TL;DR: 提出了一种名为SPIRAL的自对弈框架，通过零和游戏的多轮训练，增强语言模型的推理能力，无需人工监督，且具备广泛迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法依赖人工设计的奖励函数和任务数据集，难以自主扩展任务范围。

Method: 提出SPIRAL框架，使用零和游戏的自对弈生成动态任务；实现在线多智能体RL系统，引入角色条件优势估计（RAE）。

Result: 在多个游戏上，通过自对弈训练的模型推理能力显著提升，可广泛迁移；在数学和一般推理上分别提升8.6%和8.4%。多游戏训练进一步增强推理能力。

Conclusion: 零和游戏中的自对弈可以自然发展出可迁移的推理能力，为自主推理的发展提供了一种前景广阔的方向。

Abstract: Recent advances in reinforcement learning have shown that language models can
develop sophisticated reasoning through training on tasks with verifiable
rewards, but these approaches depend on human-curated problem-answer pairs and
domain-specific reward engineering. We introduce SPIRAL, a self-play framework
where models learn by playing multi-turn, zero-sum games against continuously
improving versions of themselves, eliminating the need for human supervision.
Through self-play, SPIRAL generates an infinite curriculum of progressively
challenging problems as models must constantly adapt to stronger opponents. To
enable this self-play training at scale, We implement a fully online,
multi-turn, multi-agent reinforcement learning system for LLMs and propose
role-conditioned advantage estimation (RAE) to stabilize multi-agent training.
Using SPIRAL, self-play on zero-sum games produces reasoning capabilities that
transfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%
improvement on math and 8.4% on general reasoning, outperforming SFT on 25,000
expert game trajectories. Analysis reveals that this transfer occurs through
three cognitive patterns: systematic decomposition, expected value calculation,
and case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple
Negotiation) further enhances performance as each game develops distinct
reasoning strengths. Applying SPIRAL to a strong reasoning model
(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These
results demonstrate that zero-sum games naturally develop transferable
reasoning capabilities, highlighting a promising direction for autonomous
reasoning development.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [350] [Latent Factorization of Tensors with Threshold Distance Weighted Loss for Traffic Data Estimation](https://arxiv.org/abs/2506.22441)
*Lei Yang*

Main category: cs.LG

TL;DR: 提出了一种改进的张量潜在因子分解模型（TDWLFT），通过引入阈值加权损失函数来降低模型对异常值的敏感性，并在交通数据预测中实现了高精度和高效性。


<details>
  <summary>Details</summary>
Motivation: 解决智能交通系统（ITS）中由于数据采集过程中的通信故障和传感器失效导致的数据缺失和污染问题，以提供更完整的时空交通数据。

Method: 提出了阈值加权损失函数，并将其集成到张量潜在因子分解模型中，对个体样本分配差异化权重以降低异常值的影响，从而完成对交通数据的预测和恢复。

Result: 通过两个不同城市环境下的交通速度数据集实验，证明新方法在预测准确性和计算效率上均优于现有方法。

Conclusion: TDWLFT模型通过改进的损失函数在处理异常值时表现更佳，为智能交通系统中的缺失数据处理提供了更为可靠和有效的解决方案。

Abstract: Intelligent transportation systems (ITS) rely heavily on complete and
high-quality spatiotemporal traffic data to achieve optimal performance.
Nevertheless, in real-word traffic data collection processes, issues such as
communication failures and sensor malfunctions often lead to incomplete or
corrupted datasets, thereby posing significant challenges to the advancement of
ITS. Among various methods for imputing missing spatiotemporal traffic data,
the latent factorization of tensors (LFT) model has emerged as a widely adopted
and effective solution. However, conventional LFT models typically employ the
standard L2-norm in their learning objective, which makes them vulnerable to
the influence of outliers. To overcome this limitation, this paper proposes a
threshold distance weighted (TDW) loss-incorporated Latent Factorization of
Tensors (TDWLFT) model. The proposed loss function effectively reduces the
model's sensitivity to outliers by assigning differentiated weights to
individual samples. Extensive experiments conducted on two traffic speed
datasets sourced from diverse urban environments confirm that the proposed
TDWLFT model consistently outperforms state-of-the-art approaches in terms of
both in both prediction accuracy and computational efficiency.

</details>


### [351] [Features-based embedding or Feature-grounding](https://arxiv.org/abs/2506.22442)
*Piotr Makarevich*

Main category: cs.LG

TL;DR: 研究探讨如何利用基于特征的嵌入在深度学习模型中重现知识驱动的结构化思维。


<details>
  <summary>Details</summary>
Motivation: 日常推理中，人类通过经验形成的概念类别和先验知识塑造了我们对对象特性的预期，研究旨在探索将此类思维引入深度学习模型。

Method: 提出了一种特定方法，建立基于特征的嵌入，以对齐可操作词典的共享表示与可解释的领域特定概念特征。

Result: 提供了一个结合知识和特征嵌入的新方法，有助于改进模型对领域知识的表达和理解。

Conclusion: 基于特征的嵌入可以有效对齐概念特征和共享表示，为引入结构化知识到深度学习模型开辟了新路径。

Abstract: In everyday reasoning, when we think about a particular object, we associate
it with a unique set of expected properties such as weight, size, or more
abstract attributes like density or horsepower. These expectations are shaped
by our prior knowledge and the conceptual categories we have formed through
experience. This paper investigates how such knowledge-based structured
thinking can be reproduced in deep learning models using features based
embeddings. Specially, it introduces an specific approach to build
feature-grounded embedding, aiming to align shareable representations of
operable dictionary with interpretable domain-specific conceptual features.

</details>


### [352] [FF-INT8: Efficient Forward-Forward DNN Training on Edge Devices with INT8 Precision](https://arxiv.org/abs/2506.22771)
*Jingxiao Ma,Priyadarshini Panda,Sherief Reda*

Main category: cs.LG

TL;DR: 本文提出一种基于前向前算法的INT8量化训练方法，在嵌入式设备上显著优化能耗、内存和训练速度，同时保持较高准确性。


<details>
  <summary>Details</summary>
Motivation: 当前基于反向传播的神经网络训练方法在时间和能量消耗方面效率低下，尤其在资源受限的边缘设备上表现不佳，因此需要探索更高效的训练机制。

Method: 利用前向前算法替代反向传播中的反向传播过程，并采用INT8量化训练策略减少内存占用。同时，提出了一种"前瞻"策略来缓解前向前算法的局限性并提升模型准确性。

Result: 在NVIDIA Jetson Orin Nano设备上实验表明，该方法训练速度加快4.6%、节省能量8.3%、内存使用减少27.0%，并且在保持与现有最先进方法相近的准确率。

Conclusion: 提出的前向前算法结合INT8量化训练不仅在嵌入式设备上提升了资源效率，还保持了模型精度，为资源受限环境的神经网络训练提供了一种新思路。

Abstract: Backpropagation has been the cornerstone of neural network training for
decades, yet its inefficiencies in time and energy consumption limit its
suitability for resource-constrained edge devices. While low-precision neural
network quantization has been extensively researched to speed up model
inference, its application in training has been less explored. Recently, the
Forward-Forward (FF) algorithm has emerged as a promising alternative to
backpropagation, replacing the backward pass with an additional forward pass.
By avoiding the need to store intermediate activations for backpropagation, FF
can reduce memory footprint, making it well-suited for embedded devices. This
paper presents an INT8 quantized training approach that leverages FF's
layer-by-layer strategy to stabilize gradient quantization. Furthermore, we
propose a novel "look-ahead" scheme to address limitations of FF and improve
model accuracy. Experiments conducted on NVIDIA Jetson Orin Nano board
demonstrate 4.6% faster training, 8.3% energy savings, and 27.0% reduction in
memory usage, while maintaining competitive accuracy compared to the
state-of-the-art.

</details>


### [353] [Learning Interpretable Rules from Neural Networks: Neurosymbolic AI for Radar Hand Gesture Recognition](https://arxiv.org/abs/2506.22443)
*Sarah Seifi,Tobias Sukianto,Cecilia Carbonelli,Lorenzo Servadei,Robert Wille*

Main category: cs.LG

TL;DR: RL-Net是一种结合规则和神经网络的模型，在雷达手势识别应用中兼顾性能和可解释性，实现93.03%的F1得分并降低规则复杂性。


<details>
  <summary>Details</summary>
Motivation: 在复杂的数据任务中，传统的基于规则的方法缺乏性能，而深度神经网络虽然性能强大但缺乏透明性。需要开发一种既能保持高性能又能提供可解释性的模型。

Method: 提出了一种名为RL-Net的神经符号规则学习神经网络，通过神经优化学习可解释的规则列表，并将其首次应用于基于雷达的手势识别任务，同时对比了一个完全透明的规则系统（MIRA）和一个可解释的黑箱模型（XentricAI）。

Result: RL-Net在性能和可解释性之间达到了平衡，取得了93.03%的F1得分，显著降低了规则复杂性，还针对优化中的规则剪枝和层级偏差问题提出了稳定性改进方案。

Conclusion: RL-Net被证明在透明性和性能之间提供了有效的中间解决方案，展示了神经符号模型在真实应用可解释手势识别中的潜力，对实现可解释 AI 和边缘计算系统具有重要参考意义。

Abstract: Rule-based models offer interpretability but struggle with complex data,
while deep neural networks excel in performance yet lack transparency. This
work investigates a neuro-symbolic rule learning neural network named RL-Net
that learns interpretable rule lists through neural optimization, applied for
the first time to radar-based hand gesture recognition (HGR). We benchmark
RL-Net against a fully transparent rule-based system (MIRA) and an explainable
black-box model (XentricAI), evaluating accuracy, interpretability, and user
adaptability via transfer learning. Our results show that RL-Net achieves a
favorable trade-off, maintaining strong performance (93.03% F1) while
significantly reducing rule complexity. We identify optimization challenges
specific to rule pruning and hierarchy bias and propose stability-enhancing
modifications. Compared to MIRA and XentricAI, RL-Net emerges as a practical
middle ground between transparency and performance. This study highlights the
real-world feasibility of neuro-symbolic models for interpretable HGR and
offers insights for extending explainable AI to edge-deployable sensing
systems.

</details>


### [354] [Mirror Descent Policy Optimisation for Robust Constrained Markov Decision Processes](https://arxiv.org/abs/2506.23165)
*David Bossens,Atsushi Nitanda*

Main category: cs.LG

TL;DR: 本文提出了一种应用于鲁棒约束马尔可夫决策过程（RCMDPs）的镜像下降策略优化方法。


<details>
  <summary>Details</summary>
Motivation: 研究如何在长期约束和认知不确定性下，开发安全且鲁棒的强化学习策略。

Method: 利用镜像下降策略优化技术，在拉格朗日公式下同时最大化策略和最小化对抗性转移核的损失函数，适用于RCMDP的oracle和基于样本的两种场景。

Result: 在oracle-based场景中，平方距离收敛率达到$\mathcal{O}(1/T)$，熵正则化目标收敛率为$\mathcal{O}(e^{-T})$；在基于样本的场景中，收敛率达到$\tilde{\mathcal{O}}(1/T^{1/3})$。实验表明在约束和非约束优化中效果显著，且鲁棒性测试中优于基线算法。

Conclusion: 镜像下降策略优化方法提升了RCMDP的学习政策的鲁棒性和约束满足能力，为强化学习中的安全性研究提供了新的解决方案。

Abstract: Safety is an essential requirement for reinforcement learning systems. The
newly emerging framework of robust constrained Markov decision processes allows
learning policies that satisfy long-term constraints while providing guarantees
under epistemic uncertainty. This paper presents mirror descent policy
optimisation for robust constrained Markov decision processes (RCMDPs), making
use of policy gradient techniques to optimise both the policy (as a maximiser)
and the transition kernel (as an adversarial minimiser) on the Lagrangian
representing a constrained MDP. In the oracle-based RCMDP setting, we obtain an
$\mathcal{O}\left(\frac{1}{T}\right)$ convergence rate for the squared distance
as a Bregman divergence, and an $\mathcal{O}\left(e^{-T}\right)$ convergence
rate for entropy-regularised objectives. In the sample-based RCMDP setting, we
obtain an $\tilde{\mathcal{O}}\left(\frac{1}{T^{1/3}}\right)$ convergence rate.
Experiments confirm the benefits of mirror descent policy optimisation in
constrained and unconstrained optimisation, and significant improvements are
observed in robustness tests when compared to baseline policy optimisation
algorithms.

</details>


### [355] [Active Learning for Forecasting Severity among Patients with Post Acute Sequelae of SARS-CoV-2](https://arxiv.org/abs/2506.22444)
*Jing Wang,Amar Sra,Jeremy C. Weiss*

Main category: cs.LG

TL;DR: 提出了一种基于大型语言模型和主动注意网络的方法，用于预测PASC患者的临床风险和相关事件进展。


<details>
  <summary>Details</summary>
Motivation: 解决PASC长期影响对医疗系统的挑战，尤其是进展事件的识别困难。

Method: 用Llama-3.1-70B-Instruct模型生成文本特征，结合临床专家注释的风险数据，并采用主动注意网络预测风险及事件。

Result: 提高了临床风险预测的准确性，并减少了人工标注的需求。

Conclusion: 结合人类专家知识和主动学习的方法改善了PASC患者护理和决策，对医疗资源优化提供帮助。

Abstract: The long-term effects of Postacute Sequelae of SARS-CoV-2, known as PASC,
pose a significant challenge to healthcare systems worldwide. Accurate
identification of progression events, such as hospitalization and reinfection,
is essential for effective patient management and resource allocation. However,
traditional models trained on structured data struggle to capture the nuanced
progression of PASC. In this study, we introduce the first publicly available
cohort of 18 PASC patients, with text time series features based on Large
Language Model Llama-3.1-70B-Instruct and clinical risk annotated by clinical
expert. We propose an Active Attention Network to predict the clinical risk and
identify progression events related to the risk. By integrating human expertise
with active learning, we aim to enhance clinical risk prediction accuracy and
enable progression events identification with fewer number of annotation. The
ultimate goal is to improves patient care and decision-making for SARS-CoV-2
patient.

</details>


### [356] [Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning for Cyber-Physical Systems Security](https://arxiv.org/abs/2506.22445)
*Saad Alqithami*

Main category: cs.LG

TL;DR: 本文提出了一种名为HAMARL的框架，针对传统安全方法对CPS系统日益复杂的网络攻击防御不足的问题，采用分层多智能体强化学习和对抗训练策略，显著提升系统网络安全性。


<details>
  <summary>Details</summary>
Motivation: 传统的安全方法难以应对CPS因连通性增加而面临的高级威胁（如零日攻击）；为增强工业物联网等行业的网络安全，有必要开发更先进和高效的防御机制。

Method: HAMARL框架采用层级式多智能体强化学习：由本地智能体负责子系统安全，而全局协调器负责整体策略优化。同时，通过对抗训练模拟和预测威胁，提升系统的防御适应能力。

Result: 实验表明，HAMARL相较传统多智能体强化学习显著提升了攻击检测准确性、减少了响应时间，并确保了操作的持续性。

Conclusion: 这种结合分层多智能体协调和对抗训练的创新方法有效增强了下一代CPS的弹性与安全性。

Abstract: Cyber-Physical Systems play a critical role in the infrastructure of various
sectors, including manufacturing, energy distribution, and autonomous
transportation systems. However, their increasing connectivity renders them
highly vulnerable to sophisticated cyber threats, such as adaptive and zero-day
attacks, against which traditional security methods like rule-based intrusion
detection and single-agent reinforcement learning prove insufficient. To
overcome these challenges, this paper introduces a novel Hierarchical
Adversarially-Resilient Multi-Agent Reinforcement Learning (HAMARL) framework.
HAMARL employs a hierarchical structure consisting of local agents dedicated to
subsystem security and a global coordinator that oversees and optimizes
comprehensive, system-wide defense strategies. Furthermore, the framework
incorporates an adversarial training loop designed to simulate and anticipate
evolving cyber threats, enabling proactive defense adaptation. Extensive
experimental evaluations conducted on a simulated industrial IoT testbed
indicate that HAMARL substantially outperforms traditional multi-agent
reinforcement learning approaches, significantly improving attack detection
accuracy, reducing response times, and ensuring operational continuity. The
results underscore the effectiveness of combining hierarchical multi-agent
coordination with adversarially-aware training to enhance the resilience and
security of next-generation CPS.

</details>


### [357] [EAGLE: Efficient Alignment of Generalized Latent Embeddings for Multimodal Survival Prediction with Interpretable Attribution Analysis](https://arxiv.org/abs/2506.22446)
*Aakash Tripathi,Asim Waqas,Matthew B. Schabath,Yasin Yilmaz,Ghulam Rasool*

Main category: cs.LG

TL;DR: 本文提出了一种名为EAGLE的深度学习框架，用于癌症存活预测，具有高效多模态数据融合、显著降低计算需求并提供临床可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态融合方法存在简单化融合策略、巨大的计算需求和缺乏可解释性的问题，阻碍了其临床应用。

Method: 通过动态跨模态注意机制、维度大幅度缩减、多种归因方法及统一管道进行癌症存活预测。

Result: 在三种癌症类型的911名患者中进行了评估，发现高风险患者主要依赖不利成像特征，而低风险患者则展现多模态贡献的平衡，并实现了中位生存期差异高达4至5倍的风险分层。

Conclusion: EAGLE结合先进性能与临床可解释性，推动多模态生存预测的实际医疗部署，提升预测准确性及医生对自动化预测的信任。

Abstract: Accurate cancer survival prediction requires integration of diverse data
modalities that reflect the complex interplay between imaging, clinical
parameters, and textual reports. However, existing multimodal approaches suffer
from simplistic fusion strategies, massive computational requirements, and lack
of interpretability-critical barriers to clinical adoption. We present EAGLE
(Efficient Alignment of Generalized Latent Embeddings), a novel deep learning
framework that addresses these limitations through attention-based multimodal
fusion with comprehensive attribution analysis. EAGLE introduces four key
innovations: (1) dynamic cross-modal attention mechanisms that learn
hierarchical relationships between modalities, (2) massive dimensionality
reduction (99.96%) while maintaining predictive performance, (3) three
complementary attribution methods providing patient-level interpretability, and
(4) a unified pipeline enabling seamless adaptation across cancer types. We
evaluated EAGLE on 911 patients across three distinct malignancies:
glioblastoma (GBM, n=160), intraductal papillary mucinous neoplasms (IPMN,
n=171), and non-small cell lung cancer (NSCLC, n=580). Patient-level analysis
showed high-risk individuals relied more heavily on adverse imaging features,
while low-risk patients demonstrated balanced modality contributions. Risk
stratification identified clinically meaningful groups with 4-fold (GBM) to
5-fold (NSCLC) differences in median survival, directly informing treatment
intensity decisions. By combining state-of-the-art performance with clinical
interpretability, EAGLE bridges the gap between advanced AI capabilities and
practical healthcare deployment, offering a scalable solution for multimodal
survival prediction that enhances both prognostic accuracy and physician trust
in automated predictions.

</details>


### [358] [Vision Transformers for Multi-Variable Climate Downscaling: Emulating Regional Climate Models with a Shared Encoder and Multi-Decoder Architecture](https://arxiv.org/abs/2506.22447)
*Fabio Merizzi,Harilaos Loukos*

Main category: cs.LG

TL;DR: 这篇论文引入了一种多任务、多变量的Vision Transformer架构，用于模拟和预测关键气候变量，从而改进传统的区域气候建模方法。


<details>
  <summary>Details</summary>
Motivation: 现有气候模型难以在区域尺度上进行精确建模，且现有深度学习方法通常只处理单变量，缺乏上下文联动和计算效率。

Method: 提出了一种共享编码器和特定解码器的多任务、多变量Vision Transformer架构，用于联合预测三个气候变量。

Result: 与单变量基线相比，提出的方法实现了正向的跨变量知识迁移，提升了预测精度，并提高了计算效率。

Conclusion: 多变量建模在高分辨率气候下采样中具有显著优势，验证了该方法的有效性。

Abstract: Global Climate Models (GCMs) are critical for simulating large-scale climate
dynamics, but their coarse spatial resolution limits their applicability in
regional studies. Regional Climate Models (RCMs) refine this through dynamic
downscaling, albeit at considerable computational cost and with limited
flexibility. While deep learning has emerged as an efficient data-driven
alternative, most existing studies have focused on single-variable models that
downscale one variable at a time. This approach can lead to limited contextual
awareness, redundant computation, and lack of cross-variable interaction. Our
study addresses these limitations by proposing a multi-task, multi-variable
Vision Transformer (ViT) architecture with a shared encoder and
variable-specific decoders (1EMD). The proposed architecture jointly predicts
three key climate variables: surface temperature (tas), wind speed (sfcWind),
and 500 hPa geopotential height (zg500), directly from GCM-resolution inputs,
emulating RCM-scale downscaling over Europe. We show that our multi-variable
approach achieves positive cross-variable knowledge transfer and consistently
outperforms single-variable baselines trained under identical conditions, while
also improving computational efficiency. These results demonstrate the
effectiveness of multi-variable modeling for high-resolution climate
downscaling.

</details>


### [359] [Stabilization of industrial processes with time series machine learning](https://arxiv.org/abs/2506.22502)
*Matvei Anoshin,Olga Tsurkan,Vadim Lopatkin,Leonid Fedichkin*

Main category: cs.LG

TL;DR: 提出了一种简单的机器学习流程，用于改善时间序列过程的稳定性，特别是在温度控制方面表现优越。


<details>
  <summary>Details</summary>
Motivation: 解决时间序列过程在工业领域中的广泛应用中所涉及的稳定性问题，利用机器学习提升稳定性和减少计算资源需求。

Method: 设计了由两个神经网络组成的流程，包括预测网络（oracle predictor）和优化器，替代传统逐点值优化，将问题转化为神经网络训练问题。

Result: 在温度控制的稳定性方面，相较于普通解算器，提出的方法提升了约3倍的稳定性。

Conclusion: 所设计的机器学习流程成功实现了提高时间序列过程稳定性的目标，同时在计算资源需求上表现出色。

Abstract: The stabilization of time series processes is a crucial problem that is
ubiquitous in various industrial fields. The application of machine learning to
its solution can have a decisive impact, improving both the quality of the
resulting stabilization with less computational resources required. In this
work, we present a simple pipeline consisting of two neural networks: the
oracle predictor and the optimizer, proposing a substitution of the point-wise
values optimization to the problem of the neural network training, which
successfully improves stability in terms of the temperature control by about 3
times compared to ordinary solvers.

</details>


### [360] [Task-Agnostic Contrastive Pretraining for Relational Deep Learning](https://arxiv.org/abs/2506.22530)
*Jakub Peleška,Gustav Šír*

Main category: cs.LG

TL;DR: 该研究提出了一种新的任务无关对比预训练方法，用于从关系数据库中学习表征，并验证其在基准测试中的性能优越性。


<details>
  <summary>Details</summary>
Motivation: 当前的关系深度学习（RDL）模型依赖任务特定的监督学习，这限制了其扩展性和重用性。为了解决这一问题，该研究旨在开发一种任务无关的数据库表征学习方法。

Method: 提出了一种基于对比预训练的方法，通过定义三种对比目标（行级、链接级和上下文级）来捕捉关系数据的结构和语义异质性，并结合模块化的RDL架构与高效的采样策略。

Result: 在标准RDL基准测试上，预训练后的模型微调性能显著优于从零开始训练的模型。

Conclusion: 证明了所提出的方法能够有效学习关系数据的可转移表征，为关系深度学习的未来应用提供了新的方向。

Abstract: Relational Deep Learning (RDL) is an emerging paradigm that leverages Graph
Neural Network principles to learn directly from relational databases by
representing them as heterogeneous graphs. However, existing RDL models
typically rely on task-specific supervised learning, requiring training
separate models for each predictive task, which may hamper scalability and
reuse.
  In this work, we propose a novel task-agnostic contrastive pretraining
approach for RDL that enables database-wide representation learning. For that
aim, we introduce three levels of contrastive objectives$-$row-level,
link-level, and context-level$-$designed to capture the structural and semantic
heterogeneity inherent to relational data. We implement the respective
pretraining approach through a modular RDL architecture and an efficient
sampling strategy tailored to the heterogeneous database setting. Our
preliminary results on standard RDL benchmarks demonstrate that fine-tuning the
pretrained models measurably outperforms training from scratch, validating the
promise of the proposed methodology in learning transferable representations
for relational data.

</details>


### [361] [Exploration Behavior of Untrained Policies](https://arxiv.org/abs/2506.22566)
*Jacob Adamczyk*

Main category: cs.LG

TL;DR: 研究了深度神经策略架构在训练前如何影响强化学习的探索行为，明确了非训练策略下生成轨迹的策略和状态分布的关系。


<details>
  <summary>Details</summary>
Motivation: 在稀疏或对抗性奖励环境的强化学习中，探索是一个基础性挑战。

Method: 结合理论和实验，利用无穷宽网络理论和连续时间极限分析未训练策略，揭示动作的相关性及状态访问分布。

Result: 发现未训练策略初始的动作选择具有相关性，导致产生特定形式的轨迹分布，深入分析常见架构的初始分布及探索偏置。

Conclusion: 提供了用策略初始化作为设计工具来理解早期探索行为的理论和实验框架。

Abstract: Exploration remains a fundamental challenge in reinforcement learning (RL),
particularly in environments with sparse or adversarial reward structures. In
this work, we study how the architecture of deep neural policies implicitly
shapes exploration before training. We theoretically and empirically
demonstrate strategies for generating ballistic or diffusive trajectories from
untrained policies in a toy model. Using the theory of infinite-width networks
and a continuous-time limit, we show that untrained policies return correlated
actions and result in non-trivial state-visitation distributions. We discuss
the distributions of the corresponding trajectories for a standard
architecture, revealing insights into inductive biases for tackling
exploration. Our results establish a theoretical and experimental framework for
using policy initialization as a design tool to understand exploration behavior
in early training.

</details>


### [362] [The Hidden Link Between RLHF and Contrastive Learning](https://arxiv.org/abs/2506.22578)
*Xufei Lv,Haoyuan Sun,Xuefeng Bai,Min Zhang,Houde Liu,Kehai Chen*

Main category: cs.LG

TL;DR: 这篇论文探讨了将大语言模型的对齐问题与互信息最大化联系起来，并提出了一种新的优化方法MIO，能够克服现有方法的一些缺陷。


<details>
  <summary>Details</summary>
Motivation: 目前主流方法如RLHF和DPO存在高成本或效果受限的问题，作者希望找到一种更有效的方法来提升模型的推理能力。

Method: 作者以互信息（MI）最大化为框架，提出用对比学习解释RLHF和DPO，并在此基础上引入了Jensen-Shannon MI估计器，设计了一种新的优化方法MIO。

Result: 论文通过理论与实验验证发现，MIO能够减轻DPO中选择似然下降的问题，并在多个挑战性推理和数学基准测试中表现优异。

Conclusion: MIO是一种有效的改进方法，与现有对齐方法相比能够表现出竞争力甚至更优的结果，且系统将在接受后开源。

Abstract: Alignment of large language models (LLMs) with human values has recently
garnered significant attention, with prominent examples including the canonical
yet costly Reinforcement Learning from Human Feedback (RLHF) and the simple
Direct Preference Optimization (DPO). In this work, we demonstrate that both
RLHF and DPO can be interpreted from the perspective of mutual information (MI)
maximization, uncovering a profound connection to contrastive learning. Within
this framework, both RLHF and DPO can be viewed as methods that perform
contrastive learning based on the positive and negative samples derived from
the base model, leveraging the Donsker-Varadhan (DV) lower bound on MI
(equivalently, the MINE estimator). This paradigm further explains why RLHF may
not intrinsically incentivize reasoning capacities in LLMs beyond what is
already present in the base model. Building on this perspective, we replace the
DV/MINE bound with the Jensen-Shannon MI estimator and propose Mutual
Information Optimization (MIO). Comprehensive theoretical analysis and
extensive empirical evaluations demonstrate that MIO mitigates the late-stage
decline in chosen-likelihood observed in DPO, achieving competitive or superior
performance across various challenging reasoning and mathematical benchmarks.
We will release the model and code upon acceptance.

</details>


### [363] [Are Fast Methods Stable in Adversarially Robust Transfer Learning?](https://arxiv.org/abs/2506.22602)
*Joshua C. Zhao,Saurabh Bagchi*

Main category: cs.LG

TL;DR: 本文探讨在迁移学习中利用快速梯度符号法（FGSM）进行对抗性微调，以提高对抗性微调的计算效率，同时保持稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 对抗性训练从头开始计算成本高，研究希望通过迁移学习减少计算成本，并探索在微调阶段使用FGSM提高效率。

Method: 通过FGSM进行对抗性微调，与PGD方法比较，评估在多个数据集上的稳定性和表现，同时探索参数高效的微调方法的效果。

Result: FGSM在迁移学习的对抗性微调中表现出稳定性和良好性能，与PGD方法相比平均在高效性和结果上损失较小，并显著降低了计算时间。

Conclusion: FGSM为对抗性迁移学习提供了一个高效且性能良好的替代方案，特别是在参数高效的情况下表现更加突出。

Abstract: Transfer learning is often used to decrease the computational cost of model
training, as fine-tuning a model allows a downstream task to leverage the
features learned from the pre-training dataset and quickly adapt them to a new
task. This is particularly useful for achieving adversarial robustness, as
adversarially training models from scratch is very computationally expensive.
However, high robustness in transfer learning still requires adversarial
training during the fine-tuning phase, which requires up to an order of
magnitude more time than standard fine-tuning. In this work, we revisit the use
of the fast gradient sign method (FGSM) in robust transfer learning to improve
the computational cost of adversarial fine-tuning. We surprisingly find that
FGSM is much more stable in adversarial fine-tuning than when training from
scratch. In particular, FGSM fine-tuning does not suffer from any issues with
catastrophic overfitting at standard perturbation budgets of $\varepsilon=4$ or
$\varepsilon=8$. This stability is further enhanced with parameter-efficient
fine-tuning methods, where FGSM remains stable even up to $\varepsilon=32$ for
linear probing. We demonstrate how this stability translates into performance
across multiple datasets. Compared to fine-tuning with the more commonly used
method of projected gradient descent (PGD), on average, FGSM only loses 0.39%
and 1.39% test robustness for $\varepsilon=4$ and $\varepsilon=8$ while using
$4\times$ less training time. Surprisingly, FGSM may not only be a
significantly more efficient alternative to PGD in adversarially robust
transfer learning but also a well-performing one.

</details>


### [364] [Hierarchical Modeling and Architecture Optimization: Review and Unified Framework](https://arxiv.org/abs/2506.22621)
*Paul Saves,Edward Hallé-Hannan,Jasper Bussemaker,Youssef Diouane,Nathalie Bartoli*

Main category: cs.LG

TL;DR: 本文致力于解决混合变量输入模拟问题，提出了一种通用框架来建模和优化复杂系统的分层、条件和异构结构，并通过工具与实际案例展示其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前许多模拟问题面临分层、条件以及异构结构的建模和优化挑战，现有方法难以系统化处理这些复杂特性。

Method: 提出了一种统一框架，通过设计空间图结合特征建模与图论方法，构建复杂体系架构，并引入新的代理模型及分层核距离实现高效建模与优化，并在开源工具SMT 2.0中实现。

Result: 展示了其方法在复杂系统设计（如绿色飞机设计领域）中的应用及其高效性，尤其在贝叶斯优化中的表现。

Conclusion: 该框架通过引入设计空间图和增强的代理建模能力，为复杂分层领域问题提供了新的解决方案，在实际案例中表现优异。

Abstract: Simulation-based problems involving mixed-variable inputs frequently feature
domains that are hierarchical, conditional, heterogeneous, or tree-structured.
These characteristics pose challenges for data representation, modeling, and
optimization. This paper reviews extensive literature on these structured input
spaces and proposes a unified framework that generalizes existing approaches.
In this framework, input variables may be continuous, integer, or categorical.
A variable is described as meta if its value governs the presence of other
decreed variables, enabling the modeling of conditional and hierarchical
structures.
  We further introduce the concept of partially-decreed variables, whose
activation depends on contextual conditions. To capture these inter-variable
hierarchical relationships, we introduce design space graphs, combining
principles from feature modeling and graph theory. This allows the definition
of general hierarchical domains suitable for describing complex system
architectures. The framework supports the use of surrogate models over such
domains and integrates hierarchical kernels and distances for efficient
modeling and optimization. The proposed methods are implemented in the
open-source Surrogate Modeling Toolbox (SMT 2.0), and their capabilities are
demonstrated through applications in Bayesian optimization for complex system
design, including a case study in green aircraft architecture.

</details>


### [365] [A hierarchical Vovk-Azoury-Warmuth forecaster with discounting for online regression in RKHS](https://arxiv.org/abs/2506.22631)
*Dmitry B. Rokhlin*

Main category: cs.LG

TL;DR: 本文研究了基于再生核希尔伯特空间（RKHS）的在线回归问题，提出了一种名为H-VAW-D的完全自适应分层算法，其在计算复杂度和动态遗憾方面达到了较优的结果。


<details>
  <summary>Details</summary>
Motivation: 旨在将已有的有限维动态遗憾优化方法推广至更广泛的非参数域，通过随机特征逼近解决动态函数序列学习问题。

Method: 结合折现的Vovk-Azoury-Warmuth (DVAW)框架与随机特征逼近，提出了H-VAW-D算法，该算法同时优化折现因子与随机特征数量。

Result: 提出的H-VAW-D算法具有每次迭代$O(T\ln T)$的计算复杂度，可实现$O(T^{2/3}P_T^{1/3} + \sqrt{T}\ln T)$的动态遗憾，其中$P_T$为比较器序列的函数路径长度。

Conclusion: H-VAW-D算法在非参数域中有效且高效地解决了在线回归问题，展示了折现动态优化方法的潜力。

Abstract: We study the problem of online regression with the unconstrained quadratic
loss against a time-varying sequence of functions from a Reproducing Kernel
Hilbert Space (RKHS). Recently, Jacobsen and Cutkosky (2024) introduced a
discounted Vovk-Azoury-Warmuth (DVAW) forecaster that achieves optimal dynamic
regret in the finite-dimensional case. In this work, we lift their approach to
the non-parametric domain by synthesizing the DVAW framework with a random
feature approximation. We propose a fully adaptive, hierarchical algorithm,
which we call H-VAW-D (Hierarchical Vovk-Azoury-Warmuth with Discounting), that
learns both the discount factor and the number of random features. We prove
that this algorithm, which has a per-iteration computational complexity of
$O(T\ln T)$, achieves an expected dynamic regret of $O(T^{2/3}P_T^{1/3} +
\sqrt{T}\ln T)$, where $P_T$ is the functional path length of a comparator
sequence.

</details>


### [366] [Layer Importance for Mathematical Reasoning is Forged in Pre-Training and Invariant after Post-Training](https://arxiv.org/abs/2506.22638)
*Aadim Nepal,Safal Shrestha,Anubhav Shrestha,Minwu Kim,Keith Ross*

Main category: cs.LG

TL;DR: 研究分析大型语言模型在数学推理能力上的提升原理特别关注模型层级的重要结构。研究发现数学推理任务存在特定关键层，其影响显著，表现为移除这些层可能导致准确性降低多达80%。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了解大型语言模型通过指令调优、强化学习或知识蒸馏后数学推理能力提升的原因，特别是这些提升是否源自粗粒度的结构变化或是局部层级调整。

Method: 通过系统性分层消融实验，研究了基本模型及其不同训练变体（指令调优、知识蒸馏和强化学习模型）在数学推理基准测试中的表现。

Result: 数学推理任务产生了特定层级的重要性结构，该结构在所有后训练范式中保持一致并发挥关键作用；非数学任务如事实记忆则不存在关键层。

Conclusion: 数学推理任务需要在预训练中形成的特定专业化层，而非推理任务对层的需求没有如此显著，同时关键层也是信息表示转换显著发生的地方。

Abstract: Large language models can exhibit improved mathematical reasoning
capabilities following post-training with instruction tuning, reinforcement
learning, or knowledge distillation. However, it remains unclear whether these
improvements are driven by major changes in transformer layers or from minor
adjustments that leave the relative layer importance structures of the base
model largely unchanged. We investigate this question through systematic
layer-wise ablation experiments, examining base, instruction-tuned,
knowledge-distilled, and reinforcement learning variants on mathematical
reasoning benchmarks. Our findings show that mathematical reasoning gives rise
to a specific layer importance structure, and this structure persists across
all post-training paradigms. Removal of such layers causes accuracy drops of up
to 80%. In contrast, non-mathematical tasks like factual recall exhibit no
critical layers. This distinction suggests that mathematical reasoning requires
specialized layers that emerge during pre-training, while other non-reasoning
tasks do not. From an information-theoretic perspective, we also observe that
these critical layers are the same layers where major representational
transformation occurs.

</details>


### [367] [Cost-effective Reduced-Order Modeling via Bayesian Active Learning](https://arxiv.org/abs/2506.22645)
*Amir Hossein Rahmati,Nathan M. Urban,Byung-Jun Yoon,Xiaoning Qian*

Main category: cs.LG

TL;DR: 提出了一种基于不确定性感知的贝叶斯正交分解（BayPOD-AL）的主动学习框架，用于降低高保真模型数据所需的计算资源。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习代理需依赖大规模训练数据集，限制其在实际应用中的可行性，急需一种高效学习复杂系统低阶模型的方法。

Method: 开发了一个称为BayPOD-AL的框架，通过基于不确定性感知的贝叶斯正交分解方法，选取关键信息数据点以构建低阶模型。

Result: 实验表明，在预测杆的温度演化时，与其他不确定性驱动的主动学习方法相比，BayPOD-AL能更有效地提供信息化数据并降低数据集构建的计算成本。此外，它在更高时间分辨率数据集上的表现也验证了其可推广性和效率。

Conclusion: BayPOD-AL通过有效利用主动学习和不确定性建模，能够减少训练数据需求并提高复杂系统模拟中的计算效率，具有广泛应用前景。

Abstract: Machine Learning surrogates have been developed to accelerate solving systems
dynamics of complex processes in different science and engineering
applications. To faithfully capture governing systems dynamics, these methods
rely on large training datasets, hence restricting their applicability in
real-world problems. In this work, we propose BayPOD-AL, an active learning
framework based on an uncertainty-aware Bayesian proper orthogonal
decomposition (POD) approach, which aims to effectively learn reduced-order
models from high-fidelity full-order models representing complex systems.
Experimental results on predicting the temperature evolution over a rod
demonstrate BayPOD-AL's effectiveness in suggesting the informative data and
reducing computational cost related to constructing a training dataset compared
to other uncertainty-guided active learning strategies. Furthermore, we
demonstrate BayPOD-AL's generalizability and efficiency by evaluating its
performance on a dataset of higher temporal resolution than the training
dataset.

</details>


### [368] [Learning Stochastic Multiscale Models](https://arxiv.org/abs/2506.22655)
*Andrew F. Ilersich,Prasanth B. Nair*

Main category: cs.LG

TL;DR: 提出了一种基于观测数据学习随机多尺度模型的新方法，克服了直接数值模拟的计算挑战。


<details>
  <summary>Details</summary>
Motivation: 解决物理领域动态系统中多尺度的计算难题，尤其是高维状态空间的模拟问题。

Method: 采用一种现代的免前向求解器的变分推断方法，直接从观测数据学习随机微分方程形式的多尺度模型。

Result: 所学得的多尺度模型在预测精度上优于等分辨率的直接数值模拟和闭合类型模型。

Conclusion: 通过结合物理基础的多尺度建模方法和机器学习，提出了一种高效的多尺度建模方法，适用于处理复杂物理系统。

Abstract: The physical sciences are replete with dynamical systems that require the
resolution of a wide range of length and time scales. This presents significant
computational challenges since direct numerical simulation requires
discretization at the finest relevant scales, leading to a high-dimensional
state space. In this work, we propose an approach to learn stochastic
multiscale models in the form of stochastic differential equations directly
from observational data. Our method resolves the state on a coarse mesh while
introducing an auxiliary state to capture the effects of unresolved scales. We
learn the parameters of the multiscale model using a modern forward-solver-free
amortized variational inference method. Our approach draws inspiration from
physics-based multiscale modeling approaches, such as large-eddy simulation in
fluid dynamics, while learning directly from data. We present numerical studies
to demonstrate that our learned multiscale models achieve superior predictive
accuracy compared to direct numerical simulation and closure-type models at
equivalent resolution.

</details>


### [369] [DistShap: Scalable GNN Explanations with Distributed Shapley Values](https://arxiv.org/abs/2506.22668)
*Selahattin Akkas,Aditya Devarakonda,Ariful Azad*

Main category: cs.LG

TL;DR: 论文提出DistShap，一个可以并行分布实现Shapley值解释的算法，用于提升图神经网络(GNN)的解释效率与扩展性。


<details>
  <summary>Details</summary>
Motivation: 近年来随着图神经网络（GNN）的普及，解释GNN预测的重要性日益提升；但为特定边或特征归因仍然计算成本高昂。

Method: 论文提出DistShap算法，通过在多GPU环境中分布式进行子图采样和并行推理，并求解分布式最小二乘问题，从而计算边的重要性分数。

Result: DistShap在精度上优于现有大多数GNN解释方法，并且首次在高达百万特征的GNN模型上可扩展运行，使用了多达128个GPU。

Conclusion: DistShap不仅提升了解释效率，还解决了现有方法在处理大规模GNN模型上的扩展性问题，为GNN的应用与解释开辟了新的可能性。

Abstract: With the growing adoption of graph neural networks (GNNs), explaining their
predictions has become increasingly important. However, attributing predictions
to specific edges or features remains computationally expensive. For example,
classifying a node with 100 neighbors using a 3-layer GNN may involve
identifying important edges from millions of candidates contributing to the
prediction. To address this challenge, we propose DistShap, a parallel
algorithm that distributes Shapley value-based explanations across multiple
GPUs. DistShap operates by sampling subgraphs in a distributed setting,
executing GNN inference in parallel across GPUs, and solving a distributed
least squares problem to compute edge importance scores. DistShap outperforms
most existing GNN explanation methods in accuracy and is the first to scale to
GNN models with millions of features by using up to 128 GPUs on the NERSC
Perlmutter supercomputer.

</details>


### [370] [Mitigating Semantic Collapse in Generative Personalization with a Surprisingly Simple Test-Time Embedding Adjustment](https://arxiv.org/abs/2506.22685)
*Anh Bui,Trang Vu,Trung Le,Junae Kim,Tamas Abraham,Rollin Omari,Amar Kaur,Dinh Phung*

Main category: cs.LG

TL;DR: 本文探讨生成个性化中的语义崩塌问题，并提出了一种训练无关的方法，通过在推理阶段调整预训练嵌入的幅度与方向，有效缓解语义崩塌问题，在多种场景中显著改善文本-图像的匹配度。


<details>
  <summary>Details</summary>
Motivation: 在生成个性化中，学习到的视觉概念（$V^*$）语义出现漂移，导致输入的多概念提示词的语义丰富性下降，最终生成的输出图像无法体现预期概念。

Method: 提出了一种简单但有效的训练无关方法，在推理阶段调整预训练嵌入的幅度与方向，从而控制优化过程中的嵌入漂移。

Result: 该方法在多种个性化方法中表现出广泛适用性，并在不同使用场景中显著改善了文本-图像的匹配效果。

Conclusion: 提出的无训练方法能够有效减缓语义崩塌问题，提升生成图像与输入文本提示的语义对齐度，具有广泛适用性。

Abstract: In this paper, we investigate the semantic collapsing problem in generative
personalization, an under-explored topic where the learned visual concept
($V^*$) gradually shifts from its original textual meaning and comes to
dominate other concepts in multi-concept input prompts. This issue not only
reduces the semantic richness of complex input prompts like "a photo of $V^*$
wearing glasses and playing guitar" into simpler, less contextually rich forms
such as "a photo of $V^*$" but also leads to simplified output images that fail
to capture the intended concept.
  We identify the root cause as unconstrained optimisation, which allows the
learned embedding $V^*$ to drift arbitrarily in the embedding space, both in
direction and magnitude. To address this, we propose a simple yet effective
training-free method that adjusts the magnitude and direction of pre-trained
embedding at inference time, effectively mitigating the semantic collapsing
problem. Our method is broadly applicable across different personalization
methods and demonstrates significant improvements in text-image alignment in
diverse use cases. Our code is anonymously published at
https://anonymous.4open.science/r/Embedding-Adjustment.

</details>


### [371] [Residual Matrix Transformers: Scaling the Size of the Residual Stream](https://arxiv.org/abs/2506.22696)
*Brian Mak,Jeffrey Flanigan*

Main category: cs.LG

TL;DR: 提出了一种名为Residual Matrix Transformer (RMT)的新模型，用外积记忆矩阵替代传统Transformer的残差流，改善了内存和计算效率。


<details>
  <summary>Details</summary>
Motivation: 探索替代Transformer中残差流的机制，通过引入外积记忆矩阵解决传统方法在效率上的不足。

Method: 将Transformer网络中的残差流替换为外积记忆矩阵，称之为RMT，并对比分析其与传统Transformer的性能。

Result: RMT在相同损失的情况下减少58%的FLOPS、25%的参数量和41%的训练样本；在下游任务评估中表现优于传统Transformer。

Conclusion: RMT通过改进残差流的扩展特性和方差传播性能，实现了更高的效率和更优的表现，展现了替代现有Transformer方法的潜力。

Abstract: The residual stream acts as a memory bus where transformer layers both store
and access features (Elhage et al., 2021). We consider changing the mechanism
for retrieving and storing information in the residual stream, and replace the
residual stream of the transformer with an outer product memory matrix
(Kohonen, 1972, Anderson, 1972). We call this model the Residual Matrix
Transformer (RMT). We find that the RMT enjoys a number of attractive
properties: 1) the size of the residual stream can be scaled independently of
compute and model size, improving performance, 2) the RMT can achieve the same
loss as the transformer with 58% fewer FLOPS, 25% fewer parameters, and 41%
fewer training tokens tokens, and 3) the RMT outperforms the transformer on
downstream evaluations. We theoretically analyze the transformer and the RMT,
and show that the RMT allows for more efficient scaling of the residual stream,
as well as improved variance propagation properties. Code for this project can
be found at https://github.com/bmac3/residual-matrix-transformer.

</details>


### [372] [FairMarket-RL: LLM-Guided Fairness Shaping for Multi-Agent Reinforcement Learning in Peer-to-Peer Markets](https://arxiv.org/abs/2506.22708)
*Shrenik Jadhav,Birva Sevak,Srijita Das,Akhtar Hussain,Wencong Su,Van-Hai Bui*

Main category: cs.LG

TL;DR: 本文提出了FairMarket-RL，一个结合大语言模型（LLMs）和强化学习（RL）的框架，用于提升点对点交易的公平。当中通过公平性指标与回报调整机制，达到高效的公平交易成果。


<details>
  <summary>Details</summary>
Motivation: 解决现有点对点交易系统在公平性保障上的不足，提出一个去中心化市场调节中更可靠和公平的方法。

Method: 结合大语言模型作为实时公平性评估工具，并通过强化学习的奖励调整机制促进公平交易。

Result: 通过公平指标优化后，买家需求满足超过90%，卖家公平得益增加，公平指标（FTB和FBS）均超0.80，显示了显著的公平性改进。

Conclusion: FairMarket-RL框架提升了去中心化市场中的公平性、透明性与可扩展性，为自治能源交易提供可行的、公平导向的解决策略。

Abstract: Peer-to-peer (P2P) trading is increasingly recognized as a key mechanism for
decentralized market regulation, yet existing approaches often lack robust
frameworks to ensure fairness. This paper presents FairMarket-RL, a novel
hybrid framework that combines Large Language Models (LLMs) with Reinforcement
Learning (RL) to enable fairness-aware trading agents. In a simulated P2P
microgrid with multiple sellers and buyers, the LLM acts as a real-time
fairness critic, evaluating each trading episode using two metrics:
Fairness-To-Buyer (FTB) and Fairness-Between-Sellers (FBS). These fairness
scores are integrated into agent rewards through scheduled
{\lambda}-coefficients, forming an adaptive LLM-guided reward shaping loop that
replaces brittle, rule-based fairness constraints. Agents are trained using
Independent Proximal Policy Optimization (IPPO) and achieve equitable outcomes,
fulfilling over 90% of buyer demand, maintaining fair seller margins, and
consistently reaching FTB and FBS scores above 0.80. The training process
demonstrates that fairness feedback improves convergence, reduces buyer
shortfalls, and narrows profit disparities between sellers. With its
language-based critic, the framework scales naturally, and its extension to a
large power distribution system with household prosumers illustrates its
practical applicability. FairMarket-RL thus offers a scalable, equity-driven
solution for autonomous trading in decentralized energy systems.

</details>


### [373] [Generalized Linear Mode Connectivity for Transformers](https://arxiv.org/abs/2506.22712)
*Alexander Theus,Alessandro Cabodi,Sotiris Anagnostidis,Antonio Orvieto,Sidak Pal Singh,Valentina Boeva*

Main category: cs.LG

TL;DR: 本文介绍了一种旨在揭示神经网络损失景观几何性质的统一框架，并展示了其在发现低损失路径上的应用。


<details>
  <summary>Details</summary>
Motivation: 神经网络的损失景观几何与泛化及优化密切相关，但由于参数空间中的对称性（如神经元置换），模型之间的关系被掩盖，因此需要一种方法揭示这些对称性。

Method: 提出了一个统一框架，捕捉四种对称性类别：置换、半置换、正交变换和广义可逆映射，涵盖了现有方法的特殊情况。

Result: 通过该框架首次发现了独立训练的视觉Transformer和GPT-2之间低损失的线性插值路径。

Conclusion: 研究结果显示了损失景观中的更深层次结构，再次强调了对称性分析对理解模型空间几何的重要性。

Abstract: Understanding the geometry of neural network loss landscapes is a central
question in deep learning, with implications for generalization and
optimization. A striking phenomenon is linear mode connectivity (LMC), where
independently trained models can be connected by low- or zero-loss paths,
despite appearing to lie in separate loss basins. However, this is often
obscured by symmetries in parameter space -- such as neuron permutations --
which make functionally equivalent models appear dissimilar. Prior work has
predominantly focused on neuron re-ordering through permutations, but such
approaches are limited in scope and fail to capture the richer symmetries
exhibited by modern architectures such as Transformers. In this work, we
introduce a unified framework that captures four symmetry classes:
permutations, semi-permutations, orthogonal transformations, and general
invertible maps -- broadening the set of valid reparameterizations and
subsuming many previous approaches as special cases. Crucially, this
generalization enables, for the first time, the discovery of low- and
zero-barrier linear interpolation paths between independently trained Vision
Transformers and GPT-2 models. These results reveal deeper structure in the
loss landscape and underscore the importance of symmetry-aware analysis for
understanding model space geometry.

</details>


### [374] [BEST-Route: Adaptive LLM Routing with Test-Time Optimal Compute](https://arxiv.org/abs/2506.22716)
*Dujian Ding,Ankur Mallick,Shaokun Zhang,Chi Wang,Daniel Madrigal,Mirian Del Carmen Hipolito Garcia,Menglin Xia,Laks V. S. Lakshmanan,Qingyun Wu,Victor Rühle*

Main category: cs.LG

TL;DR: 提出BEST-Route框架，通过动态分配查询至不同成本和质量的模型，且对小模型生成多次响应，减少了最多60%的成本，性能下降不到1%。


<details>
  <summary>Details</summary>
Motivation: 高效利用不同规模的语言模型，在成本和性能之间找到最佳权衡。

Method: 开发了BEST-Route，通过评估查询难度和质量阈值，根据所选模型生成相应数量的响应，以优化成本和性能。

Result: 与传统方法相比，BEST-Route在实际数据集上验证了减少成本高达60%，但性能仅下降不到1%。

Conclusion: BEST-Route通过结合小模型多次生成的响应和对大模型的有效利用，能够显著节省成本，同时保持较高性能。

Abstract: Large language models (LLMs) are powerful tools but are often expensive to
deploy at scale. LLM query routing mitigates this by dynamically assigning
queries to models of varying cost and quality to obtain a desired trade-off.
Prior query routing approaches generate only one response from the selected
model and a single response from a small (inexpensive) model was often not good
enough to beat a response from a large (expensive) model due to which they end
up overusing the large model and missing out on potential cost savings.
However, it is well known that for small models, generating multiple responses
and selecting the best can enhance quality while remaining cheaper than a
single large-model response. We leverage this idea to propose BEST-Route, a
novel routing framework that chooses a model and the number of responses to
sample from it based on query difficulty and the quality thresholds.
Experiments on real-world datasets demonstrate that our method reduces costs by
up to 60% with less than 1% performance drop.

</details>


### [375] [Robust Tensor Completion via Gradient Tensor Nulclear L1-L2 Norm for Traffic Data Recovery](https://arxiv.org/abs/2506.22732)
*Hao Shu,Jicheng Li,Tianyv Lei,Lijun Sun*

Main category: cs.LG

TL;DR: 本文提出了一种新型的鲁棒张量补全方法，通过新定义的梯度张量核L1-L2范数模型解决交通数据同时存在的丢失和噪声问题，实验表明该方法优于现有最先进技术。


<details>
  <summary>Details</summary>
Motivation: 传统张量补全方法无法有效处理噪声问题，现有鲁棒张量补全方法利用局部一致性有限，模型精度不足，无法充分解决交通数据的双重降级问题。

Method: 引入非凸张量秩代理——张量L1-L2范数，同时利用高级特征融合策略发展梯度张量L1-L2范数，通过将其集成到鲁棒张量补全框架中，提出RTC-GTNLN模型，无需权衡参数即可充分利用全局低秩性与局部一致性。

Result: 在多个真实世界交通数据集上的实验表明，RTC-GTNLN模型在处理同时丢失值和噪声的复杂恢复场景中性能优于现有方法。

Conclusion: RTC-GTNLN模型能够有效解决交通数据中的双重降级问题，为数据驱动应用的可靠性提供保证，在鲁棒张量补全领域具有重要意义。

Abstract: In real-world scenarios, spatiotemporal traffic data frequently experiences
dual degradation from missing values and noise caused by sensor malfunctions
and communication failures. Therefore, effective data recovery methods are
essential to ensure the reliability of downstream data-driven applications.
while classical tensor completion methods have been widely adopted, they are
incapable of modeling noise, making them unsuitable for complex scenarios
involving simultaneous data missingness and noise interference. Existing Robust
Tensor Completion (RTC) approaches offer potential solutions by separately
modeling the actual tensor data and noise. However, their effectiveness is
often constrained by the over-relaxation of convex rank surrogates and the
suboptimal utilization of local consistency, leading to inadequate model
accuracy. To address these limitations, we first introduce the tensor L1-L2
norm, a novel non-convex tensor rank surrogate that functions as an effective
low-rank representation tool. Leveraging an advanced feature fusion strategy,
we further develop the gradient tensor L1-L2 norm by incorporating the tensor
L1-L2 norm in the gradient domain. By integrating the gradient tensor nuclear
L1-L2 norm into the RTC framework, we propose the Robust Tensor Completion via
Gradient Tensor Nuclear L1-L2 Norm (RTC-GTNLN) model, which not only fully
exploits both global low-rankness and local consistency without trade-off
parameter, but also effectively handles the dual degradation challenges of
missing data and noise in traffic data. Extensive experiments conducted on
multiple real-world traffic datasets demonstrate that the RTC-GTNLN model
consistently outperforms existing state-of-the-art methods in complex recovery
scenarios involving simultaneous missing values and noise.

</details>


### [376] [Multimodal Atmospheric Super-Resolution With Deep Generative Models](https://arxiv.org/abs/2506.22780)
*Dibyajyoti Chakraborty,Haiwen Guan,Jason Stock,Troy Arcomano,Guido Cervone,Romit Maulik*

Main category: cs.LG

TL;DR: 本文探讨了基于分数的扩散模型在生成任务中的潜力，主要应用于高维动态系统的超分辨率问题，结合了多模态数据中的稀疏和实时观测。


<details>
  <summary>Details</summary>
Motivation: 研究目的是利用基于分数的扩散模型独特的条件生成能力，将观测数据与生成模型结合，实现高维动态系统的超分辨率重建。

Method: 采用基于分数的扩散建模，通过一个贝叶斯框架来更新预训练模型，并借助生成式扩散采样对低分辨率稀疏观测数据进行超分辨率生成。

Result: 实验在超分辨率任务中，通过融合ERA5大气数据集的稀疏观测与IGRA探空气球观测数据，成功重建了高维动态状态，并证明生成式模型在时空重建时可平衡不同数据模态的影响。

Conclusion: 基于分数的扩散建模可在多模态数据下实现高效的高维态的重建，同时提供了不确定性估计的潜力，展现了强大的多模态数据融合能力。

Abstract: Score-based diffusion modeling is a generative machine learning algorithm
that can be used to sample from complex distributions. They achieve this by
learning a score function, i.e., the gradient of the log-probability density of
the data, and reversing a noising process using the same. Once trained,
score-based diffusion models not only generate new samples but also enable
zero-shot conditioning of the generated samples on observed data. This promises
a novel paradigm for data and model fusion, wherein the implicitly learned
distributions of pretrained score-based diffusion models can be updated given
the availability of online data in a Bayesian formulation. In this article, we
apply such a concept to the super-resolution of a high-dimensional dynamical
system, given the real-time availability of low-resolution and experimentally
observed sparse sensor measurements from multimodal data. Additional analysis
on how score-based sampling can be used for uncertainty estimates is also
provided. Our experiments are performed for a super-resolution task that
generates the ERA5 atmospheric dataset given sparse observations from a
coarse-grained representation of the same and/or from unstructured experimental
observations of the IGRA radiosonde dataset. We demonstrate accurate recovery
of the high dimensional state given multiple sources of low-fidelity
measurements. We also discover that the generative model can balance the
influence of multiple dataset modalities during spatiotemporal reconstructions.

</details>


### [377] [Riemannian-Geometric Fingerprints of Generative Models](https://arxiv.org/abs/2506.22802)
*Hae Jin Song,Laurent Itti*

Main category: cs.LG

TL;DR: 提出了一种基于黎曼几何的新方法定义生成模型（GMs）的指纹和伪影，用于更好地定位模型和区分合成数据与人类数据。


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展使得对模型指纹和伪影的研究需求增加，用于保护知识产权、提高可信性以及解决模型坍塌和“反刍式训练”问题。但在现有框架中对模型指纹的定义和分析仍存在缺口。

Method: 引入了基于黎曼几何的定义，将欧氏距离和最近邻搜索替换为测地距离和基于kNN的黎曼质心，并提出一种新的梯度算法计算模型指纹。

Result: 通过对4个不同数据集、27种模型架构、2种分辨率和2种模态的测试，所提出方法显著提升了模型归属性能，并表现出良好的通用性和实际效果。

Conclusion: 新方法为生成模型指纹的定义和分析提供了理论支持，并在跨模态、跨数据集和跨模型类型上展现出了优异的归属和泛化能力。

Abstract: Recent breakthroughs and rapid integration of generative models (GMs) have
sparked interest in the problem of model attribution and their fingerprints.
For instance, service providers need reliable methods of authenticating their
models to protect their IP, while users and law enforcement seek to verify the
source of generated content for accountability and trust. In addition, a
growing threat of model collapse is arising, as more model-generated data are
being fed back into sources (e.g., YouTube) that are often harvested for
training ("regurgitative training"), heightening the need to differentiate
synthetic from human data. Yet, a gap still exists in understanding generative
models' fingerprints, we believe, stemming from the lack of a formal framework
that can define, represent, and analyze the fingerprints in a principled way.
To address this gap, we take a geometric approach and propose a new definition
of artifact and fingerprint of GMs using Riemannian geometry, which allows us
to leverage the rich theory of differential geometry. Our new definition
generalizes previous work (Song et al., 2024) to non-Euclidean manifolds by
learning Riemannian metrics from data and replacing the Euclidean distances and
nearest-neighbor search with geodesic distances and kNN-based Riemannian center
of mass. We apply our theory to a new gradient-based algorithm for computing
the fingerprints in practice. Results show that it is more effective in
distinguishing a large array of GMs, spanning across 4 different datasets in 2
different resolutions (64 by 64, 256 by 256), 27 model architectures, and 2
modalities (Vision, Vision-Language). Using our proposed definition
significantly improves the performance on model attribution, as well as a
generalization to unseen datasets, model types, and modalities, suggesting its
practical efficacy.

</details>


### [378] [BayesLoRA: Task-Specific Uncertainty in Low-Rank Adapters](https://arxiv.org/abs/2506.22809)
*Cooper Doyle*

Main category: cs.LG

TL;DR: 本文提出了BayesLoRA，一种将MC-Dropout集成到低秩适配器中的任务特定不确定性量化框架。


<details>
  <summary>Details</summary>
Motivation: 现有的变压器不确定性量化方法较为通用，缺乏面向特定任务的能力；需要一种新方法为下游工作流提供更精确的不确定性分析。

Method: 设计BayesLoRA，将MC-Dropout与LoRA结合起来，为特定任务提供不确定性量化，允许代理依据不确定性调节行为。

Result: 数学和实验证明，LoRA适配器在微调分布之外会放大方差，提供可靠的置信估计。

Conclusion: 新方法能有效为代理决策提供置信估计，并在下游任务中表现出可靠性。

Abstract: We propose BayesLoRA, a task-specific uncertainty quantification framework
that integrates MC-Dropout into Low-Rank Adapters (LoRA). Unlike
general-purpose transformer uncertainty methods, BayesLoRA provides guardrails
tailored to downstream workflows, enabling agents to introspect and modulate
behavior under uncertainty. We demonstrate mathematically and empirically that
LoRA adapters exhibit amplified variance outside fine-tuning distributions,
yielding reliable confidence estimates for agentic decision-making.

</details>


### [379] [Deep learning 40 years of human migration](https://arxiv.org/abs/2506.22821)
*Thomas Gaskin,Guy J. Abel*

Main category: cs.LG

TL;DR: 本文介绍了一个涵盖230个国家和地区、从1990年至今的年度迁移流动和库存数据集，以及通过深度循环神经网络生成迁移估算的创新方法。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在填补全球迁移数据的空白，特别是通过提供高分辨率和全面的国家间迁移数据，为迁移路径、模式及趋势的研究奠定基础。

Method: 研究采用深度循环神经网络，利用地理、经济、文化、社会及政治领域的18个变量进行训练，结合不确定性分析，估算近43年的迁移流动数据。

Result: 模型实现了更高的时间分辨率，且在测试中显著优于传统方法。同时提供所有估算的置信区间，有助于发现需要加强数据收集的地区。

Conclusion: 提供的开源解决方案，包括训练数据、模型权重及代码，为未来的全球迁移研究提供了有力支持。

Abstract: We present a novel and detailed dataset on origin-destination annual
migration flows and stocks between 230 countries and regions, spanning the
period from 1990 to the present. Our flow estimates are further disaggregated
by country of birth, providing a comprehensive picture of migration over the
last 43 years. The estimates are obtained by training a deep recurrent neural
network to learn flow patterns from 18 covariates for all countries, including
geographic, economic, cultural, societal, and political information. The
recurrent architecture of the neural network means that the entire past can
influence current migration patterns, allowing us to learn long-range temporal
correlations. By training an ensemble of neural networks and additionally
pushing uncertainty on the covariates through the trained network, we obtain
confidence bounds for all our estimates, allowing researchers to pinpoint the
geographic regions most in need of additional data collection. We validate our
approach on various test sets of unseen data, demonstrating that it
significantly outperforms traditional methods estimating five-year flows while
delivering a significant increase in temporal resolution. The model is fully
open source: all training data, neural network weights, and training code are
made public alongside the migration estimates, providing a valuable resource
for future studies of human migration.

</details>


### [380] [xLSTMAD: A Powerful xLSTM-based Method for Anomaly Detection](https://arxiv.org/abs/2506.22837)
*Kamil Faber,Marcin Pietroń,Dominik Żurek,Roberto Corizzo*

Main category: cs.LG

TL;DR: 本文提出了xLSTMAD，首次将xLSTM应用于异常检测，展示了其在多变量时间序列数据上的优越性能，并超过23种流行基线方法。


<details>
  <summary>Details</summary>
Motivation: 填补xLSTM在异常检测领域应用的空白，探索其在多变量时间序列数据上的潜力。

Method: 提出了xLSTMAD模型，包括两种变体——基于预测的xLSTMAD-F和基于重构的xLSTMAD-R，分别采用MSE和SoftDTW损失函数进行性能优化。

Result: 通过在涵盖17个实际数据集的TSB-AD-M基准上评估，xLSTMAD在包括VUS-PR等挑战性指标上展示出最先进的准确性表现，超越了23种流行算法。

Conclusion: xLSTMAD首次证明了xLSTM在异常检测领域的强大建模能力，为相关领域的研究发展开辟了新方向。

Abstract: The recently proposed xLSTM is a powerful model that leverages expressive
multiplicative gating and residual connections, providing the temporal capacity
needed for long-horizon forecasting and representation learning. This
architecture has demonstrated success in time series forecasting, lossless
compression, and even large-scale language modeling tasks, where its linear
memory footprint and fast inference make it a viable alternative to
Transformers. Despite its growing popularity, no prior work has explored xLSTM
for anomaly detection. In this work, we fill this gap by proposing xLSTMAD, the
first anomaly detection method that integrates a full encoder-decoder xLSTM
architecture, purpose-built for multivariate time series data. Our encoder
processes input sequences to capture historical context, while the decoder is
devised in two separate variants of the method. In the forecasting approach,
the decoder iteratively generates forecasted future values xLSTMAD-F, while the
reconstruction approach reconstructs the input time series from its encoded
counterpart xLSTMAD-R. We investigate the performance of two loss functions:
Mean Squared Error (MSE), and Soft Dynamic Time Warping (SoftDTW) to consider
local reconstruction fidelity and global sequence alignment, respectively. We
evaluate our method on the comprehensive TSB-AD-M benchmark, which spans 17
real-world datasets, using state-of-the-art challenging metrics such as VUS-PR.
In our results, xLSTM showcases state-of-the-art accuracy, outperforming 23
popular anomaly detection baselines. Our paper is the first work revealing the
powerful modeling capabilities of xLSTM for anomaly detection, paving the way
for exciting new developments on this subject. Our code is available at:
https://github.com/Nyderx/xlstmad

</details>


### [381] [Quantum Neural Networks for Wind Energy Forecasting: A Comparative Study of Performance and Scalability with Classical Models](https://arxiv.org/abs/2506.22845)
*Batuhan Hangun,Oguz Altun,Onder Eyecioglu*

Main category: cs.LG

TL;DR: 本文探讨量子神经网络（QNNs）在风力发电机功率输出预测中的应用，证明其预测性能在某些情况下优于经典方法，并分析了数据集大小和电路复杂度对性能及模拟时间的影响。


<details>
  <summary>Details</summary>
Motivation: 随着智能电网和可再生能源系统的整合，预测电力需求和检测系统干扰变得尤为重要，研究旨在探讨QNNs作为经典机器学习方法的替代方案的潜力。

Method: 本研究采用基于Z特征映射的数据编码和不同的ansatz结构的六种QNN配置，通过详细的交叉验证和对未见数据集的测试来评估其预测性能与模拟时间。

Result: QNNs在预测性能方面可以与经典方法竞争，在某些情况下甚至略胜一筹，同时揭示了数据集大小与电路复杂度对预测性能和模拟时间的影响。

Conclusion: 研究表明QNNs在能源领域，特别是风力发电预测任务中具有应用潜力，为未来将量子机器学习融入能源领域研究提供了引导。

Abstract: Quantum Neural Networks (QNNs), a prominent approach in Quantum Machine
Learning (QML), are emerging as a powerful alternative to classical machine
learning methods. Recent studies have focused on the applicability of QNNs to
various tasks, such as time-series forecasting, prediction, and classification,
across a wide range of applications, including cybersecurity and medical
imaging. With the increased use of smart grids driven by the integration of
renewable energy systems, machine learning plays an important role in
predicting power demand and detecting system disturbances. This study provides
an in-depth investigation of QNNs for predicting the power output of a wind
turbine. We assess the predictive performance and simulation time of six QNN
configurations that are based on the Z Feature Map for data encoding and
varying ansatz structures. Through detailed cross-validation experiments and
tests on an unseen hold-out dataset, we experimentally demonstrate that QNNs
can achieve predictive performance that is competitive with, and in some cases
marginally better than, the benchmarked classical approaches. Our results also
reveal the effects of dataset size and circuit complexity on predictive
performance and simulation time. We believe our findings will offer valuable
insights for researchers in the energy domain who wish to incorporate quantum
machine learning into their work.

</details>


### [382] [Scalable Structure Learning of Bayesian Networks by Learning Algorithm Ensembles](https://arxiv.org/abs/2506.22848)
*Shengcai Liu,Hui Ou-yang,Zhiyuan Wang,Cheng Chen,Qijun Cai,Yew-Soon Ong,Ke Tang*

Main category: cs.LG

TL;DR: 提出一种基于结构学习集成（SLE）的可扩展贝叶斯网络（BN）结构学习方法Auto-SLE，通过多算法集成显著提升大规模数据集的学习精度。


<details>
  <summary>Details</summary>
Motivation: 现有分而治之方法在大规模BN学习中的准确性不稳定，手动设计高质量结构学习集成（SLE）存在挑战。

Method: 引入多算法集成的结构学习集成（SLE）并设计自动化学习SLE的方法Auto-SLE，将其整合到分而治之框架中。

Result: 实验显示，与单一算法的分而治之方法相比，Auto-SLE在包含1万-3万变量的大规模数据集上提升准确性达30%-225%，且对不同网络特性表现出良好的泛化能力。

Conclusion: 通过自动化学习高质量SLE，本方法显著提升了大规模BN结构学习的可扩展性和稳定性，展示了SLE在此领域的重大潜力。

Abstract: Learning the structure of Bayesian networks (BNs) from data is challenging,
especially for datasets involving a large number of variables. The recently
proposed divide-and-conquer (D\&D) strategies present a promising approach for
learning large BNs. However, they still face a main issue of unstable learning
accuracy across subproblems. In this work, we introduce the idea of employing
structure learning ensemble (SLE), which combines multiple BN structure
learning algorithms, to consistently achieve high learning accuracy. We further
propose an automatic approach called Auto-SLE for learning near-optimal SLEs,
addressing the challenge of manually designing high-quality SLEs. The learned
SLE is then integrated into a D\&D method. Extensive experiments firmly show
the superiority of our method over D\&D methods with single BN structure
learning algorithm in learning large BNs, achieving accuracy improvement
usually by 30\%$\sim$225\% on datasets involving 10,000 variables. Furthermore,
our method generalizes well to datasets with many more (e.g., 30000) variables
and different network characteristics than those present in the training data
for learning the SLE. These results indicate the significant potential of
employing (automatic learning of) SLEs for scalable BN structure learning.

</details>


### [383] [P$^2$U: Progressive Precision Update For Efficient Model Distribution](https://arxiv.org/abs/2506.22871)
*Homayun Afrabandpey,Hamed Rezazadegan Tavakoli*

Main category: cs.LG

TL;DR: 提出了一个名为Progressive Precision Update (P$^2$U)的新方法，通过传输低精度模型及其更新差异来提高模型分发效率，同时降低带宽消耗和启动延迟，实验结果表明，该方法在性能和资源消耗间取得了较好平衡。


<details>
  <summary>Details</summary>
Motivation: 在带宽受限环境中高效分发模型是一个关键问题，当前方法在效率、准确性和资源消耗之间存在不足。

Method: 利用P$^2$U方法，传输低比特精度模型及原始高精度模型与低精度版本之间差异的更新，兼容现有压缩技术如剪枝、量化等。

Result: 在不同模型和数据集上的实验显示P$^2$U在准确性、带宽使用和延迟之间达到了更佳的平衡，尤其在带宽或启动时间有限的情况下表现更佳。

Conclusion: P$^2$U是一种适用于低资源场景中高效、可扩展模型分发的有效解决方案，可作为现有压缩方法的补充，通过进一步组合实现更高效的性能优化。

Abstract: Efficient model distribution is becoming increasingly critical in
bandwidth-constrained environments. In this paper, we propose a simple yet
effective approach called Progressive Precision Update (P$^2$U) to address this
problem. Instead of transmitting the original high-precision model, P$^2$U
transmits a lower-bit precision model, coupled with a model update representing
the difference between the original high-precision model and the transmitted
low precision version. With extensive experiments on various model
architectures, ranging from small models ($1 - 6$ million parameters) to a
large model (more than $100$ million parameters) and using three different data
sets, e.g., chest X-Ray, PASCAL-VOC, and CIFAR-100, we demonstrate that P$^2$U
consistently achieves better tradeoff between accuracy, bandwidth usage and
latency. Moreover, we show that when bandwidth or startup time is the priority,
aggressive quantization (e.g., 4-bit) can be used without severely compromising
performance. These results establish P$^2$U as an effective and practical
solution for scalable and efficient model distribution in low-resource
settings, including federated learning, edge computing, and IoT deployments.
Given that P$^2$U complements existing compression techniques and can be
implemented alongside any compression method, e.g., sparsification,
quantization, pruning, etc., the potential for improvement is even greater.

</details>


### [384] [Interpretable Time Series Autoregression for Periodicity Quantification](https://arxiv.org/abs/2506.22895)
*Xinyu Chen,Vassilis Digalakis Jr,Lijun Ding,Dingyi Zhuang,Jinhua Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种新的稀疏自回归框架，通过引入$\ell_0$-范数稀疏性约束，提高了模型的解释性，并针对时间变化和多维时间序列开发了快速优化方法。实验验证了模型在真实场景下的有效性和准确性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在从可解释机器学习视角出发，改进传统时间序列自回归模型，使其能够更好地量化周期性并适应复杂的时间变化和多维数据场景。

Method: 提出了基于$\ell_0$-范数的稀疏自回归框架，通过混合整数优化(MIO)求解时间变化模型，辅以决策变量修剪(DVP)策略以加速计算；针对高维度数据，设计了空间和时间可变的稀疏自回归模型，并采用两阶段优化方案提高可拓展性。

Result: 实验结果显示，DVP策略显著加速了MIO求解，同时保持了解的质量。实际应用中，模型揭示了共乘数据的周期性特征和气候变量的动态变化模式，如El Nino现象。

Conclusion: 该稀疏自回归模型在时间序列分析中展现了优异的性能，具有高解释性和灵活性，可广泛应用于交通、气候等领域。

Abstract: Time series autoregression is a classical statistical model for capturing
auto-correlations and identifying temporal patterns such as periodicity and
seasonality. In this work, we propose a novel sparse autoregression framework
from an interpretable machine learning perspective and the model
interpretability for periodicity quantification is reinforced by $\ell_0$-norm
induced sparsity constraints. On the time-varying time series data, we
reformulate the sparse autoregression and convert the involved optimization
problem into a mixed-integer optimization (MIO). To accelerate it, we develop a
subspace pursuit based decision variable pruning (DVP) strategy to reduce the
search space. On the multidimensional time series that involves complicated
spatial and temporal dimensions, we propose a spatially- and time-varying
sparse autoregression model and resolve the corresponding MIO problem by
developing a two-stage optimization scheme. In particular, the proposed scheme
makes the model scalable to large problems even with millions of decision
variables. Empirically, we conduct extensive experiments to evaluate the
proposed models on real-world time series data. First, we demonstrate that the
MIO solver can be drastically accelerated through the DVP strategy, while
maintaining the same solution quality as a full MIO solver. Applying the
time-varying sparse autoregression model to ridesharing trip data, we uncover
both daily and weekly periodicities and reveal long-term changes in regularity
of human mobility. Second, we demonstrate the spatial patterns of yearly
seasonality in climate variable time series such as temperature and
precipitation across the past four decades, and our model allows to discover
dynamic climate patterns and identify climate phenomena such as El Nino in sea
surface temperature.

</details>


### [385] [Missing-Modality-Aware Graph Neural Network for Cancer Classification](https://arxiv.org/abs/2506.22901)
*Sina Tabakhi,Haiping Lu*

Main category: cs.LG

TL;DR: 研究提出MAGNET，一种图神经网络模型，用于在多模态生物数据中处理缺失模态问题。与传统方法相比，在癌症分类任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决多模态生物数据中因患者模态缺失导致的信息融合困难的问题，尤其应对随着模态数增加而带来的模式多样性及复杂性。

Method: 提出MAGNET，采用患者-模态多头注意力机制以融合重要性及缺失信息，并通过构建患者图，实现基于缺失模态的节点表征与预测。

Result: 实验证明了MAGNET在使用真实世界的多组学癌症分类数据集时，优于最先进的模态融合方法。

Conclusion: MAGNET有效解决了模态缺失下的数据融合与预测问题，展现了在多模态生物数据中的潜力。

Abstract: A key challenge in learning from multimodal biological data is missing
modalities, where all data from some modalities are missing for some patients.
Current fusion methods address this by excluding patients with missing
modalities, imputing missing modalities, or making predictions directly with
partial modalities. However, they often struggle with diverse missing-modality
patterns and the exponential growth of the number of such patterns as the
number of modalities increases. To address these limitations, we propose MAGNET
(Missing-modality-Aware Graph neural NETwork) for direct prediction with
partial modalities, which introduces a patient-modality multi-head attention
mechanism to fuse lower-dimensional modality embeddings based on their
importance and missingness. MAGNET's complexity increases linearly with the
number of modalities while adapting to missing-pattern variability. To generate
predictions, MAGNET further constructs a patient graph with fused multimodal
embeddings as node features and the connectivity determined by the modality
missingness, followed by a conventional graph neural network. Experiments on
three public multiomics datasets for cancer classification, with real-world
instead of artificial missingness, show that MAGNET outperforms the
state-of-the-art fusion methods. The data and code are available at
https://github.com/SinaTabakhi/MAGNET.

</details>


### [386] [Towards Time Series Generation Conditioned on Unstructured Natural Language](https://arxiv.org/abs/2506.22927)
*Jaeyun Woo,Jiseok Lee,Brian Kenji Iwana*

Main category: cs.LG

TL;DR: 提出了一种利用自然语言生成时间序列的新方法，并通过构建新的数据集验证了效果。


<details>
  <summary>Details</summary>
Motivation: 现有生成式AI技术对时间序列生成的关注较少，而时间序列在诸如金融、气候等领域尤为重要，亟需发展。

Method: 将扩散模型和语言模型结合，用自然语言生成时间序列。同时构建了一个包括63,010个时间序列及对应描述的新数据集。

Result: 证明了基于自然语言生成时间序列的可行性，并展示了其在多种任务中的应用潜力。

Conclusion: 所提出方法扩展了生成式AI的应用范围，可广泛用于定制预测、时间序列操作、数据增强和迁移学习等，多领域具有重要意义。

Abstract: Generative Artificial Intelligence (AI) has rapidly become a powerful tool,
capable of generating various types of data, such as images and text. However,
despite the significant advancement of generative AI, time series generative AI
remains underdeveloped, even though the application of time series is essential
in finance, climate, and numerous fields. In this research, we propose a novel
method of generating time series conditioned on unstructured natural language
descriptions. We use a diffusion model combined with a language model to
generate time series from the text. Through the proposed method, we demonstrate
that time series generation based on natural language is possible. The proposed
method can provide various applications such as custom forecasting, time series
manipulation, data augmentation, and transfer learning. Furthermore, we
construct and propose a new public dataset for time series generation,
consisting of 63,010 time series-description pairs.

</details>


### [387] [Mathematical Computation on High-dimensional Data via Array Programming and Parallel Acceleration](https://arxiv.org/abs/2506.22929)
*Chen Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于空间完备性的并行计算框架，旨在解决高维数据中的计算挑战，并支持多数据类型的科学计算。


<details>
  <summary>Details</summary>
Motivation: 当前高维数据分析中存在计算复杂性问题，现有工具难以支持深入分析。需要一种新的框架来有效处理高维数据。

Method: 构建基于空间完备性的新型并行计算框架，利用维度独立结构实现分布式处理，并结合数据挖掘与并行优化的机器学习方法。

Result: 框架在统一系统中能支持包括医学图像和自然图像在内的多样化数据类型，优化了高维数据的处理能力。

Conclusion: 该架构能够极大地改善高维数据的分析能力，为科学计算提供更高效的解决方案。

Abstract: While deep learning excels in natural image and language processing, its
application to high-dimensional data faces computational challenges due to the
dimensionality curse. Current large-scale data tools focus on business-oriented
descriptive statistics, lacking mathematical statistics support for advanced
analysis. We propose a parallel computation architecture based on space
completeness, decomposing high-dimensional data into dimension-independent
structures for distributed processing. This framework enables seamless
integration of data mining and parallel-optimized machine learning methods,
supporting scientific computations across diverse data types like medical and
natural images within a unified system.

</details>


### [388] [Infinite Sampling: Efficient and Stable Grouped RL Training for Large Language Models](https://arxiv.org/abs/2506.22950)
*Liangyu Wang,Huanyi Xie,Xinhai Wang,Tianjin Huang,Mengdi Li,Di Wang*

Main category: cs.LG

TL;DR: 提出了一个名为Infinite Sampling的框架来优化群体奖励政策优化（GRPO）算法，解决了存储多样响应时的内存开销问题，提升了大规模语言模型的训练效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统GRPO算法在硬件有限条件下的内存和效率问题，便于大规模语言模型的可扩展性。

Method: 提出了Infinite Sampling框架，包括：（1）微采样分组（Micro Sampling Groups），将大组划分为内存可行的小轮次；（2）连续采样（Continuous Sampling），通过跨组交替生成提升利用率；（3）长度感知调度器，结合全局分组和运行时动态填充策略优化采样过程。

Result: 实验显示，Micro Sampling Groups相比传统的全组解码方法可减少50%以上的峰值内存使用，而基于此的Infinite Sampling相比直观微采样方法提升了25%以上的吞吐量，且在有限GPU内存下能实现稳定的长文本生成。

Conclusion: Infinite Sampling框架有效缓解了大组GRPO训练中的内存瓶颈，改善了采样过程效率和稳定性，为硬件受限环境中大规模语言模型的训练提供了解决方案。

Abstract: Group-based reinforcement learning algorithms such as Group Reward Policy
Optimization (GRPO) have proven effective for fine-tuning large language models
(LLMs) with human feedback. However, generating and storing multiple responses
per prompt incurs substantial memory overhead, especially as the sample group
size increases, limiting scalability under constrained hardware.
  We propose Infinite Sampling, a framework that enables efficient and stable
GRPO training by decoupling group size from GPU memory usage. It consists of:
(1) micro sampling groups that decompose large groups into memory-feasible
rounds; (2) continuous sampling that interleaves generation across groups to
improve utilization; and (3) a length-aware scheduler combining
token-conditioned sequence length prediction with a two-stage plan: global
grouping via FPTAS and runtime refill via SJF.
  Experiments show that our Micro Sampling Groups reduce peak memory usage by
over 50% compared to full-group decoding (e.g., from 21.55 GB to 10.64 GB on
Qwen3-1.7B). Building on this, Infinite Sampling improves throughput by over
25% compared to the naive micro sampling group method, reducing decoding steps
while maintaining full-length completions and memory usage. Our hybrid
scheduling ensures efficient and stable GRPO training with larger groups under
realistic GPU memory constraints.

</details>


### [389] [Cybersecurity-Focused Anomaly Detection in Connected Autonomous Vehicles Using Machine Learning](https://arxiv.org/abs/2506.22984)
*Prathyush Kumar Reddy Lebaku,Lu Gao,Yunpeng Zhang,Zhixia Li,Yongxin Liu,Tanvir Arafin*

Main category: cs.LG

TL;DR: 此研究提出基于机器学习的异常检测方法，用于识别联网自动驾驶汽车中异常驾驶模式，结果表明该方法具有很高的准确性和性能。


<details>
  <summary>Details</summary>
Motivation: 保障联网自动驾驶汽车在面对传感器故障、网络攻击及意外环境破坏时的运输安全与可靠性。

Method: 利用模拟的车辆行为生成时间序列数据集，结合堆叠LSTM模型捕捉时序依赖，以及随机森林模型进行集成预测以增加可解释性和性能。

Result: 随机森林模型和堆叠LSTM模型分别达到了优秀的R2值（0.9830和0.9998），显示了较低的平均绝对误差（5.746和82.425），并确定了各自的95%异常阈值。

Conclusion: 该方法有效预测了车辆轨迹并检测了自动驾驶场景中的异常，证明了模型的高效性及潜在应用价值。

Abstract: Anomaly detection in connected autonomous vehicles (CAVs) is crucial for
maintaining safe and reliable transportation networks, as CAVs can be
susceptible to sensor malfunctions, cyber-attacks, and unexpected environmental
disruptions. This study explores an anomaly detection approach by simulating
vehicle behavior, generating a dataset that represents typical and atypical
vehicular interactions. The dataset includes time-series data of position,
speed, and acceleration for multiple connected autonomous vehicles. We utilized
machine learning models to effectively identify abnormal driving patterns.
First, we applied a stacked Long Short-Term Memory (LSTM) model to capture
temporal dependencies and sequence-based anomalies. The stacked LSTM model
processed the sequential data to learn standard driving behaviors.
Additionally, we deployed a Random Forest model to support anomaly detection by
offering ensemble-based predictions, which enhanced model interpretability and
performance. The Random Forest model achieved an R2 of 0.9830, MAE of 5.746,
and a 95th percentile anomaly threshold of 14.18, while the stacked LSTM model
attained an R2 of 0.9998, MAE of 82.425, and a 95th percentile anomaly
threshold of 265.63. These results demonstrate the models' effectiveness in
accurately predicting vehicle trajectories and detecting anomalies in
autonomous driving scenarios.

</details>


### [390] [Kernel Outlier Detection](https://arxiv.org/abs/2506.22994)
*Can Hakan Dağıdır,Mia Hubert,Peter J. Rousseeuw*

Main category: cs.LG

TL;DR: 提出了一种新型的异常检测方法KOD，通过核变换结合投影寻求解决高维数据异常检测中的难题。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法依赖于分布假设或难以调整的超参数，难于应对高维数据中复杂的结构。

Method: 采用核变换与投影寻求方法，引入新型方向搜索集合及结果合并方式，从而构建灵活轻量化的异常检测方法。

Result: 在三个具有挑战性结构的小数据集和四个大型基准数据集上证明了KOD方法的有效性。

Conclusion: KOD是一种有效且高效的异常检测方法，可适用于复杂高维数据环境。

Abstract: A new anomaly detection method called kernel outlier detection (KOD) is
proposed. It is designed to address challenges of outlier detection in
high-dimensional settings. The aim is to overcome limitations of existing
methods, such as dependence on distributional assumptions or on hyperparameters
that are hard to tune. KOD starts with a kernel transformation, followed by a
projection pursuit approach. Its novelties include a new ensemble of directions
to search over, and a new way to combine results of different direction types.
This provides a flexible and lightweight approach for outlier detection. Our
empirical evaluations illustrate the effectiveness of KOD on three small
datasets with challenging structures, and on four large benchmark datasets.

</details>


### [391] [A Reinforcement Learning Approach for Optimal Control in Microgrids](https://arxiv.org/abs/2506.22995)
*Davide Salaorni,Federico Bianchi,Francesco Trovò,Marcello Restelli*

Main category: cs.LG

TL;DR: 本文提出了一种基于强化学习的微电网能源管理方法，并通过数字孪生模拟与意大利电网数据验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源的增加，传统电网需要新的方法来管理分布式能源的生产和消费。

Method: 本文提出了一种基于强化学习的代理，通过历史数据学习最优的能源交易与存储策略，并使用数字孪生模拟包含退化因素的能源存储系统动态。

Result: 实验结果表明，此强化学习策略优于基于规则的方法及现有的RL基准。

Conclusion: 所提出的方法为智能化微电网管理提供了一种高效且稳健的解决方案。

Abstract: The increasing integration of renewable energy sources (RESs) is transforming
traditional power grid networks, which require new approaches for managing
decentralized energy production and consumption. Microgrids (MGs) provide a
promising solution by enabling localized control over energy generation,
storage, and distribution. This paper presents a novel reinforcement learning
(RL)-based methodology for optimizing microgrid energy management.
Specifically, we propose an RL agent that learns optimal energy trading and
storage policies by leveraging historical data on energy production,
consumption, and market prices. A digital twin (DT) is used to simulate the
energy storage system dynamics, incorporating degradation factors to ensure a
realistic emulation of the analysed setting. Our approach is validated through
an experimental campaign using real-world data from a power grid located in the
Italian territory. The results indicate that the proposed RL-based strategy
outperforms rule-based methods and existing RL benchmarks, offering a robust
solution for intelligent microgrid management.

</details>


### [392] [BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs](https://arxiv.org/abs/2506.23024)
*Jerry Liu,Yasa Baig,Denise Hui Jean Lee,Rajat Vadiraj Dwaraknath,Atri Rudra,Chris Ré*

Main category: cs.LG

TL;DR: 本文研究PINN精度不足的原因，并提出通过添加或替换Barycentric Weight Layer (BWLer)来提高精度。


<details>
  <summary>Details</summary>
Motivation: 探索PINNs无法达到科学任务所需机器精度的原因，解决多层感知机(MLP)架构或PDE病态条件的限制。

Method: 引入Barycentric Weight Layer (BWLer)，可添加到现有MLP或完全替代以区分解的表示和PDE损失的求导过程，并结合频谱导数和预条件技术优化训练。

Result: 在五个基准PDE任务上添加BWLer显著提升精度，RMSE提升最多30x、10x、1800x；完全替换MLP可达接近机器精度，提升高达100亿倍。

Conclusion: 通过BWLer结合PINN设计可以实现PINN的灵活性与经典谱方法的精度的结合，提供了实用路径。

Abstract: Physics-informed neural networks (PINNs) offer a flexible way to solve
partial differential equations (PDEs) with machine learning, yet they still
fall well short of the machine-precision accuracy many scientific tasks demand.
In this work, we investigate whether the precision ceiling comes from the
ill-conditioning of the PDEs or from the typical multi-layer perceptron (MLP)
architecture. We introduce the Barycentric Weight Layer (BWLer), which models
the PDE solution through barycentric polynomial interpolation. A BWLer can be
added on top of an existing MLP (a BWLer-hat) or replace it completely
(explicit BWLer), cleanly separating how we represent the solution from how we
take derivatives for the PDE loss. Using BWLer, we identify fundamental
precision limitations within the MLP: on a simple 1-D interpolation task, even
MLPs with O(1e5) parameters stall around 1e-8 RMSE -- about eight orders above
float64 machine precision -- before any PDE terms are added. In PDE learning,
adding a BWLer lifts this ceiling and exposes a tradeoff between achievable
accuracy and the conditioning of the PDE loss. For linear PDEs we fully
characterize this tradeoff with an explicit error decomposition and navigate it
during training with spectral derivatives and preconditioning. Across five
benchmark PDEs, adding a BWLer on top of an MLP improves RMSE by up to 30x for
convection, 10x for reaction, and 1800x for wave equations while remaining
compatible with first-order optimizers. Replacing the MLP entirely lets an
explicit BWLer reach near-machine-precision on convection, reaction, and wave
problems (up to 10 billion times better than prior results) and match the
performance of standard PINNs on stiff Burgers' and irregular-geometry Poisson
problems. Together, these findings point to a practical path for combining the
flexibility of PINNs with the precision of classical spectral solvers.

</details>


### [393] [Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models](https://arxiv.org/abs/2506.23025)
*Tejas Vaidhya,Ayush Kaushal,Vineet Jain,Francis Couture Harpin,Prashant Shishodia,Majid Behbahani,Yuriy Nevmyvaka,Irina Rish*

Main category: cs.LG

TL;DR: 本文研究了三元语言模型(TriLMs)，通过量化感知训练减少内存需求，并提出了2位与1.6位权重打包方案以加速推理。此外，开发了GPU内核TriRun，使推理速度相比浮点基线快5倍，并发布TriLMs的Spectra-1.1套件及推理内核资源。


<details>
  <summary>Details</summary>
Motivation: 随着GPU计算能力提升，其内存带宽与容量未能成比例扩展，模型推理效率成为关键瓶颈，因此需要研究方法以优化推理过程和降低内存需求。

Method: 本文通过量化感知训练实现三元语言模型(TriLMs)的开发，并提出2位与1.6位权重打包方案以提高推理效率。此外，设计了GPU内核TriRun以进一步提升推理速度，同时进行TriLMs模型的扩展性分析与数据训练测试。

Result: 开发了Spectra-1.1模型套件，并通过实验表明相比浮点基线，GPU内核TriRun能将模型推理效率提升至5倍，同时TriLMs在显著减少内存使用的前提下保持性能优势。

Conclusion: 本研究显著提高了LLMs模型推理效率，推出的模型与工具为学术界与工业界进一步探索与部署提供了重要资源和方向。

Abstract: Large language models (LLMs) are increasingly used across research and
industry applications, yet their inference efficiency remains a significant
challenge. As the computational power of modern GPU architectures continuously
improves, their memory bandwidth and capacity have not scaled proportionally,
creating a critical bottleneck during inference. To address this, we
investigate ternary language models (TriLMs) that employ quantization-aware
training to significantly reduce memory requirements. We first analyze the
scalability of TriLMs by conducting a scaling law analysis, revealing that
TriLMs benefit more from increasing training data than from scaling model
parameters. Based on this observation, we introduce Spectra-1.1, an open suite
of TriLMs trained on up to 1.2 trillion tokens, demonstrating sustained
performance gains at scale. Furthermore, to improve inference efficiency, we
propose novel 2-bit and 1.6-bit packing schemes for ternary weights, which
demonstrate accelerated inference across various CPU architectures. Also,
building on the 2-bit packing, we develop a GPU kernel called TriRun that
accelerates end-to-end model inference by up to 5 times compared to
floating-point baselines. To encourage further exploration and development of
TriLMs, we will release the Spectra-1.1 suite and TriRun inference kernels.
Overall, our work lays the foundation for building and deploying efficient
LLMs, providing a valuable resource for the research community.

</details>


### [394] [Feature-Wise Mixing for Mitigating Contextual Bias in Predictive Supervised Learning](https://arxiv.org/abs/2506.23033)
*Yash Vardhan Tomar*

Main category: cs.LG

TL;DR: 提出一种特征混合框架来缓解机器学习模型中的偏差，通过跨多个上下文数据集重新分配特征表征，显著减少偏差且提高预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前偏差纠正方法限制了模型的扩展性和普适性，因此需要一种更加灵活和高效的方法来提升模型公平性。

Method: 通过特征混合框架对特征表征在多个上下文数据集中进行重新分配，并采用交叉验证和敏感损失函数来评估其减偏效果。

Result: 相较传统方法，该方法在偏差减少方面表现更优，平均减偏43.35%，在所有分类器中均显著降低了均方误差（MSE）。

Conclusion: 特征混合是一种高效且无需明确偏差属性识别的减偏方法，未来研究可将其应用于需高预测准确性的实际领域。

Abstract: Bias in predictive machine learning (ML) models is a fundamental challenge
due to the skewed or unfair outcomes produced by biased models. Existing
mitigation strategies rely on either post-hoc corrections or rigid constraints.
However, emerging research claims that these techniques can limit scalability
and reduce generalizability. To address this, this paper introduces a
feature-wise mixing framework to mitigate contextual bias. This was done by
redistributing feature representations across multiple contextual datasets. To
assess feature-wise mixing's effectiveness, four ML classifiers were trained
using cross-validation and evaluated with bias-sensitive loss functions,
including disparity metrics and mean squared error (MSE), which served as a
standard measure of predictive performance. The proposed method achieved an
average bias reduction of 43.35% and a statistically significant decrease in
MSE across all classifiers trained on mixed datasets. Additionally,
benchmarking against established bias mitigation techniques found that
feature-wise mixing consistently outperformed SMOTE oversampling and
demonstrated competitive effectiveness without requiring explicit bias
attribute identification. Feature-wise mixing efficiently avoids the
computational overhead typically associated with fairness-aware learning
algorithms. Future work could explore applying feature-wise mixing for
real-world fields where accurate predictions are necessary.

</details>


### [395] [Fragile, Robust, and Antifragile: A Perspective from Parameter Responses in Reinforcement Learning Under Stress](https://arxiv.org/abs/2506.23036)
*Zain ul Abdeen,Ming Jin*

Main category: cs.LG

TL;DR: 本文分析了强化学习策略的鲁棒性，通过内部和外部压力对网络参数进行系统性研究，发现了可以应对压力提升策略表现的抗脆弱参数。


<details>
  <summary>Details</summary>
Motivation: 受神经科学中突触可塑性的启发，探索强化学习中如何通过分析网络参数的内部及外部压力提高策略适应性和鲁棒性。

Method: 采用一种双重方法：1. 内部压力通过突触筛选技术有选择性地扰动网络参数；2. 外部压力通过对代理观察值进行对抗攻击，同时定义参数评分以量化参数的脆弱性、鲁棒性和抗脆弱性特性，并在Mujoco环境中验证。

Result: 实验结果显示存在抗脆弱的网络参数，这些参数在压力下能够提升策略的表现。

Conclusion: 证明了针对性筛选技术可以提高强化学习策略的适应性，为未来开发鲁棒和抗脆弱的强化学习系统奠定了基础。

Abstract: This paper explores Reinforcement learning (RL) policy robustness by
systematically analyzing network parameters under internal and external
stresses. Inspired by synaptic plasticity in neuroscience, synaptic filtering
introduces internal stress by selectively perturbing parameters, while
adversarial attacks apply external stress through modified agent observations.
This dual approach enables the classification of parameters as fragile, robust,
or antifragile, based on their influence on policy performance in clean and
adversarial settings. Parameter scores are defined to quantify these
characteristics, and the framework is validated on PPO-trained agents in Mujoco
continuous control environments. The results highlight the presence of
antifragile parameters that enhance policy performance under stress,
demonstrating the potential of targeted filtering techniques to improve RL
policy adaptability. These insights provide a foundation for future
advancements in the design of robust and antifragile RL systems.

</details>


### [396] [ResQuNNs:Towards Enabling Deep Learning in Quantum Convolution Neural Networks](https://arxiv.org/abs/2402.09146)
*Muhammad Kashif,Muhammad Shafique*

Main category: cs.LG

TL;DR: 本文提出一种新的框架，通过引入可训练的量子卷积层和残差学习，显著提升量子卷积神经网络（QuNNs）的性能。


<details>
  <summary>Details</summary>
Motivation: 传统量子卷积层虽然在特征提取方面有用，但缺乏灵活性和适应性。本文旨在解决这些缺陷并改进QuNNs的训练能力。

Method: 提出了一种新型架构——残差量子卷积神经网络（ResQuNNs），通过在量子卷积层之间加入残差块，改进梯度传播与优化效果。

Result: 实验验证了残差块的战略性设置显著提升了网络的训练性能，并明确了优化配置以改善梯度流动和网络训练效率。

Conclusion: 研究结果表明，精确设置残差块是提升QuNNs性能的关键，为量子深度学习的发展开辟了新的理论和应用方向。

Abstract: In this paper, we present a novel framework for enhancing the performance of
Quanvolutional Neural Networks (QuNNs) by introducing trainable quanvolutional
layers and addressing the critical challenges associated with them. Traditional
quanvolutional layers, although beneficial for feature extraction, have largely
been static, offering limited adaptability. Unlike state-of-the-art, our
research overcomes this limitation by enabling training within these layers,
significantly increasing the flexibility and potential of QuNNs. However, the
introduction of multiple trainable quanvolutional layers induces complexities
in gradient-based optimization, primarily due to the difficulty in accessing
gradients across these layers. To resolve this, we propose a novel
architecture, Residual Quanvolutional Neural Networks (ResQuNNs), leveraging
the concept of residual learning, which facilitates the flow of gradients by
adding skip connections between layers. By inserting residual blocks between
quanvolutional layers, we ensure enhanced gradient access throughout the
network, leading to improved training performance. Moreover, we provide
empirical evidence on the strategic placement of these residual blocks within
QuNNs. Through extensive experimentation, we identify an efficient
configuration of residual blocks, which enables gradients across all the layers
in the network that eventually results in efficient training. Our findings
suggest that the precise location of residual blocks plays a crucial role in
maximizing the performance gains in QuNNs. Our results mark a substantial step
forward in the evolution of quantum deep learning, offering new avenues for
both theoretical development and practical quantum computing applications.

</details>


### [397] [ReMem: Mutual Information-Aware Fine-tuning of Pretrained Vision Transformers for Effective Knowledge Distillation](https://arxiv.org/abs/2506.23041)
*Chengyu Dong,Huan Gui,Noveen Sachdeva,Long Jin,Ke Yin,Jingbo Shang,Lichan Hong,Ed H. Chi,Zhe Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种通过为预训练ViT模型进行优化微调以提高蒸馏效果的新方法，尤其在数据集规模较小或不平衡时具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 针对从强大的大规模预训练模型中提取知识蒸馏效果降低的问题，作者建议改进蒸馏技术以更高效地利用ViT模型。

Method: 提出基于互信息感知优化的微调方法，以及对小型或高度不平衡下游数据集使用的MLP模块重加权策略来增强蒸馏效果。

Result: 所提出的方法显著提升了小型学生模型利用强大预训练模型的能力。

Conclusion: 新的微调和重加权方法能够使任务特定的小型生产模型从最强的预训练模型中受益。

Abstract: Knowledge distillation from pretrained visual representation models offers an
effective approach to improve small, task-specific production models. However,
the effectiveness of such knowledge transfer drops significantly when
distilling from strong models that are pretrained in a large scale. In this
paper, we address this challenge for pretrained Vision Transformers (ViTs) by
exploring methods to fine-tune them for more effective knowledge transfer.
Motivated by the connection between mutual information and distillation
effectiveness, we propose to employ mutual information-aware optimization
during finetuning. For small or highly-imbalanced downstream datasets where
such optimization becomes less effective, we introduce a simple yet effective
heuristic of reweighting MLP blocks. This approach is inspired by our
observation that top MLP blocks are primarily responsible for mutual
information loss. Our method enables small student models to benefit from those
pretrained models among the strongest.

</details>


### [398] [Double-Diffusion: Diffusion Conditioned Diffusion Probabilistic Model For Air Quality Prediction](https://arxiv.org/abs/2506.23053)
*Hanlin Dong,Arian Prabowo,Hao Xue,Flora D. Salim*

Main category: cs.LG

TL;DR: 提出了Double-Diffusion模型，通过结合已知物理规律与扩散模型，改善空气质量预测的效果与效率。


<details>
  <summary>Details</summary>
Motivation: 当前空气质量预测中，如何平衡确定性与不确定性仍是未解决的问题。

Method: 提出一种结合已知物理规律的双扩散概率模型，并采用新的采样策略及去噪器架构。

Result: Double-Diffusion在两个真实数据集上的评估场景中排名第一，预测准确性提高3%-12%，推断时间减少30%-50%。

Conclusion: 该方法在空气质量预测中显著提高了结果的准确性与计算效率，并为物理指导的生成模型使用开辟了新的方向。

Abstract: Air quality prediction is a challenging forecasting task due to its
spatio-temporal complexity and the inherent dynamics as well as uncertainty.
Most of the current models handle these two challenges by applying Graph Neural
Networks or known physics principles, and quantifying stochasticity through
probabilistic networks like Diffusion models. Nevertheless, finding the right
balancing point between the certainties and uncertainties remains an open
question. Therefore, we propose Double-Diffusion, a novel diffusion
probabilistic model that harnesses the power of known physics to guide air
quality forecasting with stochasticity. To the best of our knowledge, while
precedents have been made of using conditional diffusion models to predict air
pollution, this is the first attempt to use physics as a conditional generative
approach for air quality prediction. Along with a sampling strategy adopted
from image restoration and a new denoiser architecture, Double-Diffusion ranks
first in most evaluation scenarios across two real-life datasets compared with
other probabilistic models, it also cuts inference time by 50% to 30% while
enjoying an increase between 3-12% in Continuous Ranked Probabilistic Score
(CRPS).

</details>


### [399] [Measuring How LLMs Internalize Human Psychological Concepts: A preliminary analysis](https://arxiv.org/abs/2506.23055)
*Hiro Taiyo Hamada,Ippei Fujisawa,Genji Kawakita,Yuki Yamada*

Main category: cs.LG

TL;DR: 本文通过分析43种标准心理问卷和语言模型的相似性，研究了大型语言模型（LLM）与人类心理维度的概念契合度，发现GPT-4在分类准确性上表现最好，展示了现代LLM在逼近人类心理构建方面的能力。


<details>
  <summary>Details</summary>
Motivation: 研究人类心理维度和大型语言模型之间的概念契合性，进一步理解语言模型对人类思想和行为的内化程度。

Method: 使用43种经过验证的心理问卷，通过成对相似性分析和层次聚类，评估LLM对问卷项目的重建与分类准确性，并通过与人类的语义相似性关联系数进一步验证模型表现。

Result: GPT-4的分类准确率为66.2%，显著高于GPT-3.5（55.9%）和BERT（48.1%），且所有模型均优于随机基线（31.9%）。GPT-4的语义相似性估计与人类心理问卷的Pearson相关系数存在显著关联。

Conclusion: 现代的LLM可以以可量化的准确性逼近人类心理构建，研究成果为开发更具解释性的人工智能系统提供了新的见解。

Abstract: Large Language Models (LLMs) such as ChatGPT have shown remarkable abilities
in producing human-like text. However, it is unclear how accurately these
models internalize concepts that shape human thought and behavior. Here, we
developed a quantitative framework to assess concept alignment between LLMs and
human psychological dimensions using 43 standardized psychological
questionnaires, selected for their established validity in measuring distinct
psychological constructs. Our method evaluates how accurately language models
reconstruct and classify questionnaire items through pairwise similarity
analysis. We compared resulting cluster structures with the original
categorical labels using hierarchical clustering. A GPT-4 model achieved
superior classification accuracy (66.2\%), significantly outperforming GPT-3.5
(55.9\%) and BERT (48.1\%), all exceeding random baseline performance (31.9\%).
We also demonstrated that the estimated semantic similarity from GPT-4 is
associated with Pearson's correlation coefficients of human responses in
multiple psychological questionnaires. This framework provides a novel approach
to evaluate the alignment of the human-LLM concept and identify potential
representational biases. Our findings demonstrate that modern LLMs can
approximate human psychological constructs with measurable accuracy, offering
insights for developing more interpretable AI systems.

</details>


### [400] [Curious Causality-Seeking Agents Learn Meta Causal World](https://arxiv.org/abs/2506.23068)
*Zhiyu Zhao,Haoxuan Li,Haifeng Zhang,Jun Wang,Francesco Faccio,Jürgen Schmidhuber,Mengyue Yang*

Main category: cs.LG

TL;DR: 此论文提出了Meta-Causal Graph来建模环境因果机制的转变，并基于此设计了Causality-Seeking Agent，通过实验验证了其在复杂场景下捕捉因果动态转变和推广能力的效果。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型通常假设环境因果机制不变，但在实际中因果机制可能随政策或环境变化而改变，需要一种能够动态适应这种因果机制变化的模型框架。

Method: 提出Meta-Causal Graph作为世界模型，将因果结构的转变编码为由潜在状态空间触发的多个因果子图；设计Causality-Seeking Agent，通过好奇心驱动的干预策略识别潜在状态、发现因果关系并逐步完善Meta-Causal Graph。

Result: 实验包括合成任务和机器人臂操控任务，证明方法能够鲁棒地捕捉因果动态变化，并在未见过的环境下具有较好的泛化能力。

Conclusion: Meta-Causal Graph和Causality-Seeking Agent为动态因果机制建模提供了一种有效的方法，为处理更加复杂的现实问题奠定了基础。

Abstract: When building a world model, a common assumption is that the environment has
a single, unchanging underlying causal rule, like applying Newton's laws to
every situation. In reality, what appears as a drifting causal mechanism is
often the manifestation of a fixed underlying mechanism seen through a narrow
observational window. This brings about a problem that, when building a world
model, even subtle shifts in policy or environment states can alter the very
observed causal mechanisms. In this work, we introduce the \textbf{Meta-Causal
Graph} as world models, a minimal unified representation that efficiently
encodes the transformation rules governing how causal structures shift across
different latent world states. A single Meta-Causal Graph is composed of
multiple causal subgraphs, each triggered by meta state, which is in the latent
state space. Building on this representation, we introduce a
\textbf{Causality-Seeking Agent} whose objectives are to (1) identify the meta
states that trigger each subgraph, (2) discover the corresponding causal
relationships by agent curiosity-driven intervention policy, and (3)
iteratively refine the Meta-Causal Graph through ongoing curiosity-driven
exploration and agent experiences. Experiments on both synthetic tasks and a
challenging robot arm manipulation task demonstrate that our method robustly
captures shifts in causal dynamics and generalizes effectively to previously
unseen contexts.

</details>


### [401] [Forget-MI: Machine Unlearning for Forgetting Multimodal Information in Healthcare Settings](https://arxiv.org/abs/2506.23145)
*Shahad Hardan,Darya Taratynova,Abdelmajid Essofi,Karthik Nandakumar,Mohammad Yaqub*

Main category: cs.LG

TL;DR: 提出Forget-MI方法用于医疗数据的机器遗忘，有效平衡遗忘和模型性能，代码已开放。


<details>
  <summary>Details</summary>
Motivation: 保护AI中的隐私信息，满足医疗中对敏感患者数据的遗忘需求。

Method: 通过损失函数与扰动技术，实现多模态医疗数据中单模态及联合表示的遗忘，同时保留其余数据的知识和模型性能。

Result: 方法在遗忘数据的表现上超越现有技术，MIA降低0.202，AUC降低0.221，F1分数降低0.305，测试集性能与重训模型持平。

Conclusion: Forget-MI能够实现数据的有效遗忘，同时保持模型性能，展示了在隐私保护中的应用潜力。

Abstract: Privacy preservation in AI is crucial, especially in healthcare, where models
rely on sensitive patient data. In the emerging field of machine unlearning,
existing methodologies struggle to remove patient data from trained multimodal
architectures, which are widely used in healthcare. We propose Forget-MI, a
novel machine unlearning method for multimodal medical data, by establishing
loss functions and perturbation techniques. Our approach unlearns unimodal and
joint representations of the data requested to be forgotten while preserving
knowledge from the remaining data and maintaining comparable performance to the
original model. We evaluate our results using performance on the forget
dataset, performance on the test dataset, and Membership Inference Attack
(MIA), which measures the attacker's ability to distinguish the forget dataset
from the training dataset. Our model outperforms the existing approaches that
aim to reduce MIA and the performance on the forget dataset while keeping an
equivalent performance on the test set. Specifically, our approach reduces MIA
by 0.202 and decreases AUC and F1 scores on the forget set by 0.221 and 0.305,
respectively. Additionally, our performance on the test set matches that of the
retrained model, while allowing forgetting. Code is available at
https://github.com/BioMedIA-MBZUAI/Forget-MI.git

</details>


### [402] [maneuverRecognition -- A Python package for Timeseries Classification in the domain of Vehicle Telematics](https://arxiv.org/abs/2506.23147)
*Jonathan Schuster,Fabian Transchel*

Main category: cs.LG

TL;DR: 该研究开发了一个Python包mannerRecognition，帮助进行驾驶行为检测的时序分类。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶行为检测方法数据处理复杂且缺乏易用工具。

Method: 提供了实现驾驶数据预处理、建模与评估的Python函数与一个可修改的基于LSTM的网络。

Result: 通过智能手机传感器获取的真实驾驶数据演示了该包的实用性。

Conclusion: 该包有助于更快地完成驾驶动作识别任务，对评价驾驶行为和促进安全驾驶有积极意义。

Abstract: In the domain of vehicle telematics the automated recognition of driving
maneuvers is used to classify and evaluate driving behaviour. This not only
serves as a component to enhance the personalization of insurance policies, but
also to increase road safety, reduce accidents and the associated costs as well
as to reduce fuel consumption and support environmentally friendly driving. In
this context maneuver recognition technically requires a continuous application
of time series classification which poses special challenges to the transfer,
preprocessing and storage of telematic sensor data, the training of predictive
models, and the prediction itself. Although much research has been done in the
field of gathering relevant data or regarding the methods to build predictive
models for the task of maneuver recognition, there is a practical need for
python packages and functions that allow to quickly transform data into the
required structure as well as to build and evaluate such models. The
maneuverRecognition package was therefore developed to provide the necessary
functions for preprocessing, modelling and evaluation and also includes a ready
to use LSTM based network structure that can be modified. The implementation of
the package is demonstrated using real driving data of three different persons
recorded via smartphone sensors.

</details>


### [403] [Data Can Speak for Itself: Quality-guided Utilization of Wireless Synthetic Data](https://arxiv.org/abs/2506.23174)
*Chen Gong,Bo Liang,Wei Gao,Chenren Xu*

Main category: cs.LG

TL;DR: 该研究提出了针对当前无线合成数据质量问题的评估指标和优化方法，通过引入SynCheck机制提升合成数据对任务性能的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管生成模型能够提升无线感知任务性能，但合成数据质量无法预测，导致性能提升无法保证。研究动机在于提出解决这一问题的方法，从而更好地利用合成数据。

Method: 设计了两种指标（affinity和diversity）评估合成数据质量；提出质量导向的合成数据使用框架SynCheck，以在任务模型训练过程中优化合成数据质量。

Result: 评估结果表明，SynCheck方案在任务性能上优于未加质量控制的合成数据使用方法，实现了4.3%的性能提升，并纠正了性能下降13.4%的问题。

Conclusion: 通过融合数据质量评估和优化方法，SynCheck能够有效改善无线合成数据的实际应用效果，并显著提升任务性能。

Abstract: Generative models have gained significant attention for their ability to
produce realistic synthetic data that supplements the quantity of real-world
datasets. While recent studies show performance improvements in wireless
sensing tasks by incorporating all synthetic data into training sets, the
quality of synthetic data remains unpredictable and the resulting performance
gains are not guaranteed. To address this gap, we propose tractable and
generalizable metrics to quantify quality attributes of synthetic data -
affinity and diversity. Our assessment reveals prevalent affinity limitation in
current wireless synthetic data, leading to mislabeled data and degraded task
performance. We attribute the quality limitation to generative models' lack of
awareness of untrained conditions and domain-specific processing. To mitigate
these issues, we introduce SynCheck, a quality-guided synthetic data
utilization scheme that refines synthetic data quality during task model
training. Our evaluation demonstrates that SynCheck consistently outperforms
quality-oblivious utilization of synthetic data, and achieves 4.3% performance
improvement even when the previous utilization degrades performance by 13.4%.

</details>


### [404] [Attribution assignment for deep-generative sequence models enables interpretability analysis using positive-only data](https://arxiv.org/abs/2506.23182)
*Robert Frank,Michael Widrich,Rahmad Akbar,Günter Klambauer,Geir Kjetil Sandve,Philippe A. Robert,Victor Greiff*

Main category: cs.LG

TL;DR: 本研究提出了一种名为GAMA的归因方法，用于解释生成式模型的内部机制，特别是在生物序列设计场景中。


<details>
  <summary>Details</summary>
Motivation: 生成模型如LSTMs可以只使用正样本进行训练，但缺乏归因方法阻碍了其解释能力。研究的目标是开发一种方法来解释生成模型的生物意义。

Method: 研究提出了GAMA，基于集成梯度的归因方法，用于生成模型的解释性分析。

Result: GAMA在已知真值的合成数据集上被评估为具有良好性能，并应用于抗体-抗原结合实验数据，能够验证生物学相关特征。

Conclusion: GAMA为生成模型带来了更好的可解释性，并在缺乏负样本的情况下也能验证设计策略的效果。

Abstract: Generative machine learning models offer a powerful framework for therapeutic
design by efficiently exploring large spaces of biological sequences enriched
for desirable properties. Unlike supervised learning methods, which require
both positive and negative labeled data, generative models such as LSTMs can be
trained solely on positively labeled sequences, for example, high-affinity
antibodies. This is particularly advantageous in biological settings where
negative data are scarce, unreliable, or biologically ill-defined. However, the
lack of attribution methods for generative models has hindered the ability to
extract interpretable biological insights from such models. To address this
gap, we developed Generative Attribution Metric Analysis (GAMA), an attribution
method for autoregressive generative models based on Integrated Gradients. We
assessed GAMA using synthetic datasets with known ground truths to characterize
its statistical behavior and validate its ability to recover biologically
relevant features. We further demonstrated the utility of GAMA by applying it
to experimental antibody-antigen binding data. GAMA enables model
interpretability and the validation of generative sequence design strategies
without the need for negative training data.

</details>


### [405] [Efficient Algorithms for Learning and Compressing Monophonic Halfspaces in Graphs](https://arxiv.org/abs/2506.23186)
*Marco Bressan,Victor Chepoi,Emmanuel Esposito,Maximilian Thiessen*

Main category: cs.LG

TL;DR: 本文研究了基于图路径闭包定义的monophonic halfspaces，并提出了可高效表示和学习此类halfspaces的分解方法及算法。


<details>
  <summary>Details</summary>
Motivation: 探索一种广义的图凸性以及其应用于机器学习中的学习问题，如教学学习、主动学习和在线学习中的可能性和可行性。

Method: 提出基于2-可满足性的分解定理，将monophonic halfspaces表达为顶点子集的不相交并，通过此方法开发高效近似最优的学习算法，同时提出适用于此图半空间的新型样本压缩方案。

Result: 开发了有效的多种学习算法，包括经验风险最小化的多项式时间算法，以及稳定、有效率的样本压缩方案，证明了在PAC设定中可以实现线性色误差率（$1/\varepsilon$）。

Conclusion: 提供了一种高效学习monophonic halfspaces的新方法，并明确区分了其与NP难的geodesic halfspaces，在理论和实际方面填补了相关研究的空白。

Abstract: Abstract notions of convexity over the vertices of a graph, and corresponding
notions of halfspaces, have recently gained attention from the machine learning
community. In this work we study monophonic halfspaces, a notion of graph
halfspaces defined through closure under induced paths. Our main result is a
$2$-satisfiability based decomposition theorem, which allows one to represent
monophonic halfspaces as a disjoint union of certain vertex subsets. Using this
decomposition, we achieve efficient and (nearly) optimal algorithms for various
learning problems, such as teaching, active, and online learning. Most notably,
we obtain a polynomial-time algorithm for empirical risk minimization.
Independently of the decomposition theorem, we obtain an efficient, stable, and
proper sample compression scheme. This makes monophonic halfspaces efficiently
learnable with proper learners and linear error rate $1/\varepsilon$ in the
realizable PAC setting. Our results answer open questions from the literature,
and show a stark contrast with geodesic halfspaces, for which most of the said
learning problems are NP-hard.

</details>


### [406] [External Data-Enhanced Meta-Representation for Adaptive Probabilistic Load Forecasting](https://arxiv.org/abs/2506.23201)
*Haoran Li,Muhao Guo,Marija Ilic,Yang Weng,Guangchun Ruan*

Main category: cs.LG

TL;DR: 准确的居民负载预测对于随着可再生能源整合的增加和需求侧灵活性的重要性愈加显著，本文提出通过超网络和专家混合机制的创新方法，显著提高了预测的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有统计和机器学习模型将外部因素（如天气、日历效应和定价）仅作为额外输入，忽略了其异质性，从而限制了对有用外部信息的提取。

Method: 设计一个使用超网络的元表示框架，根据外部条件动态调整深度学习模型的参数，并结合专家混合机制（MoE）提高效率和鲁棒性。

Result: 所提模型M2oE2在多种负载数据集上实现了准确性和鲁棒性的显著提升，且额外开销有限，优于现有的最先进方法。

Conclusion: 利用外部数据动态调整预测模型是一种有效的新方法，这种方法既提升了预测表现，又展示了良好的鲁棒性和效率创新。

Abstract: Accurate residential load forecasting is critical for power system
reliability with rising renewable integration and demand-side flexibility.
However, most statistical and machine learning models treat external factors,
such as weather, calendar effects, and pricing, as extra input, ignoring their
heterogeneity, and thus limiting the extraction of useful external information.
We propose a paradigm shift: external data should serve as meta-knowledge to
dynamically adapt the forecasting model itself. Based on this idea, we design a
meta-representation framework using hypernetworks that modulate selected
parameters of a base Deep Learning (DL) model in response to external
conditions. This provides both expressivity and adaptability. We further
integrate a Mixture-of-Experts (MoE) mechanism to enhance efficiency through
selective expert activation, while improving robustness by filtering redundant
external inputs. The resulting model, dubbed as a Meta Mixture of Experts for
External data (M2oE2), achieves substantial improvements in accuracy and
robustness with limited additional overhead, outperforming existing
state-of-the-art methods in diverse load datasets. The dataset and source code
are publicly available at
https://github.com/haorandd/M2oE2\_load\_forecast.git.

</details>


### [407] [FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model](https://arxiv.org/abs/2506.23210)
*Taehwan Yoon,Bongjun Choi*

Main category: cs.LG

TL;DR: 本文提出了一种基于参考模型的联邦学习方法，用于优化微调并克服灾难性遗忘问题，从而实现高性能和低计算成本的AI模型训练。


<details>
  <summary>Details</summary>
Motivation: 联邦学习保证用户隐私的同时可能无法满足用户对模型性能的期望，特别是在面对用户多样化需求时，存在模型优化的挑战。

Method: 提出了一种基于参考模型的联邦学习方法，利用贝叶斯参数高效迁移学习中的最优近似项，结合模型微调和个性化策略，参考先前模型参数以克服灾难性遗忘问题。

Result: 该方法兼顾了模型性能和计算成本，达到了高效的AI模型训练效果。

Conclusion: 基于参考模型的联邦学习是一种在隐私保护前提下提升模型性能的有效解决方案，并能以低计算成本实现最佳模型优化。

Abstract: Federated learning(FL) is used for distributed scenarios to train artificial
intelligence(AI) models while ensuring users' privacy. In federated learning
scenario, the server generally never knows about users' data. This type of
concept makes the AI training process efficient in terms of data privacy.
However, regarding model performance, federated AI models may not sufficiently
satisfy AI users' expectations. Furthermore, AI users have a wide range of
different needs. It is not easy to satisfy the whole users needs. These types
of issues can be addressed through AI model optimization, fine-tuning, or
personalization to achieve optimal model performance. To address model
optimization challenges, we propose reference model-based federated learning
for optimal fine-tuning, which overcomes catastrophic forgetting in each round.
This method is derived from Bayesian parameter-efficient transfer learning,
which includes an optimal proximal term and enables overcoming the catastrophic
forgetting issue in each round by utilizing a reference model that incorporates
previous model parameters. As a result, this method achieves both high model
performance and low computing cost.

</details>


### [408] [Single Image Inpainting and Super-Resolution with Simultaneous Uncertainty Guarantees by Universal Reproducing Kernels](https://arxiv.org/abs/2506.23221)
*Bálint Horváth,Balázs Csanád Csáji*

Main category: cs.LG

TL;DR: 本文提出了用于图像缺失像素估计的统计学习方法，称为SGKI，不仅能估计缺失值，还能提供全局非渐近置信区间。


<details>
  <summary>Details</summary>
Motivation: 图像修复和超分辨率问题依赖于准确的缺失像素恢复，同时需要增加不确定性量化以提升方法可靠性。

Method: 提出了Simultaneously Guaranteed Kernel Interpolation（SGKI）方法，基于生成函数处于再生核希尔伯特空间的假设，利用Schur补高效计算全局置信带。

Result: 通过对合成和基准图像数据集的实验，验证了SGKI在估计缺失像素值及不确定性量化上的有效性。

Conclusion: SGKI方法有效扩展了一种最近的核方法，为图像处理任务提供了更加可靠的估计和不确定性量化。

Abstract: The paper proposes a statistical learning approach to the problem of
estimating missing pixels of images, crucial for image inpainting and
super-resolution problems. One of the main novelties of the method is that it
also provides uncertainty quantifications together with the estimated values.
Our core assumption is that the underlying data-generating function comes from
a Reproducing Kernel Hilbert Space (RKHS). A special emphasis is put on
band-limited functions, central to signal processing, which form Paley-Wiener
type RKHSs. The proposed method, which we call Simultaneously Guaranteed Kernel
Interpolation (SGKI), is an extension and refinement of a recently developed
kernel method. An advantage of SGKI is that it not only estimates the missing
pixels, but also builds non-asymptotic confidence bands for the unobserved
values, which are simultaneously guaranteed for all missing pixels. We also
show how to compute these bands efficiently using Schur complements, we discuss
a generalization to vector-valued functions, and we present a series of
numerical experiments on various datasets containing synthetically generated
and benchmark images, as well.

</details>


### [409] [Masked Gated Linear Unit](https://arxiv.org/abs/2506.23225)
*Yukito Tajima,Nakamasa Inoue,Yusuke Sekikawa,Ikuro Sato,Rio Yokota*

Main category: cs.LG

TL;DR: 引入了Masked Gated Linear Units (MGLUs)，一种更高效的GLU变体，减少内存传输并提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的GLUs因需要单独的权重矩阵，导致内存读取需求大幅增加，成为效率瓶颈。

Method: 提出了MGLUs，通过混合元素级门控架构（MoEG）减少内存传输，并开发了硬件友好的FlashMGLU内核优化推理速度。

Result: FlashMGLU在RTX5090 GPU上达到19.7倍推理速度提升，同时比标准GLUs减少47%的内存占用，提高34%的速度。

Conclusion: MGLUs有效提升了GLUs的内存和计算效率，并在保持甚至提升下游任务准确性的同时降低资源开销，适用于大语言模型。

Abstract: Gated Linear Units (GLUs) have become essential components in the
feed-forward networks of state-of-the-art Large Language Models (LLMs).
However, they require twice as many memory reads compared to feed-forward
layers without gating, due to the use of separate weight matrices for the gate
and value streams. To address this bottleneck, we introduce Masked Gated Linear
Units (MGLUs), a novel family of GLUs with an efficient kernel implementation.
The core contribution of MGLUs include: (1) the Mixture of Element-wise Gating
(MoEG) architecture that learns multiple binary masks, each determining gate or
value assignments at the element level on a single shared weight matrix
resulting in reduced memory transfer, and (2) FlashMGLU, a hardware-friendly
kernel that yields up to a 19.7 $\times$ inference-time speed-up over a naive
PyTorch MGLU and is 47% more memory-efficient and 34% faster than standard GLUs
despite added architectural complexity on an RTX5090 GPU. In LLM experiments,
the Swish-activated variant SwiMGLU preserves its memory advantages while
matching - or even surpassing - the downstream accuracy of the SwiGLU baseline.

</details>


### [410] [Sub-MoE: Efficient Mixture-of-Expert LLMs Compression via Subspace Expert Merging](https://arxiv.org/abs/2506.23266)
*Lujun Li,Zhu Qiyuan,Jiacheng Wang,Wei Li,Hao Gu,Sirui Han,Yike Guo*

Main category: cs.LG

TL;DR: 提出了一种名为Sub-MoE的新方法，通过子空间专家合并以压缩大型MoE LLM，同时保持较高的性能表现。


<details>
  <summary>Details</summary>
Motivation: 解决大规模参数导致的存储和部署问题，并克服专家专业化带来的参数冲突。

Method: 包括两个创新阶段：自适应专家聚类和子空间专家合并，其中利用联合奇异值分解提取共享参数并合并专家专用部分。

Result: 在Mixtral、DeepSeek和Qwen-1.5|3模型测试中显著优于现有方法，并在减少25%和50%专家数时分别保留了96%和86%的原始性能。

Conclusion: 通过子空间的专家合并不仅提升了效率，同时也保持了模型性能，为压缩和推理优化提供了一种有效方案。

Abstract: Mixture of Experts (MoE) LLMs face significant obstacles due to their massive
parameter scale, which imposes memory, storage, and deployment challenges.
Although recent expert merging methods promise greater efficiency by
consolidating multiple experts, they are fundamentally hindered by parameter
conflicts arising from expert specialization. In this paper, we present
Sub-MoE, a novel MoE compression framework via Subspace Expert Merging. Our key
insight is to perform joint Singular Value Decomposition (SVD) on concatenated
expert weights, reducing conflicting parameters by extracting shared
$U$-matrices while enabling effective merging of the expert-specific $V$
components. Specifically, Sub-MoE consists of two innovative phases: (1)
Adaptive Expert Clustering, which groups functionally coherent experts via
K-means clustering based on cosine similarity of expert outputs; and (2)
Subspace Expert Merging, which first enforces Experts Union Decomposition to
derive the shared $U$-matrix across experts in the same group, then pursues
frequency-based merging for individual $V$-matrices, and finalizes expert
reconstruction using the merged $V$-matrix. In this way, we align and fuse
experts in a shared subspace, and can be extended with intra-expert compression
for further inference optimization. Extensive experiments on Mixtral, DeepSeek,
and Qwen-1.5|3 MoE LLMs demonstrate that our Sub-MoE significantly outperforms
existing expert pruning and merging methods. Notably, our Sub-MoE maintains
96\%|86\% of original performance with 25\%|50\% expert reduction on
Mixtral-8x7B in zero-shot benchmarks. Code will be released at
https://github.com/lliai/MoERazor.

</details>


### [411] [Predicting thinking time in Reasoning models](https://arxiv.org/abs/2506.23274)
*Hans Peter Lynsgøe Raaschou-jensen,Constanza Fierro,Anders Søgaard*

Main category: cs.LG

TL;DR: 提出了一种预测模型推理时间的方法，为用户交互提供进度指示。


<details>
  <summary>Details</summary>
Motivation: 解决长推理链模型的不确定性，减少用户因无法预测模型推理时间而产生的挫败感。

Method: 研究了在线和离线预测模型推理时间的方法，提出“推理进度条”概念。

Result: 实验验证了预测模型推理时间的方法的可行性，为推理模型的用户交互优化提供了支持。

Conclusion: 通过预测推理时间改善用户体验，并为未来研究提供方向。

Abstract: Reasoning models that produce long, hidden chains of thought have emerged as
powerful tools for complex, reasoning-intensive
tasks\citep{deepseekai2025deepseekr1incentivizingreasoningcapability,
openai2024openaio1card}. However, this paradigm introduces a new user
experience challenge: users have little insight into how much time the model
will spend reasoning before returning an answer. This unpredictability, can
lead to user frustration and is likely to compound as LLMs can produce
increasingly long tasks asynchronously
\citep{kwa2025measuringaiabilitycomplete}. In this paper, we introduce and
evaluate methods for both online and offline prediction of model "thinking
time," aiming to develop a practical "progress bar for reasoning." We discuss
the implications for user interaction and future research directions.

</details>


### [412] [BAPE: Learning an Explicit Bayes Classifier for Long-tailed Visual Recognition](https://arxiv.org/abs/2506.23280)
*Chaoqun Du,Yulin Wang,Shiji Song,Gao Huang*

Main category: cs.LG

TL;DR: 本文提出了一种新方法BAPE，通过显式建模后验概率的参数并使用点估计解决它们，直接学习贝叶斯分类器，解决了真实世界长尾分布数据中的梯度不平衡问题并保证了贝叶斯最优决策规则。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法通常通过隐式估计后验概率的方式，无法有效处理真实世界的长尾分布数据，导致梯度不平衡并且未保证贝叶斯最优决策规则，因此需要开发更精确的理论方法。

Method: 提出了一种显式建模后验概率参数并通过点估计直接学习贝叶斯分类器的方法（BAPE），并引入了一种简单但有效的分布调整技术，使得分类器能适应测试数据分布的任何不平衡系数。

Result: 在CIFAR-10-LT、CIFAR-100-LT、ImageNet-LT和iNaturalist等数据集的实验中，该方法显著提升了主流深度网络的泛化性能。

Conclusion: 所提出的方法简单但有效，能够提升在长尾数据分布下分类器的性能，并与现有学习方法相辅相成。

Abstract: Bayesian decision theory advocates the Bayes classifier as the optimal
approach for minimizing the risk in machine learning problems. Current deep
learning algorithms usually solve for the optimal classifier by
\emph{implicitly} estimating the posterior probabilities, \emph{e.g.}, by
minimizing the Softmax cross-entropy loss. This simple methodology has been
proven effective for meticulously balanced academic benchmark datasets.
However, it is not applicable to the long-tailed data distributions in the real
world, where it leads to the gradient imbalance issue and fails to ensure the
Bayes optimal decision rule. To address these challenges, this paper presents a
novel approach (BAPE) that provides a more precise theoretical estimation of
the data distributions by \emph{explicitly} modeling the parameters of the
posterior probabilities and solving them with point estimation. Consequently,
our method directly learns the Bayes classifier without gradient descent based
on Bayes' theorem, simultaneously alleviating the gradient imbalance and
ensuring the Bayes optimal decision rule. Furthermore, we propose a
straightforward yet effective \emph{distribution adjustment} technique. This
method enables the Bayes classifier trained from the long-tailed training set
to effectively adapt to the test data distribution with an arbitrary imbalance
factor, thereby enhancing performance without incurring additional
computational costs. In addition, we demonstrate the gains of our method are
orthogonal to existing learning approaches for long-tailed scenarios, as they
are mostly designed under the principle of \emph{implicitly} estimating the
posterior probabilities. Extensive empirical evaluations on CIFAR-10-LT,
CIFAR-100-LT, ImageNet-LT, and iNaturalist demonstrate that our method
significantly improves the generalization performance of popular deep networks,
despite its simplicity.

</details>


### [413] [Not All Explanations for Deep Learning Phenomena Are Equally Valuable](https://arxiv.org/abs/2506.23286)
*Alan Jeffares,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 本文探讨了深度学习研究中的一些令人惊讶或违反直觉的现象，建议改变以孤立的视角解决这些问题的研究方式，并提出通过这些现象改进一般性深度学习理论的价值。


<details>
  <summary>Details</summary>
Motivation: 目前许多研究对深度学习中的反直觉现象进行个案解析，但作者认为这些现象在真实世界应用中并无明显证据表明其意义，呼吁关注大局发展的潜力。

Method: 通过分析近年来一些现象的研究成果，评估其对深度学习领域进步的贡献，并重新审视现有的研究规范，最终提出具体的研究建议。

Result: 研究建议关注如何通过这些现象帮助改进深度学习的普遍理论，而非仅仅追求对单一现象的孤立解释。

Conclusion: 通过更系统化的方法研究深度学习现象可以更好地推进领域整体的发展，并为未来研究提供更加有意义的指导。

Abstract: Developing a better understanding of surprising or counterintuitive phenomena
has constituted a significant portion of deep learning research in recent
years. These include double descent, grokking, and the lottery ticket
hypothesis -- among many others. Works in this area often develop ad hoc
hypotheses attempting to explain these observed phenomena on an isolated,
case-by-case basis. This position paper asserts that, in many prominent cases,
there is little evidence to suggest that these phenomena appear in real-world
applications and these efforts may be inefficient in driving progress in the
broader field. Consequently, we argue against viewing them as isolated puzzles
that require bespoke resolutions or explanations. However, despite this, we
suggest that deep learning phenomena do still offer research value by providing
unique settings in which we can refine our broad explanatory theories of more
general deep learning principles. This position is reinforced by analyzing the
research outcomes of several prominent examples of these phenomena from the
recent literature. We revisit the current norms in the research community in
approaching these problems and propose practical recommendations for future
research, aiming to ensure that progress on deep learning phenomena is well
aligned with the ultimate pragmatic goal of progress in the broader field of
deep learning.

</details>


### [414] [Hierarchical Quantized Diffusion Based Tree Generation Method for Hierarchical Representation and Lineage Analysis](https://arxiv.org/abs/2506.23287)
*Zelin Zang,WenZhe Li,Fei Chen,Yongjie Xu,Chang Yu,Zhen Lei,Stan Z. Li*

Main category: cs.LG

TL;DR: 引入了一种称为HDTree的基于扩散的单细胞分析方法，显著提升了准确性和性能，提供了新的细胞分化路径建模工具。


<details>
  <summary>Details</summary>
Motivation: 当前单细胞研究方法面临普适性与稳定性欠佳以及缺乏生成能力的挑战。

Method: 提出基于量化扩散过程的HDTree模型，利用单一的层级代码本以实现树结构关系的建模，并消除分支特定模块依赖。

Result: 在通用与单细胞数据集上的性能均优于现有方法，证明了模型的有效性。

Conclusion: HDTree为层次化谱系分析提供了更准确和高效的工具，用于更好地解析细胞分化路径并支持后续生物学任务研究。

Abstract: In single-cell research, tracing and analyzing high-throughput single-cell
differentiation trajectories is crucial for understanding complex biological
processes. Key to this is the modeling and generation of hierarchical data that
represents the intrinsic structure within datasets. Traditional methods face
limitations in terms of computational cost, performance, generative capacity,
and stability. Recent VAEs based approaches have made strides in addressing
these challenges but still require specialized network modules for each tree
branch, limiting their stability and ability to capture deep hierarchical
relationships. To overcome these challenges, we introduce diffusion-based
approach called HDTree. HDTree captures tree relationships within a
hierarchical latent space using a unified hierarchical codebook and quantized
diffusion processes to model tree node transitions. This method improves
stability by eliminating branch-specific modules and enhancing generative
capacity through gradual hierarchical changes simulated by the diffusion
process. HDTree's effectiveness is demonstrated through comparisons on both
general-purpose and single-cell datasets, where it outperforms existing methods
in terms of accuracy and performance. These contributions provide a new tool
for hierarchical lineage analysis, enabling more accurate and efficient
modeling of cellular differentiation paths and offering insights for downstream
biological tasks. The code of HDTree is available at anonymous link
https://anonymous.4open.science/r/code_HDTree_review-A8DB.

</details>


### [415] [VALID-Mol: a Systematic Framework for Validated LLM-Assisted Molecular Design](https://arxiv.org/abs/2506.23339)
*Malikussaid,Hilal Hudan Nuha*

Main category: cs.LG

TL;DR: 本文提出了VALID-Mol，一个整合化学验证和大语言模型（LLM）驱动分子设计的框架，可将生成有效化学结构的成功率从3%提高到83%。


<details>
  <summary>Details</summary>
Motivation: 探讨如何在需要事实准确性和特定领域约束的科学发现中可靠地应用大语言模型（LLMs），尤其是在药物分子设计领域中。

Method: 提出了VALID-Mol框架，结合提示设计、自动化化学验证及针对领域调优的LLM，确保生成具有化学可行性和改进性质的分子结构。

Result: 使用该框架后，生成化学结构的有效率显著提高到83%，并能生成合成可能性高且目标亲和性改善高达17倍的分子。

Conclusion: VALID-Mol为领域特定的LLM应用提供了可复现的通用方法，提高了其可靠性，且为其他科学领域中的类似应用提供了参考。

Abstract: Large Language Models (LLMs) demonstrate remarkable potential for scientific
discovery, but their application in domains requiring factual accuracy and
domain-specific constraints remains challenging. In molecular design for drug
discovery, LLMs can suggest creative molecular modifications but often produce
chemically invalid or impractical structures. We present VALID-Mol, a
systematic framework for integrating chemical validation with LLM-driven
molecular design that increases the rate of generating valid chemical
structures from 3% to 83%. Our approach combines methodical prompt engineering,
automated chemical validation, and a fine-tuned domain-adapted LLM to ensure
reliable generation of synthesizable molecules with improved properties. Beyond
the specific implementation, we contribute a generalizable methodology for
scientifically-constrained LLM applications, with quantifiable reliability
improvements. Computational predictions suggest our framework can generate
promising candidates for synthesis with up to 17-fold computationally predicted
improvements in target affinity while maintaining synthetic accessibility. We
provide a detailed analysis of our prompt engineering process, validation
architecture, and fine-tuning approach, offering a reproducible blueprint for
applying LLMs to other scientific domains where domain-specific validation is
essential.

</details>


### [416] [A case for data valuation transparency via DValCards](https://arxiv.org/abs/2506.23349)
*Keziah Naggita,Julienne LaChance*

Main category: cs.LG

TL;DR: 该研究探讨数据估值方法在数据市场中的应用，发现其存在偏差和不稳定性，并提出了具有透明性的新框架。


<details>
  <summary>Details</summary>
Motivation: 随着数据驱动机器学习的兴起，研究者希望通过数据估值方法为数据市场中的买卖双方提供公平补偿机制。

Method: 分析了9个分类数据集与6种数据估值方法，揭示了数据预处理、抽样方式等对数据估值的影响，并提出了DValCards框架。

Result: 发现现有数据估值方法对简单的算法设计选择敏感，可能加剧类别不平衡，并低估少数群体的数据价值。

Conclusion: 建议提高数据估值方法的透明性，依靠DValCards框架减少误用，并促进对负责任机器学习系统的信任。

Abstract: Following the rise in popularity of data-centric machine learning (ML),
various data valuation methods have been proposed to quantify the contribution
of each datapoint to desired ML model performance metrics (e.g., accuracy).
Beyond the technical applications of data valuation methods (e.g., data
cleaning, data acquisition, etc.), it has been suggested that within the
context of data markets, data buyers might utilize such methods to fairly
compensate data owners. Here we demonstrate that data valuation metrics are
inherently biased and unstable under simple algorithmic design choices,
resulting in both technical and ethical implications. By analyzing 9 tabular
classification datasets and 6 data valuation methods, we illustrate how (1)
common and inexpensive data pre-processing techniques can drastically alter
estimated data values; (2) subsampling via data valuation metrics may increase
class imbalance; and (3) data valuation metrics may undervalue underrepresented
group data. Consequently, we argue in favor of increased transparency
associated with data valuation in-the-wild and introduce the novel Data
Valuation Cards (DValCards) framework towards this aim. The proliferation of
DValCards will reduce misuse of data valuation metrics, including in data
pricing, and build trust in responsible ML systems.

</details>


### [417] [Federated Timeline Synthesis: Scalable and Private Methodology For Model Training and Deployment](https://arxiv.org/abs/2506.23358)
*Pawel Renc,Michal K. Grzeszczyk,Linglong Qian,Nassim Oufattole,Jeff Rasley,Arkadiusz Sitek*

Main category: cs.LG

TL;DR: 提出了一个新的框架：联邦时间线合成(FTS)，可在分布的时间序列数据基础上训练生成型基础模型，用于电子健康记录(EHR)。


<details>
  <summary>Details</summary>
Motivation: 希望通过这种方法在保证隐私的同时，实现跨机构的大规模数据整合与建模，应用于医疗健康数据的生成和预测。

Method: 将患者历史表示为PHT(token化的患者健康时间线)，用自回归变换器在本地训练；中心服务器集成权重并通过Monte Carlo模拟训练全球生成器，基于合成数据实现推断。

Result: 在MIMIC-IV数据上的五个预测任务中，合成数据训练的模型性能与真实数据训练的模型相当。

Conclusion: FTS具备隐私保护、高可扩展性，可广泛应用于医疗健康模拟、警告检测、反事实推断及合成试验设计等任务。

Abstract: We present Federated Timeline Synthesis (FTS), a novel framework for training
generative foundation models across distributed timeseries data applied to
electronic health records (EHR). At its core, FTS represents patient history as
tokenized Patient Health Timelines (PHTs), language-agnostic sequences encoding
temporal, categorical, and continuous clinical information. Each institution
trains an autoregressive transformer on its local PHTs and transmits only model
weights to a central server. The server uses the generators to synthesize a
large corpus of trajectories and train a Global Generator (GG), enabling
zero-shot inference via Monte Carlo simulation of future PHTs. We evaluate FTS
on five clinically meaningful prediction tasks using MIMIC-IV data, showing
that models trained on synthetic data generated by GG perform comparably to
those trained on real data. FTS offers strong privacy guarantees, scalability
across institutions, and extensibility to diverse prediction and simulation
tasks especially in healthcare, including counterfactual inference, early
warning detection, and synthetic trial design.

</details>


### [418] [When Additive Noise Meets Unobserved Mediators: Bivariate Denoising Diffusion for Causal Discovery](https://arxiv.org/abs/2506.23374)
*Dominik Meier,Sujai Hiremath,Promit Ghosal,Kyra Gan*

Main category: cs.LG

TL;DR: 提出了一种新的基于双变量去噪扩散的因果发现方法BiDD，提升了在存在未观测中介情况下的因果关系识别能力，同时保持了在无中介时的强劲表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有加性噪声模型方法在未测量中介存在时因果发现能力不足的问题，同时克服现有方法在有限样本条件下的脆弱性。

Method: 提出方法BiDD，通过噪声与去噪过程中基于另一个变量输入评估预测噪声的独立性，而非以往通过均方误差的损失比较以推断方向性。

Result: BiDD在合成与真实数据上的实验表现出色，在存在中介干扰的情况下优于现有方法，同时在无中介的情境下表现稳定。

Conclusion: BiDD方法在解决因未观测中介干扰的因果发现问题上取得了重要突破，具有良好的应用潜力。

Abstract: Distinguishing cause and effect from bivariate observational data is a
foundational problem in many disciplines, but challenging without additional
assumptions. Additive noise models (ANMs) are widely used to enable
sample-efficient bivariate causal discovery. However, conventional ANM-based
methods fail when unobserved mediators corrupt the causal relationship between
variables. This paper makes three key contributions: first, we rigorously
characterize why standard ANM approaches break down in the presence of
unmeasured mediators. Second, we demonstrate that prior solutions for hidden
mediation are brittle in finite sample settings, limiting their practical
utility. To address these gaps, we propose Bivariate Denoising Diffusion (BiDD)
for causal discovery, a method designed to handle latent noise introduced by
unmeasured mediators. Unlike prior methods that infer directionality through
mean squared error loss comparisons, our approach introduces a novel
independence test statistic: during the noising and denoising processes for
each variable, we condition on the other variable as input and evaluate the
independence of the predicted noise relative to this input. We prove asymptotic
consistency of BiDD under the ANM, and conjecture that it performs well under
hidden mediation. Experiments on synthetic and real-world data demonstrate
consistent performance, outperforming existing methods in mediator-corrupted
settings while maintaining strong performance in mediator-free settings.

</details>


### [419] [Do LLMs Dream of Discrete Algorithms?](https://arxiv.org/abs/2506.23408)
*Claudionor Coelho Jr,Yanen Li,Philip Tee*

Main category: cs.LG

TL;DR: 本文提出了一种结合大语言模型（LLMs）和基于逻辑推理模块的神经符号方法，通过使用Prolog谓词和可组合工具集，使LLMs能够更可靠地分解和解决复杂任务，从而提高模型的精确性和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 当前的LLMs在需要严格逻辑推理、离散决策和鲁棒解释能力的领域仍存在局限。本文旨在解决这些问题。

Method: 提出了一种将LLMs与基于逻辑的推理模块相结合的框架，整合了一阶逻辑和显式规则系统，使模型能够将复杂查询分解为可验证的子任务，并通过Prolog谓词和相关工具集组织可靠解决方案。

Result: 在DABStep基准测试上进行实验，证明了该混合系统在多步推理任务中的精准性、覆盖率和系统文档化的改进。

Conclusion: 结合LLMs和模块化逻辑推理能够提升工程标准、系统可靠性，并为跨复杂领域实现可信、可解释的AI代理提供了可扩展路径。

Abstract: Large Language Models (LLMs) have rapidly transformed the landscape of
artificial intelligence, enabling natural language interfaces and dynamic
orchestration of software components. However, their reliance on probabilistic
inference limits their effectiveness in domains requiring strict logical
reasoning, discrete decision-making, and robust interpretability. This paper
investigates these limitations and proposes a neurosymbolic approach that
augments LLMs with logic-based reasoning modules, particularly leveraging
Prolog predicates and composable toolsets. By integrating first-order logic and
explicit rule systems, our framework enables LLMs to decompose complex queries
into verifiable sub-tasks, orchestrate reliable solutions, and mitigate common
failure modes such as hallucination and incorrect step decomposition. We
demonstrate the practical benefits of this hybrid architecture through
experiments on the DABStep benchmark, showing improved precision, coverage, and
system documentation in multi-step reasoning tasks. Our results indicate that
combining LLMs with modular logic reasoning restores engineering rigor,
enhances system reliability, and offers a scalable path toward trustworthy,
interpretable AI agents across complex domains.

</details>


### [420] [BenchMake: Turn any scientific data set into a reproducible benchmark](https://arxiv.org/abs/2506.23419)
*Amanda S Barnard*

Main category: cs.LG

TL;DR: 本研究提出了一种新工具BenchMake，用于将公开的科学数据集转换为社区可用的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 解决当前计算科学中基准数据集稀缺的问题，确保新的方法能够被有效评估。

Method: 使用非负矩阵分解（NMF）技术，识别并分离凸包上的难解边界案例；将指定比例的数据实例分组到测试集中，以最大化分布差异和统计显著性。

Result: BenchMake在多个科学领域的十个公开基准数据集上进行了对比测试，与既有划分和随机划分相比，取得了优异结果。

Conclusion: BenchMake能够有效将各种格式的科学数据集转化为适用于社区的基准测试数据集，提升新算法的评测能力。

Abstract: Benchmark data sets are a cornerstone of machine learning development and
applications, ensuring new methods are robust, reliable and competitive. The
relative rarity of benchmark sets in computational science, due to the
uniqueness of the problems and the pace of change in the associated domains,
makes evaluating new innovations difficult for computational scientists. In
this paper a new tool is developed and tested to potentially turn any of the
increasing numbers of scientific data sets made openly available into a
benchmark accessible to the community. BenchMake uses non-negative matrix
factorisation to deterministically identify and isolate challenging edge cases
on the convex hull (the smallest convex set that contains all existing data
instances) and partitions a required fraction of matched data instances into a
testing set that maximises divergence and statistical significance, across
tabular, graph, image, signal and textual modalities. BenchMake splits are
compared to establish splits and random splits using ten publicly available
benchmark sets from different areas of science, with different sizes, shapes,
distributions.

</details>


### [421] [Accurate Parameter-Efficient Test-Time Adaptation for Time Series Forecasting](https://arxiv.org/abs/2506.23424)
*Heitor R. Medeiros,Hossein Sharifi-Noghabi,Gabriel L. Oliveira,Saghar Irandoust*

Main category: cs.LG

TL;DR: 提出PETSA，这是一种在测试时通过更新输入和输出上的小校准模块来调整预测模型性能的参数高效方法。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列预测模型在处理具有非平稳性的实际数据时性能下降，而现有的测试时适应方法需要更新整个模型，导致高内存和计算成本。

Method: 使用低秩适配器和动态门控，在不重新训练的情况下调整模型表示，并引入一个三部分结合的专用损失：鲁棒性、频域和局部结构对齐。

Result: PETSA在各个预测范围内显示了与基线模型相比具有竞争力或者更好的性能，同时所需参数更少。

Conclusion: PETSA可显著提高各种预测框架的适应性，同时具有更低的参数需求。

Abstract: Real-world time series often exhibit a non-stationary nature, degrading the
performance of pre-trained forecasting models. Test-Time Adaptation (TTA)
addresses this by adjusting models during inference, but existing methods
typically update the full model, increasing memory and compute costs. We
propose PETSA, a parameter-efficient method that adapts forecasters at test
time by only updating small calibration modules on the input and output. PETSA
uses low-rank adapters and dynamic gating to adjust representations without
retraining. To maintain accuracy despite limited adaptation capacity, we
introduce a specialized loss combining three components: (1) a robust term, (2)
a frequency-domain term to preserve periodicity, and (3) a patch-wise
structural term for structural alignment. PETSA improves the adaptability of
various forecasting backbones while requiring fewer parameters than baselines.
Experimental results on benchmark datasets show that PETSA achieves competitive
or better performance across all horizons. Our code is available at:
https://github.com/BorealisAI/PETSA

</details>


### [422] [Enhancing Insider Threat Detection Using User-Based Sequencing and Transformer Encoders](https://arxiv.org/abs/2506.23446)
*Mohamed Elbasheer,Adewale Akinfaderin*

Main category: cs.LG

TL;DR: 提出了用于检测内部威胁的用户序列建模方法，基于Transformer和异常分数评估，表现优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决内部威胁检测中由于恶意行为具有授权身份和行为异常微弱的难题，通过建模用户行为序列提升检测效果。

Method: 将CERT内部威胁数据集转换为时间序列结构，结合Transformer编码器建模用户行为，并使用异常分数进行无监督异常检测（包括OCSVM、LOF和iForest）。

Result: 在四个测试集上达到了96.61%准确率、99.43%召回率、96.38% F1分数、95.00% AUROC等表现，且低误检和漏检率，显著优于传统方法。

Conclusion: 利用用户行为的序列建模和高级异常检测方法可有效增强内部威胁检测，其提出方法表现优异且具广泛应用潜力。

Abstract: Insider threat detection presents unique challenges due to the authorized
status of malicious actors and the subtlety of anomalous behaviors. Existing
machine learning methods often treat user activity as isolated events, thereby
failing to leverage sequential dependencies in user behavior. In this study, we
propose a User-Based Sequencing (UBS) methodology, transforming the CERT
insider threat dataset into structured temporal sequences suitable for deep
sequential modeling. We deploy a Transformer Encoder architecture to model
benign user activity and employ its reconstruction errors as anomaly scores.
These scores are subsequently evaluated using three unsupervised outlier
detection algorithms: One-Class SVM (OCSVM), Local Outlier Factor (LOF), and
Isolation Forest (iForest). Across four rigorously designed test sets,
including combinations of multiple CERT dataset releases, our UBS-Transformer
pipeline consistently achieves state-of-the-art performance - notably 96.61%
accuracy, 99.43% recall, 96.38% F1-score, 95.00% AUROC, and exceptionally low
false negative (0.0057) and false positive (0.0571) rates. Comparative analyses
demonstrate that our approach substantially outperforms tabular and
conventional autoencoder baselines, underscoring the efficacy of sequential
user modeling and advanced anomaly detection in the insider threat domain.

</details>


### [423] [Can We Predict the Unpredictable? Leveraging DisasterNet-LLM for Multimodal Disaster Classification](https://arxiv.org/abs/2506.23462)
*Manaswi Kulahara,Gautam Siddharth Kashyap,Nipun Joshi,Arpita Soni*

Main category: cs.LG

TL;DR: 该研究提出了一种专用的大型语言模型DisasterNet-LLM，用于灾害综合分析。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以整合图像、天气记录和文本等多模态数据。

Method: 通过先进的预训练、跨模态注意机制和自适应变换器来构建DisasterNet-LLM。

Result: 实验结果显示其在灾害分类任务中的表现优于现有模型，精度为89.5%，F1得分为88.0%，AUC为0.92%，BERTScore为0.88%。

Conclusion: DisasterNet-LLM是一种高效的多模态灾害分析模型，为灾害管理提供了重要支持。

Abstract: Effective disaster management requires timely and accurate insights, yet
traditional methods struggle to integrate multimodal data such as images,
weather records, and textual reports. To address this, we propose
DisasterNet-LLM, a specialized Large Language Model (LLM) designed for
comprehensive disaster analysis. By leveraging advanced pretraining,
cross-modal attention mechanisms, and adaptive transformers, DisasterNet-LLM
excels in disaster classification. Experimental results demonstrate its
superiority over state-of-the-art models, achieving higher accuracy of 89.5%,
an F1 score of 88.0%, AUC of 0.92%, and BERTScore of 0.88% in multimodal
disaster classification tasks.

</details>


### [424] [Reconciling Attribute and Structural Anomalies for Improved Graph Anomaly Detection](https://arxiv.org/abs/2506.23469)
*Chunjing Xiao,Jiahui Lu,Xovee Xu,Fan Zhou,Tianshu Xie,Wei Lu,Lifeng Xu*

Main category: cs.LG

TL;DR: 提出了TripleAD框架，通过三通道模型检测图中属性、结构和混合异常，并解决了不同类型异常之间的干扰问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法无法均衡检测图中属性和结构异常的性能不足问题。

Method: 设计了三通道模型，分别包含多尺度属性估计模块、基于链接强化的结构估计模块，以及利用属性混合曲率的新指标，同时引入互蒸馏策略促进模块间协同。

Result: 大量实验表明TripleAD在对比强基线模型下具有较优性能。

Conclusion: TripleAD有效缓解了不同类型异常间干扰问题，在图异常检测任务中表现出色。

Abstract: Graph anomaly detection is critical in domains such as healthcare and
economics, where identifying deviations can prevent substantial losses.
Existing unsupervised approaches strive to learn a single model capable of
detecting both attribute and structural anomalies. However, they confront the
tug-of-war problem between two distinct types of anomalies, resulting in
suboptimal performance. This work presents TripleAD, a mutual
distillation-based triple-channel graph anomaly detection framework. It
includes three estimation modules to identify the attribute, structural, and
mixed anomalies while mitigating the interference between different types of
anomalies. In the first channel, we design a multiscale attribute estimation
module to capture extensive node interactions and ameliorate the over-smoothing
issue. To better identify structural anomalies, we introduce a link-enhanced
structure estimation module in the second channel that facilitates information
flow to topologically isolated nodes. The third channel is powered by an
attribute-mixed curvature, a new indicator that encapsulates both attribute and
structural information for discriminating mixed anomalies. Moreover, a mutual
distillation strategy is introduced to encourage communication and
collaboration between the three channels. Extensive experiments demonstrate the
effectiveness of the proposed TripleAD model against strong baselines.

</details>


### [425] [Sample Margin-Aware Recalibration of Temperature Scaling](https://arxiv.org/abs/2506.23492)
*Haolan Guo,Linwei Tao,Haoyang Luo,Minjing Dong,Chang Xu*

Main category: cs.LG

TL;DR: 本文提出了一种名为SMART的新方法，用于解决现代神经网络过度自信问题，结合边界不确定性和新目标函数，实现高效而准确的模型校准。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络在预测准确性上的改进伴随着其过度自信，这在安全关键场景中存在风险。因此，研究如何高效、稳定地校准模型预测成为重要问题。

Method: 提出了一种基于样本边缘感知的重校准方法（SMART），通过对两个最高logit间的差距进行调整，同时结合一种新颖的SoftECE目标函数以自适应分箱方式平衡偏差和方差。

Result: SMART在多个数据集及神经网络架构中表现出可与现有方法相比或更优的校准性能，且其模型参数需求显著减少。

Conclusion: SMART是一种轻量化、高效且分布鲁棒的神经网络预测不确定性定量化解决方案，适合实际使用场景，且代码已发布供研究者使用。

Abstract: Recent advances in deep learning have significantly improved predictive
accuracy. However, modern neural networks remain systematically overconfident,
posing risks for deployment in safety-critical scenarios. Current post-hoc
calibration methods face a fundamental dilemma: global approaches like
Temperature Scaling apply uniform adjustments across all samples, introducing
high bias despite computational efficiency, while more expressive methods that
operate on full logit distributions suffer from high variance due to noisy
high-dimensional inputs and insufficient validation data. To address these
challenges, we propose Sample Margin-Aware Recalibration of Temperature
(SMART), a lightweight, data-efficient recalibration method that precisely
scales logits based on the margin between the top two logits -- termed the
logit gap. Specifically, the logit gap serves as a denoised, scalar signal
directly tied to decision boundary uncertainty, providing a robust indicator
that avoids the noise inherent in high-dimensional logit spaces while
preserving model prediction invariance. Meanwhile, SMART employs a novel
soft-binned Expected Calibration Error (SoftECE) objective that balances model
bias and variance through adaptive binning, enabling stable parameter updates
even with extremely limited calibration data. Extensive evaluations across
diverse datasets and architectures demonstrate that SMART achieves
state-of-the-art calibration performance even with substantially fewer
parameters compared to existing parametric methods, offering a principled,
robust, and highly efficient solution for practical uncertainty quantification
in neural network predictions. The source code is available at:
https://anonymous.4open.science/r/SMART-8B11.

</details>


### [426] [FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization](https://arxiv.org/abs/2506.23516)
*Seung-Wook Kim,Seongyeol Kim,Jiah Kim,Seowon Ji,Se-Ho Lee*

Main category: cs.LG

TL;DR: 提出了FedWSQ框架，通过权值标准化和分布感知非均匀量化改进联邦学习性能，同时减少通信开销。


<details>
  <summary>Details</summary>
Motivation: 当前联邦学习在数据异质性和通信限制下表现较差，因此需要新的方法来改善其性能和通信效率。

Method: 设计了结合权值标准化（WS）和分布感知非均匀量化（DANUQ）的联邦学习框架FedWSQ。WS用于去除本地更新中的偏差成分；DANUQ通过利用本地更新统计特性来最小化量化误差。

Result: FedWSQ在数据异质性和极低通信场景下表现优异，实验结果表明在多个基准数据集上优于现有方法。

Conclusion: FedWSQ框架较好地解决了联邦学习中的数据异质性和通信限制问题，同时保证了较高的模型精度。

Abstract: Federated learning (FL) often suffers from performance degradation due to key
challenges such as data heterogeneity and communication constraints. To address
these limitations, we present a novel FL framework called FedWSQ, which
integrates weight standardization (WS) and the proposed distribution-aware
non-uniform quantization (DANUQ). WS enhances FL performance by filtering out
biased components in local updates during training, thereby improving the
robustness of the model against data heterogeneity and unstable client
participation. In addition, DANUQ minimizes quantization errors by leveraging
the statistical properties of local model updates. As a result, FedWSQ
significantly reduces communication overhead while maintaining superior model
accuracy. Extensive experiments on FL benchmark datasets demonstrate that
FedWSQ consistently outperforms existing FL methods across various challenging
FL settings, including extreme data heterogeneity and ultra-low-bit
communication scenarios.

</details>


### [427] [Both Asymptotic and Non-Asymptotic Convergence of Quasi-Hyperbolic Momentum using Increasing Batch Size](https://arxiv.org/abs/2506.23544)
*Kento Imaizumi,Hideaki Iiduka*

Main category: cs.LG

TL;DR: 提出了一种名为“mini-batch QHM”的方法，同时分析了其非渐近和渐近收敛特性。


<details>
  <summary>Details</summary>
Motivation: 目前广泛应用的动量方法在非凸优化如深度神经网络中的理论支撑有限，此论文尝试填补这一空缺。

Method: 提出了一种通用的动量方法(QHM)的改进版本，探讨增加mini-batch大小而不使用衰减学习率的策略对训练的效果。

Result: 证明了逐步增加mini-batch大小可以实现无衰减学习率条件下的高效收敛，并在实验中验证了有效性。

Conclusion: 对于深度神经网络训练，增加batch大小而非降低学习率是更优的策略，尤其在mini-batch QHM中。

Abstract: Momentum methods were originally introduced for their superiority to
stochastic gradient descent (SGD) in deterministic settings with convex
objective functions. However, despite their widespread application to deep
neural networks -- a representative case of stochastic nonconvex optimization
-- the theoretical justification for their effectiveness in such settings
remains limited. Quasi-hyperbolic momentum (QHM) is an algorithm that
generalizes various momentum methods and has been studied to better understand
the class of momentum-based algorithms as a whole. In this paper, we provide
both asymptotic and non-asymptotic convergence results for mini-batch QHM with
an increasing batch size. We show that achieving asymptotic convergence
requires either a decaying learning rate or an increasing batch size. Since a
decaying learning rate adversely affects non-asymptotic convergence, we
demonstrate that using mini-batch QHM with an increasing batch size -- without
decaying the learning rate -- can be a more effective strategy. Our experiments
show that even a finite increase in batch size can provide benefits for
training neural networks.

</details>


### [428] [A unified framework on the universal approximation of transformer-type architectures](https://arxiv.org/abs/2506.23551)
*Jingpu Cheng,Qianxiao Li,Ting Lin,Zuowei Shen*

Main category: cs.LG

TL;DR: 研究探讨了带有注意力机制的Transformer架构的通用逼近性质（UAP），提出了一个统一的理论框架，并指出“标记区分”是UAP的关键条件。


<details>
  <summary>Details</summary>
Motivation: 分析Transformer模型中的UAP特性，并拓展残差网络中相关结果至包含注意力机制的模型中。

Method: 定义并验证在注意力层上的解析性假设，通过提供一种非构造性方法，简化验证机制；同时证明具有核机制和稀疏机制的Transformer架构的UAP。

Result: 该框架不仅推广并涵盖了之前的工作，还首次为某些新型架构证明了UAP；此外，为设计具有UAP保证的新型Transformer架构提供了理论支撑。

Conclusion: 研究为不同注意力机制的Transformer模型统一提供了UAP证明，同时也为新型架构的设计提供了见解和工具。

Abstract: We investigate the universal approximation property (UAP) of transformer-type
architectures, providing a unified theoretical framework that extends prior
results on residual networks to models incorporating attention mechanisms. Our
work identifies token distinguishability as a fundamental requirement for UAP
and introduces a general sufficient condition that applies to a broad class of
architectures. Leveraging an analyticity assumption on the attention layer, we
can significantly simplify the verification of this condition, providing a
non-constructive approach in establishing UAP for such architectures. We
demonstrate the applicability of our framework by proving UAP for transformers
with various attention mechanisms, including kernel-based and sparse attention
mechanisms. The corollaries of our results either generalize prior works or
establish UAP for architectures not previously covered. Furthermore, our
framework offers a principled foundation for designing novel transformer
architectures with inherent UAP guarantees, including those with specific
functional symmetries. We propose examples to illustrate these insights.

</details>


### [429] [Transition Matching: Scalable and Flexible Generative Modeling](https://arxiv.org/abs/2506.23589)
*Neta Shaul,Uriel Singer,Itai Gat,Yaron Lipman*

Main category: cs.LG

TL;DR: 该论文提出了Transition Matching (TM)，一种新型生成范式，结合并改进了扩散/流模型和连续自回归生成方法。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散和流匹配模型在媒体生成上取得了巨大进展，但设计空间受限，而自回归模型特别是连续令牌生成开始展现整合文本和媒体生成的潜力。

Method: 提出了Transition Matching (TM)方法，并探索了三种变体：(i) Difference Transition Matching (DTM)，扩展流匹配至离散时间；(ii) Autoregressive Transition Matching (ARTM) 和 (iii) Full History Transition Matching (FHTM)，后两者将连续自回归扩展至因果生成。

Result: TM在图像质量、文本一致性与采样效率上优于现有方法；FHTM首次使全因果模型在连续域的文本生成任务中匹敌或超越了基于流的方法。

Conclusion: TM为生成任务提供了灵活的设计选择，与优越的性能表现，开辟了统一和增强生成模型的新方向。

Abstract: Diffusion and flow matching models have significantly advanced media
generation, yet their design space is well-explored, somewhat limiting further
improvements. Concurrently, autoregressive (AR) models, particularly those
generating continuous tokens, have emerged as a promising direction for
unifying text and media generation. This paper introduces Transition Matching
(TM), a novel discrete-time, continuous-state generative paradigm that unifies
and advances both diffusion/flow models and continuous AR generation. TM
decomposes complex generation tasks into simpler Markov transitions, allowing
for expressive non-deterministic probability transition kernels and arbitrary
non-continuous supervision processes, thereby unlocking new flexible design
avenues. We explore these choices through three TM variants: (i) Difference
Transition Matching (DTM), which generalizes flow matching to discrete-time by
directly learning transition probabilities, yielding state-of-the-art image
quality and text adherence as well as improved sampling efficiency. (ii)
Autoregressive Transition Matching (ARTM) and (iii) Full History Transition
Matching (FHTM) are partially and fully causal models, respectively, that
generalize continuous AR methods. They achieve continuous causal AR generation
quality comparable to non-causal approaches and potentially enable seamless
integration with existing AR text generation techniques. Notably, FHTM is the
first fully causal model to match or surpass the performance of flow-based
methods on text-to-image task in continuous domains. We demonstrate these
contributions through a rigorous large-scale comparison of TM variants and
relevant baselines, maintaining a fixed architecture, training data, and
hyperparameters.

</details>


### [430] [When Will It Fail?: Anomaly to Prompt for Forecasting Future Anomalies in Time Series](https://arxiv.org/abs/2506.23596)
*Min-Yeong Park,Won-Jeong Lee,Seong Tae Kim,Gyeong-Moon Park*

Main category: cs.LG

TL;DR: 该论文提出了A2P框架解决异常预测问题，包括AAF和SAP模块，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 预测未来异常事件对实际需求具有重要意义，但现有方法在异常预测(AP)任务上存在不足，无法精确预测未来异常发生的时间点。

Method: 提出了一种名为A2P的框架，包含Anomaly-Aware Forecasting (AAF) 和 Synthetic Anomaly Prompting (SAP) 两部分，通过学习异常之间的关系进行预测，并引入一个可学习的异常提示池(APP)模拟多样化异常模式。

Result: 通过在多个真实世界数据集上的全面实验，证明了A2P相较于最先进的方法具有优越性，能够更精准地预测未来异常。

Conclusion: A2P框架为异常预测任务提供了一种有效解决方案，为未来异常预测相关研究提供了新的思路。

Abstract: Recently, forecasting future abnormal events has emerged as an important
scenario to tackle real-world necessities. However, the solution of predicting
specific future time points when anomalies will occur, known as Anomaly
Prediction (AP), remains under-explored. Existing methods dealing with time
series data fail in AP, focusing only on immediate anomalies or failing to
provide precise predictions for future anomalies. To address the AP task, we
propose a novel framework called Anomaly to Prompt (A2P), comprised of
Anomaly-Aware Forecasting (AAF) and Synthetic Anomaly Prompting (SAP). To
enable the forecasting model to forecast abnormal time points, we adopt a
strategy to learn the relationships of anomalies. For the robust detection of
anomalies, our proposed SAP introduces a learnable Anomaly Prompt Pool (APP)
that simulates diverse anomaly patterns using signal adaptive prompt.
Comprehensive experiments on multiple real-world datasets demonstrate the
superiority of A2P over state-of-the-art methods, showcasing its ability to
predict future anomalies. Our implementation code is available at
https://github.com/KU-VGI/AP.

</details>


### [431] [A Nonlinear Low-rank Representation Model with Convolutional Neural Network for Imputing Water Quality Data](https://arxiv.org/abs/2506.23629)
*Xin Liao,Bing Yang,Cai Yu*

Main category: cs.LG

TL;DR: 该研究提出了一种结合卷积神经网络（CNN）的非线性低秩表示（NLR）模型，用于解决水质数据中因传感器故障和通信延迟导致的大量缺失数据问题，提高数据估算的准确性。


<details>
  <summary>Details</summary>
Motivation: 水质数据的完整性对于环境监测中的科学决策和生态保护至关重要，但传统的数据插补方法难以有效刻画数据的潜在动态，导致插补性能不佳。

Method: 采用一种非线性低秩表示模型，结合卷积神经网络：a）通过时间特性融合建模数据时序依赖性；b）提取非线性交互与局部模式，挖掘高阶关系特征，实现多维信息的深度融合。

Result: 通过三个真实的水质数据集进行实验研究，提出的模型在估算准确性上显著优于现有的最先进数据插补模型。

Conclusion: 该模型为复杂动态环境下的水质监测数据处理提供了一种有效途径。

Abstract: The integrity of Water Quality Data (WQD) is critical in environmental
monitoring for scientific decision-making and ecological protection. However,
water quality monitoring systems are often challenged by large amounts of
missing data due to unavoidable problems such as sensor failures and
communication delays, which further lead to water quality data becoming
High-Dimensional and Sparse (HDS). Traditional data imputation methods are
difficult to depict the potential dynamics and fail to capture the deep data
features, resulting in unsatisfactory imputation performance. To effectively
address the above issues, this paper proposes a Nonlinear Low-rank
Representation model (NLR) with Convolutional Neural Networks (CNN) for
imputing missing WQD, which utilizes CNNs to implement two ideas: a) fusing
temporal features to model the temporal dependence of data between time slots,
and b) Extracting nonlinear interactions and local patterns to mine
higher-order relationships features and achieve deep fusion of multidimensional
information. Experimental studies on three real water quality datasets
demonstrate that the proposed model significantly outperforms existing
state-of-the-art data imputation models in terms of estimation accuracy. It
provides an effective approach for handling water quality monitoring data in
complex dynamic environments.

</details>


### [432] [Learning Modular Exponentiation with Transformers](https://arxiv.org/abs/2506.23679)
*David Demitri Africa,Sara M. Kapoor,Theo Simon Sorg*

Main category: cs.LG

TL;DR: 本文通过训练4层编码器-解码器Transformer模型进行模幂运算，并分析其数值推理能力的形成过程。


<details>
  <summary>Details</summary>
Motivation: 探究Transformer模型在模幂运算中编码数论性质的能力，并探索其可解释性机制。

Method: 采用抽样策略、基于PCA的嵌入分析及激活修补等方法研究模型在数论推理中的表现。

Result: 发现模型在训练过程中通过递归操作符训练实现了性能的大幅提升，甚至能突然对相关模数实现泛化能力，且在最终层中有特定注意力头组成的子图可完全实现模幂运算。

Conclusion: Transformer模型能通过专用计算回路学习模算术，这为解释性和高效的模幂运算神经方法奠定了基础。

Abstract: Modular exponentiation is crucial to number theory and cryptography, yet
remains largely unexplored from a mechanistic interpretability standpoint. We
train a 4-layer encoder-decoder Transformer model to perform this operation and
investigate the emergence of numerical reasoning during training. Utilizing
principled sampling strategies, PCA-based embedding analysis, and activation
patching, we examine how number-theoretic properties are encoded within the
model. We find that reciprocal operand training leads to strong performance
gains, with sudden generalization across related moduli. These synchronized
accuracy surges reflect grokking-like dynamics, suggesting the model
internalizes shared arithmetic structure. We also find a subgraph consisting
entirely of attention heads in the final layer sufficient to achieve full
performance on the task of regular exponentiation. These results suggest that
transformer models learn modular arithmetic through specialized computational
circuits, paving the way for more interpretable and efficient neural approaches
to modular exponentiation.

</details>


### [433] [DABstep: Data Agent Benchmark for Multi-step Reasoning](https://arxiv.org/abs/2506.23719)
*Alex Egg,Martin Iglesias Goyanes,Friso Kingma,Andreu Mora,Leandro von Werra,Thomas Wolf*

Main category: cs.LG

TL;DR: DABstep是一个新型基准，用于评估AI在多步骤数据分析任务中的表现，包含450多个现实世界的挑战。


<details>
  <summary>Details</summary>
Motivation: 希望通过DABstep推动AI在现实数据分析任务中的能力进步。

Method: 设计了一个包含数据操控和多源上下文推理任务的基准测试，并提供自动评估机制和公开工具包。

Result: 当前领先的语言模型在该基准上的最高表现为14.55%的精确度。

Conclusion: DABstep揭示了现有技术的能力差距，为自主数据分析研究提供了一个平台。

Abstract: We introduce DABstep, a novel benchmark for evaluating AI agents on realistic
multi-step data analysis tasks. DABstep comprises over 450 real-world
challenges derived from a financial analytics platform, requiring models to
combine code-based data processing with contextual reasoning over heterogeneous
documentation. Each task demands an iterative, multi-step problem-solving
approach, testing capabilities in data manipulation, cross-referencing multiple
sources, and precise result reporting. The benchmark provides a factoid-style
answer format with automatic correctness checks for objective scoring at scale.
We evaluate leading LLM-based agents, revealing a substantial performance gap:
even the best agent achieves only 14.55% accuracy on the hardest tasks. We
detail our benchmark's design, dataset composition, task formulation,
evaluation protocol, report baseline results and analyze failure modes. DABstep
is released with a public leaderboard and toolkit to accelerate research in
autonomous data analysis.

</details>


### [434] [System-Embedded Diffusion Bridge Models](https://arxiv.org/abs/2506.23726)
*Bartlomiej Sobieski,Matthew Tivnan,Yuang Wang,Siyeop Yoon,Pengfei Jin,Dufan Wu,Quanzheng Li,Przemyslaw Biecek*

Main category: cs.LG

TL;DR: 本文提出了系统嵌入扩散桥模型（SDBs），一种新型的监督桥方法，用于解决线性逆问题，并展示了其在多种场景中的稳定表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法在求解逆问题时各有局限，监督桥方法未充分利用测量模型的结构信息。

Method: 设计了一种新的监督桥方法SDBs，通过将已知线性测量系统嵌入矩阵值随机微分方程（SDE）的系数中，实现逆问题的求解。

Result: SDBs在多种线性逆问题上取得了稳定的性能提升，并在训练和部署间系统误差下表现出良好的泛化能力。

Conclusion: SDBs为现实应用提供了有前景的解决方案，克服了现有方法的不足并提高了鲁棒性。

Abstract: Solving inverse problems -- recovering signals from incomplete or noisy
measurements -- is fundamental in science and engineering. Score-based
generative models (SGMs) have recently emerged as a powerful framework for this
task. Two main paradigms have formed: unsupervised approaches that adapt
pretrained generative models to inverse problems, and supervised bridge methods
that train stochastic processes conditioned on paired clean and corrupted data.
While the former typically assume knowledge of the measurement model, the
latter have largely overlooked this structural information. We introduce System
embedded Diffusion Bridge Models (SDBs), a new class of supervised bridge
methods that explicitly embed the known linear measurement system into the
coefficients of a matrix-valued SDE. This principled integration yields
consistent improvements across diverse linear inverse problems and demonstrates
robust generalization under system misspecification between training and
deployment, offering a promising solution to real-world applications.

</details>


### [435] [Radioactive Watermarks in Diffusion and Autoregressive Image Generative Models](https://arxiv.org/abs/2506.23731)
*Michel Meintz,Jan Dubiński,Franziska Boenisch,Adam Dziedzic*

Main category: cs.LG

TL;DR: 研究者分析了扩散模型（DMs）和图像自回归模型（IARs）的水印辐射性问题，提出了适用于IARs并且具备辐射性的水印方法，实验显示这种方法能有效追踪图像生成来源并防止未授权使用。


<details>
  <summary>Details</summary>
Motivation: 目前图像生成模型（如扩散模型和自回归模型）的训练需要大规模数据集，收集和整理成本很高，而有些人通过使用生成的图像训练自己的模型非法获利，因此需要一种方法追踪生成图像的使用来源。

Method: 研究了现有的扩散模型水印方法的不足，并基于语言模型的启发，首次提出了一种适用于自回归模型的具备辐射性水印方法，确保水印在模型训练及生成中能够保留。

Result: 实验验证了新方法的有效性，水印辐射性能在自回归模型中得到了很好的保留，可以实现生成图像来源的可靠追踪和防止滥用。

Conclusion: 本文提出的方法弥补了现有技术在自回归图像生成模型中水印辐射性方面的不足，为追踪和保护生成内容的版权提供了一种创新解决方案。

Abstract: Image generative models have become increasingly popular, but training them
requires large datasets that are costly to collect and curate. To circumvent
these costs, some parties may exploit existing models by using the generated
images as training data for their own models. In general, watermarking is a
valuable tool for detecting unauthorized use of generated images. However, when
these images are used to train a new model, watermarking can only enable
detection if the watermark persists through training and remains identifiable
in the outputs of the newly trained model - a property known as radioactivity.
We analyze the radioactivity of watermarks in images generated by diffusion
models (DMs) and image autoregressive models (IARs). We find that existing
watermarking methods for DMs fail to retain radioactivity, as watermarks are
either erased during encoding into the latent space or lost in the
noising-denoising process (during the training in the latent space). Meanwhile,
despite IARs having recently surpassed DMs in image generation quality and
efficiency, no radioactive watermarking methods have been proposed for them. To
overcome this limitation, we propose the first watermarking method tailored for
IARs and with radioactivity in mind - drawing inspiration from techniques in
large language models (LLMs), which share IARs' autoregressive paradigm. Our
extensive experimental evaluation highlights our method's effectiveness in
preserving radioactivity within IARs, enabling robust provenance tracking, and
preventing unauthorized use of their generated images.

</details>


### [436] [Training of Spiking Neural Networks with Expectation-Propagation](https://arxiv.org/abs/2506.23757)
*Dan Yao,Steve McLaughlin,Yoann Altmann*

Main category: cs.LG

TL;DR: 本文提出了一个用于训练脉冲神经网络（SNN）的统一消息传递框架，基于期望传播，避免了梯度计算。


<details>
  <summary>Details</summary>
Motivation: 提高脉冲神经网络的训练效率，并支持离散和连续权重的训练。

Method: 使用期望传播的无梯度方法学习网络参数的边缘分布，同时边缘化隐藏层输出等干扰参数。

Result: 提出的算法比梯度方法收敛更快，无需多次遍历训练数据，并且能够进行分类和回归。

Conclusion: 该框架为深度贝叶斯网络的新型高效训练方法奠定了基础，尽管无法确保收敛性，但在实践中表现良好。

Abstract: In this paper, we propose a unifying message-passing framework for training
spiking neural networks (SNNs) using Expectation-Propagation. Our gradient-free
method is capable of learning the marginal distributions of network parameters
and simultaneously marginalizes nuisance parameters, such as the outputs of
hidden layers. This framework allows for the first time, training of discrete
and continuous weights, for deterministic and stochastic spiking networks,
using batches of training samples. Although its convergence is not ensured, the
algorithm converges in practice faster than gradient-based methods, without
requiring a large number of passes through the training data. The
classification and regression results presented pave the way for new efficient
training methods for deep Bayesian networks.

</details>


### [437] [Model-driven Stochastic Trace Clustering](https://arxiv.org/abs/2506.23776)
*Jari Peeperkorn,Johannes De Smedt,Jochen De Weerdt*

Main category: cs.LG

TL;DR: 提出了一种优化基于事件日志模型的聚类方法，利用熵相关度和随机模型进行高效的聚类。


<details>
  <summary>Details</summary>
Motivation: 现有的聚类方法大多不考虑随机性，因而无法准确捕捉实际执行的动态变化，因此需要一种更精确的过程聚类方法。

Method: 采用熵相关度这一随机一致性指标，通过直接后续概率优化聚类过程，以提高随机过程模型的解释性和聚类效率。

Result: 该方法在实际数据集上优于现有方法，能够更好地表现过程行为，并凸显当引入随机性后聚类性能的变化。

Conclusion: 利用随机模型和熵相关度的聚类方法有效提高模型解释性和聚类表现，并且具备高效和良好的扩展性。

Abstract: Process discovery algorithms automatically extract process models from event
logs, but high variability often results in complex and hard-to-understand
models. To mitigate this issue, trace clustering techniques group process
executions into clusters, each represented by a simpler and more understandable
process model. Model-driven trace clustering improves on this by assigning
traces to clusters based on their conformity to cluster-specific process
models. However, most existing clustering techniques rely on either no process
model discovery, or non-stochastic models, neglecting the frequency or
probability of activities and transitions, thereby limiting their capability to
capture real-world execution dynamics. We propose a novel model-driven trace
clustering method that optimizes stochastic process models within each cluster.
Our approach uses entropic relevance, a stochastic conformance metric based on
directly-follows probabilities, to guide trace assignment. This allows
clustering decisions to consider both structural alignment with a cluster's
process model and the likelihood that a trace originates from a given
stochastic process model. The method is computationally efficient, scales
linearly with input size, and improves model interpretability by producing
clusters with clearer control-flow patterns. Extensive experiments on public
real-life datasets show that our method outperforms existing alternatives in
representing process behavior and reveals how clustering performance rankings
can shift when stochasticity is considered.

</details>


### [438] [Calibrating Graph Neural Networks with Wavelet-Aware Temperature Scaling](https://arxiv.org/abs/2506.23782)
*Xiaoyang Li,Linwei Tao,Haohui Lu,Minjing Dong,Junbin Gao,Chang Xu*

Main category: cs.LG

TL;DR: 提出了一种后处理校准框架（WATS），利用图波特来改进图神经网络的信心估计，大幅降低了校准误差，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的图校准方法依赖粗略的统计数据或嵌入，忽略了图拓扑中的细粒度结构异质性，限制了在安全关键场景中的应用。

Method: 该研究引入Wavelet-Aware Temperature Scaling (WATS)，基于可调热核图波特特征分配节点特定的温度，从而改善信心估计，不需要模型重新训练或邻居预测数据。

Result: 在七个基准数据集上，WATS表现出最低的期望校准误差（ECE），相较于其它方法在ECE上提升了最多42.3%，并将校准方差平均降低了17.24%。

Conclusion: WATS通过引入图波特特征，在保持计算效率的同时，大幅提升了校准效果，为图神经网络提供了更准确的信心估计。

Abstract: Graph Neural Networks (GNNs) have demonstrated strong predictive performance
on relational data; however, their confidence estimates often misalign with
actual predictive correctness, posing significant limitations for deployment in
safety-critical settings. While existing graph-aware calibration methods seek
to mitigate this limitation, they primarily depend on coarse one-hop
statistics, such as neighbor-predicted confidence, or latent node embeddings,
thereby neglecting the fine-grained structural heterogeneity inherent in graph
topology. In this work, we propose Wavelet-Aware Temperature Scaling (WATS), a
post-hoc calibration framework that assigns node-specific temperatures based on
tunable heat-kernel graph wavelet features. Specifically, WATS harnesses the
scalability and topology sensitivity of graph wavelets to refine confidence
estimates, all without necessitating model retraining or access to neighboring
logits or predictions. Extensive evaluations across seven benchmark datasets
with varying graph structures and two GNN backbones demonstrate that WATS
achieves the lowest Expected Calibration Error (ECE) among all compared
methods, outperforming both classical and graph-specific baselines by up to
42.3\% in ECE and reducing calibration variance by 17.24\% on average compared
with graph-specific methods. Moreover, WATS remains computationally efficient,
scaling well across graphs of diverse sizes and densities. Code will be
released based on publication.

</details>


### [439] [KAIROS: Scalable Model-Agnostic Data Valuation](https://arxiv.org/abs/2506.23799)
*Jiongli Zhu,Parjanya Prajakta Prashant,Alex Cloninger,Babak Salimi*

Main category: cs.LG

TL;DR: 本文提出KAIROS，一种可扩展的模型无关数据价值评估框架，通过最大均值差异(MMD)为每个样本分配一个分布影响分数，并实现快速在线更新，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据价值评估方法要么依赖单一模型且具有偏差，要么计算成本高，无法有效处理大规模数据。

Method: 引入基于MMD的分布影响分数，通过闭合形式公式避免重训练，支持条件核扩展以统一处理标签和特征错误，同时支持高效在线更新。

Result: 在噪音、错误标注和数据中毒基准测试中，KAIROS在准确性和运行时间上均优于当前最先进的方法，显著提升了效率和可靠性。

Conclusion: KAIROS在理论上和实践上都提供了优异的结果，包括排名对称性和密度分离的可解释性，可广泛应用于数据质量管理和AI资产评估等领域。

Abstract: Training data increasingly shapes not only model accuracy but also regulatory
compliance and market valuation of AI assets. Yet existing valuation methods
remain inadequate: model-based techniques depend on a single fitted model and
inherit its biases, while algorithm-based approaches such as Data Shapley
require costly retrainings at web scale. Recent Wasserstein-based
model-agnostic methods rely on approximations that misrank examples relative to
their true leave-one-out (LOO) utility. We introduce KAIROS, a scalable,
model-agnostic valuation framework that assigns each example a distributional
influence score: its contribution to the Maximum Mean Discrepancy (MMD) between
the empirical training distribution and a clean reference set. Unlike
Wasserstein surrogates, our MMD-based influence admits a closed-form solution
that faithfully approximates the exact LOO ranking within $O(1/N^2)$ error,
requires no retraining, and naturally extends to conditional kernels for
unified label- and feature-error detection. Moreover, KAIROS supports efficient
online updates: when a new batch of size m arrives, all scores can be updated
in $O(mN)$ time, delivering up to 50x speedup without compromising ranking
quality. Empirical evaluations on noise, mislabeling, and poisoning benchmarks
show that KAIROS consistently outperforms state-of-the-art model-, Shapley-,
and Wasserstein-based baselines in both accuracy and runtime. We provide
rigorous theoretical guarantees, including symmetry for reproducible rankings
and density-separation for interpretable thresholds.

</details>


### [440] [Towards the Training of Deeper Predictive Coding Neural Networks](https://arxiv.org/abs/2506.23800)
*Chang Qi,Matteo Forasassi,Thomas Lukasiewicz,Tommaso Salvatori*

Main category: cs.LG

TL;DR: 过去研究表明预测性编码网络训练在深层网络中表现不佳。本文通过衡量误差分布和平衡权重更新两种新方法，提升了深度网络的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的预测性编码网络在深度超出五到七层时表现显著下降，需探索提升深层网络训练性能的方法。

Method: 提出两种新方法：一是通过精度加权优化潜变量，重平衡层间能量分布；二是提出新的权重更新机制以减少深层误差累积。

Result: 实验表明在超过七层的网络上，图像分类任务的测试准确性显著提升，与使用反向传播的类似模型表现相当。

Conclusion: 对放松阶段的深入理解是提高使用平衡传播训练模型能力的关键，为其应用于复杂任务开辟了新可能性。

Abstract: Predictive coding networks trained with equilibrium propagation are neural
models that perform inference through an iterative energy minimization process.
Previous studies have demonstrated their effectiveness in shallow
architectures, but show significant performance degradation when depth exceeds
five to seven layers. In this work, we show that the reason behind this
degradation is due to exponentially imbalanced errors between layers during
weight updates, and predictions from the previous layer not being effective in
guiding updates in deeper layers. We address the first issue by introducing two
novel methods to optimize the latent variables that use precision-weighting to
re-balance the distribution of energy among layers during the `relaxation
phase', and the second issue by proposing a novel weight update mechanism that
reduces error accumulation in deeper layers. Empirically, we test our methods
on a large number of image classification tasks, resulting in large
improvements in test accuracy across networks with more than seven layers, with
performances comparable to those of backprop on similar models. These findings
suggest that a better understanding of the relaxation phase is important to
train models using equilibrium propagation at scale, and open new possibilities
for their application in complex tasks.

</details>


### [441] [Adaptive Out-of-Control Point Pattern Detection in Sequential Random Finite Set Observations](https://arxiv.org/abs/2506.23802)
*Konstantinos Bourazas,Savvas Papaioannou,Panayiotis Kolios*

Main category: cs.LG

TL;DR: 提出了一种新的用于监测序列型随机有限集(RFS)观测的自适应异常检测框架，通过检测统计行为的偏差来区分正常数据和异常数据。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个系统，能够在线学习正常行为，并动态适应行为变化，从而准确识别异常点模式。

Method: 引入一种新的RFS后验分布类别，称为Power Discounting Posteriors (PD)，可适应数据变化，并通过新颖的预测后验密度函数实现异常检测。

Result: 通过广泛的定性和定量仿真实验验证了其有效性。

Conclusion: 该框架能够有效学习和适应正常数据行为变化，并准确检测异常点模式，对异常检测任务具有创新性贡献。

Abstract: In this work we introduce a novel adaptive anomaly detection framework
specifically designed for monitoring sequential random finite set (RFS)
observations. Our approach effectively distinguishes between In-Control data
(normal) and Out-Of-Control data (anomalies) by detecting deviations from the
expected statistical behavior of the process. The primary contributions of this
study include the development of an innovative RFS-based framework that not
only learns the normal behavior of the data-generating process online but also
dynamically adapts to behavioral shifts to accurately identify abnormal point
patterns. To achieve this, we introduce a new class of RFS-based posterior
distributions, named Power Discounting Posteriors (PD), which facilitate
adaptation to systematic changes in data while enabling anomaly detection of
point pattern data through a novel predictive posterior density function. The
effectiveness of the proposed approach is demonstrated by extensive qualitative
and quantitative simulation experiments.

</details>


### [442] [SGD with Adaptive Preconditioning: Unified Analysis and Momentum Acceleration](https://arxiv.org/abs/2506.23803)
*Dmitry Kovalev*

Main category: cs.LG

TL;DR: 本文重新探讨了带自适应预处理的随机梯度下降（SGD），并统一分析了其收敛性及噪声假设。此外，还证明了通过Nesterov动量可进一步加速方法的收敛。


<details>
  <summary>Details</summary>
Motivation: 为了分析带有自适应预处理的SGD算法，并揭示其与现有算法的关系，同时探讨其加速可能性。

Method: 通过统一的收敛性分析框架对SGD中的多种自适应算法进行研究，并结合Nesterov动量探讨其加速效果。

Result: 提出了SGD自适应预处理的理论贡献，总结出了多种算法的收敛性，并首次证明了动量与自适应预处理可协同加速。

Conclusion: 自适应预处理和动量的协作能为算法带来加速效果，这为Adam算法的高效性提供了新的理论解释。

Abstract: In this paper, we revisit stochastic gradient descent (SGD) with AdaGrad-type
preconditioning. Our contributions are twofold. First, we develop a unified
convergence analysis of SGD with adaptive preconditioning under anisotropic or
matrix smoothness and noise assumptions. This allows us to recover
state-of-the-art convergence results for several popular adaptive gradient
methods, including AdaGrad-Norm, AdaGrad, and ASGO/One-sided Shampoo. In
addition, we establish the fundamental connection between two recently proposed
algorithms, Scion and DASGO, and provide the first theoretical guarantees for
the latter. Second, we show that the convergence of methods like AdaGrad and
DASGO can be provably accelerated beyond the best-known rates using Nesterov
momentum. Consequently, we obtain the first theoretical justification that
AdaGrad-type algorithms can simultaneously benefit from both diagonal
preconditioning and momentum, which may provide an ultimate explanation for the
practical efficiency of Adam.

</details>


### [443] [Supercm: Revisiting Clustering for Semi-Supervised Learning](https://arxiv.org/abs/2506.23824)
*Durgesh Singh,Ahcene Boubekki,Robert Jenssen,Michael C. Kampffmeyer*

Main category: cs.LG

TL;DR: 这篇文章提出了一种通过扩展可微分聚类模块来实现简单、高效的半监督学习新方法。


<details>
  <summary>Details</summary>
Motivation: 当前半监督学习主要关注通过一致性正则化或熵最小化的方式提升表现，但常带来复杂的模型训练过程。

Method: 文章提出了一种基于可微分聚类模块并利用带注释数据引导聚类中心的新方法，从而实现半监督学习的端到端训练。

Result: 与仅监督训练的模型相比，该方法提升了性能，并可以联合其他半监督学习方法进一步提高效果。

Conclusion: 这一研究为半监督学习提供了一种高效且简化的实现方式，并展现了其良好的扩展能力。

Abstract: The development of semi-supervised learning (SSL) has in recent years largely
focused on the development of new consistency regularization or entropy
minimization approaches, often resulting in models with complex training
strategies to obtain the desired results. In this work, we instead propose a
novel approach that explicitly incorporates the underlying clustering
assumption in SSL through extending a recently proposed differentiable
clustering module. Leveraging annotated data to guide the cluster centroids
results in a simple end-to-end trainable deep SSL approach. We demonstrate that
the proposed model improves the performance over the supervised-only baseline
and show that our framework can be used in conjunction with other SSL methods
to further boost their performance.

</details>


### [444] [EFPI: Elastic Formation and Position Identification in Football (Soccer) using Template Matching and Linear Assignment](https://arxiv.org/abs/2506.23843)
*Joris Bekkers*

Main category: cs.LG

TL;DR: 论文提出了EFPI方法，通过先验的静态阵型模板与成本最小化来识别足球中的阵型和球员位置。


<details>
  <summary>Details</summary>
Motivation: 足球战术分析需要对球队阵型和球员位置有深入理解，该研究旨在通过数据驱动方式实现此目标。

Method: 使用线性分配算法，将球员位置与模板阵型位置进行最优匹配，最小化位置偏差，并加入稳定性参数减少无关阵型切换。

Result: 提出的EFPI方法能够准确识别不同时间尺度下的阵型和位置，广泛适用于多种场景，并已开源。

Conclusion: EFPI提供了一种灵活且数据驱动的解决方案，推动了足球战术分析的进步。

Abstract: Understanding team formations and player positioning is crucial for tactical
analysis in football (soccer). This paper presents a flexible method for
formation recognition and player position assignment in football using
predefined static formation templates and cost minimization from spatiotemporal
tracking data, called EFPI. Our approach employs linear sum assignment to
optimally match players to positions within a set of template formations by
minimizing the total distance between actual player locations and template
positions, subsequently selecting the formation with the lowest assignment
cost. To improve accuracy, we scale actual player positions to match the
dimensions of these formation templates in both width and length. While the
method functions effectively on individual frames, it extends naturally to
larger game segments such as complete periods, possession sequences or specific
intervals (e.g. 10 second intervals, 5 minute intervals etc.). Additionally, we
incorporate an optional stability parameter that prevents unnecessary formation
changes when assignment costs differ only marginally between time segments.
EFPI is available as open-source code through the unravelsports Python package.

</details>


### [445] [Use Sparse Autoencoders to Discover Unknown Concepts, Not to Act on Known Concepts](https://arxiv.org/abs/2506.23845)
*Kenny Peng,Rajiv Movva,Jon Kleinberg,Emma Pierson,Nikhil Garg*

Main category: cs.LG

TL;DR: 本文探讨了稀疏自编码器（SAEs）在已知概念应用中的局限性及其在探索未知概念中的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究如何调整针对SAEs的不同观点之间的矛盾，重新定义其在机器学习中的实际价值。

Method: 将SAEs应用区分为已知概念与未知概念两类并进行理论分析，以及展示SAEs在不同行业的典型用例。

Result: 发现SAEs更适合用于发掘未知概念，而非处理已知概念，可在机器学习解释性、公平性，以及社会和健康科学中发挥作用。

Conclusion: 通过重新定义SAEs的使用场景，提升对其潜在强大功能的理解，扩展了其应用场景。

Abstract: While sparse autoencoders (SAEs) have generated significant excitement, a
series of negative results have added to skepticism about their usefulness.
Here, we establish a conceptual distinction that reconciles competing
narratives surrounding SAEs. We argue that while SAEs may be less effective for
acting on known concepts, SAEs are powerful tools for discovering unknown
concepts. This distinction cleanly separates existing negative and positive
results, and suggests several classes of SAE applications. Specifically, we
outline use cases for SAEs in (i) ML interpretability, explainability,
fairness, auditing, and safety, and (ii) social and health sciences.

</details>


### [446] [When Plants Respond: Electrophysiology and Machine Learning for Green Monitoring Systems](https://arxiv.org/abs/2506.23872)
*Eduard Buss,Till Aust,Heiko Hamann*

Main category: cs.LG

TL;DR: 本文探索了植物作为生态监测新型传感器的潜力，并通过生物混合系统实现植物、生物电信号记录设备与AI分析的结合。


<details>
  <summary>Details</summary>
Motivation: 探讨利用植物内在生理状态和环境条件传递信息的可能性，以进一步发展环境监测及精准农业。

Method: 使用常春藤（Hedera helix）搭载可穿戴设备“PhytoNode”记录生物电信号，并通过自动化机器学习（AutoML）分析数据，预测植物生理信号与环境条件的关联。

Result: 在长达五个月的实验中，建立的分类模型在二分类任务中达到了高达95%的宏F1得分，并验证了AutoML优于手动调参，选取统计特征子集进一步提高准确率。

Conclusion: 实现了将植物与设备集成的自我维持型生物混合系统，可在真实条件下进行环境监测，为可持续生态监测的发展做出贡献。

Abstract: Living plants, while contributing to ecological balance and climate
regulation, also function as natural sensors capable of transmitting
information about their internal physiological states and surrounding
conditions. This rich source of data provides potential for applications in
environmental monitoring and precision agriculture. With integration into
biohybrid systems, we establish novel channels of physiological signal flow
between living plants and artificial devices. We equipped *Hedera helix* with a
plant-wearable device called PhytoNode to continuously record the plant's
electrophysiological activity. We deployed plants in an uncontrolled outdoor
environment to map electrophysiological patterns to environmental conditions.
Over five months, we collected data that we analyzed using state-of-the-art and
automated machine learning (AutoML). Our classification models achieve high
performance, reaching macro F1 scores of up to 95 percent in binary tasks.
AutoML approaches outperformed manual tuning, and selecting subsets of
statistical features further improved accuracy. Our biohybrid living system
monitors the electrophysiology of plants in harsh, real-world conditions. This
work advances scalable, self-sustaining, and plant-integrated living biohybrid
systems for sustainable environmental monitoring.

</details>


### [447] [Chain of Thought in Order: Discovering Learning-Friendly Orders for Arithmetic](https://arxiv.org/abs/2506.23875)
*Yuta Sato,Kazuhiko Kawamoto,Hiroshi Kera*

Main category: cs.LG

TL;DR: 本文提出了一种方法，通过重新排列解码器输入的顺序以提高Transformer学习算术任务的效果。


<details>
  <summary>Details</summary>
Motivation: 研究中发现，在变换器中，推理步骤的顺序对算法的学习能力有重要影响。提出这一任务以优化这些顺序。

Method: 采用两阶段分层方法，对解码器的输入序列进行重排序。先通过混合序列训练找出快速损失下降的顺序，然后进一步优化。

Result: 实验验证了在四个敏感顺序的算术任务中，该方法在几十亿候选顺序中找到了学习友好的顺序，特别是在乘法任务中确认了先前研究的反向数字顺序。

Conclusion: 本文证明了通过优化推理步骤顺序，可以显著提升Transformer对顺序敏感型任务的学习能力。

Abstract: The chain of thought is fundamental in Transformers, which is to perform
step-by-step reasoning. Besides what intermediate steps work, the order of
these steps critically affects the difficulty of the reasoning. This study
addresses a novel task of unraveling chain of thought - reordering decoder
input tokens to a learning-friendly sequence for Transformers to learn
arithmetic tasks. The proposed pipeline first trains a Transformer on a mixture
of target sequences arranged in different orders and then identifies benign
orders as those with fast loss drops in the early stage. As the search space
grows factorially with sequence length, we propose a two-stage hierarchical
approach for inter- and intra-block reordering. Experiments on four
order-sensitive arithmetic tasks show that our method identifies a
learning-friendly order out of a few billion candidates. Notably, on the
multiplication task, it recovered the reverse-digit order reported in prior
studies.

</details>


### [448] [Reinforcement Learning for Synchronised Flow Control in a Dual-Gate Resin Infusion System](https://arxiv.org/abs/2506.23923)
*Miguel Camacho-Sánchez,Fernando García-Torres,Jesper John Lisegaard,Rocío del Amor,Sankhya Mohanty,Valery Naranjo*

Main category: cs.LG

TL;DR: 本文利用强化学习（RL）方法控制树脂灌注和传输成形过程中的树脂流动，实现树脂流动态同步。


<details>
  <summary>Details</summary>
Motivation: 研究动机是提升高性能纤维增强聚合物复合材料制造过程中树脂流动的控制精度，以提高产品质量和结构完整性。

Method: 使用基于Proximal Policy Optimisation（PPO）的强化学习方法，在部分可观察环境下优化树脂流动前沿的同步控制。

Result: 实验结果表明，该强化学习方法可以实现树脂流动态的精确收敛，并有效提升过程控制和产品质量。

Conclusion: 强化学习方法在复合材料制造中具有潜力，可以改善树脂灌注工艺的控制并提高最终产品的质量。

Abstract: Resin infusion (RI) and resin transfer moulding (RTM) are critical processes
for the manufacturing of high-performance fibre-reinforced polymer composites,
particularly for large-scale applications such as wind turbine blades.
Controlling the resin flow dynamics in these processes is critical to ensure
the uniform impregnation of the fibre reinforcements, thereby preventing
residual porosities and dry spots that impact the consequent structural
integrity of the final component. This paper presents a reinforcement learning
(RL) based strategy, established using process simulations, for synchronising
the different resin flow fronts in an infusion scenario involving two resin
inlets and a single outlet. Using Proximal Policy Optimisation (PPO), our
approach addresses the challenge of managing the fluid dynamics in a partially
observable environment. The results demonstrate the effectiveness of the RL
approach in achieving an accurate flow convergence, highlighting its potential
towards improving process control and product quality in composites
manufacturing.

</details>


### [449] [Bridging the Gap with Retrieval-Augmented Generation: Making Prosthetic Device User Manuals Available in Marginalised Languages](https://arxiv.org/abs/2506.23958)
*Ikechukwu Ogbonna,Lesley Davidson,Soumya Banerjee,Abhishek Dasgupta,Laurence Kenney,Vikranth Harthikote Nagaraja*

Main category: cs.LG

TL;DR: 本研究开发了一个AI框架，将复杂的医疗文档（如假肢设备用户手册）翻译成边缘化语言，提升非洲欠发达群体的医疗信息可及性。


<details>
  <summary>Details</summary>
Motivation: 非洲许多地区因语言和文化壁垒难以获取重要的医疗信息，这种研究旨在解决这一问题。

Method: 研究提出了一个开放源码的AI框架，通过结合RAG管线和NLP模型处理和翻译复杂医疗文档，并支持多语言生成问答。

Result: 系统能够实时翻译和回答问题，促进用户获取设备使用说明、治疗协议和安全信息，辅助患者及医务人员进行医疗决策。

Conclusion: 该框架能够提高医疗信息的可及性，为边缘化语言社群提供重要支持，具有广泛适应性和扩展潜力。

Abstract: Millions of people in African countries face barriers to accessing healthcare
due to language and literacy gaps. This research tackles this challenge by
transforming complex medical documents -- in this case, prosthetic device user
manuals -- into accessible formats for underserved populations. This case study
in cross-cultural translation is particularly pertinent/relevant for
communities that receive donated prosthetic devices but may not receive the
accompanying user documentation. Or, if available online, may only be available
in formats (e.g., language and readability) that are inaccessible to local
populations (e.g., English-language, high resource settings/cultural context).
The approach is demonstrated using the widely spoken Pidgin dialect, but our
open-source framework has been designed to enable rapid and easy extension to
other languages/dialects. This work presents an AI-powered framework designed
to process and translate complex medical documents, e.g., user manuals for
prosthetic devices, into marginalised languages. The system enables users --
such as healthcare workers or patients -- to upload English-language medical
equipment manuals, pose questions in their native language, and receive
accurate, localised answers in real time. Technically, the system integrates a
Retrieval-Augmented Generation (RAG) pipeline for processing and semantic
understanding of the uploaded manuals. It then employs advanced Natural
Language Processing (NLP) models for generative question-answering and
multilingual translation. Beyond simple translation, it ensures accessibility
to device instructions, treatment protocols, and safety information, empowering
patients and clinicians to make informed healthcare decisions.

</details>


### [450] [LLM Agents Are the Antidote to Walled Gardens](https://arxiv.org/abs/2506.23978)
*Samuele Marro,Philip Torr*

Main category: cs.LG

TL;DR: 本文讨论了当前互联网应用层的封闭性，提出基于LLM的代理能够通过自动数据格式翻译实现普遍互操作性，从而削弱垄断并提升数据流通，但也伴随新安全风险和技术债务。


<details>
  <summary>Details</summary>
Motivation: 探讨如何打破现有互联网应用层的封闭性和垄断行为，促进数据流畅及用户自由。

Method: 通过引入LLM驱动的智能代理，实现自动化的数据格式翻译和与人类设计界面的交互，从而大幅降低互操作性成本。

Result: 提出普遍互操作性的概念，认为此方式能够促进数据便携性，削弱垄断行为，但也可能引发安全隐患和技术债务。

Conclusion: ML社区应积极拥抱这一趋势，同时构建必要的框架以应对相关风险，从而实现用户自由和竞争市场的平衡。

Abstract: While the Internet's core infrastructure was designed to be open and
universal, today's application layer is dominated by closed, proprietary
platforms. Open and interoperable APIs require significant investment, and
market leaders have little incentive to enable data exchange that could erode
their user lock-in. We argue that LLM-based agents fundamentally disrupt this
status quo. Agents can automatically translate between data formats and
interact with interfaces designed for humans: this makes interoperability
dramatically cheaper and effectively unavoidable. We name this shift universal
interoperability: the ability for any two digital services to exchange data
seamlessly using AI-mediated adapters. Universal interoperability undermines
monopolistic behaviours and promotes data portability. However, it can also
lead to new security risks and technical debt. Our position is that the ML
community should embrace this development while building the appropriate
frameworks to mitigate the downsides. By acting now, we can harness AI to
restore user freedom and competitive markets without sacrificing security.

</details>


### [451] [ADReFT: Adaptive Decision Repair for Safe Autonomous Driving via Reinforcement Fine-Tuning](https://arxiv.org/abs/2506.23960)
*Mingfei Cheng,Xiaofei Xie,Renzhi Wang,Yuan Zhou,Ming Hu*

Main category: cs.LG

TL;DR: 本文提出了一种新的在线修复方法ADReFT，通过深度学习和强化学习提升自动驾驶系统的安全性和适应性，比现有方法更高效。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统在性能和设计上仍存在局限性，容易导致安全问题，现有修复方法无法有效解决这些问题，并影响驾驶体验，因此需要一种更具适应性和效率的解决方案。

Method: 介绍了一种新的修复方法ADReFT，它基于变压器模型，包括状态监控器和决策调整器两个模块。通过监督学习预训练与强化学习微调，模型可评估状态的安全严重性，并生成适应性修复行为。

Result: 实验结果表明，ADReFT在修复性能上优于现有方法。

Conclusion: ADReFT在提高自动驾驶系统运行时的安全性和可靠性方面表现出色，具备推广潜力。

Abstract: Autonomous Driving Systems (ADSs) continue to face safety-critical risks due
to the inherent limitations in their design and performance capabilities.
Online repair plays a crucial role in mitigating such limitations, ensuring the
runtime safety and reliability of ADSs. Existing online repair solutions
enforce ADS compliance by transforming unacceptable trajectories into
acceptable ones based on predefined specifications, such as rule-based
constraints or training datasets. However, these approaches often lack
generalizability, adaptability and tend to be overly conservative, resulting in
ineffective repairs that not only fail to mitigate safety risks sufficiently
but also degrade the overall driving experience. To address this issue, we
propose Adaptive Decision Repair (ADReFT), a novel and effective repair method
that identifies safety-critical states through offline learning from failed
tests and generates appropriate mitigation actions to improve ADS safety.
Specifically, ADReFT incorporates a transformer-based model with two joint
heads, State Monitor and Decision Adapter, designed to capture complex driving
environment interactions to evaluate state safety severity and generate
adaptive repair actions. Given the absence of oracles for state safety
identification, we first pretrain ADReFT using supervised learning with coarse
annotations, i.e., labeling states preceding violations as positive samples and
others as negative samples. It establishes ADReFT's foundational capability to
mitigate safety-critical violations, though it may result in somewhat
conservative mitigation strategies. Therefore, we subsequently finetune ADReFT
using reinforcement learning to improve its initial capability and generate
more precise and contextually appropriate repair decisions. Our evaluation
results illustrate that ADReFT achieves better repair performance.

</details>


### [452] [UMA: A Family of Universal Models for Atoms](https://arxiv.org/abs/2506.23971)
*Brandon M. Wood,Misko Dzamba,Xiang Fu,Meng Gao,Muhammed Shuaibi,Luis Barroso-Luque,Kareem Abdelmaqsoud,Vahe Gharakhanyan,John R. Kitchin,Daniel S. Levine,Kyle Michel,Anuroop Sriram,Taco Cohen,Abhishek Das,Ammar Rizvi,Sushree Jagriti Sahoo,Zachary W. Ulissi,C. Lawrence Zitnick*

Main category: cs.LG

TL;DR: Meta FAIR开发了一种被称为通用原子模型（UMA）的模型家族，能够快速准确地从原子模拟中计算化学和材料科学相关属性。


<details>
  <summary>Details</summary>
Motivation: 为了提高化学和材料科学中的关键任务（如药物发现和能源存储）的效率，需要一种能够快速准确计算原子模拟属性的通用工具。

Method: 通过整合跨多个化学领域（分子、材料和催化剂）的数据，训练了一种大规模的、多领域通用原子模型UMA，结合混合线性专家的新架构设计，允许在增加模型容量的同时保持高速度。

Result: 单一UMA模型在多种应用领域中的性能与专用模型相当甚至更好，实现了跨领域的高性能且无需微调。

Conclusion: 发布的UMA代码、权重及相关数据，将帮助社区加速计算工作流并开发更强大的AI模型。

Abstract: The ability to quickly and accurately compute properties from atomic
simulations is critical for advancing a large number of applications in
chemistry and materials science including drug discovery, energy storage, and
semiconductor manufacturing. To address this need, Meta FAIR presents a family
of Universal Models for Atoms (UMA), designed to push the frontier of speed,
accuracy, and generalization. UMA models are trained on half a billion unique
3D atomic structures (the largest training runs to date) by compiling data
across multiple chemical domains, e.g. molecules, materials, and catalysts. We
develop empirical scaling laws to help understand how to increase model
capacity alongside dataset size to achieve the best accuracy. The UMA small and
medium models utilize a novel architectural design we refer to as mixture of
linear experts that enables increasing model capacity without sacrificing
speed. For example, UMA-medium has 1.4B parameters but only ~50M active
parameters per atomic structure. We evaluate UMA models on a diverse set of
applications across multiple domains and find that, remarkably, a single model
without any fine-tuning can perform similarly or better than specialized
models. We are releasing the UMA code, weights, and associated data to
accelerate computational workflows and enable the community to continue to
build increasingly capable AI models.

</details>


### [453] [A Scalable Approach for Safe and Robust Learning via Lipschitz-Constrained Networks](https://arxiv.org/abs/2506.23977)
*Zain ul Abdeen,Vassilis Kekatos,Ming Jin*

Main category: cs.LG

TL;DR: 本文提出了一种新的凸优化框架，用于在训练神经网络时施加Lipschitz约束，通过随机子空间矩阵不等式(RS-LMI)实现了对全局约束的分解，显著提升了训练的效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 目前的Lipschitz约束神经网络训练方法受制于非凸优化问题和全局半定规划(SDP)，严重影响了可扩展性和实际应用需求。

Method: 通过环变换重新参数化神经网络并引入一个凸的可容许性条件，结合随机子空间线性矩阵不等式(RS-LMI)方法，将全局约束分解为分层局部约束，从而实现高效且可验证的鲁棒性训练框架。

Result: 在MNIST、CIFAR-10和ImageNet测试集上的实验表明，该框架在保证模型鲁棒性的同时，达到了有竞争力的准确性，并显著提高了训练的Lipschitz界优化效果和运行效率。

Conclusion: 提出的RS-LMI训练框架解决了全局Lipschitz约束训练方法的扩展性问题，在准确性和鲁棒性之间取得了良好平衡，是神经网络安全应用的一个重要进展。

Abstract: Certified robustness is a critical property for deploying neural networks
(NN) in safety-critical applications. A principle approach to achieving such
guarantees is to constrain the global Lipschitz constant of the network.
However, accurate methods for Lipschitz-constrained training often suffer from
non-convex formulations and poor scalability due to reliance on global
semidefinite programs (SDPs). In this letter, we propose a convex training
framework that enforces global Lipschitz constraints via semidefinite
relaxation. By reparameterizing the NN using loop transformation, we derive a
convex admissibility condition that enables tractable and certifiable training.
While the resulting formulation guarantees robustness, its scalability is
limited by the size of global SDP. To overcome this, we develop a randomized
subspace linear matrix inequalities (RS-LMI) approach that decomposes the
global constraints into sketched layerwise constraints projected onto
low-dimensional subspaces, yielding a smooth and memory-efficient training
objective. Empirical results on MNIST, CIFAR-10, and ImageNet demonstrate that
the proposed framework achieves competitive accuracy with significantly
improved Lipschitz bounds and runtime performance.

</details>


### [454] [The Jacobian and Hessian of the Kullback-Leibler Divergence between Multivariate Gaussian Distributions (Technical Report)](https://arxiv.org/abs/2506.23996)
*Juan Maroñas*

Main category: cs.LG

TL;DR: 本文讨论了两个多元高斯分布之间的KL散度Jacobian和Hessian矩阵的推导方法。


<details>
  <summary>Details</summary>
Motivation: 通过利用一阶和二阶微分，为研究多元高斯分布间的KL散度提供更深的理论理解。

Method: 基于微分理论以及现有文献中的推导方法，详细推导了Jacobian和Hessian矩阵的计算步骤和概念基础。

Result: 分结果和推导两部分进行；结果部分总结了结论，推导部分详细叙述推导原理和所用技巧。

Conclusion: 通过详细推导展示了KL散度相关指标的计算方法，提供了理论分析和应用的完整理解。

Abstract: This document shows how to obtain the Jacobian and Hessian matrices of the
Kullback-Leibler divergence between two multivariate Gaussian distributions,
using the first and second-order differentials. The presented derivations are
based on the theory presented by \cite{magnus99}. I've also got great
inspiration from some of the derivations in \cite{minka}.
  Since I pretend to be at most didactic, the document is split into a summary
of results and detailed derivations on each of the elements involved, with
specific references to the tricks used in the derivations, and to many of the
underlying concepts.

</details>


### [455] [The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models](https://arxiv.org/abs/2506.24000)
*Lijun Sheng,Jian Liang,Ran He,Zilei Wang,Tieniu Tan*

Main category: cs.LG

TL;DR: 本文提出了TTA-VLM基准，综合评估测试时适应（TTA）方法在视觉语言模型（VLM）中的表现，指出当前TTA方法的局限性并提供改进方向。


<details>
  <summary>Details</summary>
Motivation: 当前TTA方法在基准结果复制、评估指标、实验设置以及分析深度方面存在不足，影响方法间公平比较及其实用性。

Method: 设计TTA-VLM基准，集成8种episodic TTA方法、7种在线TTA方法，统一框架内进行在15个数据集上的评价，扩展评估范围涵盖基于Sigmoid损失训练的SigLIP模型及 CoOp、MaPLe、TeCoA等训练时微调方法，采用多维度评估指标。

Result: 实验表明现有TTA方法的改进收益有限，与训练时微调方法协同性差，并常伴随模型可信度下降。

Conclusion: TTA-VLM提供了公平比较和全面评价TTA方法的新基准，作者期望促进更可靠且具广泛适用性的TTA策略研究。

Abstract: Test-time adaptation (TTA) methods have gained significant attention for
enhancing the performance of vision-language models (VLMs) such as CLIP during
inference, without requiring additional labeled data. However, current TTA
researches generally suffer from major limitations such as duplication of
baseline results, limited evaluation metrics, inconsistent experimental
settings, and insufficient analysis. These problems hinder fair comparisons
between TTA methods and obscure their practical strengths and weaknesses. To
address these challenges, we introduce TTA-VLM, a comprehensive benchmark for
evaluating TTA methods on VLMs. Our benchmark implements 8 episodic TTA and 7
online TTA methods within a unified and reproducible framework, and evaluates
them across 15 widely used datasets. Unlike prior studies focused solely on
CLIP, we extend the evaluation to SigLIP--a model trained with a Sigmoid
loss--and include training-time tuning methods such as CoOp, MaPLe, and TeCoA
to assess generality. Beyond classification accuracy, TTA-VLM incorporates
various evaluation metrics, including robustness, calibration,
out-of-distribution detection, and stability, enabling a more holistic
assessment of TTA methods. Through extensive experiments, we find that 1)
existing TTA methods produce limited gains compared to the previous pioneering
work; 2) current TTA methods exhibit poor collaboration with training-time
fine-tuning methods; 3) accuracy gains frequently come at the cost of reduced
model trustworthiness. We release TTA-VLM to provide fair comparison and
comprehensive evaluation of TTA methods for VLMs, and we hope it encourages the
community to develop more reliable and generalizable TTA strategies.

</details>


### [456] [Provably Efficient and Agile Randomized Q-Learning](https://arxiv.org/abs/2506.24005)
*He Wang,Xingyu Xu,Yuejie Chi*

Main category: cs.LG

TL;DR: 提出了一种新的Q-learning变体，RandomizedQ，用于提升采样探索和策略更新的动态性，解决了目前算法的计算复杂性与响应速度问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于贝叶斯的探索在强化学习特别是基于模型的方法上表现优越，但在无模型场景下的理论理解有限，现有方法存在计算不可行或阶段性策略更新导致的响应缓慢问题。

Method: 设计了RandomizedQ算法，通过采样探索结合逐步策略更新的方式，在表格型强化学习中实现理论上的$O(\sqrt{H^5SAT})$后悔值界。

Result: 在常用基准测试中，RandomizedQ在实践中显著优于现有的基于奖励和贝叶斯探索的Q-learning变体，并在一定条件下取得对数级别的后悔值界。

Conclusion: RandomizedQ算法通过结合采样探索与敏捷策略更新，为表格型强化学习提供了一种理论上有效且实际表现优秀的新方法。

Abstract: While Bayesian-based exploration often demonstrates superior empirical
performance compared to bonus-based methods in model-based reinforcement
learning (RL), its theoretical understanding remains limited for model-free
settings. Existing provable algorithms either suffer from computational
intractability or rely on stage-wise policy updates which reduce responsiveness
and slow down the learning process. In this paper, we propose a novel variant
of Q-learning algorithm, refereed to as RandomizedQ, which integrates
sampling-based exploration with agile, step-wise, policy updates, for episodic
tabular RL. We establish an $\widetilde{O}(\sqrt{H^5SAT})$ regret bound, where
$S$ is the number of states, $A$ is the number of actions, $H$ is the episode
length, and $T$ is the total number of episodes. In addition, we present a
logarithmic regret bound under a mild positive sub-optimality condition on the
optimal Q-function. Empirically, RandomizedQ exhibits outstanding performance
compared to existing Q-learning variants with both bonus-based and
Bayesian-based exploration on standard benchmarks.

</details>


### [457] [Bridging Theory and Practice in Link Representation with Graph Neural Networks](https://arxiv.org/abs/2506.24018)
*Veronica Lachi,Francesco Ferrini,Antonio Longa,Bruno Lepri,Andrea Passerini,Manfred Jaeger*

Main category: cs.LG

TL;DR: 本文研究了图神经网络（GNN）在链接表示上的表达能力，并提出了用于评估链接层次的表达性的新框架和基准测试方法。


<details>
  <summary>Details</summary>
Motivation: 大多数理论关注的是GNN在图整体表示上的能力，少有研究讨论其在节点对或链接层次的表达能力。

Method: 提出了$k_\phi$-$k_\rho$-$m$框架，用于统一现有的消息传递链接模型并进行表达性比较，同时设计了首个评估链接表达性的基准测试协议。

Result: 通过图对称性度量和实验，发现表达能力较高的模型在对称性高的数据集上具有显著优势。

Conclusion: 需要进行面向数据集的模型选择，更高表达性的模型在适当情况下表现优异。

Abstract: Graph Neural Networks (GNNs) are widely used to compute representations of
node pairs for downstream tasks such as link prediction. Yet, theoretical
understanding of their expressive power has focused almost entirely on
graph-level representations. In this work, we shift the focus to links and
provide the first comprehensive study of GNN expressiveness in link
representation. We introduce a unifying framework, the $k_\phi$-$k_\rho$-$m$
framework, that subsumes existing message-passing link models and enables
formal expressiveness comparisons. Using this framework, we derive a hierarchy
of state-of-the-art methods and offer theoretical tools to analyze future
architectures. To complement our analysis, we propose a synthetic evaluation
protocol comprising the first benchmark specifically designed to assess
link-level expressiveness. Finally, we ask: does expressiveness matter in
practice? We use a graph symmetry metric that quantifies the difficulty of
distinguishing links and show that while expressive models may underperform on
standard benchmarks, they significantly outperform simpler ones as symmetry
increases, highlighting the need for dataset-aware model selection.

</details>


### [458] [Faster Diffusion Models via Higher-Order Approximation](https://arxiv.org/abs/2506.24042)
*Gen Li,Yuchen Zhou,Yuting Wei,Yuxin Chen*

Main category: cs.LG

TL;DR: 本文提出了一种可证明加速扩散模型的采样算法，无需重新训练，能够在复杂条件下有效近似目标数据分布。


<details>
  <summary>Details</summary>
Motivation: 解决在不需要重新训练的代价下，加速复杂目标数据分布的扩散模型采样问题。

Method: 开发了一种基于高阶Lagrange插值和概率流ODE的训练无关采样算法，结合高阶ODE解算器进行积分近似。

Result: 提出的算法在$d^{1+2/K} \varepsilon^{-1/K}$阶的分数得分评估下，比现有方法更高效，并对得分评估误差表现出鲁棒性。

Conclusion: 新算法适用于广泛的数据分布条件，减少假设限制且具有实际的稳定性能，为扩散模型的加速提供了新的理论和算法支持。

Abstract: In this paper, we explore provable acceleration of diffusion models without
any additional retraining. Focusing on the task of approximating a target data
distribution in $\mathbb{R}^d$ to within $\varepsilon$ total-variation
distance, we propose a principled, training-free sampling algorithm that
requires only the order of
  $$ d^{1+2/K} \varepsilon^{-1/K} $$
  score function evaluations (up to log factor) in the presence of accurate
scores, where $K$ is an arbitrarily large fixed integer. This result applies to
a broad class of target data distributions, without the need for assumptions
such as smoothness or log-concavity. Our theory is robust vis-a-vis inexact
score estimation, degrading gracefully as the score estimation error increases
-- without demanding higher-order smoothness on the score estimates as assumed
in previous work. The proposed algorithm draws insight from high-order ODE
solvers, leveraging high-order Lagrange interpolation and successive refinement
to approximate the integral derived from the probability flow ODE.

</details>


### [459] [Development of Hybrid Artificial Intelligence Training on Real and Synthetic Data: Benchmark on Two Mixed Training Strategies](https://arxiv.org/abs/2506.24093)
*Paul Wachter,Lukas Niehaus,Julius Schöning*

Main category: cs.LG

TL;DR: 本研究分析两种混合数据集的策略对神经网络性能的影响，优化合成数据使用，提升模型鲁棒性与效果。


<details>
  <summary>Details</summary>
Motivation: 探讨合成数据与真实数据混合训练在减少领域差距中的影响及其在各种任务和架构下的泛化能力。

Method: 系统性地评估两种混合数据策略在三种常用架构和数据集中的表现，并分析不同合成与真实数据比例对结果的影响。

Result: 研究结果提供了优化人工神经网络训练中合成数据使用的宝贵见解。

Conclusion: 通过混合数据训练，可增强模型在真实场景中的表现，提高合成数据的实用性与可靠性。

Abstract: Synthetic data has emerged as a cost-effective alternative to real data for
training artificial neural networks (ANN). However, the disparity between
synthetic and real data results in a domain gap. That gap leads to poor
performance and generalization of the trained ANN when applied to real-world
scenarios. Several strategies have been developed to bridge this gap, which
combine synthetic and real data, known as mixed training using hybrid datasets.
While these strategies have been shown to mitigate the domain gap, a systematic
evaluation of their generalizability and robustness across various tasks and
architectures remains underexplored. To address this challenge, our study
comprehensively analyzes two widely used mixing strategies on three prevalent
architectures and three distinct hybrid datasets. From these datasets, we
sample subsets with varying proportions of synthetic to real data to
investigate the impact of synthetic and real components. The findings of this
paper provide valuable insights into optimizing the use of synthetic data in
the training process of any ANN, contributing to enhancing robustness and
efficacy.

</details>


### [460] [Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime](https://arxiv.org/abs/2506.24120)
*Yuqing Wang,Shangding Gu*

Main category: cs.LG

TL;DR: 本文探讨了在复杂任务中，通过数据选择提高模型训练效率和性能的方法，发现选择分布更均匀的数据能够带来显著改进。


<details>
  <summary>Details</summary>
Motivation: 在有限先验知识的非平凡任务中，探索是否存在通用的、定量化的原则帮助提升数据选择的效率和模型表现。

Method: 作者提出一种理论框架，通过最小数据点对距离$h_{min}$指标来评估数据分布均匀性，并结合实验验证分布均匀性对模型性能和训练效率的影响。

Result: 实验表明，选择最大化数据点对距离的数据，可以显著加速梯度下降训练，且在各种设置中获得更好的或相当的性能。

Conclusion: 选择分布均匀性好的数据是提升LLMs训练效率和性能的有效手段，提供理论依据与实践验证，为深度学习架构优化提供新视角。

Abstract: Data selection plays a crucial role in data-driven decision-making, including
in large language models (LLMs), and is typically task-dependent. Properties
such as data quality and diversity have been extensively studied and are known
to enhance model performance. However, it remains unclear whether there exist
other quantitative and general principles of data selection that can
consistently improve performance, especially for complex tasks with limited
prior knowledge. In this paper, we demonstrate that selecting more uniformly
distributed data can improve training efficiency while enhancing performance.
Specifically, we establish that more uniform (less biased) distribution leads
to a larger minimum pairwise distance between data points, denoted by
$h_{\min}$, and prove that a smaller $h_{\min}$ can slow down the training
dynamics of gradient descent (GD). Moreover, we theoretically show that the
approximation error of neural networks decreases as $h_{\min}$ increases. Our
analysis introduces a convergence framework for GD beyond the Neural Tangent
Kernel (NTK) regime, applicable to a broad class of architectures, including
transformers, without requiring Lipschitz smoothness. This framework further
provides theoretical justification for the use of residual connections and
function compositions in deep neural architectures. In the end, we conduct
comprehensive experiments for supervised fine-tuning across various settings,
including different optimization strategies, model sizes, and training
datasets. The results consistently demonstrate that selecting data by
maximizing pairwise distance significantly accelerates training and achieves
comparable or better performance in LLMs across diverse datasets. Code and
Datasets are available at the link:
https://github.com/SafeRL-Lab/data-uniformity.

</details>


### [461] [Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives](https://arxiv.org/abs/2506.24124)
*Dong Sixun,Fan Wei,Teresa Wu,Fu Yanjie*

Main category: cs.LG

TL;DR: 本文提出一种多模态对比学习框架，通过将时间序列数据转化为文本和视觉信息，提升时间序列预测的效果。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法难以捕捉高层语义模式，且使用大语言模型处理时间序列的方法受限于离散的符号序列表示和对视觉模式直觉的缺乏。

Method: 设计了一个多模态对比学习框架，将原始时间序列转化为视觉和文本视角，在共享语义空间中通过对比学习对齐多模态表示，并引入变量选择模块识别信息量最大的变量。

Result: 在15个短期和6个长期预测基准数据集上的实验表明，该方法一致超越强基线方法，验证了多模态对齐在提升时间序列预测中的有效性。

Conclusion: 通过多模态对比学习，可获得更丰富互补的时序数据表示，从而改进预测性能。

Abstract: Time series forecasting traditionally relies on unimodal numerical inputs,
which often struggle to capture high-level semantic patterns due to their dense
and unstructured nature. While recent approaches have explored representing
time series as text using large language models (LLMs), these methods remain
limited by the discrete nature of token sequences and lack the perceptual
intuition humans typically apply, such as interpreting visual patterns. In this
paper, we propose a multimodal contrastive learning framework that transforms
raw time series into structured visual and textual perspectives. Rather than
using natural language or real-world images, we construct both modalities
directly from numerical sequences. We then align these views in a shared
semantic space via contrastive learning, enabling the model to capture richer
and more complementary representations. Furthermore, we introduce a variate
selection module that leverages the aligned representations to identify the
most informative variables for multivariate forecasting. Extensive experiments
on fifteen short-term and six long-term forecasting benchmarks demonstrate that
our approach consistently outperforms strong unimodal and cross-modal
baselines, highlighting the effectiveness of multimodal alignment in enhancing
time series forecasting. Code is available at:
https://github.com/Ironieser/TimesCLIP.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [462] [Towards Efficient and Accurate Spiking Neural Networks via Adaptive Bit Allocation](https://arxiv.org/abs/2506.23717)
*Xingting Yao,Qinghao Hu,Fei Zhou,Tielong Liu,Gang Li,Peisong Wang,Jian Cheng*

Main category: cs.NE

TL;DR: 提出了一种适用于多比特脉冲神经网络（SNNs）的自适应比特分配策略，兼具高效性与高准确率。


<details>
  <summary>Details</summary>
Motivation: 随着多比特参与，SNNs的内存和计算需求显著增加，导致性能提升变得不成比例。因此需要一种方法优化资源分配。

Method: 通过参数化权重和脉冲的时间长度及比特宽度，使其可通过梯度学习优化，并提出改进的脉冲神经元和步长更新机制以应对渐变位宽及时间长度带来的量化误差。

Result: 在CIFAR、ImageNet等静态和动态数据集上验证，提高了精度同时降低内存消耗，SEWResNet-34在ImageNet上较基线提升2.69%精度，减少4.16倍的比特预算。

Conclusion: 所提出的方法能够在减少SNNs整体内存和计算成本的同时，提高模型准确性，展现了良好的应用潜力，计划开源。

Abstract: Multi-bit spiking neural networks (SNNs) have recently become a heated
research spot, pursuing energy-efficient and high-accurate AI. However, with
more bits involved, the associated memory and computation demands escalate to
the point where the performance improvements become disproportionate. Based on
the insight that different layers demonstrate different importance and extra
bits could be wasted and interfering, this paper presents an adaptive bit
allocation strategy for direct-trained SNNs, achieving fine-grained layer-wise
allocation of memory and computation resources. Thus, SNN's efficiency and
accuracy can be improved. Specifically, we parametrize the temporal lengths and
the bit widths of weights and spikes, and make them learnable and controllable
through gradients. To address the challenges caused by changeable bit widths
and temporal lengths, we propose the refined spiking neuron, which can handle
different temporal lengths, enable the derivation of gradients for temporal
lengths, and suit spike quantization better. In addition, we theoretically
formulate the step-size mismatch problem of learnable bit widths, which may
incur severe quantization errors to SNN, and accordingly propose the step-size
renewal mechanism to alleviate this issue. Experiments on various datasets,
including the static CIFAR and ImageNet and the dynamic CIFAR-DVS and
DVS-GESTURE, demonstrate that our methods can reduce the overall memory and
computation cost while achieving higher accuracy. Particularly, our
SEWResNet-34 can achieve a 2.69\% accuracy gain and 4.16$\times$ lower bit
budgets over the advanced baseline work on ImageNet. This work will be fully
open-sourced.

</details>


### [463] [Marker Gene Method : Identifying Stable Solutions in a Dynamic Environment](https://arxiv.org/abs/2506.23734)
*Hao Shi,Xi Li,Fangfang Xie*

Main category: cs.NE

TL;DR: 本文提出了Marker Gene Method (MGM)，一种通过动态基准和自适应权重机制来增强竞争共进化算法（CCEAs）稳定性的框架。


<details>
  <summary>Details</summary>
Motivation: 解决CCEAs因不稳定动态（如非传递性、红皇后效应）导致的收敛性问题。

Method: 引入标记基因作为动态基准，并采用自适应加权机制以在探索和开发之间实现平衡，具体通过数学证明吸引Nash平衡附近的点，并扩展至记忆池增强方法。

Result: MGM稳固了经典的“剪刀石头布”问题，提升了C-RMOEA/D算法在ZDT基准上的表现，并成功解决了复杂的Shapley Biased Game问题。

Conclusion: MGM提供了一个理论可靠、经验验证的框架，显著提升了CCEAs在复杂竞争环境中的稳定性与鲁棒性。

Abstract: Competitive Co-evolutionary Algorithms (CCEAs) are often hampered by complex
dynamics like intransitivity and the Red Queen effect, leading to unstable
convergence. To counter these challenges, this paper introduces the Marker Gene
Method (MGM), a framework that establishes stability by using a 'marker gene'
as a dynamic benchmark and an adaptive weighting mechanism to balance
exploration and exploitation. We provide rigorous mathematical proofs
demonstrating that MGM creates strong attractors near Nash Equilibria within
the Strictly Competitive Game framework. Empirically, MGM demonstrates its
efficacy across a spectrum of challenges: it stabilizes the canonical
Rock-Paper-Scissors game, significantly improves the performance of C-RMOEA/D
on ZDT benchmarks, and, when augmented with a Memory Pool (MP) extension, it
successfully tames the notoriously pathological Shapley Biased Game. This work
presents a theoretically sound and empirically validated framework that
substantially enhances the stability and robustness of CCEAs in complex
competitive environments.

</details>


### [464] [More Efficient Real-Valued Gray-Box Optimization through Incremental Distribution Estimation in RV-GOMEA](https://arxiv.org/abs/2506.23738)
*Renzo J. Scholman,Tanja Alderliesten,Peter A. N. Bosman*

Main category: cs.NE

TL;DR: 研究改进了RV-GOMEA，通过引入增量式分布估计以提高效率，在有重叠依赖的基准问题中表现出显著的改善。


<details>
  <summary>Details</summary>
Motivation: 现有的RV-GOMEA在分布估计上没有采用增量式学习，而众多高效的进化算法（如NES和CMA-ES）已经证明了增量式学习的优势。为了提升RV-GOMEA的效率，研究了增量分布估计的潜力。

Method: 通过增量式分布估计改进RV-GOMEA，并基于具有不同重叠依赖性质的基准问题进行测试；利用两种设置测试性能：问题特定的种群大小调优和通用种群大小指南。

Result: 改进后的算法在达到高质量解所需的评价次数上，与RV-GOMEA和VKD-CMA-ES相比有明显下降。在特定问题调优中减少约1.5倍，在通用设置中可减少2到3倍。

Conclusion: 引入增量分布估计显著提升了RV-GOMEA的运行效率，尤其在多种设置下都有改善，表明增量式方法的有效性。

Abstract: The Gene-pool Optimal Mixing EA (GOMEA) family of EAs offers a specific means
to exploit problem-specific knowledge through linkage learning, i.e.,
inter-variable dependency detection, expressed using subsets of variables, that
should undergo joint variation. Such knowledge can be exploited if faster
fitness evaluations are possible when only a few variables are changed in a
solution, enabling large speed-ups. The recent-most version of Real-Valued
GOMEA (RV-GOMEA) can learn a conditional linkage model during optimization
using fitness-based linkage learning, enabling fine-grained dependency
exploitation in learning and sampling a Gaussian distribution. However, while
the most efficient Gaussian-based EAs, like NES and CMA-ES, employ incremental
learning of the Gaussian distribution rather than performing full re-estimation
every generation, the recent-most RV-GOMEA version does not employ such
incremental learning. In this paper, we therefore study whether incremental
distribution estimation can lead to efficiency enhancements of RV-GOMEA. We
consider various benchmark problems with varying degrees of overlapping
dependencies. We find that, compared to RV-GOMEA and VKD-CMA-ES, the required
number of evaluations to reach high-quality solutions can be reduced by a
factor of up to 1.5 if population sizes are tuned problem-specifically, while a
reduction by a factor of 2-3 can be achieved with generic population-sizing
guidelines.

</details>


### [465] [Unsupervised Sparse Coding-based Spiking Neural Network for Real-time Spike Sorting](https://arxiv.org/abs/2506.24041)
*Alexis Melot,Sean U. N. Wood,Yannick Coffinier,Pierre Yger,Fabien Alibart*

Main category: cs.NE

TL;DR: 本文提出Neuromorphic Sparse Sorter (NSS)，一种面向边缘实时低功耗神经信号处理的新型神经网络。NSS基于LCA算法进行稀疏编码，实现在线无监督高效地对神经信号进行分类。在Intel Loihi 2平台的评估中，NSS表现出优异性能和效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决脑机接口中实时、低功耗同时保持高性能的尖峰分类问题。

Method: 通过二层脉冲神经网络与LCA稀疏编码算法，开发一种可在线学习并无监督运行的分类器；同时利用Loihi 2神经平台实现灵活的功耗性能折中。

Result: 在模拟和实际信号评估中，NSS超过现有方法，如WaveClus3和PCA+KMeans，并在Loihi 2平台上实现77%的F1分数，耗电低至8.6mW，推理时间仅0.25ms。

Conclusion: NSS成功适配神经形态计算平台，实现了高效、低功耗的神经信号分类，在脑机接口领域表现出极大潜力，可为实时应用提供支持。

Abstract: Spike sorting is a crucial step in decoding multichannel extracellular neural
signals, enabling the identification of individual neuronal activity. A key
challenge in brain-machine interfaces (BMIs) is achieving real-time, low-power
spike sorting at the edge while keeping high neural decoding performance. This
study introduces the Neuromorphic Sparse Sorter (NSS), a compact two-layer
spiking neural network optimized for efficient spike sorting. NSS leverages the
Locally Competitive Algorithm (LCA) for sparse coding to extract relevant
features from noisy events with reduced computational demands. NSS learns to
sort detected spike waveforms in an online fashion and operates entirely
unsupervised. To exploit multi-bit spike coding capabilities of neuromorphic
platforms like Intel's Loihi 2, a custom neuron model was implemented, enabling
flexible power-performance trade-offs via adjustable spike bit-widths.
Evaluations on simulated and real-world tetrode signals with biological drift
showed NSS outperformed established pipelines such as WaveClus3 and PCA+KMeans.
With 2-bit graded spikes, NSS on Loihi 2 outperformed NSS implemented with
leaky integrate-and-fire neuron and achieved an F1-score of 77% (+10%
improvement) while consuming 8.6mW (+1.65mW) when tested on a drifting
recording, with a computational processing time of 0.25ms (+60 us) per
inference.

</details>
