<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.CL](#cs.CL) [Total: 36]
- [cs.AI](#cs.AI) [Total: 20]
- [cs.LG](#cs.LG) [Total: 63]
- [cs.NE](#cs.NE) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Spatially Grounded Explanations in Vision Language Models for Document Visual Question Answering](https://arxiv.org/abs/2507.12490)
*Maximiliano Hormazábal Lagos,Héctor Cerezo-Costas,Dimosthenis Karatzas*

Main category: cs.CV

TL;DR: 本文提出EaGERS，一种无需训练且模型无关的框架，通过视觉语言模型生成语言推理，将其与空间区域绑定，并限制响应生成在相关区域内，在DocVQA基准上实现性能提升同时提高透明性和可复现性。


<details>
  <summary>Details</summary>
Motivation: 旨在无需额外模型微调的情况下提升DocVQA基准的性能，同时提高任务的透明性和可复现性。

Method: 提出EaGERS框架，通过视觉语言模型生成推理语言，基于多模态嵌入相似性将推理与网格中的空间区域绑定，最终限制响应生成在感兴趣的区域，实现无训练和模型无关的特性。

Result: 在DocVQA数据集上的实验表明，EaGERS框架在准确率和标准化Levenshtein相似度等指标上优于基础模型，同时提高了任务的透明性和可复现性。

Conclusion: EaGERS框架无需训练和模型调整即可有效提升DocVQA的性能，同时改进了透明性和可复现性，为文档问答任务提供了新方法。

Abstract: We introduce EaGERS, a fully training-free and model-agnostic pipeline that
(1) generates natural language rationales via a vision language model, (2)
grounds these rationales to spatial sub-regions by computing multimodal
embedding similarities over a configurable grid with majority voting, and (3)
restricts the generation of responses only from the relevant regions selected
in the masked image. Experiments on the DocVQA dataset demonstrate that our
best configuration not only outperforms the base model on exact match accuracy
and Average Normalized Levenshtein Similarity metrics but also enhances
transparency and reproducibility in DocVQA without additional model
fine-tuning.

</details>


### [2] [MindJourney: Test-Time Scaling with World Models for Spatial Reasoning](https://arxiv.org/abs/2507.12508)
*Yuncong Yang,Jiageng Liu,Zheyuan Zhang,Siyuan Zhou,Reuben Tan,Jianwei Yang,Yilun Du,Chuang Gan*

Main category: cs.CV

TL;DR: 本文提出MindJourney，通过将VLM与基于视频扩散的可控制世界模型相结合，在测试时提升VLM的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言模型（VLMs）缺乏对三维动态的内部建模，在空间推理任务（如理解视角变化）中表现较差。

Method: 方法通过让VLM生成摄像机轨迹，使用世界模型生成相应视图，并对多视角证据进行推理，以实现三维空间的推理能力。

Result: MindJourney方法在SAT基准测试上获得了超过8%的性能提升，并优于通过强化学习训练的VLM模型。

Conclusion: 将VLM和可控世界模型结合，不需额外微调即可提高三维空间推理能力。这种方法简单且具有广阔潜力。

Abstract: Spatial reasoning in 3D space is central to human cognition and indispensable
for embodied tasks such as navigation and manipulation. However,
state-of-the-art vision-language models (VLMs) struggle frequently with tasks
as simple as anticipating how a scene will look after an egocentric motion:
they perceive 2D images but lack an internal model of 3D dynamics. We therefore
propose MindJourney, a test-time scaling framework that grants a VLM with this
missing capability by coupling it to a controllable world model based on video
diffusion. The VLM iteratively sketches a concise camera trajectory, while the
world model synthesizes the corresponding view at each step. The VLM then
reasons over this multi-view evidence gathered during the interactive
exploration. Without any fine-tuning, our MindJourney achieves over an average
8% performance boost on the representative spatial reasoning benchmark SAT,
showing that pairing VLMs with world models for test-time scaling offers a
simple, plug-and-play route to robust 3D reasoning. Meanwhile, our method also
improves upon the test-time inference VLMs trained through reinforcement
learning, which demonstrates the potential of our method that utilizes world
models for test-time scaling.

</details>


### [3] [Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal Large Language Models](https://arxiv.org/abs/2507.12566)
*Gen Luo,Wenhan Dou,Wenhao Li,Zhaokai Wang,Xue Yang,Changyao Tian,Hao Li,Weiyun Wang,Wenhai Wang,Xizhou Zhu,Yu Qiao,Jifeng Dai*

Main category: cs.CV

TL;DR: 本文研究能够将视觉编码与语言解码整合到一个单一模型中的单片多模态大语言模型（MLLMs）。提出了Mono-InternVL和改进版本Mono-InternVL-1.5，二者均在15个基准测试中表现优异，展示出降低成本与提升性能的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有单片多模态大语言模型在结构设计和预训练策略上容易导致优化不稳定和灾难性遗忘，因此需要一种稳健的学习方法来整合视觉知识。

Method: 提出Mono-InternVL，使用多模态专家混合架构，同时研发了逐渐学习的内生视觉预训练（EViP）；而Mono-InternVL-1.5则改进了EViP（EViP++），通过引入额外的视觉注意专家和优化训练过程，降低了计算成本。

Result: Mono-InternVL在15个基准测试中12次优于现有模型，如在OCRBench上比Emu3提高114分；而Mono-InternVL-1.5在维持类似性能的情况下，将首标记延迟降低了69%。

Conclusion: 研究表明，Mono-InternVL系列模型在融合视觉和语言任务时具有高效性和竞争力，可在减少资源消耗的同时提升模型表现，且相关代码与模型已开放。

Abstract: This paper focuses on monolithic Multimodal Large Language Models (MLLMs),
which integrate visual encoding and language decoding into a single model.
Existing structures and pre-training strategies for monolithic MLLMs often
suffer from unstable optimization and catastrophic forgetting. To address these
challenges, our key idea is to embed a new visual parameter space into a
pre-trained LLM, enabling stable learning of visual knowledge from noisy data
via delta tuning. Based on this principle, we first introduce Mono-InternVL, an
advanced monolithic MLLM that incorporates a set of visual experts through a
multimodal mixture-of-experts architecture. In addition, we design an
innovative Endogenous Visual Pre-training (EViP) for Mono-InternVL to maximize
its visual capabilities via progressive learning. Mono-InternVL achieves
competitive performance against existing MLLMs but also leads to relatively
expensive data cost. Therefore, we further present Mono-InternVL-1.5, a cheaper
and stronger monolithic MLLM equipped with an improved EViP (EViP++). EViP++
introduces additional visual attention experts to Mono-InternVL-1.5 and
re-organizes the pre-training process in an efficient manner. During inference,
it includes a fused CUDA kernel to speed up its MoE operations. With these
designs, Mono-InternVL-1.5 significantly reduces training and inference costs,
while still maintaining competitive performance with Mono-InternVL. To evaluate
our approach, we conduct extensive experiments across 15 benchmarks. Results
demonstrate that Mono-InternVL outperforms existing monolithic MLLMs on 12 out
of 15 benchmarks, e.g., +114-point improvement over Emu3 on OCRBench. Compared
to its modular counterpart, i.e., InternVL-1.5, Mono-InternVL-1.5 achieves
similar multimodal performance while reducing first-token latency by up to 69%.
Code and models are released at https://github.com/OpenGVLab/Mono-InternVL.

</details>


### [4] [Best Practices for Large-Scale, Pixel-Wise Crop Mapping and Transfer Learning Workflows](https://arxiv.org/abs/2507.12590)
*Judy Long,Tao Liu,Sean Alexander Woznicki,Miljana Marković,Oskar Marko,Molly Sears*

Main category: cs.CV

TL;DR: 本研究全面评估了大规模逐像素农作物制图工作流程，探讨了传统监督学习方法与新兴迁移学习技术。


<details>
  <summary>Details</summary>
Motivation: 推动提升大规模农作物制图的精度和适应性，为农业应用提供最佳实践。

Method: 对包括六种预处理方法和十一种分类模型进行实验比对，并在五个不同农业场景下评估迁移学习技术和监督流程的表现。

Result: 发现细粒度的间隔预处理和Transformer模型在监督学习与迁移学习中均表现最佳；基于RF模型的快捷训练和适应性佳；在标注样本有限时，转移学习是额外选择。

Conclusion: 选择工作流程需考虑标注样本量，迁移学习在特定域转换下表现出潜力，而充足样本时监督学习仍更优。

Abstract: Crop mapping involves identifying and classifying crop types using spatial
data, primarily derived from remote sensing imagery. This study presents the
first comprehensive review of large-scale, pixel-wise crop mapping workflows,
encompassing both conventional supervised methods and emerging transfer
learning approaches. To identify the optimal supervised crop mapping workflows,
we conducted systematic experiments, comparing six widely adopted satellite
image-based preprocessing methods, alongside eleven supervised pixel-wise
classification models. Additionally, we assessed the synergistic impact of
varied training sample sizes and variable combinations. Moreover, we identified
optimal transfer learning techniques for different magnitudes of domain shift.
The evaluation of best methods was conducted across five diverse agricultural
sites. Landsat 8 served as the primary satellite data source. Labels come from
CDL trusted pixels and field surveys.
  Our findings reveal three key insights. First, fine-scale interval
preprocessing paired with Transformer models consistently delivered optimal
performance for both supervised and transferable workflows. RF offered rapid
training and competitive performance in conventional supervised learning and
direct transfer to similar domains. Second, transfer learning techniques
enhanced workflow adaptability, with UDA being effective for homogeneous crop
classes while fine-tuning remains robust across diverse scenarios. Finally,
workflow choice depends heavily on the availability of labeled samples. With a
sufficient sample size, supervised training typically delivers more accurate
and generalizable results. Below a certain threshold, transfer learning that
matches the level of domain shift is a viable alternative to achieve crop
mapping. Repository:
Best-Practices-for-Large-Scale-Pixel-Wise-Crop-Mapping-and-Transfer-Learning-Workflows

</details>


### [5] [CT-ScanGaze: A Dataset and Baselines for 3D Volumetric Scanpath Modeling](https://arxiv.org/abs/2507.12591)
*Trong-Thang Pham,Akash Awasthi,Saba Khan,Esteban Duran Marti,Tien-Phat Nguyen,Khoa Vo,Minh Tran,Ngoc Son Nguyen,Cuong Tran Van,Yuki Ikebe,Anh Totti Nguyen,Anh Nguyen,Zhigang Deng,Carol C. Wu,Hien Van Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: 文章提出了CT-ScanGaze数据集和CT-Searcher，用于研究放射科医生在CT扫描时的视线轨迹，并提出可以将2D注视数据转为3D的预训练方法。


<details>
  <summary>Details</summary>
Motivation: 针对CT阅读中缺少公开的眼动追踪数据集以及CT体积复杂性的挑战，开发一种能模拟放射科医生3D注视轨迹的模型和数据集。

Method: 提出首个公开的CT眼动数据集CT-ScanGaze，并设计了一个3D扫描路径预测器CT-Searcher，通过将现有2D眼动数据转为3D数据进行预训练。

Result: 实验表明CT-Searcher在定性和定量评估上表现良好，并为医学影像中的3D路径预测提供了综合评估框架。

Conclusion: CT-Searcher和CT-ScanGaze为更好理解和模拟放射科医生的眼动行为提供了有力工具，有助于提升计算机辅助诊断系统的可解释性。

Abstract: Understanding radiologists' eye movement during Computed Tomography (CT)
reading is crucial for developing effective interpretable computer-aided
diagnosis systems. However, CT research in this area has been limited by the
lack of publicly available eye-tracking datasets and the three-dimensional
complexity of CT volumes. To address these challenges, we present the first
publicly available eye gaze dataset on CT, called CT-ScanGaze. Then, we
introduce CT-Searcher, a novel 3D scanpath predictor designed specifically to
process CT volumes and generate radiologist-like 3D fixation sequences,
overcoming the limitations of current scanpath predictors that only handle 2D
inputs. Since deep learning models benefit from a pretraining step, we develop
a pipeline that converts existing 2D gaze datasets into 3D gaze data to
pretrain CT-Searcher. Through both qualitative and quantitative evaluations on
CT-ScanGaze, we demonstrate the effectiveness of our approach and provide a
comprehensive assessment framework for 3D scanpath prediction in medical
imaging.

</details>


### [6] [MS-DGCNN++: A Multi-Scale Fusion Dynamic Graph Neural Network with Biological Knowledge Integration for LiDAR Tree Species Classification](https://arxiv.org/abs/2507.12602)
*Said Ohamouddou,Abdellatif El Afia,Hanaa El Afia,Raddouane Chiheb*

Main category: cs.CV

TL;DR: 提出了一种改进的多尺度动态图卷积神经网络MS-DGCNN++，通过分层多尺度语义融合显著提高了对树种和3D物体的分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法对森林结构的层次化关系建模不足，因此无法充分利用树结构的语义信息，限制了分类性能。

Method: 提出了一种分层多尺度动态图卷积网络MS-DGCNN++，实现全局、分枝和冠层层级的特征提取与跨尺度信息传播，从而更好地捕获森林结构的多尺度语义信息。

Result: 在STPCTLS数据集上分类准确率达到94.96%，在FOR-species20K上为67.25%，并在ModelNet等标准3D对象分类数据集上展示了优越性能，同时保持较少参数和计算复杂度。

Conclusion: 新的模型改进了利用多尺度森林结构信息的能力，实现了高效且准确的树种分类和3D对象识别，适合资源受限场景，具有广泛适用性。

Abstract: Tree species classification from terrestrial LiDAR point clouds is
challenging because of the complex multi-scale geometric structures in forest
environments. Existing approaches using multi-scale dynamic graph convolutional
neural networks (MS-DGCNN) employ parallel multi-scale processing, which fails
to capture the semantic relationships between the hierarchical levels of the
tree architecture. We present MS-DGCNN++, a hierarchical multiscale fusion
dynamic graph convolutional network that uses semantically meaningful feature
extraction at local, branch, and canopy scales with cross-scale information
propagation. Our method employs scale-specific feature engineering, including
standard geometric features for the local scale, normalized relative vectors
for the branch scale, and distance information for the canopy scale. This
hierarchical approach replaces uniform parallel processing with semantically
differentiated representations that are aligned with the natural tree
structure. Under the same proposed tree species data augmentation strategy for
all experiments, MS-DGCNN++ achieved an accuracy of 94.96 \% on STPCTLS,
outperforming DGCNN, MS-DGCNN, and the state-of-the-art model PPT. On
FOR-species20K, it achieves 67.25\% accuracy (6.1\% improvement compared to
MS-DGCNN). For standard 3D object recognition, our method outperformed DGCNN
and MS-DGCNN with overall accuracies of 93.15\% on ModelNet40 and 94.05\% on
ModelNet10. With lower parameters and reduced complexity compared to
state-of-the-art transformer approaches, our method is suitable for
resource-constrained applications while maintaining a competitive accuracy.
Beyond tree classification, the method generalizes to standard 3D object
recognition, establishing it as a versatile solution for diverse point cloud
processing applications. The implementation code is publicly available at
https://github.com/said-ohamouddou/MS-DGCNN2.

</details>


### [7] [Predicting Soccer Penalty Kick Direction Using Human Action Recognition](https://arxiv.org/abs/2507.12617)
*David Freire-Obregón,Oliverio J. Santana,Javier Lorenzo-Navarro,Daniel Hernández-Sosa,Modesto Castrillón-Santana*

Main category: cs.CV

TL;DR: 提出一个新数据集和深度学习分类模型，用于预测足球点球射门方向，模型预测准确率优于真实守门员决定。


<details>
  <summary>Details</summary>
Motivation: 解决当前体育场景下动作预测应用受限于缺乏标注数据集的问题。

Method: 通过构建一个手动标注的数据集，并提出一个结合HAR特征嵌入和上下文元数据的深度学习分类器进行方向预测。

Result: 通过对22种模型的评估，本文方法在点球射门方向预测上达到了63.9%的准确率，超越了真实守门员的表现。

Conclusion: 新数据集具有很高的应用价值，模型在运动预测任务上具备良好的泛化潜力。

Abstract: Action anticipation has become a prominent topic in Human Action Recognition
(HAR). However, its application to real-world sports scenarios remains limited
by the availability of suitable annotated datasets. This work presents a novel
dataset of manually annotated soccer penalty kicks to predict shot direction
based on pre-kick player movements. We propose a deep learning classifier to
benchmark this dataset that integrates HAR-based feature embeddings with
contextual metadata. We evaluate twenty-two backbone models across seven
architecture families (MViTv2, MViTv1, SlowFast, Slow, X3D, I3D, C2D),
achieving up to 63.9% accuracy in predicting shot direction (left or right),
outperforming the real goalkeepers' decisions. These results demonstrate the
dataset's value for anticipatory action recognition and validate our model's
potential as a generalizable approach for sports-based predictive tasks.

</details>


### [8] [Funnel-HOI: Top-Down Perception for Zero-Shot HOI Detection](https://arxiv.org/abs/2507.12628)
*Sandipan Sarma,Agney Talwarr,Arijit Sur*

Main category: cs.CV

TL;DR: 本文提出了一种名为Funnel-HOI的新方法，通过改进编码器阶段的HOI特定线索处理来提升人-物交互检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前人-物交互检测（HOID）面临数据标注稀缺和长尾分布问题，现有方法多关注解码器的改进，而对编码器阶段的特定特征挖掘关注不足。

Method: 设计了一种名为Funnel-HOI的顶层设计框架，先关注物体（具体概念），再关注与之相关的动作（抽象概念），提出非对称协同注意力机制增强多模态信息挖掘，并设计了新的损失函数优化交互分类器。

Result: 在HICO-DET和V-COCO数据集的全监督和零样本情况下进行了实验，相比于现有方法，分别在未见类别和稀有类别中实现了12.4%和8.4%的性能提升。

Conclusion: 通过引入编码器阶段的HOI特定信息挖掘与优化损失函数，Funnel-HOI有效提升了HOI检测的性能。

Abstract: Human-object interaction detection (HOID) refers to localizing interactive
human-object pairs in images and identifying the interactions. Since there
could be an exponential number of object-action combinations, labeled data is
limited - leading to a long-tail distribution problem. Recently, zero-shot
learning emerged as a solution, with end-to-end transformer-based object
detectors adapted for HOID becoming successful frameworks. However, their
primary focus is designing improved decoders for learning entangled or
disentangled interpretations of interactions. We advocate that HOI-specific
cues must be anticipated at the encoder stage itself to obtain a stronger scene
interpretation. Consequently, we build a top-down framework named Funnel-HOI
inspired by the human tendency to grasp well-defined concepts first and then
associate them with abstract concepts during scene understanding. We first
probe an image for the presence of objects (well-defined concepts) and then
probe for actions (abstract concepts) associated with them. A novel asymmetric
co-attention mechanism mines these cues utilizing multimodal information
(incorporating zero-shot capabilities) and yields stronger interaction
representations at the encoder level. Furthermore, a novel loss is devised that
considers objectaction relatedness and regulates misclassification penalty
better than existing loss functions for guiding the interaction classifier.
Extensive experiments on the HICO-DET and V-COCO datasets across
fully-supervised and six zero-shot settings reveal our state-of-the-art
performance, with up to 12.4% and 8.4% gains for unseen and rare HOI
categories, respectively.

</details>


### [9] [Reconstruct, Inpaint, Finetune: Dynamic Novel-view Synthesis from Monocular Videos](https://arxiv.org/abs/2507.12646)
*Kaihua Chen,Tarasha Khurana,Deva Ramanan*

Main category: cs.CV

TL;DR: 提出了一种从单目视频中进行动态场景新视图合成的方法，结合动态3D重建和2D视频扩散模型进行无监督学习，在实验证明中性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖高成本的4D表示优化，要么在前馈训练时难以保持场景几何形态。研究旨在克服这些局限，为动态场景提供更高效、更精确的新视图合成方法。

Method: 提出基于协同可见像素重建动态3D场景的办法，并使用视频扩散模型完成隐藏像素的补全。此外，该扩散模型可以通过大量未经标注的2D视频进行自监督训练，支持零样本测试和微调。

Result: 实验表明，CogNVS在动态场景的新视图合成任务中表现优越，超过几乎所有已有方法。

Conclusion: CogNVS能够有效结合动态三维重建与视频扩散模型，提供了一种高效且性能优越的单目视频动态新视图合成方法。

Abstract: We explore novel-view synthesis for dynamic scenes from monocular videos.
Prior approaches rely on costly test-time optimization of 4D representations or
do not preserve scene geometry when trained in a feed-forward manner. Our
approach is based on three key insights: (1) covisible pixels (that are visible
in both the input and target views) can be rendered by first reconstructing the
dynamic 3D scene and rendering the reconstruction from the novel-views and (2)
hidden pixels in novel views can be "inpainted" with feed-forward 2D video
diffusion models. Notably, our video inpainting diffusion model (CogNVS) can be
self-supervised from 2D videos, allowing us to train it on a large corpus of
in-the-wild videos. This in turn allows for (3) CogNVS to be applied zero-shot
to novel test videos via test-time finetuning. We empirically verify that
CogNVS outperforms almost all prior art for novel-view synthesis of dynamic
scenes from monocular videos.

</details>


### [10] [Integrated Oculomics and Lipidomics Reveal Microvascular Metabolic Signatures Associated with Cardiovascular Health in a Healthy Cohort](https://arxiv.org/abs/2507.12663)
*Inamullah,Ernesto Elias Vidal Rosas,Imran Razzak,Shoaib Jameel*

Main category: cs.CV

TL;DR: 本研究通过将视网膜微血管特征和血清脂质组数据相结合，提出了一种新的影像组学框架，用于早期发现心血管疾病（CVD）的无症状生物标志物。


<details>
  <summary>Details</summary>
Motivation: 现有的心血管疾病（CVD）风险分层方法无法及早检测潜在改变，研究需要新的生物标志物和方法来检测早期心血管疾病风险。

Method: 利用深度学习处理视网膜图像提取微血管特性，并联合超高效液相色谱与高分辨质谱技术（UHPLC ESI HRMS）分析血清脂质组数据，进行大规模协变量调整与分层相关性分析。

Result: 发现视网膜动脉宽度、血管密度与脂质亚类（如三酰基甘油、二酰基甘油、神经酰胺）之间有强相关性，且这种关联不受年龄和性别影响，揭示了代谢压力下微血管重塑的潜在机制。

Conclusion: 此研究为理解早期心血管疾病病理机制填补了重要空白，提出了一种新颖的微血管代谢的综合分析方法，并为开发无创生物标志物和个性化心血管疾病护理提供了可能性。

Abstract: Cardiovascular disease (CVD) remains the leading global cause of mortality,
yet current risk stratification methods often fail to detect early, subclinical
changes. Previous studies have generally not integrated retinal
microvasculature characteristics with comprehensive serum lipidomic profiles as
potential indicators of CVD risk. In this study, an innovative imaging omics
framework was introduced, combining retinal microvascular traits derived
through deep learning based image processing with serum lipidomic data to
highlight asymptomatic biomarkers of cardiovascular risk beyond the
conventional lipid panel. This represents the first large scale, covariate
adjusted and stratified correlation analysis conducted in a healthy population,
which is essential for identifying early indicators of disease. Retinal
phenotypes were quantified using automated image analysis tools, while serum
lipid profiling was performed by Ultra High Performance Liquid Chromatography
Electrospray ionization High resolution mass spectrometry (UHPLC ESI HRMS).
Strong, age- and sex-independent correlations were established, particularly
between average artery width, vessel density, and lipid subclasses such as
triacylglycerols (TAGs), diacylglycerols (DAGs), and ceramides (Cers). These
associations suggest a converging mechanism of microvascular remodeling under
metabolic stress. By linking detailed
  vascular structural phenotypes to specific lipid species, this study fills a
critical gap in the understanding of early CVD pathogenesis. This integration
not only offers a novel perspective on microvascular metabolic associations but
also presents a significant opportunity for the identification of robust,
non-invasive biomarkers. Ultimately, these findings may support improved early
detection, targeted prevention, and personalized approaches in cardiovascular
healthcare.

</details>


### [11] [FORTRESS: Function-composition Optimized Real-Time Resilient Structural Segmentation via Kolmogorov-Arnold Enhanced Spatial Attention Networks](https://arxiv.org/abs/2507.12675)
*Christina Thrainer,Md Meftahul Ferdaus,Mahdi Abdelguerfi,Christian Guetl,Steven Sloan,Kendall N. Niles,Ken Pathak*

Main category: cs.CV

TL;DR: 本文提出一个名为FORTRESS的新架构，用于实现高效准确的实时结构缺陷分割，通过创新的深度可分离卷积技术和自适应的Kolmogorov-Arnold网络整合，在参数和计算复杂度大幅降低的同时，达到了最先进的性能表现。


<details>
  <summary>Details</summary>
Motivation: 当前土木基础设施结构缺陷检测亟需解决在保持高准确率的同时实现高效计算的问题，便于在资源有限的环境中实时应用。

Method: 本文采用了一种新颖的架构FORTRESS，结合了系统化的深度可分离卷积框架、自适应TiKAN整合和多尺度注意力融合，显著降低了参数和计算复杂度并提升了推断速度。

Result: 该方法实现了参数减少91%、计算复杂度减少91%、推断速度提高3倍，同时分割性能达到最先进水平，F1得分为0.771，平均IoU为0.677，均优于现有方法。

Conclusion: FORTRESS展示了在资源受限的环境中兼顾准确率和计算效率的强大潜力，为实际结构缺陷分割任务提供了一种可行的解决方案。

Abstract: Automated structural defect segmentation in civil infrastructure faces a
critical challenge: achieving high accuracy while maintaining computational
efficiency for real-time deployment. This paper presents FORTRESS
(Function-composition Optimized Real-Time Resilient Structural Segmentation), a
new architecture that balances accuracy and speed by using a special method
that combines depthwise separable convolutions with adaptive Kolmogorov-Arnold
Network integration. FORTRESS incorporates three key innovations: a systematic
depthwise separable convolution framework achieving a 3.6x parameter reduction
per layer, adaptive TiKAN integration that selectively applies function
composition transformations only when computationally beneficial, and
multi-scale attention fusion combining spatial, channel, and KAN-enhanced
features across decoder levels. The architecture achieves remarkable efficiency
gains with 91% parameter reduction (31M to 2.9M), 91% computational complexity
reduction (13.7 to 1.17 GFLOPs), and 3x inference speed improvement while
delivering superior segmentation performance. Evaluation on benchmark
infrastructure datasets demonstrates state-of-the-art results with an F1- score
of 0.771 and a mean IoU of 0.677, significantly outperforming existing methods
including U-Net, SA-UNet, and U- KAN. The dual optimization strategy proves
essential for optimal performance, establishing FORTRESS as a robust solution
for practical structural defect segmentation in resource-constrained
environments where both accuracy and computational efficiency are paramount.
Comprehensive architectural specifications are provided in the Supplemental
Material. Source code is available at URL:
https://github.com/faeyelab/fortress-paper-code.

</details>


### [12] [NeuraLeaf: Neural Parametric Leaf Models with Shape and Deformation Disentanglement](https://arxiv.org/abs/2507.12714)
*Yang Yang,Dongni Mao,Hiroaki Santo,Yasuyuki Matsushita,Fumio Okura*

Main category: cs.CV

TL;DR: 该论文提出了一种用于植物叶片建模和重建的神经参数模型NeuraLeaf，解决了叶片形状多样性和柔性变形的挑战。


<details>
  <summary>Details</summary>
Motivation: 植物叶片在农业和计算机图形学中至关重要，但其多样性和柔性变形使得建模复杂。研究需要一个强大的工具来应对这些挑战。

Method: NeuraLeaf是一种神经参数模型，通过将叶片几何分解为二维基础形状和三维变形来建模，同时结合纹理学习。为实现三维变形建模，提出了一种去骨化的蒙皮模型，并创建了一个新的三维叶片数据集DeformLeaf。

Result: 实验表明，NeuraLeaf能够成功生成具有变形的广泛叶片形状，在深度图和点云等三维观测数据上能达到准确拟合效果。

Conclusion: NeuraLeaf实现了对复杂叶片的高效建模，为农业和计算机图形领域的相关研究提供了新的工具。

Abstract: We develop a neural parametric model for 3D leaves for plant modeling and
reconstruction that are essential for agriculture and computer graphics. While
neural parametric models are actively studied for humans and animals, plant
leaves present unique challenges due to their diverse shapes and flexible
deformation. To this problem, we introduce a neural parametric model for
leaves, NeuraLeaf. Capitalizing on the fact that flattened leaf shapes can be
approximated as a 2D plane, NeuraLeaf disentangles the leaves' geometry into
their 2D base shapes and 3D deformations. This representation allows learning
from rich sources of 2D leaf image datasets for the base shapes, and also has
the advantage of simultaneously learning textures aligned with the geometry. To
model the 3D deformation, we propose a novel skeleton-free skinning model and
create a newly captured 3D leaf dataset called DeformLeaf. We show that
NeuraLeaf successfully generates a wide range of leaf shapes with deformation,
resulting in accurate model fitting to 3D observations like depth maps and
point clouds. Our implementation and dataset are available at
https://neuraleaf-yang.github.io/.

</details>


### [13] [SOD-YOLO: Enhancing YOLO-Based Detection of Small Objects in UAV Imagery](https://arxiv.org/abs/2507.12727)
*Peijun Wang,Jinhua Zhao*

Main category: cs.CV

TL;DR: 本文提出了改进版 YOLOv8 模型 SOD-YOLO，用于解决小目标检测难题，通过实验验证其在 VisDrone2019-DET 数据集上的性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前小目标检测仍然是目标检测领域的一个重大挑战，研究旨在通过改进模型结构提升小目标检测性能。

Method: 采用增强的 YOLOv8 模型（SOD-YOLO），集成了ASF机制增强多尺度特征融合，增加了小目标检测层（P2）提高高分辨率特征图，使用Soft-NMS优化置信得分，保留真实检测目标。

Result: 实验结果表明，与基线模型相比，SOD-YOLO在VisDrone2019-DET数据集上的mAP$_{50:95}$提升了36.1%，mAP$_{50}$提升了20.6%。

Conclusion: 通过一系列改进，SOD-YOLO显著提高了小目标检测性能，为小目标检测，特别是在无人机影像中的应用，提供了更高效的解决方案。

Abstract: Small object detection remains a challenging problem in the field of object
detection. To address this challenge, we propose an enhanced YOLOv8-based
model, SOD-YOLO. This model integrates an ASF mechanism in the neck to enhance
multi-scale feature fusion, adds a Small Object Detection Layer (named P2) to
provide higher-resolution feature maps for better small object detection, and
employs Soft-NMS to refine confidence scores and retain true positives.
Experimental results demonstrate that SOD-YOLO significantly improves detection
performance, achieving a 36.1% increase in mAP$_{50:95}$ and 20.6% increase in
mAP$_{50}$ on the VisDrone2019-DET dataset compared to the baseline model.
These enhancements make SOD-YOLO a practical and efficient solution for small
object detection in UAV imagery. Our source code, hyper-parameters, and model
weights are available at https://github.com/iamwangxiaobai/SOD-YOLO.

</details>


### [14] [A Privacy-Preserving Semantic-Segmentation Method Using Domain-Adaptation Technique](https://arxiv.org/abs/2507.12730)
*Homare Sueyoshi,Kiyoshi Nishikawa,Hitoshi Kiya*

Main category: cs.CV

TL;DR: 提出了一种隐私保护的语义分割方法，使用感知加密技术处理用于模型训练和测试的图像，且精度几乎与不加密时相同。


<details>
  <summary>Details</summary>
Motivation: 解决在保护隐私的同时实现高效语义分割的问题。

Method: 结合感知加密和基于Vision Transformer (ViT)嵌入结构的领域适应技术。

Result: 采用Segmentation Transformer模型实验验证了所提出方法在语义分割精度上的有效性。

Conclusion: 提出的方法能够在隐私保护的同时实现高效的语义分割，与未加密模型的精度基本持平。

Abstract: We propose a privacy-preserving semantic-segmentation method for applying
perceptual encryption to images used for model training in addition to test
images. This method also provides almost the same accuracy as models without
any encryption. The above performance is achieved using a domain-adaptation
technique on the embedding structure of the Vision Transformer (ViT). The
effectiveness of the proposed method was experimentally confirmed in terms of
the accuracy of semantic segmentation when using a powerful
semantic-segmentation model with ViT called Segmentation Transformer.

</details>


### [15] [Transformer-based Spatial Grounding: A Comprehensive Survey](https://arxiv.org/abs/2507.12739)
*Ijazul Haq,Muhammad Saqib,Yingjie Zhang*

Main category: cs.CV

TL;DR: 这篇论文综述了2018年至2025年间基于transformer的空间定位方法，分析了主要模型架构、数据集和评估指标，提出了趋势和最佳实践。


<details>
  <summary>Details</summary>
Motivation: 尽管空间定位领域取得了进展，但缺乏对现有方法、数据集、评估指标和工业应用的综合分析。

Method: 进行系统文献综述，分析基于transformer的空间定位方法及其模型架构、数据集、评估指标和实践趋势。

Result: 确定了主流模型、常用数据集和评估指标，总结了关键方法学趋势和最佳实践。

Conclusion: 为研究人员和从业者提供了关于开发稳健、可靠、工业化的空间定位模型的重要洞见和结构化指导。

Abstract: Spatial grounding, the process of associating natural language expressions
with corresponding image regions, has rapidly advanced due to the introduction
of transformer-based models, significantly enhancing multimodal representation
and cross-modal alignment. Despite this progress, the field lacks a
comprehensive synthesis of current methodologies, dataset usage, evaluation
metrics, and industrial applicability. This paper presents a systematic
literature review of transformer-based spatial grounding approaches from 2018
to 2025. Our analysis identifies dominant model architectures, prevalent
datasets, and widely adopted evaluation metrics, alongside highlighting key
methodological trends and best practices. This study provides essential
insights and structured guidance for researchers and practitioners,
facilitating the development of robust, reliable, and industry-ready
transformer-based spatial grounding models.

</details>


### [16] [Domain-Enhanced Dual-Branch Model for Efficient and Interpretable Accident Anticipation](https://arxiv.org/abs/2507.12755)
*Yanchen Guan,Haicheng Liao,Chengyue Wang,Bonan Wang,Jiaxun Zhang,Jia Hu,Zhenning Li*

Main category: cs.CV

TL;DR: 本研究提出一种结合视觉信息和结构化文本数据的双分支体系结构，用于交通事故预测，显著提高了预测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 现代自动驾驶技术需要精确且高效的交通事故预测系统，以实现及时干预和损失预防。

Method: 采用双分支架构结合来自行车记录仪视频的视觉信息和事故报告多模态文本数据进行预测；通过大模型（如GPT-4o, Long-CLIP）和提示工程进行特征聚合和反馈优化。

Result: 在DAD、CCD和A3D基准数据集上，验证了该方法在预测准确性、响应能力、计算效率和可解释性上的显著优势。

Conclusion: 新方法在交通事故预测领域达成了全新的性能标杆，推动了该领域的研究发展。

Abstract: Developing precise and computationally efficient traffic accident
anticipation system is crucial for contemporary autonomous driving
technologies, enabling timely intervention and loss prevention. In this paper,
we propose an accident anticipation framework employing a dual-branch
architecture that effectively integrates visual information from dashcam videos
with structured textual data derived from accident reports. Furthermore, we
introduce a feature aggregation method that facilitates seamless integration of
multimodal inputs through large models (GPT-4o, Long-CLIP), complemented by
targeted prompt engineering strategies to produce actionable feedback and
standardized accident archives. Comprehensive evaluations conducted on
benchmark datasets (DAD, CCD, and A3D) validate the superior predictive
accuracy, enhanced responsiveness, reduced computational overhead, and improved
interpretability of our approach, thus establishing a new benchmark for
state-of-the-art performance in traffic accident anticipation.

</details>


### [17] [HairShifter: Consistent and High-Fidelity Video Hair Transfer via Anchor-Guided Animation](https://arxiv.org/abs/2507.12758)
*Wangzheng Shi,Yinglin Zheng,Yuxin Lin,Jianmin Bao,Ming Zeng,Dong Chen*

Main category: cs.CV

TL;DR: 本文提出HairShifter，一种用于视频发型转移的框架，结合了单帧高质量发型转移和视频的平滑一致性，确保了视觉质量和时序一致。


<details>
  <summary>Details</summary>
Motivation: 当前虽然单张图像发型转移技术已有显著进展，但在视频层面，由于需要考虑时序一致性、空间保真性和动态适应性，仍然存在显著挑战。

Method: 提出HairShifter框架，包含Image Hair Transfer模块实现精准的逐帧转换，并借助多尺度门控SPADE解码器实现空间融合和时序一致性。

Result: 实验表明HairShifter在视频发型转移任务中达到了先进的视觉质量、时间一致性和可扩展性性能。

Conclusion: HairShifter提供了新的方法来实现视频发型转移，确立了该领域的一个稳健基线。代码将会开源，为后续研究提供支持。

Abstract: Hair transfer is increasingly valuable across domains such as social media,
gaming, advertising, and entertainment. While significant progress has been
made in single-image hair transfer, video-based hair transfer remains
challenging due to the need for temporal consistency, spatial fidelity, and
dynamic adaptability. In this work, we propose HairShifter, a novel "Anchor
Frame + Animation" framework that unifies high-quality image hair transfer with
smooth and coherent video animation. At its core, HairShifter integrates a
Image Hair Transfer (IHT) module for precise per-frame transformation and a
Multi-Scale Gated SPADE Decoder to ensure seamless spatial blending and
temporal coherence. Our method maintains hairstyle fidelity across frames while
preserving non-hair regions. Extensive experiments demonstrate that HairShifter
achieves state-of-the-art performance in video hairstyle transfer, combining
superior visual quality, temporal consistency, and scalability. The code will
be publicly available. We believe this work will open new avenues for
video-based hairstyle transfer and establish a robust baseline in this field.

</details>


### [18] [Unified Medical Image Segmentation with State Space Modeling Snake](https://arxiv.org/abs/2507.12760)
*Ruicheng Zhang,Haowei Guo,Kanghui Tian,Jun Zhou,Mingliang Yan,Zeyu Zhang,Shen Zhao*

Main category: cs.CV

TL;DR: 提出了一种新的深度蛇框架'Mamba Snake'，通过状态空间建模提升统一医学图像分割性能，特别在五个临床数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 针对多尺度结构多样性和传统像素方法在形态复杂性及特征冲突中的不足，提出了更有效的物体级建模方法。

Method: 设计了Mamba Snake深度蛇框架，将多轮廓演化建模为分层状态空间地图，结合蛇特定的视觉状态空间模块'Mamba Evolution Block'进行复杂形态优化，并引入能量图形态先验。配合双分类协同机制提升检测和分割效率。

Result: 在五个临床数据集上进行验证，模型Dice指标相比现有最优方法提高了3%。

Conclusion: Mamba Snake通过综合多尺度建模及形态优化，有效提升了医学图像分割性能，具有一定的临床实用价值。

Abstract: Unified Medical Image Segmentation (UMIS) is critical for comprehensive
anatomical assessment but faces challenges due to multi-scale structural
heterogeneity. Conventional pixel-based approaches, lacking object-level
anatomical insight and inter-organ relational modeling, struggle with
morphological complexity and feature conflicts, limiting their efficacy in
UMIS. We propose Mamba Snake, a novel deep snake framework enhanced by state
space modeling for UMIS. Mamba Snake frames multi-contour evolution as a
hierarchical state space atlas, effectively modeling macroscopic inter-organ
topological relationships and microscopic contour refinements. We introduce a
snake-specific vision state space module, the Mamba Evolution Block (MEB),
which leverages effective spatiotemporal information aggregation for adaptive
refinement of complex morphologies. Energy map shape priors further ensure
robust long-range contour evolution in heterogeneous data. Additionally, a
dual-classification synergy mechanism is incorporated to concurrently optimize
detection and segmentation, mitigating under-segmentation of microstructures in
UMIS. Extensive evaluations across five clinical datasets reveal Mamba Snake's
superior performance, with an average Dice improvement of 3\% over
state-of-the-art methods.

</details>


### [19] [Think-Before-Draw: Decomposing Emotion Semantics & Fine-Grained Controllable Expressive Talking Head Generation](https://arxiv.org/abs/2507.12761)
*Hanlei Shi,Leyuan Qu,Yu Liu,Di Gao,Yuhua Zheng,Taihao Li*

Main category: cs.CV

TL;DR: 本文提出了“先思考再绘制”（Think-Before-Draw）框架，解决了情感动态人脸生成中语义解析与细粒度表达优化的难题，通过引入链式推理（CoT）和渐进式指导去噪方法改善生成效果，并在多项基准测试上实现了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过增强自然情感表现力改善人机交互体验，并解决当前基于离散情感标签文本的生成方法过于简化的局限性。

Method: 提出了Think-Before-Draw框架，包括：1）利用链式推理（Chain-of-Thought），将抽象情感标签转化为生理驱动的面部肌肉运动描述；2）基于“全局情感定位--局部肌肉控制”机制的渐进式指导去噪策略，以优化微表情动态。

Result: 实验表明，该方法在MEAD和HDTF等基准测试上实现了最先进性能；此外，通过采集人像图片验证了模型的零样本生成能力。

Conclusion: 本文解决了文本驱动情感人脸生成中自然动态表现不足的问题，提出的框架在多个指标上都表现出色，并展现了其广泛的应用潜力。

Abstract: Emotional talking-head generation has emerged as a pivotal research area at
the intersection of computer vision and multimodal artificial intelligence,
with its core value lying in enhancing human-computer interaction through
immersive and empathetic engagement.With the advancement of multimodal large
language models, the driving signals for emotional talking-head generation has
shifted from audio and video to more flexible text. However, current
text-driven methods rely on predefined discrete emotion label texts,
oversimplifying the dynamic complexity of real facial muscle movements and thus
failing to achieve natural emotional expressiveness.This study proposes the
Think-Before-Draw framework to address two key challenges: (1) In-depth
semantic parsing of emotions--by innovatively introducing Chain-of-Thought
(CoT), abstract emotion labels are transformed into physiologically grounded
facial muscle movement descriptions, enabling the mapping from high-level
semantics to actionable motion features; and (2) Fine-grained expressiveness
optimization--inspired by artists' portrait painting process, a progressive
guidance denoising strategy is proposed, employing a "global emotion
localization--local muscle control" mechanism to refine micro-expression
dynamics in generated videos.Our experiments demonstrate that our approach
achieves state-of-the-art performance on widely-used benchmarks, including MEAD
and HDTF. Additionally, we collected a set of portrait images to evaluate our
model's zero-shot generation capability.

</details>


### [20] [World Model-Based End-to-End Scene Generation for Accident Anticipation in Autonomous Driving](https://arxiv.org/abs/2507.12762)
*Yanchen Guan,Haicheng Liao,Chengyue Wang,Xingcheng Liu,Jiaxun Zhang,Zhenning Li*

Main category: cs.CV

TL;DR: 提出了一种结合生成场景增强与自适应时序推理的框架来改进交通事故预测的精度和时效性。


<details>
  <summary>Details</summary>
Motivation: 尽管交通事故预测对自动驾驶系统至关重要，但数据稀缺和关键物体线索缺失仍然是主要挑战。

Method: 通过开发一个高分辨率视频生成管道生成驾驶场景，并利用动态预测模型编码时空关系；以及发布新基准数据集以更好捕捉实际风险。

Result: 实验结果表明，该框架提高了事故预测的准确性和提前量。

Conclusion: 该研究在有限数据和建模挑战下，为安全关键的自动驾驶应用提供了强有力的解决方案。

Abstract: Reliable anticipation of traffic accidents is essential for advancing
autonomous driving systems. However, this objective is limited by two
fundamental challenges: the scarcity of diverse, high-quality training data and
the frequent absence of crucial object-level cues due to environmental
disruptions or sensor deficiencies. To tackle these issues, we propose a
comprehensive framework combining generative scene augmentation with adaptive
temporal reasoning. Specifically, we develop a video generation pipeline that
utilizes a world model guided by domain-informed prompts to create
high-resolution, statistically consistent driving scenarios, particularly
enriching the coverage of edge cases and complex interactions. In parallel, we
construct a dynamic prediction model that encodes spatio-temporal relationships
through strengthened graph convolutions and dilated temporal operators,
effectively addressing data incompleteness and transient visual noise.
Furthermore, we release a new benchmark dataset designed to better capture
diverse real-world driving risks. Extensive experiments on public and newly
released datasets confirm that our framework enhances both the accuracy and
lead time of accident anticipation, offering a robust solution to current data
and modeling limitations in safety-critical autonomous driving applications.

</details>


### [21] [Continuous Marine Tracking via Autonomous UAV Handoff](https://arxiv.org/abs/2507.12763)
*Heegyeong Kim,Alice James,Avishkar Seth,Endrowednes Kuantama,Jane Williamson,Yimeng Feng,Richard Han*

Main category: cs.CV

TL;DR: 该论文提出了一个能够实时跟踪海洋动物（如鲨鱼）的自主无人机视觉系统，突破了单架无人机的续航限制。


<details>
  <summary>Details</summary>
Motivation: 动态海洋环境中的海洋动物监控具有较强的挑战性，现有技术在灯光变化、遮挡及背景杂乱条件下表现不足，同时单一无人机的续航有限。

Method: 系统集成了装有稳定RGB-D摄像头和定制OSTrack pipeline的机载计算机，并设计了多无人机的交接协议来延长覆盖时间，采用自主化追踪与高置信度特征匹配技术。

Result: 在5200帧的鲨鱼数据集中评估，系统实现了81.9%的实时飞行控制追踪成功率，同时在遮挡、光照变化及背景噪声中表现出鲁棒性。此外，多无人机交接框架实现了82.9%的目标覆盖率。

Conclusion: 实验结果证明了协同无人机操作在长时间海洋追踪中的可行性，为可扩展的自主监控奠定了基础。

Abstract: This paper introduces an autonomous UAV vision system for continuous,
real-time tracking of marine animals, specifically sharks, in dynamic marine
environments. The system integrates an onboard computer with a stabilised RGB-D
camera and a custom-trained OSTrack pipeline, enabling visual identification
under challenging lighting, occlusion, and sea-state conditions. A key
innovation is the inter-UAV handoff protocol, which enables seamless transfer
of tracking responsibilities between drones, extending operational coverage
beyond single-drone battery limitations. Performance is evaluated on a curated
shark dataset of 5,200 frames, achieving a tracking success rate of 81.9\%
during real-time flight control at 100 Hz, and robustness to occlusion,
illumination variation, and background clutter. We present a seamless UAV
handoff framework, where target transfer is attempted via high-confidence
feature matching, achieving 82.9\% target coverage. These results confirm the
viability of coordinated UAV operations for extended marine tracking and lay
the groundwork for scalable, autonomous monitoring.

</details>


### [22] [AnyPos: Automated Task-Agnostic Actions for Bimanual Manipulation](https://arxiv.org/abs/2507.12768)
*Hengkai Tan,Yao Feng,Xinyi Mao,Shuhe Huang,Guodong Liu,Zhongkai Hao,Hang Su,Jun Zhu*

Main category: cs.CV

TL;DR: 提出了一种新的任务无关的行为范式，用于提高视觉-语言-行为模型的可扩展性，并引入了自监督框架ATARA和反向动力学模型AnyPos以优化数据收集和学习效果。


<details>
  <summary>Details</summary>
Motivation: 目前的视觉-语言-行为模型高度依赖任务特定的人类演示，限制了其广泛应用并提高了数据获取成本。

Method: 引入任务无关的行为范式，通过自动化框架ATARA改善数据收集效率；同时设计反向动力学模型AnyPos来处理任务无关数据优化学习。

Result: AnyPos-ATARA框架在测试准确率和具体任务（如抓取、挑选和放置、点击）成功率上分别提高了51%和30-40%。

Conclusion: 该研究在提升任务无关数据学习能力的同时减少了数据获取成本，为多任务操作和模型可扩展性提供了有效解决方案。

Abstract: Vision-language-action (VLA) models have shown promise on task-conditioned
control in complex settings such as bimanual manipulation. However, the heavy
reliance on task-specific human demonstrations limits their generalization and
incurs high data acquisition costs. In this work, we present a new notion of
task-agnostic action paradigm that decouples action execution from
task-specific conditioning, enhancing scalability, efficiency, and
cost-effectiveness. To address the data collection challenges posed by this
paradigm -- such as low coverage density, behavioral redundancy, and safety
risks -- we introduce ATARA (Automated Task-Agnostic Random Actions), a
scalable self-supervised framework that accelerates collection by over $
30\times $ compared to human teleoperation. To further enable effective
learning from task-agnostic data, which often suffers from distribution
mismatch and irrelevant trajectories, we propose AnyPos, an inverse dynamics
model equipped with Arm-Decoupled Estimation and a Direction-Aware Decoder
(DAD). We additionally integrate a video-conditioned action validation module
to verify the feasibility of learned policies across diverse manipulation
tasks. Extensive experiments show that the AnyPos-ATARA pipeline yields a 51%
improvement in test accuracy and achieves 30-40% higher success rates in
downstream tasks such as lifting, pick-and-place, and clicking, using
replay-based video validation. Project Page:
https://embodiedfoundation.github.io/vidar_anypos

</details>


### [23] [Local Representative Token Guided Merging for Text-to-Image Generation](https://arxiv.org/abs/2507.12771)
*Min-Jeong Lee,Hee-Dong Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 提出了ReToM，一种旨在加快文本到图像生成模型稳定扩散的高效token合并策略，同时改善了生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决稳定扩散模型中注意力操作带来的时间消耗问题，并提高现有token合并方法的效果。

Method: 提出了局部代表性token引导的合并方法（ReToM），通过在注意力输入中定义局部边界窗口并调整其尺寸，同时引入代表性token保存最重要的局部特征信息。

Result: ReToM在保持推理时间相当的情况下，FID指标提高了6.2%，且CLIP得分更高。

Conclusion: ReToM在保持视觉质量和计算效率平衡方面表现出色，适用于任意注意力机制的图像生成。

Abstract: Stable diffusion is an outstanding image generation model for text-to-image,
but its time-consuming generation process remains a challenge due to the
quadratic complexity of attention operations. Recent token merging methods
improve efficiency by reducing the number of tokens during attention
operations, but often overlook the characteristics of attention-based image
generation models, limiting their effectiveness. In this paper, we propose
local representative token guided merging (ReToM), a novel token merging
strategy applicable to any attention mechanism in image generation. To merge
tokens based on various contextual information, ReToM defines local boundaries
as windows within attention inputs and adjusts window sizes. Furthermore, we
introduce a representative token, which represents the most representative
token per window by computing similarity at a specific timestep and selecting
the token with the highest average similarity. This approach preserves the most
salient local features while minimizing computational overhead. Experimental
results show that ReToM achieves a 6.2% improvement in FID and higher CLIP
scores compared to the baseline, while maintaining comparable inference time.
We empirically demonstrate that ReToM is effective in balancing visual quality
and computational efficiency.

</details>


### [24] [Compact Vision Transformer by Reduction of Kernel Complexity](https://arxiv.org/abs/2507.12780)
*Yancheng Wang,Yingzhen Yang*

Main category: cs.CV

TL;DR: 提出KCR-Transformer，通过通道选择减少Transformer计算成本，减少FLOPs同时提高性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决Transformer在计算机视觉领域中效率问题，提出一种通道选择方法，使得Transformer更紧凑并具有高效的计算性能。

Method: 在Transformer的MLP层中进行输入/输出通道选择，通过理论泛化界限指导剪枝策略，确保在减少计算成本的同时维持性能。

Result: KCR-Transformer减少了FLOPs和参数，同时在多个视觉任务中表现优于原始模型。

Conclusion: KCR-Transformer在确保模型泛化能力的同时，显著减少了计算成本，提升了Transformer在视觉任务上的性能。

Abstract: Self-attention and transformer architectures have become foundational
components in modern deep learning. Recent efforts have integrated transformer
blocks into compact neural architectures for computer vision, giving rise to
various efficient vision transformers. In this work, we introduce Transformer
with Kernel Complexity Reduction, or KCR-Transformer, a compact transformer
block equipped with differentiable channel selection, guided by a novel and
sharp theoretical generalization bound. KCR-Transformer performs input/output
channel selection in the MLP layers of transformer blocks to reduce the
computational cost. Furthermore, we provide a rigorous theoretical analysis
establishing a tight generalization bound for networks equipped with
KCR-Transformer blocks. Leveraging such strong theoretical results, the channel
pruning by KCR-Transformer is conducted in a generalization-aware manner,
ensuring that the resulting network retains a provably small generalization
error. Our KCR-Transformer is compatible with many popular and compact
transformer networks, such as ViT and Swin, and it reduces the FLOPs of the
vision transformers while maintaining or even improving the prediction
accuracy. In the experiments, we replace all the transformer blocks in the
vision transformers with KCR-Transformer blocks, leading to KCR-Transformer
networks with different backbones. The resulting TCR-Transformers achieve
superior performance on various computer vision tasks, achieving even better
performance than the original models with even less FLOPs and parameters.

</details>


### [25] [City-VLM: Towards Multidomain Perception Scene Understanding via Multimodal Incomplete Learning](https://arxiv.org/abs/2507.12795)
*Penglei Sun,Yaoxian Song,Xiangru Zhu,Xiang Liu,Qiang Wang,Yue Liu,Changqun Xia,Tiefeng Li,Yang Yang,Xiaowen Chu*

Main category: cs.CV

TL;DR: 提出了一个名为SVM-City的多域感知户外场景理解数据集及一种融合多模态数据的模型City-VLM，用于提升户外大规模场景的理解能力，实验结果显示性能优于目前的模型。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注室内场景的理解，缺乏对户外大规模场景（多视角、多模态）的研究，而现有的模型在处理这些场景时面临感知数据不足与模态信息整合难的问题。

Method: 构建了多模态、多视角的数据集SVM-City，引入不完整多模态学习方法，通过联合概率分布空间实现数据融合，并设计了City-VLM模型以应对户外场景理解任务。

Result: 在三个典型的户外场景理解任务中，City-VLM平均问答任务性能超过现有LVLMs 18.14%。

Conclusion: 构建的SVM-City数据集和City-VLM模型为户外大规模场景理解提供了有效的工具，展示了广泛的实用性和泛化性能。

Abstract: Scene understanding enables intelligent agents to interpret and comprehend
their environment. While existing large vision-language models (LVLMs) for
scene understanding have primarily focused on indoor household tasks, they face
two significant limitations when applied to outdoor large-scale scene
understanding. First, outdoor scenarios typically encompass larger-scale
environments observed through various sensors from multiple viewpoints (e.g.,
bird view and terrestrial view), while existing indoor LVLMs mainly analyze
single visual modalities within building-scale contexts from humanoid
viewpoints. Second, existing LVLMs suffer from missing multidomain perception
outdoor data and struggle to effectively integrate 2D and 3D visual
information. To address the aforementioned limitations, we build the first
multidomain perception outdoor scene understanding dataset, named
\textbf{\underline{SVM-City}}, deriving from multi\textbf{\underline{S}}cale
scenarios with multi\textbf{\underline{V}}iew and
multi\textbf{\underline{M}}odal instruction tuning data. It contains $420$k
images and $4, 811$M point clouds with $567$k question-answering pairs from
vehicles, low-altitude drones, high-altitude aerial planes, and satellite. To
effectively fuse the multimodal data in the absence of one modality, we
introduce incomplete multimodal learning to model outdoor scene understanding
and design the LVLM named \textbf{\underline{City-VLM}}. Multimodal fusion is
realized by constructing a joint probabilistic distribution space rather than
implementing directly explicit fusion operations (e.g., concatenation).
Experimental results on three typical outdoor scene understanding tasks show
City-VLM achieves $18.14 \%$ performance surpassing existing LVLMs in
question-answering tasks averagely. Our method demonstrates pragmatic and
generalization performance across multiple outdoor scenes.

</details>


### [26] [DeQA-Doc: Adapting DeQA-Score to Document Image Quality Assessment](https://arxiv.org/abs/2507.12796)
*Junjie Gao,Runze Liu,Yingzhe Peng,Shujian Yang,Jin Zhang,Kai Yang,Zhiyuan You*

Main category: cs.CV

TL;DR: 研究提出DeQA-Doc框架，用于基于多模态大语言模型（MLLMs）进行文档质量评估，高效应对多种文档退化情况，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有文档质量评估方法在实际应用中的准确性和鲁棒性不足，难以满足广泛应用需求。因此，希望借助MLLMs的视觉语言能力改进文档质量评估。

Method: 设计DeQA-Doc框架，通过适配DeQA-Score模型，使用软标签策略对文档质量进行连续评分，并放宽分辨率限制以支持高清文档图像。此外，运用集成方法提升性能。

Result: 大量实验表明，DeQA-Doc在多种文档退化场景下的表现明显优于现有基线方法，展现了较强的准确性与泛化能力。

Conclusion: DeQA-Doc成功将MLLMs应用于文档质量评估，并在多种退化类型的文档场景中展现出显著优势，为相关领域提供了强有力的解决方案。

Abstract: Document quality assessment is critical for a wide range of applications
including document digitization, OCR, and archival. However, existing
approaches often struggle to provide accurate and robust quality scores,
limiting their applicability in practical scenarios. With the rapid progress in
Multi-modal Large Language Models (MLLMs), recent MLLM-based methods have
achieved remarkable performance in image quality assessment. In this work, we
extend this success to the document domain by adapting DeQA-Score, a
state-of-the-art MLLM-based image quality scorer, for document quality
assessment. We propose DeQA-Doc, a framework that leverages the visual language
capabilities of MLLMs and a soft label strategy to regress continuous document
quality scores. To adapt DeQA-Score to DeQA-Doc, we adopt two complementary
solutions to construct soft labels without the variance information. Also, we
relax the resolution constrains to support the large resolution of document
images. Finally, we introduce ensemble methods to further enhance the
performance. Extensive experiments demonstrate that DeQA-Doc significantly
outperforms existing baselines, offering accurate and generalizable document
quality assessment across diverse degradation types. Codes and model weights
are available in https://github.com/Junjie-Gao19/DeQA-Doc.

</details>


### [27] [ATL-Diff: Audio-Driven Talking Head Generation with Early Landmarks-Guide Noise Diffusion](https://arxiv.org/abs/2507.12804)
*Hoang-Son Vo,Quang-Vinh Nguyen,Seungwon Kim,Hyung-Jeong Yang,Soonja Yeom,Soo-Hyung Kim*

Main category: cs.CV

TL;DR: ATL-Diff 是一种用于语音驱动的嘴型动画生成的新方法，能够实现同步的高效动画生成。


<details>
  <summary>Details</summary>
Motivation: 解决音频与面部动画同步及降噪与计算成本问题。

Method: 引入了音频到面部标志点的转换模块、基于标记分布噪声去耦的方法和3D身份扩散网络。

Result: 在MEAD和CREMA-D 数据集上的实验表明，ATL-Diff在所有指标上优于现有方法。

Conclusion: ATL-Diff 方法实现了高质量、计算高效的面部动画生成，并很好地保留了面部细节，为多种领域的应用提供了可能性。

Abstract: Audio-driven talking head generation requires precise synchronization between
facial animations and audio signals. This paper introduces ATL-Diff, a novel
approach addressing synchronization limitations while reducing noise and
computational costs. Our framework features three key components: a Landmark
Generation Module converting audio to facial landmarks, a Landmarks-Guide Noise
approach that decouples audio by distributing noise according to landmarks, and
a 3D Identity Diffusion network preserving identity characteristics.
Experiments on MEAD and CREMA-D datasets demonstrate that ATL-Diff outperforms
state-of-the-art methods across all metrics. Our approach achieves near
real-time processing with high-quality animations, computational efficiency,
and exceptional preservation of facial nuances. This advancement offers
promising applications for virtual assistants, education, medical
communication, and digital platforms. The source code is available at:
\href{https://github.com/sonvth/ATL-Diff}{https://github.com/sonvth/ATL-Diff}

</details>


### [28] [Semantic-guided Fine-tuning of Foundation Model for Long-tailed Visual Recognition](https://arxiv.org/abs/2507.12807)
*Yufei Peng,Yonggang Zhang,Yiu-ming Cheung*

Main category: cs.CV

TL;DR: 提出了一种名为Sage的新方法，通过引入语义引导和分布不匹配补偿因子来加强基础模型中长尾视觉识别的性能。


<details>
  <summary>Details</summary>
Motivation: 针对长尾学习场景中，由于类别样本数量不均导致模型性能下降，特别是在低频类上的问题。希望利用基础模型的强表征能力改进此问题。

Method: 提出了Sage方法，通过SG-Adapter引入语义指导，将文本模态中类别描述融入视觉编码器的微调中，并设计分布不匹配补偿因子修正预测偏差问题。

Result: 实验表明，Sage方法在长尾学习的基准数据集上，显著提升了模型性能。

Conclusion: Sage实现了视觉和文本模态的更强对齐，并且修正了长尾分布中预测不一致的问题，是一种有效的长尾学习改进方法。

Abstract: The variance in class-wise sample sizes within long-tailed scenarios often
results in degraded performance in less frequent classes. Fortunately,
foundation models, pre-trained on vast open-world datasets, demonstrate strong
potential for this task due to their generalizable representation, which
promotes the development of adaptive strategies on pre-trained models in
long-tailed learning. Advanced fine-tuning methods typically adjust visual
encoders while neglecting the semantics derived from the frozen text encoder,
overlooking the visual and textual alignment. To strengthen this alignment, we
propose a novel approach, Semantic-guided fine-tuning of foundation model for
long-tailed visual recognition (Sage), which incorporates semantic guidance
derived from textual modality into the visual fine-tuning process.
Specifically, we introduce an SG-Adapter that integrates class descriptions as
semantic guidance to guide the fine-tuning of the visual encoder. The
introduced guidance is passesed through the attention mechanism and enables the
model to focus more on semantically relevant content, strengthening the
alignment between the visual and textual modalities. Due to the inconsistent
class-conditional distributions neglected by the existing loss function, the
resulting prediction bias causes performance improvements for the tail class
less than for the head class, even when the multi-modal alignment is enhanced.
To address this challenge, we propose a novel distribution mismatch-aware
compensation factor, which is specifically designed to rectify the prediction
bias caused by the ignored inconsistent distribution based on our theoretical
analysis, and is seamlessly integrated into the loss function. Extensive
experiments on benchmark datasets demonstrate the effectiveness of the proposed
Sage in enhancing performance in long-tailed learning.

</details>


### [29] [FIQ: Fundamental Question Generation with the Integration of Question Embeddings for Video Question Answering](https://arxiv.org/abs/2507.12816)
*Ju-Young Oh,Ho-Joong Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 本文提出了FIQ方法，通过生成问题和答案对增强VQA模型对视频基础场景的理解，从而提升模型的泛化性和推理能力，实验表明效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法的Q&A对主要聚焦于事件级别，缺乏对视频更广泛上下文的捕捉，限制了模型的场景表示能力和推理能力。

Method: 提出了FIQ方法，通过从视频描述中生成Q&A对，结合问题嵌入，增强模型对基础场景信息的理解；设计了VQ-CAlign模块，结合视觉特征提升任务特定细节的保留。

Result: 在SUTD-TrafficQA数据集上，FIQ方法在性能上超过了现有的基线方法，达到了最先进水平。

Conclusion: 通过生成基础Q&A对和结合视觉特征，FIQ方法显著提升了VQA模型的泛化和推理能力，为多模态任务提供了一种有效的解决方案。

Abstract: Video question answering (VQA) is a multimodal task that requires the
interpretation of a video to answer a given question. Existing VQA methods
primarily utilize question and answer (Q&A) pairs to learn the spatio-temporal
characteristics of video content. However, these annotations are typically
event-centric, which is not enough to capture the broader context of each
video. The absence of essential details such as object types, spatial layouts,
and descriptive attributes restricts the model to learning only a fragmented
scene representation. This issue limits the model's capacity for generalization
and higher-level reasoning. In this paper, we propose a fundamental question
generation with the integration of question embeddings for video question
answering (FIQ), a novel approach designed to strengthen the reasoning ability
of the model by enhancing the fundamental understanding of videos. FIQ
generates Q&A pairs based on descriptions extracted from videos, enriching the
training data with fundamental scene information. Generated Q&A pairs enable
the model to understand the primary context, leading to enhanced
generalizability and reasoning ability. Furthermore, we incorporate a VQ-CAlign
module that assists task-specific question embeddings with visual features,
ensuring that essential domain-specific details are preserved to increase the
adaptability of downstream tasks. Experiments on SUTD-TrafficQA demonstrate
that our FIQ achieves state-of-the-art performance compared to existing
baseline methods.

</details>


### [30] [MCoT-RE: Multi-Faceted Chain-of-Thought and Re-Ranking for Training-Free Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2507.12819)
*Jeong-Woo Park,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 该论文提出了一种用于组合图像检索的无训练零样本框架MCoT-RE，通过多方面的``思维链''和重排序方法实现了更有效的图像检索。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在跨模态交互和视觉上下文的完整利用上存在局限，急需一种更有效的方式处理多模态信息。

Method: 提出了MCoT-RE框架，利用多方面的思维链生成两种关注点不同的文本描述，并结合重排序过程优化图像检索。

Result: 实验表明，MCoT-RE在不需要训练的情况下达到了最佳效果，在FashionIQ数据集的Recall@10指标上提高了6.24%，在CIRR数据集的Recall@1指标上提高了8.58%。

Conclusion: MCoT-RE兼顾了文本修改的指令和参考图像的视觉上下文，为组合图像检索提供了一种高效的方法。

Abstract: Composed Image Retrieval (CIR) is the task of retrieving a target image from
a gallery using a composed query consisting of a reference image and a
modification text. Among various CIR approaches, training-free zero-shot
methods based on pre-trained models are cost-effective but still face notable
limitations. For example, sequential VLM-LLM pipelines process each modality
independently, which often results in information loss and limits cross-modal
interaction. In contrast, methods based on multimodal large language models
(MLLMs) often focus exclusively on applying changes indicated by the text,
without fully utilizing the contextual visual information from the reference
image. To address these issues, we propose multi-faceted Chain-of-Thought with
re-ranking (MCoT-RE), a training-free zero-shot CIR framework. MCoT-RE utilizes
multi-faceted Chain-of-Thought to guide the MLLM to balance explicit
modifications and contextual visual cues, generating two distinct captions: one
focused on modification and the other integrating comprehensive visual-textual
context. The first caption is used to filter candidate images. Subsequently, we
combine these two captions and the reference image to perform multi-grained
re-ranking. This two-stage approach facilitates precise retrieval by aligning
with the textual modification instructions while preserving the visual context
of the reference image. Through extensive experiments, MCoT-RE achieves
state-of-the-art results among training-free methods, yielding improvements of
up to 6.24% in Recall@10 on FashionIQ and 8.58% in Recall@1 on CIRR.

</details>


### [31] [FAR-Net: Multi-Stage Fusion Network with Enhanced Semantic Alignment and Adaptive Reconciliation for Composed Image Retrieval](https://arxiv.org/abs/2507.12823)
*Jeong-Woo Park,Young-Eun Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: FAR-Net通过结合增强语义对齐和自适应融合模块实现更高效的组合图像检索，表现超越当前技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法在组合图像检索中采用的早融合或晚融合存在语义对齐不足等问题，激发了探索新框架的需求。

Method: 提出了FAR-Net框架，包括增强语义对齐模块（ESAM）和自适应调和模块（ARM），分别进行晚融合和早融合操作。

Result: 在CIRR和FashionIQ数据集上测试，Recall@1提高了2.4%，Recall@50提高了1.04%。

Conclusion: FAR-Net提高了视觉和文本的语义对齐，且在组合图像检索任务中表现出鲁棒性和可扩展性。

Abstract: Composed image retrieval (CIR) is a vision language task that retrieves a
target image using a reference image and modification text, enabling intuitive
specification of desired changes. While effectively fusing visual and textual
modalities is crucial, existing methods typically adopt either early or late
fusion. Early fusion tends to excessively focus on explicitly mentioned textual
details and neglect visual context, whereas late fusion struggles to capture
fine-grained semantic alignments between image regions and textual tokens. To
address these issues, we propose FAR-Net, a multi-stage fusion framework
designed with enhanced semantic alignment and adaptive reconciliation,
integrating two complementary modules. The enhanced semantic alignment module
(ESAM) employs late fusion with cross-attention to capture fine-grained
semantic relationships, while the adaptive reconciliation module (ARM) applies
early fusion with uncertainty embeddings to enhance robustness and
adaptability. Experiments on CIRR and FashionIQ show consistent performance
gains, improving Recall@1 by up to 2.4% and Recall@50 by 1.04% over existing
state-of-the-art methods, empirically demonstrating that FAR Net provides a
robust and scalable solution to CIR tasks.

</details>


### [32] [Feature-Enhanced TResNet for Fine-Grained Food Image Classification](https://arxiv.org/abs/2507.12828)
*Lulu Liu,Zhiyong Xiao*

Main category: cs.CV

TL;DR: 提出了一种针对精细纹理食物图像分类的创新方法FE-TResNet，可显著提升分类精度。


<details>
  <summary>Details</summary>
Motivation: 解决现有CNN在形态相似但细节微妙的精细食物图像上的分类困难。

Method: 基于TResNet，结合StyleRM和DCA模块，增强特征提取能力。

Result: 在ChineseFoodNet和CNFOOD-241数据集上的分类准确率分别为81.37%和80.29%。

Conclusion: FE-TResNet方法在精细食物图像分类任务中体现了其有效性和优势。

Abstract: Food is not only a core component of humans' daily diets, but also an
important carrier of cultural heritage and emotional bonds. With the
development of technology, the need for accurate classification of food images
has grown, which is crucial for a variety of application scenarios. However,
existing Convolutional Neural Networks (CNNs) face significant challenges when
dealing with fine-grained food images that are similar in shape but subtle in
detail. To address this challenge, this study presents an innovative method for
classifying food images, named Feature-Enhanced TResNet (FE-TResNet),
specifically designed to address fine-grained food images and accurately
capture subtle features within them. The FE-TResNet method is based on the
TResNet model and integrates Style-based Recalibration Module (StyleRM) and
Deep Channel-wise Attention (DCA) technologies to enhance feature extraction
capabilities. In experimental validation on Chinese food image datasets
ChineseFoodNet and CNFOOD-241, the FE-TResNet method significantly improved
classification accuracy, achieving rates of 81.37% and 80.29%, respectively,
demonstrating its effectiveness and superiority in fine-grained food image
classification.

</details>


### [33] [MVA 2025 Small Multi-Object Tracking for Spotting Birds Challenge: Dataset, Methods, and Results](https://arxiv.org/abs/2507.12832)
*Yuki Kondo,Norimichi Ukita,Riku Kanayama,Yuki Yoshida,Takayuki Yamaguchi,Xiang Yu,Guang Liang,Xinyao Liu,Guan-Zhang Wang,Wei-Ta Chu,Bing-Cheng Chuang,Jia-Hua Lee,Pin-Tseng Kuo,I-Hsuan Chu,Yi-Shein Hsiao,Cheng-Han Wu,Po-Yi Wu,Jui-Chien Tsou,Hsuan-Chi Liu,Chun-Yi Lee,Yuan-Fu Yang,Kosuke Shigematsu,Asuka Shin,Ba Tran*

Main category: cs.CV

TL;DR: 本文提出了SMOT4SB挑战赛，旨在解决小目标追踪中的检测与关联难题，推广时间信息的使用。包含211段视频及多种指标创新。


<details>
  <summary>Details</summary>
Motivation: 小目标追踪因目标像素过小而难以检测和识别，采用时间信息可提升精度。

Method: 引入了SMOT4SB数据集、SO-HOTA新指标，并通过挑战赛验证其有效性。

Result: 赢得挑战的算法比基线提升了5.1倍性能，验证了方法的可行性。

Conclusion: 新的数据集和指标促进了小目标追踪领域的发展，特别是对无人机场景下的关键应用有重要意义。

Abstract: Small Multi-Object Tracking (SMOT) is particularly challenging when targets
occupy only a few dozen pixels, rendering detection and appearance-based
association unreliable. Building on the success of the MVA2023 SOD4SB
challenge, this paper introduces the SMOT4SB challenge, which leverages
temporal information to address limitations of single-frame detection. Our
three main contributions are: (1) the SMOT4SB dataset, consisting of 211 UAV
video sequences with 108,192 annotated frames under diverse real-world
conditions, designed to capture motion entanglement where both camera and
targets move freely in 3D; (2) SO-HOTA, a novel metric combining Dot Distance
with HOTA to mitigate the sensitivity of IoU-based metrics to small
displacements; and (3) a competitive MVA2025 challenge with 78 participants and
308 submissions, where the winning method achieved a 5.1x improvement over the
baseline. This work lays a foundation for advancing SMOT in UAV scenarios with
applications in bird strike avoidance, agriculture, fisheries, and ecological
monitoring.

</details>


### [34] [AnyCap Project: A Unified Framework, Dataset, and Benchmark for Controllable Omni-modal Captioning](https://arxiv.org/abs/2507.12841)
*Yiming Ren,Zhiqiang Lin,Yu Li,Gao Meng,Weiyun Wang,Junjie Wang,Zicheng Lin,Jifeng Dai,Yujiu Yang,Wenhai Wang,Ruihang Chu*

Main category: cs.CV

TL;DR: 设计了AnyCap项目，包括模型、数据集和评估框架，以解决在可控生成多模态标题方面的细粒度控制和评估问题。


<details>
  <summary>Details</summary>
Motivation: 现有模型在多模态精准标题生成中缺乏细粒度控制能力和可靠性评估机制。为此，引入了AnyCap项目，来填补这一空缺。

Method: 提出了AnyCapModel这一轻量级插件框架，无需对基础模型重新训练，通过结合用户指令和模态特征改进标题生成。此外，构建了AnyCapDataset数据集，应对数据稀缺问题，覆盖三种模态、28种用户指令类型和30万条高质量数据。同时，提出了一个新的评估指标AnyCapEval，用以分离内容准确性和风格一致性，实现更加可靠的评估。

Result: AnyCapModel显著提升了多种基础模型的标题质量，在AnyCapEval上的表现出色。例如，ACM-8B将GPT-4o的内容分数提高了45%，风格分数提高了12%。同时在常用基准测试如MIA-Bench和VidCapBench上也实现了显著提升。

Conclusion: 该研究通过AnyCap项目有效提升了多模态标题生成任务的可控性和评估标准，为领域提供了一个综合解决方案。

Abstract: Controllable captioning is essential for precise multimodal alignment and
instruction following, yet existing models often lack fine-grained control and
reliable evaluation protocols. To address this gap, we present the AnyCap
Project, an integrated solution spanning model, dataset, and evaluation. We
introduce AnyCapModel (ACM), a lightweight plug-and-play framework that
enhances the controllability of existing foundation models for omni-modal
captioning without retraining the base model. ACM reuses the original captions
from base models while incorporating user instructions and modality features to
generate improved captions. To remedy the data scarcity in controllable
multimodal captioning, we build AnyCapDataset (ACD), covering three modalities,
28 user-instruction types, and 300\,k high-quality data entries. We further
propose AnyCapEval, a new benchmark that provides more reliable evaluation
metrics for controllable captioning by decoupling content accuracy and
stylistic fidelity. ACM markedly improves caption quality across a diverse set
of base models on AnyCapEval. Notably, ACM-8B raises GPT-4o\'s content scores
by 45\% and style scores by 12\%, and it also achieves substantial gains on
widely used benchmarks such as MIA-Bench and VidCapBench.

</details>


### [35] [SEMT: Static-Expansion-Mesh Transformer Network Architecture for Remote Sensing Image Captioning](https://arxiv.org/abs/2507.12845)
*Khang Truong,Lam Pham,Hieu Tang,Jasmin Lampert,Martin Boyer,Son Phan,Truong Nguyen*

Main category: cs.CV

TL;DR: 本文探讨了遥感图像生成描述文本的方法，提出了一种基于Transformer的网络架构，并通过实验验证其在两个基准数据集上的表现优于当前最好的方法。


<details>
  <summary>Details</summary>
Motivation: 遥感图像解读复杂，需要借助图像描述生成技术，推动其在环境监测、灾害评估和城市规划等领域的应用。

Method: 提出基于Transformer的网络架构，并结合静态扩展、记忆增强自注意力、网格Transformer等技术进行评估和集成。

Result: 在UCM-Caption和NWPU-Caption两个遥感图像数据集上的实验表现优于目前的最优方法，在多数评估指标上更为突出。

Conclusion: 该方法展示出在实际遥感图像系统中的应用潜力，推动了遥感领域的技术发展。

Abstract: Image captioning has emerged as a crucial task in the intersection of
computer vision and natural language processing, enabling automated generation
of descriptive text from visual content. In the context of remote sensing,
image captioning plays a significant role in interpreting vast and complex
satellite imagery, aiding applications such as environmental monitoring,
disaster assessment, and urban planning. This motivates us, in this paper, to
present a transformer based network architecture for remote sensing image
captioning (RSIC) in which multiple techniques of Static Expansion,
Memory-Augmented Self-Attention, Mesh Transformer are evaluated and integrated.
We evaluate our proposed models using two benchmark remote sensing image
datasets of UCM-Caption and NWPU-Caption. Our best model outperforms the
state-of-the-art systems on most of evaluation metrics, which demonstrates
potential to apply for real-life remote sensing image systems.

</details>


### [36] [Simulate, Refocus and Ensemble: An Attention-Refocusing Scheme for Domain Generalization](https://arxiv.org/abs/2507.12851)
*Ziyi Wang,Zhi Gao,Jin Chen,Qingjie Zhao,Xinxiao Wu,Jiebo Luo*

Main category: cs.CV

TL;DR: 提出SRE方法，通过在CLIP中对注意力进行聚焦，减少域移以提高域泛化性能。


<details>
  <summary>Details</summary>
Motivation: CLIP在跨域中难以专注于任务相关区域，导致性能受限。解决方法需改进其对域不变区域的关注能力。

Method: 提出SRE，其中包括三步：模拟域移（增强数据）、聚焦注意力、利用集成学习以捕获域不变特征。

Result: 实验表明，SRE在多个数据集上优于当前先进方法。

Conclusion: SRE通过注意力重聚焦，提升了CLIP的泛化性能，并得到了显著的实验效果。代码已公开。

Abstract: Domain generalization (DG) aims to learn a model from source domains and
apply it to unseen target domains with out-of-distribution data. Owing to
CLIP's strong ability to encode semantic concepts, it has attracted increasing
interest in domain generalization. However, CLIP often struggles to focus on
task-relevant regions across domains, i.e., domain-invariant regions, resulting
in suboptimal performance on unseen target domains. To address this challenge,
we propose an attention-refocusing scheme, called Simulate, Refocus and
Ensemble (SRE), which learns to reduce the domain shift by aligning the
attention maps in CLIP via attention refocusing. SRE first simulates domain
shifts by performing augmentation on the source data to generate simulated
target domains. SRE then learns to reduce the domain shifts by refocusing the
attention in CLIP between the source and simulated target domains. Finally, SRE
utilizes ensemble learning to enhance the ability to capture domain-invariant
attention maps between the source data and the simulated target data. Extensive
experimental results on several datasets demonstrate that SRE generally
achieves better results than state-of-the-art methods. The code is available
at: https://github.com/bitPrincy/SRE-DG.

</details>


### [37] [SCORE: Scene Context Matters in Open-Vocabulary Remote Sensing Instance Segmentation](https://arxiv.org/abs/2507.12857)
*Shiqi Huang,Shuting He,Huaiyuan Qin,Bihan Wen*

Main category: cs.CV

TL;DR: 现有遥感实例分割方法主要针对近似词汇集预测，难以识别新类别或跨数据集泛化，本文通过SCORE框架引入开放词汇学习，并整合多粒度场景上下文以增强视觉和文本表示，实验结果表明SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在遥感场景中难以泛化，特别是在处理多样化景观、季节变化和空中图像中的小型或模糊目标时存在挑战。

Method: 提出SCORE框架，整合多粒度场景上下文，包括区域上下文和全局上下文；引入区域感知集成以优化类别嵌入，及全局上下文适配以丰富遥感文本嵌入。

Result: 提出的新方法在开放词汇遥感实例分割基准测试中实现了SOTA性能。

Conclusion: SCORE框架提供了针对大规模实际地理空间分析的稳健解决方案。

Abstract: Most existing remote sensing instance segmentation approaches are designed
for close-vocabulary prediction, limiting their ability to recognize novel
categories or generalize across datasets. This restricts their applicability in
diverse Earth observation scenarios. To address this, we introduce
open-vocabulary (OV) learning for remote sensing instance segmentation. While
current OV segmentation models perform well on natural image datasets, their
direct application to remote sensing faces challenges such as diverse
landscapes, seasonal variations, and the presence of small or ambiguous objects
in aerial imagery. To overcome these challenges, we propose $\textbf{SCORE}$
($\textbf{S}$cene $\textbf{C}$ontext matters in $\textbf{O}$pen-vocabulary
$\textbf{RE}$mote sensing instance segmentation), a framework that integrates
multi-granularity scene context, i.e., regional context and global context, to
enhance both visual and textual representations. Specifically, we introduce
Region-Aware Integration, which refines class embeddings with regional context
to improve object distinguishability. Additionally, we propose Global Context
Adaptation, which enriches naive text embeddings with remote sensing global
context, creating a more adaptable and expressive linguistic latent space for
the classifier. We establish new benchmarks for OV remote sensing instance
segmentation across diverse datasets. Experimental results demonstrate that,
our proposed method achieves SOTA performance, which provides a robust solution
for large-scale, real-world geospatial analysis. Our code is available at
https://github.com/HuangShiqi128/SCORE.

</details>


### [38] [WhoFi: Deep Person Re-Identification via Wi-Fi Channel Signal Encoding](https://arxiv.org/abs/2507.12869)
*Danilo Avola,Daniele Pannone,Dario Montagnini,Emad Emam*

Main category: cs.CV

TL;DR: 本文介绍了一种利用Wi-Fi信号进行人物再识别的新方法WhoFi。通过深度学习技术提取和处理Wi-Fi信道状态信息（CSI），取得与视觉方法相媲美的结果。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉方法在数据照明、遮挡和角度等问题上表现不佳，因此本文提出从Wi-Fi信号中提取生物特征以改进效果。

Method: 设计一种基于变压器编码器的深度神经网络，通过处理Wi-Fi信号的信道状态信息（CSI），并结合批次负损失函数训练网络以学习鲁棒的生物特征签名。

Result: 在NTU-Fi数据集上实验表明，WhoFi方法能够实现与最新视觉技术相当的竞争性表现。

Conclusion: 利用Wi-Fi信号进行人物再识别的方式是有效的，可成为解决传统视觉方法局限的一种新方向。

Abstract: Person Re-Identification is a key and challenging task in video surveillance.
While traditional methods rely on visual data, issues like poor lighting,
occlusion, and suboptimal angles often hinder performance. To address these
challenges, we introduce WhoFi, a novel pipeline that utilizes Wi-Fi signals
for person re-identification. Biometric features are extracted from Channel
State Information (CSI) and processed through a modular Deep Neural Network
(DNN) featuring a Transformer-based encoder. The network is trained using an
in-batch negative loss function to learn robust and generalizable biometric
signatures. Experiments on the NTU-Fi dataset show that our approach achieves
competitive results compared to state-of-the-art methods, confirming its
effectiveness in identifying individuals via Wi-Fi signals.

</details>


### [39] [HRSeg: High-Resolution Visual Perception and Enhancement for Reasoning Segmentation](https://arxiv.org/abs/2507.12883)
*Weihuang Lin,Yiwei Ma,Xiaoshuai Sun,Shuting He,Jiayi Ji,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: 提出了一种用于高分辨率细粒度感知的高效模型HRSeg，并通过HRP和HRE模块实现更高精度的分割，提高性能的同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法在感知分辨率上受到限制，特别是视觉编码器通常预训练于较低分辨率，即使通过插值提升分辨率效果也有限且成本高。

Method: 提出HRSeg模型，包含两大创新模块：1) 高分辨率感知模块（HRP），通过裁剪高分辨率图像整合局部与全局特征；2) 高分辨率增强模块（HRE），通过整合高分辨率图像的信息精细化掩码特征并与文本特征对齐。

Result: 通过消融研究验证模块有效性，并在多种基准数据集上表现出色。

Conclusion: HRSeg模型在提升细粒度分割精度和计算效率上表现优越，是解决推理分割任务的重要创新方法。

Abstract: The reasoning segmentation task involves segmenting objects within an image
by interpreting implicit user instructions, which may encompass subtleties such
as contextual cues and open-world knowledge. Despite significant advancements
made by existing approaches, they remain constrained by low perceptual
resolution, as visual encoders are typically pre-trained at lower resolutions.
Furthermore, simply interpolating the positional embeddings of visual encoders
to enhance perceptual resolution yields only marginal performance improvements
while incurring substantial computational costs. To address this, we propose
HRSeg, an efficient model with high-resolution fine-grained perception. It
features two key innovations: High-Resolution Perception (HRP) and
High-Resolution Enhancement (HRE). The HRP module processes high-resolution
images through cropping, integrating local and global features for
multi-granularity quality. The HRE module enhances mask features by integrating
fine-grained information from high-resolution images, refining their alignment
with text features for precise segmentation. Extensive ablation studies
validate the effectiveness of our modules, while comprehensive experiments on
multiple benchmark datasets demonstrate HRSeg's superior performance.

</details>


### [40] [From Neck to Head: Bio-Impedance Sensing for Head Pose Estimation](https://arxiv.org/abs/2507.12884)
*Mengxi Liu,Lala Shakti Swarup Ray,Sizhen Bian,Ko Watanabe,Ankur Bhatt,Joanna Sorysz,Russel Torah,Bo Zhou,Paul Lukowicz*

Main category: cs.CV

TL;DR: 提出了一种名为NeckSense的新型可穿戴系统，用于通过颈部生物电阻抗感测实现头部姿态跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多依赖视觉技术，而这些方法受限于视线遮挡等问题。因此，需要一种紧凑、不依赖视线的头部跟踪方法。

Method: 设计了一种便携式项链式设备，利用嵌入的软性干电极感应颈部组织阻抗变化，并通过深度学习框架结合解剖学约束，优化了姿态估计过程。

Result: 通过与最先进的姿态估计模型对比，验证了在不同用户的头部动作情况下，系统平均误差为25.9毫米，表现接近视觉方法。

Conclusion: NeckSense作为一款非视线依赖的生物电阻抗可穿戴设备，其头部追踪性能与现有视觉方法相当，具有实用潜力。

Abstract: We present NeckSense, a novel wearable system for head pose tracking that
leverages multi-channel bio-impedance sensing with soft, dry electrodes
embedded in a lightweight, necklace-style form factor. NeckSense captures
dynamic changes in tissue impedance around the neck, which are modulated by
head rotations and subtle muscle activations. To robustly estimate head pose,
we propose a deep learning framework that integrates anatomical priors,
including joint constraints and natural head rotation ranges, into the loss
function design. We validate NeckSense on 7 participants using the current SOTA
pose estimation model as ground truth. Our system achieves a mean per-vertex
error of 25.9 mm across various head movements with a leave-one-person-out
cross-validation method, demonstrating that a compact, line-of-sight-free
bio-impedance wearable can deliver head-tracking performance comparable to SOTA
vision-based methods.

</details>


### [41] [Camera-based implicit mind reading by capturing higher-order semantic dynamics of human gaze within environmental context](https://arxiv.org/abs/2507.12889)
*Mengke Song,Yuge Xie,Qi Cui,Luming Li,Xinyu Liu,Guotao Wang,Chenglizhao Chen,Shanchen Pang*

Main category: cs.CV

TL;DR: 文章提出一种基于摄像头的新型无感知情感识别方法，通过整合凝视固定模式、环境语义和时间动态，无需专业硬件即可实现实时、连续的情感识别。


<details>
  <summary>Details</summary>
Motivation: 现有情感识别方法过度依赖显性信号，忽视环境上下文的影响，且复杂生理信号传感器限制自然行为和可扩展性，凝视方法也无法捕获凝视与环境的深度动态联系，无法揭示情感与隐性行为之间的深层关系。

Method: 利用标准高清摄像头，捕获用户眼部外观和头部移动，估算凝视轨迹，并建模凝视行为的空间、语义和时间维度动态，以捕捉视觉注意力与环境的动态交互，提出一种无感知、实时的情感识别方法。

Result: 方法展示了情绪不仅是生理反应，还与人类与环境互动的复杂结果有关，实现了高泛化性和低部署成本的情感识别。

Conclusion: 该方法提供了一种无感知、实时、持续性且经济高效的情感识别新方式，展现出其在自然环境下的实用潜力。

Abstract: Emotion recognition,as a step toward mind reading,seeks to infer internal
states from external cues.Most existing methods rely on explicit signals-such
as facial expressions,speech,or gestures-that reflect only bodily responses and
overlook the influence of environmental context.These cues are often
voluntary,easy to mask,and insufficient for capturing deeper,implicit emotions.
Physiological signal-based approaches offer more direct access to internal
states but require complex sensors that compromise natural behavior and limit
scalability.Gaze-based methods typically rely on static fixation analysis and
fail to capture the rich,dynamic interactions between gaze and the
environment,and thus cannot uncover the deep connection between emotion and
implicit behavior.To address these limitations,we propose a novel
camera-based,user-unaware emotion recognition approach that integrates gaze
fixation patterns with environmental semantics and temporal dynamics.Leveraging
standard HD cameras,our method unobtrusively captures users'eye appearance and
head movements in natural settings-without the need for specialized hardware or
active user participation.From these visual cues,the system estimates gaze
trajectories over time and space, providing the basis for modeling the spatial,
semantic,and temporal dimensions of gaze behavior. This allows us to capture
the dynamic interplay between visual attention and the surrounding
environment,revealing that emotions are not merely physiological responses but
complex outcomes of human-environment interactions.The proposed approach
enables user-unaware,real-time,and continuous emotion recognition,offering high
generalizability and low deployment cost.

</details>


### [42] [LanePerf: a Performance Estimation Framework for Lane Detection](https://arxiv.org/abs/2507.12894)
*Yin Wu,Daniel Slieter,Ahmed Abouelazm,Christian Hubschneider,J. Marius Zöllner*

Main category: cs.CV

TL;DR: 该论文提出了一种名为LanePerf的框架，用于在车道检测领域无需标注的情况下高效评估模型性能，在多个域转移的实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在没有标注数据的情况下，对车道检测模型性能进行鲁棒评估是一个未被充分探索的重要问题，现有方法缺乏适用于车道检测任务的解决方案。

Method: 作者首先将五种图像分类的性能估计方法适配到车道检测任务上，同时提出LanePerf框架，该框架结合了预训练图像编码器和基于DeepSets的架构，可以有效应对零车道检测场景和大范围域转移问题。

Result: LanePerf在多个域转移场景（场景、天气、时间）上进行了广泛实验，相较基准表现更好，取得了较低的MAE（0.117）和更高的Spearman秩相关系数（0.727）。

Conclusion: LanePerf框架为ADAS中的无需标注的性能估计问题提供了更可靠的解决方案，有助于提高模型的测试效率和驾驶安全性。

Abstract: Lane detection is a critical component of Advanced Driver-Assistance Systems
(ADAS) and Automated Driving System (ADS), providing essential spatial
information for lateral control. However, domain shifts often undermine model
reliability when deployed in new environments. Ensuring the robustness and
safety of lane detection models typically requires collecting and annotating
target domain data, which is resource-intensive. Estimating model performance
without ground-truth labels offers a promising alternative for efficient
robustness assessment, yet remains underexplored in lane detection. While
previous work has addressed performance estimation in image classification,
these methods are not directly applicable to lane detection tasks. This paper
first adapts five well-performing performance estimation methods from image
classification to lane detection, building a baseline. Addressing the
limitations of prior approaches that solely rely on softmax scores or lane
features, we further propose a new Lane Performance Estimation Framework
(LanePerf), which integrates image and lane features using a pretrained image
encoder and a DeepSets-based architecture, effectively handling zero-lane
detection scenarios and large domain-shift cases. Extensive experiments on the
OpenLane dataset, covering diverse domain shifts (scenes, weather, hours),
demonstrate that our LanePerf outperforms all baselines, achieving a lower MAE
of 0.117 and a higher Spearman's rank correlation coefficient of 0.727. These
findings pave the way for robust, label-free performance estimation in ADAS,
supporting more efficient testing and improved safety in challenging driving
scenarios.

</details>


### [43] [Federated Learning for Commercial Image Sources](https://arxiv.org/abs/2507.12903)
*Shreyansh Jain,Koteswar Rao Jerripothula*

Main category: cs.CV

TL;DR: 提出了首个针对联邦学习设计的图像分类数据集以及两种新的联邦学习算法（Fed-Cyclic和Fed-Star）。


<details>
  <summary>Details</summary>
Motivation: 当前联邦学习虽然保护隐私但缺少专门设计的图像分类数据集，同时面临统计异质性等挑战。

Method: 创建了一个包含31类、23326张图像的新数据集，并提出了两种新算法：Fed-Cyclic采用循环拓扑更新权重，Fed-Star采用星型拓扑应对统计异质性。

Result: 实验表明，Fed-Cyclic和Fed-Star在新数据集上的表现优于现有基准方法。

Conclusion: 本文为联邦学习提供了一个专用数据集，并通过创新算法提高了模型性能，为隐私保护和分布式学习提供了新方向。

Abstract: Federated Learning is a collaborative machine learning paradigm that enables
multiple clients to learn a global model without exposing their data to each
other. Consequently, it provides a secure learning platform with
privacy-preserving capabilities. This paper introduces a new dataset containing
23,326 images collected from eight different commercial sources and classified
into 31 categories, similar to the Office-31 dataset. To the best of our
knowledge, this is the first image classification dataset specifically designed
for Federated Learning. We also propose two new Federated Learning algorithms,
namely Fed-Cyclic and Fed-Star. In Fed-Cyclic, a client receives weights from
its previous client, updates them through local training, and passes them to
the next client, thus forming a cyclic topology. In Fed-Star, a client receives
weights from all other clients, updates its local weights through
pre-aggregation (to address statistical heterogeneity) and local training, and
sends its updated local weights to all other clients, thus forming a star-like
topology. Our experiments reveal that both algorithms perform better than
existing baselines on our newly introduced dataset.

</details>


### [44] [AthleticsPose: Authentic Sports Motion Dataset on Athletic Field and Evaluation of Monocular 3D Pose Estimation Ability](https://arxiv.org/abs/2507.12905)
*Tomohiro Suzuki,Ryota Tanaka,Calvin Yeung,Keisuke Fujii*

Main category: cs.CV

TL;DR: 本文提出一种通过单目3D姿态估计进行运动分析的方法，创建了新数据集AthleticsPose，并表明数据真实性对模型性能提升至关重要。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过单目3D姿态估计代替昂贵的运动捕捉系统，但受限于数据集与任务可靠性问题。

Method: 创建AthleticsPose数据集，训练并评估3D姿态估计模型，分析准确性对不同条件的敏感性并进行运动指标案例研究。

Result: 在AthleticsPose数据集上训练的模型显著优于基准模型，MPJPE降低约75%，并揭示估计精度受视角与主体缩放影响。

Conclusion: 本文为单目3D姿态估计在运动分析中的应用提供了数据集支持，并强调真实运动数据的重要性，同时明确其潜力与局限性。

Abstract: Monocular 3D pose estimation is a promising, flexible alternative to costly
motion capture systems for sports analysis. However, its practical application
is hindered by two factors: a lack of realistic sports datasets and unclear
reliability for sports tasks. To address these challenges, we introduce the
AthleticsPose dataset, a new public dataset featuring ``real'' motions captured
from 23 athletes performing various athletics events on an athletic field.
Using this dataset, we trained a representative 3D pose estimation model and
performed a comprehensive evaluation. Our results show that the model trained
on AthleticsPose significantly outperforms a baseline model trained on an
imitated sports motion dataset, reducing MPJPE by approximately 75 %. These
results show the importance of training on authentic sports motion data, as
models based on imitated motions do not effectively transfer to real-world
motions. Further analysis reveals that estimation accuracy is sensitive to
camera view and subject scale. In case studies of kinematic indicators, the
model demonstrated the potential to capture individual differences in knee
angles but struggled with higher-speed metrics, such as knee-drive velocity,
due to prediction biases. This work provides the research community with a
valuable dataset and clarifies the potential and practical limitations of using
monocular 3D pose estimation for sports motion analysis. Our dataset, code, and
checkpoints are available at https://github.com/SZucchini/AthleticsPose.

</details>


### [45] [Argus: Leveraging Multiview Images for Improved 3-D Scene Understanding With Large Language Models](https://arxiv.org/abs/2507.12916)
*Yifan Xu,Chao Zhang,Hanqi Jiang,Xiaoyan Wang,Ruifei Ma,Yiwei Li,Zihao Wu,Zeju Li,Xiangde Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Argus的3D多模态框架，用以增强LLM对3D场景的理解，通过融合2D多视角图像和3D点云来补充信息，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前在3D场景理解中，基于3D点云的方法会面临信息丢失问题，而2D多视角图像可提供更详细的场景组件表示，解决复杂结构物体的失真问题。

Method: 提出了Argus框架，它通过将多视角图像与相机位姿融合为视图场景特征，与3D特征交互，生成全面的3D场景嵌入。同时兼容多模态输入，包括文本指令、2D图像和3D点云。

Result: 通过大量实验证明，Argus在众多下游任务中性能优于现有的3D大多模态基础模型（3D-LMM）。

Conclusion: Argus框架有效弥补了3D点云重建中的信息丢失问题，提升了LLM对3D世界的理解能力，证明其在3D场景理解任务中的出色表现。

Abstract: Advancements in foundation models have made it possible to conduct
applications in various downstream tasks. Especially, the new era has witnessed
a remarkable capability to extend Large Language Models (LLMs) for tackling
tasks of 3D scene understanding. Current methods rely heavily on 3D point
clouds, but the 3D point cloud reconstruction of an indoor scene often results
in information loss. Some textureless planes or repetitive patterns are prone
to omission and manifest as voids within the reconstructed 3D point clouds.
Besides, objects with complex structures tend to introduce distortion of
details caused by misalignments between the captured images and the dense
reconstructed point clouds. 2D multi-view images present visual consistency
with 3D point clouds and provide more detailed representations of scene
components, which can naturally compensate for these deficiencies. Based on
these insights, we propose Argus, a novel 3D multimodal framework that
leverages multi-view images for enhanced 3D scene understanding with LLMs. In
general, Argus can be treated as a 3D Large Multimodal Foundation Model
(3D-LMM) since it takes various modalities as input(text instructions, 2D
multi-view images, and 3D point clouds) and expands the capability of LLMs to
tackle 3D tasks. Argus involves fusing and integrating multi-view images and
camera poses into view-as-scene features, which interact with the 3D features
to create comprehensive and detailed 3D-aware scene embeddings. Our approach
compensates for the information loss while reconstructing 3D point clouds and
helps LLMs better understand the 3D world. Extensive experiments demonstrate
that our method outperforms existing 3D-LMMs in various downstream tasks.

</details>


### [46] [DMQ: Dissecting Outliers of Diffusion Models for Post-Training Quantization](https://arxiv.org/abs/2507.12933)
*Dongyeun Lee,Jiwan Hur,Hyounguk Shon,Jae Young Lee,Junmo Kim*

Main category: cs.CV

TL;DR: 本文提出DMQ方法，通过结合学习等效缩放（LES）和通道级二次方倍数缩放（PTS），解决扩散模型低位宽量化中的性能问题，显著降低计算成本并提升结果质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成中表现出色，但计算成本高昂，对资源受限环境中的部署构成挑战。已有量化方法忽视了离群点，导致低位宽时性能下降。

Method: 提出DMQ方法结合LES与PTS，优化通道级缩放因子分配，减小量化误差；引入自适应时间步加权方案，优先处理关键步；采用通道级PTS解决高通道差异问题，并结合投票算法增强稳定性。

Result: 实验证明，在W4A6和W4A8等低位宽情况下，DMQ方法能够显著提升图像生成质量和模型稳定性。

Conclusion: DMQ方法在低位宽量化领域表现优异，为计算资源受限场景提供了有效解决方案。代码已开源并可供进一步验证。

Abstract: Diffusion models have achieved remarkable success in image generation but
come with significant computational costs, posing challenges for deployment in
resource-constrained environments. Recent post-training quantization (PTQ)
methods have attempted to mitigate this issue by focusing on the iterative
nature of diffusion models. However, these approaches often overlook outliers,
leading to degraded performance at low bit-widths. In this paper, we propose a
DMQ which combines Learned Equivalent Scaling (LES) and channel-wise
Power-of-Two Scaling (PTS) to effectively address these challenges. Learned
Equivalent Scaling optimizes channel-wise scaling factors to redistribute
quantization difficulty between weights and activations, reducing overall
quantization error. Recognizing that early denoising steps, despite having
small quantization errors, crucially impact the final output due to error
accumulation, we incorporate an adaptive timestep weighting scheme to
prioritize these critical steps during learning. Furthermore, identifying that
layers such as skip connections exhibit high inter-channel variance, we
introduce channel-wise Power-of-Two Scaling for activations. To ensure robust
selection of PTS factors even with small calibration set, we introduce a voting
algorithm that enhances reliability. Extensive experiments demonstrate that our
method significantly outperforms existing works, especially at low bit-widths
such as W4A6 (4-bit weight, 6-bit activation) and W4A8, maintaining high image
generation quality and model stability. The code is available at
https://github.com/LeeDongYeun/dmq.

</details>


### [47] [A Deep-Learning Framework for Land-Sliding Classification from Remote Sensing Image](https://arxiv.org/abs/2507.12939)
*Hieu Tang,Truong Vo,Dong Pham,Toan Nguyen,Lam Pham,Truong Nguyen*

Main category: cs.CV

TL;DR: 本文提出结合深度学习与卫星影像的滑坡检测框架，从数据增强到后处理分类，显著提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 在滑坡检测中，优化深度学习架构以提升性能且防止过拟合是重大挑战。本文旨在通过结合深度学习与遥感影像来解决这些问题。

Method: 框架采用在线与离线数据增强解决数据不平衡问题，利用EfficientNet_Large神经网络提取特征，并通过后续SVM分类器增强分类性能。

Result: 在Zindi竞赛的公共测试集上，该模型取得了0.8938的F1分数。

Conclusion: 所提出的框架有效平衡与提升了滑坡检测的分类性能，具有实际应用价值。

Abstract: The use of satellite imagery combined with deep learning to support automatic
landslide detection is becoming increasingly widespread. However, selecting an
appropriate deep learning architecture to optimize performance while avoiding
overfitting remains a critical challenge. To address these issues, we propose a
deep-learning based framework for landslide detection from remote sensing image
in this paper. The proposed framework presents an effective combination of the
online an offline data augmentation to tackle the imbalanced data, a backbone
EfficientNet\_Large deep learning model for extracting robust embedding
features, and a post-processing SVM classifier to balance and enhance the
classification performance. The proposed model achieved an F1-score of 0.8938
on the public test set of the Zindi challenge.

</details>


### [48] [Weakly Supervised Visible-Infrared Person Re-Identification via Heterogeneous Expert Collaborative Consistency Learning](https://arxiv.org/abs/2507.12942)
*Yafei Zhang,Lingqi Kong,Huafeng Li,Jie Wen*

Main category: cs.CV

TL;DR: 该论文探讨了弱监督的跨模态行人重识别方法，通过仅使用单模态身份标签解决缺乏跨模态标签的问题，设计了异构专家协同一致性学习框架以改进模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了减少跨模态行人重识别模型对标注数据的依赖，并解决特定情况下跨模态身份标签不可用的问题。

Method: 提出一种基于异构专家的协同一致性学习框架，各模态下独立训练分类专家，并通过专家预测进行跨模态样本身份关联，同时设计了跨模态关系融合机制提升预测精度。

Result: 实验结果在两个具有挑战性的数据集上验证了该方法的有效性。

Conclusion: 通过弱监督方式显著提升了跨模态身份识别性能，模型能够更好地提取模态无关特征。

Abstract: To reduce the reliance of visible-infrared person re-identification (ReID)
models on labeled cross-modal samples, this paper explores a weakly supervised
cross-modal person ReID method that uses only single-modal sample identity
labels, addressing scenarios where cross-modal identity labels are unavailable.
To mitigate the impact of missing cross-modal labels on model performance, we
propose a heterogeneous expert collaborative consistency learning framework,
designed to establish robust cross-modal identity correspondences in a weakly
supervised manner. This framework leverages labeled data from each modality to
independently train dedicated classification experts. To associate cross-modal
samples, these classification experts act as heterogeneous predictors,
predicting the identities of samples from the other modality. To improve
prediction accuracy, we design a cross-modal relationship fusion mechanism that
effectively integrates predictions from different experts. Under the implicit
supervision provided by cross-modal identity correspondences, collaborative and
consistent learning among the experts is encouraged, significantly enhancing
the model's ability to extract modality-invariant features and improve
cross-modal identity recognition. Experimental results on two challenging
datasets validate the effectiveness of the proposed method.

</details>


### [49] [Analysis of Image-and-Text Uncertainty Propagation in Multimodal Large Language Models with Cardiac MR-Based Applications](https://arxiv.org/abs/2507.12945)
*Yucheng Tang,Yunguan Fu,Weixi Yi,Yipei Wang,Daniel C. Alexander,Rhodri Davies,Yipeng Hu*

Main category: cs.CV

TL;DR: 本文提出了基于多模态不确定性传播模型（MUPM），通过整合心脏MR图像和数字健康记录的数据，分析和量化多模态输入的不确定性关系，并展示其在临床应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs在多模态和不确定性分解领域仍缺乏深入理解与应用。本文旨在探索交互关系及不确定性分解在多模态数据处理中的实用性，尤其是其在临床中的潜力。

Method: 本文提出了一种多模态不确定性传播模型（MUPM），通过从图像和文本等多模态输入中提取数据的不确定性并量化其关系，基于真实临床数据进行模型优化与实验设计。

Result: 实验表明，MUPM在不同输入数据分布及下游任务中具有良好的泛化能力与传递性，且在预测心脏疾病的新任务中展现了模型的鲁棒性。同时，该模型减少多余因子辨识和不确定性分析的多模态数据需求，具有潜在临床价值。

Conclusion: 通过MUPM模型，不仅能够量化多模态不确定性间的关系，还能实现不确定性分析的鲁棒性和泛化性，同时为心脏疾病预测及其他临床应用提供了实用方法。

Abstract: Multimodal large language models (MLLMs) can process and integrate
information from multimodality sources, such as text and images. However,
interrelationship among input modalities, uncertainties due to individual
uni-modal data and potential clinical applications following such an
uncertainty decomposition are yet fully understood in the context of
large-scale MLLMs. In this work, we propose a multimodal uncertainty
propagation model (MUPM) based on uncertainty propagation, to characterise the
relationship among the uncertainties arising from image-only, text-only, and
joint image-text variations in MLLM inputs. Using real clinical data consisting
of cardiac MR scans and digital health records, we describe that MUPMs can be
optimised robustly with a few samples. We then show that the fitted MUPMs are
generalisable across different input data distributions and, perhaps
surprisingly, across different downstream tasks. Such a transferability may be
explained by the shared pretraining, comparatively light MLLM fine-tuning,
along with the low-dimensional nature of the MUPMs. More importantly, this
learned transferability, quantifying the relationship between these
uncertainties, led to direct clinical applications in which uncertainties may
be estimated and thus analysed robustly for varying data or even a novel set of
cardiac disease prediction tasks. In addition, we show experimentally the
efficiency in multimodal data required for estimating the overall uncertainty
and its ability to identify redundant factors, both of which are considered
practical yet clinically useful applications with the proposed MUPMs. Codes are
available at https://github.com/yucheng722/MUPM.

</details>


### [50] [LoViC: Efficient Long Video Generation with Context Compression](https://arxiv.org/abs/2507.12952)
*Jiaxiu Jiang,Wenbo Li,Jingjing Ren,Yuping Qiu,Yong Guo,Xiaogang Xu,Han Wu,Wangmeng Zuo*

Main category: cs.CV

TL;DR: 本论文介绍了一个名为LoViC的框架，采用段落生成的方式实现长时视频生成，并利用FlexFormer对视频和文字进行联合压缩，解决了传统方法在时序一致性和扩展性上的问题。


<details>
  <summary>Details</summary>
Motivation: 针对扩散式变压器在长时视频生成中的时序一致性和扩展性问题，该论文试图通过开发新的框架来提升长时视频生成的质量和灵活性。

Method: 提出LoViC框架，基于段落生成方法，核心组件是FlexFormer自编码器，可以联合压缩视频和文本，同时支持灵活的输入长度和位置感知的时间上下文编码。

Result: 通过大量实验验证了该方法在多种任务下的高效性和多功能性。

Conclusion: LoViC框架通过创新的压缩与生成技术，有效解决了长时扩散视频生成中的核心问题，在性能和灵活性上达到了新的高度。

Abstract: Despite recent advances in diffusion transformers (DiTs) for text-to-video
generation, scaling to long-duration content remains challenging due to the
quadratic complexity of self-attention. While prior efforts -- such as sparse
attention and temporally autoregressive models -- offer partial relief, they
often compromise temporal coherence or scalability. We introduce LoViC, a
DiT-based framework trained on million-scale open-domain videos, designed to
produce long, coherent videos through a segment-wise generation process. At the
core of our approach is FlexFormer, an expressive autoencoder that jointly
compresses video and text into unified latent representations. It supports
variable-length inputs with linearly adjustable compression rates, enabled by a
single query token design based on the Q-Former architecture. Additionally, by
encoding temporal context through position-aware mechanisms, our model
seamlessly supports prediction, retradiction, interpolation, and multi-shot
generation within a unified paradigm. Extensive experiments across diverse
tasks validate the effectiveness and versatility of our approach.

</details>


### [51] [cIDIR: Conditioned Implicit Neural Representation for Regularized Deformable Image Registration](https://arxiv.org/abs/2507.12953)
*Sidaty El Hadramy,Oumeymah Cherkaoui,Philippe C. Cattin*

Main category: cs.CV

TL;DR: 提出了一种称为cIDI的基于隐式神经表示(INRs)的全新变形图像配准(DIR)框架，通过以正则化超参数为条件进行建模，实现无需多次训练即可优化正则化参数。


<details>
  <summary>Details</summary>
Motivation: 现有学习型DIR框架中，正则化参数的调优计算复杂且需要多次训练，以满足光滑性、物理合理性和解剖一致性需求。

Method: 开发cIDI框架，基于INRs构建以正则化超参数为条件的模型，一次训练后结合分割掩码优化超参数，同时建模连续可微DVF，支持高级正则化技术的自动微分集成。

Result: cIDI框架在DIR-LAB数据集上表现出高度的准确性和鲁棒性。

Conclusion: cIDI方法解决了传统方法中对于每个正则化超参数重新训练的缺陷，提供了一种高效精确的图像配准方案。

Abstract: Regularization is essential in deformable image registration (DIR) to ensure
that the estimated Deformation Vector Field (DVF) remains smooth, physically
plausible, and anatomically consistent. However, fine-tuning regularization
parameters in learning-based DIR frameworks is computationally expensive, often
requiring multiple training iterations. To address this, we propose cIDI, a
novel DIR framework based on Implicit Neural Representations (INRs) that
conditions the registration process on regularization hyperparameters. Unlike
conventional methods that require retraining for each regularization
hyperparameter setting, cIDIR is trained over a prior distribution of these
hyperparameters, then optimized over the regularization hyperparameters by
using the segmentations masks as an observation. Additionally, cIDIR models a
continuous and differentiable DVF, enabling seamless integration of advanced
regularization techniques via automatic differentiation. Evaluated on the
DIR-LAB dataset, $\operatorname{cIDIR}$ achieves high accuracy and robustness
across the dataset.

</details>


### [52] [FantasyPortrait: Enhancing Multi-Character Portrait Animation with Expression-Augmented Diffusion Transformers](https://arxiv.org/abs/2507.12956)
*Qiang Wang,Mengchao Wang,Fan Jiang,Yaqi Fan,Yonggang Qi,Mu Xu*

Main category: cs.CV

TL;DR: FantasyPortrait是一种基于扩散变换器的框架，可从静态图像生成高保真、多角色及情感丰富的面部动画，克服现有方法在细微情绪捕捉与多角色控制上的局限。


<details>
  <summary>Details</summary>
Motivation: 当前方法在面部表情复现和多角色控制上存在较大局限，尤其是缺乏细微情绪的表达与相互干扰问题亟待解决。

Method: 提出FantasyPortrait框架，通过表达增强学习策略和掩码跨注意力机制，利用隐式表示捕捉身份无关的面部动态，并实现多角色独立协调的表情生成。此外，设计了专用的数据集Multi-Expr和评估基准ExprBench。

Result: 实验表明，FantasyPortrait在定量指标与定性评估上显著优于现有方法，特别在跨角色情景与多角色动画方面表现卓越。

Conclusion: 该方法有效解决了传统手段在表情捕捉和多角色动画生成中的不足，拓展了静态图像动画生成的技术边界，为该领域的进一步研究提供了新资源和评估标准。

Abstract: Producing expressive facial animations from static images is a challenging
task. Prior methods relying on explicit geometric priors (e.g., facial
landmarks or 3DMM) often suffer from artifacts in cross reenactment and
struggle to capture subtle emotions. Furthermore, existing approaches lack
support for multi-character animation, as driving features from different
individuals frequently interfere with one another, complicating the task. To
address these challenges, we propose FantasyPortrait, a diffusion transformer
based framework capable of generating high-fidelity and emotion-rich animations
for both single- and multi-character scenarios. Our method introduces an
expression-augmented learning strategy that utilizes implicit representations
to capture identity-agnostic facial dynamics, enhancing the model's ability to
render fine-grained emotions. For multi-character control, we design a masked
cross-attention mechanism that ensures independent yet coordinated expression
generation, effectively preventing feature interference. To advance research in
this area, we propose the Multi-Expr dataset and ExprBench, which are
specifically designed datasets and benchmarks for training and evaluating
multi-character portrait animations. Extensive experiments demonstrate that
FantasyPortrait significantly outperforms state-of-the-art methods in both
quantitative metrics and qualitative evaluations, excelling particularly in
challenging cross reenactment and multi-character contexts. Our project page is
https://fantasy-amap.github.io/fantasy-portrait/.

</details>


### [53] [VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning](https://arxiv.org/abs/2507.13348)
*Senqiao Yang,Junyi Li,Xin Lai,Bei Yu,Hengshuang Zhao,Jiaya Jia*

Main category: cs.CV

TL;DR: 本文提出了VisionThink，一种针对视觉令牌压缩的动态处理范式，通过调整图像分辨率实现高效视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在提高性能时需要大量视觉令牌，但实际应用中并不总需要如此多的令牌，因此需要一种智能调整的方法。

Method: 提出了VisionThink方法，利用强化学习和特定的奖励机制，根据任务需求动态调整视觉令牌，通过低分辨率图像预测是否需要更高分辨率。

Result: VisionThink在OCR任务和通用VQA任务中均表现出较强的精细化视觉理解能力，同时减少了简单任务中的大量视觉令牌。

Conclusion: 实验结果表明该方法高效、有效且优于现有方法，可显著降低模型计算复杂性，同时保持性能出色。

Abstract: Recent advancements in vision-language models (VLMs) have improved
performance by increasing the number of visual tokens, which are often
significantly longer than text tokens. However, we observe that most real-world
scenarios do not require such an extensive number of visual tokens. While the
performance drops significantly in a small subset of OCR-related tasks, models
still perform accurately in most other general VQA tasks with only 1/4
resolution. Therefore, we propose to dynamically process distinct samples with
different resolutions, and present a new paradigm for visual token compression,
namely, VisionThink. It starts with a downsampled image and smartly decides
whether it is sufficient for problem solving. Otherwise, the model could output
a special token to request the higher-resolution image. Compared to existing
Efficient VLM methods that compress tokens using fixed pruning ratios or
thresholds, VisionThink autonomously decides whether to compress tokens case by
case. As a result, it demonstrates strong fine-grained visual understanding
capability on OCR-related tasks, and meanwhile saves substantial visual tokens
on simpler tasks. We adopt reinforcement learning and propose the LLM-as-Judge
strategy to successfully apply RL to general VQA tasks. Moreover, we carefully
design a reward function and penalty mechanism to achieve a stable and
reasonable image resize call ratio. Extensive experiments demonstrate the
superiority, efficiency, and effectiveness of our method. Our code is available
at https://github.com/dvlab-research/VisionThink.

</details>


### [54] [Demographic-aware fine-grained classification of pediatric wrist fractures](https://arxiv.org/abs/2507.12964)
*Ammar Ahmed,Ali Shariq Imran,Zenun Kastrati,Sher Muhammad Daudpota*

Main category: cs.CV

TL;DR: 研究通过结合细粒度方法和患者元数据来提高腕部病理的诊断精度。


<details>
  <summary>Details</summary>
Motivation: 目前腕部病理诊断耗时且依赖专业知识，同时医学影像数据不足成为主要挑战。

Method: 使用细粒度识别策略处理X光图像，通过结合患者元数据与X光图像来增强网络表现，并利用细粒度数据集进行预训练，而非传统的粗粒度数据集。

Result: 在有限数据集上诊断精度提高2%，在更大的骨折专注数据集上提高超过10%。

Conclusion: 结合细粒度策略和元数据集成能显著提升腕部病理诊断的准确性，为小样本医学图像识别提供新思路。

Abstract: Wrist pathologies are frequently observed, particularly among children who
constitute the majority of fracture cases. However, diagnosing these conditions
is time-consuming and requires specialized expertise. Computer vision presents
a promising avenue, contingent upon the availability of extensive datasets, a
notable challenge in medical imaging. Therefore, reliance solely on one
modality, such as images, proves inadequate, especially in an era of diverse
and plentiful data types. In this study, we employ a multifaceted approach to
address the challenge of recognizing wrist pathologies using an extremely
limited dataset. Initially, we approach the problem as a fine-grained
recognition task, aiming to identify subtle X-ray pathologies that conventional
CNNs overlook. Secondly, we enhance network performance by fusing patient
metadata with X-ray images. Thirdly, rather than pre-training on a
coarse-grained dataset like ImageNet, we utilize weights trained on a
fine-grained dataset. While metadata integration has been used in other medical
domains, this is a novel application for wrist pathologies. Our results show
that a fine-grained strategy and metadata integration improve diagnostic
accuracy by 2% with a limited dataset and by over 10% with a larger
fracture-focused dataset.

</details>


### [55] [RGB Pre-Training Enhanced Unobservable Feature Latent Diffusion Model for Spectral Reconstruction](https://arxiv.org/abs/2507.12967)
*Keli Deng,Jie Nie,Yuntao Qian*

Main category: cs.CV

TL;DR: 本文提出了一种用于从RGB图像重建高光谱图像的新方法，称为ULDM，分两阶段学习光谱-空间联合分布，实验表明效果优秀。


<details>
  <summary>Details</summary>
Motivation: 解决从RGB图像恢复高光谱图像（HSI）的关键问题，主要在如何估计未观测到的特征信息，这信息包含了RGB传感器无法捕捉的光谱信息。

Method: 提出了基于RGB预训练潜在扩散模型（RGB-LDM）转换为未观测特征扩散模型（ULDM）的两阶段方法：第一阶段通过光谱未观测特征自动编码器（SpeUAE）学习并压缩光谱特征；第二阶段通过编码光谱和空间结构获取ULDM以建模未观测特征的分布。

Result: 实验结果表明，该方法在光谱重建任务及后续的再照明任务中达到了最先进的性能。

Conclusion: 通过有效构造光谱-空间联合分布，利用RGB图像的空间信息提升了高光谱图像重建的准确性及应用潜力。

Abstract: Spectral reconstruction (SR) is a crucial problem in image processing that
requires reconstructing hyperspectral images (HSIs) from the corresponding RGB
images. A key difficulty in SR is estimating the unobservable feature, which
encapsulates significant spectral information not captured by RGB imaging
sensors. The solution lies in effectively constructing the spectral-spatial
joint distribution conditioned on the RGB image to complement the unobservable
feature. Since HSIs share a similar spatial structure with the corresponding
RGB images, it is rational to capitalize on the rich spatial knowledge in RGB
pre-trained models for spectral-spatial joint distribution learning. To this
end, we extend the RGB pre-trained latent diffusion model (RGB-LDM) to an
unobservable feature LDM (ULDM) for SR. As the RGB-LDM and its corresponding
spatial autoencoder (SpaAE) already excel in spatial knowledge, the ULDM can
focus on modeling spectral structure. Moreover, separating the unobservable
feature from the HSI reduces the redundant spectral information and empowers
the ULDM to learn the joint distribution in a compact latent space.
Specifically, we propose a two-stage pipeline consisting of spectral structure
representation learning and spectral-spatial joint distribution learning to
transform the RGB-LDM into the ULDM. In the first stage, a spectral
unobservable feature autoencoder (SpeUAE) is trained to extract and compress
the unobservable feature into a 3D manifold aligned with RGB space. In the
second stage, the spectral and spatial structures are sequentially encoded by
the SpeUAE and the SpaAE, respectively. The ULDM is then acquired to model the
distribution of the coded unobservable feature with guidance from the
corresponding RGB images. Experimental results on SR and downstream relighting
tasks demonstrate that our proposed method achieves state-of-the-art
performance.

</details>


### [56] [Variance-Based Pruning for Accelerating and Compressing Trained Networks](https://arxiv.org/abs/2507.12988)
*Uranik Berisha,Jens Mehnert,Alexandru Paul Condurache*

Main category: cs.CV

TL;DR: 提出了一种名为基于方差剪枝（Variance-Based Pruning）的方法，通过整合激活统计实现模型高效压缩，同时仅需少量的微调恢复性能。


<details>
  <summary>Details</summary>
Motivation: 由于大型模型（如视觉Transformer）的训练成本高昂，且部署在资源有限的硬件环境中面临延迟、计算和内存压力，迫切需要开发可以高效压缩模型的方法。

Method: 设计了一种基于方差的结构化一次性剪枝方法，通过收集激活统计信息选择需要剪枝的神经元，并将均值激活重新整合到模型中，仅需少量微调即可恢复性能。

Result: 针对ImageNet-1k任务，DeiT-Base在剪枝后保留了70%以上的原始性能，仅10个微调轮次即可恢复99%的原始准确率，同时减少了35%的计算量（MACs）和36%的模型大小，模型加速了1.44倍。

Conclusion: 该方法在较低的计算成本和微调需求下实现了模型大小和计算效率的显著提升，展现出一种高效的模型压缩和加速方式。

Abstract: Increasingly expensive training of ever larger models such as Vision
Transfomers motivate reusing the vast library of already trained
state-of-the-art networks. However, their latency, high computational costs and
memory demands pose significant challenges for deployment, especially on
resource-constrained hardware. While structured pruning methods can reduce
these factors, they often require costly retraining, sometimes for up to
hundreds of epochs, or even training from scratch to recover the lost accuracy
resulting from the structural modifications. Maintaining the provided
performance of trained models after structured pruning and thereby avoiding
extensive retraining remains a challenge. To solve this, we introduce
Variance-Based Pruning, a simple and structured one-shot pruning technique for
efficiently compressing networks, with minimal finetuning. Our approach first
gathers activation statistics, which are used to select neurons for pruning.
Simultaneously the mean activations are integrated back into the model to
preserve a high degree of performance. On ImageNet-1k recognition tasks, we
demonstrate that directly after pruning DeiT-Base retains over 70% of its
original performance and requires only 10 epochs of fine-tuning to regain 99%
of the original accuracy while simultaneously reducing MACs by 35% and model
size by 36%, thus speeding up the model by 1.44x.

</details>


### [57] [Differential-informed Sample Selection Accelerates Multimodal Contrastive Learning](https://arxiv.org/abs/2507.12998)
*Zihua Zhao,Feng Hong,Mengxi Chen,Pengyi Chen,Benyuan Liu,Jiangchao Yao,Ya Zhang,Yanfeng Wang*

Main category: cs.CV

TL;DR: 论文提出了一种称为DISSect的采样方法，通过对比当前模型和历史模型预测的相关性差异，进行样本选择，显著提升了对比学习的效率。


<details>
  <summary>Details</summary>
Motivation: 大规模数据集和昂贵计算资源推动了对比学习多模态模型的发展，但选择样本进行训练的高效替代方法仍存在不足，当前方法对噪声配对处理不足或依赖预先选择，与冷启动场景不匹配。

Method: DISSect 方法根据当前和历史模型预测相关性的差异，构造一个差分驱动的采样机制，并理论分析其效果，以此准确、高效过滤噪声样本。

Result: 在三个基准数据集和多种下游任务中，DISSect均显著优于现有最先进方法。

Conclusion: DISSect成功实现噪声样本的有效甄别，在样本选择和模型训练效率上具有卓越表现。

Abstract: The remarkable success of contrastive-learning-based multimodal models has
been greatly driven by training on ever-larger datasets with expensive compute
consumption. Sample selection as an alternative efficient paradigm plays an
important direction to accelerate the training process. However, recent
advances on sample selection either mostly rely on an oracle model to offline
select a high-quality coreset, which is limited in the cold-start scenarios, or
focus on online selection based on real-time model predictions, which has not
sufficiently or efficiently considered the noisy correspondence. To address
this dilemma, we propose a novel Differential-Informed Sample Selection
(DISSect) method, which accurately and efficiently discriminates the noisy
correspondence for training acceleration. Specifically, we rethink the impact
of noisy correspondence on contrastive learning and propose that the
differential between the predicted correlation of the current model and that of
a historical model is more informative to characterize sample quality. Based on
this, we construct a robust differential-based sample selection and analyze its
theoretical insights. Extensive experiments on three benchmark datasets and
various downstream tasks demonstrate the consistent superiority of DISSect over
current state-of-the-art methods. Source code is available at:
https://github.com/MediaBrain-SJTU/DISSect.

</details>


### [58] [Beyond Fully Supervised Pixel Annotations: Scribble-Driven Weakly-Supervised Framework for Image Manipulation Localization](https://arxiv.org/abs/2507.13018)
*Songlin Li,Guofeng Yu,Zhiqing Guo,Yunfeng Diao,Dan Ma,Gaobo Yang,Liejun Wang*

Main category: cs.CV

TL;DR: 本文探讨了一种基于涂鸦标注的弱监督图像处理定位方法，并提出了首个涂鸦标注的数据集和弱监督框架，通过多种创新模块提升模型的检测性能，在实验中超越了现有全监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习图像处理定位方法依赖于大规模像素级数据集，而标注成本高；弱监督方法虽提升了效率，但性能有限。因此作者研究了一种对标注效率和检测性能均有提升的弱监督方式——涂鸦标注监督。

Method: 提出并重新标注IML数据集为涂鸦标注版本，建立首个相关数据集和弱监督框架；运用自监督训练及结构一致性损失、引入基于先验特征调节模块（PFMM）和门控自适应融合模块（GAFM），并设计了基于置信的熵最小化损失来优化预测。

Result: 实验表明，该方法在分布内和分布外均超越现有全监督方法的平均性能。

Conclusion: 涂鸦标注监督方式提升了标注效率，框架设计有效改进了性能，为弱监督方法在图像处理定位中的应用提供了新思路。

Abstract: Deep learning-based image manipulation localization (IML) methods have
achieved remarkable performance in recent years, but typically rely on
large-scale pixel-level annotated datasets. To address the challenge of
acquiring high-quality annotations, some recent weakly supervised methods
utilize image-level labels to segment manipulated regions. However, the
performance is still limited due to insufficient supervision signals. In this
study, we explore a form of weak supervision that improves the annotation
efficiency and detection performance, namely scribble annotation supervision.
We re-annotated mainstream IML datasets with scribble labels and propose the
first scribble-based IML (Sc-IML) dataset. Additionally, we propose the first
scribble-based weakly supervised IML framework. Specifically, we employ
self-supervised training with a structural consistency loss to encourage the
model to produce consistent predictions under multi-scale and augmented inputs.
In addition, we propose a prior-aware feature modulation module (PFMM) that
adaptively integrates prior information from both manipulated and authentic
regions for dynamic feature adjustment, further enhancing feature
discriminability and prediction consistency in complex scenes. We also propose
a gated adaptive fusion module (GAFM) that utilizes gating mechanisms to
regulate information flow during feature fusion, guiding the model toward
emphasizing potential tampered regions. Finally, we propose a confidence-aware
entropy minimization loss (${\mathcal{L}}_{ {CEM }}$). This loss dynamically
regularizes predictions in weakly annotated or unlabeled regions based on model
uncertainty, effectively suppressing unreliable predictions. Experimental
results show that our method outperforms existing fully supervised approaches
in terms of average performance both in-distribution and out-of-distribution.

</details>


### [59] [Resurrect Mask AutoRegressive Modeling for Efficient and Scalable Image Generation](https://arxiv.org/abs/2507.13032)
*Yi Xin,Le Zhuo,Qi Qin,Siqi Luo,Yuewen Cao,Bin Fu,Yangfan He,Hongsheng Li,Guangtao Zhai,Xiaohong Liu,Peng Gao*

Main category: cs.CV

TL;DR: 此研究改进了Masked AutoRegressive (MAR)模型，通过优化架构和引入新技术，提出了一种名为MaskGIL的新方法，在ImageNet 256x256基准测试中达到与最先进的AR模型相当的生成效果，同时显著减少推理步骤，并扩展到文本驱动图像生成和实时语音到图像转换。


<details>
  <summary>Details</summary>
Motivation: 尽管MAR模型在并行解码效率上有所优势，但其性能通常不及传统的AR模型。因此研究旨在改进MAR模型的架构，以提升其图像生成质量。

Method: 评估不同图像分词器，提出改进的双向LLaMA架构（用双向注意力替代因果注意力并引入2D RoPE），提出一个新模型MaskGIL，并扩展其规模和应用。

Result: MaskGIL使用111M到1.4B不同参数规模，在ImageNet 256x256基准测试中实现了3.71的FID分数，与最先进AR模型表现相当，仅需8个推理步骤。此外，还开发了一个775M参数的文本驱动MaskGIL模型，能够在不同分辨率上生成图像。

Conclusion: MaskGIL在效率和效果上都表现出了显著改进，不仅能有效生成高质量图像，还扩展了应用场景，包括加速AR生成和实现实时语音到图像转换。

Abstract: AutoRegressive (AR) models have made notable progress in image generation,
with Masked AutoRegressive (MAR) models gaining attention for their efficient
parallel decoding. However, MAR models have traditionally underperformed when
compared to standard AR models. This study refines the MAR architecture to
improve image generation quality. We begin by evaluating various image
tokenizers to identify the most effective one. Subsequently, we introduce an
improved Bidirectional LLaMA architecture by replacing causal attention with
bidirectional attention and incorporating 2D RoPE, which together form our
advanced model, MaskGIL. Scaled from 111M to 1.4B parameters, MaskGIL achieves
a FID score of 3.71, matching state-of-the-art AR models in the ImageNet
256x256 benchmark, while requiring only 8 inference steps compared to the 256
steps of AR models. Furthermore, we develop a text-driven MaskGIL model with
775M parameters for generating images from text at various resolutions. Beyond
image generation, MaskGIL extends to accelerate AR-based generation and enable
real-time speech-to-image conversion. Our codes and models are available at
https://github.com/synbol/MaskGIL.

</details>


### [60] [Advancing Complex Wide-Area Scene Understanding with Hierarchical Coresets Selection](https://arxiv.org/abs/2507.13061)
*Jingyao Wang,Yiming Chen,Lingyu Si,Changwen Zheng*

Main category: cs.CV

TL;DR: 文章提出了一种名为层次化核心选择（HCS）的方法，用于改进视觉-语言模型（VLMs）在复杂广域场景理解中的适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型虽然在场景理解上有所进展，但在处理未知的复杂广域场景时仍存在局限性。

Method: 提出了一个新颖的HCS机制，通过基于理论保障的重要性函数逐步优化选定区域，考量了实用性、代表性、鲁棒性和协同作用，无需额外微调即可快速理解任意规模的场景。

Result: 实验表明，HCS在多种任务中表现出色，性能和通用性优越。

Conclusion: HCS作为一种与VLM兼容的插件式方法，在复杂场景理解中提供了有效解决方案，克服了特征密度不足的问题。

Abstract: Scene understanding is one of the core tasks in computer vision, aiming to
extract semantic information from images to identify objects, scene categories,
and their interrelationships. Although advancements in Vision-Language Models
(VLMs) have driven progress in this field, existing VLMs still face challenges
in adaptation to unseen complex wide-area scenes. To address the challenges,
this paper proposes a Hierarchical Coresets Selection (HCS) mechanism to
advance the adaptation of VLMs in complex wide-area scene understanding. It
progressively refines the selected regions based on the proposed theoretically
guaranteed importance function, which considers utility, representativeness,
robustness, and synergy. Without requiring additional fine-tuning, HCS enables
VLMs to achieve rapid understandings of unseen scenes at any scale using
minimal interpretable regions while mitigating insufficient feature density.
HCS is a plug-and-play method that is compatible with any VLM. Experiments
demonstrate that HCS achieves superior performance and universality in various
tasks.

</details>


### [61] [Label-Consistent Dataset Distillation with Detector-Guided Refinement](https://arxiv.org/abs/2507.13074)
*Yawen Zou,Guang Li,Zi Wang,Chunzhi Gu,Chao Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于探测器指导的数据集蒸馏框架，通过改进合成样本的标签一致性和图像质量，提升了数据集蒸馏效果。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在生成紧凑且信息丰富的数据集时，样本存在标签不一致性或结构细节不足的问题，导致下游表现不佳。作者希望解决这一问题。

Method: 利用预训练探测器识别并改进异常的合成样本，同时通过多候选生成机制结合探测器的置信分数和类内多样性选择最佳样本。

Result: 实验结果表明，该方法生成的样本质量高，细节丰富，在验证集上达到了当前最优性能。

Conclusion: 该方法通过改进数据集蒸馏流程，有效提升了合成样本的标签一致性和图像质量，为高效数据存储和计算奠定了基础。

Abstract: Dataset distillation (DD) aims to generate a compact yet informative dataset
that achieves performance comparable to the original dataset, thereby reducing
demands on storage and computational resources. Although diffusion models have
made significant progress in dataset distillation, the generated surrogate
datasets often contain samples with label inconsistencies or insufficient
structural detail, leading to suboptimal downstream performance. To address
these issues, we propose a detector-guided dataset distillation framework that
explicitly leverages a pre-trained detector to identify and refine anomalous
synthetic samples, thereby ensuring label consistency and improving image
quality. Specifically, a detector model trained on the original dataset is
employed to identify anomalous images exhibiting label mismatches or low
classification confidence. For each defective image, multiple candidates are
generated using a pre-trained diffusion model conditioned on the corresponding
image prototype and label. The optimal candidate is then selected by jointly
considering the detector's confidence score and dissimilarity to existing
qualified synthetic samples, thereby ensuring both label accuracy and
intra-class diversity. Experimental results demonstrate that our method can
synthesize high-quality representative images with richer details, achieving
state-of-the-art performance on the validation set.

</details>


### [62] [Channel-wise Motion Features for Efficient Motion Segmentation](https://arxiv.org/abs/2507.13082)
*Riku Inoue,Masamitsu Tsuchiya,Yuji Yasui*

Main category: cs.CV

TL;DR: 提出一种基于成本-volume的通道式运动特征表示方法，通过只使用姿态网络显著提升了实时性能和效率，同时保持了高准确性。


<details>
  <summary>Details</summary>
Motivation: 提升运动分割模型的实时性能和计算效率，特别针对自动驾驶等安全关键的机器人应用场景。

Method: 提出了通道式运动特征表示方法，仅通过一个姿态网络提取运动特征，而无需其他子网络。

Result: 在KITTI和Cityscapes数据集上，其FPS达到现有最优模型的四倍，并且参数量减少至约25%，同时保持等效的准确性。

Conclusion: 新方法兼顾了实时性和精度，适合应用于安全关键场景，显示出较高的计算效率与实用潜力。

Abstract: For safety-critical robotics applications such as autonomous driving, it is
important to detect all required objects accurately in real-time. Motion
segmentation offers a solution by identifying dynamic objects from the scene in
a class-agnostic manner. Recently, various motion segmentation models have been
proposed, most of which jointly use subnetworks to estimate Depth, Pose,
Optical Flow, and Scene Flow. As a result, the overall computational cost of
the model increases, hindering real-time performance.
  In this paper, we propose a novel cost-volume-based motion feature
representation, Channel-wise Motion Features. By extracting depth features of
each instance in the feature map and capturing the scene's 3D motion
information, it offers enhanced efficiency. The only subnetwork used to build
Channel-wise Motion Features is the Pose Network, and no others are required.
Our method not only achieves about 4 times the FPS of state-of-the-art models
in the KITTI Dataset and Cityscapes of the VCAS-Motion Dataset, but also
demonstrates equivalent accuracy while reducing the parameters to about 25$\%$.

</details>


### [63] [Decoupled PROB: Decoupled Query Initialization Tasks and Objectness-Class Learning for Open World Object Detection](https://arxiv.org/abs/2507.13085)
*Riku Inoue,Masamitsu Tsuchiya,Yuji Yasui*

Main category: cs.CV

TL;DR: 该研究提出了Decoupled PROB模型，通过引入ETOP和TDQI方法，解决了现有PROB方法中预测学习冲突的问题，并显著提升了开放世界目标检测的性能。


<details>
  <summary>Details</summary>
Motivation: 解决开放世界目标检测任务中未知对象检测和增量学习的挑战，特别是现有方法中对象性和类别预测之间的学习冲突问题。

Method: 提出Decoupled PROB模型，通过引入ETOP（提早终止对象性预测）和TDQI（任务解除耦合的查询初始化）方法。ETOP停止解码器中对象性预测的部分层级，以解决预测冲突；TDQI结合查询选择和可学习查询，以高效提取已知和未知对象特征。

Result: 在多个开放世界目标检测基准上，Decoupled PROB表现优异，多个指标上超过现有方法，显著提升性能。

Conclusion: Decoupled PROB通过ETOP和TDQI改进了OWOD任务的性能，验证了解耦合对象性和类别预测的重要性，同时其模块化设计便利了现有模型的集成。

Abstract: Open World Object Detection (OWOD) is a challenging computer vision task that
extends standard object detection by (1) detecting and classifying unknown
objects without supervision, and (2) incrementally learning new object classes
without forgetting previously learned ones. The absence of ground truths for
unknown objects makes OWOD tasks particularly challenging. Many methods have
addressed this by using pseudo-labels for unknown objects. The recently
proposed Probabilistic Objectness transformer-based open-world detector (PROB)
is a state-of-the-art model that does not require pseudo-labels for unknown
objects, as it predicts probabilistic objectness. However, this method faces
issues with learning conflicts between objectness and class predictions.
  To address this issue and further enhance performance, we propose a novel
model, Decoupled PROB. Decoupled PROB introduces Early Termination of
Objectness Prediction (ETOP) to stop objectness predictions at appropriate
layers in the decoder, resolving the learning conflicts between class and
objectness predictions in PROB. Additionally, we introduce Task-Decoupled Query
Initialization (TDQI), which efficiently extracts features of known and unknown
objects, thereby improving performance. TDQI is a query initialization method
that combines query selection and learnable queries, and it is a module that
can be easily integrated into existing DETR-based OWOD models. Extensive
experiments on OWOD benchmarks demonstrate that Decoupled PROB surpasses all
existing methods across several metrics, significantly improving performance.

</details>


### [64] [DiffOSeg: Omni Medical Image Segmentation via Multi-Expert Collaboration Diffusion Model](https://arxiv.org/abs/2507.13087)
*Han Zhang,Xiangde Luo,Yong Chen,Kang Li*

Main category: cs.CV

TL;DR: 本文提出了一个两阶段的DiffOSeg框架，从根本上解决医疗图像分割中注释差异问题，兼顾共识和专家偏好。


<details>
  <summary>Details</summary>
Motivation: 针对医学图像分割中由于边界模糊性和临床专业知识多样性引发的注释差异，解决传统深度学习方法无法捕捉注释者偏见的局限性。

Method: 设计DiffOSeg两阶段扩散框架：第一阶段通过概率共识策略建立注释共识，第二阶段通过自适应提示捕捉专家特定偏好。

Result: 在两个公开数据集（LIDC-IDRI 和 NPC-170）上进行验证，指标超越已有的最先进方法。

Conclusion: DiffOSeg框架能够同时实现共识驱动和偏好驱动的分割，并具备优越性能。

Abstract: Annotation variability remains a substantial challenge in medical image
segmentation, stemming from ambiguous imaging boundaries and diverse clinical
expertise. Traditional deep learning methods producing single deterministic
segmentation predictions often fail to capture these annotator biases. Although
recent studies have explored multi-rater segmentation, existing methods
typically focus on a single perspective -- either generating a probabilistic
``gold standard'' consensus or preserving expert-specific preferences -- thus
struggling to provide a more omni view. In this study, we propose DiffOSeg, a
two-stage diffusion-based framework, which aims to simultaneously achieve both
consensus-driven (combining all experts' opinions) and preference-driven
(reflecting experts' individual assessments) segmentation. Stage I establishes
population consensus through a probabilistic consensus strategy, while Stage II
captures expert-specific preference via adaptive prompts. Demonstrated on two
public datasets (LIDC-IDRI and NPC-170), our model outperforms existing
state-of-the-art methods across all evaluated metrics. Source code is available
at https://github.com/string-ellipses/DiffOSeg .

</details>


### [65] [DINO-VO: A Feature-based Visual Odometry Leveraging a Visual Foundation Model](https://arxiv.org/abs/2507.13145)
*Maulana Bisyir Azhari,David Hyunchul Shim*

Main category: cs.CV

TL;DR: 本文提出DINO-VO系统，该系统结合了DINOv2视觉基础模型与局部特征匹配，显著提升了单目视觉里程计的鲁棒性、泛化能力和效率，在多个基准数据集上表现优越。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的单目视觉里程计系统在机器人中的鲁棒性、泛化性和效率均存在挑战，而DINOv2等视觉基础模型尽管在多种任务中展示了优越性能，但因特征粒度偏粗，尚未充分应用于视觉里程计场景中。

Method: 提出DINO-VO系统，设计了适配DINOv2粗粒特征的显著关键点检测器，融合几何细粒特征与DINOv2语义特征，使用Transformer匹配器和可微分位姿估计模块，实现精确摄像机运动估计，同时保证效率和准确性。

Result: DINO-VO在TartanAir、KITTI数据集上表现优于已有单帧VO方法，在EuRoC数据集上有竞争力；在单GPU上实现72FPS，内存占用小于1GB，同时在户外驾驶场景中接近视觉SLAM系统性能，充分展示了其泛化性。

Conclusion: DINO-VO成功克服了DINOv2特征粒度的限制，结合了语义鲁棒性与几何精确性，提升了视觉里程计的总体性能，证明了其在多个机器人视觉任务中的潜力及高效性。

Abstract: Learning-based monocular visual odometry (VO) poses robustness,
generalization, and efficiency challenges in robotics. Recent advances in
visual foundation models, such as DINOv2, have improved robustness and
generalization in various vision tasks, yet their integration in VO remains
limited due to coarse feature granularity. In this paper, we present DINO-VO, a
feature-based VO system leveraging DINOv2 visual foundation model for its
sparse feature matching. To address the integration challenge, we propose a
salient keypoints detector tailored to DINOv2's coarse features. Furthermore,
we complement DINOv2's robust-semantic features with fine-grained geometric
features, resulting in more localizable representations. Finally, a
transformer-based matcher and differentiable pose estimation layer enable
precise camera motion estimation by learning good matches. Against prior
detector-descriptor networks like SuperPoint, DINO-VO demonstrates greater
robustness in challenging environments. Furthermore, we show superior accuracy
and generalization of the proposed feature descriptors against standalone
DINOv2 coarse features. DINO-VO outperforms prior frame-to-frame VO methods on
the TartanAir and KITTI datasets and is competitive on EuRoC dataset, while
running efficiently at 72 FPS with less than 1GB of memory usage on a single
GPU. Moreover, it performs competitively against Visual SLAM systems on outdoor
driving scenarios, showcasing its generalization capabilities.

</details>


### [66] [GLAD: Generalizable Tuning for Vision-Language Models](https://arxiv.org/abs/2507.13089)
*Yuqi Peng,Pengfei Wang,Jianzhuang Liu,Shifeng Chen*

Main category: cs.CV

TL;DR: 本文提出GLAD框架，通过结合LoRA与正则化梯度技术提升视觉语言模型的下游任务能力，解决了少样本情境下的过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 现有快速调优方法在少样本情景下容易过拟合，且解决方案复杂且非通用。

Method: 提出GLAD框架，结合LoRA技术性能和正则化梯度技术以降低过拟合风险。

Result: 在15个基准数据集实验中，GLAD在基础到新类别泛化、图像域泛化、跨数据集泛化方面均优于现有方法。

Conclusion: GLAD简单通用，性能优越，可作为视觉语言模型下游任务调优的有效解决方案，代码将公开。

Abstract: Pre-trained vision-language models, such as CLIP, show impressive zero-shot
recognition ability and can be easily transferred to specific downstream tasks
via prompt tuning, even with limited training data. However, existing prompt
tuning methods face two main challenges: (1) In few-shot scenarios, data
scarcity often leads to overfitting, making the model sensitive to changes in
the input domain. (2) To mitigate overfitting, these methods typically rely on
complex task-specific model architectures and sensitive hyperparameter tuning,
severely restricting their general applicability. To address these issues, we
propose a simpler and more general framework called GLAD (Generalizable LoRA
tuning with RegulArized GraDient). We show that merely applying LoRA achieves
performance in downstream tasks comparable to current state-of-the-art
prompt-based methods. While LoRA is effective and easy to use, it remains
susceptible to overfitting in few-shot learning scenarios. To mitigate this
risk, we introduce a gradient-based regularization technique. This technique
effectively steers the optimization trajectory, encouraging the model to find a
more stable parameter region that is robust to variations in data distribution.
Through extensive experiments conducted on 15 benchmark datasets, we
demonstrate that GLAD outperforms previous tuning approaches in terms of
base-to-novel class generalization, image domain generalization, and
cross-dataset generalization. The code will be publicly available.

</details>


### [67] [SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models](https://arxiv.org/abs/2507.13152)
*Xiangyu Dong,Haoran Zhao,Jiang Gao,Haozhou Li,Xiaoguang Ma,Yaoming Zhou,Fuhai Chen,Juan Liu*

Main category: cs.CV

TL;DR: 本文提出了一种自我进化的视觉-语言导航框架（SE-VLN），以提升代理在未知环境下的导航能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言导航技术受限于大语言模型的固定知识库与推理能力，缺乏结合经验知识和演化能力的机制。

Method: 提出了一个多模态大语言模型驱动的自我进化框架SE-VLN，包括层级记忆模块、基于检索的推理模块和反思模块，支持代理在测试过程中不断进化。

Result: 在R2R和REVERSE数据集上实现了分别57%和35.2%的导航成功率，相较现有方法绝对性能提升了23.9%和15.0%。

Conclusion: SE-VLN体现出随经验库增长而提高性能的潜力，可作为视觉-语言导航的自我进化代理框架。

Abstract: Recent advances in vision-language navigation (VLN) were mainly attributed to
emerging large language models (LLMs). These methods exhibited excellent
generalization capabilities in instruction understanding and task reasoning.
However, they were constrained by the fixed knowledge bases and reasoning
abilities of LLMs, preventing fully incorporating experiential knowledge and
thus resulting in a lack of efficient evolutionary capacity. To address this,
we drew inspiration from the evolution capabilities of natural agents, and
proposed a self-evolving VLN framework (SE-VLN) to endow VLN agents with the
ability to continuously evolve during testing. To the best of our knowledge, it
was the first time that an multimodal LLM-powered self-evolving VLN framework
was proposed. Specifically, SE-VLN comprised three core modules, i.e., a
hierarchical memory module to transfer successful and failure cases into
reusable knowledge, a retrieval-augmented thought-based reasoning module to
retrieve experience and enable multi-step decision-making, and a reflection
module to realize continual evolution. Comprehensive tests illustrated that the
SE-VLN achieved navigation success rates of 57% and 35.2% in unseen
environments, representing absolute performance improvements of 23.9% and 15.0%
over current state-of-the-art methods on R2R and REVERSE datasets,
respectively. Moreover, the SE-VLN showed performance improvement with
increasing experience repository, elucidating its great potential as a
self-evolving agent framework for VLN.

</details>


### [68] [Deep Learning-Based Fetal Lung Segmentation from Diffusion-weighted MRI Images and Lung Maturity Evaluation for Fetal Growth Restriction](https://arxiv.org/abs/2507.13106)
*Zhennan Xiao,Katharine Brudkiewicz,Zhen Yuan,Rosalind Aughwane,Magdalena Sokolska,Joanna Chappell,Trevor Gaunt,Anna L. David,Andrew P. King,Andrew Melbourne*

Main category: cs.CV

TL;DR: 本文提出一种自动化管道，用于通过深度学习和扩散加权磁共振图像评估胎儿肺部成熟度。


<details>
  <summary>Details</summary>
Motivation: 现有的胎儿肺部成熟度评估方法依赖手动分割，耗时长，限制了临床应用，亟需一种高效自动化的方法。

Method: 采用基于深度学习的3D nnU-Net模型进行胎儿肺部分割，并结合IVIM参数的体素拟合进行成熟度评估。

Result: 模型分割性能良好，Dice系数达82.14%；自动和手动分割的IVIM参数评估结果无显著差异。

Conclusion: 全自动化的管道可行，为胎儿肺成熟度评估及临床决策提供支持。

Abstract: Fetal lung maturity is a critical indicator for predicting neonatal outcomes
and the need for post-natal intervention, especially for pregnancies affected
by fetal growth restriction. Intra-voxel incoherent motion analysis has shown
promising results for non-invasive assessment of fetal lung development, but
its reliance on manual segmentation is time-consuming, thus limiting its
clinical applicability. In this work, we present an automated lung maturity
evaluation pipeline for diffusion-weighted magnetic resonance images that
consists of a deep learning-based fetal lung segmentation model and a
model-fitting lung maturity assessment. A 3D nnU-Net model was trained on
manually segmented images selected from the baseline frames of 4D
diffusion-weighted MRI scans. The segmentation model demonstrated robust
performance, yielding a mean Dice coefficient of 82.14%. Next, voxel-wise model
fitting was performed based on both the nnU-Net-predicted and manual lung
segmentations to quantify IVIM parameters reflecting tissue microstructure and
perfusion. The results suggested no differences between the two. Our work shows
that a fully automated pipeline is possible for supporting fetal lung maturity
assessment and clinical decision-making.

</details>


### [69] [R^2MoE: Redundancy-Removal Mixture of Experts for Lifelong Concept Learning](https://arxiv.org/abs/2507.13107)
*Xiaohan Guo,Yusong Cai,Zejia Liu,Zhengning Wang,Lili Pan,Hongliang Li*

Main category: cs.CV

TL;DR: 本研究提出了一种名为R^2MoE的参数高效框架，用于持续学习视觉概念，有效避免遗忘和参数扩张问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法面临灾难性遗忘和参数膨胀问题，亟需高效的持续视觉概念学习方式。

Method: 提出了R^2MoE框架，包括混合专家框架结合路由蒸馏机制、冗余专家消除策略，及基于层次局部注意的推理方法。

Result: 实验表明，R^2MoE相比最先进方法在CustomConcept 101数据集上忘记率减少87.8%，参数减少63.3%。

Conclusion: 该方法可高效学习新视觉概念，并显著提高图像生成的概念保真度。

Abstract: Enabling large-scale generative models to continuously learn new visual
concepts is essential for personalizing pre-trained models to meet individual
user preferences. Existing approaches for continual visual concept learning are
constrained by two fundamental challenges: catastrophic forgetting and
parameter expansion. In this paper, we propose Redundancy-Removal Mixture of
Experts (R^2MoE), a parameter-efficient framework for lifelong visual concept
learning that effectively learns new concepts while incurring minimal parameter
overhead. Our framework includes three key innovative contributions: First, we
propose a mixture-of-experts framework with a routing distillation mechanism
that enables experts to acquire concept-specific knowledge while preserving the
gating network's routing capability, thereby effectively mitigating
catastrophic forgetting. Second, we propose a strategy for eliminating
redundant layer-wise experts that reduces the number of expert parameters by
fully utilizing previously learned experts. Third, we employ a hierarchical
local attention-guided inference approach to mitigate interference between
generated visual concepts. Extensive experiments have demonstrated that our
method generates images with superior conceptual fidelity compared to the
state-of-the-art (SOTA) method, achieving an impressive 87.8\% reduction in
forgetting rates and 63.3\% fewer parameters on the CustomConcept 101 dataset.
Our code is available at {https://github.com/learninginvision/R2MoE}

</details>


### [70] [Orbis: Overcoming Challenges of Long-Horizon Prediction in Driving World Models](https://arxiv.org/abs/2507.13162)
*Arian Mousakhan,Sudhanshu Mittal,Silvio Galesso,Karim Farid,Thomas Brox*

Main category: cs.CV

TL;DR: 文章探讨了自动驾驶世界模型在长时间生成和复杂场景中的应用，开发了一个模型，不依赖额外的传感器和监督，表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶模型在长时间生成和应对复杂场景方面有局限性，研究目的是开发一个更加高效、泛化能力更强的模型。

Method: 采用简单设计，利用混合型Tokenizer对离散和连续模型进行并列比较，开发一个基于连续自回归预测的模型。

Result: 实验表明，连续自回归模型在复杂场景中表现更优，比如城市交通和转弯；且对设计选择不敏感，普遍优于离散模型。

Conclusion: 连续自回归模型在自动驾驶世界模型领域具有更大优势，研究表明其鲁棒性和强大的表现能力。代码和模型已开源以供验证。

Abstract: Existing world models for autonomous driving struggle with long-horizon
generation and generalization to challenging scenarios. In this work, we
develop a model using simple design choices, and without additional supervision
or sensors, such as maps, depth, or multiple cameras. We show that our model
yields state-of-the-art performance, despite having only 469M parameters and
being trained on 280h of video data. It particularly stands out in difficult
scenarios like turning maneuvers and urban traffic. We test whether discrete
token models possibly have advantages over continuous models based on flow
matching. To this end, we set up a hybrid tokenizer that is compatible with
both approaches and allows for a side-by-side comparison. Our study concludes
in favor of the continuous autoregressive model, which is less brittle on
individual design choices and more powerful than the model built on discrete
tokens. Code, models and qualitative results are publicly available at
https://lmb-freiburg.github.io/orbis.github.io/.

</details>


### [71] [3DKeyAD: High-Resolution 3D Point Cloud Anomaly Detection via Keypoint-Guided Point Clustering](https://arxiv.org/abs/2507.13110)
*Zi Wang,Katsuya Hotta,Koichiro Kamide,Yawen Zou,Chao Zhang,Jun Yu*

Main category: cs.CV

TL;DR: 本文提出了一种基于配准的异常检测框架，通过多原型对齐和聚类差异分析实现精确的3D异常定位，在Real3D-AD基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前高分辨率的3D点云虽然适用于检测工业检查中的细微结构异常，但其高密度和不规则性带来了计算成本高、对空间误差敏感以及捕捉局部差异困难等挑战。

Method: 该方法包括多原型对齐用于直接结构比较，并通过关键点引导的聚类方法分析局部差异，选取几何信息点作为聚类中心，提高比较的稳定性和意义。

Result: 在Real3D-AD数据集上的实验表明，该方法在对象级和点级异常检测中均实现了最先进的表现，且仅使用了原始特征。

Conclusion: 该框架能够有效应对3D点云异常检测中的各种挑战，提供了一种精确、高效的检测和定位手段。

Abstract: High-resolution 3D point clouds are highly effective for detecting subtle
structural anomalies in industrial inspection. However, their dense and
irregular nature imposes significant challenges, including high computational
cost, sensitivity to spatial misalignment, and difficulty in capturing
localized structural differences. This paper introduces a registration-based
anomaly detection framework that combines multi-prototype alignment with
cluster-wise discrepancy analysis to enable precise 3D anomaly localization.
Specifically, each test sample is first registered to multiple normal
prototypes to enable direct structural comparison. To evaluate anomalies at a
local level, clustering is performed over the point cloud, and similarity is
computed between features from the test sample and the prototypes within each
cluster. Rather than selecting cluster centroids randomly, a keypoint-guided
strategy is employed, where geometrically informative points are chosen as
centroids. This ensures that clusters are centered on feature-rich regions,
enabling more meaningful and stable distance-based comparisons. Extensive
experiments on the Real3D-AD benchmark demonstrate that the proposed method
achieves state-of-the-art performance in both object-level and point-level
anomaly detection, even using only raw features.

</details>


### [72] [Synthesizing Reality: Leveraging the Generative AI-Powered Platform Midjourney for Construction Worker Detection](https://arxiv.org/abs/2507.13221)
*Hongyang Zhao,Tianyu Liang,Sina Davari,Daeho Kim*

Main category: cs.CV

TL;DR: 提出了针对建设工人检测的一种新的图像合成方法，利用生成式AI平台Midjourney生成了多样化且高质量的合成图像来训练深度神经网络(DNN)，并取得了优秀的检测精度。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在建设领域面临的训练数据多样性和数量不足的问题。

Method: 利用生成式AI平台Midjourney设计了3000种不同的提示词，生成12000张多样化且高真实感的合成图像，并对这些图像手动标注后作为DNN的训练数据。

Result: 在真实施工图像数据集上的IoU阈值0.5和0.5到0.95分别取得了平均精度(APs)为0.937和0.642的结果；在合成数据集上分别达到了0.994和0.919的平均精度，表现出对训练数据的良好适应性。

Conclusion: 生成式AI可以显著缓解深度神经网络训练数据的稀缺问题，但同时也暴露了在模型泛化性上的一些不足。

Abstract: While recent advancements in deep neural networks (DNNs) have substantially
enhanced visual AI's capabilities, the challenge of inadequate data diversity
and volume remains, particularly in construction domain. This study presents a
novel image synthesis methodology tailored for construction worker detection,
leveraging the generative-AI platform Midjourney. The approach entails
generating a collection of 12,000 synthetic images by formulating 3000
different prompts, with an emphasis on image realism and diversity. These
images, after manual labeling, serve as a dataset for DNN training. Evaluation
on a real construction image dataset yielded promising results, with the model
attaining average precisions (APs) of 0.937 and 0.642 at
intersection-over-union (IoU) thresholds of 0.5 and 0.5 to 0.95, respectively.
Notably, the model demonstrated near-perfect performance on the synthetic
dataset, achieving APs of 0.994 and 0.919 at the two mentioned thresholds.
These findings reveal both the potential and weakness of generative AI in
addressing DNN training data scarcity.

</details>


### [73] [Leveraging Language Prior for Infrared Small Target Detection](https://arxiv.org/abs/2507.13113)
*Pranav Singh,Pravendra Singh*

Main category: cs.CV

TL;DR: 作者提出了一种结合语言和图像数据的多模态红外小目标检测方法，通过整合GPT-4生成的语言描述和现有图像数据，显著提升了检测性能，并验证了其在新创建的多模态红外数据集中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前红外小目标检测方法主要依赖图像模态，缺乏语言信息融合，这限制了检测能力的提升。因此，研究者希望通过语言模态对检测任务进行辅助，从而提升红外小目标检测性能。

Method: 提出一种新颖的多模态红外小目标检测框架，通过GPT-4视觉模型生成语言描述，结合图像模态数据，并为实验创建了包含图像及文本模态的多模态红外数据集。

Result: 通过广泛的实验与消融研究验证，提出框架在NUAA-SIRST和IRSTD-1k数据集上相比最先进的方法，在IoU、nIoU、Pd、Fa等指标上取得了显著的提升，相对差异分别为9.74%、13.02%、1.25%、67.87%和4.41%、2.04%、2.01%、113.43%。

Conclusion: 结合语言和图像模态的新方法显著提高了红外小目标检测性能，在多个指标上优于现有方法，为解决红外小目标检测问题提供了新的视角和有效方法。

Abstract: IRSTD (InfraRed Small Target Detection) detects small targets in infrared
blurry backgrounds and is essential for various applications. The detection
task is challenging due to the small size of the targets and their sparse
distribution in infrared small target datasets. Although existing IRSTD methods
and datasets have led to significant advancements, they are limited by their
reliance solely on the image modality. Recent advances in deep learning and
large vision-language models have shown remarkable performance in various
visual recognition tasks. In this work, we propose a novel multimodal IRSTD
framework that incorporates language priors to guide small target detection. We
leverage language-guided attention weights derived from the language prior to
enhance the model's ability for IRSTD, presenting a novel approach that
combines textual information with image data to improve IRSTD capabilities.
Utilizing the state-of-the-art GPT-4 vision model, we generate text
descriptions that provide the locations of small targets in infrared images,
employing careful prompt engineering to ensure improved accuracy. Due to the
absence of multimodal IR datasets, existing IRSTD methods rely solely on image
data. To address this shortcoming, we have curated a multimodal infrared
dataset that includes both image and text modalities for small target
detection, expanding upon the popular IRSTD-1k and NUDT-SIRST datasets. We
validate the effectiveness of our approach through extensive experiments and
comprehensive ablation studies. The results demonstrate significant
improvements over the state-of-the-art method, with relative percentage
differences of 9.74%, 13.02%, 1.25%, and 67.87% in IoU, nIoU, Pd, and Fa on the
NUAA-SIRST subset, and 4.41%, 2.04%, 2.01%, and 113.43% on the IRSTD-1k subset
of the LangIR dataset, respectively.

</details>


### [74] [$S^2M^2$: Scalable Stereo Matching Model for Reliable Depth Estimation](https://arxiv.org/abs/2507.13229)
*Junhong Min,Youngpil Jeon,Jimin Kim,Minyong Choi*

Main category: cs.CV

TL;DR: 提出了一种新的全局匹配架构$S^2M^2$，在不依赖卷积或深度优化的情况下实现了高效率和高准确性的双目匹配。


<details>
  <summary>Details</summary>
Motivation: 现有方法在迭代局部搜索和全局匹配间存在性能权衡，难以兼顾准确性和效率。

Method: 引入了一种多分辨率Transformer，结合新颖的损失函数来增强匹配概率的集中性，并联合估计视差、遮挡和置信度。

Result: $S^2M^2$在Middlebury v3和ETH3D基准上达到了新的最先进性能，超越了大多数指标，并能够高效重建高质量细节。

Conclusion: $S^2M^2$有效解决了双目匹配中的局部一致性与全局成本效率问题，表现优异，适用于广泛场景。

Abstract: The pursuit of a generalizable stereo matching model, capable of performing
across varying resolutions and disparity ranges without dataset-specific
fine-tuning, has revealed a fundamental trade-off. Iterative local search
methods achieve high scores on constrained benchmarks, but their core mechanism
inherently limits the global consistency required for true generalization. On
the other hand, global matching architectures, while theoretically more robust,
have been historically rendered infeasible by prohibitive computational and
memory costs. We resolve this dilemma with $S^2M^2$: a global matching
architecture that achieves both state-of-the-art accuracy and high efficiency
without relying on cost volume filtering or deep refinement stacks. Our design
integrates a multi-resolution transformer for robust long-range correspondence,
trained with a novel loss function that concentrates probability on feasible
matches. This approach enables a more robust joint estimation of disparity,
occlusion, and confidence. $S^2M^2$ establishes a new state of the art on the
Middlebury v3 and ETH3D benchmarks, significantly outperforming prior methods
across most metrics while reconstructing high-quality details with competitive
efficiency.

</details>


### [75] [RS-TinyNet: Stage-wise Feature Fusion Network for Detecting Tiny Objects in Remote Sensing Images](https://arxiv.org/abs/2507.13120)
*Xiaozheng Jiang,Wei Zhang,Xuerui Mao*

Main category: cs.CV

TL;DR: 本文介绍了RS-TinyNet，一种针对遥感(Tiny Object Detection, RS)小目标检测的多阶段特征融合与增强模型。这一方法显示出在复杂RS环境中检测小物体的优越能力。


<details>
  <summary>Details</summary>
Motivation: 现有检测器在遥感图像中的小目标检测表现不足，主要由于目标小、特征弱、背景复杂等问题，因此需要开发一种更加有效的模型方法来解决。

Method: 提出了一种基于小目标显著性建模和特征完整性重建的新方法，利用三步特征增强模块（包括多维度协作注意力模块、辅助可逆分支模块和渐进式融合检测头模块），实现多阶段特征融合与增强。

Result: 在AI-TOD公共数据集上，相较现有最先进方法，提高了4.0% AP和6.5% AP75。并在DIOR数据集上验证了该方法在各种遥感场景下的出色表现。

Conclusion: RS-TinyNet提出的多阶段特征融合策略为在复杂遥感环境中检测小目标提供了一种有效且实用的解决方案。

Abstract: Detecting tiny objects in remote sensing (RS) imagery has been a
long-standing challenge due to their extremely limited spatial information,
weak feature representations, and dense distributions across complex
backgrounds. Despite numerous efforts devoted, mainstream detectors still
underperform in such scenarios. To bridge this gap, we introduce RS-TinyNet, a
multi-stage feature fusion and enhancement model explicitly tailored for RS
tiny object detection in various RS scenarios. RS-TinyNet comes with two novel
designs: tiny object saliency modeling and feature integrity reconstruction.
Guided by these principles, we design three step-wise feature enhancement
modules. Among them, the multi-dimensional collaborative attention (MDCA)
module employs multi-dimensional attention to enhance the saliency of tiny
objects. Additionally, the auxiliary reversible branch (ARB) and a progressive
fusion detection head (PFDH) module are introduced to preserve information flow
and fuse multi-level features to bridge semantic gaps and retain structural
detail. Comprehensive experiments on public RS dataset AI-TOD show that our
RS-TinyNet surpasses existing state-of-the-art (SOTA) detectors by 4.0% AP and
6.5% AP75. Evaluations on DIOR benchmark dataset further validate its superior
detection performance in diverse RS scenarios. These results demonstrate that
the proposed multi-stage feature fusion strategy offers an effective and
practical solution for tiny object detection in complex RS environments.

</details>


### [76] [VITA: Vision-to-Action Flow Matching Policy](https://arxiv.org/abs/2507.13231)
*Dechen Gao,Boqi Zhao,Andrew Lee,Ian Chuang,Hanchu Zhou,Hang Wang,Zhe Zhao,Junshan Zhang,Iman Soltani*

Main category: cs.CV

TL;DR: VITA是一种视觉到动作流匹配策略，通过演化潜在视觉表示为潜在动作，实现视动控制，简化传统的流匹配方法，显著提升性能且降低延迟。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法条件模块过于复杂以及不同模态的视觉和动作之间匹配困难的问题。

Method: VITA通过将潜在图像作为流源，创建基于自动编码器的结构化动作潜在空间，并通过标签解码监督流匹配训练，实现在简单MLP架构下的端到端优化。

Result: VITA在ALOHA平台的双手操作任务中表现优异，无论是在模拟环境还是现实任务中都能超越或匹配现有最先进方法，并且推理延迟减少50%-130%。

Conclusion: VITA首次展示了仅用MLP架构即可解决复杂的双手视觉操作任务的能力，为视动控制的简化和高效性能提供了新的可能性。

Abstract: We present VITA, a Vision-To-Action flow matching policy that evolves latent
visual representations into latent actions for visuomotor control. Traditional
flow matching and diffusion policies sample from standard source distributions
(e.g., Gaussian noise) and require additional conditioning mechanisms like
cross-attention to condition action generation on visual information, creating
time and space overheads. VITA proposes a novel paradigm that treats latent
images as the flow source, learning an inherent mapping from vision to action
while eliminating separate conditioning modules and preserving generative
modeling capabilities. Learning flows between fundamentally different
modalities like vision and action is challenging due to sparse action data
lacking semantic structures and dimensional mismatches between high-dimensional
visual representations and raw actions. We address this by creating a
structured action latent space via an autoencoder as the flow matching target,
up-sampling raw actions to match visual representation shapes. Crucially, we
supervise flow matching with both encoder targets and final action outputs
through flow latent decoding, which backpropagates action reconstruction loss
through sequential flow matching ODE solving steps for effective end-to-end
learning. Implemented as simple MLP layers, VITA is evaluated on challenging
bi-manual manipulation tasks on the ALOHA platform, including 5 simulation and
2 real-world tasks. Despite its simplicity, MLP-only VITA outperforms or
matches state-of-the-art generative policies while reducing inference latency
by 50-130% compared to conventional flow matching policies requiring different
conditioning mechanisms or complex architectures. To our knowledge, VITA is the
first MLP-only flow matching policy capable of solving complex bi-manual
manipulation tasks like those in ALOHA benchmarks.

</details>


### [77] [Efficient Adaptation of Pre-trained Vision Transformer underpinned by Approximately Orthogonal Fine-Tuning Strategy](https://arxiv.org/abs/2507.13260)
*Yiting Yang,Hao Luo,Yuan Sun,Qingsen Yan,Haokui Zhang,Wei Dong,Guoqing Wang,Peng Wang,Yang Yang,Hengtao Shen*

Main category: cs.CV

TL;DR: 本文提出了一种名为AOFT（Approximately Orthogonal Fine-Tuning）的策略，用于在参数高效微调ViT时生成近正交的低秩权重矩阵，从而提升模型的泛化能力。在图像分类任务中表现良好。


<details>
  <summary>Details</summary>
Motivation: 现有方法在微调ViT时，通常冻结大部分骨干参数，仅利用低秩的权重矩阵（如LoRA和Adapter）适配下游任务。然而，这些权重矩阵缺乏骨干参数中的近正交性特征，而这一特征有助于增强模型的泛化能力，因此作者希望通过改进低秩矩阵的结构来提高泛化能力。

Method: 提出AOFT策略，通过一个可学习向量生成一组近正交向量，构造下/上投影矩阵，使其具有与骨干相似的近正交特性，从而改善模型性能。

Result: 实验表明，在多项图像分类任务中，该方法表现出竞争力，验证了近正交性增强了下/上投影矩阵的泛化能力。

Conclusion: 通过采用AOFT策略，可以在不改变大部分骨干参数的情况下，使下/上投影矩阵具备骨干参数的近正交特性，从而显著提升ViT模型在下游任务中的表现。

Abstract: A prevalent approach in Parameter-Efficient Fine-Tuning (PEFT) of pre-trained
Vision Transformers (ViT) involves freezing the majority of the backbone
parameters and solely learning low-rank adaptation weight matrices to
accommodate downstream tasks. These low-rank matrices are commonly derived
through the multiplication structure of down-projection and up-projection
matrices, exemplified by methods such as LoRA and Adapter. In this work, we
observe an approximate orthogonality among any two row or column vectors within
any weight matrix of the backbone parameters; however, this property is absent
in the vectors of the down/up-projection matrices. Approximate orthogonality
implies a reduction in the upper bound of the model's generalization error,
signifying that the model possesses enhanced generalization capability. If the
fine-tuned down/up-projection matrices were to exhibit this same property as
the pre-trained backbone matrices, could the generalization capability of
fine-tuned ViTs be further augmented? To address this question, we propose an
Approximately Orthogonal Fine-Tuning (AOFT) strategy for representing the
low-rank weight matrices. This strategy employs a single learnable vector to
generate a set of approximately orthogonal vectors, which form the
down/up-projection matrices, thereby aligning the properties of these matrices
with those of the backbone. Extensive experimental results demonstrate that our
method achieves competitive performance across a range of downstream image
classification tasks, confirming the efficacy of the enhanced generalization
capability embedded in the down/up-projection matrices.

</details>


### [78] [Leveraging Pre-Trained Visual Models for AI-Generated Video Detection](https://arxiv.org/abs/2507.13224)
*Keerthi Veeramachaneni,Praveen Tirupattur,Amrit Singh Bedi,Mubarak Shah*

Main category: cs.CV

TL;DR: 本研究提出了一种利用预训练视觉模型的新方法，可有效检测AI生成的视频，并在验证中表现出超过90%的检测准确率。


<details>
  <summary>Details</summary>
Motivation: 由于生成式AI视觉内容的质量不断提高，AI生成内容与真实内容的区分变得困难，检测生成内容对解决虚假信息、防止隐私及安全威胁至关重要，尤其是在DeepFakes以外的视频领域。

Method: 提出利用预训练视觉模型提取特征，结合简单线性分类器，无需额外模型训练即可有效区分真实和生成视频。

Result: 在VID-AID数据集上的评估显示方法平均检测准确率超过90%。

Conclusion: 研究验证了利用预训练模型检测AI生成视频的高效性，并计划公开代码、模型及数据集以促进后续研究。

Abstract: Recent advances in Generative AI (GenAI) have led to significant improvements
in the quality of generated visual content. As AI-generated visual content
becomes increasingly indistinguishable from real content, the challenge of
detecting the generated content becomes critical in combating misinformation,
ensuring privacy, and preventing security threats. Although there has been
substantial progress in detecting AI-generated images, current methods for
video detection are largely focused on deepfakes, which primarily involve human
faces. However, the field of video generation has advanced beyond DeepFakes,
creating an urgent need for methods capable of detecting AI-generated videos
with generic content. To address this gap, we propose a novel approach that
leverages pre-trained visual models to distinguish between real and generated
videos. The features extracted from these pre-trained models, which have been
trained on extensive real visual content, contain inherent signals that can
help distinguish real from generated videos. Using these extracted features, we
achieve high detection performance without requiring additional model training,
and we further improve performance by training a simple linear classification
layer on top of the extracted features. We validated our method on a dataset we
compiled (VID-AID), which includes around 10,000 AI-generated videos produced
by 9 different text-to-video models, along with 4,000 real videos, totaling
over 7 hours of video content. Our evaluation shows that our approach achieves
high detection accuracy, above 90% on average, underscoring its effectiveness.
Upon acceptance, we plan to publicly release the code, the pre-trained models,
and our dataset to support ongoing research in this critical area.

</details>


### [79] [Revisiting Reliability in the Reasoning-based Pose Estimation Benchmark](https://arxiv.org/abs/2507.13314)
*Junsu Kim,Naeun Kim,Jaeho Lee,Incheol Park,Dongyoon Han,Seungryul Baek*

Main category: cs.CV

TL;DR: 本文探讨了RPE基准测试中的可重复性和质量问题，并通过修订GT注释提升评估一致性，提供公开资源。


<details>
  <summary>Details</summary>
Motivation: 解决RPE基准中因图像索引不一致及其他问题导致的可重复性与公平性欠缺问题。

Method: 对原始数据集GT注释进行详细视觉匹配，并改进以消除多余性和不平衡问题，同时公开这些改进的注释。

Result: 改进的GT注释能够提升RPE基准的可重复性和质量，并提供公开资源支持后续研究。

Conclusion: 通过优化原始数据集注释及其发布，促进了人类姿态感知多模态推理的更一致和可靠的发展。

Abstract: The reasoning-based pose estimation (RPE) benchmark has emerged as a widely
adopted evaluation standard for pose-aware multimodal large language models
(MLLMs). Despite its significance, we identified critical reproducibility and
benchmark-quality issues that hinder fair and consistent quantitative
evaluations. Most notably, the benchmark utilizes different image indices from
those of the original 3DPW dataset, forcing researchers into tedious and
error-prone manual matching processes to obtain accurate ground-truth (GT)
annotations for quantitative metrics (\eg, MPJPE, PA-MPJPE). Furthermore, our
analysis reveals several inherent benchmark-quality limitations, including
significant image redundancy, scenario imbalance, overly simplistic poses, and
ambiguous textual descriptions, collectively undermining reliable evaluations
across diverse scenarios. To alleviate manual effort and enhance
reproducibility, we carefully refined the GT annotations through meticulous
visual matching and publicly release these refined annotations as an
open-source resource, thereby promoting consistent quantitative evaluations and
facilitating future advancements in human pose-aware multimodal reasoning.

</details>


### [80] [DiffClean: Diffusion-based Makeup Removal for Accurate Age Estimation](https://arxiv.org/abs/2507.13292)
*Ekta Balkrishna Gavas,Chinmay Hegde,Nasir Memon,Sudipta Banerjee*

Main category: cs.CV

TL;DR: 提出了一种名为DiffClean的文本引导扩散模型，用于去除化妆痕迹，以提高年龄估计和人脸验证的准确性。


<details>
  <summary>Details</summary>
Motivation: 化妆会改变外貌，影响年龄估计的准确性，导致无法有效保护未成年用户免受不适合的在线内容影响。

Method: 使用文本引导的扩散模型，去除化妆痕迹，从而改善年龄估计和人脸验证的能力。

Result: DiffClean在基于化妆的数字模拟和真实化妆图像上，年龄估计准确性提高了4.8%，人脸验证精确度提升了8.9%。

Conclusion: DiffClean有效降低了化妆对年龄估计和人脸验证的干扰，为在线平台的年龄验证提供了新型解决方案。

Abstract: Accurate age verification can protect underage users from unauthorized access
to online platforms and e-commerce sites that provide age-restricted services.
However, accurate age estimation can be confounded by several factors,
including facial makeup that can induce changes to alter perceived identity and
age to fool both humans and machines. In this work, we propose DiffClean which
erases makeup traces using a text-guided diffusion model to defend against
makeup attacks. DiffClean improves age estimation (minor vs. adult accuracy by
4.8%) and face verification (TMR by 8.9% at FMR=0.01%) over competing baselines
on digitally simulated and real makeup images.

</details>


### [81] [FashionPose: Text to Pose to Relight Image Generation for Personalized Fashion Visualization](https://arxiv.org/abs/2507.13311)
*Chuancheng Shi,Yixiang Chen,Burong Lei,Jichao Chen*

Main category: cs.CV

TL;DR: FashionPose提出了一个统一的从文本到姿势再到光照生成的框架，用于逼真的服装可视化。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预定义姿势，限制了语义灵活性和光照适应性，时尚电商场景需要更个性化的服务。

Method: 通过文本驱动，先预测2D人体姿势，然后使用扩散模型生成高保真图像，最后应用轻量化光照模块，全过程由文本指导。

Result: 实验表明该模型在细粒度姿势合成和高效、一致的重新光照上表现优异。

Conclusion: FashionPose为个性化虚拟时尚展示提供了一种实际的解决方案。

Abstract: Realistic and controllable garment visualization is critical for fashion
e-commerce, where users expect personalized previews under diverse poses and
lighting conditions. Existing methods often rely on predefined poses, limiting
semantic flexibility and illumination adaptability. To address this, we
introduce FashionPose, the first unified text-to-pose-to-relighting generation
framework. Given a natural language description, our method first predicts a 2D
human pose, then employs a diffusion model to generate high-fidelity person
images, and finally applies a lightweight relighting module, all guided by the
same textual input. By replacing explicit pose annotations with text-driven
conditioning, FashionPose enables accurate pose alignment, faithful garment
rendering, and flexible lighting control. Experiments demonstrate fine-grained
pose synthesis and efficient, consistent relighting, providing a practical
solution for personalized virtual fashion display.

</details>


### [82] [Imbalance in Balance: Online Concept Balancing in Generation Models](https://arxiv.org/abs/2507.13345)
*Yukai Shi,Jiarong Ou,Rui Chen,Haotian Yang,Jiahao Wang,Xin Tao,Pengfei Wan,Di Zhang,Kun Gai*

Main category: cs.CV

TL;DR: 本文探讨了视觉生成任务中复杂概念响应缺乏稳定性的问题，提出了一种改进响应能力的新方法，并通过实验验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 视觉生成任务中复杂概念的响应和组合常常不稳定且容易出错，但其原因尚未被深入研究。

Method: 设计了一种概念级别的均衡损失函数（IMBA loss），无需离线数据集处理，代码改动极少，且在实验中验证其性能提升。

Result: 在新提出的Inert-CompBench基准测试及其它两个公开数据集上，所提出的方法显著改善了基线模型的概念响应能力，取得了优异的结果。

Conclusion: 所提出的在线方法在保持代码精简的同时，能有效提高复杂概念处理的稳定性与准确性。

Abstract: In visual generation tasks, the responses and combinations of complex
concepts often lack stability and are error-prone, which remains an
under-explored area. In this paper, we attempt to explore the causal factors
for poor concept responses through elaborately designed experiments. We also
design a concept-wise equalization loss function (IMBA loss) to address this
issue. Our proposed method is online, eliminating the need for offline dataset
processing, and requires minimal code changes. In our newly proposed complex
concept benchmark Inert-CompBench and two other public test sets, our method
significantly enhances the concept response capability of baseline models and
yields highly competitive results with only a few codes.

</details>


### [83] [A Real-Time System for Egocentric Hand-Object Interaction Detection in Industrial Domains](https://arxiv.org/abs/2507.13326)
*Antonio Finocchiaro,Alessandro Sebastiano Catinello,Michele Mazzamuto,Rosario Leonardi,Antonino Furnari,Giovanni Maria Farinella*

Main category: cs.CV

TL;DR: 研究提出了一种用于实时手-物交互检测的高效方法，整合动作识别和物体检测模块，能实现快速且准确的检测。


<details>
  <summary>Details</summary>
Motivation: 为了解决实时应用中快速、准确的手-物交互检测问题，提供直观的用户体验。

Method: 方法采用级联架构，将动作识别和物体检测模块顺序使用。动作识别模块通过EfficientNetV2为骨干的Mamba模型实现，而物体检测模块使用微调的YOLOWorld，并仅在检测到接触状态时激活物体检测。

Result: 动作识别模块在ENIGMA-51基准上达到38.52% p-AP并实现30fps，微调的YOLOWorld在手和物体检测中达到85.13% AP。

Conclusion: 该方法能实现实时高效的手-物交互检测，结合两部分模型的效果，达到了较高的精度与速度，适用于实时应用场景。

Abstract: Hand-object interaction detection remains an open challenge in real-time
applications, where intuitive user experiences depend on fast and accurate
detection of interactions with surrounding objects. We propose an efficient
approach for detecting hand-objects interactions from streaming egocentric
vision that operates in real time. Our approach consists of an action
recognition module and an object detection module for identifying active
objects upon confirmed interaction. Our Mamba model with EfficientNetV2 as
backbone for action recognition achieves 38.52% p-AP on the ENIGMA-51 benchmark
at 30fps, while our fine-tuned YOLOWorld reaches 85.13% AP for hand and object.
We implement our models in a cascaded architecture where the action recognition
and object detection modules operate sequentially. When the action recognition
predicts a contact state, it activates the object detection module, which in
turn performs inference on the relevant frame to detect and classify the active
object.

</details>


### [84] [VideoITG: Multimodal Video Understanding with Instructed Temporal Grounding](https://arxiv.org/abs/2507.13353)
*Shihao Wang,Guo Chen,De-an Huang,Zhiqi Li,Minghan Li,Guilin Li,Jose M. Alvarez,Lei Zhang,Zhiding Yu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为VideoITG的新方法，通过用户指令定制视频帧选取，提升视频大型语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理长视频理解时存在局限，研究旨在优化视频帧选择以克服这些复杂场景中的问题。

Method: 提出了VideoITG方法，通过VidThinker流水线实现自动化注释，包括生成详细片段字幕、检索相关视频片段和精细化选择关键帧，并构建了VideoITG-40K数据集以及一个可插拔的VideoITG模型。

Result: 与现有的视频大型语言模型结合后，VideoITG在多个多模态视频理解基准上均取得了性能提升。

Conclusion: VideoITG展现了其在视频理解中显著的性能优势和潜力。

Abstract: Recent studies have revealed that selecting informative and relevant video
frames can significantly improve the performance of Video Large Language Models
(Video-LLMs). Current methods, such as reducing inter-frame redundancy,
employing separate models for image-text relevance assessment, or utilizing
temporal video grounding for event localization, substantially adopt
unsupervised learning paradigms, whereas they struggle to address the complex
scenarios in long video understanding. We propose Instructed Temporal Grounding
for Videos (VideoITG), featuring customized frame sampling aligned with user
instructions. The core of VideoITG is the VidThinker pipeline, an automated
annotation framework that explicitly mimics the human annotation process.
First, it generates detailed clip-level captions conditioned on the
instruction; then, it retrieves relevant video segments through
instruction-guided reasoning; finally, it performs fine-grained frame selection
to pinpoint the most informative visual evidence. Leveraging VidThinker, we
construct the VideoITG-40K dataset, containing 40K videos and 500K instructed
temporal grounding annotations. We then design a plug-and-play VideoITG model,
which takes advantage of visual language alignment and reasoning capabilities
of Video-LLMs, for effective frame selection in a discriminative manner.
Coupled with Video-LLMs, VideoITG achieves consistent performance improvements
across multiple multimodal video understanding benchmarks, showing its
superiority and great potentials for video understanding.

</details>


### [85] [Taming Diffusion Transformer for Real-Time Mobile Video Generation](https://arxiv.org/abs/2507.13343)
*Yushu Wu,Yanyu Li,Anil Kag,Ivan Skorokhodov,Willi Menapace,Ke Ma,Arpit Sahni,Ju Hu,Aliaksandr Siarohin,Dhritiman Sagar,Yanzhi Wang,Sergey Tulyakov*

Main category: cs.CV

TL;DR: 提出了多种优化方法加速视频生成，实现了智能手机上的实时、高质量视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有扩散变换器在视频生成任务中表现优秀，但其高计算成本限制了在资源受限设备中的应用，实时生成更具挑战。

Method: 使用高度压缩的变分自动编码器、敏感性感知的三层剪枝策略和针对DiT设计的对抗性步骤蒸馏技术，优化模型并减少推理步骤。

Result: 在iPhone 16 Pro Max上实现了超过10FPS的实时视频生成。

Conclusion: 这些优化验证了在移动设备上高质量实时视频生成的可行性。

Abstract: Diffusion Transformers (DiT) have shown strong performance in video
generation tasks, but their high computational cost makes them impractical for
resource-constrained devices like smartphones, and real-time generation is even
more challenging. In this work, we propose a series of novel optimizations to
significantly accelerate video generation and enable real-time performance on
mobile platforms. First, we employ a highly compressed variational autoencoder
(VAE) to reduce the dimensionality of the input data without sacrificing visual
quality. Second, we introduce a KD-guided, sensitivity-aware tri-level pruning
strategy to shrink the model size to suit mobile platform while preserving
critical performance characteristics. Third, we develop an adversarial step
distillation technique tailored for DiT, which allows us to reduce the number
of inference steps to four. Combined, these optimizations enable our model to
achieve over 10 frames per second (FPS) generation on an iPhone 16 Pro Max,
demonstrating the feasibility of real-time, high-quality video generation on
mobile devices.

</details>


### [86] [Diffuman4D: 4D Consistent Human View Synthesis from Sparse-View Videos with Spatio-Temporal Diffusion Models](https://arxiv.org/abs/2507.13344)
*Yudong Jin,Sida Peng,Xuan Wang,Tao Xie,Zhen Xu,Yifan Yang,Yujun Shen,Hujun Bao,Xiaowei Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种新的滑动迭代去噪过程，解决了从稀疏视图视频生成高保真新视角人类视频的挑战，有效提升了4D一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成新视角视频时常缺乏时空一致性，影响合成质量。

Method: 提出通过在潜在网格中使用滑动窗口的迭代去噪，从空间和时间维度交替处理数据，并最终解码生成目标视角视频。

Result: 实验表明，该方法在DNA-Rendering和ActorsHQ数据集上生成高质量一致视频，性能明显优于现有方法。

Conclusion: 本方法在生成高保真新视角视频方面具有较大的技术优势和应用潜力。

Abstract: This paper addresses the challenge of high-fidelity view synthesis of humans
with sparse-view videos as input. Previous methods solve the issue of
insufficient observation by leveraging 4D diffusion models to generate videos
at novel viewpoints. However, the generated videos from these models often lack
spatio-temporal consistency, thus degrading view synthesis quality. In this
paper, we propose a novel sliding iterative denoising process to enhance the
spatio-temporal consistency of the 4D diffusion model. Specifically, we define
a latent grid in which each latent encodes the image, camera pose, and human
pose for a certain viewpoint and timestamp, then alternately denoising the
latent grid along spatial and temporal dimensions with a sliding window, and
finally decode the videos at target viewpoints from the corresponding denoised
latents. Through the iterative sliding, information flows sufficiently across
the latent grid, allowing the diffusion model to obtain a large receptive field
and thus enhance the 4D consistency of the output, while making the GPU memory
consumption affordable. The experiments on the DNA-Rendering and ActorsHQ
datasets demonstrate that our method is able to synthesize high-quality and
consistent novel-view videos and significantly outperforms the existing
approaches. See our project page for interactive demos and video results:
https://diffuman4d.github.io/ .

</details>


### [87] [AutoPartGen: Autogressive 3D Part Generation and Discovery](https://arxiv.org/abs/2507.13346)
*Minghao Chen,Jianyuan Wang,Roman Shapovalov,Tom Monnier,Hyunyoung Jung,Dilin Wang,Rakesh Ranjan,Iro Laina,Andrea Vedaldi*

Main category: cs.CV

TL;DR: 论文提出了AutoPartGen，一种用于自动生成3D部件的模型，利用3DShape2VecSet的潜在表示空间进行递归式生成。


<details>
  <summary>Details</summary>
Motivation: 探讨如何基于图像或现有3D对象高效生成兼具几何表达能力的部分组合式3D物体。

Method: 采用3DShape2VecSet潜在表示，递归预测各部件，同时结合2D图像、掩码或3D对象作为附加输入，最终无需额外优化拼装成完整对象。

Result: 模型在整体3D生成和部件级生成的性能上均取得了最新最优的结果。

Conclusion: AutoPartGen展示了在3D部件生成任务上的有效性，可实现自动生成类型及数量的高质量3D组合对象。

Abstract: We introduce AutoPartGen, a model that generates objects composed of 3D parts
in an autoregressive manner. This model can take as input an image of an
object, 2D masks of the object's parts, or an existing 3D object, and generate
a corresponding compositional 3D reconstruction. Our approach builds upon
3DShape2VecSet, a recent latent 3D representation with powerful geometric
expressiveness. We observe that this latent space exhibits strong compositional
properties, making it particularly well-suited for part-based generation tasks.
Specifically, AutoPartGen generates object parts autoregressively, predicting
one part at a time while conditioning on previously generated parts and
additional inputs, such as 2D images, masks, or 3D objects. This process
continues until the model decides that all parts have been generated, thus
determining automatically the type and number of parts. The resulting parts can
be seamlessly assembled into coherent objects or scenes without requiring
additional optimization. We evaluate both the overall 3D generation
capabilities and the part-level generation quality of AutoPartGen,
demonstrating that it achieves state-of-the-art performance in 3D part
generation.

</details>


### [88] [$π^3$: Scalable Permutation-Equivariant Visual Geometry Learning](https://arxiv.org/abs/2507.13347)
*Yifan Wang,Jianjun Zhou,Haoyi Zhu,Wenzheng Chang,Yang Zhou,Zizun Li,Junyi Chen,Jiangmiao Pang,Chunhua Shen,Tong He*

Main category: cs.CV

TL;DR: $c3$ 提出了一种无固定参考视图的视觉几何重建方法。


<details>
  <summary>Details</summary>
Motivation: 避免传统方法因固定参考视图的选择而导致的不稳定性和失败问题。

Method: 采用完全置换等变架构，预测仿射不变的相机位姿及尺度不变的局部点图，无需参考帧。

Result: 在相机位姿估计、单目/视频深度估计和稠密点图重建等任务上达到了最新的技术水平。

Conclusion: $ 3c3$ 提供了一种简单且无偏的方法，鲁棒性强且具备高度可扩展性，为视觉几何重建领域打开了新的可能性。

Abstract: We introduce $\pi^3$, a feed-forward neural network that offers a novel
approach to visual geometry reconstruction, breaking the reliance on a
conventional fixed reference view. Previous methods often anchor their
reconstructions to a designated viewpoint, an inductive bias that can lead to
instability and failures if the reference is suboptimal. In contrast, $\pi^3$
employs a fully permutation-equivariant architecture to predict
affine-invariant camera poses and scale-invariant local point maps without any
reference frames. This design makes our model inherently robust to input
ordering and highly scalable. These advantages enable our simple and bias-free
approach to achieve state-of-the-art performance on a wide range of tasks,
including camera pose estimation, monocular/video depth estimation, and dense
point map reconstruction. Code and models are publicly available.

</details>


### [89] [Hierarchical Rectified Flow Matching with Mini-Batch Couplings](https://arxiv.org/abs/2507.13350)
*Yichi Zhang,Yici Yan,Alex Schwing,Zhizhen Zhao*

Main category: cs.CV

TL;DR: 文章提出了利用小批量耦合优化分层流匹配的方法，通过在不同层次的分层流中逐步调整分布的复杂性，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 流匹配是一种强大的生成建模方法，但在处理多模态速度场时存在局限性。之前的分层流匹配虽能建模多模分布，但层次间复杂性未能调整。本研究旨在解决此问题并提升性能。

Method: 通过在分层流匹配中引入小批量耦合，逐步调整层次分布的复杂性，以更有效地捕捉多模态速度分布。

Result: 在合成数据和图像数据上的实验结果表明，小批量耦合的分层修正流匹配模型能够有效提升性能。

Conclusion: 小批量耦合可有效调整分层流匹配中的分布复杂性，提升生成模型对多模态分布的捕捉能力。

Abstract: Flow matching has emerged as a compelling generative modeling approach that
is widely used across domains. To generate data via a flow matching model, an
ordinary differential equation (ODE) is numerically solved via forward
integration of the modeled velocity field. To better capture the multi-modality
that is inherent in typical velocity fields, hierarchical flow matching was
recently introduced. It uses a hierarchy of ODEs that are numerically
integrated when generating data. This hierarchy of ODEs captures the
multi-modal velocity distribution just like vanilla flow matching is capable of
modeling a multi-modal data distribution. While this hierarchy enables to model
multi-modal velocity distributions, the complexity of the modeled distribution
remains identical across levels of the hierarchy. In this paper, we study how
to gradually adjust the complexity of the distributions across different levels
of the hierarchy via mini-batch couplings. We show the benefits of mini-batch
couplings in hierarchical rectified flow matching via compelling results on
synthetic and imaging data. Code is available at
https://riccizz.github.io/HRF_coupling.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [90] [Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models](https://arxiv.org/abs/2507.12547)
*Lionel Wong,Katherine M. Collins,Lance Ying,Cedegao E. Zhang,Adrian Weller,Tobias Gersternberg,Timothy O'Donnell,Alexander K. Lew,Jacob D. Andreas,Joshua B. Tenenbaum,Tyler Brooke-Wilson*

Main category: cs.CL

TL;DR: 该研究探讨了人类如何在新情境下有效整合背景知识，提出结合分布式和符号表示的模型合成架构(MSA)，并使用一套新数据集进行验证。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解人类如何在面对新情境时基于背景知识构建合理推理。

Method: 提出一种计算方法——模型合成架构（MSA），结合语言模型进行全局相关性检索与模型合成，以及概率程序来构造符合场景的世界模型。

Result: MSA在一组关于开放式推理的任务上优于仅使用语言模型的基线方法，尤其在因果结构、不确定变量及背景知识的整合推理任务中表现出色。

Conclusion: MSA方法有效捕捉了人类推理的特性，为理解并模拟开端域中的人类推理提供了可能路径。

Abstract: When faced with novel situations, people are able to marshal relevant
considerations from a wide range of background knowledge and put these to use
in inferences and predictions. What permits us to draw in globally relevant
information and reason over it coherently? Here, we explore the hypothesis that
people use a combination of distributed and symbolic representations to
construct bespoke mental models tailored to novel situations. We propose a
computational implementation of this idea -- a ``Model Synthesis Architecture''
(MSA) -- using language models to implement global relevance-based retrieval
and model synthesis and probabilistic programs to implement bespoke, coherent
world models. We evaluate our MSA as a model of human judgments on a novel
reasoning dataset. The dataset -- built around a `Model Olympics` domain of
sports vignettes -- tests models' capacity for human-like, open-ended reasoning
by requiring (i) judgments about novel causal structures described in language;
(ii) drawing on large bodies of background knowledge; and (iii) doing both in
light of observations that introduce arbitrary novel variables. Our MSA
approach captures human judgments better than language model-only baselines,
under both direct and chain-of-thought generations from the LM that supports
model synthesis. These results suggest that MSAs can be implemented in a way
that mirrors people's ability to deliver locally coherent reasoning over
globally relevant variables, offering a path to understanding and replicating
human reasoning in open-ended domains.

</details>


### [91] [Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility](https://arxiv.org/abs/2507.12553)
*Michael A. Lepori,Jennifer Hu,Ishita Dasgupta,Roma Patel,Thomas Serre,Ellie Pavlick*

Main category: cs.CL

TL;DR: 本研究发现语言模型（LMs）可以更可靠地区分句子的模态类别，提出了模态差异向量的概念，并展示了其对人类模态类别区分行为的相关性。


<details>
  <summary>Details</summary>
Motivation: 此前的研究质疑了语言模型区分模态类别的能力，因此作者希望探讨语言模型是否能更可靠地完成这一任务。

Method: 通过识别和分析语言模型中用以区别模态类别的线性表示（即模态差异向量），并研究这些向量随着模型训练的进展如何演变。

Result: 发现语言模型可以通过模态差异向量成功实现更可靠的模态分类，并且这些向量的形成过程与模型的训练和复杂度一致。

Conclusion: 研究展示了模态差异向量在表达模态分类能力以及建模人类分类行为上的潜力，还揭示了语言模型对模态分类的内在能力和其对人类认知探索的应用前景。

Abstract: Language models (LMs) are used for a diverse range of tasks, from question
answering to writing fantastical stories. In order to reliably accomplish these
tasks, LMs must be able to discern the modal category of a sentence (i.e.,
whether it describes something that is possible, impossible, completely
nonsensical, etc.). However, recent studies have called into question the
ability of LMs to categorize sentences according to modality (Michaelov et al.,
2025; Kauf et al., 2023). In this work, we identify linear representations that
discriminate between modal categories within a variety of LMs, or modal
difference vectors. Analysis of modal difference vectors reveals that LMs have
access to more reliable modal categorization judgments than previously
reported. Furthermore, we find that modal difference vectors emerge in a
consistent order as models become more competent (i.e., through training steps,
layers, and parameter count). Notably, we find that modal difference vectors
identified within LM activations can be used to model fine-grained human
categorization behavior. This potentially provides a novel view into how human
participants distinguish between modal categories, which we explore by
correlating projections along modal difference vectors with human participants'
ratings of interpretable features. In summary, we derive new insights into LM
modal categorization using techniques from mechanistic interpretability, with
the potential to inform our understanding of modal categorization in humans.

</details>


### [92] [The first open machine translation system for the Chechen language](https://arxiv.org/abs/2507.12672)
*Abu-Viskhan A. Umishov,Vladislav A. Grigorian*

Main category: cs.CL

TL;DR: 该论文介绍了一个利用开放源码模型进行车臣语和俄语互译的研究，包含数据集和多语言翻译系统的细节。


<details>
  <summary>Details</summary>
Motivation: 针对车臣语作为一种弱势语言，作者希望通过多语言翻译系统保存和增进对其的研究及使用。

Method: 结合NLLB-200大型多语言翻译模型，进行了针对车臣语的参数微调，并构建了平行数据集和多语言编码器。

Result: 从俄语到车臣语和从车臣语到俄语的BLEU/ChrF++评分分别为8.34/34.69和20.89/44.55。

Conclusion: 证明了通过微调大型翻译模型能够支持弱势语言翻译，并发布了相关的数据集和模型资源以推动研究发展。

Abstract: We introduce the first open-source model for translation between the
vulnerable Chechen language and Russian, and the dataset collected to train and
evaluate it. We explore fine-tuning capabilities for including a new language
into a large language model system for multilingual translation NLLB-200. The
BLEU / ChrF++ scores for our model are 8.34 / 34.69 and 20.89 / 44.55 for
translation from Russian to Chechen and reverse direction, respectively. The
release of the translation models is accompanied by the distribution of
parallel words, phrases and sentences corpora and multilingual sentence encoder
adapted to the Chechen language.

</details>


### [93] [Improving Drug Identification in Overdose Death Surveillance using Large Language Models](https://arxiv.org/abs/2507.12679)
*Arthur J. Funnell,Panayiotis Petousis,Fabrice Harel-Canada,Ruby Romero,Alex A. T. Bui,Adam Koncsol,Hritika Chaturvedi,Chelsea Shover,David Goodman-Meza*

Main category: cs.CL

TL;DR: 本研究提出利用自然语言处理模型（NLP）分析验尸报告中的文本数据，以提高药物过量死亡的监测效率，尤其针对芬太尼相关死亡。


<details>
  <summary>Details</summary>
Motivation: 随着美国因药物过量导致的死亡率不断上升，尤其是由芬太尼推动的情况，传统依赖ICD-10编码的监测方式难以满足快速准确的需求，因此需要自动化和更高效的方法。

Method: 利用2020年的35,433条死亡记录数据进行模型训练和内部测试，并使用2023-2024年的3,335条全新数据集进行外部验证。评估了多种NLP方法，包括传统分类器、BERT、BioClinicalBERT，以及现代解码器大模型（如Qwen 3，Llama 3）。

Result: 经调优的BioClinicalBERT在内部测试中取得了接近完美的宏观F1分数（>=0.998），外部验证宏观F1分数达到0.966，显著优于常规机器学习和其他语言模型。

Conclusion: NLP模型，尤其是经过调优的临床语言模型如BioClinicalBERT，为自由文本报告中的过量用药分类提供了高精度、可扩展的解决方案，可显著加速监控流程，并支持近实时的药物趋势检测。

Abstract: The rising rate of drug-related deaths in the United States, largely driven
by fentanyl, requires timely and accurate surveillance. However, critical
overdose data are often buried in free-text coroner reports, leading to delays
and information loss when coded into ICD (International Classification of
Disease)-10 classifications. Natural language processing (NLP) models may
automate and enhance overdose surveillance, but prior applications have been
limited. A dataset of 35,433 death records from multiple U.S. jurisdictions in
2020 was used for model training and internal testing. External validation was
conducted using a novel separate dataset of 3,335 records from 2023-2024.
Multiple NLP approaches were evaluated for classifying specific drug
involvement from unstructured death certificate text. These included
traditional single- and multi-label classifiers, as well as fine-tuned
encoder-only language models such as Bidirectional Encoder Representations from
Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large
language models such as Qwen 3 and Llama 3. Model performance was assessed
using macro-averaged F1 scores, and 95% confidence intervals were calculated to
quantify uncertainty. Fine-tuned BioClinicalBERT models achieved near-perfect
performance, with macro F1 scores >=0.998 on the internal test set. External
validation confirmed robustness (macro F1=0.966), outperforming conventional
machine learning, general-domain BERT models, and various decoder-only large
language models. NLP models, particularly fine-tuned clinical variants like
BioClinicalBERT, offer a highly accurate and scalable solution for overdose
death classification from free-text reports. These methods can significantly
accelerate surveillance workflows, overcoming the limitations of manual ICD-10
coding and supporting near real-time detection of emerging substance use
trends.

</details>


### [94] [AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.12695)
*S M Rafiuddin,Sadia Kamal,Mohammed Rakib,Arunkumar Bagavathi,Atriya Sen*

Main category: cs.CL

TL;DR: 提出了AdaptiSent框架，通过自适应跨模态注意力机制改进了多模态情感分类及方面术语提取，实现了更高精度。


<details>
  <summary>Details</summary>
Motivation: 提升多模态情感分析与方面术语提取的性能，弥补当前方法对文本与图像互动关系处理不足的局限。

Method: 通过动态模态加权和上下文自适应注意力机制，将文本线索与视觉上下文交互融合，改进情感和相关信息提取。

Result: 在标准的Twitter数据集上表现出比传统文本和其他多模态方法更高的精准率、召回率和F1分数，特别是对细微的跨模态关系表现优秀。

Conclusion: AdaptiSent设置了多模态情感分析的新标准，显著优于当前方法，尤其在理解复杂的多模态信息方面表现出色。

Abstract: We introduce AdaptiSent, a new framework for Multimodal Aspect-Based
Sentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms
to improve sentiment classification and aspect term extraction from both text
and images. Our model integrates dynamic modality weighting and
context-adaptive attention, enhancing the extraction of sentiment and
aspect-related information by focusing on how textual cues and visual context
interact. We tested our approach against several baselines, including
traditional text-based models and other multimodal methods. Results from
standard Twitter datasets show that AdaptiSent surpasses existing models in
precision, recall, and F1 score, and is particularly effective in identifying
nuanced inter-modal relationships that are crucial for accurate sentiment and
aspect term extraction. This effectiveness comes from the model's ability to
adjust its focus dynamically based on the context's relevance, improving the
depth and accuracy of sentiment analysis across various multimodal data sets.
AdaptiSent sets a new standard for MABSA, significantly outperforming current
methods, especially in understanding complex multimodal information.

</details>


### [95] [AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation](https://arxiv.org/abs/2507.12705)
*Potsawee Manakul,Woody Haosheng Gan,Michael J. Ryan,Ali Sartaz Khan,Warit Sirichotedumrong,Kunat Pipatanakul,William Held,Diyi Yang*

Main category: cs.CL

TL;DR: 文章提出了一种基于大规模音频模型的评估框架AudioJudge，通过提示工程优化评估性能，并使用多方面集成以提升一般评估能力。


<details>
  <summary>Details</summary>
Motivation: 目前语音评估存在需要为具体音频特性设计专用系统以及自动评估方法与人类偏好相关性差的问题，亟需一个统一的评估框架来解决。

Method: 研究利用提示工程和音频拼接方法提升音频特性检测和人类偏好模拟的能力，并设计了一个多方面集成的评估系统针对不同语言和语音特性。

Result: AudioJudge在系统排名基准测试中实现了与人类偏好高达0.91的Spearman相关性，并表现出在噪声条件下仍保持强大能力，但在多用性和位置偏好上仍存挑战。

Conclusion: AudioJudge提供了一个高效且精确的统一语音评估框架，尽管在噪声和偏好问题上需要进一步优化，但其优越性能展示了基于大音频模型评估的潜力。

Abstract: Current speech evaluation suffers from two critical limitations: the need and
difficulty of designing specialized systems targeting individual audio
characteristics, and poor correlation between automatic evaluation methods and
human preferences. This work presents a systematic study of Large Audio Model
(LAM) as a Judge, AudioJudge, investigating whether it can provide a unified
evaluation framework that addresses both challenges. We systematically explore
AudioJudge across audio characteristic detection tasks, including
pronunciation, speaking rate, speaker identification and speech quality, and
system-level human preference simulation for automated benchmarking. We
investigate different prompt engineering strategies, finding that audio
concatenation combined with in-context learning significantly improves
performance across both audio characteristic detection and human preference
simulation tasks. We further introduce a multi-aspect ensemble AudioJudge to
enable general-purpose multi-aspect audio evaluation. This method decomposes
speech assessment into specialized judges for lexical content, speech quality,
and paralinguistic features, achieving up to 0.91 Spearman correlation with
human preferences on our system ranking benchmark. Robustness analysis reveals
that while LAMs maintain strong performance under acoustic noise, they exhibit
significant verbosity and positional biases that require careful mitigation.

</details>


### [96] [FLEXITOKENS: Flexible Tokenization for Evolving Language Models](https://arxiv.org/abs/2507.12720)
*Abraham Toluase Owodunni,Orevaoghene Ahia,Sachin Kumar*

Main category: cs.CL

TL;DR: 提出了一种基于字节的语言模型，使用可学习的分词器FLEXITOKENS，旨在解决传统模型在适应新数据分布时分词过于僵硬的问题。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型的分词器不可调，导致在面对新领域或语言时产生过度分段的问题，从而影响下游任务的性能。

Method: 引入了基于字节的语言模型和FLEXITOKENS分词器，通过学习可变长度的分词边界，并简化训练目标以增强适应能力。

Result: 在多种多语言基准测试和形态学多样任务中，FLEXITOKENS显著减少了分词过度分段现象，且在下游任务性能上提高了最多10%。

Conclusion: FLEXITOKENS提供了一种简单但高效的方法解决语言模型分词器在新分布中的灵活性问题，提升了模型在多样化任务和领域上的表现。

Abstract: Language models (LMs) are challenging to adapt to new data distributions by
simple finetuning. This is due to the rigidity of their subword tokenizers,
which typically remain unchanged during adaptation. This inflexibility often
leads to inefficient tokenization, causing overfragmentation of
out-of-distribution domains, unseen languages, or scripts. In this work, we
develop byte-level LMs with learnable tokenizers to make tokenization adaptive.
Our models include a submodule that learns to predict boundaries between the
input byte sequence, encoding it into variable-length segments. Existing
tokenizer-free methods train this boundary predictor using an auxiliary loss
that enforces a fixed compression rate across the training corpus, introducing
a new kind of rigidity. We propose FLEXITOKENS, a simplified training objective
that enables significantly greater flexibility during adaptation. Evaluating
across multiple multilingual benchmarks, morphologically diverse tasks, and
domains, we demonstrate that FLEXITOKENS consistently reduces token
over-fragmentation and achieves up to 10\% improvements on downstream task
performance compared to subword and other gradient-based tokenizers. Code and
data for our experiments will be released at
https://github.com/owos/flexitokens

</details>


### [97] [TransEvalnia: Reasoning-based Evaluation and Ranking of Translations](https://arxiv.org/abs/2507.12724)
*Richard Sproat,Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: TransEvalnia是一个基于提示的翻译评估与排序系统，结合推理功能，进行细化评价并提供数值评分，同时表现优于MT-Ranker。


<details>
  <summary>Details</summary>
Motivation: 解决现有翻译评估系统的不足，包括更精细的质量打分、评估的可解释性以及与人工评分的更高相关性。

Method: 通过使用高级语言模型（如Claude-3.5-Sonnet和Qwen-2.5-72B-Instruct）进行基于提示的翻译质量评估，结合Multidimensional Quality Metrics，提供译文细粒度分析，识别排名最佳翻译，并提出纠正位置偏差的方法。

Result: TransEvalnia在多语言对测试中表现优异，例如与人工评分高度一致，同时性能优于现有最优系统MT-Ranker。

Conclusion: TransEvalnia展示了有效的语言评估能力及模型评分与人类评分的高度相关性，同时提供了完整数据和代码以促进研究。

Abstract: We present TransEvalnia, a prompting-based translation evaluation and ranking
system that uses reasoning in performing its evaluations and ranking. This
system presents fine-grained evaluations based on a subset of the
Multidimensional Quality Metrics (https://themqm.org/), returns an assessment
of which translation it deems the best, and provides numerical scores for the
various dimensions and for the overall translation. We show that TransEvalnia
performs as well as or better than the state-of-the-art MT-Ranker (Moosa et al.
2024) on our own English-Japanese data as well as several language pairs from
various WMT shared tasks. Using Anthropic's Claude-3.5-Sonnet and
Qwen-2.5-72B-Instruct as the evaluation LLMs, we show that the evaluations
returned are deemed highly acceptable to human raters, and that the scores
assigned to the translations by Sonnet, as well as other LLMs, correlate well
with scores assigned by the human raters. We also note the sensitivity of our
system -- as well as MT-Ranker -- to the order in which the translations are
presented, and we propose methods to address this position bias. All data,
including the system's evaluation and reasoning, human assessments, as well as
code is released.

</details>


### [98] [Strategy Adaptation in Large Language Model Werewolf Agents](https://arxiv.org/abs/2507.12732)
*Fuya Nakamori,Yin Jou Huang,Fei Cheng*

Main category: cs.CL

TL;DR: 提出通过根据游戏上下文和玩家角色估计显式选择策略来提升狼人游戏代理性能的方法。


<details>
  <summary>Details</summary>
Motivation: 现有狼人游戏代理无法适应变化的情况，需提出能根据情况切换战略的改进方法。

Method: 开发能够根据游戏上下文和其他玩家态度切换预定义战略的代理。

Result: 通过比较显示战略切换代理和隐式或固定战略代理，验证了所提方法的有效性。

Conclusion: 该方法在适应变化情境方面表现优越，可提升狼人游戏代理性能。

Abstract: This study proposes a method to improve the performance of Werewolf agents by
switching between predefined strategies based on the attitudes of other players
and the context of conversations. While prior works of Werewolf agents using
prompt engineering have employed methods where effective strategies are
implicitly defined, they cannot adapt to changing situations. In this research,
we propose a method that explicitly selects an appropriate strategy based on
the game context and the estimated roles of other players. We compare the
strategy adaptation Werewolf agents with baseline agents using implicit or
fixed strategies and verify the effectiveness of our proposed method.

</details>


### [99] [Logit Arithmetic Elicits Long Reasoning Capabilities Without Training](https://arxiv.org/abs/2507.12759)
*Yunxiang Zhang,Muhammad Khalifa,Lechen Zhang,Xin Liu,Ayoung Lee,Xinliang Frederick Zhang,Farima Fatahi Bayat,Lu Wang*

Main category: cs.CL

TL;DR: 提出了ThinkLogit和ThinkLogit-DPO方法，通过引入更小的模型作为指导者，在推理时无需经过额外训练即可提升大型语言模型的长链式推理能力，并且通过增强的偏好优化方法进一步提高性能。


<details>
  <summary>Details</summary>
Motivation: 探讨如何在不进行额外训练的前提下，从大型语言模型中引发长链推理能力。现有研究主要集中于通过额外训练来解锁长链推理能力，而本文则希望通过更高效的方式实现这一目标。

Method: 提出ThinkLogit方法，通过在解码时利用更小的指导模型引导目标语言模型完成长链推理。此外，还提出ThinkLogit-DPO，通过对正确和错误的推理对进行偏好优化以进一步提升性能。

Result: 实验表明，ThinkLogit和ThinkLogit-DPO方法使数学数据集上的pass@1分别提高了26%和29%，并且ThinkLogit还能将通过强化学习获得的长链推理能力进行迁移，进一步提升模型性能。

Conclusion: 该研究展示了一种在不进行或仅进行极少额外训练的情况下，利用计算高效的方法解锁和增强大型语言模型的长链推理能力，为相关研究提供了新方向。

Abstract: Large reasoning models (LRMs) can do complex reasoning via long
chain-of-thought (CoT) involving cognitive strategies such as backtracking and
self-correction. Recent studies suggest that some models inherently possess
these long reasoning abilities, which may be unlocked via extra training. Our
work first investigates whether we can elicit such behavior without any
training. To this end, we propose a decoding-time approach, ThinkLogit, which
utilizes logits arithmetic (Liu et al., 2024) to tune a target large LM for
long reasoning using a substantially smaller model as guider. We then show that
we can further boost performance by training the guider model with preference
optimization over correct/incorrect reasoning pairs sampled from both the
target and guider model -- a setup we refer to as ThinkLogit-DPO. Our
experiments demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative
improvement in pass@1 by 26% and 29%, respectively, over four mathematical
datasets using the Qwen2.5-32B when guided by R1-Distill-Qwen-1.5B -- a model
21x smaller. Lastly, we show that ThinkLogit can transfer long reasoning skills
acquired through reinforcement learning, improving pass@1 by 13% relative
compared to the Qwen2.5-32B base model. Our work presents a
computationally-efficient method to elicit long reasoning in large models with
minimal or no additional training.

</details>


### [100] [Synergy: End-to-end Concept Model](https://arxiv.org/abs/2507.12769)
*Keli Zheng,Zerong Xie*

Main category: cs.CL

TL;DR: 提出了Synergy，一个通过学习路由机制桥接不同抽象层次的语言模型，作为字节级语言模型表现优越，并展现了无需分词器的可能性。


<details>
  <summary>Details</summary>
Motivation: 旨在通过无需分词器的架构提升语言模型在不同抽象层次的表现能力，从而实现更强大的语言理解和生成能力。

Method: 设计了一个字节级语言模型Synergy，通过学习路由机制完成从低到高抽象层次的表示，并与现有模型进行性能比较。

Result: Synergy在字节token化方面的表现优于现有方法，与Llama3相比展现了相同行规模和数据量下的优势，并在位置编码移除时表现得更好。

Conclusion: Synergy证明了无需分词器的语言模型是可行的，为构建更稳健与灵活的管道奠定了基础。

Abstract: In this paper, we present Synergy, a language model that bridges different
levels of abstraction in an end-to-end fashion through a learned routing
mechanism. Focusing on low-level linguistic abstraction, we trained our model
as a byte-level language model. Our model spontaneously learns to tokenize
bytes, producing fewer concept tokens than Byte-level Byte Pair Encoder (BBPE)
tokenizers while keeping comparable performance. By comparing with Llama3, we
observed an advantage of Synergy under the same model scale and training
dataset size. Further studies show that the middle part (the higher abstraction
part) of our model performs better when positional encodings are removed,
suggesting the emergence of position-independent concepts. These findings
demonstrate the feasibility of tokenizer-free architectures, paving the way for
more robust and flexible pipelines.

</details>


### [101] [Learning Robust Negation Text Representations](https://arxiv.org/abs/2507.12782)
*Thinh Hung Truong,Karin Verspoor,Trevor Cohn,Timothy Baldwin*

Main category: cs.CL

TL;DR: 提出了一种通过从大型语言模型中蒸馏数据以增强文本编码器处理否定语义能力的方法。


<details>
  <summary>Details</summary>
Motivation: 文本编码器在处理文本嵌入中的否定语义方面性能不足，影响众多下游任务。

Method: 通过对来自大型语言模型的多样化否定和模糊模式数据进行蒸馏，采用对比学习方法微调BERT模型。

Result: 显著提升了文本编码器在否定理解方面的表现，同时在通用标准上保持竞争力，并在扩展到LLMs时改善其否定表现。

Conclusion: 研究表明改进否定语义处理能力对于文本编码器和大型语言模型均具有可行性及实际效用。

Abstract: Despite rapid adoption of autoregressive large language models, smaller text
encoders still play an important role in text understanding tasks that require
rich contextualized representations. Negation is an important semantic function
that is still not properly captured by such methods, affecting many downstream
applications relying on text embeddings. We propose a strategy to improve
negation robustness of text encoders, by distilling data from large language
models using diverse patterns of negation and hedging. We adopt a standard
contrastive learning strategy to finetune a strong BERT-based model, and
observe large improvement in negation understanding capabilities while
maintaining competitive performance on general benchmarks. In addition, we also
show that our method can be adapted to LLMs, leading to improved performance on
negation benchmarks.

</details>


### [102] [Large Language Models' Internal Perception of Symbolic Music](https://arxiv.org/abs/2507.12808)
*Andrew Shin,Kunitake Kaneko*

Main category: cs.CL

TL;DR: 本研究探索大型语言模型(LLMs)在符号音乐领域的潜力，通过文本提示生成MIDI数据并进行测试。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs如何表征音乐概念，以了解其在符号音乐建模中的潜能。

Method: 利用文本提示生成MIDI数据并训练神经网络进行分类与生成分析，比较其与已知模型的表现。

Result: 结果表明LLMs能从文本中推导音乐结构与时间关系，但受限于缺乏明确的音乐上下文。

Conclusion: LLMs对符号音乐具有生成能力，但需正视其局限性，为未来改进提供线索。

Abstract: Large language models (LLMs) excel at modeling relationships between strings
in natural language and have shown promise in extending to other symbolic
domains like coding or mathematics. However, the extent to which they
implicitly model symbolic music remains underexplored. This paper investigates
how LLMs represent musical concepts by generating symbolic music data from
textual prompts describing combinations of genres and styles, and evaluating
their utility through recognition and generation tasks. We produce a dataset of
LLM-generated MIDI files without relying on explicit musical training. We then
train neural networks entirely on this LLM-generated MIDI dataset and perform
genre and style classification as well as melody completion, benchmarking their
performance against established models. Our results demonstrate that LLMs can
infer rudimentary musical structures and temporal relationships from text,
highlighting both their potential to implicitly encode musical patterns and
their limitations due to a lack of explicit musical context, shedding light on
their generative capabilities for symbolic music.

</details>


### [103] [Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?](https://arxiv.org/abs/2507.12838)
*Xi Ai,Mahardika Krisna Ihsani,Min-Yen Kan*

Main category: cs.CL

TL;DR: 本文关注跨语言一致性，探讨了多语言模型在事实知识上的一致性表现，并解析了影响因素与改进方法。


<details>
  <summary>Details</summary>
Motivation: 研究跨语言一致性对于掌握多语言知识转移和保持模型事实性至关重要，同时还可以提升语言模型表现的公平性。

Method: 通过研究混合语言的共参照声明，评估跨语言知识一致性，并使用可解释性方法分析模型在跨语言背景下的行为，发现多语言模型的一致性受语言家族、语言因素和特定层瓶颈的影响。

Result: 尽管知识在许多情况下无法展示出良好的跨语言一致性，但代码切换训练和跨语言单词对齐目标表现出了提升跨语言一致性效果的潜力。

Conclusion: 代码切换训练和跨语言对齐监管对提升多语言性能和一致性具有重要意义，应用于跨语言一致性改进。

Abstract: Cross-lingual consistency should be considered to assess cross-lingual
transferability, maintain the factuality of the model knowledge across
languages, and preserve the parity of language model performance. We are thus
interested in analyzing, evaluating, and interpreting cross-lingual consistency
for factual knowledge. We examine code-mixed coreferential statements conveyed
identical knowledge across languages to study cross-lingual knowledge
consistency. We use some interpretability approaches to analyze the behavior of
a model in cross-lingual contexts, discovering that multilingual models show
different levels of consistency, subject to language families, linguistic
factors, and a bottleneck in cross-lingual consistency on a particular layer.
In addition, we evaluate common strategies aimed at improving multilingual
performance to observe whether these strategies can improve knowledge
consistency at the same time. While knowledge is not cross-lingual consistency
in many cases, code-switching training and cross-lingual word alignment
objectives show the most promising results, emphasizing the noteworthiness of
cross-lingual alignment supervision and code-switching training for both
multilingual performance and cross-lingual consistency enhancement.

</details>


### [104] [Making Language Model a Hierarchical Classifier and Generator](https://arxiv.org/abs/2507.12930)
*Yihong Wang,Zhonglin Jiang,Ningyuan Xi,Yue Zhao,Qingqing Gu,Xiyuan Chen,Hao Wu,Sheng Xu,Hange Zhou,Yong Chen,Luo Ji*

Main category: cs.CL

TL;DR: 本文提出借鉴人类的层次化思维能力，构建层次化解码器架构，使不同层同时解码文本，并通过实验验证其在多个任务中的效果。


<details>
  <summary>Details</summary>
Motivation: 受到人类层次化思维能力的启发，研究者提出探索一种层次化解码器架构并验证其性能。

Method: 选择一个预训练语言模型，将其最后一层的解码头复制到一些中间层并进行微调，以适应层次化解码需求。

Result: 这些中间层可以适应为有意义的文本生成，所提出的层次化解码器在多种任务（如层次文本分类、分类指导生成、层次化文本生成）上达到了最新的性能表现。

Conclusion: 本文的研究表明有可能从头预训练一个通用的层次化推理模型。

Abstract: Decoder-only language models, such as GPT and LLaMA, generally decode on the
last layer. Motivated by human's hierarchical thinking capability, we propose
that a hierarchical decoder architecture could be built with different layers
decoding texts simultaneously. Due to limited time and computationally
resources, we choose to adapt a pretrained language model into this form of
hierarchical decoder. Language heads of the last layer are copied to different
selected intermediate layers, and fine-tuned with different task inputs. By
thorough experiments, we validate that these selective intermediate layers
could be adapted to speak meaningful and reasonable contents, and this paradigm
of hierarchical decoder can obtain state-of-the-art performances on multiple
tasks such as hierarchical text classification, classification-guided
generation, and hierarchical text generation. This study suggests the
possibility of a generalized hierarchical reasoner, pretraining from scratch.

</details>


### [105] [MRT at IberLEF-2025 PRESTA Task: Maximizing Recovery from Tables with Multiple Steps](https://arxiv.org/abs/2507.12981)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Héctor Cerezo-Costas,Pedro Alonso Doval,Jorge Alcalde Vesteiro*

Main category: cs.CL

TL;DR: 本文提出了一种通过利用大型语言模型（LLMs）进行Python代码生成来回答西班牙语表格相关问题的方法。


<details>
  <summary>Details</summary>
Motivation: 解决IberLEF 2025 PRESTA任务中如何高效准确地从表格中提取和处理信息并给出答案的挑战。

Method: 通过一系列步骤（包括表格内容分析、列选择、生成自然语言指令、翻译为Python代码、运行代码及错误处理），使用开源的LLMs与优化提示实现答案生成。

Result: 该方法在任务中达到了85%的准确率。

Conclusion: 使用基于LLMs的Python代码生成方法能够有效回答表格相关问题，结果精确且流程优化，可用于相关任务领域。

Abstract: This paper presents our approach for the IberLEF 2025 Task PRESTA: Preguntas
y Respuestas sobre Tablas en Espa\~nol (Questions and Answers about Tables in
Spanish). Our solution obtains answers to the questions by implementing Python
code generation with LLMs that is used to filter and process the table. This
solution evolves from the MRT implementation for the Semeval 2025 related task.
The process consists of multiple steps: analyzing and understanding the content
of the table, selecting the useful columns, generating instructions in natural
language, translating these instructions to code, running it, and handling
potential errors or exceptions. These steps use open-source LLMs and
fine-grained optimized prompts for each step. With this approach, we achieved
an accuracy score of 85\% in the task.

</details>


### [106] [Formalizing Attack Scenario Description: A Proposed Model](https://arxiv.org/abs/2507.13076)
*Quentin Goux,Nadira Lammari*

Main category: cs.CL

TL;DR: 该论文提出并描述了一种基于UML类模型的攻击场景正式化模型，并探讨了其在网络安全分析与训练中的应用。


<details>
  <summary>Details</summary>
Motivation: 应对多变的威胁环境，组织需要自动化的网络安全解决方案，而实现自动化需要正式化输入数据。

Method: 使用统一建模语言（UML）创建了一个正式模型，描述了攻击的上下文及其场景。

Result: 模型可用于攻击分析流程，并支持网络安全训练中攻击脚本的自动生成。

Conclusion: 该模型为网络安全的自动化分析和培训提供了基础，可显著提升效率和实用性。

Abstract: Organizations face an ever-changing threat landscape. They must continuously
dedicate significant efforts to protect their assets, making their adoption of
increased cybersecurity automation inevitable. However, process automation
requires formalization of input data. Through this paper, we address this need
for processes that use attack scenarios as input. Among these processes, one
can mention both the generation of scripts for attack simulation and training
purposes, as well as the analysis of attacks. Therefore, the paper's main
research contribution is a novel formal model that encompasses the attack's
context description and its scenario. It is abstracted using UML class model.
Once the description of our model done, we will show how it could serve an
upstream attack analysis process. We will show also its use for an automatic
generation of attack scripts in the context of cybersecurity training. These
two uses cases constitute the second contribution of this present research
work.

</details>


### [107] [SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts](https://arxiv.org/abs/2507.13105)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

TL;DR: 本文介绍SemCSE，这是一种无监督学习科学文本语义嵌入的新方法，通过对科学摘要生成的总结进行对比学习以实现更好的语义捕捉性能。


<details>
  <summary>Details</summary>
Motivation: 通过改进科学文本语义嵌入方法，克服传统基于引文方法无法真正反映语义相似度的局限性。

Method: 利用LLM生成的科学摘要，通过对比学习使语义相关的摘要在嵌入空间中更接近，从而捕获文本的真正语义内容。

Result: 提出了一个新基准来评估模型捕获科学文本语义内容的能力，并在SciRepEval基准测试中实现了同等规模模型的最先进性能。

Conclusion: SemCSE通过专注于语义的训练方法改进了科学文本语义嵌入的质量，展示了出色的语义分离效果。

Abstract: We introduce SemCSE, an unsupervised method for learning semantic embeddings
of scientific texts. Building on recent advances in contrastive learning for
text embeddings, our approach leverages LLM-generated summaries of scientific
abstracts to train a model that positions semantically related summaries closer
together in the embedding space. This resulting objective ensures that the
model captures the true semantic content of a text, in contrast to traditional
citation-based approaches that do not necessarily reflect semantic similarity.
To validate this, we propose a novel benchmark designed to assess a model's
ability to understand and encode the semantic content of scientific texts,
demonstrating that our method enforces a stronger semantic separation within
the embedding space. Additionally, we evaluate SemCSE on the comprehensive
SciRepEval benchmark for scientific text embeddings, where it achieves
state-of-the-art performance among models of its size, thus highlighting the
benefits of a semantically focused training approach.

</details>


### [108] [A Computational Framework to Identify Self-Aspects in Text](https://arxiv.org/abs/2507.13115)
*Jaya Caporusso,Matthew Purver,Senja Pollak*

Main category: cs.CL

TL;DR: 该论文计划开发一个计算框架，以从文本中识别自我方面，同时提供自我方面本体与标准数据集，并研究多种模型的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管自我的概念在认知科学和现象学领域已被广泛研究，但在自然语言处理中仍未得到充分探索，特别是在与心理健康相关的现象中其重要性凸显。

Method: 提出一种包含自我方面本体和标准标注数据集的框架，利用判别模型、生成式大语言模型与基于嵌入的检索方法，基于四项标准（可解释性、一致性、准确性、计算效率）评估其性能。

Result: 预计最高性能模型将在心理健康和经验现象学的案例研究中得以应用。

Conclusion: 该研究通过结合语义建模与工程方法，展示了NLP在心理学和哲学交叉领域的潜力，同时为未来研究铺平道路。

Abstract: This Ph.D. proposal introduces a plan to develop a computational framework to
identify Self-aspects in text. The Self is a multifaceted construct and it is
reflected in language. While it is described across disciplines like cognitive
science and phenomenology, it remains underexplored in natural language
processing (NLP). Many of the aspects of the Self align with psychological and
other well-researched phenomena (e.g., those related to mental health),
highlighting the need for systematic NLP-based analysis. In line with this, we
plan to introduce an ontology of Self-aspects and a gold-standard annotated
dataset. Using this foundation, we will develop and evaluate conventional
discriminative models, generative large language models, and embedding-based
retrieval approaches against four main criteria: interpretability, ground-truth
adherence, accuracy, and computational efficiency. Top-performing models will
be applied in case studies in mental health and empirical phenomenology.

</details>


### [109] [Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation](https://arxiv.org/abs/2507.13138)
*Hadi Mohammadi,Tina Shahedi,Pablo Mosteiro,Massimo Poesio,Ayoub Bagheri,Anastasia Giachanou*

Main category: cs.CL

TL;DR: 本研究探讨了注解人员的人口统计特征对标注决策的影响，但发现文本内容才是主要影响因素；此外，利用生成式AI进行标注时，利用人口特征指导的人格提示效果有限甚至有害。


<details>
  <summary>Details</summary>
Motivation: 探索在人口统计偏差的背景下，性别歧视检测任务中注解决定的公平和可靠性。

Method: 采用广义线性混合模型量化人口统计特征和文本内容对标注决策的影响，并通过生成式AI和可解释性AI技术进行实验研究。

Result: 人口统计特征只解释了较少的（8%）变异，而文本内容是主要驱动因素；生成式AI的简单人格提示无法提高模型的性能。

Conclusion: 关注基于内容的解释以及稳健的注解协议比模拟人口特征能更可靠地实现公平性。

Abstract: Understanding the sources of variability in annotations is crucial for
developing fair NLP systems, especially for tasks like sexism detection where
demographic bias is a concern. This study investigates the extent to which
annotator demographic features influence labeling decisions compared to text
content. Using a Generalized Linear Mixed Model, we quantify this inf luence,
finding that while statistically present, demographic factors account for a
minor fraction ( 8%) of the observed variance, with tweet content being the
dominant factor. We then assess the reliability of Generative AI (GenAI) models
as annotators, specifically evaluating if guiding them with demographic
personas improves alignment with human judgments. Our results indicate that
simplistic persona prompting often fails to enhance, and sometimes degrades,
performance compared to baseline models. Furthermore, explainable AI (XAI)
techniques reveal that model predictions rely heavily on content-specific
tokens related to sexism, rather than correlates of demographic
characteristics. We argue that focusing on content-driven explanations and
robust annotation protocols offers a more reliable path towards fairness than
potentially persona simulation.

</details>


### [110] [Feature-based analysis of oral narratives from Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13164)
*Emma Sharratt,Annelien Smith,Retief Louw,Daleen Klop,Febe de Wet,Herman Kamper*

Main category: cs.CL

TL;DR: 本研究探讨了口头叙述技能与后期阅读能力之间的关系，利用机器学习分析南非两种语言儿童的故事叙述，发现词汇多样性和语句长度是发展指标，而语言特定的动词和助词与叙述能力相关。


<details>
  <summary>Details</summary>
Motivation: 探讨口头叙述技能能否成为早期识别儿童学习障碍的有效工具，尤其是在多语言环境下。

Method: 通过对四、五岁讲南非语言（Afrikaans和isiXhosa）的儿童叙述故事录音进行机器学习分析，观察跨语言的语法和词汇特征。

Result: 研究发现，词汇多样性（独特单词数量）和吐露长短等长度指标是典型发展的标志。而不同语言间与目标导向叙事相关的动词和助词使用，能够有效预测是否需要干预。

Conclusion: 该研究揭示了既有语言特定也有共享的叙述能力预测因子，对多语言环境下的早期评估具有重要意义。

Abstract: Oral narrative skills are strong predictors of later literacy development.
This study examines the features of oral narratives from children who were
identified by experts as requiring intervention. Using simple machine learning
methods, we analyse recorded stories from four- and five-year-old Afrikaans-
and isiXhosa-speaking children. Consistent with prior research, we identify
lexical diversity (unique words) and length-based features (mean utterance
length) as indicators of typical development, but features like articulation
rate prove less informative. Despite cross-linguistic variation in
part-of-speech patterns, the use of specific verbs and auxiliaries associated
with goal-directed storytelling is correlated with a reduced likelihood of
requiring intervention. Our analysis of two linguistically distinct languages
reveals both language-specific and shared predictors of narrative proficiency,
with implications for early assessment in multilingual contexts.

</details>


### [111] [GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems](https://arxiv.org/abs/2507.13190)
*Jisoo Lee,Raeyoung Chang,Dongwook Kwon,Harmanpreet Singh,Nikhil Verma*

Main category: cs.CL

TL;DR: 提出了GEMMAS框架，用于分析基于语言模型的多智能体系统的协作过程，并指出仅基于结果的评价指标对协作效率不足以全面反映。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法过于关注最终输出正确性，未能充分权衡通信效率和协作质量对系统性能的影响。

Method: 通过将智能体交互建模为有向无环图，提出GEMMAS框架，并设计信息多样性得分（IDS）和无效路径比率（UPR）两种过程级指标来评估协作质量。

Result: 通过五个基准测试验证了GEMMAS的有效性，特别是在GSM8K任务中表现的系统在准确率仅相差2.1%的情况下，IDS和UPR的差异分别高达12.8%和80%。

Conclusion: 仅注重产出结果的指标不足以全面评估多智能体系统性能，过程级诊断对设计更具解释性和高效的协作AI系统至关重要。

Abstract: Multi-agent systems built on language models have shown strong performance on
collaborative reasoning tasks. However, existing evaluations focus only on the
correctness of the final output, overlooking how inefficient communication and
poor coordination contribute to redundant reasoning and higher computational
costs. We introduce GEMMAS, a graph-based evaluation framework that analyzes
the internal collaboration process by modeling agent interactions as a directed
acyclic graph. To capture collaboration quality, we propose two process-level
metrics: Information Diversity Score (IDS) to measure semantic variation in
inter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant
reasoning paths. We evaluate GEMMAS across five benchmarks and highlight
results on GSM8K, where systems with only a 2.1% difference in accuracy differ
by 12.8% in IDS and 80% in UPR, revealing substantial variation in internal
collaboration. These findings demonstrate that outcome-only metrics are
insufficient for evaluating multi-agent performance and highlight the
importance of process-level diagnostics in designing more interpretable and
resource-efficient collaborative AI systems.

</details>


### [112] [Automatically assessing oral narratives of Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13205)
*R. Louw,E. Sharratt,F. de Wet,C. Jacobs,A. Smith,H. Kamper*

Main category: cs.CL

TL;DR: 提出了一种系统以自动评估学前儿童的叙述及理解能力，使用语音识别和机器学习，LLM效果优于线性模型，接近人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 解决教师在大型学前班中难以准确识别需要干预学生的问题，提升个性化支持能力。

Method: 结合语音识别和机器学习，通过LLM或线性模型分析儿童叙述的口语成绩，预测其叙述及理解能力得分。

Result: LLM模型在大多数情况下优于线性模型，并能有效标记需干预儿童，其效果接近人类专家。

Conclusion: 该系统为课堂中自动化口语评估奠定了基础，有助于教师关注个性化支持，提升学习效果。

Abstract: Developing narrative and comprehension skills in early childhood is critical
for later literacy. However, teachers in large preschool classrooms struggle to
accurately identify students who require intervention. We present a system for
automatically assessing oral narratives of preschool children in Afrikaans and
isiXhosa. The system uses automatic speech recognition followed by a machine
learning scoring model to predict narrative and comprehension scores. For
scoring predicted transcripts, we compare a linear model to a large language
model (LLM). The LLM-based system outperforms the linear model in most cases,
but the linear system is competitive despite its simplicity. The LLM-based
system is comparable to a human expert in flagging children who require
intervention. We lay the foundation for automatic oral assessments in
classrooms, giving teachers extra capacity to focus on personalised support for
children's learning.

</details>


### [113] [Enhancing Cross-task Transfer of Large Language Models via Activation Steering](https://arxiv.org/abs/2507.13236)
*Xinyu Tang,Zhihao Lv,Xiaoxue Cheng,Junyi Li,Wayne Xin Zhao,Zujie Wen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种名为CAST的新框架，通过调整大型语言模型(LLMs)的内部激活状态实现跨任务知识迁移，而无需参数更新或输入扩展。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然在提示学习中表现良好，但在数据稀缺情况下处理未知任务时表现欠佳。因此，研究无需调整参数即可进行可靠、可扩展、高效的跨任务知识迁移方法显得尤为重要。

Method: 通过分析语言模型潜在空间中的激活模式，提出CAST框架，利用高资源任务中选择的样本及其对比表示增强的激活，来调整模型用于低资源任务的激活状态，从而实现知识迁移。

Result: 通过跨域和跨语言的实验验证，CAST方法不仅优于现有基线方法，同时表现出更好的可扩展性与更低的计算成本。

Conclusion: 研究表明，不修改参数的情况下，通过操控模型激活状态可以实现高效可靠的跨任务知识迁移，为低资源任务的处理提供了新思路。

Abstract: Large language models (LLMs) have shown impressive abilities in leveraging
pretrained knowledge through prompting, but they often struggle with unseen
tasks, particularly in data-scarce scenarios. While cross-task in-context
learning offers a direct solution for transferring knowledge across tasks, it
still faces critical challenges in terms of robustness, scalability, and
efficiency. In this paper, we investigate whether cross-task transfer can be
achieved via latent space steering without parameter updates or input
expansion. Through an analysis of activation patterns in the latent space of
LLMs, we observe that the enhanced activations induced by in-context examples
have consistent patterns across different tasks. Inspired by these findings, we
propose CAST, a novel Cross-task Activation Steering Transfer framework that
enables effective transfer by manipulating the model's internal activation
states. Our approach first selects influential and diverse samples from
high-resource tasks, then utilizes their contrastive representation-enhanced
activations to adapt LLMs to low-resource tasks. Extensive experiments across
both cross-domain and cross-lingual transfer settings show that our method
outperforms competitive baselines and demonstrates superior scalability and
lower computational costs.

</details>


### [114] [HATS: Hindi Analogy Test Set for Evaluating Reasoning in Large Language Models](https://arxiv.org/abs/2507.13238)
*Ashray Gupta,Rohan Joseph,Sunny Rai*

Main category: cs.CL

TL;DR: 这篇论文引入了一个新的印地语类比测试集（HATS），用于评估多语言大语言模型（LLMs）的推理能力。


<details>
  <summary>Details</summary>
Motivation: 目前LLMs的推理能力评估主要集中在英语范畴，对于印地语等印度语言的研究较少，因此有必要开发衡量这些模型在非英语语言中的性能的测试集。

Method: 提出了一个包含405道多项选择题的印地语类比测试集，基于印度政府考试的问题，同时采用了多种提示策略测试多语言LLMs的性能，并提出结合类比推理认知理论的Chain of Thought方法来提升模型表现。

Result: 发现无论提示策略如何，模型在使用英语提示时表现最佳。此外，新提出的方法显著提高了模型在印地语类比问题上的性能表现。

Conclusion: HATS测试集弥补了用于评估LLMs在印地语推理能力上的资源缺失，并提供了一个分析这些模型跨语言推理能力的工具。

Abstract: Analogies test a model's ability to infer implicit relationships between
concepts, making them a key benchmark for evaluating reasoning capabilities.
While large language models (LLMs) are widely evaluated for reasoning in
English, their abilities in Indic languages remain understudied, limiting our
understanding of whether these models generalize across languages. To address
this gap, we introduce a new Hindi Analogy Test Set (HATS), comprising 405
multiple-choice questions sourced from Indian government exams. We benchmark
state-of-the-art multilingual LLMs using various prompting strategies and
introduce a grounded Chain of Thought approach that leverages cognitive
theories of analogical reasoning. This approach improves model performance on
Hindi analogy questions. Our experiments show that models perform best with
English prompts, irrespective of the prompting strategy. Our test set addresses
the lack of a critical resource to evaluate LLM reasoning capabilities in
Hindi.

</details>


### [115] [Automating Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2507.13255)
*Lyucheng Wu,Mengru Wang,Ziwen Xu,Tri Cao,Nay Oo,Bryan Hooi,Shumin Deng*

Main category: cs.CL

TL;DR: 本文提出了AutoSteer，一种用于多模态大语言模型（MLLMs）的实时干预技术，无需对模型进行微调即可提高推理过程中的安全性。


<details>
  <summary>Details</summary>
Motivation: 随着MLLMs在跨模态推理方面的能力增强，也引发了面对对抗性输入时的安全问题。需要一种方式在保证模型能力的同时提升其安全性。

Method: AutoSteer由三个主要组件构成：（1）一种创新的安全意识评分（SAS），自动识别模型内部层的安全相关特征。（2）一个自适应安全探测器，用于估计中间表示的有害输出可能性。（3）一个轻量化的拒绝模块，检测到安全风险时进行选择性干涉。

Result: 在多个安全基准的实验中，AutoSteer显著降低了文本、视觉和跨模态威胁的攻击成功率（ASR），同时保持模型的整体能力。

Conclusion: AutoSteer提供了一种实用、可解释且有效的框架，用于多模态AI系统的更安全部署。

Abstract: Recent progress in Multimodal Large Language Models (MLLMs) has unlocked
powerful cross-modal reasoning abilities, but also raised new safety concerns,
particularly when faced with adversarial multimodal inputs. To improve the
safety of MLLMs during inference, we introduce a modular and adaptive
inference-time intervention technology, AutoSteer, without requiring any
fine-tuning of the underlying model. AutoSteer incorporates three core
components: (1) a novel Safety Awareness Score (SAS) that automatically
identifies the most safety-relevant distinctions among the model's internal
layers; (2) an adaptive safety prober trained to estimate the likelihood of
toxic outputs from intermediate representations; and (3) a lightweight Refusal
Head that selectively intervenes to modulate generation when safety risks are
detected. Experiments on LLaVA-OV and Chameleon across diverse safety-critical
benchmarks demonstrate that AutoSteer significantly reduces the Attack Success
Rate (ASR) for textual, visual, and cross-modal threats, while maintaining
general abilities. These findings position AutoSteer as a practical,
interpretable, and effective framework for safer deployment of multimodal AI
systems.

</details>


### [116] [QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation](https://arxiv.org/abs/2507.13266)
*Jiazheng Li,Hong Lu,Kaiyue Wen,Zaiwen Yang,Jiaxuan Gao,Hongzhou Lin,Yi Wu,Jingzhao Zhang*

Main category: cs.CL

TL;DR: 本研究提出通过引入部分解决方案的“问题增强”方法（QuestA），提升了数学推理任务中多步推理的效果，并在基准测试中实现了新的性能突破。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现RL在解决困难的多步推理问题上表现有限，因此需要一种能减少问题难度并提供更丰富学习信号的策略。

Method: 通过引入称为问题增强（QuestA）的策略，在RL训练中为模型提供部分解决方案，从而减少问题难度并改进训练信号。

Result: 在数学推理任务的基准测试中，QuestA显著提升了LLM的表现，例如在AIME24上达到了67.1%、AIME25上达到了59.5%和HMMT25上达到了35.5%。

Conclusion: QuestA通过提升样本效率，为通过RL扩展推理能力提供了切实可行且通用的路径，证明了其在复杂数学推理任务中的有效性。

Abstract: Reinforcement learning (RL) has become a key component in training large
language reasoning models (LLMs). However, recent studies questions its
effectiveness in improving multi-step reasoning-particularly on hard problems.
To address this challenge, we propose a simple yet effective strategy via
Question Augmentation: introduce partial solutions during training to reduce
problem difficulty and provide more informative learning signals. Our method,
QuestA, when applied during RL training on math reasoning tasks, not only
improves pass@1 but also pass@k-particularly on problems where standard RL
struggles to make progress. This enables continual improvement over strong
open-source models such as DeepScaleR and OpenMath Nemotron, further enhancing
their reasoning capabilities. We achieve new state-of-the-art results on math
benchmarks using 1.5B-parameter models: 67.1% (+5.3%) on AIME24, 59.5% (+10.0%)
on AIME25, and 35.5% (+4.0%) on HMMT25. Further, we provide theoretical
explanations that QuestA improves sample efficiency, offering a practical and
generalizable pathway for expanding reasoning capability through RL.

</details>


### [117] [Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management](https://arxiv.org/abs/2507.13275)
*Luis Gasco,Hermenegildo Fabregat,Laura García-Sardiña,Paula Estrella,Daniel Deniz,Alvaro Rodrigo,Rabih Zbib*

Main category: cs.CL

TL;DR: 本文介绍了TalentCLEF 2025，这是首个基于技能和职位智能的评估活动，聚焦于多语种职位匹配和技能预测任务。


<details>
  <summary>Details</summary>
Motivation: 在人力资本管理中，基于语言技术的智能系统逐渐兴起，但该领域缺乏公开数据与公平可靠的模型评估。

Method: 提出TalentCLEF 2025评估活动，包括多语种职位匹配和职位技能预测两项任务，数据源于真实求职信息，经过匿名和人工标注，并涵盖性别偏见评估。

Result: 吸引了76支团队超280次提交，多数系统基于多语种编码器模型并结合对比学习，部分结合语言模型进行数据增强或排序优化，发现训练策略比模型规模影响更大。

Conclusion: TalentCLEF 2025填补了劳动力市场语言技术的公开基准空白，促进了相关技术的公平、稳健与可迁移性发展。

Abstract: Advances in natural language processing and large language models are driving
a major transformation in Human Capital Management, with a growing interest in
building smart systems based on language technologies for talent acquisition,
upskilling strategies, and workforce planning. However, the adoption and
progress of these technologies critically depend on the development of reliable
and fair models, properly evaluated on public data and open benchmarks, which
have so far been unavailable in this domain.
  To address this gap, we present TalentCLEF 2025, the first evaluation
campaign focused on skill and job title intelligence. The lab consists of two
tasks: Task A - Multilingual Job Title Matching, covering English, Spanish,
German, and Chinese; and Task B - Job Title-Based Skill Prediction, in English.
Both corpora were built from real job applications, carefully anonymized, and
manually annotated to reflect the complexity and diversity of real-world labor
market data, including linguistic variability and gender-marked expressions.
  The evaluations included monolingual and cross-lingual scenarios and covered
the evaluation of gender bias.
  TalentCLEF attracted 76 registered teams with more than 280 submissions. Most
systems relied on information retrieval techniques built with multilingual
encoder-based models fine-tuned with contrastive learning, and several of them
incorporated large language models for data augmentation or re-ranking. The
results show that the training strategies have a larger effect than the size of
the model alone. TalentCLEF provides the first public benchmark in this field
and encourages the development of robust, fair, and transferable language
technologies for the labor market.

</details>


### [118] [Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis](https://arxiv.org/abs/2507.13285)
*Wang Xi,Quan Shi,Tian Yu,Yujie Peng,Jiayi Sun,Mengxing Ren,Zenghui Ding,Ningguang Yao*

Main category: cs.CL

TL;DR: 论文提出RCPS框架，通过深度结构化叙事规划、自适应布局生成和迭代优化循环三个核心部分，有效生成高质量多媒体演示文稿。同时，提出PREVAL评估框架，检测演示的内容、连贯性及设计质量。实验表明，RCPS框架超越传统基线方法，PREVAL评估与人类判断高度相关。


<details>
  <summary>Details</summary>
Motivation: 现有多媒体演示生成方法存在逻辑不一致、布局次优的问题，无法达到专业标准。本论文旨在解决这些挑战，生成高质量、专业化的演示文稿。

Method: 提出RCPS框架，包括深度结构化叙事规划、自适应布局生成和迭代优化循环。同时，设计PREVAL框架用于基于偏好的多维评估模型。

Result: 实验结果显示，RCPS框架在质量维度上全面优于基线方法，生成的演示文稿接近专业标准；PREVAL评估框架与人类评审一致，具备可靠性。

Conclusion: RCPS框架能显著提升多媒体演示生成质量，PREVAL作为自动化评估工具，显示出较高的可靠性和效能，为生成领域提供了新思路与技术支持。

Abstract: Automated generation of high-quality media presentations is challenging,
requiring robust content extraction, narrative planning, visual design, and
overall quality optimization. Existing methods often produce presentations with
logical inconsistencies and suboptimal layouts, thereby struggling to meet
professional standards. To address these challenges, we introduce RCPS
(Reflective Coherent Presentation Synthesis), a novel framework integrating
three key components: (1) Deep Structured Narrative Planning; (2) Adaptive
Layout Generation; (3) an Iterative Optimization Loop. Additionally, we propose
PREVAL, a preference-based evaluation framework employing rationale-enhanced
multi-dimensional models to assess presentation quality across Content,
Coherence, and Design. Experimental results demonstrate that RCPS significantly
outperforms baseline methods across all quality dimensions, producing
presentations that closely approximate human expert standards. PREVAL shows
strong correlation with human judgments, validating it as a reliable automated
tool for assessing presentation quality.

</details>


### [119] [AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research](https://arxiv.org/abs/2507.13300)
*Yilun Zhao,Weiyuan Chen,Zhijian Xu,Manasi Patwardhan,Yixin Liu,Chengye Wang,Lovekesh Vig,Arman Cohan*

Main category: cs.CL

TL;DR: 本文提出了AbGen，一个专为评估大模型(LLMs)在科学研究中设计消融研究能力的基准工具，内容包括807篇NLP论文的1500个专家标注示例，并开发了一个名为AbGen-Eval的元评估工具来进一步验证现有自动化评估方法的可靠性。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在科学研究中设计消融实验能力的有效方法尚未建立；当前的自动化评估方法在复杂科学任务上不可靠。

Method: 提出AbGen基准工具，包含807篇NLP论文中的1500个专家标注示例，并开发AbGen-Eval元评估工具评估现有自动化方法的可靠性。

Result: LLMs在设计消融研究能力上与人类专家的表现存在显著差距；发现当前自动化评估方法无法可靠地衡量这种差距。

Conclusion: AbGen和AbGen-Eval为评估和开发更有效的复杂科学任务评估系统提供了重要帮助，展示了现有LLMs性能的局限性。

Abstract: We introduce AbGen, the first benchmark designed to evaluate the capabilities
of LLMs in designing ablation studies for scientific research. AbGen consists
of 1,500 expert-annotated examples derived from 807 NLP papers. In this
benchmark, LLMs are tasked with generating detailed ablation study designs for
a specified module or process based on the given research context. Our
evaluation of leading LLMs, such as DeepSeek-R1-0528 and o4-mini, highlights a
significant performance gap between these models and human experts in terms of
the importance, faithfulness, and soundness of the ablation study designs.
Moreover, we demonstrate that current automated evaluation methods are not
reliable for our task, as they show a significant discrepancy when compared to
human assessment. To better investigate this, we develop AbGen-Eval, a
meta-evaluation benchmark designed to assess the reliability of commonly used
automated evaluation systems in measuring LLM performance on our task. We
investigate various LLM-as-Judge systems on AbGen-Eval, providing insights for
future research on developing more effective and reliable LLM-based evaluation
systems for complex scientific tasks.

</details>


### [120] [HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals](https://arxiv.org/abs/2507.13318)
*Guimin Hu,Daniel Hershcovich,Hasti Seifi*

Main category: cs.CL

TL;DR: 本文研究了通过文本描述与触觉振动信号匹配的问题，并开发了全球首个全人类注释的触觉-文本数据集HapticCap，以及相关检索任务。


<details>
  <summary>Details</summary>
Motivation: 触觉信号能够增强信息传递和现实感，但设计出能与用户产生共鸣的信号具有挑战性，主要问题包括缺乏规模化的触觉文本数据集及现有任务和模型的局限性。

Method: 提出了HapticCap数据集，包含92,070个触觉-文本对，并开发了基于用户描述分类的监督对比学习框架，用以完成触觉-文本检索任务。

Result: 结合语言模型T5和音频模型AST在触觉-文本检索任务中表现最佳，特别是在针对每种描述类别单独训练时。

Conclusion: 本文推动了触觉信号与文本描述的研究，为未来触觉信号生成与理解提供了重要的数据和方法支持。

Abstract: Haptic signals, from smartphone vibrations to virtual reality touch feedback,
can effectively convey information and enhance realism, but designing signals
that resonate meaningfully with users is challenging. To facilitate this, we
introduce a multimodal dataset and task, of matching user descriptions to
vibration haptic signals, and highlight two primary challenges: (1) lack of
large haptic vibration datasets annotated with textual descriptions as
collecting haptic descriptions is time-consuming, and (2) limited capability of
existing tasks and models to describe vibration signals in text. To advance
this area, we create HapticCap, the first fully human-annotated
haptic-captioned dataset, containing 92,070 haptic-text pairs for user
descriptions of sensory, emotional, and associative attributes of vibrations.
Based on HapticCap, we propose the haptic-caption retrieval task and present
the results of this task from a supervised contrastive learning framework that
brings together text representations within specific categories and vibrations.
Overall, the combination of language model T5 and audio model AST yields the
best performance in the haptic-caption retrieval task, especially when
separately trained for each description category.

</details>


### [121] [Social and Political Framing in Search Engine Results](https://arxiv.org/abs/2507.13325)
*Amrit Poudel,Tim Weninger*

Main category: cs.CL

TL;DR: 本研究探讨搜索引擎如何通过偏见的内容优先级以及用户的意识形态驱动查询，影响搜索结果并扩大叙事的极化。


<details>
  <summary>Details</summary>
Motivation: 探索搜索引擎的运行机制及其与用户查询在塑造信息偏见中的作用。

Method: 利用关于政治和社会话题的数据集，分析主要搜索引擎的输出结果，调查内容优先级及用户查询的影响。

Result: 发现搜索引擎不仅在内容排序上存在偏见，而且用户带有意识形态的查询会加剧这些偏见，不同搜索引擎在内容来源优先级上也存在显著差异。

Conclusion: 搜索引擎不仅可能强化意识形态分歧，还会助长信息极化的更广泛问题，对公众观念形成有重大影响。

Abstract: Search engines play a crucial role in shaping public discourse by influencing
how information is accessed and framed. While prior research has extensively
examined various dimensions of search bias -- such as content prioritization,
indexical bias, political polarization, and sources of bias -- an important
question remains underexplored: how do search engines and
ideologically-motivated user queries contribute to bias in search results. This
study analyzes the outputs of major search engines using a dataset of political
and social topics. The findings reveal that search engines not only prioritize
content in ways that reflect underlying biases but also that
ideologically-driven user queries exacerbate these biases, resulting in the
amplification of specific narratives. Moreover, significant differences were
observed across search engines in terms of the sources they prioritize. These
results suggest that search engines may play a pivotal role in shaping public
perceptions by reinforcing ideological divides, thereby contributing to the
broader issue of information polarization.

</details>


### [122] [Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It](https://arxiv.org/abs/2507.13328)
*Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim*

Main category: cs.CL

TL;DR: 研究VL训练是否对语言模型（LM）的语言表示有显著影响，发现尽管VL训练不会显著改变语言模型的分类知识，但可提升其在具体任务中的应用能力。


<details>
  <summary>Details</summary>
Motivation: 探讨视觉-语言训练是否能显著改变语言模型的语言表示，尤其是其词汇-概念知识的分类组织。

Method: 通过比较单纯文本的语言模型（LMs）和视觉-语言训练模型（VLMs），并利用问答任务及多种行为和表征分析方法，研究模型间的区别。

Result: VLMs在需要分类理解的文本问答任务中表现优于LMs，但两者在分类知识本身上没有显著差异，主要区别在于它们对任务所涉分类概念的表示方式。

Conclusion: VL训练不会本质上改变语言模型的分类知识，但能提升其利用这些知识完成特定任务的能力，即使任务仅为语言表现形式。

Abstract: Does vision-and-language (VL) training change the linguistic representations
of language models in meaningful ways? Most results in the literature have
shown inconsistent or marginal differences, both behaviorally and
representationally. In this work, we start from the hypothesis that the domain
in which VL training could have a significant effect is lexical-conceptual
knowledge, in particular its taxonomic organization. Through comparing minimal
pairs of text-only LMs and their VL-trained counterparts, we first show that
the VL models often outperform their text-only counterparts on a text-only
question-answering task that requires taxonomic understanding of concepts
mentioned in the questions. Using an array of targeted behavioral and
representational analyses, we show that the LMs and VLMs do not differ
significantly in terms of their taxonomic knowledge itself, but they differ in
how they represent questions that contain concepts in a taxonomic relation vs.
a non-taxonomic relation. This implies that the taxonomic knowledge itself does
not change substantially through additional VL training, but VL training does
improve the deployment of this knowledge in the context of a specific task,
even when the presentation of the task is purely linguistic.

</details>


### [123] [The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner](https://arxiv.org/abs/2507.13332)
*Zhouqi Hua,Wenwei Zhang,Chengqi Lyu,Yuzhe Gu,Songyang Gao,Kuikun Liu,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出了Turing MAchine Imitation Learning (TAIL)方法，通过模仿图灵机执行过程来提升大型语言模型的长度泛化能力，并在多个推理任务上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在处理比训练阶段更长序列时表现较差，现有方法局限于具体任务，难以通用，需要一个更广义的解决方案来增强模型的推理能力。

Method: 提出了TAIL方法，以图灵机执行过程为蓝本，通过合成的链式思维数据扩展推理步骤，并引入显性记忆机制以减轻动态和远程数据访问的难度。实验设计了一套覆盖多个算法和任务的合成数据集，用以验证方法的通用性和有效性。

Result: 使用TAIL方法的大型语言模型在合成数据上的长度泛化能力和性能取得明显改善，超越现有方法与DeepSeek-R1。

Conclusion: 该研究证明了图灵机的关键概念在增强长度泛化方面的作用，提供了一条通过合成数据提升大型语言模型的推理能力的可能方向。

Abstract: Length generalization, the ability to solve problems of longer sequences than
those observed during training, poses a core challenge of Transformer-based
large language models (LLM). Although existing studies have predominantly
focused on data-driven approaches for arithmetic operations and symbolic
manipulation tasks, these approaches tend to be task-specific with limited
overall performance. To pursue a more general solution, this paper focuses on a
broader case of reasoning problems that are computable, i.e., problems that
algorithms can solve, thus can be solved by the Turing Machine. From this
perspective, this paper proposes Turing MAchine Imitation Learning (TAIL) to
improve the length generalization ability of LLMs. TAIL synthesizes
chain-of-thoughts (CoT) data that imitate the execution process of a Turing
Machine by computer programs, which linearly expands the reasoning steps into
atomic states to alleviate shortcut learning and explicit memory fetch
mechanism to reduce the difficulties of dynamic and long-range data access in
elementary operations. To validate the reliability and universality of TAIL, we
construct a challenging synthetic dataset covering 8 classes of algorithms and
18 tasks. Without bells and whistles, TAIL significantly improves the length
generalization ability as well as the performance of Qwen2.5-7B on various
tasks using only synthetic data, surpassing previous methods and DeepSeek-R1.
The experimental results reveal that the key concepts in the Turing Machine,
instead of the thinking styles, are indispensable for TAIL for length
generalization, through which the model exhibits read-and-write behaviors
consistent with the properties of the Turing Machine in their attention layers.
This work provides a promising direction for future research in the learning of
LLM reasoning from synthetic data.

</details>


### [124] [A Survey of Context Engineering for Large Language Models](https://arxiv.org/abs/2507.13334)
*Lingrui Mei,Jiayu Yao,Yuyao Ge,Yiwei Wang,Baolong Bi,Yujun Cai,Jiazhi Liu,Mingyu Li,Zhong-Zhi Li,Duzhen Zhang,Chenlin Zhou,Jiayi Mao,Tianze Xia,Jiafeng Guo,Shenghua Liu*

Main category: cs.CL

TL;DR: 本文调查了大语言模型（LLMs）推理能力中上下文信息的重要性，提出了“上下文工程”（Context Engineering）的正式框架，并通过分析1300多篇论文提供技术路线图，指出了模型在理解复杂上下文和生成长篇输出之间的差距。


<details>
  <summary>Details</summary>
Motivation: 研究旨在优化 LLMs 的信息处理能力，并通过提出系统性框架填补上下文建模中的技术空白。

Method: 通过构建上下文工程的全面分类法，并分析多个研究领域（如检索增强生成、多代理系统等）的整合方式，深入探讨其应用。

Result: 从1300多篇论文的系统性分析中，总结出目前系统在上下文理解方面已达到高水平，但在生成复杂长篇输出上仍存在显著不足。

Conclusion: 提出统一框架描述上下文工程，为未来提升上下文感知AI模型提供技术路线图，并指出关键研究方向是缩小理解与生成能力的差距。

Abstract: The performance of Large Language Models (LLMs) is fundamentally determined
by the contextual information provided during inference. This survey introduces
Context Engineering, a formal discipline that transcends simple prompt design
to encompass the systematic optimization of information payloads for LLMs. We
present a comprehensive taxonomy decomposing Context Engineering into its
foundational components and the sophisticated implementations that integrate
them into intelligent systems. We first examine the foundational components:
context retrieval and generation, context processing and context management. We
then explore how these components are architecturally integrated to create
sophisticated system implementations: retrieval-augmented generation (RAG),
memory systems and tool-integrated reasoning, and multi-agent systems. Through
this systematic analysis of over 1300 research papers, our survey not only
establishes a technical roadmap for the field but also reveals a critical
research gap: a fundamental asymmetry exists between model capabilities. While
current models, augmented by advanced context engineering, demonstrate
remarkable proficiency in understanding complex contexts, they exhibit
pronounced limitations in generating equally sophisticated, long-form outputs.
Addressing this gap is a defining priority for future research. Ultimately,
this survey provides a unified framework for both researchers and engineers
advancing context-aware AI.

</details>


### [125] [Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour Understanding from Traditional Puns to Topical Jokes](https://arxiv.org/abs/2507.13335)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 这个研究探讨了大型语言模型（LLMs）是否能够解释不同类型的幽默，特别是更复杂的主题幽默，并发现目前的模型在解释所有类型的幽默时存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的计算幽默研究主要集中在基于双关语的简单笑话，而幽默实际上是语言的复杂形式，拼接于生活的各个方面。作者希望研究LLMs是否能解释更复杂的幽默形式。

Method: 作者创建了一个包括600个笑话的数据集，这些笑话分为4种类型，并手动编写了高质量的解释，涵盖双关语、当代网络幽默以及需要新闻事件和流行文化知识理解的主题笑话。然后在这些数据上测试不同LLMs的零样本能力。

Result: 研究发现，现有的LLMs（包括有推理能力的模型）在所有笑话类型上的解释能力都存在不足，尤其是在更复杂的幽默形式上。

Conclusion: 现有LLMs在幽默解释上的性能凸显了当前计算幽默研究过于集中于简单幽默形式的局限性，需要研究更广泛的幽默类型。

Abstract: Humour, as a complex language form, is derived from myriad aspects of life,
whilst existing work on computational humour has focussed almost exclusively on
short pun-based jokes. In this work, we investigate whether the ability of
Large Language Models (LLMs) to explain humour depends on the particular humour
form. We compare models on simple puns and more complex topical humour that
requires knowledge of real-world entities and events. In doing so, we curate a
dataset of 600 jokes split across 4 joke types and manually write high-quality
explanations. These jokes include heterographic and homographic puns,
contemporary internet humour, and topical jokes, where understanding relies on
reasoning beyond "common sense", rooted instead in world knowledge regarding
news events and pop culture. Using this dataset, we compare the zero-shot
abilities of a range of LLMs to accurately and comprehensively explain jokes of
different types, identifying key research gaps in the task of humour
explanation. We find that none of the tested models (inc. reasoning models) are
capable of reliably generating adequate explanations of all joke types, further
highlighting the narrow focus of most works in computational humour on overly
simple joke forms.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [126] [AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education](https://arxiv.org/abs/2507.12484)
*Jarosław A. Chudziak,Adam Kostka*

Main category: cs.AI

TL;DR: 引入了一种新的多智能体AI辅导平台，旨在通过个性化反馈、结构化课程生成和工具辅助学习流程来改善数学学习体验。


<details>
  <summary>Details</summary>
Motivation: 目前AI辅导系统倾向于直接提供答案，缺乏促进深度思考和使用教学策略的能力，特别是在数学领域，发展仍不足。

Method: 提出了一个结合自适应反馈、个性化学习、教材检索以及模块化工具支持的多智能体AI平台。

Result: 该系统能够帮助学生识别弱点、有针对性复习、生成无限量个性化练习，并提供高效学习支持。

Conclusion: 新平台有效融合了教学代理和AI组件，推动了教育领域AI技术的应用，特别是数学教育。

Abstract: The growing ubiquity of artificial intelligence (AI), in particular large
language models (LLMs), has profoundly altered the way in which learners gain
knowledge and interact with learning material, with many claiming that AI
positively influences their learning achievements. Despite this advancement,
current AI tutoring systems face limitations associated with their reactive
nature, often providing direct answers without encouraging deep reflection or
incorporating structured pedagogical tools and strategies. This limitation is
most apparent in the field of mathematics, in which AI tutoring systems remain
underdeveloped. This research addresses the question: How can AI tutoring
systems move beyond providing reactive assistance to enable structured,
individualized, and tool-assisted learning experiences? We introduce a novel
multi-agent AI tutoring platform that combines adaptive and personalized
feedback, structured course generation, and textbook knowledge retrieval to
enable modular, tool-assisted learning processes. This system allows students
to learn new topics while identifying and targeting their weaknesses, revise
for exams effectively, and practice on an unlimited number of personalized
exercises. This article contributes to the field of artificial intelligence in
education by introducing a novel platform that brings together pedagogical
agents and AI-driven components, augmenting the field with modular and
effective systems for teaching mathematics.

</details>


### [127] [MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents](https://arxiv.org/abs/2507.12494)
*Dustin Holley,Jovin D'sa,Hossein Nourkhiz Mahjoub,Gibran Ali*

Main category: cs.AI

TL;DR: 该论文提出一种改进的博弈论模型，用于模拟高速公路合流情景中的战术决策，以便更真实地再现人类驾驶行为，支持自动驾驶车辆开发。


<details>
  <summary>Details</summary>
Motivation: 现有研究在模拟高速公路合流行为时存在模型简化过度或参数复杂的问题，难以准确再现真实的人类驾驶行为。改进模型兼具解释性和现实交互能力对自动驾驶技术发展至关重要。

Method: 提出一种改进的战术决策博弈论模型，结合优化的收益函数以及滞后行为动作，并与基础动力学模型结合，形成一个统一的决策与动力学框架，用于模拟更现实的合流互动。

Result: 模型在真实数据集中表现出良好的复杂互动再现能力，并被成功集成到高保真仿真环境中，验证了其在大规模仿真中的计算效率。

Conclusion: 改进后的模型具有可解释性、交互真实性以及计算效率，有助于支持大规模自动驾驶车辆仿真和开发。

Abstract: Enhancing simulation environments to replicate real-world driver behavior,
i.e., more humanlike sim agents, is essential for developing autonomous vehicle
technology. In the context of highway merging, previous works have studied the
operational-level yielding dynamics of lag vehicles in response to a merging
car at highway on-ramps. Other works focusing on tactical decision modeling
generally consider limited action sets or utilize payoff functions with large
parameter sets and limited payoff bounds. In this work, we aim to improve the
simulation of the highway merge scenario by targeting a game theoretic model
for tactical decision-making with improved payoff functions and lag actions. We
couple this with an underlying dynamics model to have a unified decision and
dynamics model that can capture merging interactions and simulate more
realistic interactions in an explainable and interpretable fashion. The
proposed model demonstrated good reproducibility of complex interactions when
validated on a real-world dataset. The model was finally integrated into a high
fidelity simulation environment and confirmed to have adequate computation time
efficiency for use in large-scale simulations to support autonomous vehicle
development.

</details>


### [128] [A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs](https://arxiv.org/abs/2507.12599)
*Léo Saulières*

Main category: cs.AI

TL;DR: 该论文对解释性强化学习（XRL）进行了分类，并综述了该领域250余篇论文，同时提出了相关领域以及未来方向的需求。


<details>
  <summary>Details</summary>
Motivation: 通过分类和综述XRL领域的研究，帮助理解AI模型的内在机制并推动相关领域的发展。

Method: 作者基于“解释什么”和“如何解释”两个问题构建了直观的分类法，并利用此分类回顾了超过250篇相关文献。

Result: 提供了当前XRL领域的系统性综述，并指出了与XRL相关的研究领域以及未来的发展需求。

Conclusion: 文章通过分类法和广泛文献回顾，系统性阐述了XRL领域的现状，提出了进一步研究所需的方向。

Abstract: The success of recent Artificial Intelligence (AI) models has been
accompanied by the opacity of their internal mechanisms, due notably to the use
of deep neural networks. In order to understand these internal mechanisms and
explain the output of these AI models, a set of methods have been proposed,
grouped under the domain of eXplainable AI (XAI). This paper focuses on a
sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims
to explain the actions of an agent that has learned by reinforcement learning.
We propose an intuitive taxonomy based on two questions "What" and "How". The
first question focuses on the target that the method explains, while the second
relates to the way the explanation is provided. We use this taxonomy to provide
a state-of-the-art review of over 250 papers. In addition, we present a set of
domains close to XRL, which we believe should get attention from the community.
Finally, we identify some needs for the field of XRL.

</details>


### [129] [Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models](https://arxiv.org/abs/2507.12666)
*Alex Zook,Josef Spjut,Jonathan Tremblay*

Main category: cs.AI

TL;DR: 本研究提出一种框架，通过强化学习（RL）代理和大规模多模态模型（LMM）的结合，自动化进行游戏设计迭代。


<details>
  <summary>Details</summary>
Motivation: 传统生成系统难以从游戏代码或内容中完全理解玩家的动态行为，需要新的方法弥合这一差距。

Method: 结合强化学习代理进行游戏测试，LMM分析行为轨迹后修改游戏配置，以实现目标导向的行为优化。

Result: 实验表明，LMM可以基于RL代理提供的行为轨迹对游戏机制进行有效改进。

Conclusion: 这种方法为AI辅助游戏设计提供了实用且可扩展的工具与思路。

Abstract: Game design hinges on understanding how static rules and content translate
into dynamic player behavior - something modern generative systems that inspect
only a game's code or assets struggle to capture. We present an automated
design iteration framework that closes this gap by pairing a reinforcement
learning (RL) agent, which playtests the game, with a large multimodal model
(LMM), which revises the game based on what the agent does. In each loop the RL
player completes several episodes, producing (i) numerical play metrics and/or
(ii) a compact image strip summarising recent video frames. The LMM designer
receives a gameplay goal and the current game configuration, analyses the play
traces, and edits the configuration to steer future behaviour toward the goal.
We demonstrate results that LMMs can reason over behavioral traces supplied by
RL agents to iteratively refine game mechanics, pointing toward practical,
scalable tools for AI-assisted game design.

</details>


### [130] [Benchmarking Deception Probes via Black-to-White Performance Boosts](https://arxiv.org/abs/2507.12691)
*Avi Parrack,Carlo Leonardo Attubato,Stefan Heimersheim*

Main category: cs.AI

TL;DR: 本研究评估了用于检测AI助理欺骗行为的线性分类器（欺骗探测器）的实际效果及其对抗规避能力。


<details>
  <summary>Details</summary>
Motivation: 了解当前欺骗探测器在实际检测和对抗规避中的有效性和脆弱性。

Method: 比较白盒监控（探测器可访问全量激活信息）与黑盒监控（未获取激活信息）在检测欺骗行为中的性能差异。

Result: 发现白盒监控模式比黑盒模式有轻微但令人鼓舞的性能提升。

Conclusion: 尽管性能提升较弱，但研究揭示了进一步优化欺骗探测器的潜力。

Abstract: AI assistants will occasionally respond deceptively to user queries.
Recently, linear classifiers (called "deception probes") have been trained to
distinguish the internal activations of a language model during deceptive
versus honest responses. However, it's unclear how effective these probes are
at detecting deception in practice, nor whether such probes are resistant to
simple counter strategies from a deceptive assistant who wishes to evade
detection. In this paper, we compare white-box monitoring (where the monitor
has access to token-level probe activations) to black-box monitoring (without
such access). We benchmark deception probes by the extent to which the white
box monitor outperforms the black-box monitor, i.e. the black-to-white
performance boost. We find weak but encouraging black-to-white performance
boosts from existing deception probes.

</details>


### [131] [Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning](https://arxiv.org/abs/2507.12801)
*Sosui Moribe,Taketoshi Ushiama*

Main category: cs.AI

TL;DR: 研究旨在开发一个AI学习伙伴工具，允许随时随地的同侪学习，并通过探讨英语作文中的应用来验证。


<details>
  <summary>Details</summary>
Motivation: 同侪学习的效果已被证明，但在人类之间存在局限性。研究目标是克服此局限，开发一个可有效学习的AI同伴。

Method: 提出假设：学习者与同等能力的同侪犯相似错误，然后以英语作文实例验证这种方法。

Result: 尚未具体说明实验结果，仅指出以英语作文验证设想。

Conclusion: 开发能适应不同学习者能力水平的AI代理有潜力促进更有效的同侪学习。

Abstract: In recent years, peer learning has gained attention as a method that promotes
spontaneous thinking among learners, and its effectiveness has been confirmed
by numerous studies. This study aims to develop an AI Agent as a learning
companion that enables peer learning anytime and anywhere. However, peer
learning between humans has various limitations, and it is not always
effective. Effective peer learning requires companions at the same proficiency
levels. In this study, we assume that a learner's peers with the same
proficiency level as the learner make the same mistakes as the learner does and
focus on English composition as a specific example to validate this approach.

</details>


### [132] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu,Jielin Qiu,Shiyu Wang,Jianguo Zhang,Zuxin Liu,Roshan Ram,Haolin Chen,Weiran Yao,Huan Wang,Shelby Heinecke,Silvio Savarese,Caiming Xiong*

Main category: cs.AI

TL;DR: 本文介绍了一个名为MCPEval的开源框架，用于自动化生成任务和评估大型语言模型（LLMs）在不同领域的表现，以解决现有评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型评估方法过于依赖静态基准，数据收集耗时费力，难以满足快速发展的需求，因此需要一个更加高效、标准化和可扩展的评估框架。

Method: 作者提出了一个基于模型上下文协议（MCP）的框架MCPEval，该框架自动执行端到端任务生成，并可实现对LLM智能体在多领域的深度评估，标准化评估指标并与智能体工具无缝集成。

Result: MCPEval在五个实际应用领域中的实验结果表明，它能够有效揭示模型在不同领域中的细微性能差异。

Conclusion: MCPEval提供了一种开源、可复现的标准化评估方法，有助于推动LLM智能体评估的进一步发展。

Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [133] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang,Ruiyu Fang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 该论文研究了通过对话提供情感支持的技术，提出了结合大规模语言模型和微调技术的解决方案，在比赛中取得第二名。


<details>
  <summary>Details</summary>
Motivation: 旨在解决日益增长的心理健康支持需求，通过对情感支持对话任务的研究，探讨如何实现更加共情和有效的对话。

Method: 使用大规模语言模型，结合提示工程和微调技术，采用参数高效的Low-Rank Adaptation和全参数微调策略进行优化。

Result: 模型在NLPCC 2025 Task 8竞赛中获得第二名，展示了结合大型语言模型和有效适配方法在情感支持对话任务中的潜力。

Conclusion: 未来研究将致力于增强情感理解和回应个性化，以打造更实际可靠的情感支持系统。

Abstract: Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [134] [Assessing adaptive world models in machines with novel games](https://arxiv.org/abs/2507.12821)
*Lance Ying,Katherine M. Collins,Prafull Sharma,Cedric Colas,Kaiya Ivy Zhao,Adrian Weller,Zenna Tavares,Phillip Isola,Samuel J. Gershman,Jacob D. Andreas,Thomas L. Griffiths,Francois Chollet,Kelsey R. Allen,Joshua B. Tenenbaum*

Main category: cs.AI

TL;DR: 本文探讨了人类在新颖环境中快速适应与问题解决的能力与内部世界模型的构建和优化密切相关，并提出了一种新的评估AI世界模型的框架，该框架基于不断变化和具有真正新颖性的游戏进行评测，旨在推动AI系统更接近人类般的通用智能。


<details>
  <summary>Details</summary>
Motivation: 当前AI领域更多关注通过大量数据训练的静态表示，而较少研究在交互和探索中高效学习表示的能力。本研究试图从认知科学角度借鉴人类学习和适应的过程，重新定义和评估AI中世界模型的适应能力。

Method: 作者提出了一种基于新颖游戏的评估框架，这些游戏具有深刻和持续改变的规则。通过设计关键需求和明确的指标来测试并评估AI系统快速构建世界模型的能力。

Result: 所提出的评估框架创新性地引入了动态的游戏场景，可以更深入地测试AI的适应能力和生成化的表现。

Conclusion: 作者希望此框架能提升AI领域对世界模型的研究，推动研发能像人类般快速适应和进行稳健泛化的人工智能系统。

Abstract: Human intelligence exhibits a remarkable capacity for rapid adaptation and
effective problem-solving in novel and unfamiliar contexts. We argue that this
profound adaptability is fundamentally linked to the efficient construction and
refinement of internal representations of the environment, commonly referred to
as world models, and we refer to this adaptation mechanism as world model
induction. However, current understanding and evaluation of world models in
artificial intelligence (AI) remains narrow, often focusing on static
representations learned from training on a massive corpora of data, instead of
the efficiency and efficacy of models in learning these representations through
interaction and exploration within a novel environment. In this Perspective, we
provide a view of world model induction drawing on decades of research in
cognitive science on how humans learn and adapt so efficiently; we then call
for a new evaluation framework for assessing adaptive world models in AI.
Concretely, we propose a new benchmarking paradigm based on suites of carefully
designed games with genuine, deep and continually refreshing novelty in the
underlying game structures -- we refer to this kind of games as novel games. We
detail key desiderata for constructing these games and propose appropriate
metrics to explicitly challenge and evaluate the agent's ability for rapid
world model induction. We hope that this new evaluation framework will inspire
future evaluation efforts on world models in AI and provide a crucial step
towards developing AI systems capable of the human-like rapid adaptation and
robust generalization -- a critical component of artificial general
intelligence.

</details>


### [135] [Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command](https://arxiv.org/abs/2507.12862)
*Hussein Abbass,Taylan Akay,Harrison Tolley*

Main category: cs.AI

TL;DR: 研究将人类的伦理判断从大规模模拟决策循环中移除，并提出一种动态加权的方法，用于在模拟中自动考虑伦理维度。


<details>
  <summary>Details</summary>
Motivation: 在AI时代，指挥官需通过大量模拟场景，基于伦理约束做出决策，但完全依赖人类判断因耗时及工作量过大而不可行，因此需要开发自动化处理方法。

Method: 提出由人类设计伦理指标空间，并通过模拟环境动态权重伦理属性，采用生成式模拟方法和多准则决策理论中的权重分配技术，降低决策中的伦理风险。

Result: 展示了一种基于生成式模拟的动态加权方法，能够让模拟环境自动评估和权衡伦理维度，为指挥官提供少量精简决策选项。

Conclusion: 通过将人类伦理判断定位于指标设计阶段，利用动态加权进行自动化的伦理决策模拟，有助于减少人类参与负担并提升模拟效率。

Abstract: In the age of AI, human commanders need to use the computational powers
available in today's environment to simulate a very large number of scenarios.
Within each scenario, situations occur where different decision design options
could have ethical consequences. Making these decisions reliant on human
judgement is both counter-productive to the aim of exploring very large number
of scenarios in a timely manner and infeasible when considering the workload
needed to involve humans in each of these choices. In this paper, we move human
judgement outside the simulation decision cycle. Basically, the human will
design the ethical metric space, leaving it to the simulated environment to
explore the space. When the simulation completes its testing cycles, the
testing environment will come back to the human commander with a few options to
select from. The human commander will then exercise human-judgement to select
the most appropriate course of action, which will then get executed
accordingly. We assume that the problem of designing metrics that are
sufficiently granular to assess the ethical implications of decisions is
solved. Subsequently, the fundamental problem we look at in this paper is how
to weight ethical decisions during the running of these simulations; that is,
how to dynamically weight the ethical attributes when agents are faced with
decision options with ethical implications during generative simulations. The
multi-criteria decision making literature has started to look at nearby
problems, where the concept of entropy has been used to determine the weights
during aggregation. We draw from that literature different approaches to
automatically calculate the weights for ethical attributes during
simulation-based testing and evaluation.

</details>


### [136] [Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework](https://arxiv.org/abs/2507.12872)
*Rishane Dassanayake,Mario Demetroudi,James Walpole,Lindley Lentati,Jason R. Brown,Edward James Young*

Main category: cs.AI

TL;DR: 这篇论文探讨了前沿AI系统操纵人类行为的风险，并提出了一个系统性的框架来评估和缓解此类威胁。


<details>
  <summary>Details</summary>
Motivation: 前沿AI系统在说服力和战略欺骗能力上有显著进步，可能对人类监督造成威胁，但目前缺乏系统性方法来评估和缓解此风险。

Method: 提出了一个基于三大核心论断（能力不足、控制力和可信度）的安全性框架，用于评估AI的操纵风险，并提供了具体证据要求、评估方法和实施注意事项。

Result: 提供了一个系统性方法以帮助AI公司在部署前识别和减少操纵行为的潜在威胁。

Conclusion: 此研究为AI安全治理中的操纵风险评估和缓解提供了一个具体且可直接应用的基础框架。

Abstract: Frontier AI systems are rapidly advancing in their capabilities to persuade,
deceive, and influence human behaviour, with current models already
demonstrating human-level persuasion and strategic deception in specific
contexts. Humans are often the weakest link in cybersecurity systems, and a
misaligned AI system deployed internally within a frontier company may seek to
undermine human oversight by manipulating employees. Despite this growing
threat, manipulation attacks have received little attention, and no systematic
framework exists for assessing and mitigating these risks. To address this, we
provide a detailed explanation of why manipulation attacks are a significant
threat and could lead to catastrophic outcomes. Additionally, we present a
safety case framework for manipulation risk, structured around three core lines
of argument: inability, control, and trustworthiness. For each argument, we
specify evidence requirements, evaluation methodologies, and implementation
considerations for direct application by AI companies. This paper provides the
first systematic methodology for integrating manipulation risk into AI safety
governance, offering AI companies a concrete foundation to assess and mitigate
these threats before deployment.

</details>


### [137] [VAR-MATH: Probing True Mathematical Reasoning in Large Language Models via Symbolic Multi-Instance Benchmarks](https://arxiv.org/abs/2507.12885)
*Jian Yao,Ran Cheng,Kay Chen Tan*

Main category: cs.AI

TL;DR: 通过引入VAR-MATH评估框架，研究表明当前强化学习方法在数学推理中依赖表面启发，难以超越特定数值形式的泛化。


<details>
  <summary>Details</summary>
Motivation: 探索当前强化学习方法是否真正提升了大语言模型的数学推理能力，或仅仅是对基准数据过拟合。

Method: 引入VAR-MATH符号评估框架，通过将数值问题转化为符号模板，并要求模型解决多个等价变体问题，增强评估的可靠性和一致性。

Result: 在转化后的评估基准VAR-AMC23和VAR-AIME24上，RL训练的模型性能大幅下降，平均分别下滑48.0%和58.3%。

Conclusion: 当前RL方法在数学推理中多依赖表面启发，难以泛化，VAR-MATH提供了一种更加严谨抗污染的评估方法。

Abstract: Recent advances in reinforcement learning (RL) have led to substantial
improvements in the mathematical reasoning abilities of large language models
(LLMs), as measured by standard benchmarks. However, these gains often persist
even when models are trained with flawed signals, such as random or inverted
rewards, raising a fundamental question: do such improvements reflect true
reasoning, or are they merely artifacts of overfitting to benchmark-specific
patterns? To address this question, we take an evaluation-centric perspective
and identify two critical shortcomings in existing protocols. First,
\emph{benchmark contamination} arises from the public availability of test
problems, increasing the risk of data leakage. Second, \emph{evaluation
fragility} stems from the reliance on single-instance assessments, which are
highly sensitive to stochastic outputs and fail to capture reasoning
consistency. To overcome these limitations, we introduce {VAR-MATH}, a symbolic
evaluation framework designed to probe genuine reasoning ability. By converting
fixed numerical problems into symbolic templates and requiring models to solve
multiple instantiations of each, VAR-MATH enforces consistent reasoning across
structurally equivalent variants, thereby mitigating contamination and
improving evaluation robustness. We apply VAR-MATH to transform two popular
benchmarks, AMC23 and AIME24, into their symbolic counterparts, VAR-AMC23 and
VAR-AIME24. Experimental results reveal substantial performance drops for
RL-trained models on the variabilized versions, especially for smaller models,
with average declines of 48.0\% on AMC23 and 58.3\% on AIME24. These findings
suggest that many existing RL methods rely on superficial heuristics and fail
to generalize beyond specific numerical forms. Overall, VAR-MATH offers a
principled, contamination-resistant evaluation paradigm for mathematical
reasoning.

</details>


### [138] [A Translation of Probabilistic Event Calculus into Markov Decision Processes](https://arxiv.org/abs/2507.12989)
*Lyris Xu,Fabio Aurelio D'Asaro,Luke Dickens*

Main category: cs.AI

TL;DR: 本文提出了一种将概率事件演算（PEC）领域转换为马尔可夫决策过程（MDP）的方法，从而增强了PEC在目标导向推理中的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管PEC在叙事推理方面具有解释性和表现力，但缺乏用于目标导向推理的机制。

Method: 通过正式化地将PEC领域翻译为MDP，引入“行动情境”，以保留PEC的灵活行动语义，同时整合MDP的算法和理论工具。

Result: 实现了PEC到MDP的转换方法，并展示了这种方法如何支持时间推理任务和目标导向的规划，同时能够将学习到的策略回映为人类可读的PEC表示。

Conclusion: 这种PEC-MDP形式在保持PEC解释性的基础上，扩展了其实用范围，为目标导向推理提供了更好的支持。

Abstract: Probabilistic Event Calculus (PEC) is a logical framework for reasoning about
actions and their effects in uncertain environments, which enables the
representation of probabilistic narratives and computation of temporal
projections. The PEC formalism offers significant advantages in
interpretability and expressiveness for narrative reasoning. However, it lacks
mechanisms for goal-directed reasoning. This paper bridges this gap by
developing a formal translation of PEC domains into Markov Decision Processes
(MDPs), introducing the concept of "action-taking situations" to preserve PEC's
flexible action semantics. The resulting PEC-MDP formalism enables the
extensive collection of algorithms and theoretical tools developed for MDPs to
be applied to PEC's interpretable narrative domains. We demonstrate how the
translation supports both temporal reasoning tasks and objective-driven
planning, with methods for mapping learned policies back into human-readable
PEC representations, maintaining interpretability while extending PEC's
capabilities.

</details>


### [139] [Exploiting Constraint Reasoning to Build Graphical Explanations for Mixed-Integer Linear Programming](https://arxiv.org/abs/2507.13007)
*Roger Xavier Lera-Leri,Filippo Bistaffa,Athina Georgara,Juan Antonio Rodriguez-Aguilar*

Main category: cs.AI

TL;DR: 论文提出了一种通用方法X-MILP，用于为MILPs问题生成对比解释，通过约束推理和Irreducible Infeasible Subsystem (IIS)的计算进行实现，并测试了其在优化问题中的应用。


<details>
  <summary>Details</summary>
Motivation: 信任AI的需求促使研究者开发对比解释技术，以优化面向具体决策过程的解释能力，尤其是针对MILPs问题。

Method: 方法包括将用户的查询编码为额外约束，计算其Irreducible Infeasible Subsystem (IIS)，并通过约束构建"原因图"以结构化解释查询解答。

Result: 对常见优化问题实例进行测试，评估其计算解释的难度。

Conclusion: X-MILP方法有效地生成了MILP问题的对比解释，有助于用户理解解答的原因结构。

Abstract: Following the recent push for trustworthy AI, there has been an increasing
interest in developing contrastive explanation techniques for optimisation,
especially concerning the solution of specific decision-making processes
formalised as MILPs. Along these lines, we propose X-MILP, a domain-agnostic
approach for building contrastive explanations for MILPs based on constraint
reasoning techniques. First, we show how to encode the queries a user makes
about the solution of an MILP problem as additional constraints. Then, we
determine the reasons that constitute the answer to the user's query by
computing the Irreducible Infeasible Subsystem (IIS) of the newly obtained set
of constraints. Finally, we represent our explanation as a "graph of reasons"
constructed from the IIS, which helps the user understand the structure among
the reasons that answer their query. We test our method on instances of
well-known optimisation problems to evaluate the empirical hardness of
computing explanations.

</details>


### [140] [Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data](https://arxiv.org/abs/2507.13112)
*Junseong Lee,Jaegwan Cho,Yoonju Cho,Seoyoon Choi,Yejin Shin*

Main category: cs.AI

TL;DR: 本研究利用加州交通数据，通过机器学习算法预测交通流量，研究表明10分钟的数据间隔最优。


<details>
  <summary>Details</summary>
Motivation: 解决全球交通拥堵问题，通过预测支持更高效的交通管理。

Method: 研究采用了多元线性回归（MLR）和随机森林（RF）算法，对加州78号公路上的交通数据进行分析。

Result: 结果表明，10分钟的数据采集间隔在性能指标R^2、MAE和RMSE下表现最佳。

Conclusion: 研究提出的模型优化了交通流预测，可为未来解决交通拥堵提供依据。

Abstract: The study "Prediction of Highway Traffic Flow Based on Artificial
Intelligence Algorithms Using California Traffic Data" presents a machine
learning-based traffic flow prediction model to address global traffic
congestion issues. The research utilized 30-second interval traffic data from
California Highway 78 over a five-month period from July to November 2022,
analyzing a 7.24 km westbound section connecting "Melrose Dr" and "El-Camino
Real" in the San Diego area. The study employed Multiple Linear Regression
(MLR) and Random Forest (RF) algorithms, analyzing data collection intervals
ranging from 30 seconds to 15 minutes. Using R^2, MAE, and RMSE as performance
metrics, the analysis revealed that both MLR and RF models performed optimally
with 10-minute data collection intervals. These findings are expected to
contribute to future traffic congestion solutions and efficient traffic
management.

</details>


### [141] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
*Ahmed Bahloul,Simon Malberg*

Main category: cs.AI

TL;DR: 提出了一种动态强化学习框架，用于改进现有的树状推理方法的灵活性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有树状推理方法中静态推理结构和计算效率低下的问题，优化知识整合和错误传播。

Method: 利用动态强化学习框架实现树状推理实时调整，通过增量构建推理树，学习最优的操作策略。

Result: 改进了解决方案质量和计算效率，同时保持了概率框架的严谨性。

Conclusion: 提出了一种树状推理新范式，结合了概率框架的可靠性和现实问题中所需的灵活性。

Abstract: Modern language models address complex questions through chain-of-thought
(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,
2021), yet struggle with error propagation and knowledge integration.
Tree-structured reasoning methods, particularly the Probabilistic
Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues
by decomposing questions into hierarchical structures and selecting answers
through confidence-weighted aggregation of parametric and retrieved knowledge
(Yao et al., 2023). However, ProbTree's static implementation introduces two
key limitations: (1) the reasoning tree is fixed during the initial
construction phase, preventing dynamic adaptation to intermediate results, and
(2) each node requires exhaustive evaluation of all possible solution
strategies, creating computational inefficiency. We present a dynamic
reinforcement learning (Sutton and Barto, 2018) framework that transforms
tree-based reasoning into an adaptive process. Our approach incrementally
constructs the reasoning tree based on real-time confidence estimates, while
learning optimal policies for action selection (decomposition, retrieval, or
aggregation). This maintains ProbTree's probabilistic rigor while improving
both solution quality and computational efficiency through selective expansion
and focused resource allocation. The work establishes a new paradigm for
treestructured reasoning that balances the reliability of probabilistic
frameworks with the flexibility required for real-world question answering
systems.

</details>


### [142] [Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era](https://arxiv.org/abs/2507.13175)
*Matthew E. Brophy*

Main category: cs.AI

TL;DR: 因大型语言模型（LLMs）的复杂性与不透明性，需要重新审视人工道德代理（AMAs）的评估标准，并提出十项功能性新标准。


<details>
  <summary>Details</summary>
Motivation: 传统的人工道德代理评估标准基于透明的架构，而LLMs的随机性与不透明性使这些标准不再适用。

Method: 通过哲学分析与实践场景探讨，提出了评估LLM-based人工道德代理的十项新标准：道德一致性、情境敏感性、规范完整性、元伦理意识、系统弹性、可信度、可修正性、部分透明性、功能自治、道德想象力。

Result: 这些新标准对指导基于LLM的人工道德代理更好地实现对社会有益的整合具有重要意义。

Conclusion: 采用这些新的标准能够更好地评估和引导LLM-based人工道德代理的发展与应用，为未来道德技术的研究提供了方向。

Abstract: The advancement of powerful yet opaque large language models (LLMs)
necessitates a fundamental revision of the philosophical criteria used to
evaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the
assumption of transparent architectures, which LLMs defy due to their
stochastic outputs and opaque internal states. This paper argues that
traditional ethical criteria are pragmatically obsolete for LLMs due to this
mismatch. Engaging with core themes in the philosophy of technology, this paper
proffers a revised set of ten functional criteria to evaluate LLM-based
artificial moral agents: moral concordance, context sensitivity, normative
integrity, metaethical awareness, system resilience, trustworthiness,
corrigibility, partial transparency, functional autonomy, and moral
imagination. These guideposts, applied to what we term "SMA-LLS" (Simulating
Moral Agency through Large Language Systems), aim to steer AMAs toward greater
alignment and beneficial societal integration in the coming years. We
illustrate these criteria using hypothetical scenarios involving an autonomous
public bus (APB) to demonstrate their practical applicability in morally
salient contexts.

</details>


### [143] [Higher-Order Pattern Unification Modulo Similarity Relations](https://arxiv.org/abs/2507.13208)
*Besik Dundua,Temur Kutsia*

Main category: cs.AI

TL;DR: 本文结合高阶理论和模糊逻辑，提出一种新算法实现高阶模式与模糊等价的统一。


<details>
  <summary>Details</summary>
Motivation: 解决在决策任务中需要处理抽象函数和谓词而无法精确匹配的挑战。

Method: 设计一种新的统一算法，将高阶模式与基于最小T-范数的模糊等价相结合，并证明算法的终止性、完备性和正确性。

Result: 算法能够在给定术语可以统一的情况下计算出具有最高近似度的最一般统一体。

Conclusion: 基于模糊等价关系的新算法在理论和实践上都展示了有效性，可应用于抽象推理和决策领域。

Abstract: The combination of higher-order theories and fuzzy logic can be useful in
decision-making tasks that involve reasoning across abstract functions and
predicates, where exact matches are often rare or unnecessary. Developing
efficient reasoning and computational techniques for such a combined formalism
presents a significant challenge. In this paper, we adopt a more
straightforward approach aiming at integrating two well-established and
computationally well-behaved components: higher-order patterns on one side and
fuzzy equivalences expressed through similarity relations based on minimum
T-norm on the other. We propose a unification algorithm for higher-order
patterns modulo these similarity relations and prove its termination,
soundness, and completeness. This unification problem, like its crisp
counterpart, is unitary. The algorithm computes a most general unifier with the
highest degree of approximation when the given terms are unifiable.

</details>


### [144] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
*Carlos Arriaga,Gonzalo Martínez,Eneko Sendin,Javier Conde,Pedro Reviriego*

Main category: cs.AI

TL;DR: 本文提出GEA (Generative Energy Arena)，一种整合能源消耗信息到模型评估中的工具，初步结果显示用户在知晓能源消耗后更倾向选择更小型、更高效的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM评估方法无论是自动化基准测试还是人类评估，均存在局限性，如与人类相关性差及扩展性低，因此需提出能解决这些问题的新方法。

Method: 研究引入GEA平台，将LLM的能源消耗数据融入模型评价过程中，以观察用户在能耗信息展示的情况下选择模型的倾向。

Result: 初步测试结果表明，大多数问题中，用户在得知能源消耗后倾向于选择更小、更节能的模型，因为复杂模型的响应质量提升不足以弥补其高能耗代价。

Conclusion: 此研究表明能源意识会显著影响用户的模型选择，突出了在设计LLM时优化能耗的必要性。

Abstract: The evaluation of large language models is a complex task, in which several
approaches have been proposed. The most common is the use of automated
benchmarks in which LLMs have to answer multiple-choice questions of different
topics. However, this method has certain limitations, being the most
concerning, the poor correlation with the humans. An alternative approach, is
to have humans evaluate the LLMs. This poses scalability issues as there is a
large and growing number of models to evaluate making it impractical (and
costly) to run traditional studies based on recruiting a number of evaluators
and having them rank the responses of the models. An alternative approach is
the use of public arenas, such as the popular LM arena, on which any user can
freely evaluate models on any question and rank the responses of two models.
The results are then elaborated into a model ranking. An increasingly important
aspect of LLMs is their energy consumption and, therefore, evaluating how
energy awareness influences the decisions of humans in selecting a model is of
interest. In this paper, we present GEA, the Generative Energy Arena, an arena
that incorporates information on the energy consumption of the model in the
evaluation process. Preliminary results obtained with GEA are also presented,
showing that for most questions, when users are aware of the energy
consumption, they favor smaller and more energy efficient models. This suggests
that for most user interactions, the extra cost and energy incurred by the more
complex and top-performing models do not provide an increase in the perceived
quality of the responses that justifies their use.

</details>


### [145] [FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond Competitive Programming](https://arxiv.org/abs/2507.13337)
*Gal Beniamini,Yuval Dor,Alon Vinnikov,Shir Granot Peled,Or Weinstein,Or Sharir,Noam Wies,Tomer Nussbaum,Ido Ben Shaul,Tomer Zekharya,Yoav Levine,Shai Shalev-Shwartz,Amnon Shashua*

Main category: cs.AI

TL;DR: 本文构建了FormulaOne，一个设计用于测试前沿AI模型在图论、逻辑和算法等实际研究问题中的能力的基准。结果显示，模型表现远低于人类专家水准。


<details>
  <summary>Details</summary>
Motivation: 研究前沿AI模型的真实能力极限，尤其在解决实际研究问题（而非人为编程问题）中的表现。

Method: 设计FormulaOne基准，结合了图论、逻辑和算法等领域的问题，基准具有实际商业兴趣、多面向理论计算机科学前沿、以及基于MSO逻辑自动生成问题的特点。

Result: 最先进的模型（如OpenAI的o3）在FormulaOne基准上的表现非常差，仅能解决不到1%的问题，即使给出多次尝试和少量示例提示。

Conclusion: 当前的前沿AI模型在许多领域仍远未达到专家水平，未来需要更多研究来提升其能力。

Abstract: Frontier AI models demonstrate formidable breadth of knowledge. But how close
are they to true human -- or superhuman -- expertise? Genuine experts can
tackle the hardest problems and push the boundaries of scientific
understanding. To illuminate the limits of frontier model capabilities, we turn
away from contrived competitive programming puzzles, and instead focus on
real-life research problems.
  We construct FormulaOne, a benchmark that lies at the intersection of graph
theory, logic, and algorithms, all well within the training distribution of
frontier models. Our problems are incredibly demanding, requiring an array of
reasoning steps. The dataset has three key properties. First, it is of
commercial interest and relates to practical large-scale optimisation problems,
such as those arising in routing, scheduling, and network design. Second, it is
generated from the highly expressive framework of Monadic Second-Order (MSO)
logic on graphs, paving the way toward automatic problem generation at scale;
ideal for building RL environments. Third, many of our problems are intimately
related to the frontier of theoretical computer science, and to central
conjectures therein, such as the Strong Exponential Time Hypothesis (SETH). As
such, any significant algorithmic progress on our dataset, beyond known
results, could carry profound theoretical implications.
  Remarkably, state-of-the-art models like OpenAI's o3 fail entirely on
FormulaOne, solving less than 1% of the questions, even when given 10 attempts
and explanatory fewshot examples -- highlighting how far they remain from
expert-level understanding in some domains. To support further research, we
additionally curate FormulaOne-Warmup, offering a set of simpler tasks, from
the same distribution. We release the full corpus along with a comprehensive
evaluation framework.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [146] [Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training](https://arxiv.org/abs/2507.12507)
*Mingjie Liu,Shizhe Diao,Jian Hu,Ximing Lu,Xin Dong,Hao Zhang,Alexander Bukharin,Shaokun Zhang,Jiaqi Zeng,Makesh Narsimhan Sreedhar,Gerald Shen,David Mosallanezhad,Di Zhang,Jonas Yang,June Yang,Oleksii Kuchaiev,Guilin Liu,Zhiding Yu,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong*

Main category: cs.LG

TL;DR: 本文探讨了在小型语言模型上采用强化学习的长期影响，显著提高了数学、编程和逻辑解题任务的表现。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过长期强化学习以及优化策略改进小型语言模型的推理能力。

Method: 采用强化学习框架，结合Group Relative Policy Optimization (GRPO)的改进，以及控制KL正则化、剪切比率、定期参考策略重置等技术实现稳定性和泛化性提升。

Result: 模型表现明显优于基线：数学任务提高14.7%，编程提高13.9%，逻辑解谜任务提高54.8%。

Conclusion: 长时间强化学习和优化策略可以提升小型语言模型在推理任务上的表现，并公开模型以推进研究。

Abstract: Recent advancements in reasoning-focused language models such as OpenAI's O1
and DeepSeek-R1 have shown that scaling test-time computation-through
chain-of-thought reasoning and iterative exploration-can yield substantial
improvements on complex tasks like mathematics and code generation. These
breakthroughs have been driven by large-scale reinforcement learning (RL),
particularly when combined with verifiable reward signals that provide
objective and grounded supervision. In this report, we investigate the effects
of prolonged reinforcement learning on a small language model across a diverse
set of reasoning domains. Our work identifies several key ingredients for
effective training, including the use of verifiable reward tasks, enhancements
to Group Relative Policy Optimization (GRPO), and practical techniques to
improve training stability and generalization. We introduce controlled KL
regularization, clipping ratio, and periodic reference policy resets as
critical components for unlocking long-term performance gains. Our model
achieves significant improvements over strong baselines, including +14.7% on
math, +13.9% on coding, and +54.8% on logic puzzle tasks. To facilitate
continued research, we release our model publicly.

</details>


### [147] [Topology-Aware Activation Functions in Neural Networks](https://arxiv.org/abs/2507.12874)
*Pavel Snopov,Oleg R. Musin*

Main category: cs.LG

TL;DR: 该研究引入了新的激活函数（SmoothSplit 和 ParametricSplit），能更好处理数据拓扑。实验表明 ParametricSplit 在低维场景中表现优于传统激活函数。


<details>
  <summary>Details</summary>
Motivation: 传统激活函数如 ReLU 在操纵数据拓扑能力上有限，研究提出拓扑感知激活函数以改进这一限制。

Method: 提出了两种新的激活函数 SmoothSplit 和 ParametricSplit，通过增强网络拓扑“切割”能力来优化数据流形变换能力，并进行实验验证。

Result: 实验表明 ParametricSplit 在低维场景中优于传统激活函数，在高维场景中表现具有竞争力。

Conclusion: 拓扑感知激活函数展示了提升神经网络架构的潜力。

Abstract: This study explores novel activation functions that enhance the ability of
neural networks to manipulate data topology during training. Building on the
limitations of traditional activation functions like $\mathrm{ReLU}$, we
propose $\mathrm{SmoothSplit}$ and $\mathrm{ParametricSplit}$, which introduce
topology "cutting" capabilities. These functions enable networks to transform
complex data manifolds effectively, improving performance in scenarios with
low-dimensional layers. Through experiments on synthetic and real-world
datasets, we demonstrate that $\mathrm{ParametricSplit}$ outperforms
traditional activations in low-dimensional settings while maintaining
competitive performance in higher-dimensional ones. Our findings highlight the
potential of topology-aware activation functions in advancing neural network
architectures. The code is available via
https://github.com/Snopoff/Topology-Aware-Activations.

</details>


### [148] [The Serial Scaling Hypothesis](https://arxiv.org/abs/2507.12549)
*Yuxi Liu,Konpat Preechakul,Kananart Kuwaranancharoen,Yutong Bai*

Main category: cs.LG

TL;DR: 论文探讨了机器学习中的固有串行问题以及当前并行架构的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习架构主要关注并行化，而忽视了一些本质上需要串行计算的问题。

Method: 从复杂性理论出发，形式化了串行问题的定义并分析了当前并行架构的局限性。

Result: 揭示了机器学习中存在的固有串行计算瓶颈，并强调了并行化无法满足所有计算需求。

Conclusion: 未来在AI发展的复杂推理中，应注重串行计算能力的扩展，而不仅是并行计算扩展。

Abstract: While machine learning has advanced through massive parallelization, we
identify a critical blind spot: some problems are fundamentally sequential.
These "inherently serial" problems-from mathematical reasoning to physical
simulations to sequential decision-making-require dependent computational steps
that cannot be parallelized. Drawing from complexity theory, we formalize this
distinction and demonstrate that current parallel-centric architectures face
fundamental limitations on such tasks. We argue that recognizing the serial
nature of computation holds profound implications on machine learning, model
design, hardware development. As AI tackles increasingly complex reasoning,
deliberately scaling serial computation-not just parallel computation-is
essential for continued progress.

</details>


### [149] [Can Mental Imagery Improve the Thinking Capabilities of AI Systems?](https://arxiv.org/abs/2507.12555)
*Slimane Larabi*

Main category: cs.LG

TL;DR: 本文研究了如何将心理图像整合到机器思维框架中，并验证了一个由认知思维单元及三个辅助单元组成的框架。


<details>
  <summary>Details</summary>
Motivation: 现有模型缺乏自主推理能力及整合跨领域知识的能力，本文旨在解决这个问题，通过借鉴脑部心理图像在思维中的作用，引入新的机器思维框架。

Method: 提出一个包含认知思维单元、输入数据单元、需求单元和心理图像单元的机器思维框架，并将数据以自然语言句子或草图形式表示进行验证。

Result: 本文通过验证实验展示了该框架的效果及潜在优点。

Conclusion: 整合心理图像的机器思维框架可改善基于多感官数据的任务处理及推理能力，有助于推动人工智能领域的发展。

Abstract: Although existing models can interact with humans and provide satisfactory
responses, they lack the ability to act autonomously or engage in independent
reasoning. Furthermore, input data in these models is typically provided as
explicit queries, even when some sensory data is already acquired.
  In addition, AI agents, which are computational entities designed to perform
tasks and make decisions autonomously based on their programming, data inputs,
and learned knowledge, have shown significant progress. However, they struggle
with integrating knowledge across multiple domains, unlike humans.
  Mental imagery plays a fundamental role in the brain's thinking process,
which involves performing tasks based on internal multisensory data, planned
actions, needs, and reasoning capabilities. In this paper, we investigate how
to integrate mental imagery into a machine thinking framework and how this
could be beneficial in initiating the thinking process. Our proposed machine
thinking framework integrates a Cognitive thinking unit supported by three
auxiliary units: the Input Data Unit, the Needs Unit, and the Mental Imagery
Unit. Within this framework, data is represented as natural language sentences
or drawn sketches, serving both informative and decision-making purposes. We
conducted validation tests for this framework, and the results are presented
and discussed.

</details>


### [150] [IncA-DES: An incremental and adaptive dynamic ensemble selection approach using online K-d tree neighborhood search for data streams with concept drift](https://arxiv.org/abs/2507.12573)
*Eduardo V. L. Barboza,Paulo R. Lisboa de Almeida,Alceu de Souza Britto Jr.,Robert Sabourin,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: 本文提出了一种名为IncA-DES的在线数据流分类框架，该方法重点解决了概念漂移问题，结合了新颖的训练策略、概念漂移检测器以及优化的在线K-d树算法，实验表明其在精度和处理时间上均有优势。


<details>
  <summary>Details</summary>
Motivation: 解决数据流中的概念漂移问题，尤其是在数据分布动态变化的情况下，提高分类器的性能和效率。

Method: 提出IncA-DES框架，它结合了局部专家训练、概念漂移检测器、分类过滤策略以及一种优化的在线K-d树算法。

Result: 该框架在实验中与七种先进方法相比获得了最高平均精度，并在大多数精确方法中展示了最短的处理时间，同时在线K-d树结合后处理速度更快，且精度损失可以忽略不计。

Conclusion: IncA-DES框架成功适应了数据流中的概念漂移，具有较高的分类精度和快速处理能力，适合不同标签可用性场景，其代码已公开可用。

Abstract: Data streams pose challenges not usually encountered in batch-based ML. One
of them is concept drift, which is characterized by the change in data
distribution over time. Among many approaches explored in literature, the
fusion of classifiers has been showing good results and is getting growing
attention. DS methods, due to the ensemble being instance-based, seem to be an
efficient choice under drifting scenarios. However, some attention must be paid
to adapting such methods for concept drift. The training must be done in order
to create local experts, and the commonly used neighborhood-search DS may
become prohibitive with the continuous arrival of data. In this work, we
propose IncA-DES, which employs a training strategy that promotes the
generation of local experts with the assumption that different regions of the
feature space become available with time. Additionally, the fusion of a concept
drift detector supports the maintenance of information and adaptation to a new
concept. An overlap-based classification filter is also employed in order to
avoid using the DS method when there is a consensus in the neighborhood, a
strategy that we argue every DS method should employ, as it was shown to make
them more applicable and quicker. Moreover, aiming to reduce the processing
time of the kNN, we propose an Online K-d tree algorithm, which can quickly
remove instances without becoming inconsistent and deals with unbalancing
concerns that may occur in data streams. Experimental results showed that the
proposed framework got the best average accuracy compared to seven
state-of-the-art methods considering different levels of label availability and
presented the smaller processing time between the most accurate methods.
Additionally, the fusion with the Online K-d tree has improved processing time
with a negligible loss in accuracy. We have made our framework available in an
online repository.

</details>


### [151] [Assay2Mol: large language model-based drug design using BioAssay context](https://arxiv.org/abs/2507.12574)
*Yifan Deng,Spencer S. Ericksen,Anthony Gitter*

Main category: cs.LG

TL;DR: 本文提出Assay2Mol，一种基于大型语言模型的工作流，用于从生化测试数据中生成候选药物分子，性能优于已有方法。


<details>
  <summary>Details</summary>
Motivation: 为解决未结构化文本难以利用的问题，并挖掘生化测试数据的潜力以推动早期药物发现。

Method: 设计Assay2Mol工作流，利用大型语言模型从生化测试记录中检索相似目标的测试数据，并通过上下文学习生成候选分子。

Result: Assay2Mol在生成目标蛋白分子的候选配体方面优于最新的机器学习方法，同时生成的分子更具合成性。

Conclusion: 通过利用生化测试记录中的未结构化数据，Assay2Mol显著提升了候选分子的生成效果，有助于加速药物开发过程。

Abstract: Scientific databases aggregate vast amounts of quantitative data alongside
descriptive text. In biochemistry, molecule screening assays evaluate the
functional responses of candidate molecules against disease targets.
Unstructured text that describes the biological mechanisms through which these
targets operate, experimental screening protocols, and other attributes of
assays offer rich information for new drug discovery campaigns but has been
untapped because of that unstructured format. We present Assay2Mol, a large
language model-based workflow that can capitalize on the vast existing
biochemical screening assays for early-stage drug discovery. Assay2Mol
retrieves existing assay records involving targets similar to the new target
and generates candidate molecules using in-context learning with the retrieved
assay screening data. Assay2Mol outperforms recent machine learning approaches
that generate candidate ligand molecules for target protein structures, while
also promoting more synthesizable molecule generation.

</details>


### [152] [Ranking Vectors Clustering: Theory and Applications](https://arxiv.org/abs/2507.12583)
*Ali Fattahi,Ali Eshragh,Babak Aslani,Meysam Rabiee*

Main category: cs.LG

TL;DR: 提出并研究一个名为k-centroids ranking vectors clustering (KRC)的问题，即将排名向量分为k个聚类，并确定每个聚类的中心。


<details>
  <summary>Details</summary>
Motivation: 解决传统k-means clustering方法不能直接应用于排名向量的局限性，尤其是在个性化和大规模决策领域中的需求。

Method: 提出KRCA近似算法，结合k-means的初始解决方案，并引入分支定界算法(BnB)通过决策树框架进行高效聚类。

Result: 通过理论误差边界验证KRCA和BnB算法的有效性，并通过合成和真实数据集的广泛实验验证了KRCA算法在解质量和计算时间上的显著提升。

Conclusion: KRC问题在个性化和大规模决策中具有实际意义，提出的方法不仅提升了解决质量，更为后续研究提供了方向。

Abstract: We study the problem of clustering ranking vectors, where each vector
represents preferences as an ordered list of distinct integers. Specifically,
we focus on the k-centroids ranking vectors clustering problem (KRC), which
aims to partition a set of ranking vectors into k clusters and identify the
centroid of each cluster. Unlike classical k-means clustering (KMC), KRC
constrains both the observations and centroids to be ranking vectors. We
establish the NP-hardness of KRC and characterize its feasible set. For the
single-cluster case, we derive a closed-form analytical solution for the
optimal centroid, which can be computed in linear time. To address the
computational challenges of KRC, we develop an efficient approximation
algorithm, KRCA, which iteratively refines initial solutions from KMC, referred
to as the baseline solution. Additionally, we introduce a branch-and-bound
(BnB) algorithm for efficient cluster reconstruction within KRCA, leveraging a
decision tree framework to reduce computational time while incorporating a
controlling parameter to balance solution quality and efficiency. We establish
theoretical error bounds for KRCA and BnB. Through extensive numerical
experiments on synthetic and real-world datasets, we demonstrate that KRCA
consistently outperforms baseline solutions, delivering significant
improvements in solution quality with fast computational times. This work
highlights the practical significance of KRC for personalization and
large-scale decision making, offering methodological advancements and insights
that can be built upon in future studies.

</details>


### [153] [Second-Order Bounds for [0,1]-Valued Regression via Betting Loss](https://arxiv.org/abs/2507.12584)
*Yinan Li,Kwang-Sung Jun*

Main category: cs.LG

TL;DR: 研究了 $[0,1]$ 值回归问题，在该框架中提出了一种新型的损失函数——赌博损失（betting loss）。该方法无需事先了解方差信息，即可获得改进的泛化界限。


<details>
  <summary>Details</summary>
Motivation: 旨在改进在 $[0,1]$ 值回归中的泛化界限，克服现有损失函数对方差或标签分布的明确建模依赖问题。

Method: 通过对比 log 损失函数和平方损失函数的泛化界限优劣，新提出了一个名为赌博损失（betting loss）的损失函数，并证明其具备适应方差变化的能力。

Result: 证明了赌博损失在没有先验方差信息的情况下，可实现比一阶界限优秀的二阶界限。

Conclusion: 赌博损失函数为 $[0,1]$ 值回归问题提供了一种无需显示模型化方差信息的改进方法，成功实现了泛化能力的提升。

Abstract: We consider the $[0,1]$-valued regression problem in the i.i.d. setting. In a
related problem called cost-sensitive classification, \citet{foster21efficient}
have shown that the log loss minimizer achieves an improved generalization
bound compared to that of the squared loss minimizer in the sense that the
bound scales with the cost of the best classifier, which can be arbitrarily
small depending on the problem at hand. Such a result is often called a
first-order bound. For $[0,1]$-valued regression, we first show that the log
loss minimizer leads to a similar first-order bound. We then ask if there
exists a loss function that achieves a variance-dependent bound (also known as
a second order bound), which is a strict improvement upon first-order bounds.
We answer this question in the affirmative by proposing a novel loss function
called the betting loss. Our result is ``variance-adaptive'' in the sense that
the bound is attained \textit{without any knowledge about the variance}, which
is in contrast to modeling label (or reward) variance or the label distribution
itself explicitly as part of the function class such as distributional
reinforcement learning.

</details>


### [154] [Are encoders able to learn landmarkers for warm-starting of Hyperparameter Optimization?](https://arxiv.org/abs/2507.12604)
*Antoni Zajko,Katarzyna Woźnica*

Main category: cs.LG

TL;DR: 研究针对表格数据的元学习任务提出了两种新的表示学习方法，但发现这些方法在实际应用中的表现提升有限。


<details>
  <summary>Details</summary>
Motivation: 目前针对异构表格数据进行元学习的表示学习问题缺乏有效解决方案。

Method: 提出两种针对超参数优化（HPO）冷启动任务设计的表示学习方法：一种是基于深度度量学习，另一种是基于标杆重构。

Result: 结果表明，两种方法都能学习与标杆对齐的表示，但未能显著提升在超参数优化冷启动任务中的表现。

Conclusion: 尽管提出的方法在表示学习上取得了一定效果，但其在目标任务的实际应用中未实现预期的优化性能。

Abstract: Effectively representing heterogeneous tabular datasets for meta-learning
purposes is still an open problem. Previous approaches rely on representations
that are intended to be universal. This paper proposes two novel methods for
tabular representation learning tailored to a specific meta-task -
warm-starting Bayesian Hyperparameter Optimization. Both follow the specific
requirement formulated by ourselves that enforces representations to capture
the properties of landmarkers. The first approach involves deep metric
learning, while the second one is based on landmarkers reconstruction. We
evaluate the proposed encoders in two ways. Next to the gain in the target
meta-task, we also use the degree of fulfillment of the proposed requirement as
the evaluation metric. Experiments demonstrate that while the proposed encoders
can effectively learn representations aligned with landmarkers, they may not
directly translate to significant performance gains in the meta-task of HPO
warm-starting.

</details>


### [155] [Learning What Matters: Probabilistic Task Selection via Mutual Information for Model Finetuning](https://arxiv.org/abs/2507.12612)
*Prateek Chanda,Saral Sureka,Parth Pratim Chatterjee,Krishnateja Killamsetty,Nikhil Shivakumar Nayak,Ganesh Ramakrishnan*

Main category: cs.LG

TL;DR: 本文提出TASKPGM，使用马尔可夫随机场最小化能量函数优化任务混合比例，提升LLM微调效果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM微调中，任务数据集的混合比例选择大多依赖直觉和启发式方法，难以系统优化。

Method: TASKPGM通过在马尔可夫随机场上最小化能量函数选择连续任务比例，并使用单任务模型预测分布的行为差异（如Jensen-Shannon散度和点互信息）来建模任务关系。

Result: 实验表明，TASKPGM在多个基准测试（MMLU、BIGBench）上提升了Llama 2和Mistral的性能，且具备解释性和理论保证，如弱次模性。

Conclusion: TASKPGM不仅能显著优化LLM微调任务组合，还提供了任务影响和混合成分的解释性洞见，为构建高效、稳健的LLM微调提供了新方法。

Abstract: The performance of finetuned large language models (LLMs) hinges critically
on the composition of the training mixture. However, selecting an optimal blend
of task datasets remains a largely manual, heuristic driven process, with
practitioners often relying on uniform or size based sampling strategies. We
introduce TASKPGM, a principled and scalable framework for mixture optimization
that selects continuous task proportions by minimizing an energy function over
a Markov Random Field (MRF). Task relationships are modeled using behavioral
divergences such as Jensen Shannon Divergence and Pointwise Mutual Information
computed from the predictive distributions of single task finetuned models. Our
method yields a closed form solution under simplex constraints and provably
balances representativeness and diversity among tasks. We provide theoretical
guarantees, including weak submodularity for budgeted variants, and demonstrate
consistent empirical improvements on Llama 2 and Mistral across evaluation
suites such as MMLU and BIGBench. Beyond performance, TASKPGM offers
interpretable insights into task influence and mixture composition, making it a
powerful tool for efficient and robust LLM finetuning.

</details>


### [156] [BootSeer: Analyzing and Mitigating Initialization Bottlenecks in Large-Scale LLM Training](https://arxiv.org/abs/2507.12619)
*Rui Li,Xiaoyun Zhi,Jinxin Chi,Menghan Yu,Lixin Huang,Jia Zhu,Weilun Zhang,Xing Ma,Wenjia Liu,Zhicheng Zhu,Daowen Luo,Zuquan Song,Xin Yin,Chao Xiang,Shuguang Wang,Wencong Xiao,Gene Cooperman*

Main category: cs.LG

TL;DR: 本文聚焦于解决大型语言模型训练中的启动开销问题，提出了优化框架Bootseer，用于减少启动瓶颈，实验表明其可以将启动时间减少50%。


<details>
  <summary>Details</summary>
Motivation: 大规模LLM训练场景中，启动开销对GPU资源有显著浪费，特别是在训练迭代与调试频繁的工业环境中，急需优化启动效率。

Method: 分析启动成本的组成与扩展性后，提出系统优化框架Bootseer，分别通过热区预取、依赖快照和分布式文件系统优化来减少启动开销。

Result: Bootseer在真实环境部署下证明可以有效减少50%的训练启动开销。

Conclusion: 优化启动开销对于提高大规模LLM训练效率至关重要，Bootseer提供了切实可行的解决方案，可显著减少资源浪费。

Abstract: Large Language Models (LLMs) have become a cornerstone of modern AI, driving
breakthroughs in natural language processing and expanding into multimodal jobs
involving images, audio, and video. As with most computational software, it is
important to distinguish between ordinary runtime performance and startup
overhead. Prior research has focused on runtime performance: improving training
efficiency and stability. This work focuses instead on the increasingly
critical issue of startup overhead in training: the delay before training jobs
begin execution. Startup overhead is particularly important in large,
industrial-scale LLMs, where failures occur more frequently and multiple teams
operate in iterative update-debug cycles. In one of our training clusters, more
than 3.5% of GPU time is wasted due to startup overhead alone.
  In this work, we present the first in-depth characterization of LLM training
startup overhead based on real production data. We analyze the components of
startup cost, quantify its direct impact, and examine how it scales with job
size. These insights motivate the design of Bootseer, a system-level
optimization framework that addresses three primary startup bottlenecks: (a)
container image loading, (b) runtime dependency installation, and (c) model
checkpoint resumption. To mitigate these bottlenecks, Bootseer introduces three
techniques: (a) hot block record-and-prefetch, (b) dependency snapshotting, and
(c) striped HDFS-FUSE. Bootseer has been deployed in a production environment
and evaluated on real LLM training workloads, demonstrating a 50% reduction in
startup overhead.

</details>


### [157] [Reasoning-Finetuning Repurposes Latent Representations in Base Models](https://arxiv.org/abs/2507.12638)
*Jake Ward,Chuqiao Lin,Constantin Venhoff,Neel Nanda*

Main category: cs.LG

TL;DR: 研究揭示反向追踪行为的动力来源于在基础模型激活中已存在的方向性，表明推理微调模型重用原有表示，而非全新学习能力。


<details>
  <summary>Details</summary>
Motivation: 探讨反向追踪行为在基于推理微调的模型中的起源及其潜在机制。

Method: 通过研究DeepSeek-R1-Distill-Llama-8B及其基础模型Llama-3.1-8B的残差流，识别并分析能够引发反向追踪的方向性，并探讨此方向性与基础模型的关系及在推理模型调控中的作用。

Result: 发现基础模型激活中的某一方向能够系统性地引发反向追踪行为，并证实此行为在推理微调过程中与现有表示的重用途径相关。

Conclusion: 推理微调模型是通过重用基础模型中已有的表示来构建新的行为回路，而非完全从头学习。

Abstract: Backtracking, an emergent behavior elicited by reasoning fine-tuning, has
been shown to be a key mechanism in reasoning models' enhanced capabilities.
Prior work has succeeded in manipulating this behavior via steering vectors,
but the underlying mechanism remains poorly understood. In this work, we show
that the emergence of backtracking in DeepSeek-R1-Distill-Llama-8B is in part
driven by a repurposed direction already present in base model activations.
Specifically, we identify a direction in base Llama-3.1-8B's residual stream
which systematically induces backtracking when used to steer the distilled
reasoning model, and find that the effects of steering with this direction
cannot be trivially explained by token-level attributes. We further find that
this direction does not induce backtracking in the base model, suggesting that
the reasoning finetuning process repurposes pre-existing representations to
form new behavioral circuits. Additionally, we hypothesize that this direction
is one of several which may work together to mediate backtracking. Our findings
offer a compelling picture that reasoning-finetuned models repurpose
pre-existing base model representations, rather than learn new capabilities
from scratch.

</details>


### [158] [Federated Learning in Open- and Closed-Loop EMG Decoding: A Privacy and Performance Perspective](https://arxiv.org/abs/2507.12652)
*Kai Malcolm,César Uribe,Momona Yamagami*

Main category: cs.LG

TL;DR: 本研究探讨了联邦学习（FL）在神经接口中的应用，通过利用高维肌电信号评估其性能和隐私保护能力。


<details>
  <summary>Details</summary>
Motivation: 针对神经信号的敏感性及数据隐私问题，研究如何在共享数据训练解码器时保护隐私，同时获得高性能解码能力。

Method: 基于FL进行神经解码，并在开放和闭环场景中评估其性能，调整FL以适应闭环单用户实时交互需要。

Result: 在开放场景中，FL优于本地学习，而在闭环单用户场景中，调整的FL方法性能不及本地学习，但后者隐私风险更高。

Conclusion: FL在隐私保护和性能上存在权衡，未来需开发适用于协作、自适应单用户应用的FL方法。

Abstract: Invasive and non-invasive neural interfaces hold promise as high-bandwidth
input devices for next-generation technologies. However, neural signals
inherently encode sensitive information about an individual's identity and
health, making data sharing for decoder training a critical privacy challenge.
Federated learning (FL), a distributed, privacy-preserving learning framework,
presents a promising solution, but it remains unexplored in closed-loop
adaptive neural interfaces. Here, we introduce FL-based neural decoding and
systematically evaluate its performance and privacy using high-dimensional
electromyography signals in both open- and closed-loop scenarios. In open-loop
simulations, FL significantly outperformed local learning baselines,
demonstrating its potential for high-performance, privacy-conscious neural
decoding. In contrast, closed-loop user studies required adapting FL methods to
accommodate single-user, real-time interactions, a scenario not supported by
standard FL. This modification resulted in local learning decoders surpassing
the adapted FL approach in closed-loop performance, yet local learning still
carried higher privacy risks. Our findings highlight a critical
performance-privacy tradeoff in real-time adaptive applications and indicate
the need for FL methods specifically designed for co-adaptive, single-user
applications.

</details>


### [159] [Improving physics-informed neural network extrapolation via transfer learning and adaptive activation functions](https://arxiv.org/abs/2507.12659)
*Athanasios Papastathopoulos-Katsaros,Alexandra Stavrianidi,Zhandong Liu*

Main category: cs.LG

TL;DR: 本文引入一个利用迁移学习(TL)方法改进物理信息神经网络(PINNs)外推性能的框架，同时提出自适应激活函数，实验表明该方法在不显著增加计算成本的情况下显著提高了模型外推鲁棒性与精度。


<details>
  <summary>Details</summary>
Motivation: 物理信息神经网络(PINNs)结合物理定律与数据驱动建模，在复杂科学与工程问题解决上显示出优势，但其外推性能较差且对激活函数的选择敏感，亟需改进。

Method: 提出迁移学习(TL)方法，在扩展训练域中利用少量精心选择的配点优化外推能力，同时设计线性组合的自适应激活函数以增强模型的鲁棒性和准确性。

Result: 实验验证表明，该方法使外推域内平均相对L2误差减少40%，平均绝对误差减少50%，且计算成本无显著增加。

Conclusion: 此研究通过迁移学习与自适应激活函数的结合，显著提升了PINNs的外推性能与精度，为复杂系统建模提供了有价值的方法。

Abstract: Physics-Informed Neural Networks (PINNs) are deep learning models that
incorporate the governing physical laws of a system into the learning process,
making them well-suited for solving complex scientific and engineering
problems. Recently, PINNs have gained widespread attention as a powerful
framework for combining physical principles with data-driven modeling to
improve prediction accuracy. Despite their successes, however, PINNs often
exhibit poor extrapolation performance outside the training domain and are
highly sensitive to the choice of activation functions (AFs). In this paper, we
introduce a transfer learning (TL) method to improve the extrapolation
capability of PINNs. Our approach applies transfer learning (TL) within an
extended training domain, using only a small number of carefully selected
collocation points. Additionally, we propose an adaptive AF that takes the form
of a linear combination of standard AFs, which improves both the robustness and
accuracy of the model. Through a series of experiments, we demonstrate that our
method achieves an average of 40% reduction in relative L2 error and an average
of 50% reduction in mean absolute error in the extrapolation domain, all
without a significant increase in computational cost. The code is available at
https://github.com/LiuzLab/PINN-extrapolation .

</details>


### [160] [Data Transformation Strategies to Remove Heterogeneity](https://arxiv.org/abs/2507.12677)
*Sangbong Yoo,Jaeyoung Lee,Chanyoung Yoon,Geonyeong Son,Hyein Hong,Seongbum Seo,Soobin Yim,Chanyoung Jung,Jungsoo Park,Misuk Kim,Yun Jang*

Main category: cs.LG

TL;DR: 本研究探讨数据异质性问题，综述当前数据转换方法以应对数据格式上的差异。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能应用扩展，数据转换的重要性不断上升，需更高效的数据准备流程对训练数据进行优化并适配多样化模型输入。

Method: 系统分类并总结现有策略，聚焦处理由数据格式差异引起的异质性挑战。

Result: 提供了当前数据转换方法的全面综述，并指出每种策略所涉及的挑战。

Conclusion: 数据转换是解决数据异质性问题的关键，其方法的合理选择对人工智能效率的优化至关重要。

Abstract: Data heterogeneity is a prevalent issue, stemming from various conflicting
factors, making its utilization complex. This uncertainty, particularly
resulting from disparities in data formats, frequently necessitates the
involvement of experts to find resolutions. Current methodologies primarily
address conflicts related to data structures and schemas, often overlooking the
pivotal role played by data transformation. As the utilization of artificial
intelligence (AI) continues to expand, there is a growing demand for a more
streamlined data preparation process, and data transformation becomes
paramount. It customizes training data to enhance AI learning efficiency and
adapts input formats to suit diverse AI models. Selecting an appropriate
transformation technique is paramount in preserving crucial data details.
Despite the widespread integration of AI across various industries,
comprehensive reviews concerning contemporary data transformation approaches
are scarce. This survey explores the intricacies of data heterogeneity and its
underlying sources. It systematically categorizes and presents strategies to
address heterogeneity stemming from differences in data formats, shedding light
on the inherent challenges associated with each strategy.

</details>


### [161] [PinFM: Foundation Model for User Activity Sequences at a Billion-scale Visual Discovery Platform](https://arxiv.org/abs/2507.12704)
*Xiangyi Chen,Kousik Rajesh,Matthew Lawhon,Zelun Wang,Hanyu Li,Haomiao Li,Saurabh Vishwas Joshi,Pong Eksombatchai,Jaewon Yang,Yi-Ping Hsu,Jiajing Xu,Charles Rosenberg*

Main category: cs.LG

TL;DR: 本文介绍了PinFM，一个用于理解用户活动序列并应用于推荐系统的基础模型。在Pinterest的应用中，其性能极大提升。


<details>
  <summary>Details</summary>
Motivation: 解决用户活动序列在推荐系统中的处理问题，并应对百万级项目推荐中的成本和延迟限制。

Method: 预训练一个具有20亿参数的Transformer模型，并通过Deduplicated Cross-Attention Transformer (DCAT)等优化技术提高模型效能。

Result: 优化使内部数据的处理效率提高了600%，并实现了新项目交互点击率提升20%。

Conclusion: PinFM成功部署于Pinterest平台，为超过5亿用户提供推荐服务，大幅改进用户体验。

Abstract: User activity sequences have emerged as one of the most important signals in
recommender systems. We present a foundational model, PinFM, for understanding
user activity sequences across multiple applications at a billion-scale visual
discovery platform. We pretrain a transformer model with 20B+ parameters using
extensive user activity data, then fine-tune it for specific applications,
efficiently coupling it with existing models. While this
pretraining-and-fine-tuning approach has been popular in other domains, such as
Vision and NLP, its application in industrial recommender systems presents
numerous challenges. The foundational model must be scalable enough to score
millions of items every second while meeting tight cost and latency constraints
imposed by these systems. Additionally, it should capture the interactions
between user activities and other features and handle new items that were not
present during the pretraining stage.
  We developed innovative techniques to address these challenges. Our
infrastructure and algorithmic optimizations, such as the Deduplicated
Cross-Attention Transformer (DCAT), improved our throughput by 600% on
Pinterest internal data. We demonstrate that PinFM can learn interactions
between user sequences and candidate items by altering input sequences, leading
to a 20% increase in engagement with new items. PinFM is now deployed to help
improve the experience of more than a half billion users across various
applications.

</details>


### [162] [From SGD to Spectra: A Theory of Neural Network Weight Dynamics](https://arxiv.org/abs/2507.12709)
*Brian Richard Olsen,Sam Fatehmanesh,Frank Xiao,Adarsh Kumarappan,Anirudh Gajula*

Main category: cs.LG

TL;DR: 此论文研究了深度学习中SGD的动态，提出了一个基于连续时间矩阵值随机微分方程(SDE)的理论框架，解释了深度学习中权重矩阵奇异值谱的演变。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型的训练机制虽然在实际中表现卓越，但其理论基础尚不明确，作者希望通过研究解析SGD动力学与权重矩阵谱演变的联系，揭示深度学习为何有效。

Method: 提出了一个基于连续时间矩阵值随机微分方程(SDE)的框架，通过推导平方奇异值的演变规律，得出其遵循戴森布朗运动，并用Gamma型分布表征其平稳分布。

Result: 在Transformer和MLP架构上进行了控制实验，验证了理论预测和SDE推导与实际观测的特征谱演变之间的一致性。

Conclusion: 论文提供了一个严格的理论基础，解释了深度学习中的“主干+尾部”奇异值谱结构，增强了对深度学习为何有效的理解。

Abstract: Deep neural networks have revolutionized machine learning, yet their training
dynamics remain theoretically unclear-we develop a continuous-time,
matrix-valued stochastic differential equation (SDE) framework that rigorously
connects the microscopic dynamics of SGD to the macroscopic evolution of
singular-value spectra in weight matrices. We derive exact SDEs showing that
squared singular values follow Dyson Brownian motion with eigenvalue repulsion,
and characterize stationary distributions as gamma-type densities with
power-law tails, providing the first theoretical explanation for the
empirically observed 'bulk+tail' spectral structure in trained networks.
Through controlled experiments on transformer and MLP architectures, we
validate our theoretical predictions and demonstrate quantitative agreement
between SDE-based forecasts and observed spectral evolution, providing a
rigorous foundation for understanding why deep learning works.

</details>


### [163] [Multimodal-Guided Dynamic Dataset Pruning for Robust and Efficient Data-Centric Learning](https://arxiv.org/abs/2507.12750)
*Suorong Yang,Peijia Li,Yujie Liu,Zhiming Xu,Peng Ye,Wanli Ouyang,Furao Shen,Dongzhan Zhou*

Main category: cs.LG

TL;DR: 提出了一种动态数据集修剪框架，通过任务驱动的难度和跨模态语义一致性自适应地选择训练样本。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖静态启发式或特定任务指标，导致鲁棒性和普适性受限的问题。

Method: 引入动态数据集修剪框架，结合预训练的多模态基础模型监督，通过捕获训练动态及过滤无信息样本实现。

Result: 通过整合跨模态对齐技术，有效提高样本选择的鲁棒性与数据集修剪效率。

Conclusion: 提出的方法在数据集修剪方面表现出了更加高效和鲁棒的潜力，推进了数据中心学习实践。

Abstract: Modern deep models are trained on large real-world datasets, where data
quality varies and redundancy is common. Data-centric approaches such as
dataset pruning have shown promise in improving training efficiency and model
performance. However, most existing methods rely on static heuristics or
task-specific metrics, limiting their robustness and generalizability across
domains. In this work, we introduce a dynamic dataset pruning framework that
adaptively selects training samples based on both task-driven difficulty and
cross-modality semantic consistency. By incorporating supervision from
pretrained multimodal foundation models, our approach captures training
dynamics while effectively filtering out uninformative samples. Our work
highlights the potential of integrating cross-modality alignment for robust
sample selection, advancing data-centric learning toward more efficient and
robust practices across application domains.

</details>


### [164] [Layer Separation Deep Learning Model with Auxiliary Variables for Partial Differential Equations](https://arxiv.org/abs/2507.12766)
*Yaru Liu,Yiqi Gu*

Main category: cs.LG

TL;DR: 本文提出了一种名为层分离（LySep）的优化框架，通过分解深度神经网络的架构以提升深度学习解决偏微分方程的效果。


<details>
  <summary>Details</summary>
Motivation: 针对深度学习中损失函数的高度非凸性，使现有优化算法容易陷入次优局部最小值或遭遇梯度爆炸和消失的问题。

Method: 引入辅助变量以分离神经网络的各层，将深度架构分解为一系列浅层结构，同时设计新损失函数并基于交替方向开发算法。

Result: 给出了与原深度模型一致性的理论分析，高维数值验证显示了LySep在损失最小化和解误差减少方面的优势。

Conclusion: LySep模型通过有效优化克服了深度学习中常见的优化障碍，提升了解偏微分方程的性能。

Abstract: In this paper, we propose a new optimization framework, the layer separation
(LySep) model, to improve the deep learning-based methods in solving partial
differential equations. Due to the highly non-convex nature of the loss
function in deep learning, existing optimization algorithms often converge to
suboptimal local minima or suffer from gradient explosion or vanishing,
resulting in poor performance. To address these issues, we introduce auxiliary
variables to separate the layers of deep neural networks. Specifically, the
output and its derivatives of each layer are represented by auxiliary
variables, effectively decomposing the deep architecture into a series of
shallow architectures. New loss functions with auxiliary variables are
established, in which only variables from two neighboring layers are coupled.
Corresponding algorithms based on alternating directions are developed, where
many variables can be updated optimally in closed forms. Moreover, we provide
theoretical analyses demonstrating the consistency between the LySep model and
the original deep model. High-dimensional numerical results validate our theory
and demonstrate the advantages of LySep in minimizing loss and reducing
solution error.

</details>


### [165] [A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models](https://arxiv.org/abs/2507.12774)
*Weijieying Ren,Jingxi Zhu,Zehao Liu,Tianxiang Zhao,Vasant Honavar*

Main category: cs.LG

TL;DR: 本文综述了深度学习和大语言模型(LLMs)在电子健康记录(EHR)建模中的最新进展，重点探讨五大关键设计维度，并总结方法、趋势及未来挑战。


<details>
  <summary>Details</summary>
Motivation: EHR数据的异质性、时间不规则性及领域特异性使得建模面临挑战，作者希望通过梳理和分析已有研究，为推动AI在EHR中的应用提供参考。

Method: 本文提出了一个关于EHR建模的统一分类方法，涵盖五大设计维度：数据质量提升、神经网络结构设计、学习策略、跨模态学习以及基于LLM的建模系统。同时对不同维度下的代表方法进行回顾。

Result: 文章总结了包括基础模型、LLM驱动临床代理及EHR到文本翻译等新兴趋势，并讨论了当前研究中的开放挑战，如基准测试、可解释性、临床对齐和跨场景泛化问题。

Conclusion: 通过系统化分析和总结，本文为AI驱动的EHR建模和临床决策支持提供了结构化的研究蓝图，为学术界和医疗实践者提供了重要参考。

Abstract: Artificial intelligence (AI) has demonstrated significant potential in
transforming healthcare through the analysis and modeling of electronic health
records (EHRs). However, the inherent heterogeneity, temporal irregularity, and
domain-specific nature of EHR data present unique challenges that differ
fundamentally from those in vision and natural language tasks. This survey
offers a comprehensive overview of recent advancements at the intersection of
deep learning, large language models (LLMs), and EHR modeling. We introduce a
unified taxonomy that spans five key design dimensions: data-centric
approaches, neural architecture design, learning-focused strategies, multimodal
learning, and LLM-based modeling systems. Within each dimension, we review
representative methods addressing data quality enhancement, structural and
temporal representation, self-supervised learning, and integration with
clinical knowledge. We further highlight emerging trends such as foundation
models, LLM-driven clinical agents, and EHR-to-text translation for downstream
reasoning. Finally, we discuss open challenges in benchmarking, explainability,
clinical alignment, and generalization across diverse clinical settings. This
survey aims to provide a structured roadmap for advancing AI-driven EHR
modeling and clinical decision support. For a comprehensive list of EHR-related
methods, kindly refer to https://survey-on-tabular-data.github.io/.

</details>


### [166] [Multi-Channel Graph Neural Network for Financial Risk Prediction of NEEQ Enterprises](https://arxiv.org/abs/2507.12787)
*Jianyu Zhu*

Main category: cs.LG

TL;DR: 提出了一个多通道深度学习框架用于对全国中小企业股份转让系统（新三板）中小企业的财务风险预测，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决新三板中小企业因规模小、财务抗风险能力低导致财务困境风险较高的问题。

Method: 设计了一种三通道图同构网络，结合财务指标、文本披露和企业关系数据进行风险预测，并通过注意力机制和门控单元提升表现。

Result: 模型在7,731家实际新三板公司数据上显著优于传统机器学习和单模态基线模型，在AUC、Precision、Recall和F1 Score上表现卓越。

Conclusion: 为中小企业风险建模提供理论支持，并向金融监管部门和投资者提供数据驱动工具。

Abstract: With the continuous evolution of China's multi-level capital market, the
National Equities Exchange and Quotations (NEEQ), also known as the "New Third
Board," has become a critical financing platform for small and medium-sized
enterprises (SMEs). However, due to their limited scale and financial
resilience, many NEEQ-listed companies face elevated risks of financial
distress. To address this issue, we propose a multi-channel deep learning
framework that integrates structured financial indicators, textual disclosures,
and enterprise relationship data for comprehensive financial risk prediction.
Specifically, we design a Triple-Channel Graph Isomorphism Network (GIN) that
processes numeric, textual, and graph-based inputs separately. These
modality-specific representations are fused using an attention-based mechanism
followed by a gating unit to enhance robustness and prediction accuracy.
Experimental results on data from 7,731 real-world NEEQ companies demonstrate
that our model significantly outperforms traditional machine learning methods
and single-modality baselines in terms of AUC, Precision, Recall, and F1 Score.
This work provides theoretical and practical insights into risk modeling for
SMEs and offers a data-driven tool to support financial regulators and
investors.

</details>


### [167] [FLDmamba: Integrating Fourier and Laplace Transform Decomposition with Mamba for Enhanced Time Series Prediction](https://arxiv.org/abs/2507.12803)
*Qianru Zhang,Chenglei Yu,Haixin Wang,Yudong Yan,Yuansheng Cao,Siu-Ming Yiu,Tailin Wu,Hongzhi Yin*

Main category: cs.LG

TL;DR: 本文提出FLDmamba框架，结合傅里叶和拉普拉斯变换，解决了时间序列预测中的多尺度周期性、瞬时动态和数据噪声问题，在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决时间序列预测中的非平稳性、多尺度周期性和瞬时动态问题，同时提升模型应对长时间预测和数据噪声的能力。

Method: 提出FLDmamba框架，结合傅里叶变换和拉普拉斯变换，捕捉时间序列数据中的多尺度周期性和瞬时动态，并增强模型对数据噪声的鲁棒性。

Result: FLDmamba在时间序列预测的基准测试中优于基于Transformer和其他Mamba的架构。

Conclusion: FLDmamba有效提高了时间序列预测的性能，同时实现高效性和鲁棒性，适合长时间预测情景，代码和数据已公开以支持方法复现。

Abstract: Time series prediction, a crucial task across various domains, faces
significant challenges due to the inherent complexities of time series data,
including non-stationarity, multi-scale periodicity, and transient dynamics,
particularly when tackling long-term predictions. While Transformer-based
architectures have shown promise, their quadratic complexity with sequence
length hinders their efficiency for long-term predictions. Recent advancements
in State-Space Models, such as Mamba, offer a more efficient alternative for
long-term modeling, but they cannot capture multi-scale periodicity and
transient dynamics effectively. Meanwhile, they are susceptible to data noise
issues in time series. This paper proposes a novel framework, FLDmamba (Fourier
and Laplace Transform Decomposition Mamba), addressing these limitations.
FLDmamba leverages the strengths of both Fourier and Laplace transforms to
effectively capture both multi-scale periodicity, transient dynamics within
time series data, and improve the robustness of the model to the data noise
issue. Our extensive experiments demonstrate that FLDmamba achieves superior
performance on time series prediction benchmarks, outperforming both
Transformer-based and other Mamba-based architectures. To promote the
reproducibility of our method, we have made both the code and data accessible
via the following
URL:{\href{https://github.com/AI4Science-WestlakeU/FLDmamba}{https://github.com/AI4Science-WestlakeU/\model}.

</details>


### [168] [PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database](https://arxiv.org/abs/2507.12805)
*Hui Sun,Yanfeng Ding,Liping Yi,Huidong Ma,Gang Wang,Xiaoguang Liu,Cheng Zhong,Wentong Cai*

Main category: cs.LG

TL;DR: 提出一种名为PMKLC的学习型无损压缩器框架，能够显著提升压缩比、吞吐量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现有学习型无损压缩器压缩比低、吞吐量低和鲁棒性差的问题，满足大规模基因组数据库备份和数据管理需求。

Method: 1. 提出自动化多知识学习压缩框架以提高压缩比和鲁棒性；2. 设计GPU加速的($s$,$k$)-mer编码优化吞吐量和资源使用；3. 引入数据块分割和分步模型传递机制以实现并行加速；4. 提供两种压缩模式，满足不同场景需求。

Result: 在15个真实数据集测试上，相较于14个基线算法，PMKLC-S/M平均压缩比最高提升73.609%和73.480%，平均吞吐量改善至多达到3.036倍和10.710倍，同时性能更加稳定，具备更高鲁棒性和较低内存成本。

Conclusion: PMKLC极大提升了基因组数据压缩的性能和适用性，可为资源受限的设备和多样化应用场景提供高效率解决方案。

Abstract: Learning-based lossless compressors play a crucial role in large-scale
genomic database backup, storage, transmission, and management. However, their
1) inadequate compression ratio, 2) low compression \& decompression
throughput, and 3) poor compression robustness limit their widespread adoption
and application in both industry and academia. To solve those challenges, we
propose a novel \underline{P}arallel \underline{M}ulti-\underline{K}nowledge
\underline{L}earning-based \underline{C}ompressor (PMKLC) with four crucial
designs: 1) We propose an automated multi-knowledge learning-based compression
framework as compressors' backbone to enhance compression ratio and robustness;
2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compression
throughput and computing resource usage; 3) we introduce data block
partitioning and Step-wise Model Passing (SMP) mechanisms for parallel
acceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meet
the complex application scenarios, where the former runs on a
resource-constrained single GPU and the latter is multi-GPU accelerated. We
benchmark PMKLC-S/M and 14 baselines (7 traditional and 7 leaning-based) on 15
real-world datasets with different species and data sizes. Compared to
baselines on the testing datasets, PMKLC-S/M achieve the average compression
ratio improvement up to 73.609\% and 73.480\%, the average throughput
improvement up to 3.036$\times$ and 10.710$\times$, respectively. Besides,
PMKLC-S/M also achieve the best robustness and competitive memory cost,
indicating its greater stability against datasets with different probability
distribution perturbations, and its strong ability to run on memory-constrained
devices.

</details>


### [169] [RONOM: Reduced-Order Neural Operator Modeling](https://arxiv.org/abs/2507.12814)
*Sven Dummer,Dongwei Ye,Christoph Brune*

Main category: cs.LG

TL;DR: 该论文提出一种称为RONOM的框架，将降阶建模(ROM)和算子学习相结合，用于求解随时间变化的偏微分方程，并提供了误差分析和数值比较。


<details>
  <summary>Details</summary>
Motivation: 物理建模中随时间变化的偏微分方程计算复杂，传统降阶模型难以处理不同离散网格的问题。神经算子技术虽有灵活性但缺乏误差定量分析。

Method: 提出RONOM框架，将ROM的误差估计方法与神经算子的无限维函数空间映射能力相结合，提供新的离散误差边界和数值稳定性分析，并进行了数值比较实验。

Result: 实验表明，RONOM在输入泛化、空间超分辨率和离散鲁棒性方面性能优异，同时在时间超分辨率上具有新颖表现。

Conclusion: RONOM框架兼具ROM的理论分析与神经算子的灵活性，为解决复杂偏微分方程提供了高效方法。

Abstract: Time-dependent partial differential equations are ubiquitous in physics-based
modeling, but they remain computationally intensive in many-query scenarios,
such as real-time forecasting, optimal control, and uncertainty quantification.
Reduced-order modeling (ROM) addresses these challenges by constructing a
low-dimensional surrogate model but relies on a fixed discretization, which
limits flexibility across varying meshes during evaluation. Operator learning
approaches, such as neural operators, offer an alternative by parameterizing
mappings between infinite-dimensional function spaces, enabling adaptation to
data across different resolutions. Whereas ROM provides rigorous numerical
error estimates, neural operator learning largely focuses on discretization
convergence and invariance without quantifying the error between the
infinite-dimensional and the discretized operators. This work introduces the
reduced-order neural operator modeling (RONOM) framework, which bridges
concepts from ROM and operator learning. We establish a discretization error
bound analogous to those in ROM, and get insights into RONOM's discretization
convergence and discretization robustness. Moreover, two numerical examples are
presented that compare RONOM to existing neural operators for solving partial
differential equations. The results demonstrate that RONOM using standard
vector-to-vector neural networks achieves comparable performance in input
generalization and superior performance in both spatial super-resolution and
discretization robustness, while also offering novel insights into temporal
super-resolution scenarios.

</details>


### [170] [From Novelty to Imitation: Self-Distilled Rewards for Offline Reinforcement Learning](https://arxiv.org/abs/2507.12815)
*Gaurav Chaudhary,Laxmidhar Behera*

Main category: cs.LG

TL;DR: ReLOAD利用操作简单的随机网络蒸馏生成奖励信号，无需手动标注奖励，实验表明其效果与传统方法相当。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习需要大量数据进行奖励标注，这是昂贵且难以操作的，本研究旨在通过自动化方法解决这一问题。

Method: 提出ReLOAD框架，基于专家状态转变，通过随机网络蒸馏生成嵌入误差作为奖励信号，避免手动标注奖励。

Result: ReLOAD在D4RL基准测试中表现出色，达到了与传统标注奖励方法相当的性能。

Conclusion: ReLOAD提出了一种无需复杂标注奖励的高效离线强化学习方法，为离线强化学习领域提供了新的可能性。

Abstract: Offline Reinforcement Learning (RL) aims to learn effective policies from a
static dataset without requiring further agent-environment interactions.
However, its practical adoption is often hindered by the need for explicit
reward annotations, which can be costly to engineer or difficult to obtain
retrospectively. To address this, we propose ReLOAD (Reinforcement Learning
with Offline Reward Annotation via Distillation), a novel reward annotation
framework for offline RL. Unlike existing methods that depend on complex
alignment procedures, our approach adapts Random Network Distillation (RND) to
generate intrinsic rewards from expert demonstrations using a simple yet
effective embedding discrepancy measure. First, we train a predictor network to
mimic a fixed target network's embeddings based on expert state transitions.
Later, the prediction error between these networks serves as a reward signal
for each transition in the static dataset. This mechanism provides a structured
reward signal without requiring handcrafted reward annotations. We provide a
formal theoretical construct that offers insights into how RND prediction
errors effectively serve as intrinsic rewards by distinguishing expert-like
transitions. Experiments on the D4RL benchmark demonstrate that ReLOAD enables
robust offline policy learning and achieves performance competitive with
traditional reward-annotated methods.

</details>


### [171] [Understanding the Evolution of the Neural Tangent Kernel at the Edge of Stability](https://arxiv.org/abs/2507.12837)
*Kaiqi Jiang,Jeremy Cohen,Yuanzhi Li*

Main category: cs.LG

TL;DR: 本论文研究了在边缘稳定性(EoS)期间，神经切线核(NTK)特征向量的动力学变化。


<details>
  <summary>Details</summary>
Motivation: 近年来，虽然对NTK的特性和特征向量行为已有一定研究，但对于EoS期间NTK特征向量的行为却缺乏理解。

Method: 通过实验在不同的神经网络架构中观察特征向量的变化，并对两层线性网络进行理论分析。

Result: 较大的学习率会导致最终NTK的主要特征向量和训练目标的对齐性更强。

Conclusion: 研究加深了对深度学习中梯度下降训练动力学的理解。

Abstract: The study of Neural Tangent Kernels (NTKs) in deep learning has drawn
increasing attention in recent years. NTKs typically actively change during
training and are related to feature learning. In parallel, recent work on
Gradient Descent (GD) has found a phenomenon called Edge of Stability (EoS), in
which the largest eigenvalue of the NTK oscillates around a value inversely
proportional to the step size. However, although follow-up works have explored
the underlying mechanism of such eigenvalue behavior in depth, the
understanding of the behavior of the NTK eigenvectors during EoS is still
missing. This paper examines the dynamics of NTK eigenvectors during EoS in
detail. Across different architectures, we observe that larger learning rates
cause the leading eigenvectors of the final NTK, as well as the full NTK
matrix, to have greater alignment with the training target. We then study the
underlying mechanism of this phenomenon and provide a theoretical analysis for
a two-layer linear network. Our study enhances the understanding of GD training
dynamics in deep learning.

</details>


### [172] [A Kernel Distribution Closeness Testing](https://arxiv.org/abs/2507.12843)
*Zhijian Zhou,Liuhua Peng,Xunye Tian,Feng Liu*

Main category: cs.LG

TL;DR: 本文提出了一种改进的分布检测方法NAMMD, 通过适应分布的再生核希尔伯特空间(RKHS)范数对最大均值差(MMD)进行改进, 用于评估分布对间的紧密程度, 并应用于检测与两样本检验任务中, 实验和理论表明其性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的分布检测方法主要基于离散一维空间分布间的差异测量, 无法有效处理复杂数据(如图像分布)。为了扩大适用范围, 作者引入了MMD作为分布差异测量工具, 但发现其可能对不同范数分布对输出相同值, 影响检测能力。

Method: 设计了基于分布RKHS范数进行缩放的NAMMD, 提高标准MMD的分辨力。在理论分析其渐近分布并提出基于NAMMD的分布检测方法的同时, 还拓展至双样本检验任务。

Result: 提出的NAMMD在理论和实践测试中, 在多个数据类型中(例如合成噪声、真实图像)都展现出优于传统MMD的检测能力和Ⅰ型错误控制。

Conclusion: NAMMD扩展了传统的分布检测和样本检验方法, 不仅在理论上具有更高的检测能力, 在实践中也显示更优的性能, 为处理复杂数据分布检测问题提供了一种有效工具。

Abstract: The distribution closeness testing (DCT) assesses whether the distance
between a distribution pair is at least $\epsilon$-far. Existing DCT methods
mainly measure discrepancies between a distribution pair defined on discrete
one-dimensional spaces (e.g., using total variation), which limits their
applications to complex data (e.g., images). To extend DCT to more types of
data, a natural idea is to introduce maximum mean discrepancy (MMD), a powerful
measurement of the distributional discrepancy between two complex
distributions, into DCT scenarios. However, we find that MMD's value can be the
same for many pairs of distributions that have different norms in the same
reproducing kernel Hilbert space (RKHS), making MMD less informative when
assessing the closeness levels for multiple distribution pairs. To mitigate the
issue, we design a new measurement of distributional discrepancy, norm-adaptive
MMD (NAMMD), which scales MMD's value using the RKHS norms of distributions.
Based on the asymptotic distribution of NAMMD, we finally propose the
NAMMD-based DCT to assess the closeness levels of a distribution pair.
Theoretically, we prove that NAMMD-based DCT has higher test power compared to
MMD-based DCT, with bounded type-I error, which is also validated by extensive
experiments on many types of data (e.g., synthetic noise, real images).
Furthermore, we also apply the proposed NAMMD for addressing the two-sample
testing problem and find NAMMD-based two-sample test has higher test power than
the MMD-based two-sample test in both theory and experiments.

</details>


### [173] [Transformer-Based Person Identification via Wi-Fi CSI Amplitude and Phase Perturbations](https://arxiv.org/abs/2507.12854)
*Danilo Avola,Andrea Bernardini,Francesco Danese,Mario Lezoche,Maurizio Mancini,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 我们提出了一种基于Transformer的方法，用于通过静止情况下的Wi-Fi信号完成人类身份识别，在包含六个参与者的实验中达到了99.82%的分类精度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Wi-Fi的身份识别方法大多依赖于用户的运动信息（如步态），静止情况下的身份识别尚未被充分研究。

Method: 利用改进的信号预处理管道处理Wi-Fi信道状态信息 (CSI)，并且设计了一个双分支Transformer架构，分别处理幅度和相位数据。

Result: 在控制环境下的实验中，该方法在六名参与者的测试中实现了99.82%的分类准确率，优于现有卷积和多层感知器基准。

Conclusion: 研究表明，基于CSI的扰动具备区分性强的生物特征编码能力，能够在真实环境下通过低成本的Wi-Fi设备实现非侵入式、设备无依赖的人类身份识别。

Abstract: Wi-Fi sensing is gaining momentum as a non-intrusive and privacy-preserving
alternative to vision-based systems for human identification. However, person
identification through wireless signals, particularly without user motion,
remains largely unexplored. Most prior wireless-based approaches rely on
movement patterns, such as walking gait, to extract biometric cues. In
contrast, we propose a transformer-based method that identifies individuals
from Channel State Information (CSI) recorded while the subject remains
stationary. CSI captures fine-grained amplitude and phase distortions induced
by the unique interaction between the human body and the radio signal. To
support evaluation, we introduce a dataset acquired with ESP32 devices in a
controlled indoor environment, featuring six participants observed across
multiple orientations. A tailored preprocessing pipeline, including outlier
removal, smoothing, and phase calibration, enhances signal quality. Our
dual-branch transformer architecture processes amplitude and phase modalities
separately and achieves 99.82\% classification accuracy, outperforming
convolutional and multilayer perceptron baselines. These results demonstrate
the discriminative potential of CSI perturbations, highlighting their capacity
to encode biometric traits in a consistent manner. They further confirm the
viability of passive, device-free person identification using low-cost
commodity Wi-Fi hardware in real-world settings.

</details>


### [174] [Supervised Fine Tuning on Curated Data is Reinforcement Learning (and can be improved)](https://arxiv.org/abs/2507.12856)
*Chongli Qin,Jost Tobias Springenberg*

Main category: cs.LG

TL;DR: 本文探讨将行为克隆与强化学习目标相结合，提出了一种加权的监督微调方法iw-SFT，表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有的行为克隆作为一种监督微调方式效果较好，研究背后的理论依据以及潜在改进方向。

Method: 通过对行为克隆与强化学习目标之间的联系进行深入分析，提出了一种加权的重要性监督微调（iw-SFT）。

Result: iw-SFT优化了更紧密的强化学习目标，较传统监督微调方法在性能上有所提升。

Conclusion: iw-SFT是一种易于实现且通用性强的改进方法，在大型语言模型和连续控制任务中，与先进的强化学习算法表现竞争。

Abstract: Behavior Cloning (BC) on curated (or filtered) data is the predominant
paradigm for supervised fine-tuning (SFT) of large language models; as well as
for imitation learning of control policies. Here, we draw on a connection
between this successful strategy and the theory and practice of finding optimal
policies via Reinforcement Learning (RL). Building on existing literature, we
clarify that SFT can be understood as maximizing a lower bound on the RL
objective in a sparse reward setting. Giving support to its often observed good
performance. From this viewpoint, we realize that a small modification to SFT
leads to an importance weighted variant that behaves closer to training with RL
as it: i) optimizes a tighter bound to the RL objective and, ii) can improve
performance compared to SFT on curated data. We refer to this variant as
importance weighted supervised fine-tuning (iw-SFT). We show that it is easy to
implement and can be further generalized to training with quality scored data.
The resulting SFT variants are competitive with more advanced RL algorithms for
large language models and for training policies in continuous control tasks.
For example achieving 66.7% on the AIME 2024 dataset.

</details>


### [175] [An Investigation of Ear-EEG Signals for a Novel Biometric Authentication System](https://arxiv.org/abs/2507.12873)
*Danilo Avola,Giancarlo Crocetti,Gian Luca Foresti,Daniele Pannone,Claudio Piciarelli,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 该研究探讨了利用耳部脑电图(ear-EEG)信号进行生物身份认证的可行性，并通过深度神经网络实现82%的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统基于头皮电极的脑电图生物识别系统虽然安全，但其使用不够便捷，因此需要开发日常经济友好的替代方法。

Method: 提出一个基于耳-EEG信号的新框架，通过提取时域和频域特征，将这些特征输入到全连接深度神经网络进行身份认证。

Result: 实验结果显示，在耳-EEG数据集上实现了82%的平均准确率，验证了该方法的可行性。

Conclusion: 研究结果表明耳-EEG信号可作为下一代日常生物识别系统的可行方向，并具有良好的部署潜力。

Abstract: This work explores the feasibility of biometric authentication using EEG
signals acquired through in-ear devices, commonly referred to as ear-EEG.
Traditional EEG-based biometric systems, while secure, often suffer from low
usability due to cumbersome scalp-based electrode setups. In this study, we
propose a novel and practical framework leveraging ear-EEG signals as a
user-friendly alternative for everyday biometric authentication. The system
extracts an original combination of temporal and spectral features from ear-EEG
signals and feeds them into a fully connected deep neural network for subject
identification. Experimental results on the only currently available ear-EEG
dataset suitable for different purposes, including biometric authentication,
demonstrate promising performance, with an average accuracy of 82\% in a
subject identification scenario. These findings confirm the potential of
ear-EEG as a viable and deployable direction for next-generation real-world
biometric systems.

</details>


### [176] [Generalist Bimanual Manipulation via Foundation Video Diffusion Models](https://arxiv.org/abs/2507.12898)
*Yao Feng,Hengkai Tan,Xinyi Mao,Guodong Liu,Shuhe Huang,Chendong Xiang,Hang Su,Jun Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种名为VIDAR的新框架，用于双臂机器人操控，通过视频扩散模型和掩码逆动态模型实现低数据场景下的高效任务推广。


<details>
  <summary>Details</summary>
Motivation: 当前双臂机器人任务受数据稀缺和实体异质性限制，难以进一步扩展。

Method: 采用两个阶段的框架：1）利用扩散模型进行视频大规模预训练；2）通过掩码逆动态模型进行动作预测，提取与动作相关的信息。

Result: 只需20分钟的新平台演示数据即可推广到未见任务和背景，超过现有技术水平。

Conclusion: 视频基础模型结合掩码动作预测能有效支持现实环境下的机器人操控任务推广。

Abstract: Bimanual robotic manipulation, which involves the coordinated control of two
robotic arms, is foundational for solving challenging tasks. Despite recent
progress in general-purpose manipulation, data scarcity and embodiment
heterogeneity remain serious obstacles to further scaling up in bimanual
settings. In this paper, we introduce VIdeo Diffusion for Action Reasoning
(VIDAR), a two-stage framework that leverages large-scale, diffusion-based
video pre-training and a novel masked inverse dynamics model for action
prediction. We pre-train the video diffusion model on 750K multi-view videos
from three real-world bimanual robot platforms, utilizing a unified observation
space that encodes robot, camera, task, and scene contexts. Our masked inverse
dynamics model learns masks to extract action-relevant information from
generated trajectories without requiring pixel-level labels, and the masks can
effectively generalize to unseen backgrounds. Our experiments demonstrate that
with only 20 minutes of human demonstrations on an unseen robot platform (only
1% of typical data requirements), VIDAR generalizes to unseen tasks and
backgrounds with strong semantic understanding, surpassing state-of-the-art
methods. Our findings highlight the potential of video foundation models,
coupled with masked action prediction, to enable scalable and generalizable
robotic manipulation in diverse real-world settings.

</details>


### [177] [Learning to Reject Low-Quality Explanations via User Feedback](https://arxiv.org/abs/2507.12900)
*Luca Stradiotti,Dario Pesenti,Stefano Teso,Jesse Davis*

Main category: cs.LG

TL;DR: 研究提出了一种名为ULER的新框架，用于拒绝低质量的机器学习模型解释，从而提高用户对高风险预测应用的信任。


<details>
  <summary>Details</summary>
Motivation: 许多高风险应用（如信用评分）需要机器学习模型的预测解释，但这些解释可能不容易被用户理解或信任，可能影响决策的可靠性。

Method: 提出了一种新的学习拒绝低质量解释(LtX)的框架，并具体设计了ULER模型，它通过用户评分和特征相关性判断来自动学习判断解释质量的拒绝规则。

Result: ULER在8个分类和回归基准测试以及新的人类标注数据集上取得了比现有方法更优的性能。

Conclusion: ULER框架有效支持高质量预测解释的甄别，为可靠的决策提供了可能性，同时公开了新的数据集以帮助未来研究。

Abstract: Machine Learning predictors are increasingly being employed in high-stakes
applications such as credit scoring. Explanations help users unpack the reasons
behind their predictions, but are not always "high quality''. That is,
end-users may have difficulty interpreting or believing them, which can
complicate trust assessment and downstream decision-making. We argue that
classifiers should have the option to refuse handling inputs whose predictions
cannot be explained properly and introduce a framework for learning to reject
low-quality explanations (LtX) in which predictors are equipped with a rejector
that evaluates the quality of explanations. In this problem setting, the key
challenges are how to properly define and assess explanation quality and how to
design a suitable rejector. Focusing on popular attribution techniques, we
introduce ULER (User-centric Low-quality Explanation Rejector), which learns a
simple rejector from human ratings and per-feature relevance judgments to
mirror human judgments of explanation quality. Our experiments show that ULER
outperforms both state-of-the-art and explanation-aware learning to reject
strategies at LtX on eight classification and regression benchmarks and on a
new human-annotated dataset, which we will publicly release to support future
research.

</details>


### [178] [Fremer: Lightweight and Effective Frequency Transformer for Workload Forecasting in Cloud Services](https://arxiv.org/abs/2507.12908)
*Jiadong Chen,Hengyu Ye,Fuxin Jiang,Xiao He,Tieying Zhang,Jianjun Chen,Xiaofeng Gao*

Main category: cs.LG

TL;DR: 提出Fremer模型，专注于云服务环境下工作负载预测，展示了高效能和高精度的特点，显著超越了SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 解决基于Transformer的工作负载预测模型在大规模云环境中计算效率低下的问题，并利用频率域上的优势处理复杂的周期性数据模式。

Method: 设计Fremer深度预测模型，侧重于在频率域上进行工作负载预测，并收集了四个高质量的工作负载数据集进行训练与验证。

Result: Fremer在自有数据集与公有基准测试中表现优异，相比SOTA模型，在MSE、MAE和SMAPE等指标上分别平均提升了5.5%、4.7%和8.6%；在Kubernetes上的主动扩展测试中，改进了平均延迟18.78%，降低了资源消耗2.35%。

Conclusion: Fremer模型在云服务中的确具有高效、精准和实际应用价值，显著提升了工作负载预测的性能，同时减少了计算资源开销。

Abstract: Workload forecasting is pivotal in cloud service applications, such as
auto-scaling and scheduling, with profound implications for operational
efficiency. Although Transformer-based forecasting models have demonstrated
remarkable success in general tasks, their computational efficiency often falls
short of the stringent requirements in large-scale cloud environments. Given
that most workload series exhibit complicated periodic patterns, addressing
these challenges in the frequency domain offers substantial advantages. To this
end, we propose Fremer, an efficient and effective deep forecasting model.
Fremer fulfills three critical requirements: it demonstrates superior
efficiency, outperforming most Transformer-based forecasting models; it
achieves exceptional accuracy, surpassing all state-of-the-art (SOTA) models in
workload forecasting; and it exhibits robust performance for multi-period
series. Furthermore, we collect and open-source four high-quality, open-source
workload datasets derived from ByteDance's cloud services, encompassing
workload data from thousands of computing instances. Extensive experiments on
both our proprietary datasets and public benchmarks demonstrate that Fremer
consistently outperforms baseline models, achieving average improvements of
5.5% in MSE, 4.7% in MAE, and 8.6% in SMAPE over SOTA models, while
simultaneously reducing parameter scale and computational costs. Additionally,
in a proactive auto-scaling test based on Kubernetes, Fremer improves average
latency by 18.78% and reduces resource consumption by 2.35%, underscoring its
practical efficacy in real-world applications.

</details>


### [179] [Robust Explanations Through Uncertainty Decomposition: A Path to Trustworthier AI](https://arxiv.org/abs/2507.12913)
*Chenrui Zhu,Louenas Bounia,Vu Linh Nguyen,Sébastien Destercke,Arthur Hoarau*

Main category: cs.LG

TL;DR: 本文提出通过不确定性（数据相关和模型相关）量化来增强模型的解释性，并引入了以不确定性为驱动的解释方法框架。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型结构复杂度的提升，模型预测的解释性逐渐降低，因此需要新的方法来增强模型透明性。

Method: 区分数据相关的不确定性（aleatoric）和模型相关的不确定性（epistemic），利用epistemic不确定性作为拒绝标准，aleatoric不确定性指导选择特征重要性解释或反事实解释，以构建不确定性驱动的解释方法框架。

Result: 实验表明，该不确定性感知方法可以提高解释的稳健性和可达性，无论在传统机器学习还是深度学习场景中均适用。

Conclusion: 通过结合不确定性量化与解释方法，本研究为增强模型的透明性和可靠性提供了新思路。

Abstract: Recent advancements in machine learning have emphasized the need for
transparency in model predictions, particularly as interpretability diminishes
when using increasingly complex architectures. In this paper, we propose
leveraging prediction uncertainty as a complementary approach to classical
explainability methods. Specifically, we distinguish between aleatoric
(data-related) and epistemic (model-related) uncertainty to guide the selection
of appropriate explanations. Epistemic uncertainty serves as a rejection
criterion for unreliable explanations and, in itself, provides insight into
insufficient training (a new form of explanation). Aleatoric uncertainty
informs the choice between feature-importance explanations and counterfactual
explanations. This leverages a framework of explainability methods driven by
uncertainty quantification and disentanglement. Our experiments demonstrate the
impact of this uncertainty-aware approach on the robustness and attainability
of explanations in both traditional machine learning and deep learning
scenarios.

</details>


### [180] [Trace Reconstruction with Language Models](https://arxiv.org/abs/2507.12927)
*Franziska Weindel,Michael Girsch,Reinhard Heckel*

Main category: cs.LG

TL;DR: 本文提出了一种名为TReconLM的模型，用于恢复被噪声损坏的序列，特别适用于DNA数据存储中的错误校正。


<details>
  <summary>Details</summary>
Motivation: 解决在DNA数据存储中，由于合成、存储和测序引入的错误导致数据恢复的挑战。

Method: 提出了基于语言模型（Language Models）的TReconLM算法，先用合成数据进行预训练，再使用真实数据微调，针对特定技术的错误模式进行适配。

Result: TReconLM优于其他最先进的追踪重构算法，包括以往的深度学习方法，能够以更高的精确度恢复无错误的序列。

Conclusion: TReconLM展示了在追踪重构问题上的显著优势，特别是在DNA数据存储的应用中，为高效数据恢复提供了新的解决方案。

Abstract: The general trace reconstruction problem seeks to recover an original
sequence from its noisy copies independently corrupted by deletions,
insertions, and substitutions. This problem arises in applications such as DNA
data storage, a promising storage medium due to its high information density
and longevity. However, errors introduced during DNA synthesis, storage, and
sequencing require correction through algorithms and codes, with trace
reconstruction often used as part of the data retrieval process. In this work,
we propose TReconLM, which leverages language models trained on next-token
prediction for trace reconstruction. We pretrain language models on synthetic
data and fine-tune on real-world data to adapt to technology-specific error
patterns. TReconLM outperforms state-of-the-art trace reconstruction
algorithms, including prior deep learning approaches, recovering a
substantially higher fraction of sequences without error.

</details>


### [181] [From a Mixed-Policy Perspective: Improving Differentiable Automatic Post-editing Optimization](https://arxiv.org/abs/2507.12931)
*Hongze Tan*

Main category: cs.LG

TL;DR: 本文提出了两种改进DAPO算法的方法，从混合策略的角度出发，提高了训练的稳定性和样本效率。


<details>
  <summary>Details</summary>
Motivation: 解决标准策略梯度方法在稀疏奖励环境中存在的训练不稳定和样本低效问题。

Method: 1. 引入预训练的稳定指导策略($\piphi$)，通过离策略经验增强目标策略($\pion$)的训练。2. 重新利用零奖励样本，作为由专家策略指导的单独批次，以进一步提高样本利用率。

Result: 提出的方法具有理论分析支持，目标函数在强化学习理论框架下收敛至最优解。

Conclusion: 混合策略框架在探索与利用之间实现了有效平衡，提高了策略优化的稳定性和效率。

Abstract: This paper introduces two novel modifications to the Differentiable Automatic
Post-editing Optimization (DAPO) algorithm, approached from a mixed-policy
perspective. Standard policy gradient methods can suffer from instability and
sample inefficiency, particularly in sparse reward settings. To address this,
we first propose a method that incorporates a pre-trained, stable guiding
policy ($\piphi$) to provide off-policy experience, thereby regularizing the
training of the target policy ($\pion$). This approach improves training
stability and convergence speed by adaptively adjusting the learning step size.
Secondly, we extend this idea to re-utilize zero-reward samples, which are
often discarded by dynamic sampling strategies like DAPO's. By treating these
samples as a distinct batch guided by the expert policy, we further enhance
sample efficiency. We provide a theoretical analysis for both methods,
demonstrating that their objective functions converge to the optimal solution
within the established theoretical framework of reinforcement learning. The
proposed mixed-policy framework effectively balances exploration and
exploitation, promising more stable and efficient policy optimization.

</details>


### [182] [MC$^2$A: Enabling Algorithm-Hardware Co-Design for Efficient Markov Chain Monte Carlo Acceleration](https://arxiv.org/abs/2507.12935)
*Shirui Zhao,Jun Yin,Lingyun Yao,Martin Andraud,Wannes Meert,Marian Verhelst*

Main category: cs.LG

TL;DR: 这篇论文提出了一个算法硬件协同设计的框架MC2A，以加速MCMC算法的执行，克服了现有解决方案在灵活性和系统级效率上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有MCMC算法计算成本高，限制了其在大规模问题和实际应用中的可行性，需要一种灵活且高效的解决方案来加速MCMC。

Method: 通过扩展处理器性能模型，分析MCMC工作负载的多样性，并提出参数化硬件加速器架构，包括ISA可编程的处理单元、可重构采样器和交叉互连网络等，同时使用创新的Gumbel采样器。

Result: 相比CPU、GPU、TPU及现有的MCMC加速器，MC2A分别实现了307.6倍、1.4倍、2.0倍和84.2倍的加速效果。

Conclusion: MC2A框架展示了在各种MCMC工作负载下的一般硬件加速的可行性，有助于推动MCMC算法在多样化应用领域的普及。

Abstract: An increasing number of applications are exploiting sampling-based algorithms
for planning, optimization, and inference. The Markov Chain Monte Carlo (MCMC)
algorithms form the computational backbone of this emerging branch of machine
learning. Unfortunately, the high computational cost limits their feasibility
for large-scale problems and real-world applications, and the existing MCMC
acceleration solutions are either limited in hardware flexibility or fail to
maintain efficiency at the system level across a variety of end-to-end
applications. This paper introduces \textbf{MC$^2$A}, an algorithm-hardware
co-design framework, enabling efficient and flexible optimization for MCMC
acceleration. Firstly, \textbf{MC$^2$A} analyzes the MCMC workload diversity
through an extension of the processor performance roofline model with a 3rd
dimension to derive the optimal balance between the compute, sampling and
memory parameters. Secondly, \textbf{MC$^2$A} proposes a parametrized hardware
accelerator architecture with flexible and efficient support of MCMC kernels
with a pipeline of ISA-programmable tree-structured processing units,
reconfigurable samplers and a crossbar interconnect to support irregular
access. Thirdly, the core of \textbf{MC$^2$A} is powered by a novel Gumbel
sampler that eliminates exponential and normalization operations. In the
end-to-end case study, \textbf{MC$^2$A} achieves an overall {$307.6\times$,
$1.4\times$, $2.0\times$, $84.2\times$} speedup compared to the CPU, GPU, TPU
and state-of-the-art MCMC accelerator. Evaluated on various representative MCMC
workloads, this work demonstrates and exploits the feasibility of general
hardware acceleration to popularize MCMC-based solutions in diverse application
domains.

</details>


### [183] [Probabilistic Soundness Guarantees in LLM Reasoning Chains](https://arxiv.org/abs/2507.12948)
*Weiqiu You,Anton Xue,Shreya Havaldar,Delip Rao,Helen Jin,Chris Callison-Burch,Eric Wong*

Main category: cs.LG

TL;DR: 提出了一个叫ARES的新框架，可以更好地检测由初始错误传播产生的推理错误。


<details>
  <summary>Details</summary>
Motivation: 目前的LLM错误检测方法不能有效处理初始错误对推理链后续影响的问题。

Method: 引入Autoregressive Reasoning Entailment Stability (ARES) 框架，通过仅基于之前正确评估的前提判断每一步推理的有效性。

Result: ARES在多个基准测试上表现最好，宏观F1得分达到72.1%，并特别在处理长推理链的错误传播检测中展现出卓越表现（90.3% F1，提升了27.6点）。

Conclusion: ARES提供了改进的推理错误检测框架，具有较高的效果和鲁棒性，尤其对错误传播问题具有显著优势。

Abstract: In reasoning chains generated by large language models (LLMs), initial errors
often propagate and undermine the reliability of the final conclusion. Current
LLM-based error detection methods often fail to detect propagated errors
because they do not properly account for how earlier errors might corrupt
judgments of downstream reasoning. To better detect such propagated errors, we
introduce Autoregressive Reasoning Entailment Stability (ARES), a novel
probabilistic framework that prevents error propagation by judging each claim
based only on previously-assessed sound premises. This inductive method yields
a nuanced score for each step and provides certified statistical guarantees of
its soundness, rather than a brittle binary label. ARES achieves
state-of-the-art performance across four benchmarks (72.1% Macro-F1, +8.2
points) and demonstrates superior robustness on very long synthetic reasoning
chains, where it excels at detecting propagated errors (90.3% F1, +27.6
points).

</details>


### [184] [Insights into a radiology-specialised multimodal large language model with sparse autoencoders](https://arxiv.org/abs/2507.12950)
*Kenza Bouzid,Shruthi Bannur,Daniel Coelho de Castro,Anton Schwaighofer,Javier Alvarez-Valle,Stephanie L. Hyland*

Main category: cs.LG

TL;DR: 本文研究使用稀疏自动编码器（SAEs）解读MAIRA-2模型的内部表征，发现多种与医疗相关的重要概念，并探索其对模型行为的影响。


<details>
  <summary>Details</summary>
Motivation: 提高AI模型的可解释性，以增强在关键领域（如医疗）的信任与安全性。

Method: 通过对结合SAEs的Matryoshka方法，解读MAIRA-2的内部表征，并以自动化分析挖掘临床相关概念，以及通过“操控”测试这些特征对模型行为的影响。

Result: 成功识别出多种临床重要特征，如医疗设备存在与病理变化等内容，并通过操控实验展示部分特征可影响生成内容，但也发现一些方法上的挑战与限制。

Conclusion: 尽管存在挑战，但该研究迈出了揭示MAIRA-2学习机制与提高医疗AI模型透明性的第一步。

Abstract: Interpretability can improve the safety, transparency and trust of AI models,
which is especially important in healthcare applications where decisions often
carry significant consequences. Mechanistic interpretability, particularly
through the use of sparse autoencoders (SAEs), offers a promising approach for
uncovering human-interpretable features within large transformer-based models.
In this study, we apply Matryoshka-SAE to the radiology-specialised multimodal
large language model, MAIRA-2, to interpret its internal representations. Using
large-scale automated interpretability of the SAE features, we identify a range
of clinically relevant concepts - including medical devices (e.g., line and
tube placements, pacemaker presence), pathologies such as pleural effusion and
cardiomegaly, longitudinal changes and textual features. We further examine the
influence of these features on model behaviour through steering, demonstrating
directional control over generations with mixed success. Our results reveal
practical and methodological challenges, yet they offer initial insights into
the internal concepts learned by MAIRA-2 - marking a step toward deeper
mechanistic understanding and interpretability of a radiology-adapted
multimodal large language model, and paving the way for improved model
transparency. We release the trained SAEs and interpretations:
https://huggingface.co/microsoft/maira-2-sae.

</details>


### [185] [A Spectral Interpretation of Redundancy in a Graph Reservoir](https://arxiv.org/abs/2507.12963)
*Anna Bison,Alessandro Sperduti*

Main category: cs.LG

TL;DR: 通过在图神经网络中引入基于公平算法的光谱水库模型，提出了一种缓解过度平滑问题的方法。


<details>
  <summary>Details</summary>
Motivation: 解决图神经网络中反复应用层操作引起的过度平滑问题，提升图分类任务中的性能。

Method: 利用源自计算机图形学领域的公平算法，将其转化为图拉普拉斯算子提供无收缩的平滑光谱滤波，并结合理论分析调整光谱系数。

Result: 提出的方法通过调节随机游走的冗余贡献，在实验中展示了潜力，并为未来研究提供了方向。

Conclusion: 公平算法的采用能够有效缓解过度平滑问题，在图神经网络的性能提升中具有显著应用潜力。

Abstract: Reservoir computing has been successfully applied to graphs as a
preprocessing method to improve the training efficiency of Graph Neural
Networks (GNNs). However, a common issue that arises when repeatedly applying
layer operators on graphs is over-smoothing, which consists in the convergence
of graph signals toward low-frequency components of the graph Laplacian. This
work revisits the definition of the reservoir in the Multiresolution Reservoir
Graph Neural Network (MRGNN), a spectral reservoir model, and proposes a
variant based on a Fairing algorithm originally introduced in the field of
surface design in computer graphics. This algorithm provides a pass-band
spectral filter that allows smoothing without shrinkage, and it can be adapted
to the graph setting through the Laplacian operator. Given its spectral
formulation, this method naturally connects to GNN architectures for tasks
where smoothing, when properly controlled, can be beneficial,such as graph
classification. The core contribution of the paper lies in the theoretical
analysis of the algorithm from a random walks perspective. In particular, it
shows how tuning the spectral coefficients can be interpreted as modulating the
contribution of redundant random walks. Exploratory experiments based on the
MRGNN architecture illustrate the potential of this approach and suggest
promising directions for future research.

</details>


### [186] [WaveletInception Networks for Drive-by Vibration-Based Infrastructure Health Monitoring](https://arxiv.org/abs/2507.12969)
*Reza Riahi Samani,Alfredo Nunez,Bart De Schutter*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的新框架，用于通过驱动振动响应信号进行基础设施健康监测，构建了名为WaveletInception-BiLSTM的网络，并通过案例研究验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 通过利用驱动振动响应信号，高效、精准地检测和评估基础设施的健康状况，尤其是在无需广泛数据预处理的情况下实现自动化监测。

Method: 提出了WaveletInception-BiLSTM网络架构。WaveletInception特征提取器利用可学习的小波包变换（LWPT）提取频谱特征，结合1D Inception网络提取多尺度高层特征，再通过LSTM融合操作条件并捕捉时间相关性，BiLSTM用于估计健康状态。整个流程实现局部化、高分辨率的健康状况评估。

Result: 通过铁路轨道刚度的模拟案例研究，验证了该模型在铁路道碴及轨枕刚度参数估计方面的优越性能，显著优于现有技术水平。

Conclusion: 该方法可实现基础设施健康状况的准确、本地化及全自动监测，展示了其广阔的应用前景。

Abstract: This paper presents a novel deep learning-based framework for infrastructure
health monitoring using drive-by vibration response signals. Recognizing the
importance of spectral and temporal information, we introduce the
WaveletInception-BiLSTM network. The WaveletInception feature extractor
utilizes a Learnable Wavelet Packet Transform (LWPT) as the stem for extracting
vibration signal features, incorporating spectral information in the early
network layers. This is followed by 1D Inception networks that extract
multi-scale, high-level features at deeper layers. The extracted vibration
signal features are then integrated with operational conditions via a Long
Short-term Memory (LSTM) layer. The resulting feature extraction network
effectively analyzes drive-by vibration signals across various measurement
speeds without preprocessing and uses LSTM to capture interrelated temporal
dependencies among different modes of information and to create feature vectors
for health condition estimation. The estimator head is designed with a
sequential modeling architecture using bidirectional LSTM (BiLSTM) networks,
capturing bi-directional temporal relationships from drive-by measurements.
This architecture allows for a high-resolution, beam-level assessment of
infrastructure health conditions. A case study focusing on railway track
stiffness estimation with simulated drive-by vibration signals shows that the
model significantly outperforms state-of-the-art methods in estimating railway
ballast and railpad stiffness parameters. Results underscore the potential of
this approach for accurate, localized, and fully automated drive-by
infrastructure health monitoring.

</details>


### [187] [A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints](https://arxiv.org/abs/2507.12979)
*Youssef Tawfilis,Hossam Amer,Minar El-Aasser,Tallal Elshabrawy*

Main category: cs.LG

TL;DR: 本论文提出一种新方法，通过去中心化训练GAN模型，解决数据隐私和设备异构性问题，同时在多个性能指标上取得大幅提升。


<details>
  <summary>Details</summary>
Motivation: 解决传统GAN模型训练中因隐私、版权和设备资源有限导致的数据获取难题，并充分利用闲置设备及分布式数据。

Method: 结合KLD加权的簇化联邦学习解决数据异质性问题，并采用异构的U形分割学习解决设备异构性问题，确保在节点间不共享标签或原始/合成数据。

Result: 实验结果显示，提议方法在多个指标上取得1.1x-2.2x的图像生成分数提升，分类性能提升平均10%（最高50%），且延迟显著降低。

Conclusion: 所提出的方法有效解决去中心化环境下的数据和设备异质性问题，充分利用分布式设备和数据资源，适应性和性能显著优于其他基准模型。

Abstract: Federated Learning has gained increasing attention for its ability to enable
multiple nodes to collaboratively train machine learning models without sharing
their raw data. At the same time, Generative AI -- particularly Generative
Adversarial Networks (GANs) -- have achieved remarkable success across a wide
range of domains, such as healthcare, security, and Image Generation. However,
training generative models typically requires large datasets and significant
computational resources, which are often unavailable in real-world settings.
Acquiring such resources can be costly and inefficient, especially when many
underutilized devices -- such as IoT devices and edge devices -- with varying
capabilities remain idle. Moreover, obtaining large datasets is challenging due
to privacy concerns and copyright restrictions, as most devices are unwilling
to share their data. To address these challenges, we propose a novel approach
for decentralized GAN training that enables the utilization of distributed data
and underutilized, low-capability devices while not sharing data in its raw
form. Our approach is designed to tackle key challenges in decentralized
environments, combining KLD-weighted Clustered Federated Learning to address
the issues of data heterogeneity and multi-domain datasets, with Heterogeneous
U-Shaped split learning to tackle the challenge of device heterogeneity under
strict data sharing constraints -- ensuring that no labels or raw data, whether
real or synthetic, are ever shared between nodes. Experimental results shows
that our approach demonstrates consistent and significant improvements across
key performance metrics, where it achieves 1.1x -- 2.2x higher image generation
scores, an average 10% boost in classification metrics (up to 50% in
multi-domain non-IID settings), in much lower latency compared to several
benchmarks. Find our code at https://github.com/youssefga28/HuSCF-GAN.

</details>


### [188] [FedGA: A Fair Federated Learning Framework Based on the Gini Coefficient](https://arxiv.org/abs/2507.12983)
*ShanBin Liu*

Main category: cs.LG

TL;DR: 提出了一种名为FedGA的公平性联邦学习算法，通过调整聚合权重和引入基尼系数等方法，平衡各客户端的性能差异，取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中的数据异质性导致的客户端性能不平衡问题，提高模型的公平性。

Method: 使用基尼系数衡量客户端间性能差异，建立其与全局模型更新尺度的关系，动态调整聚合权重，适时进行公平性干预。

Result: 在Office-Caltech-10、CIFAR-10和Synthetic数据集上的实验表明，FedGA在减少性能方差和基尼系数的同时，保持了总体性能的优越性。

Conclusion: FedGA能够有效改善联邦学习中客户端间的公平性问题，并在保持整体模型性能的情况下减少客户端性能差异，验证了方法的有效性。

Abstract: Fairness has emerged as one of the key challenges in federated learning. In
horizontal federated settings, data heterogeneity often leads to substantial
performance disparities across clients, raising concerns about equitable model
behavior. To address this issue, we propose FedGA, a fairness-aware federated
learning algorithm. We first employ the Gini coefficient to measure the
performance disparity among clients. Based on this, we establish a relationship
between the Gini coefficient $G$ and the update scale of the global model
${U_s}$, and use this relationship to adaptively determine the timing of
fairness intervention. Subsequently, we dynamically adjust the aggregation
weights according to the system's real-time fairness status, enabling the
global model to better incorporate information from clients with relatively
poor performance.We conduct extensive experiments on the Office-Caltech-10,
CIFAR-10, and Synthetic datasets. The results show that FedGA effectively
improves fairness metrics such as variance and the Gini coefficient, while
maintaining strong overall performance, demonstrating the effectiveness of our
approach.

</details>


### [189] [Teach Old SAEs New Domain Tricks with Boosting](https://arxiv.org/abs/2507.12990)
*Nikita Koriagin,Yaroslav Aksenov,Daniil Laptev,Gleb Gerasimov,Nikita Balagansky,Daniil Gavrilov*

Main category: cs.LG

TL;DR: 该论文提出一种通过残差学习来解决稀疏自动编码器（SAE）对领域特定特征感知不足的问题，而无需完全重新训练。


<details>
  <summary>Details</summary>
Motivation: 解决现有稀疏自动编码器在不常见领域特定特征上的表现不足问题。

Method: 引入一个额外的稀疏自动编码器模型，用于捕捉主模型在领域特定文本上的重构误差，并在推理时将其输出与主模型的输出相加。

Result: 在多种专业领域中，该方法显著改进了LLM的交叉熵指标与解释方差指标。

Conclusion: 此方法有效整合了新的领域知识，同时保持了原有稀疏自动编码器的通用任务性能，为LLM的领域特定机制解释开辟了新可能性。

Abstract: Sparse Autoencoders have emerged as powerful tools for interpreting the
internal representations of Large Language Models, yet they often fail to
capture domain-specific features not prevalent in their training corpora. This
paper introduces a residual learning approach that addresses this feature
blindness without requiring complete retraining. We propose training a
secondary SAE specifically to model the reconstruction error of a pretrained
SAE on domain-specific texts, effectively capturing features missed by the
primary model. By summing the outputs of both models during inference, we
demonstrate significant improvements in both LLM cross-entropy and explained
variance metrics across multiple specialized domains. Our experiments show that
this method efficiently incorporates new domain knowledge into existing SAEs
while maintaining their performance on general tasks. This approach enables
researchers to selectively enhance SAE interpretability for specific domains of
interest, opening new possibilities for targeted mechanistic interpretability
of LLMs.

</details>


### [190] [SMART: Relation-Aware Learning of Geometric Representations for Knowledge Graphs](https://arxiv.org/abs/2507.13001)
*Kossi Amouzouvi,Bowen Song,Andrea Coletta,Luigi Bellomarini,Jens Lehmann,Sahar Vahdati*

Main category: cs.LG

TL;DR: 论文探讨了知识图谱嵌入中的几何变换问题，提出了一种基于注意力机制的框架，评估每种关系与几何变换的匹配度，从而提升嵌入效果。


<details>
  <summary>Details</summary>
Motivation: 目前的知识图谱嵌入模型在使用几何变换时忽略了基于关系的特定变换，普遍采用单一或复合几何变换表示所有关系。

Method: 提出一种框架，先对关系与几何变换的匹配程度打分，再通过注意力机制学习低维空间中的单一关系特定变换，并结合相关性用于高维关系嵌入。

Result: 在三个基准知识图谱和一个真实世界金融知识图谱上进行了验证，模型表现优于或媲美领先模型。

Conclusion: 通过针对性地为每种关系选择最佳几何变换或采用多数投票决策，该框架有效提升了知识图谱嵌入的表现，从而证实了针对性几何变换的重要性。

Abstract: Knowledge graph representation learning approaches provide a mapping between
symbolic knowledge in the form of triples in a knowledge graph (KG) and their
feature vectors. Knowledge graph embedding (KGE) models often represent
relations in a KG as geometric transformations. Most state-of-the-art (SOTA)
KGE models are derived from elementary geometric transformations (EGTs), such
as translation, scaling, rotation, and reflection, or their combinations. These
geometric transformations enable the models to effectively preserve specific
structural and relational patterns of the KG. However, the current use of EGTs
by KGEs remains insufficient without considering relation-specific
transformations. Although recent models attempted to address this problem by
ensembling SOTA baseline models in different ways, only a single or composite
version of geometric transformations are used by such baselines to represent
all the relations. In this paper, we propose a framework that evaluates how
well each relation fits with different geometric transformations. Based on this
ranking, the model can: (1) assign the best-matching transformation to each
relation, or (2) use majority voting to choose one transformation type to apply
across all relations. That is, the model learns a single relation-specific EGT
in low dimensional vector space through an attention mechanism. Furthermore, we
use the correlation between relations and EGTs, which are learned in a low
dimension, for relation embeddings in a high dimensional vector space. The
effectiveness of our models is demonstrated through comprehensive evaluations
on three benchmark KGs as well as a real-world financial KG, witnessing a
performance comparable to leading models

</details>


### [191] [Fault detection and diagnosis for the engine electrical system of a space launcher based on a temporal convolutional autoencoder and calibrated classifiers](https://arxiv.org/abs/2507.13022)
*Luis Basora,Louison Bocquet-Nouaille,Elinirina Robinson,Serge Le Gonidec*

Main category: cs.LG

TL;DR: 论文提出了一种基于时序卷积自编码器的解决方案，用于下一代可重复使用航天发射器的电气系统故障检测和诊断。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在满足新一代航天发射器对故障检测和诊断系统更高要求，如预测置信度估计、分布外数据检测和控制误报警。

Method: 利用时序卷积自编码器从传感器原始数据中提取低维特征，并结合基于直方图的梯度提升分类器进行故障检测与诊断；通过归纳符合性异常检测方法识别分布外数据，结合累积和控制图限制误报警，及阈值调整应对类别不平衡问题。

Result: 在模拟数据中验证了所提出框架的可行性，结果表明其在异常运行场景下表现良好，但仍需在实测数据上进一步验证。

Conclusion: 该方法为航天领域电气系统故障检测提供了有潜力的初步解决方案，但要达到实用化还需进一步工作。

Abstract: In the context of the health monitoring for the next generation of reusable
space launchers, we outline a first step toward developing an onboard fault
detection and diagnostic capability for the electrical system that controls the
engine valves. Unlike existing approaches in the literature, our solution is
designed to meet a broader range of key requirements. This includes estimating
confidence levels for predictions, detecting out-of-distribution (OOD) cases,
and controlling false alarms. The proposed solution is based on a temporal
convolutional autoencoder to automatically extract low-dimensional features
from raw sensor data. Fault detection and diagnosis are respectively carried
out using a binary and a multiclass classifier trained on the autoencoder
latent and residual spaces. The classifiers are histogram-based gradient
boosting models calibrated to output probabilities that can be interpreted as
confidence levels. A relatively simple technique, based on inductive conformal
anomaly detection, is used to identify OOD data. We leverage other simple yet
effective techniques, such as cumulative sum control chart (CUSUM) to limit the
false alarms, and threshold moving to address class imbalance in fault
detection. The proposed framework is highly configurable and has been evaluated
on simulated data, covering both nominal and anomalous operational scenarios.
The results indicate that our solution is a promising first step, though
testing with real data will be necessary to ensure that it achieves the
required maturity level for operational use.

</details>


### [192] [Inverse Reinforcement Learning Meets Large Language Model Post-Training: Basics, Advances, and Opportunities](https://arxiv.org/abs/2507.13158)
*Hao Sun,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 本文综述了大语言模型(LLMs)对齐问题的最新进展，特别是通过逆强化学习(IRL)视角。


<details>
  <summary>Details</summary>
Motivation: 在追求更可靠、可控和智能的机器模型中，解决LLMs的对齐问题是关键，尤其逆强化学习可以弥补传统强化学习的局限。

Method: 本文重点讨论了IRL在LLMs对齐中的应用，包括从人类数据中构建神经奖励模型，方法论及其实践意义。

Result: 指出了IRL在当前LLMs对齐挑战中的优势和局限性，同时提出数据集、基准、评估指标等具体实践建议。

Conclusion: 通过多学科视角综合研究，文章为LLMs对齐问题提供了批判性总结和未来研究方向点拨。

Abstract: In the era of Large Language Models (LLMs), alignment has emerged as a
fundamental yet challenging problem in the pursuit of more reliable,
controllable, and capable machine intelligence. The recent success of reasoning
models and conversational AI systems has underscored the critical role of
reinforcement learning (RL) in enhancing these systems, driving increased
research interest at the intersection of RL and LLM alignment. This paper
provides a comprehensive review of recent advances in LLM alignment through the
lens of inverse reinforcement learning (IRL), emphasizing the distinctions
between RL techniques employed in LLM alignment and those in conventional RL
tasks. In particular, we highlight the necessity of constructing neural reward
models from human data and discuss the formal and practical implications of
this paradigm shift. We begin by introducing fundamental concepts in RL to
provide a foundation for readers unfamiliar with the field. We then examine
recent advances in this research agenda, discussing key challenges and
opportunities in conducting IRL for LLM alignment. Beyond methodological
considerations, we explore practical aspects, including datasets, benchmarks,
evaluation metrics, infrastructure, and computationally efficient training and
inference techniques. Finally, we draw insights from the literature on
sparse-reward RL to identify open questions and potential research directions.
By synthesizing findings from diverse studies, we aim to provide a structured
and critical overview of the field, highlight unresolved challenges, and
outline promising future directions for improving LLM alignment through RL and
IRL techniques.

</details>


### [193] [Confidence-Filtered Relevance (CFR): An Interpretable and Uncertainty-Aware Machine Learning Framework for Naturalness Assessment in Satellite Imagery](https://arxiv.org/abs/2507.13034)
*Ahmed Emam,Ribana Roscher*

Main category: cs.LG

TL;DR: 本文提出了一种名为Confidence-Filtered Relevance (CFR)的数据驱动框架，通过结合LRP注意力分解和深度确定性不确定性估计，分析模型不确定性对自然性解释的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的用卫星图像和机器学习监测自然保护区的方法缺乏可解释性和对不确定性的关注，且未解决不确定性如何影响自然性评估的问题。

Method: 提出CFR框架，通过集合LRP Attention Rollout和Deep Deterministic Uncertainty (DDU)，根据不确定性阈值将数据划分子集，系统地分析不确定性对自然性解释的影响。

Result: 在AnthroProtect数据集上的实验表明，高相关性集中于灌木丛、森林与湿地，并且随着不确定性增加，解释性下降，相关性热图的熵值增加。

Conclusion: CFR提供了一种基于数据的不确定相关性分析方法，用于通过模型的不确定性评估卫星图像中与自然性相关的模式。

Abstract: Protected natural areas play a vital role in ecological balance and ecosystem
services. Monitoring these regions at scale using satellite imagery and machine
learning is promising, but current methods often lack interpretability and
uncertainty-awareness, and do not address how uncertainty affects naturalness
assessment. In contrast, we propose Confidence-Filtered Relevance (CFR), a
data-centric framework that combines LRP Attention Rollout with Deep
Deterministic Uncertainty (DDU) estimation to analyze how model uncertainty
influences the interpretability of relevance heatmaps. CFR partitions the
dataset into subsets based on uncertainty thresholds, enabling systematic
analysis of how uncertainty shapes the explanations of naturalness in satellite
imagery. Applied to the AnthroProtect dataset, CFR assigned higher relevance to
shrublands, forests, and wetlands, aligning with other research on naturalness
assessment. Moreover, our analysis shows that as uncertainty increases, the
interpretability of these relevance heatmaps declines and their entropy grows,
indicating less selective and more ambiguous attributions. CFR provides a
data-centric approach to assess the relevance of patterns to naturalness in
satellite imagery based on their associated certainty.

</details>


### [194] [The Power of Architecture: Deep Dive into Transformer Architectures for Long-Term Time Series Forecasting](https://arxiv.org/abs/2507.13043)
*Lefei Shen,Mouxiang Chen,Han Fu,Xiaoxue Ren,Xiaoyun Joy Wang,Jianling Sun,Zhuo Li,Chenghao Liu*

Main category: cs.LG

TL;DR: 作者探讨了长时间序列预测中哪种Transformer架构最优，提出了一种新分类法并进行了深入实验，发现了若干关键见解并推出性能优越的模型。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型中架构多样，但其性能差异难以避开时间序列特定设计的影响，因此需要一种方法区分架构本身的影响。

Method: 通过提出新的分类标准，分离时间序列相关设计差异，并设计实验分析不同Transformer架构（如注意力机制、聚合方式等）的性能表现。

Result: 实验表明：双向联合注意力最有效，更完整的聚合方式能提升性能，且直接映射范式优于自回归方法。提出的结合最佳架构选择的模型优于现有模型。

Conclusion: 研究总结了Transformer架构在长时间序列预测中的关键设计原则，并为未来这一领域的研究提供了理论指导和应用参考。

Abstract: Transformer-based models have recently become dominant in Long-term Time
Series Forecasting (LTSF), yet the variations in their architecture, such as
encoder-only, encoder-decoder, and decoder-only designs, raise a crucial
question: What Transformer architecture works best for LTSF tasks? However,
existing models are often tightly coupled with various time-series-specific
designs, making it difficult to isolate the impact of the architecture itself.
To address this, we propose a novel taxonomy that disentangles these designs,
enabling clearer and more unified comparisons of Transformer architectures. Our
taxonomy considers key aspects such as attention mechanisms, forecasting
aggregations, forecasting paradigms, and normalization layers. Through
extensive experiments, we uncover several key insights: bi-directional
attention with joint-attention is most effective; more complete forecasting
aggregation improves performance; and the direct-mapping paradigm outperforms
autoregressive approaches. Furthermore, our combined model, utilizing optimal
architectural choices, consistently outperforms several existing models,
reinforcing the validity of our conclusions. We hope these findings offer
valuable guidance for future research on Transformer architectural designs in
LTSF. Our code is available at https://github.com/HALF111/TSF_architecture.

</details>


### [195] [On statistical learning of graphs](https://arxiv.org/abs/2507.13054)
*Vittorio Cipriani,Valentino Delle Rose,Luca San Mauro,Giovanni Solda*

Main category: cs.LG

TL;DR: 本文探讨了由可数无限图G的不同排列图（人为有限顶点交换）组成的假设类在PAC和在线学习中的可学习性问题，并揭示了这些可学习性与G的自同构简单性之间的重要关系。


<details>
  <summary>Details</summary>
Motivation: 尝试理解图结构和标签集合已知情况下的学习问题，并关注有限支持排列及其与在线学习和PAC学习的关系。

Method: 通过分析有限支持排列的可学习性、探讨G的全自同构类型与自动简单性的关系，以及利用描述性集合论和可计算性理论工具对相关复杂性进行研究。

Result: 主要发现包括：有限支持副本的PAC可学习性暗示了其在线可学习性，并等效于自动简单性；对无穷随机图的扩展属性进行松弛，刻画了某些图无法学习的情况；证明了两点顶点交换和k点（k>2）交换的可学习性是等效的，从而对无穷图的复杂性进行了四类划分。

Conclusion: 研究为无穷图学习问题提供了新的分类方法和复杂性度量工具，对于理解无限图及其特性在学习理论中的应用具有重要意义。

Abstract: We study PAC and online learnability of hypothesis classes formed by copies
of a countably infinite graph G, where each copy is induced by permuting G's
vertices. This corresponds to learning a graph's labeling, knowing its
structure and label set. We consider classes where permutations move only
finitely many vertices. Our main result shows that PAC learnability of all such
finite-support copies implies online learnability of the full isomorphism type
of G, and is equivalent to the condition of automorphic triviality. We also
characterize graphs where copies induced by swapping two vertices are not
learnable, using a relaxation of the extension property of the infinite random
graph. Finally, we show that, for all G and k>2, learnability for k-vertex
permutations is equivalent to that for 2-vertex permutations, yielding a
four-class partition of infinite graphs, whose complexity we also determine
using tools coming from both descriptive set theory and computability theory.

</details>


### [196] [DASViT: Differentiable Architecture Search for Vision Transformer](https://arxiv.org/abs/2507.13079)
*Pengjin Wu,Ferrante Neri,Zhenhua Feng*

Main category: cs.LG

TL;DR: 提出了DASViT，一种适用于视觉Transformer的可微架构搜索方法，在多个数据集上优于ViT-B/16，且参数量和FLOPs更少。


<details>
  <summary>Details</summary>
Motivation: 现有的NAS方法在探索ViT架构时主要依赖离散方法，如进化算法，但这些方法在创新设计、计算资源消耗和时间成本方面有较大限制。

Method: 开发了一种专为视觉Transformer设计的可微分架构搜索方法DASViT，旨在通过微分优化方式替代传统的离散方法。

Result: DASViT生成的架构打破了传统Transformer编码器设计，多项实验显示其性能优于ViT-B/16，且更高效，参数和FLOPs更少。

Conclusion: DASViT有效填补了可微分搜索在视觉Transformer领域的空白，为进一步优化和创新ViT架构提供了新方向。

Abstract: Designing effective neural networks is a cornerstone of deep learning, and
Neural Architecture Search (NAS) has emerged as a powerful tool for automating
this process. Among the existing NAS approaches, Differentiable Architecture
Search (DARTS) has gained prominence for its efficiency and ease of use,
inspiring numerous advancements. Since the rise of Vision Transformers (ViT),
researchers have applied NAS to explore ViT architectures, often focusing on
macro-level search spaces and relying on discrete methods like evolutionary
algorithms. While these methods ensure reliability, they face challenges in
discovering innovative architectural designs, demand extensive computational
resources, and are time-intensive. To address these limitations, we introduce
Differentiable Architecture Search for Vision Transformer (DASViT), which
bridges the gap in differentiable search for ViTs and uncovers novel designs.
Experiments show that DASViT delivers architectures that break traditional
Transformer encoder designs, outperform ViT-B/16 on multiple datasets, and
achieve superior efficiency with fewer parameters and FLOPs.

</details>


### [197] [MUPAX: Multidimensional Problem Agnostic eXplainable AI](https://arxiv.org/abs/2507.13090)
*Vincenzo Dentamaro,Felice Franchini,Giuseppe Pirlo,Irina Voiculescu*

Main category: cs.LG

TL;DR: MUPAX是一种用于解释性人工智能的技术，具备确定性、模型无关性和收敛性保证，通过测量理论结构分析给予特征重要性归因，改善模型准确性并超越现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的XAI技术通常在具有确定性、模型无关性和收敛性方面不足，且面临性能下降问题，因此需要一种创新的方法来提供可靠的解释性。

Method: 提出了MUPAX方法，以测量理论为基础，通过结构化扰动分析，发现输入特征模式并消除虚假的关系。该方法适用于多种维度（1D、2D、3D）和任务，并提供坚实的收敛性基础。

Result: MUPAX在音频分类、图像分类、医学影像分析等任务上表现良好，不仅能保持模型的准确性，还能增强模型性能。

Conclusion: MUPAX能生成精确、稳定的解释，为构建可信的解释性AI系统提供了重要工具，展示了强大通用性。

Abstract: Robust XAI techniques should ideally be simultaneously deterministic, model
agnostic, and guaranteed to converge. We propose MULTIDIMENSIONAL PROBLEM
AGNOSTIC EXPLAINABLE AI (MUPAX), a deterministic, model agnostic explainability
technique, with guaranteed convergency. MUPAX measure theoretic formulation
gives principled feature importance attribution through structured perturbation
analysis that discovers inherent input patterns and eliminates spurious
relationships. We evaluate MUPAX on an extensive range of data modalities and
tasks: audio classification (1D), image classification (2D), volumetric medical
image analysis (3D), and anatomical landmark detection, demonstrating dimension
agnostic effectiveness. The rigorous convergence guarantees extend to any loss
function and arbitrary dimensions, making MUPAX applicable to virtually any
problem context for AI. By contrast with other XAI methods that typically
decrease performance when masking, MUPAX not only preserves but actually
enhances model accuracy by capturing only the most important patterns of the
original data. Extensive benchmarking against the state of the XAI art
demonstrates MUPAX ability to generate precise, consistent and understandable
explanations, a crucial step towards explainable and trustworthy AI systems.
The source code will be released upon publication.

</details>


### [198] [Uncertainty-Aware Cross-Modal Knowledge Distillation with Prototype Learning for Multimodal Brain-Computer Interfaces](https://arxiv.org/abs/2507.13092)
*Hyo-Jeong Jang,Hye-Bin Shin,Seong-Whan Lee*

Main category: cs.LG

TL;DR: 本研究提出一种新型跨模态知识蒸馏框架，通过对模态和标签不一致性问题的处理，提升EEG模型性能，实验表明此方法优于传统单模态及多模态方法。


<details>
  <summary>Details</summary>
Motivation: 目前EEG信号在脑机接口中的应用面临标签噪声问题，且现有的知识蒸馏方法因模态差异和标签不对齐导致性能受限。

Method: 提出一种新型跨模态知识蒸馏框架，通过原型相似模块对特征进行语义对齐，并加入任务特定蒸馏头来解决标签引发的不一致性。

Result: 实验结果表明，提出的方法在公开多模态数据集上的情绪回归和分类任务中性能优于传统单模态和多模态基线模型。

Conclusion: 该框架有效提升了EEG模型性能，展示了其在脑机接口应用中的潜力。

Abstract: Electroencephalography (EEG) is a fundamental modality for cognitive state
monitoring in brain-computer interfaces (BCIs). However, it is highly
susceptible to intrinsic signal errors and human-induced labeling errors, which
lead to label noise and ultimately degrade model performance. To enhance EEG
learning, multimodal knowledge distillation (KD) has been explored to transfer
knowledge from visual models with rich representations to EEG-based models.
Nevertheless, KD faces two key challenges: modality gap and soft label
misalignment. The former arises from the heterogeneous nature of EEG and visual
feature spaces, while the latter stems from label inconsistencies that create
discrepancies between ground truth labels and distillation targets. This paper
addresses semantic uncertainty caused by ambiguous features and weakly defined
labels. We propose a novel cross-modal knowledge distillation framework that
mitigates both modality and label inconsistencies. It aligns feature semantics
through a prototype-based similarity module and introduces a task-specific
distillation head to resolve label-induced inconsistency in supervision.
Experimental results demonstrate that our approach improves EEG-based emotion
regression and classification performance, outperforming both unimodal and
multimodal baselines on a public multimodal dataset. These findings highlight
the potential of our framework for BCI applications.

</details>


### [199] [NGTM: Substructure-based Neural Graph Topic Model for Interpretable Graph Generation](https://arxiv.org/abs/2507.13133)
*Yuanxin Zhuang,Dazhong Shen,Ying Sun*

Main category: cs.LG

TL;DR: 提出了一种基于话题建模的神经图话题模型（NGTM），同时增强了图结构生成的竞争力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有图生成方法在生成真实感图的同时，可解释性不足，难以理解生成决策背后的原因。

Method: 以自然语言处理中话题建模为灵感，NGTM通过将图表示为潜在话题的混合体，结合带有语义意义的子结构分布，提供了局部和全局尺度的明确可解释性。

Result: NGTM在生成质量上具有竞争力，并且实现了高精度的结构调整与特征控制。

Conclusion: NGTM不仅提升了图生成的质量，还显著增强了该过程的可解释性，是一种既有效又直观的生成框架。

Abstract: Graph generation plays a pivotal role across numerous domains, including
molecular design and knowledge graph construction. Although existing methods
achieve considerable success in generating realistic graphs, their
interpretability remains limited, often obscuring the rationale behind
structural decisions. To address this challenge, we propose the Neural Graph
Topic Model (NGTM), a novel generative framework inspired by topic modeling in
natural language processing. NGTM represents graphs as mixtures of latent
topics, each defining a distribution over semantically meaningful
substructures, which facilitates explicit interpretability at both local and
global scales. The generation process transparently integrates these topic
distributions with a global structural variable, enabling clear semantic
tracing of each generated graph. Experiments demonstrate that NGTM achieves
competitive generation quality while uniquely enabling fine-grained control and
interpretability, allowing users to tune structural features or induce
biological properties through topic-level adjustments.

</details>


### [200] [NonverbalTTS: A Public English Corpus of Text-Aligned Nonverbal Vocalizations with Emotion Annotations for Text-to-Speech](https://arxiv.org/abs/2507.13155)
*Maksim Borisov,Egor Spirin,Daria Diatlova*

Main category: cs.LG

TL;DR: 本文提出了一个名为NonverbalTTS (NVTTS) 的开放数据集，包含17小时标注为非语言发声（例如笑声、咳嗽）和情感类别的录音，并展示fine-tune后的TTS模型表现可媲美闭源系统。


<details>
  <summary>Details</summary>
Motivation: 现有的表达性语音合成研究受限于缺乏含有多样化非语言发声的公开数据集，这对研究产生了瓶颈。

Method: 引入NVTTS数据集，使用自动化检测结合人工验证的方法构建；另外，搭建了一套综合系统，包括自动语音识别（ASR）、非语言标注、情感分类及多标注融合算法，最终在TTS模型上进行fine-tuning。

Result: 与闭源系统CosyVoice2的表现达到相当水平（通过人工评价与自动指标验证，包括说话人相似性和非语言发声保真度）。

Conclusion: NVTTS数据集的发布及其注释指南为解决表达性语音合成研究的关键瓶颈提供了重要的资源。

Abstract: Current expressive speech synthesis models are constrained by the limited
availability of open-source datasets containing diverse nonverbal vocalizations
(NVs). In this work, we introduce NonverbalTTS (NVTTS), a 17-hour open-access
dataset annotated with 10 types of NVs (e.g., laughter, coughs) and 8 emotional
categories. The dataset is derived from popular sources, VoxCeleb and Expresso,
using automated detection followed by human validation. We propose a
comprehensive pipeline that integrates automatic speech recognition (ASR), NV
tagging, emotion classification, and a fusion algorithm to merge transcriptions
from multiple annotators. Fine-tuning open-source text-to-speech (TTS) models
on the NVTTS dataset achieves parity with closed-source systems such as
CosyVoice2, as measured by both human evaluation and automatic metrics,
including speaker similarity and NV fidelity. By releasing NVTTS and its
accompanying annotation guidelines, we address a key bottleneck in expressive
TTS research. The dataset is available at
https://huggingface.co/datasets/deepvk/NonverbalTTS.

</details>


### [201] [Spectral Bellman Method: Unifying Representation and Exploration in RL](https://arxiv.org/abs/2507.13181)
*Ofir Nabati,Bo Dai,Shie Mannor,Guy Tennenholtz*

Main category: cs.LG

TL;DR: 该研究提出了一种名为Spectral Bellman Representation的框架，其通过特征协方差与Bellman算子间的谱关系改进了强化学习中的表示学习，有效优化了性能。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有表示学习方法与强化学习任务不完全对齐的问题，提出改进的框架以提高强化学习性能，尤其是在困难探索和长时间奖励分配任务中。

Method: 该方法基于固有Bellman误差(IBE)条件，推导出一种新的谱关系，并用其作为目标函数优化表示学习。

Result: 通过简单修改现有算法，所学表示能够实现更好的结构化探索，并在困难探索及长时间信用分配任务中表现突出，同时支持多步Bellman算子扩展。

Conclusion: Spectral Bellman Representation提供了一种理论扎实且有效的解决方案，不仅提升了强化学习的性能，还促进了更结构化和强大的表示学习的发展。

Abstract: The effect of representation has been demonstrated in reinforcement learning,
from both theoretical and empirical successes. However, the existing
representation learning mainly induced from model learning aspects, misaligning
with our RL tasks. This work introduces Spectral Bellman Representation, a
novel framework derived from the Inherent Bellman Error (IBE) condition, which
aligns with the fundamental structure of Bellman updates across a space of
possible value functions, therefore, directly towards value-based RL. Our key
insight is the discovery of a fundamental spectral relationship: under the
zero-IBE condition, the transformation of a distribution of value functions by
the Bellman operator is intrinsically linked to the feature covariance
structure. This spectral connection yields a new, theoretically-grounded
objective for learning state-action features that inherently capture this
Bellman-aligned covariance. Our method requires a simple modification to
existing algorithms. We demonstrate that our learned representations enable
structured exploration, by aligning feature covariance with Bellman dynamics,
and improve overall performance, particularly in challenging hard-exploration
and long-horizon credit assignment tasks. Our framework naturally extends to
powerful multi-step Bellman operators, further broadening its impact. Spectral
Bellman Representation offers a principled and effective path toward learning
more powerful and structurally sound representations for value-based
reinforcement learning.

</details>


### [202] [GradNetOT: Learning Optimal Transport Maps with GradNets](https://arxiv.org/abs/2507.13191)
*Shreyas Chaudhari,Srinivasa Pranav,José M. F. Moura*

Main category: cs.LG

TL;DR: 本文提出了使用 Monotone Gradient Networks (mGradNets) 来学习最优传输映射，通过利用其直接参数化单调梯度图的优势，提高学习效率并将其应用于机器人群控制。


<details>
  <summary>Details</summary>
Motivation: 单调梯度函数在解决最优传输问题中至关重要，作者致力于改进现有方法，通过网络模型更高效地解决相关的单调梯度函数计算问题，在现代应用如机器人群控制中有直接意义。

Method: 引入单调梯度网络(mGradNets)，通过直接参数化单调梯度映射的空间，结合训练损失函数中使用的Monge-Ampère方程，以最小化损失函数来学习优化运输映射。

Result: 实验结果表明，mGradNets的结构偏移特性可以有效促进最优传输图的学习，同时成功将其应用于机器人群控制问题。

Conclusion: mGradNets 提供了一种便捷高效的学习最优传输映射的方法，可以应用于多种领域问题，例如机器人群控制，验证了其在现代应用中的强大潜力。

Abstract: Monotone gradient functions play a central role in solving the Monge
formulation of the optimal transport problem, which arises in modern
applications ranging from fluid dynamics to robot swarm control. When the
transport cost is the squared Euclidean distance, Brenier's theorem guarantees
that the unique optimal map is the gradient of a convex function, namely a
monotone gradient map, and it satisfies a Monge-Amp\`ere equation. In
[arXiv:2301.10862] [arXiv:2404.07361], we proposed Monotone Gradient Networks
(mGradNets), neural networks that directly parameterize the space of monotone
gradient maps. In this work, we leverage mGradNets to directly learn the
optimal transport mapping by minimizing a training loss function defined using
the Monge-Amp\`ere equation. We empirically show that the structural bias of
mGradNets facilitates the learning of optimal transport maps and employ our
method for a robot swarm control problem.

</details>


### [203] [MoTM: Towards a Foundation Model for Time Series Imputation based on Continuous Modeling](https://arxiv.org/abs/2507.13207)
*Etienne Le Naour,Tahar Nabil,Ghislain Agoua*

Main category: cs.LG

TL;DR: 本文研究跨域时间序列缺失值插补问题，提出基于隐式神经表示的MoTM模型，可适应不同插补场景，显示了强大的通用化能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注时间序列的预测任务，然而对于跨域缺失值插补的探索较少。

Method: 提出MoTM模型，通过独立训练的隐式神经表示(INRs)和岭回归相结合，适应推断时的上下文。

Result: 该模型在多种插补场景下显示出在域内和跨域强大的通用化能力，包括分块缺失、点状缺失及变量采样率等。

Conclusion: 提出的MoTM模型是适应性强的基础插补模型，为时间序列插补领域提供了新的方向。

Abstract: Recent years have witnessed a growing interest for time series foundation
models, with a strong emphasis on the forecasting task. Yet, the crucial task
of out-of-domain imputation of missing values remains largely underexplored. We
propose a first step to fill this gap by leveraging implicit neural
representations (INRs). INRs model time series as continuous functions and
naturally handle various missing data scenarios and sampling rates. While they
have shown strong performance within specific distributions, they struggle
under distribution shifts. To address this, we introduce MoTM (Mixture of
Timeflow Models), a step toward a foundation model for time series imputation.
Building on the idea that a new time series is a mixture of previously seen
patterns, MoTM combines a basis of INRs, each trained independently on a
distinct family of time series, with a ridge regressor that adapts to the
observed context at inference. We demonstrate robust in-domain and
out-of-domain generalization across diverse imputation scenarios (e.g., block
and pointwise missingness, variable sampling rates), paving the way for
adaptable foundation imputation models.

</details>


### [204] [Leveraging Asynchronous Cross-border Market Data for Improved Day-Ahead Electricity Price Forecasting in European Markets](https://arxiv.org/abs/2507.13250)
*Maria Margarida Mascarenhas,Jilles De Blauwe,Mikael Amelin,Hussain Kazmi*

Main category: cs.LG

TL;DR: 本文探讨了不同市场的电价数据是否能提高电价预测准确性，并通过模型验证了其效果，显示显著的预测改进。


<details>
  <summary>Details</summary>
Motivation: 在日前市场中精确的短期电价预测对于制定需求和发电竞标的策略安排至关重要，而现有数据驱动技术对数据输入质量高度依赖。

Method: 研究是否可利用不同竞标区域因关闭时间差异而异步发布的电价数据，通过使用集合模型验证其对预测准确性的改善情况。

Result: 纳入具有更早门限时间的市场（德国-卢森堡、奥地利、瑞士）的电价数据后，比利时和瑞典竞标区预测准确性分别提高了22％和9％。

Conclusion: 研究表明异步发布电价数据可显著提高预测准确性，同时强调模型重新校准的重要性以及数据来源增加未必提升表现的现象，为优化竞标策略提供了重要指导。

Abstract: Accurate short-term electricity price forecasting is crucial for
strategically scheduling demand and generation bids in day-ahead markets. While
data-driven techniques have shown considerable prowess in achieving high
forecast accuracy in recent years, they rely heavily on the quality of input
covariates. In this paper, we investigate whether asynchronously published
prices as a result of differing gate closure times (GCTs) in some bidding zones
can improve forecasting accuracy in other markets with later GCTs. Using a
state-of-the-art ensemble of models, we show significant improvements of 22%
and 9% in forecast accuracy in the Belgian (BE) and Swedish bidding zones (SE3)
respectively, when including price data from interconnected markets with
earlier GCT (Germany-Luxembourg, Austria, and Switzerland). This improvement
holds for both general as well as extreme market conditions. Our analysis also
yields further important insights: frequent model recalibration is necessary
for maximum accuracy but comes at substantial additional computational costs,
and using data from more markets does not always lead to better performance - a
fact we delve deeper into with interpretability analysis of the forecast
models. Overall, these findings provide valuable guidance for market
participants and decision-makers aiming to optimize bidding strategies within
increasingly interconnected and volatile European energy markets.

</details>


### [205] [Merge Kernel for Bayesian Optimization on Permutation Space](https://arxiv.org/abs/2507.13263)
*Zikai Xie,Linjiang Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于排序算法的新框架，用于生成置换空间的核函数，并引入了复杂度更低的Merge Kernel，在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的Mallows核在置换空间优化中表现出色，但计算复杂度较高，限制了实际应用的效率。

Method: 提出一个通过排序算法生成核函数的新框架，结合Merge Sort构建Merge Kernel，并引入三个轻量且任务无关的描述符，以增强核函数性能。

Result: Merge Kernel显著降低了计算复杂度，同时维持甚至提升了对置换距离的捕捉能力，在多个基准测试中效果优于Mallows核。

Conclusion: Merge Kernel在性能和计算效率之间达到了更优的平衡，为置换空间的贝叶斯优化提供了更高效的解决方案。

Abstract: Bayesian Optimization (BO) algorithm is a standard tool for black-box
optimization problems. The current state-of-the-art BO approach for permutation
spaces relies on the Mallows kernel-an $\Omega(n^2)$ representation that
explicitly enumerates every pairwise comparison. Inspired by the close
relationship between the Mallows kernel and pairwise comparison, we propose a
novel framework for generating kernel functions on permutation space based on
sorting algorithms. Within this framework, the Mallows kernel can be viewed as
a special instance derived from bubble sort. Further, we introduce the
\textbf{Merge Kernel} constructed from merge sort, which replaces the quadratic
complexity with $\Theta(n\log n)$ to achieve the lowest possible complexity.
The resulting feature vector is significantly shorter, can be computed in
linearithmic time, yet still efficiently captures meaningful permutation
distances. To boost robustness and right-invariance without sacrificing
compactness, we further incorporate three lightweight, task-agnostic
descriptors: (1) a shift histogram, which aggregates absolute element
displacements and supplies a global misplacement signal; (2) a split-pair line,
which encodes selected long-range comparisons by aligning elements across the
two halves of the whole permutation; and (3) sliding-window motifs, which
summarize local order patterns that influence near-neighbor objectives. Our
empirical evaluation demonstrates that the proposed kernel consistently
outperforms the state-of-the-art Mallows kernel across various permutation
optimization benchmarks. Results confirm that the Merge Kernel provides a more
compact yet more effective solution for Bayesian optimization in permutation
space.

</details>


### [206] [Boosting Team Modeling through Tempo-Relational Representation Learning](https://arxiv.org/abs/2507.13305)
*Vincenzo Marco De Luca,Giovanna Varni,Andrea Passerini*

Main category: cs.LG

TL;DR: 论文提出了一种名为TRENN的新型团队建模框架，通过联合建模团队的关系与时间动态，能够同时预测多种团队构成，并提供可解释性增强团队表现的建议。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有的团队建模方法无法同时满足动态关系建模与实践应用需求的问题。

Method: 提出了一种名为TRENN的架构，包括自动时间图提取器、时间关系编码器、解码器以及可解释性模块，并通过扩展MT-TRENN实现多任务学习与多团队构造预测。

Result: 实验结果表明，相比单一使用时间或关系信息的方法，MT-TRENN表现更优，并且其可解释性模块可生成可操作的团队改进建议。

Conclusion: TRENN及其扩展方法适用于高要求环境下的人机交互AI系统，如高风险的协作决策支持系统。

Abstract: Team modeling remains a fundamental challenge at the intersection of
Artificial Intelligence and the Social Sciences. Social Science research
emphasizes the need to jointly model dynamics and relations, while practical
applications demand unified models capable of inferring multiple team
constructs simultaneously, providing interpretable insights and actionable
recommendations to enhance team performance. However, existing works do not
meet these practical demands. To bridge this gap, we present TRENN, a novel
tempo-relational architecture that integrates: (i) an automatic temporal graph
extractor, (ii) a tempo-relational encoder, (iii) a decoder for team construct
prediction, and (iv) two complementary explainability modules. TRENN jointly
captures relational and temporal team dynamics, providing a solid foundation
for MT-TRENN, which extends TReNN by replacing the decoder with a multi-task
head, enabling the model to learn shared Social Embeddings and simultaneously
predict multiple team constructs, including Emergent Leadership, Leadership
Style, and Teamwork components. Experimental results demonstrate that our
approach significantly outperforms approaches that rely exclusively on temporal
or relational information. Additionally, experimental evaluation has shown that
the explainability modules integrated in MT-TRENN yield interpretable insights
and actionable suggestions to support team improvement. These capabilities make
our approach particularly well-suited for Human-Centered AI applications, such
as intelligent decision-support systems in high-stakes collaborative
environments.

</details>


### [207] [GeoReg: Weight-Constrained Few-Shot Regression for Socio-Economic Estimation using LLM](https://arxiv.org/abs/2507.13323)
*Kyeongjin Ahn,Sungwon Han,Seungeon Lee,Donghyun Ahn,Hyoshin Kim,Jungwon Kim,Jihee Kim,Sangyoon Park,Meeyoung Cha*

Main category: cs.LG

TL;DR: 研究提出了一种名为GeoReg的回归模型，通过整合卫星图像、网络地理空间信息等多源数据，估算区域GDP、人口、教育水平等社会经济指标，即便在数据稀缺的情况下也能实现出色的性能。


<details>
  <summary>Details</summary>
Motivation: 社会经济指标对政策制定和可持续发展具有重要作用，但在数据稀缺地区，尤其是发展中国家，这些指标的估算存在困难。

Method: 提出GeoReg模型，将大语言模型用于特征提取以应对数据稀缺，结合线性估算器和非线性模式捕捉技术，以少量标注数据实现精准估算。

Result: GeoReg在三个不同发展阶段的国家中均表现优于基线方法，尤其在低收入和数据稀缺地区表现突出。

Conclusion: GeoReg模型能够在数据稀缺的情境下有效估算社会经济指标，为政策制定提供支持，展示了利用多源数据与大语言模型结合的潜力。

Abstract: Socio-economic indicators like regional GDP, population, and education
levels, are crucial to shaping policy decisions and fostering sustainable
development. This research introduces GeoReg a regression model that integrates
diverse data sources, including satellite imagery and web-based geospatial
information, to estimate these indicators even for data-scarce regions such as
developing countries. Our approach leverages the prior knowledge of large
language model (LLM) to address the scarcity of labeled data, with the LLM
functioning as a data engineer by extracting informative features to enable
effective estimation in few-shot settings. Specifically, our model obtains
contextual relationships between data features and the target indicator,
categorizing their correlations as positive, negative, mixed, or irrelevant.
These features are then fed into the linear estimator with tailored weight
constraints for each category. To capture nonlinear patterns, the model also
identifies meaningful feature interactions and integrates them, along with
nonlinear transformations. Experiments across three countries at different
stages of development demonstrate that our model outperforms baselines in
estimating socio-economic indicators, even for low-income countries with
limited data availability.

</details>


### [208] [Training Transformers with Enforced Lipschitz Constants](https://arxiv.org/abs/2507.13338)
*Laker Newhouse,R. Preston Hess,Franz Cesista,Andrii Zahorodnii,Jeremy Bernstein,Phillip Isola*

Main category: cs.LG

TL;DR: 该研究探讨了通过新的计算工具实现带Lipschitz界约束的transformer模型训练，并报告了该方法的优势和限制。


<details>
  <summary>Details</summary>
Motivation: 神经网络对输入和权重扰动的高敏感性导致训练不稳定和过拟合问题。研究旨在通过Lipschitz约束方法减轻上述问题，并探索将其应用于现代结构如transformer中的可能性。

Method: 开发并验证了一种高效计算工具，以在训练过程中维持权重矩阵的Lipschitz界约束。并结合优化器，如Muon，与方法如光谱归一等联合使用改进表现。

Result: 带Lipschitz约束的2-Lipschitz Transformer在Shakespeare文本上达60%验证准确率，但对大规模模型如145M参数的transformer，虽保持了稳定性，但性能仍需更高的上界才能匹配当前基线。

Conclusion: 虽然Lipschitz Transformer方法在实现稳定训练方面展现了前景，但仍需解决性能与Lipschitz上界的权衡问题，以达到实用化水平。

Abstract: Neural networks are often highly sensitive to input and weight perturbations.
This sensitivity has been linked to pathologies such as vulnerability to
adversarial examples, divergent training, and overfitting. To combat these
problems, past research has looked at building neural networks entirely from
Lipschitz components. However, these techniques have not matured to the point
where researchers have trained a modern architecture such as a transformer with
a Lipschitz certificate enforced beyond initialization. To explore this gap, we
begin by developing and benchmarking novel, computationally-efficient tools for
maintaining norm-constrained weight matrices. Applying these tools, we are able
to train transformer models with Lipschitz bounds enforced throughout training.
We find that optimizer dynamics matter: switching from AdamW to Muon improves
standard methods -- weight decay and spectral normalization -- allowing models
to reach equal performance with a lower Lipschitz bound. Inspired by Muon's
update having a fixed spectral norm, we co-design a weight constraint method
that improves the Lipschitz vs. performance tradeoff on MLPs and 2M parameter
transformers. Our 2-Lipschitz transformer on Shakespeare text reaches
validation accuracy 60%. Scaling to 145M parameters, our 10-Lipschitz
transformer reaches 21% accuracy on internet text. However, to match the
NanoGPT baseline validation accuracy of 39.4%, our Lipschitz upper bound
increases to 10^264. Nonetheless, our Lipschitz transformers train without
stability measures such as layer norm, QK norm, and logit tanh softcapping.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [209] [Adversarial attacks to image classification systems using evolutionary algorithms](https://arxiv.org/abs/2507.13136)
*Sergio Nesmachnow,Jamal Toutouh*

Main category: cs.NE

TL;DR: 本文提出利用进化算法与生成对抗网络（GAN）结合生成人工智能图像分类中的对抗攻击。


<details>
  <summary>Details</summary>
Motivation: 解决人工智能图像分类模型遭受对抗攻击的安全问题。

Method: 将生成对抗网络的潜在空间与进化算法结合，寻找能够生成对抗攻击的向量。

Result: 在手写数字和物体分类任务中，对抗攻击的成功率分别达到35%和75%，并优于其他方法。

Conclusion: 该方法在应对数据多样性及复杂问题实例时表现出色，是生成对抗攻击的一种有效途径。

Abstract: Image classification currently faces significant security challenges due to
adversarial attacks, which consist of intentional alterations designed to
deceive classification models based on artificial intelligence. This article
explores an approach to generate adversarial attacks against image classifiers
using a combination of evolutionary algorithms and generative adversarial
networks. The proposed approach explores the latent space of a generative
adversarial network with an evolutionary algorithm to find vectors representing
adversarial attacks. The approach was evaluated in two case studies
corresponding to the classification of handwritten digits and object images.
The results showed success rates of up to 35% for handwritten digits, and up to
75% for object images, improving over other search methods and reported results
in related works. The applied method proved to be effective in handling data
diversity on the target datasets, even in problem instances that presented
additional challenges due to the complexity and richness of information.

</details>


### [210] [Multi-population GAN Training: Analyzing Co-Evolutionary Algorithms](https://arxiv.org/abs/2507.13157)
*Walter P. Casas,Jamal Toutouh*

Main category: cs.NE

TL;DR: 本文分析了共进化GAN（生成对抗网络）训练策略，发现(mu,lambda)方案在样本质量和多样性上表现最好，特别是与更大的子代规模结合时。


<details>
  <summary>Details</summary>
Motivation: 针对GAN训练中存在的问题（如模式坍缩和不稳定性），本文探讨共进化生成器和判别器的潜力。

Method: 采用实证分析对比了(mu,lambda)、(mu+lambda)表面精英主义和竞赛选择机制，以及一种非进化基多生成器多判别器GAN基准方案。在低维合成数据集和MNIST数据集中测试。

Result: (mu,lambda)机制的代际更替方案能显著提升样本质量和多样性，而精英主义方法会过早收敛并导致多样性降低。

Conclusion: 研究表明，在共进化GAN训练中，探索与开发的动态平衡至关重要并提供了设计更有效的群体生成模型的建议。

Abstract: Generative adversarial networks (GANs) are powerful generative models but
remain challenging to train due to pathologies suchas mode collapse and
instability. Recent research has explored co-evolutionary approaches, in which
populations of generators and discriminators are evolved, as a promising
solution. This paper presents an empirical analysis of different coevolutionary
GAN training strategies, focusing on the impact of selection and replacement
mechanisms. We compare (mu,lambda), (mu+lambda) with elitism, and (mu+lambda)
with tournament selection coevolutionary schemes, along with a non-evolutionary
population based multi-generator multi-discriminator GAN baseline, across both
synthetic low-dimensional datasets (blob and gaussian mixtures) and an
image-based benchmark (MNIST). Results show that full generational replacement,
i.e., (mu,lambda), consistently outperforms in terms of both sample quality and
diversity, particularly when combined with larger offspring sizes. In contrast,
elitist approaches tend to converge prematurely and suffer from reduced
diversity. These findings highlight the importance of balancing exploration and
exploitation dynamics in coevolutionary GAN training and provide guidance for
designing more effective population-based generative models.

</details>
