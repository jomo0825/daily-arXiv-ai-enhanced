<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 82]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.AI](#cs.AI) [Total: 20]
- [cs.LG](#cs.LG) [Total: 53]
- [cs.NE](#cs.NE) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives](https://arxiv.org/abs/2507.13359)
*Yang Zhou,Junjie Li,CongYang Ou,Dawei Yan,Haokui Zhang,Xizhe Xue*

Main category: cs.CV

TL;DR: 无人机航空图像中，传统方法的目标检测受到预定义类别的限制，而基于文本-图像对齐的新方法（例如CLIP）推动了开放词汇目标检测（OVOD）的发展。本综述探讨了OVOD在无人机航空场景中的应用及未来方向。


<details>
  <summary>Details</summary>
Motivation: 传统方法中，目标检测的类别限制了无人机在复杂场景中的实际应用，而开放词汇目标检测可以识别通过自然语言描述的新目标，为无人机场景理解带来更高自主性与智能化。

Method: 对现有文献进行系统化分类，总结航空图像中OVOD的方法及相关数据集，对该领域的关键挑战及问题进行全面评估，提出研究方向与应用前景。

Result: 构建了OVOD方法的系统分类，全面分析了相关数据集及文献，明确了该领域的主要挑战，揭示了交叉领域的研究契机。

Conclusion: 本综述为研究者提供了一个清晰的路径和宝贵的参考，旨在推动无人机航空场景中开放词汇目标检测领域的协同创新与快速迭代。

Abstract: Due to its extensive applications, aerial image object detection has long
been a hot topic in computer vision. In recent years, advancements in Unmanned
Aerial Vehicles (UAV) technology have further propelled this field to new
heights, giving rise to a broader range of application requirements. However,
traditional UAV aerial object detection methods primarily focus on detecting
predefined categories, which significantly limits their applicability. The
advent of cross-modal text-image alignment (e.g., CLIP) has overcome this
limitation, enabling open-vocabulary object detection (OVOD), which can
identify previously unseen objects through natural language descriptions. This
breakthrough significantly enhances the intelligence and autonomy of UAVs in
aerial scene understanding. This paper presents a comprehensive survey of OVOD
in the context of UAV aerial scenes. We begin by aligning the core principles
of OVOD with the unique characteristics of UAV vision, setting the stage for a
specialized discussion. Building on this foundation, we construct a systematic
taxonomy that categorizes existing OVOD methods for aerial imagery and provides
a comprehensive overview of the relevant datasets. This structured review
enables us to critically dissect the key challenges and open problems at the
intersection of these fields. Finally, based on this analysis, we outline
promising future research directions and application prospects. This survey
aims to provide a clear road map and a valuable reference for both newcomers
and seasoned researchers, fostering innovation in this rapidly evolving domain.
We keep tracing related works at
https://github.com/zhouyang2002/OVOD-in-UVA-imagery

</details>


### [2] [Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance](https://arxiv.org/abs/2507.13360)
*Le-Anh Tran,Chung Nguyen Tran,Ngoc-Luu Nguyen,Nhan Cach Dang,Jordi Carrabina,David Castells-Rufas,Minh Son Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一个名为EDNIG的新型深度学习框架，用于低光图像增强。


<details>
  <summary>Details</summary>
Motivation: 解决低光图像增强中现有方法在处理多样光照条件时的局限性，从而提升增强效果并降低模型复杂性。

Method: 基于U-Net架构，融合亮通道先验计算的光照图作为引导，同时加入空间金字塔池化模块以提取多尺度上下文特征，并采用Swish激活函数，且在生成对抗网络框架下优化。

Result: 实验结果表明，该方法在定量指标和视觉质量上均表现优异，同时模型复杂性较低。

Conclusion: EDNIG能够有效增强低光图像，具备实际应用的潜力，并提供源代码供进一步研究。

Abstract: This paper introduces a novel deep learning framework for low-light image
enhancement, named the Encoder-Decoder Network with Illumination Guidance
(EDNIG). Building upon the U-Net architecture, EDNIG integrates an illumination
map, derived from Bright Channel Prior (BCP), as a guidance input. This
illumination guidance helps the network focus on underexposed regions,
effectively steering the enhancement process. To further improve the model's
representational power, a Spatial Pyramid Pooling (SPP) module is incorporated
to extract multi-scale contextual features, enabling better handling of diverse
lighting conditions. Additionally, the Swish activation function is employed to
ensure smoother gradient propagation during training. EDNIG is optimized within
a Generative Adversarial Network (GAN) framework using a composite loss
function that combines adversarial loss, pixel-wise mean squared error (MSE),
and perceptual loss. Experimental results show that EDNIG achieves competitive
performance compared to state-of-the-art methods in quantitative metrics and
visual quality, while maintaining lower model complexity, demonstrating its
suitability for real-world applications. The source code for this work is
available at https://github.com/tranleanh/ednig.

</details>


### [3] [VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs](https://arxiv.org/abs/2507.13361)
*Shmuel Berman,Jia Deng*

Main category: cs.CV

TL;DR: 研究表明，尽管视觉语言模型（VLMs）在复杂视觉任务上表现出色，但在基本的非局部视觉推理任务上表现较差，远低于人类表现。


<details>
  <summary>Details</summary>
Motivation: 探讨和评估当前视觉语言模型在非局部视觉推理能力上的表现，包括比较感知、扫描式搜索和连续视觉搜索。

Method: 设计了三个非局部视觉推理测试任务来评估模型：比较感知任务、扫描跳跃式搜索任务，以及平滑视觉搜索任务。

Result: 主流视觉语言模型在这些非局部视觉任务中的表现接近随机水平，显著落后于人类。

Conclusion: 虽然当前模型在视觉敏锐度上有所提升，但仍缺乏关键的视觉推理能力。

Abstract: Visual Language Models (VLMs) excel at complex visual tasks such as VQA and
chart understanding, yet recent work suggests they struggle with simple
perceptual tests. We present an evaluation that tests vision-language models'
capacity for nonlocal visual reasoning -- reasoning that requires chaining
evidence collected from multiple, possibly distant, regions of an image. We
isolate three distinct forms of non-local vision: comparative perception, which
demands holding two images in working memory and comparing them; saccadic
search, which requires making discrete, evidence-driven jumps to locate
successive targets; and smooth visual search, which involves searching smoothly
along a continuous contour. Flagship models (e.g., Gemini 2.5 Pro, Claude
Vision 3.7, GPT-o4-mini), even those that perform well on prior
primitive-vision benchmarks, fail these tests and barely exceed random accuracy
on two variants of our tasks that are trivial for humans. Our structured
evaluation suite allows us to test if VLMs can perform similar visual
algorithms to humans. Our findings show that despite gains in raw visual
acuity, current models lack core visual reasoning capabilities.

</details>


### [4] [Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning](https://arxiv.org/abs/2507.13362)
*Binbin Ji,Siddharth Agrawal,Qiance Tang,Yvonne Wu*

Main category: cs.CV

TL;DR: 本文研究了视觉语言模型的空间推理能力，通过链式思维（CoT）提示和强化学习的方法。发现简单的CoT格式可能对模型不利，而基于场景图的结构化多阶段提示显著提高了空间推理的准确性。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过提示策略和强化学习改善视觉语言模型的空间推理能力，并在领域外（OOD）条件下保持稳健性。

Method: 评估不同的CoT提示策略，并结合基于场景图的CoT设计，同时使用群体相对策略优化（GRPO）对模型进行微调，并在多个数据集上进行性能评估。

Result: 与监督微调相比，GRPO在Pass@1评估上表现更优，并能在测试时的语言表述改变或分布外（OOD）情况中保持稳健。

Conclusion: 结构化提示和强化学习策略能有效提高现代视觉语言模型的空间推理能力及泛化性能。

Abstract: This study investigates the spatial reasoning capabilities of vision-language
models (VLMs) through Chain-of-Thought (CoT) prompting and reinforcement
learning. We begin by evaluating the impact of different prompting strategies
and find that simple CoT formats, where the model generates a reasoning step
before the answer, not only fail to help, but can even harm the model's
original performance. In contrast, structured multi-stage prompting based on
scene graphs (SceneGraph CoT) significantly improves spatial reasoning
accuracy. Furthermore, to improve spatial reasoning ability, we fine-tune
models using Group Relative Policy Optimization (GRPO) on the SAT dataset and
evaluate their performance on CVBench. Compared to supervised fine-tuning
(SFT), GRPO achieves higher accuracy on Pass@1 evaluations and demonstrates
superior robustness under out-of-distribution (OOD) conditions. In particular,
we find that SFT overfits to surface-level linguistic patterns and may degrade
performance when test-time phrasing changes (e.g., from "closer to" to "farther
from"). GRPO, on the other hand, generalizes more reliably and maintains stable
performance under such shifts. Our findings provide insights into how
reinforcement learning and structured prompting improve the spatial reasoning
capabilities and generalization behavior of modern VLMs. All code is open
source at: https://github.com/Yvonne511/spatial-vlm-investigator

</details>


### [5] [Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop](https://arxiv.org/abs/2507.13363)
*Atharv Goel,Mehar Khurana*

Main category: cs.CV

TL;DR: 本文提出一种训练自由的开放词汇3D目标检测方法，通过使用2D视觉语言模型结合几何方法实现，不需要人工标注的3D标签并在多种输入条件下表现出色。


<details>
  <summary>Details</summary>
Motivation: 目前3D目标检测面临分类范围狭窄和手动标注成本高的问题，难以扩展到开放环境中。2D视觉语言模型具备丰富的语义理解能力和开放词汇检测潜力。本文旨在探索如何利用这类2D模型实现开放词汇的3D目标检测。

Method: 利用2D视觉语言检测器生成基于文本条件的目标框提议，再结合分割、重投影、DBSCAN聚类和几何膨胀策略推测3D包围盒，无需训练和人工标注。

Result: 实验表明，该方法在包含LiDAR和纯RGB-D输入的多种条件下实现了具有竞争力的定位性能，展示了2D基础模型在3D感知领域的巨大潜力。

Conclusion: 本文创新性地展现了利用2D基础模型进行开放词汇3D目标检测的可行性和有效性，为开放世界的3D感知提供了新思路，同时开源代码促进了研究社区的进一步发展。

Abstract: Modern 3D object detection datasets are constrained by narrow class
taxonomies and costly manual annotations, limiting their ability to scale to
open-world settings. In contrast, 2D vision-language models trained on
web-scale image-text pairs exhibit rich semantic understanding and support
open-vocabulary detection via natural language prompts. In this work, we
leverage the maturity and category diversity of 2D foundation models to perform
open-vocabulary 3D object detection without any human-annotated 3D labels.
  Our pipeline uses a 2D vision-language detector to generate text-conditioned
proposals, which are segmented with SAM and back-projected into 3D using camera
geometry and either LiDAR or monocular pseudo-depth. We introduce a geometric
inflation strategy based on DBSCAN clustering and Rotating Calipers to infer 3D
bounding boxes without training. To simulate adverse real-world conditions, we
construct Pseudo-nuScenes, a fog-augmented, RGB-only variant of the nuScenes
dataset.
  Experiments demonstrate that our method achieves competitive localization
performance across multiple settings, including LiDAR-based and purely RGB-D
inputs, all while remaining training-free and open-vocabulary. Our results
highlight the untapped potential of 2D foundation models for scalable 3D
perception. We open-source our code and resources at
https://github.com/atharv0goel/open-world-3D-det.

</details>


### [6] [OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning](https://arxiv.org/abs/2507.13364)
*Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

TL;DR: 本文提出了一种新型多模态多任务网络及相关训练算法，该方法能够处理12种不同模态的数据，通过变换器架构与交叉注意力机制实现在统一嵌入空间中的投影，并取得了多个数据集上的先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前多模态数据处理和任务之间的融合问题，提供一种统一的网络架构以支持多模态多任务场景。

Method: 利用模态专用的分词器、共享的Transformer架构和交叉注意力机制，将不同模态数据投影至统一嵌入空间。提出了一种新的预训练策略（迭代模态切换）和训练算法（通过模态对的渐进式训练）。

Result: 在来自12种模态的25个数据集上进行广泛评估，结果显示该方法具有先进性能。

Conclusion: 提出的方法证明了其在多模态融合及多任务处理方面的有效性，并在多数据集上表现出优越的性能。

Abstract: We present a novel multimodal multitask network and associated training
algorithm. The method is capable of ingesting data from approximately 12
different modalities namely image, video, audio, text, depth, point cloud, time
series, tabular, graph, X-ray, infrared, IMU, and hyperspectral. The proposed
approach utilizes modality specialized tokenizers, a shared transformer
architecture, and cross-attention mechanisms to project the data from different
modalities into a unified embedding space. It addresses multimodal and
multitask scenarios by incorporating modality-specific task heads for different
tasks in respective modalities. We propose a novel pretraining strategy with
iterative modality switching to initialize the network, and a training
algorithm which trades off fully joint training over all modalities, with
training on pairs of modalities at a time. We provide comprehensive evaluation
across 25 datasets from 12 modalities and show state of the art performances,
demonstrating the effectiveness of the proposed architecture, pretraining
strategy and adapted multitask training.

</details>


### [7] [Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation](https://arxiv.org/abs/2507.13371)
*Yeming Cai,Yang Wang,Zhenglin Li*

Main category: cs.CV

TL;DR: 研究提出了一种集成光学动作捕捉和基于Transformer模型的端到端深度学习框架，用于提升医疗康复效果。


<details>
  <summary>Details</summary>
Motivation: 解决动作捕捉数据因遮挡和环境因素导致的噪声和缺失问题，同时实时检测异常动作以保障患者安全。

Method: 通过时间序列建模，对动作捕捉数据进行去噪与补全，提升数据鲁棒性，并基于Transformer模型实现端到端建模。

Result: 在中风和骨科康复数据集上的评估表明，该框架在数据重建和异常检测上具有优越性能。

Conclusion: 本研究提供了一种可扩展、成本效益高的远程康复解决方案，减少了现场监督的需求。

Abstract: This paper proposes an end-to-end deep learning framework integrating optical
motion capture with a Transformer-based model to enhance medical
rehabilitation. It tackles data noise and missing data caused by occlusion and
environmental factors, while detecting abnormal movements in real time to
ensure patient safety. Utilizing temporal sequence modeling, our framework
denoises and completes motion capture data, improving robustness. Evaluations
on stroke and orthopedic rehabilitation datasets show superior performance in
data reconstruction and anomaly detection, providing a scalable, cost-effective
solution for remote rehabilitation with reduced on-site supervision.

</details>


### [8] [Enhancing Breast Cancer Detection with Vision Transformers and Graph Neural Networks](https://arxiv.org/abs/2507.13372)
*Yeming Cai,Zhenglin Li,Yang Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种结合视觉变压器（ViT）与图神经网络（GNN）的创新框架，用于提高乳腺癌检测的准确性，并取得了84.2%的精度。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性死亡的主要原因之一，早期检测对提高生存率至关重要。

Method: 提出了一个结合ViT与GNN的框架，分别利用ViT的全局图像特征提取能力和GNN的结构关系建模能力，并应用于CBIS-DDSM数据集。

Result: 该方法实现了84.2%的准确率，优于传统方法，并提供了可解释的注意力热图，辅助临床医生决策。

Conclusion: 整合不同模型的优势，不仅提高了乳腺癌检测的准确率，还提升了结果的可解释性，对临床应用具有实际价值。

Abstract: Breast cancer is a leading cause of death among women globally, and early
detection is critical for improving survival rates. This paper introduces an
innovative framework that integrates Vision Transformers (ViT) and Graph Neural
Networks (GNN) to enhance breast cancer detection using the CBIS-DDSM dataset.
Our framework leverages ViT's ability to capture global image features and
GNN's strength in modeling structural relationships, achieving an accuracy of
84.2%, outperforming traditional methods. Additionally, interpretable attention
heatmaps provide insights into the model's decision-making process, aiding
radiologists in clinical settings.

</details>


### [9] [Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection](https://arxiv.org/abs/2507.13373)
*Xiaojian Lin,Wenxin Zhang,Yuchu Jiang,Wangyu Wu,Yiran Guo,Kangxu Wang,Zongzheng Zhang,Guijin Wang,Lei Jin,Hao Zhao*

Main category: cs.CV

TL;DR: 本论文介绍了一种名为Butter的新型目标检测框架，它通过引入两个关键创新组件，提升了目标检测中的多层次特征表示能力，实现了精度与效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测网络（如YOLO和DETR）在特征一致性、检测精度与计算效率之间存在权衡问题，需改进以适应动态环境中的复杂任务。

Method: 提出Butter框架，其中包含两个关键组件：1) 自适应频率特征一致性增强 (FAFCE)，通过频率过滤提升多尺度特征一致性；2) 进阶层次特征融合网络 (PHFFNet)，逐层整合多层次特征以缩小语义差距。

Result: 通过在BDD100K、KITTI和Cityscapes数据集上的实验，Butter框架在检测精度和模型复杂度方面实现了显著提升。

Conclusion: Butter框架改进了层次特征表示与整合，为实时自动驾驶场景中的目标检测提供了精度、可部署性和计算效率之间的平衡。

Abstract: Hierarchical feature representations play a pivotal role in computer vision,
particularly in object detection for autonomous driving. Multi-level semantic
understanding is crucial for accurately identifying pedestrians, vehicles, and
traffic signs in dynamic environments. However, existing architectures, such as
YOLO and DETR, struggle to maintain feature consistency across different scales
while balancing detection precision and computational efficiency. To address
these challenges, we propose Butter, a novel object detection framework
designed to enhance hierarchical feature representations for improving
detection robustness. Specifically, Butter introduces two key innovations:
Frequency-Adaptive Feature Consistency Enhancement (FAFCE) Component, which
refines multi-scale feature consistency by leveraging adaptive frequency
filtering to enhance structural and boundary precision, and Progressive
Hierarchical Feature Fusion Network (PHFFNet) Module, which progressively
integrates multi-level features to mitigate semantic gaps and strengthen
hierarchical feature learning. Through extensive experiments on BDD100K, KITTI,
and Cityscapes, Butter demonstrates superior feature representation
capabilities, leading to notable improvements in detection accuracy while
reducing model complexity. By focusing on hierarchical feature refinement and
integration, Butter provides an advanced approach to object detection that
achieves a balance between accuracy, deployability, and computational
efficiency in real-time autonomous driving scenarios. Our model and
implementation are publicly available at https://github.com/Aveiro-Lin/Butter,
facilitating further research and validation within the autonomous driving
community.

</details>


### [10] [Smart Routing for Multimodal Video Retrieval: When to Search What](https://arxiv.org/abs/2507.13374)
*Kevin Dela Rosa*

Main category: cs.CV

TL;DR: 提出了一个称为ModaRoute的智能路由系统，以动态选择多模态视频检索的最优模式，显著减少计算开销并保持竞争力。


<details>
  <summary>Details</summary>
Motivation: 传统方法在视频检索中存在高计算成本及视觉信息丢失的问题，特别是在场景文字信息未被获取的情况下。

Method: 基于GPT-4.1的系统对查询意图进行分析并预测信息需求，在ASR、OCR和视觉索引之间智能路由查询，实现动态选择最优模式。

Result: ModaRoute将计算开销减少了41%，且在Recall@5指标上达到60.9%，并平均每次查询使用1.78种模式，优于传统的3.0模式穷尽搜索。

Conclusion: ModaRoute为多模态检索系统提供了一种实用的解决方案，在缩减基础设施成本的同时保证了实际部署中的有效性。

Abstract: We introduce ModaRoute, an LLM-based intelligent routing system that
dynamically selects optimal modalities for multimodal video retrieval. While
dense text captions can achieve 75.9% Recall@5, they require expensive offline
processing and miss critical visual information present in 34% of clips with
scene text not captured by ASR. By analyzing query intent and predicting
information needs, ModaRoute reduces computational overhead by 41% while
achieving 60.9% Recall@5. Our approach uses GPT-4.1 to route queries across ASR
(speech), OCR (text), and visual indices, averaging 1.78 modalities per query
versus exhaustive 3.0 modality search. Evaluation on 1.8M video clips
demonstrates that intelligent routing provides a practical solution for scaling
multimodal retrieval systems, reducing infrastructure costs while maintaining
competitive effectiveness for real-world deployment.

</details>


### [11] [A Comprehensive Survey for Real-World Industrial Defect Detection: Challenges, Approaches, and Prospects](https://arxiv.org/abs/2507.13378)
*Yuqi Cheng,Yunkang Cao,Haiming Yao,Wei Luo,Cheng Jiang,Hui Zhang,Weiming Shen*

Main category: cs.CV

TL;DR: 本文综述了工业缺陷检测领域的发展，特别是从封闭集到开放集检测的转变，以及2D和3D模式下的技术应用。并探讨了当前面临的挑战和未来趋势。


<details>
  <summary>Details</summary>
Motivation: 传统检测方法在现代制造需求中逐渐显得不足，需要借助计算机视觉和深度学习技术提升检测能力，尤其是开放集检测的兴起。

Method: 通过对封闭集和开放集缺陷检测的深度分析，涵盖2D与3D模式，并总结最新的研究进展与趋势。

Result: 揭示了现有方法的改进与不足，突出了开放集检测在检测新异常方面的优势，以及当前实际检测环境中的主要挑战。

Conclusion: 开放集检测方法强调了新技术的灵活性和潜力，为未来研究指明方向，同时结合综述提供了当前领域的全面见解。

Abstract: Industrial defect detection is vital for upholding product quality across
contemporary manufacturing systems. As the expectations for precision,
automation, and scalability intensify, conventional inspection approaches are
increasingly found wanting in addressing real-world demands. Notable progress
in computer vision and deep learning has substantially bolstered defect
detection capabilities across both 2D and 3D modalities. A significant
development has been the pivot from closed-set to open-set defect detection
frameworks, which diminishes the necessity for extensive defect annotations and
facilitates the recognition of novel anomalies. Despite such strides, a
cohesive and contemporary understanding of industrial defect detection remains
elusive. Consequently, this survey delivers an in-depth analysis of both
closed-set and open-set defect detection strategies within 2D and 3D
modalities, charting their evolution in recent years and underscoring the
rising prominence of open-set techniques. We distill critical challenges
inherent in practical detection environments and illuminate emerging trends,
thereby providing a current and comprehensive vista of this swiftly progressing
field.

</details>


### [12] [Using Multiple Input Modalities Can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery](https://arxiv.org/abs/2507.13385)
*Arjun Rao,Esther Rolf*

Main category: cs.CV

TL;DR: 研究表明，在用于遥感图像的机器学习模型中，结合多模态地理数据输入可显著改善模型性能，尤其是在数据有限或地理外样本场景中效果更为突出。


<details>
  <summary>Details</summary>
Motivation: 目前大多数遥感图像机器学习模型注重光学输入，而忽视了多模态地理数据可能带来的增益作用。该研究旨在探讨将其他模态数据与光学图像融合的潜力。

Method: 通过在已有的遥感机器学习基准任务中添加多模态地理数据层（如环境传感器数据等），生成增强版数据集，并评估其对分类、回归和分割任务的影响。

Result: 实验表明，多模态输入的结合显著提升了模型性能，特别是在标签数据稀缺或跨地理区域的样本外测试中效果最佳。另外，与学习型融合策略相比，硬编码式融合表现更优。

Conclusion: 研究显示多模态数据融合对于遥感机器学习具有重要意义，尤其是提升了数据效率和样本外性能，未来研究可深入探讨更优化的融合方法。

Abstract: A large variety of geospatial data layers is available around the world
ranging from remotely-sensed raster data like satellite imagery, digital
elevation models, predicted land cover maps, and human-annotated data, to data
derived from environmental sensors such as air temperature or wind speed data.
A large majority of machine learning models trained on satellite imagery
(SatML), however, are designed primarily for optical input modalities such as
multi-spectral satellite imagery. To better understand the value of using other
input modalities alongside optical imagery in supervised learning settings, we
generate augmented versions of SatML benchmark tasks by appending additional
geographic data layers to datasets spanning classification, regression, and
segmentation. Using these augmented datasets, we find that fusing additional
geographic inputs with optical imagery can significantly improve SatML model
performance. Benefits are largest in settings where labeled data are limited
and in geographic out-of-sample settings, suggesting that multi-modal inputs
may be especially valuable for data-efficiency and out-of-sample performance of
SatML models. Surprisingly, we find that hard-coded fusion strategies
outperform learned variants, with interesting implications for future work.

</details>


### [13] [Minimalist Concept Erasure in Generative Models](https://arxiv.org/abs/2507.13386)
*Yang Zhang,Er Jin,Yanfei Dong,Yixuan Wu,Philip Torr,Ashkan Khakzar,Johannes Stegmaier,Kenji Kawaguchi*

Main category: cs.CV

TL;DR: 提出了一种基于分布距离的生成模型概念删除方法，旨在在不影响整体性能的情况下安全删除不需要的概念。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型依赖大量未标记数据，存在安全性和版权问题，而现有的概念删除方法通常过于极端，影响模型的实用性。

Method: 提出一种基于最终输出分布距离的最小化概念删除目标，结合神经元屏蔽技术，通过可微优化的方式实现无过度修改的概念删除。

Result: 实验表明该方法在不降低模型性能的情况下，能够有效且稳健地删除不想要的概念。

Conclusion: 该方法为构建更加安全和负责任的生成模型提供了可能性。

Abstract: Recent advances in generative models have demonstrated remarkable
capabilities in producing high-quality images, but their reliance on
large-scale unlabeled data has raised significant safety and copyright
concerns. Efforts to address these issues by erasing unwanted concepts have
shown promise. However, many existing erasure methods involve excessive
modifications that compromise the overall utility of the model. In this work,
we address these issues by formulating a novel minimalist concept erasure
objective based \emph{only} on the distributional distance of final generation
outputs. Building on our formulation, we derive a tractable loss for
differentiable optimization that leverages backpropagation through all
generation steps in an end-to-end manner. We also conduct extensive analysis to
show theoretical connections with other models and methods. To improve the
robustness of the erasure, we incorporate neuron masking as an alternative to
model fine-tuning. Empirical evaluations on state-of-the-art flow-matching
models demonstrate that our method robustly erases concepts without degrading
overall model performance, paving the way for safer and more responsible
generative models.

</details>


### [14] [From Binary to Semantic: Utilizing Large-Scale Binary Occupancy Data for 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2507.13387)
*Chihiro Noguchi,Takaki Yamamoto*

Main category: cs.CV

TL;DR: 研究提出利用大规模二值占用数据从两个角度改善3D语义占用预测：预训练和基于学习的自动标注，提出了以二值占用为基础的预测框架，并证明该方法在实际任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前3D语义占用预测需要高成本的标注LiDAR点云数据，而大规模的二值占用数据成本更低且可用，但其潜力尚未被探索。

Method: 提出一个基于二值占用的框架，分解预测过程为二值占用模块和语义占用模块，以有效利用二值占用数据，同时从预训练和学习性的自动标注角度进行研究。

Result: 实验结果表明，该框架在预训练和自动标注任务上优于现有方法，有助于改进3D语义占用预测。

Conclusion: 基于二值占用数据的框架展示了在降低成本的同时，提升3D语义占用预测效果，具有实际意义和应用前景。

Abstract: Accurate perception of the surrounding environment is essential for safe
autonomous driving. 3D occupancy prediction, which estimates detailed 3D
structures of roads, buildings, and other objects, is particularly important
for vision-centric autonomous driving systems that do not rely on LiDAR
sensors. However, in 3D semantic occupancy prediction -- where each voxel is
assigned a semantic label -- annotated LiDAR point clouds are required, making
data acquisition costly. In contrast, large-scale binary occupancy data, which
only indicate occupied or free space without semantic labels, can be collected
at a lower cost. Despite their availability, the potential of leveraging such
data remains unexplored. In this study, we investigate the utilization of
large-scale binary occupancy data from two perspectives: (1) pre-training and
(2) learning-based auto-labeling. We propose a novel binary occupancy-based
framework that decomposes the prediction process into binary and semantic
occupancy modules, enabling effective use of binary occupancy data. Our
experimental results demonstrate that the proposed framework outperforms
existing methods in both pre-training and auto-labeling tasks, highlighting its
effectiveness in enhancing 3D semantic occupancy prediction. The code is
available at https://github.com/ToyotaInfoTech/b2s-occupancy

</details>


### [15] [InSyn: Modeling Complex Interactions for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2507.13397)
*Kaiyuan Zhai,Juan Chen,Chao Wang,Zeyi Xu*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的行人轨迹预测模型InSyn，能显式捕捉多样交互模式，并提出SSOS训练策略提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖相对位置建模行人交互，但忽视了特定交互模式（如同步行走或冲突行为），在拥挤场景中预测精度较低。

Method: 提出InSyn网络，显式捕捉多样交互模式，并有效建模方向敏感的社交行为；同时引入SSOS训练策略，缓解时间序列预测初始步误差问题。

Result: 在ETH和UCY数据集上，InSyn模型在高密度场景下显著优于近期基线；SSOS策略将初始步预测误差降低了约6.58%。

Conclusion: InSyn网络和SSOS策略有效提升了行人轨迹预测的精准度，特别是在高密度场景中表现卓越。

Abstract: Accurate pedestrian trajectory prediction is crucial for intelligent
applications, yet it remains highly challenging due to the complexity of
interactions among pedestrians. Previous methods have primarily relied on
relative positions to model pedestrian interactions; however, they tend to
overlook specific interaction patterns such as paired walking or conflicting
behaviors, limiting the prediction accuracy in crowded scenarios. To address
this issue, we propose InSyn (Interaction-Synchronization Network), a novel
Transformer-based model that explicitly captures diverse interaction patterns
(e.g., walking in sync or conflicting) while effectively modeling
direction-sensitive social behaviors. Additionally, we introduce a training
strategy termed Seq-Start of Seq (SSOS), designed to alleviate the common issue
of initial-step divergence in numerical time-series prediction. Experiments on
the ETH and UCY datasets demonstrate that our model outperforms recent
baselines significantly, especially in high-density scenarios. Furthermore, the
SSOS strategy proves effective in improving sequential prediction performance,
reducing the initial-step prediction error by approximately 6.58%.

</details>


### [16] [MADI: Masking-Augmented Diffusion with Inference-Time Scaling for Visual Editing](https://arxiv.org/abs/2507.13401)
*Shreya Kadambi,Risheek Garrepalli,Shubhankar Borse,Munawar Hyatt,Fatih Porikli*

Main category: cs.CV

TL;DR: 提出了MADI框架，通过增强扩散模型的编辑性和组合性，优化了其在结构化、可控生成和编辑方面的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在文本到图像生成中的成功促使研究其在视觉编辑和组件控制中的应用，但现有方法存在编辑性和可控性不足的问题。

Method: 提出MADI框架，包括两大创新：1. 引入Masking-Augmented Gaussian Diffusion (MAgD)训练策略，通过双重扰动过程训练扩散模型；2. 在推理阶段基于Pause Tokens引入推理容量扩展机制。

Result: 通过采用更表达性和密集的提示，显著改善了MADI的性能，特别是在编辑性方面。

Conclusion: MADI框架增强了扩散模型的编辑能力，为其集成到通用生成式扩散架构中提供了可能性。

Abstract: Despite the remarkable success of diffusion models in text-to-image
generation, their effectiveness in grounded visual editing and compositional
control remains challenging. Motivated by advances in self-supervised learning
and in-context generative modeling, we propose a series of simple yet powerful
design choices that significantly enhance diffusion model capacity for
structured, controllable generation and editing. We introduce Masking-Augmented
Diffusion with Inference-Time Scaling (MADI), a framework that improves the
editability, compositionality and controllability of diffusion models through
two core innovations. First, we introduce Masking-Augmented gaussian Diffusion
(MAgD), a novel training strategy with dual corruption process which combines
standard denoising score matching and masked reconstruction by masking noisy
input from forward process. MAgD encourages the model to learn discriminative
and compositional visual representations, thus enabling localized and
structure-aware editing. Second, we introduce an inference-time capacity
scaling mechanism based on Pause Tokens, which act as special placeholders
inserted into the prompt for increasing computational capacity at inference
time. Our findings show that adopting expressive and dense prompts during
training further enhances performance, particularly for MAgD. Together, these
contributions in MADI substantially enhance the editability of diffusion
models, paving the way toward their integration into more general-purpose,
in-context generative diffusion architectures.

</details>


### [17] [UL-DD: A Multimodal Drowsiness Dataset Using Video, Biometric Signals, and Behavioral Data](https://arxiv.org/abs/2507.13403)
*Morteza Bodaghi,Majid Hosseini,Raju Gottumukkala,Ravi Teja Bhupatiraju,Iftikhar Ahmad,Moncef Gabbouj*

Main category: cs.CV

TL;DR: 本文提供了一个全面的公共数据集，用于驾驶员疲劳检测，整合了面部、行为和生物指标的多模态信号，涵盖了多种生理、行为和驾驶相关信号。


<details>
  <summary>Details</summary>
Motivation: 推动驾驶员疲劳检测研究，提出一个涵盖广泛多模态数据的公开数据集，弥补现有数据集的不足。

Method: 通过模拟仿真驾驶环境，使用多设备收集19名受试者在不同疲劳状态下的各种信号数据，如3D面部视频、生物指标和驾驶行为等，多模态数据持续采集40分钟。

Result: 获得了总时长1400分钟的多模态驾驶数据集，包括受试者在清醒和疲劳状态下的详细生理、行为和驾驶信号变化。

Conclusion: 该研究提出了一个高质量、多模态的疲劳驾驶数据集，为围绕驾驶员疲劳检测的后续研究提供了丰富的数据支持。

Abstract: In this study, we present a comprehensive public dataset for driver
drowsiness detection, integrating multimodal signals of facial, behavioral, and
biometric indicators. Our dataset includes 3D facial video using a depth
camera, IR camera footage, posterior videos, and biometric signals such as
heart rate, electrodermal activity, blood oxygen saturation, skin temperature,
and accelerometer data. This data set provides grip sensor data from the
steering wheel and telemetry data from the American truck simulator game to
provide more information about drivers' behavior while they are alert and
drowsy. Drowsiness levels were self-reported every four minutes using the
Karolinska Sleepiness Scale (KSS). The simulation environment consists of three
monitor setups, and the driving condition is completely like a car. Data were
collected from 19 subjects (15 M, 4 F) in two conditions: when they were fully
alert and when they exhibited signs of sleepiness. Unlike other datasets, our
multimodal dataset has a continuous duration of 40 minutes for each data
collection session per subject, contributing to a total length of 1,400
minutes, and we recorded gradual changes in the driver state rather than
discrete alert/drowsy labels. This study aims to create a comprehensive
multimodal dataset of driver drowsiness that captures a wider range of
physiological, behavioral, and driving-related signals. The dataset will be
available upon request to the corresponding author.

</details>


### [18] [AortaDiff: Volume-Guided Conditional Diffusion Models for Multi-Branch Aortic Surface Generation](https://arxiv.org/abs/2507.13404)
*Delin An,Pan Du,Jian-Xun Wang,Chaoli Wang*

Main category: cs.CV

TL;DR: 提出AortaDiff，一种基于扩散模型的3D主动脉构建框架，能够直接从CT/MRI生成CFD兼容的主动脉网格，具有高几何保真度并减少依赖大规模标注数据。


<details>
  <summary>Details</summary>
Motivation: 现有3D主动脉构建方法依赖大量标注数据和手动操作，无法生成适合CFD分析的网格，难以满足临床诊断和血流动力学模拟的需求。

Method: 提出AortaDiff框架，利用体积引导的条件扩散模型生成主动脉中心线，并从中提取血管轮廓，再拟合为连续光滑的3D表面，生成CFD兼容的主动脉网格。

Result: AortaDiff在仅需少量训练数据下，能够有效构建正常及病变（如动脉瘤或狭窄）主动脉网格，实验结果表明其性能优异。

Conclusion: AortaDiff提供了端到端的主动脉构建流程，减少对大规模标注数据的依赖，生成高几何保真度的CFD兼容主动脉网格，为心血管研究提供了一种实用解决方案。

Abstract: Accurate 3D aortic construction is crucial for clinical diagnosis,
preoperative planning, and computational fluid dynamics (CFD) simulations, as
it enables the estimation of critical hemodynamic parameters such as blood flow
velocity, pressure distribution, and wall shear stress. Existing construction
methods often rely on large annotated training datasets and extensive manual
intervention. While the resulting meshes can serve for visualization purposes,
they struggle to produce geometrically consistent, well-constructed surfaces
suitable for downstream CFD analysis. To address these challenges, we introduce
AortaDiff, a diffusion-based framework that generates smooth aortic surfaces
directly from CT/MRI volumes. AortaDiff first employs a volume-guided
conditional diffusion model (CDM) to iteratively generate aortic centerlines
conditioned on volumetric medical images. Each centerline point is then
automatically used as a prompt to extract the corresponding vessel contour,
ensuring accurate boundary delineation. Finally, the extracted contours are
fitted into a smooth 3D surface, yielding a continuous, CFD-compatible mesh
representation. AortaDiff offers distinct advantages over existing methods,
including an end-to-end workflow, minimal dependency on large labeled datasets,
and the ability to generate CFD-compatible aorta meshes with high geometric
fidelity. Experimental results demonstrate that AortaDiff performs effectively
even with limited training data, successfully constructing both normal and
pathologically altered aorta meshes, including cases with aneurysms or
coarctation. This capability enables the generation of high-quality
visualizations and positions AortaDiff as a practical solution for
cardiovascular research.

</details>


### [19] [COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark](https://arxiv.org/abs/2507.13405)
*Ishant Chintapatla,Kazuma Choji,Naaisha Agarwal,Andrew Lin,Hannah You,Charles Duong,Kevin Zhu,Sean O'Brien,Vasu Sharma*

Main category: cs.CV

TL;DR: 提出了一个名为COREVQA的基准，用于测试视觉语言模型（VLMs）的视觉蕴含推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基准虽能评估模型在视觉问答中的表现，却鲜少测试模型处理视觉蕴含任务的能力。

Method: 开发了包含5608张图片及成对真/假陈述的COREVQA数据集，利用CrowdHuman数据集中的图像，构建适用于拥挤场景的视觉蕴含推理基准。

Result: 即使是表现最好的VLM模型在COREVQA上的准确率也未超过80%，许多模型的表现仅在39.98%-69.95%之间。

Conclusion: 当前的VLMs在处理拥挤场景中的视觉蕴含推理任务时存在显著的能力局限。

Abstract: Recently, many benchmarks and datasets have been developed to evaluate
Vision-Language Models (VLMs) using visual question answering (VQA) pairs, and
models have shown significant accuracy improvements. However, these benchmarks
rarely test the model's ability to accurately complete visual entailment, for
instance, accepting or refuting a hypothesis based on the image. To address
this, we propose COREVQA (Crowd Observations and Reasoning Entailment), a
benchmark of 5608 image and synthetically generated true/false statement pairs,
with images derived from the CrowdHuman dataset, to provoke visual entailment
reasoning on challenging crowded images. Our results show that even the
top-performing VLMs achieve accuracy below 80%, with other models performing
substantially worse (39.98%-69.95%). This significant performance gap reveals
key limitations in VLMs' ability to reason over certain types of image-question
pairs in crowded scenes.

</details>


### [20] [IConMark: Robust Interpretable Concept-Based Watermark For AI Images](https://arxiv.org/abs/2507.13407)
*Vinu Sankar Sadasivan,Mehrdad Saberi,Soheil Feizi*

Main category: cs.CV

TL;DR: 本文探讨了一种将可解释概念嵌入AI生成图像的水印方法——IConMark，以解决生成式AI图像识别问题，具有鲁棒性和可读性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI带来的图像生成真伪判断问题日益严重，传统水印技术容易受到对抗攻击，亟需更鲁棒和可解释的解决方案。

Method: 提出IConMark方法，将语义化水印嵌入到AI生成图像中，结合现有技术（如StegaStamp和TrustMark）形成混合模型以提升水印鲁棒性。

Result: IConMark及其变体在图像水印检测的平均ROC曲线下面积上分别提高了10.8%、14.5%和15.9%。

Conclusion: IConMark通过嵌入语义化的水印，在增强鲁棒性的同时实现了可解释性，并且可进一步结合其他水印技术提升其整体性能。

Abstract: With the rapid rise of generative AI and synthetic media, distinguishing
AI-generated images from real ones has become crucial in safeguarding against
misinformation and ensuring digital authenticity. Traditional watermarking
techniques have shown vulnerabilities to adversarial attacks, undermining their
effectiveness in the presence of attackers. We propose IConMark, a novel
in-generation robust semantic watermarking method that embeds interpretable
concepts into AI-generated images, as a first step toward interpretable
watermarking. Unlike traditional methods, which rely on adding noise or
perturbations to AI-generated images, IConMark incorporates meaningful semantic
attributes, making it interpretable to humans and hence, resilient to
adversarial manipulation. This method is not only robust against various image
augmentations but also human-readable, enabling manual verification of
watermarks. We demonstrate a detailed evaluation of IConMark's effectiveness,
demonstrating its superiority in terms of detection accuracy and maintaining
image quality. Moreover, IConMark can be combined with existing watermarking
techniques to further enhance and complement its robustness. We introduce
IConMark+SS and IConMark+TM, hybrid approaches combining IConMark with
StegaStamp and TrustMark, respectively, to further bolster robustness against
multiple types of image manipulations. Our base watermarking technique
(IConMark) and its variants (+TM and +SS) achieve 10.8%, 14.5%, and 15.9%
higher mean area under the receiver operating characteristic curve (AUROC)
scores for watermark detection, respectively, compared to the best baseline on
various datasets.

</details>


### [21] [A Deep Learning-Based Ensemble System for Automated Shoulder Fracture Detection in Clinical Radiographs](https://arxiv.org/abs/2507.13408)
*Hemanth Kumar M,Karthika M,Saianiruth M,Vasanthakumar Venugopal,Anandakumar D,Revathi Ezhumalai,Charulatha K,Kishore Kumar J,Dayana G,Kalyan Sivasailam,Bargava Subramanian*

Main category: cs.CV

TL;DR: 本研究开发了一个基于AI的肩部X光诊断系统，利用多模型深度学习和集成技术，实现了高达95.5%的准确率，对骨折的早期检测和诊断延迟有很大帮助。


<details>
  <summary>Details</summary>
Motivation: 肩部骨折在临床中常被漏诊，特别是急诊和高负荷的医疗环境中。因此需要一种可扩展的AI工具辅助早期检测，减少诊断延迟。

Method: 研究使用了10,000张带注释的肩部X光片，结合多模型深度学习（包括Faster R-CNN, EfficientDet和RF-DETR）和集成技术（Soft-NMS, WBF, NMW融合）开发算法。

Result: NMW集成模式取得了95.5%的准确率和F1分数0.9610，超越了各个单一模型，同时表现出较强的召回率和定位精准度。

Conclusion: 融合集成的AI系统可有效可靠地检测肩部骨折，对实际临床应用具有重要意义，但目前系统仅限于二分类检测，主要设计用于快速筛查和辅助分诊。

Abstract: Background: Shoulder fractures are often underdiagnosed, especially in
emergency and high-volume clinical settings. Studies report up to 10% of such
fractures may be missed by radiologists. AI-driven tools offer a scalable way
to assist early detection and reduce diagnostic delays. We address this gap
through a dedicated AI system for shoulder radiographs. Methods: We developed a
multi-model deep learning system using 10,000 annotated shoulder X-rays.
Architectures include Faster R-CNN (ResNet50-FPN, ResNeXt), EfficientDet, and
RF-DETR. To enhance detection, we applied bounding box and classification-level
ensemble techniques such as Soft-NMS, WBF, and NMW fusion. Results: The NMW
ensemble achieved 95.5% accuracy and an F1-score of 0.9610, outperforming
individual models across all key metrics. It demonstrated strong recall and
localization precision, confirming its effectiveness for clinical fracture
detection in shoulder X-rays. Conclusion: The results show ensemble-based AI
can reliably detect shoulder fractures in radiographs with high clinical
relevance. The model's accuracy and deployment readiness position it well for
integration into real-time diagnostic workflows. The current model is limited
to binary fracture detection, reflecting its design for rapid screening and
triage support rather than detailed orthopedic classification.

</details>


### [22] [AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery](https://arxiv.org/abs/2507.13420)
*Alessandro Pistola,Valentina Orru',Nicolo' Marchetti,Marco Roccetti*

Main category: cs.CV

TL;DR: 使用CORONA灰度卫星图像改进深度学习模型，有效提高考古遗址自动识别能力，发现了4个新的遗址。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过结合历史卫星图像与AI技术发现已消失或被破坏的考古遗址。

Method: 采用初始的Bing卷积网络模型，并用CORONA卫星图像重新训练，针对阿布格莱布区域进行分析。

Result: 图像分割的IoU值超过85%，考古遗址检测精度达90%；发现4个新遗址，经过实地验证确认。

Conclusion: 结合AI技术与历史卫星图像能够识别当前已不再可见的考古遗址，为研究因人类活动导致遗址消失的景观提供了新方法。

Abstract: By upgrading an existing deep learning model with the knowledge provided by
one of the oldest sets of grayscale satellite imagery, known as CORONA, we
improved the AI model attitude towards the automatic identification of
archaeological sites in an environment which has been completely transformed in
the last five decades, including the complete destruction of many of those same
sites. The initial Bing based convolutional network model was retrained using
CORONA satellite imagery for the district of Abu Ghraib, west of Baghdad,
central Mesopotamian floodplain. The results were twofold and surprising.
First, the detection precision obtained on the area of interest increased
sensibly: in particular, the Intersection over Union (IoU) values, at the image
segmentation level, surpassed 85 percent, while the general accuracy in
detecting archeological sites reached 90 percent. Second, our retrained model
allowed the identification of four new sites of archaeological interest
(confirmed through field verification), previously not identified by
archaeologists with traditional techniques. This has confirmed the efficacy of
using AI techniques and the CORONA imagery from the 1960 to discover
archaeological sites currently no longer visible, a concrete breakthrough with
significant consequences for the study of landscapes with vanishing
archaeological evidence induced by anthropization

</details>


### [23] [CaSTFormer: Causal Spatio-Temporal Transformer for Driving Intention Prediction](https://arxiv.org/abs/2507.13425)
*Sirui Wang,Zhou Guan,Bingxi Zhao,Tongjia Gu*

Main category: cs.CV

TL;DR: 提出了CaSTFormer模型，专注于解决现有方法在驾驶意图预测中对时空互动与人类驾驶行为不确定性的建模不足问题，展示了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 当前驾驶意图预测方法难以准确建模复杂的时空交互及人类行为的不确定性，亟需更有效的模型提升安全性及交互效率。

Method: 提出了CaSTFormer模型，包含三个核心组件：RSF机制用于精准时间对齐，CPE模块消除伪相关以揭示真实因果关系，FSN网络合成纯化后的时空表征。

Result: 在Brain4Cars公开数据集上获得了最新的性能表现，验证了其在捕捉复杂因果时空依赖及提升预测精度和透明性方面的效果。

Conclusion: CaSTFormer通过因果时空建模显著提升了驾驶意图预测的准确性与透明性，可为实现高级自动驾驶提供支持。

Abstract: Accurate prediction of driving intention is key to enhancing the safety and
interactive efficiency of human-machine co-driving systems. It serves as a
cornerstone for achieving high-level autonomous driving. However, current
approaches remain inadequate for accurately modeling the complex
spatio-temporal interdependencies and the unpredictable variability of human
driving behavior. To address these challenges, we propose CaSTFormer, a Causal
Spatio-Temporal Transformer to explicitly model causal interactions between
driver behavior and environmental context for robust intention prediction.
Specifically, CaSTFormer introduces a novel Reciprocal Shift Fusion (RSF)
mechanism for precise temporal alignment of internal and external feature
streams, a Causal Pattern Extraction (CPE) module that systematically
eliminates spurious correlations to reveal authentic causal dependencies, and
an innovative Feature Synthesis Network (FSN) that adaptively synthesizes these
purified representations into coherent spatio-temporal inferences. We evaluate
the proposed CaSTFormer on the public Brain4Cars dataset, and it achieves
state-of-the-art performance. It effectively captures complex causal
spatio-temporal dependencies and enhances both the accuracy and transparency of
driving intention prediction.

</details>


### [24] ["PhyWorldBench": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models](https://arxiv.org/abs/2507.13428)
*Jing Gu,Xian Liu,Yu Zeng,Ashwin Nagarajan,Fangrui Zhu,Daniel Hong,Yue Fan,Qianqi Yan,Kaiwen Zhou,Ming-Yu Liu,Xin Eric Wang*

Main category: cs.CV

TL;DR: 本研究提出了PhyWorldBench，一种用于评估视频生成模型是否遵循物理法则的综合基准测试。


<details>
  <summary>Details</summary>
Motivation: 鉴于视频生成模型在高质量内容生成方面的进展，同时其在模拟物理现象的能力上仍存在显著的缺陷，因此提出了这一基准以改进此类模型的性能评估。

Method: 设计了一个覆盖从基本物理原理到复杂物理场景的全面基准测试，并引入了可评估模型在反物理学场景中表现的新类别。结合人类评估和改进的MLLM方法进行评测。

Result: 通过分析12种先进的文本到视频生成模型在1050条提示下的表现，识别出模型在遵循物理法则方面的主要挑战。同时，分析了如何通过优化提示提高物理一致性。

Conclusion: 研究揭示了视频生成模型在物理现实性方面的弱点，并为提升生成内容与物理原则一致性提供了具有针对性的建议。

Abstract: Video generation models have achieved remarkable progress in creating
high-quality, photorealistic content. However, their ability to accurately
simulate physical phenomena remains a critical and unresolved challenge. This
paper presents PhyWorldBench, a comprehensive benchmark designed to evaluate
video generation models based on their adherence to the laws of physics. The
benchmark covers multiple levels of physical phenomena, ranging from
fundamental principles like object motion and energy conservation to more
complex scenarios involving rigid body interactions and human or animal motion.
Additionally, we introduce a novel ""Anti-Physics"" category, where prompts
intentionally violate real-world physics, enabling the assessment of whether
models can follow such instructions while maintaining logical consistency.
Besides large-scale human evaluation, we also design a simple yet effective
method that could utilize current MLLM to evaluate the physics realism in a
zero-shot fashion. We evaluate 12 state-of-the-art text-to-video generation
models, including five open-source and five proprietary models, with a detailed
comparison and analysis. we identify pivotal challenges models face in adhering
to real-world physics. Through systematic testing of their outputs across 1,050
curated prompts-spanning fundamental, composite, and anti-physics scenarios-we
identify pivotal challenges these models face in adhering to real-world
physics. We then rigorously examine their performance on diverse physical
phenomena with varying prompt types, deriving targeted recommendations for
crafting prompts that enhance fidelity to physical principles.

</details>


### [25] [Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation](https://arxiv.org/abs/2507.13486)
*Debao Huang,Rongjun Qin*

Main category: cs.CV

TL;DR: 本文提出了一个不确定性量化框架，用于弥补在摄影测量中的多视图立体（MVS）阶段的不确定性估计问题。


<details>
  <summary>Details</summary>
Motivation: 解决了由于非可微性和多模态特性而导致的MVS阶段不确定性估计难题，弥补了传统框架的不足。

Method: 提出了一种自校准方法，通过结合可靠点提取回归视差的不确定性，利用MVS阶段的相关信息进行误差协方差矩阵的分析。方法具有自监督特点，能够自然适应摄影测量过程中的误差传播路径。

Result: 在公开的航空和无人机影像数据集上评估了框架，结果表明该方法在不高估不确定性的情况下，达到了较高水平的边界率，优于现有方法。

Conclusion: 该方法提供了一种稳健且可验证的不确定性量化手段，适用于多场景，弥补了摄影测量流程中MVS阶段的不确定性估计空白。

Abstract: Uncertainty quantification of the photogrammetry process is essential for
providing per-point accuracy credentials of the point clouds. Unlike airborne
LiDAR, which typically delivers consistent accuracy across various scenes, the
accuracy of photogrammetric point clouds is highly scene-dependent, since it
relies on algorithm-generated measurements (i.e., stereo or multi-view stereo).
Generally, errors of the photogrammetric point clouds propagate through a
two-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA),
followed by Multi-view Stereo (MVS). While uncertainty estimation in the SfM
stage has been well studied using the first-order statistics of the
reprojection error function, that in the MVS stage remains largely unsolved and
non-standardized, primarily due to its non-differentiable and multi-modal
nature (i.e., from pixel values to geometry). In this paper, we present an
uncertainty quantification framework closing this gap by associating an error
covariance matrix per point accounting for this two-step photogrammetry
process. Specifically, to estimate the uncertainty in the MVS stage, we propose
a novel, self-calibrating method by taking reliable n-view points (n>=6)
per-view to regress the disparity uncertainty using highly relevant cues (such
as matching cost values) from the MVS stage. Compared to existing approaches,
our method uses self-contained, reliable 3D points extracted directly from the
MVS process, with the benefit of being self-supervised and naturally adhering
to error propagation path of the photogrammetry process, thereby providing a
robust and certifiable uncertainty quantification across diverse scenes. We
evaluate the framework using a variety of publicly available airborne and UAV
imagery datasets. Results demonstrate that our method outperforms existing
approaches by achieving high bounding rates without overestimating uncertainty.

</details>


### [26] [Sugar-Beet Stress Detection using Satellite Image Time Series](https://arxiv.org/abs/2507.13514)
*Bhumika Laxman Sadbhave,Philipp Vaeth,Denise Dejon,Gunther Schorcht,Magda Gregorová*

Main category: cs.CV

TL;DR: 本文提出了一种完全无监督的方法，利用3D卷积自编码模型和时间编码，从卫星图像时间序列中提取特征，用于检测甜菜田中的压力。


<details>
  <summary>Details</summary>
Motivation: 利用卫星图像时间序列（SITS）的光谱和时间特性，解决甜菜田中压力检测的问题，使检测系统更具实用性。

Method: 提出一种3D卷积自编码器模型，并结合根据不同获取日期设计的时间编码，提取甜菜生长的动态特征，再进行聚类以区分健康与受压区域。

Result: 通过无监督学习方法构建的压力检测系统能够适用于不同年份的数据，展现了较强的泛化能力。

Conclusion: 该研究为甜菜压力检测提供了一种高效、实用的工具，且无需监督学习，具有潜在的广泛应用前景。

Abstract: Satellite Image Time Series (SITS) data has proven effective for agricultural
tasks due to its rich spectral and temporal nature. In this study, we tackle
the task of stress detection in sugar-beet fields using a fully unsupervised
approach. We propose a 3D convolutional autoencoder model to extract meaningful
features from Sentinel-2 image sequences, combined with
acquisition-date-specific temporal encodings to better capture the growth
dynamics of sugar-beets. The learned representations are used in a downstream
clustering task to separate stressed from healthy fields. The resulting stress
detection system can be directly applied to data from different years, offering
a practical and accessible tool for stress detection in sugar-beets.

</details>


### [27] [SparseC-AFM: a deep learning method for fast and accurate characterization of MoS$_2$ with C-AFM](https://arxiv.org/abs/2507.13527)
*Levi Harris,Md Jayed Hossain,Mufan Qiu,Ruichen Zhang,Pingchuan Ma,Tianlong Chen,Jiaqi Gu,Seth Ariel Tongay,Umberto Celano*

Main category: cs.CV

TL;DR: 本文提出SparseC-AFM深度学习模型，结合稀疏扫描与AI重构技术，有效加速2D材料电导率图像的获取与分析。


<details>
  <summary>Details</summary>
Motivation: 解决当前C-AFM在二维材料大规模电表征中的低效率问题，尤其是传统栅格扫描耗时过长。

Method: 引入SparseC-AFM模型，通过稀疏扫描并结合深度学习快速重构二维材料（如MoS$_2$）的电导率图。

Result: 与经典高密度C-AFM扫描相比，在采集时间上减少了约11倍，同时能准确提取MoS$_2$的关键材料参数。

Conclusion: 该研究展示了AI助力二维材料表征的潜力，为从实验室研究向工业化的转化奠定了基础。

Abstract: The increasing use of two-dimensional (2D) materials in nanoelectronics
demands robust metrology techniques for electrical characterization, especially
for large-scale production. While atomic force microscopy (AFM) techniques like
conductive AFM (C-AFM) offer high accuracy, they suffer from slow data
acquisition speeds due to the raster scanning process. To address this, we
introduce SparseC-AFM, a deep learning model that rapidly and accurately
reconstructs conductivity maps of 2D materials like MoS$_2$ from sparse C-AFM
scans. Our approach is robust across various scanning modes, substrates, and
experimental conditions. We report a comparison between (a) classic flow
implementation, where a high pixel density C-AFM image (e.g., 15 minutes to
collect) is manually parsed to extract relevant material parameters, and (b)
our SparseC-AFM method, which achieves the same operation using data that
requires substantially less acquisition time (e.g., under 5 minutes).
SparseC-AFM enables efficient extraction of critical material parameters in
MoS$_2$, including film coverage, defect density, and identification of
crystalline island boundaries, edges, and cracks. We achieve over 11x reduction
in acquisition time compared to manual extraction from a full-resolution C-AFM
image. Moreover, we demonstrate that our model-predicted samples exhibit
remarkably similar electrical properties to full-resolution data gathered using
classic-flow scanning. This work represents a significant step toward
translating AI-assisted 2D material characterization from laboratory research
to industrial fabrication. Code and model weights are available at
github.com/UNITES-Lab/sparse-cafm.

</details>


### [28] [Total Generalized Variation of the Normal Vector Field and Applications to Mesh Denoising](https://arxiv.org/abs/2507.13530)
*Lukas Baumgärtner,Ronny Bergmann,Roland Herzog,Stephan Schmidt,Manuel Weiß*

Main category: cs.CV

TL;DR: 提出了一种用于嵌入三维空间的定向三角网格法线向量的二阶全变分(TGV)新型公式，并利用切向Raviart-Thomas型有限元空间实现对TGV离散模型的扩展。


<details>
  <summary>Details</summary>
Motivation: 现有离散TGV模型主要针对分段恒定标量数据，难以直接处理多样复杂的数据需求。

Method: 构建了一种切向Raviart-Thomas型有限元空间，从而将传统TGV公式扩展到法线向量的流形值函数情况。

Result: 通过网格去噪实验，将新正则化方法与已存在的方法进行了比较。

Conclusion: 文章的正则化方法在嵌入三维空间的法线向量处理问题上展现了创新性，提供了扩展离散TGV模型应用范围的新路径。

Abstract: We propose a novel formulation for the second-order total generalized
variation (TGV) of the normal vector on an oriented, triangular mesh embedded
in $\mathbb{R}^3$. The normal vector is considered as a manifold-valued
function, taking values on the unit sphere. Our formulation extends previous
discrete TGV models for piecewise constant scalar data that utilize a
Raviart-Thomas function space. To exctend this formulation to the manifold
setting, a tailor-made tangential Raviart-Thomas type finite element space is
constructed in this work. The new regularizer is compared to existing methods
in mesh denoising experiments.

</details>


### [29] [$\nabla$NABLA: Neighborhood Adaptive Block-Level Attention](https://arxiv.org/abs/2507.13546)
*Dmitrii Mikhailov,Aleksey Letunovskiy,Maria Kovaleva,Vladimir Arkhipkin,Vladimir Korviakov,Vladimir Polovnikov,Viacheslav Vasilev,Evelina Sidorova,Denis Dimitrov*

Main category: cs.CV

TL;DR: 提出了一种名为NABLA的邻域自适应块级注意力机制，用于视频生成任务，显著提升了效率。


<details>
  <summary>Details</summary>
Motivation: 解决全注意力机制的二次复杂性瓶颈，尤其在高分辨率和长时间视频生成任务中。

Method: 通过块级注意力和自适应稀疏阈值，动态调整稀疏模式，减少计算开销，无需依赖自定义的底层操作。

Result: NABLA相比基线在训练和推理上快了约2.7倍，同时量化指标与生成质量几乎未受影响。

Conclusion: NABLA在提高效率的同时，保持了生成质量，为视频生成任务提供了高效解决方案。

Abstract: Recent progress in transformer-based architectures has demonstrated
remarkable success in video generation tasks. However, the quadratic complexity
of full attention mechanisms remains a critical bottleneck, particularly for
high-resolution and long-duration video sequences. In this paper, we propose
NABLA, a novel Neighborhood Adaptive Block-Level Attention mechanism that
dynamically adapts to sparsity patterns in video diffusion transformers (DiTs).
By leveraging block-wise attention with adaptive sparsity-driven threshold,
NABLA reduces computational overhead while preserving generative quality. Our
method does not require custom low-level operator design and can be seamlessly
integrated with PyTorch's Flex Attention operator. Experiments demonstrate that
NABLA achieves up to 2.7x faster training and inference compared to baseline
almost without compromising quantitative metrics (CLIP score, VBench score,
human evaluation score) and visual quality drop. The code and model weights are
available here: https://github.com/gen-ai-team/Wan2.1-NABLA

</details>


### [30] [LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning](https://arxiv.org/abs/2507.13568)
*Kaihong Wang,Donghyun Kim,Margrit Betke*

Main category: cs.CV

TL;DR: 提出了一种结合任务特定低秩适配器（LoRA）和信心筛选的增强型人工合成回放框架，改进了视觉语言模型（VLMs）在不同任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的人工合成回放方法在处理具有领域特异性和细粒度语义的实际应用任务时效果不佳，生成的样本可能存在不对齐现象，导致知识保留不充分。

Method: 引入基于LoRA的增强型人工合成回放框架，通过在冻结的Stable Diffusion模型中注入任务特定的低秩适配器，调整生成的样本以更好匹配新任务。此外，采用两阶段基于信心的样本选择策略，优先提取最具代表性的任务样本进行适配，并进一步筛选生成的人工样本以进行知识蒸馏。

Result: 在多领域任务增量学习（MTIL）基准测试中，提出的方法优于现有的人工合成回放技术，并在可塑性、稳定性和零样本能力之间取得了最佳平衡。

Conclusion: 通过LoRA实现的生成器适配有效提高了视觉语言模型在持续学习中的鲁棒性，为任务特定适配开辟了新的方向。

Abstract: Continual learning for vision-language models has achieved remarkable
performance through synthetic replay, where samples are generated using Stable
Diffusion to regularize during finetuning and retain knowledge. However,
real-world downstream applications often exhibit domain-specific nuances and
fine-grained semantics not captured by generators, causing synthetic-replay
methods to produce misaligned samples that misguide finetuning and undermine
retention of prior knowledge. In this work, we propose a LoRA-enhanced
synthetic-replay framework that injects task-specific low-rank adapters into a
frozen Stable Diffusion model, efficiently capturing each new task's unique
visual and semantic patterns. Specifically, we introduce a two-stage,
confidence-based sample selection: we first rank real task data by
post-finetuning VLM confidence to focus LoRA finetuning on the most
representative examples, then generate synthetic samples and again select them
by confidence for distillation. Our approach integrates seamlessly with
existing replay pipelines-simply swap in the adapted generator to boost replay
fidelity. Extensive experiments on the Multi-domain Task Incremental Learning
(MTIL) benchmark show that our method outperforms previous synthetic-replay
techniques, achieving an optimal balance among plasticity, stability, and
zero-shot capability. These results demonstrate the effectiveness of generator
adaptation via LoRA for robust continual learning in VLMs.

</details>


### [31] [NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision](https://arxiv.org/abs/2507.13595)
*Tengkai Wang,Weihao Li,Ruikai Cui,Shi Qiu,Nick Barnes*

Main category: cs.CV

TL;DR: 提出了一种名为NoiseSDF2NoiseSDF的方法，用于从噪声点云中准确重建隐式表面。


<details>
  <summary>Details</summary>
Motivation: 当前从低质量扫描设备点云生成隐式表面存在难题，尤其是噪声数据导致表面重建不准确。

Method: 基于Noise2Noise的思路，将其扩展到三维神经场，利用噪声监督和最小均方误差损失（MSE），在神经SDF之间进行学习，隐式去噪并改进表面估算。

Result: 在ShapeNet、ABC、Famous、Real等基准数据集上的实验表明，该方法显著改善了从噪声数据生成表面的质量。

Conclusion: NoiseSDF2NoiseSDF方法可直接从噪声点云中学习干净的神经SDF，大幅提升表面重建质量，对低质量扫描设备点云数据处理具有重要意义。

Abstract: Reconstructing accurate implicit surface representations from point clouds
remains a challenging task, particularly when data is captured using
low-quality scanning devices. These point clouds often contain substantial
noise, leading to inaccurate surface reconstructions. Inspired by the
Noise2Noise paradigm for 2D images, we introduce NoiseSDF2NoiseSDF, a novel
method designed to extend this concept to 3D neural fields. Our approach
enables learning clean neural SDFs directly from noisy point clouds through
noisy supervision by minimizing the MSE loss between noisy SDF representations,
allowing the network to implicitly denoise and refine surface estimations. We
evaluate the effectiveness of NoiseSDF2NoiseSDF on benchmarks, including the
ShapeNet, ABC, Famous, and Real datasets. Experimental results demonstrate that
our framework significantly improves surface reconstruction quality from noisy
inputs.

</details>


### [32] [Learning Deblurring Texture Prior from Unpaired Data with Diffusion Model](https://arxiv.org/abs/2507.13599)
*Chengxu Liu,Lu Qi,Jinshan Pan,Xueming Qian,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型（DM）的无监督图像去模糊方法，通过从未配对数据中学习纹理先验知识，显著提升去模糊性能。


<details>
  <summary>Details</summary>
Motivation: 解决因真实模糊-清晰图像配对数据难以获取而限制去模糊研究的问题；克服现有方法忽略真实模糊模式的复杂性的问题。

Method: 1. 基于扩散模型生成图像纹理先验；2. 提出带有记忆机制的纹理先验编码器（TPE）用于训练扩散模型；3. 开发包含滤波调控的多头自注意力机制的纹理传递Transformer层（TTformer）去除空间可变模糊；4. 引入基于小波的对抗性损失保留高频纹理细节。

Result: 提出的方法能够达成具有竞争力的去模糊性能，超过多种现有主流方法，在常用基准测试集上表现优越。

Conclusion: 此研究为无监督图像去模糊提供了一种高效新路径，利用纹理先验实现对复杂模糊模式的更好处理。

Abstract: Since acquiring large amounts of realistic blurry-sharp image pairs is
difficult and expensive, learning blind image deblurring from unpaired data is
a more practical and promising solution. Unfortunately, dominant approaches
rely heavily on adversarial learning to bridge the gap from blurry domains to
sharp domains, ignoring the complex and unpredictable nature of real-world blur
patterns. In this paper, we propose a novel diffusion model (DM)-based
framework, dubbed \ours, for image deblurring by learning spatially varying
texture prior from unpaired data. In particular, \ours performs DM to generate
the prior knowledge that aids in recovering the textures of blurry images. To
implement this, we propose a Texture Prior Encoder (TPE) that introduces a
memory mechanism to represent the image textures and provides supervision for
DM training. To fully exploit the generated texture priors, we present the
Texture Transfer Transformer layer (TTformer), in which a novel
Filter-Modulated Multi-head Self-Attention (FM-MSA) efficiently removes
spatially varying blurring through adaptive filtering. Furthermore, we
implement a wavelet-based adversarial loss to preserve high-frequency texture
details. Extensive evaluations show that \ours provides a promising
unsupervised deblurring solution and outperforms SOTA methods in widely-used
benchmarks.

</details>


### [33] [Efficient Burst Super-Resolution with One-step Diffusion](https://arxiv.org/abs/2507.13607)
*Kento Kawai,Takeru Oba,Kyotaro Tokoro,Kazutoshi Akita,Norimichi Ukita*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的图像超分辨率(SR)方法，通过高阶ODE随机采样器和知识蒸馏技术提升效率，同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 以往的SR方法存在生成模糊图像的问题，本文旨在通过扩散模型生成清晰和高保真的SR图像。

Method: 采用基于高阶ODE的随机采样器和知识蒸馏技术，优化扩散模型的效能，同时实现单步扩散。

Result: 实验结果显示，相较基线方法，运行时间减少至其 1.6%，且能保持图像失真和感知质量指标的SR质量。

Conclusion: 所提出的方法显著提高了执行效率，并在保持图像质量的同时解决了以往模糊图像的缺陷。

Abstract: While burst Low-Resolution (LR) images are useful for improving their Super
Resolution (SR) image compared to a single LR image, prior burst SR methods are
trained in a deterministic manner, which produces a blurry SR image. Since such
blurry images are perceptually degraded, we aim to reconstruct sharp and
high-fidelity SR images by a diffusion model. Our method improves the
efficiency of the diffusion model with a stochastic sampler with a high-order
ODE as well as one-step diffusion using knowledge distillation. Our
experimental results demonstrate that our method can reduce the runtime to 1.6
% of its baseline while maintaining the SR quality measured based on image
distortion and perceptual quality.

</details>


### [34] [CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks](https://arxiv.org/abs/2507.13609)
*Yanan Wang,Julio Vizcarra,Zhi Li,Hao Niu,Mori Kurokawa*

Main category: cs.CV

TL;DR: 提出了一种新的框架CoTasks，通过链式推理任务来提升视频大语言模型（VideoLLMs）的推理能力，尤其是在复杂视频问题的分解与对象级别视频理解上。


<details>
  <summary>Details</summary>
Motivation: 现有的指令调优模型（如Qwen和LLaVA系列）主要集中于高层次的视频文本配对，但缺乏用于分步骤推理的结构化注释，难以支持细粒度的对象级视频理解。

Method: 提出CoTasks框架，将现有数据集中的复杂视频问题分解为四个对象级基础任务：帧定位、实体追踪、空间和时间关系提取。通过将这些任务的中间步骤嵌入输入，模型能够显式执行对象中心的时空推理。

Result: 在NeXT-QA基准测试中，应用CoTasks框架显著提升了推理性能：例如LLaVA-video-7B提高了平均GPT-4评分3.3分，Qwen2.5-VL-3B不同类别上的提升包括因果推理+14.6、时间推理+10.9和描述推理+48.1。

Conclusion: 实验结果证明，作为一种结构化的链式推理任务监督框架，CoTasks有效提升了视频大语言模型的推理能力，尤其是在组合推理领域。

Abstract: Despite recent progress in video large language models (VideoLLMs), a key
open challenge remains: how to equip models with chain-of-thought (CoT)
reasoning abilities grounded in fine-grained object-level video understanding.
Existing instruction-tuned models, such as the Qwen and LLaVA series, are
trained on high-level video-text pairs, often lacking structured annotations
necessary for compositional, step-by-step reasoning. We propose CoTasks:
Chain-of-Thought based Video Instruction Tuning Tasks, a new framework that
decomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)
into four entity-level foundational tasks: frame localization, entity tracking,
spatial and temporal relation extraction. By embedding these intermediate
CoT-style reasoning steps into the input, CoTasks enables models to explicitly
perform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA
benchmark show that CoTasks significantly enhance inference performance:
LLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and
Qwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal
(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the
effectiveness of CoTasks as a structured CoT-style supervision framework for
improving compositional video reasoning.

</details>


### [35] [Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation](https://arxiv.org/abs/2507.13628)
*Masahiro Ogawa,Qi An,Atsushi Yamashita*

Main category: cs.CV

TL;DR: 该研究提出了一种名为FoELS的方法，通过结合光流与纹理信息分离移动摄像头视角下的动态与静态物体，并在复杂场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖光流，但在检测涉及相机运动的复杂结构场景中的移动物体时存在不足，需要一种更有效的方法。

Method: 提出FoELS方法，通过计算光流的扩展焦点生成初始运动可能性，并将其与分割先验进行融合，估算最终的运动概率。

Result: FoELS在DAVIS 2016数据集和实际交通视频上的评估中展现了其效果卓著，并达到了最新性能。

Conclusion: FoELS方法有效地应对了复杂场景、相机旋转运动和平行运动的挑战，为动态与静态物体分离提供了先进解决方案。

Abstract: Separating moving and static objects from a moving camera viewpoint is
essential for 3D reconstruction, autonomous navigation, and scene understanding
in robotics. Existing approaches often rely primarily on optical flow, which
struggles to detect moving objects in complex, structured scenes involving
camera motion. To address this limitation, we propose Focus of Expansion
Likelihood and Segmentation (FoELS), a method based on the core idea of
integrating both optical flow and texture information. FoELS computes the focus
of expansion (FoE) from optical flow and derives an initial motion likelihood
from the outliers of the FoE computation. This likelihood is then fused with a
segmentation-based prior to estimate the final moving probability. The method
effectively handles challenges including complex structured scenes, rotational
camera motion, and parallel motion. Comprehensive evaluations on the DAVIS 2016
dataset and real-world traffic videos demonstrate its effectiveness and
state-of-the-art performance.

</details>


### [36] [EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation](https://arxiv.org/abs/2507.13648)
*Seungjun Moon,Sangjoon Yu,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: EPSilon提出了一种通过高效点采样策略生成三维人偶的方案，大幅减少采样点数量，并实现快速推理和训练。


<details>
  <summary>Details</summary>
Motivation: 现有基于NeRF和SMPL的混合模型在生成高质量人偶时推理速度慢，主要原因是其基于SMPL权重的变形方案对每个采样点的计算量大，而大多数采样点位于无效空间。

Method: EPSilon通过引入两种采样方法——空射线省略(ERO)和空区间省略(EIO)，减少对无效区域的采样，加速了推理和训练。

Result: EPSilon在保持生成质量的同时，仅使用3.9%的采样点，提高了约20倍的推理速度，并实现了4倍更快的训练收敛速度。

Conclusion: EPSilon通过高效点采样优化了NeRF与SMPL混合模型的推理和训练效率，同时保持了照片级真实的人偶生成质量。

Abstract: The rapid advancement of neural radiance fields (NeRF) has paved the way to
generate animatable human avatars from a monocular video. However, the sole
usage of NeRF suffers from a lack of details, which results in the emergence of
hybrid representation that utilizes SMPL-based mesh together with NeRF
representation. While hybrid-based models show photo-realistic human avatar
generation qualities, they suffer from extremely slow inference due to their
deformation scheme: to be aligned with the mesh, hybrid-based models use the
deformation based on SMPL skinning weights, which needs high computational
costs on each sampled point. We observe that since most of the sampled points
are located in empty space, they do not affect the generation quality but
result in inference latency with deformation. In light of this observation, we
propose EPSilon, a hybrid-based 3D avatar generation scheme with novel
efficient point sampling strategies that boost both training and inference. In
EPSilon, we propose two methods to omit empty points at rendering; empty ray
omission (ERO) and empty interval omission (EIO). In ERO, we wipe out rays that
progress through the empty space. Then, EIO narrows down the sampling interval
on the ray, which wipes out the region not occupied by either clothes or mesh.
The delicate sampling scheme of EPSilon enables not only great computational
cost reduction during deformation but also the designation of the important
regions to be sampled, which enables a single-stage NeRF structure without
hierarchical sampling. Compared to existing methods, EPSilon maintains the
generation quality while using only 3.9% of sampled points and achieves around
20 times faster inference, together with 4 times faster training convergence.
We provide video results on https://github.com/seungjun-moon/epsilon.

</details>


### [37] [When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework](https://arxiv.org/abs/2507.13659)
*Xiao Wang,Qian Zhu,Shujuan Wu,Bo Jiang,Shiliang Zhang,Yaowei Wang,Yonghong Tian,Bin Luo*

Main category: cs.CV

TL;DR: 本研究提出了一种基于事件相机的大规模RGB-事件行人再识别数据集EvReID，以及一种结合对比学习和行人属性的行人再识别框架TriPro-ReID，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于使用事件相机进行行人再识别具有性能优越和隐私保护更好的优势，发展相机事件数据对该领域的研究具有重要意义，但现有方法因缺乏大规模真实数据集限制了其性能评估和泛化能力。

Method: 引入了一个包含跨季节、场景和光照条件的大规模RGB-事件行人再识别数据集EvReID，并提出了一种利用对比学习和行人属性进行特征提取的框架TriPro-ReID，同时评估了15种现有行人再识别算法。

Result: 实验在EvReID和MARS数据集上进行，结果证明所提出的RGB-事件行人再识别框架的有效性。

Conclusion: 新数据集EvReID及TriPro-ReID框架为行人再识别领域的进一步研究提供了坚实的基础，并通过发布基准数据集和源码促进了社区的发展。

Abstract: Recent researchers have proposed using event cameras for person
re-identification (ReID) due to their promising performance and better balance
in terms of privacy protection, event camera-based person ReID has attracted
significant attention. Currently, mainstream event-based person ReID algorithms
primarily focus on fusing visible light and event stream, as well as preserving
privacy. Although significant progress has been made, these methods are
typically trained and evaluated on small-scale or simulated event camera
datasets, making it difficult to assess their real identification performance
and generalization ability. To address the issue of data scarcity, this paper
introduces a large-scale RGB-event based person ReID dataset, called EvReID.
The dataset contains 118,988 image pairs and covers 1200 pedestrian identities,
with data collected across multiple seasons, scenes, and lighting conditions.
We also evaluate 15 state-of-the-art person ReID algorithms, laying a solid
foundation for future research in terms of both data and benchmarking. Based on
our newly constructed dataset, this paper further proposes a pedestrian
attribute-guided contrastive learning framework to enhance feature learning for
person re-identification, termed TriPro-ReID. This framework not only
effectively explores the visual features from both RGB frames and event
streams, but also fully utilizes pedestrian attributes as mid-level semantic
features. Extensive experiments on the EvReID dataset and MARS datasets fully
validated the effectiveness of our proposed RGB-Event person ReID framework.
The benchmark dataset and source code will be released on
https://github.com/Event-AHU/Neuromorphic_ReID

</details>


### [38] [Global Modeling Matters: A Fast, Lightweight and Effective Baseline for Efficient Image Restoration](https://arxiv.org/abs/2507.13663)
*Xingyu Jiang,Ning Gao,Hongkun Dou,Xiuhui Zhang,Xiaoqing Zhong,Yue Deng,Hongjue Li*

Main category: cs.CV

TL;DR: 本文提出一种高效的图像修复基线模型，PW-FNet，利用小波和傅里叶变换，解决当前模型复杂度高和实时性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 降低基于transformer的图像修复方法中系统复杂性，提高实时处理性能。

Method: 提出了一种金字塔小波-傅里叶网络(PW-FNet)，结合小波分解和傅里叶变换，以降低计算复杂度并保留全局建模能力。

Result: PW-FNet在降雨、去雨滴、图像超分辨率、运动去模糊、去雾、去雪以及水下/低光增强等任务中超过了最新方法，且显著减少了参数、计算成本和推断时间。

Conclusion: PW-FNet通过创新的金字塔小波多输入多输出结构和傅里叶变换设计，不仅提升了修复质量，还在效率方面取得了重要进展，证明了小波-傅里叶处理的潜力。

Abstract: Natural image quality is often degraded by adverse weather conditions,
significantly impairing the performance of downstream tasks. Image restoration
has emerged as a core solution to this challenge and has been widely discussed
in the literature. Although recent transformer-based approaches have made
remarkable progress in image restoration, their increasing system complexity
poses significant challenges for real-time processing, particularly in
real-world deployment scenarios. To this end, most existing methods attempt to
simplify the self-attention mechanism, such as by channel self-attention or
state space model. However, these methods primarily focus on network
architecture while neglecting the inherent characteristics of image restoration
itself. In this context, we explore a pyramid Wavelet-Fourier iterative
pipeline to demonstrate the potential of Wavelet-Fourier processing for image
restoration. Inspired by the above findings, we propose a novel and efficient
restoration baseline, named Pyramid Wavelet-Fourier Network (PW-FNet).
Specifically, PW-FNet features two key design principles: 1) at the inter-block
level, integrates a pyramid wavelet-based multi-input multi-output structure to
achieve multi-scale and multi-frequency bands decomposition; and 2) at the
intra-block level, incorporates Fourier transforms as an efficient alternative
to self-attention mechanisms, effectively reducing computational complexity
while preserving global modeling capability. Extensive experiments on tasks
such as image deraining, raindrop removal, image super-resolution, motion
deblurring, image dehazing, image desnowing and underwater/low-light
enhancement demonstrate that PW-FNet not only surpasses state-of-the-art
methods in restoration quality but also achieves superior efficiency, with
significantly reduced parameter size, computational cost and inference time.

</details>


### [39] [MaskHOI: Robust 3D Hand-Object Interaction Estimation via Masked Pre-training](https://arxiv.org/abs/2507.13673)
*Yuechen Xie,Haobo Jiang,Jian Yang,Yigong Zhang,Jin Xie*

Main category: cs.CV

TL;DR: 提出了MaskHOI框架，通过掩码自编码器（MAE）预训练提升单目RGB图像的手-物体交互姿态估计表现。


<details>
  <summary>Details</summary>
Motivation: 解决RGB图像中固有的几何模糊性及严重互遮挡导致的手-物体交互姿态估计困难。

Method: 利用MAE的掩码重建策略，结合区域特定的掩码比率分配与骨架驱动的手部掩码引导，增强几何感知并实现遮挡鲁棒性。同时，引入基于掩码签名距离场（SDF）的多模态学习机制，以感知超越二维图像平面的三维几何结构。

Result: 实验结果表明，提出的方法在姿态估计任务中显著优于当前最先进方法。

Conclusion: MaskHOI框架有效提升了单目RGB输入下的手-物体交互三维姿态估计性能，为几何感知和遮挡鲁棒性提供了新思路。

Abstract: In 3D hand-object interaction (HOI) tasks, estimating precise joint poses of
hands and objects from monocular RGB input remains highly challenging due to
the inherent geometric ambiguity of RGB images and the severe mutual occlusions
that occur during interaction.To address these challenges, we propose MaskHOI,
a novel Masked Autoencoder (MAE)-driven pretraining framework for enhanced HOI
pose estimation. Our core idea is to leverage the masking-then-reconstruction
strategy of MAE to encourage the feature encoder to infer missing spatial and
structural information, thereby facilitating geometric-aware and
occlusion-robust representation learning. Specifically, based on our
observation that human hands exhibit far greater geometric complexity than
rigid objects, conventional uniform masking fails to effectively guide the
reconstruction of fine-grained hand structures. To overcome this limitation, we
introduce a Region-specific Mask Ratio Allocation, primarily comprising the
region-specific masking assignment and the skeleton-driven hand masking
guidance. The former adaptively assigns lower masking ratios to hand regions
than to rigid objects, balancing their feature learning difficulty, while the
latter prioritizes masking critical hand parts (e.g., fingertips or entire
fingers) to realistically simulate occlusion patterns in real-world
interactions. Furthermore, to enhance the geometric awareness of the pretrained
encoder, we introduce a novel Masked Signed Distance Field (SDF)-driven
multimodal learning mechanism. Through the self-masking 3D SDF prediction, the
learned encoder is able to perceive the global geometric structure of hands and
objects beyond the 2D image plane, overcoming the inherent limitations of
monocular input and alleviating self-occlusion issues. Extensive experiments
demonstrate that our method significantly outperforms existing state-of-the-art
approaches.

</details>


### [40] [HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors](https://arxiv.org/abs/2507.13677)
*Chuheng Wei,Ziye Qin,Walter Zimmer,Guoyuan Wu,Matthew J. Barth*

Main category: cs.CV

TL;DR: 该论文提出了一种名为HeCoFuse的框架，可促进在异构传感器配置下的车辆协同感知任务。


<details>
  <summary>Details</summary>
Motivation: 现实中，由于部署和成本限制，车辆和基础设施常采用不同的传感器配置，而这些异构性对特征融合与感知可靠性提出了较高要求。

Method: 提出了一个分层融合机制，结合通道与空间注意力权重新权重特征。另外，设计了一种自适应空间分辨率调整模块以及基于动态调整的协同学习策略。

Result: 在TUMTraf-V2X数据集上表现出色，LC+LC配置下的3D mAP达到43.22%，超过基线模型，同时在其它九种传感器配置下保持鲁棒性能。

Conclusion: HeCoFuse在TUM-Traf V2X数据集上实现了最佳性能，并展示了其在不同异构配置下的适应能力与卓越表现。

Abstract: Real-world Vehicle-to-Everything (V2X) cooperative perception systems often
operate under heterogeneous sensor configurations due to cost constraints and
deployment variability across vehicles and infrastructure. This heterogeneity
poses significant challenges for feature fusion and perception reliability. To
address these issues, we propose HeCoFuse, a unified framework designed for
cooperative perception across mixed sensor setups where nodes may carry Cameras
(C), LiDARs (L), or both. By introducing a hierarchical fusion mechanism that
adaptively weights features through a combination of channel-wise and spatial
attention, HeCoFuse can tackle critical challenges such as cross-modality
feature misalignment and imbalanced representation quality. In addition, an
adaptive spatial resolution adjustment module is employed to balance
computational cost and fusion effectiveness. To enhance robustness across
different configurations, we further implement a cooperative learning strategy
that dynamically adjusts fusion type based on available modalities. Experiments
on the real-world TUMTraf-V2X dataset demonstrate that HeCoFuse achieves 43.22%
3D mAP under the full sensor configuration (LC+LC), outperforming the CoopDet3D
baseline by 1.17%, and reaches an even higher 43.38% 3D mAP in the L+LC
scenario, while maintaining 3D mAP in the range of 21.74% to 43.38% across nine
heterogeneous sensor configurations. These results, validated by our
first-place finish in the CVPR 2025 DriveX challenge, establish HeCoFuse as the
current state-of-the-art on TUM-Traf V2X dataset while demonstrating robust
performance across diverse sensor deployments.

</details>


### [41] [Gaussian kernel-based motion measurement](https://arxiv.org/abs/2507.13693)
*Hongyi Liu,Haifeng Wang*

Main category: cs.CV

TL;DR: 提出了一种基于高斯核的运动测量方法，提高了无参数调整条件下的精度和稳健性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉运动测量方法在亚像素级测量时精度不足或需大量参数调整，难以满足结构健康监测需求。

Method: 开发了一种基于高斯核的运动测量方法，引入了运动一致性和超分辨率约束来提高精度与稳健性。

Result: 通过数值与实验验证，该方法在无需定制参数的情况下，始终保持高精度。

Conclusion: 该方法为大规模且高精度的结构健康监测提供了一种有效的视觉测量解决方案。

Abstract: The growing demand for structural health monitoring has driven increasing
interest in high-precision motion measurement, as structural information
derived from extracted motions can effectively reflect the current condition of
the structure. Among various motion measurement techniques, vision-based
methods stand out due to their low cost, easy installation, and large-scale
measurement. However, when it comes to sub-pixel-level motion measurement,
current vision-based methods either lack sufficient accuracy or require
extensive manual parameter tuning (e.g., pyramid layers, target pixels, and
filter parameters) to reach good precision. To address this issue, we developed
a novel Gaussian kernel-based motion measurement method, which can extract the
motion between different frames via tracking the location of Gaussian kernels.
The motion consistency, which fits practical structural conditions, and a
super-resolution constraint, are introduced to increase accuracy and robustness
of our method. Numerical and experimental validations show that it can
consistently reach high accuracy without customized parameter setup for
different test samples.

</details>


### [42] [GOSPA and T-GOSPA quasi-metrics for evaluation of multi-object tracking algorithms](https://arxiv.org/abs/2507.13706)
*Ángel F. García-Fernández,Jinhao Gu,Lennart Svensson,Yuxuan Xia,Jan Krejčí,Oliver Kost,Ondřej Straka*

Main category: cs.CV

TL;DR: 本研究提出两种用于多目标跟踪算法性能评估的准指标：扩展的GOSPA和扩展的T-GOSPA准指标。


<details>
  <summary>Details</summary>
Motivation: 目前的GOSPA和T-GOSPA指标在评估多目标跟踪算法性能时存在某些限制，无法灵活处理不同的惩罚成本或非对称定位成本。

Method: 研究将GOSPA和T-GOSPA指标扩展以形成准指标，使之具备更大的灵活性，可以区分惩罚漏检目标与虚假目标的不同成本，且定位成本可为非对称。使用扩展后的T-GOSPA准指标对多个贝叶斯多目标跟踪算法的性能进行仿真实验评估。

Result: 仿真结果表明，所提出的准指标能够灵活地应用于多目标跟踪不同需求场景的性能评估。

Conclusion: 本文的准指标方法扩展了现有评估工具，通过更灵活的成本设置增加了适用性，尤其在某些特定应用中优势显著。

Abstract: This paper introduces two quasi-metrics for performance assessment of
multi-object tracking (MOT) algorithms. In particular, one quasi-metric is an
extension of the generalised optimal subpattern assignment (GOSPA) metric and
measures the discrepancy between sets of objects. The other quasi-metric is an
extension of the trajectory GOSPA (T-GOSPA) metric and measures the discrepancy
between sets of trajectories. Similar to the GOSPA-based metrics, these
quasi-metrics include costs for localisation error for properly detected
objects, the number of false objects and the number of missed objects. The
T-GOSPA quasi-metric also includes a track switching cost. Differently from the
GOSPA and T-GOSPA metrics, the proposed quasi-metrics have the flexibility of
penalising missed and false objects with different costs, and the localisation
costs are not required to be symmetric. These properties can be useful in MOT
evaluation in certain applications. The performance of several Bayesian MOT
algorithms is assessed with the T-GOSPA quasi-metric via simulations.

</details>


### [43] [PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement](https://arxiv.org/abs/2507.13708)
*Sofia Jamil,Bollampalli Areen Reddy,Raghvendra Kumar,Sriparna Saha,Koustava Goswami,K. J. Joseph*

Main category: cs.CV

TL;DR: 引入PoemTale Diffusion方法和P4I数据集来改进诗歌文本到图像生成，侧重保持抽象语言的信息。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型在理解复杂或抽象语言（如诗歌）时存在困难。

Method: 提出PoemTale Diffusion方法，结合多阶段提示优化循环和修改的自注意力机制，提升诗歌文本到图像的生成效果。

Result: 通过人类评估和定量测试验证了方法的有效性，生成的图像能够更好地捕捉诗歌含义。

Conclusion: PoemTale Diffusion方法为诗歌文本到图像生成提供了新的视角，提升了抽象信息的保留与解析，并引入了P4I数据集以支持领域研究。

Abstract: Recent advancements in text-to-image diffusion models have achieved
remarkable success in generating realistic and diverse visual content. A
critical factor in this process is the model's ability to accurately interpret
textual prompts. However, these models often struggle with creative
expressions, particularly those involving complex, abstract, or highly
descriptive language. In this work, we introduce a novel training-free approach
tailored to improve image generation for a unique form of creative language:
poetic verse, which frequently features layered, abstract, and dual meanings.
Our proposed PoemTale Diffusion approach aims to minimise the information that
is lost during poetic text-to-image conversion by integrating a multi stage
prompt refinement loop into Language Models to enhance the interpretability of
poetic texts. To support this, we adapt existing state-of-the-art diffusion
models by modifying their self-attention mechanisms with a consistent
self-attention technique to generate multiple consistent images, which are then
collectively used to convey the poem's meaning. Moreover, to encourage research
in the field of poetry, we introduce the P4I (PoemForImage) dataset, consisting
of 1111 poems sourced from multiple online and offline resources. We engaged a
panel of poetry experts for qualitative assessments. The results from both
human and quantitative evaluations validate the efficacy of our method and
contribute a novel perspective to poem-to-image generation with enhanced
information capture in the generated images.

</details>


### [44] [Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction](https://arxiv.org/abs/2507.13719)
*Daniele Pannone,Alessia Castronovo,Maurizio Mancini,Gian Luca Foresti,Claudio Piciarelli,Rossana Gabrieli,Muhammad Yasir Bilal,Danilo Avola*

Main category: cs.CV

TL;DR: 论文提出一种为博物馆设计的增强现实管道系统，通过识别艺术品并从单张图片生成准确的3D模型，提高复杂艺术特征的表现。


<details>
  <summary>Details</summary>
Motivation: 提升博物馆互动体验，解决艺术品复杂形状及纹理的难点。

Method: 结合两种深度估计模型GLPN和Depth-Anything进行全球场景结构捕捉和局部细节重建，并将优化的深度图转换为高质量点云和网格。

Result: 实验表明该方法在重建精度和视觉真实度方面显著提高，可作为博物馆交互式数字内容的强大工具。

Conclusion: 该管道系统通过结合最先进的神经网络和计算机视觉技术，为博物馆提供沉浸式增强现实体验，能够有效提升观众的参与感。

Abstract: This paper presents an innovative augmented reality pipeline tailored for
museum environments, aimed at recognizing artworks and generating accurate 3D
models from single images. By integrating two complementary pre-trained depth
estimation models, i.e., GLPN for capturing global scene structure and
Depth-Anything for detailed local reconstruction, the proposed approach
produces optimized depth maps that effectively represent complex artistic
features. These maps are then converted into high-quality point clouds and
meshes, enabling the creation of immersive AR experiences. The methodology
leverages state-of-the-art neural network architectures and advanced computer
vision techniques to overcome challenges posed by irregular contours and
variable textures in artworks. Experimental results demonstrate significant
improvements in reconstruction accuracy and visual realism, making the system a
highly robust tool for museums seeking to enhance visitor engagement through
interactive digital content.

</details>


### [45] [Tackling fake images in cybersecurity -- Interpretation of a StyleGAN and lifting its black-box](https://arxiv.org/abs/2507.13722)
*Julia Laubmann,Johannes Reschke*

Main category: cs.CV

TL;DR: 探讨了StyleGAN生成器的内部机制，通过训练模型并分析权重揭示其在模型优化和特征调整上的表现。


<details>
  <summary>Details</summary>
Motivation: 深入理解StyleGAN生成器的运作原理，以探索其生成高仿真图像的机制及可能带来的伦理挑战。

Method: 利用PyTorch框架训练StyleGAN模型，结合权重修剪和潜在向量分析，研究其生成与优化机制。

Result: 发现大量权重可被删减而不会显著影响输出，同时通过潜在向量调整实现了对生成面部特征的精准控制。

Conclusion: 技术能力具有学术价值，但其滥用可能引发伦理问题，尤其是在数字欺诈和网络犯罪领域。

Abstract: In today's digital age, concerns about the dangers of AI-generated images are
increasingly common. One powerful tool in this domain is StyleGAN (style-based
generative adversarial networks), a generative adversarial network capable of
producing highly realistic synthetic faces. To gain a deeper understanding of
how such a model operates, this work focuses on analyzing the inner workings of
StyleGAN's generator component. Key architectural elements and techniques, such
as the Equalized Learning Rate, are explored in detail to shed light on the
model's behavior. A StyleGAN model is trained using the PyTorch framework,
enabling direct inspection of its learned weights. Through pruning, it is
revealed that a significant number of these weights can be removed without
drastically affecting the output, leading to reduced computational
requirements. Moreover, the role of the latent vector -- which heavily
influences the appearance of the generated faces -- is closely examined. Global
alterations to this vector primarily affect aspects like color tones, while
targeted changes to individual dimensions allow for precise manipulation of
specific facial features. This ability to finetune visual traits is not only of
academic interest but also highlights a serious ethical concern: the potential
misuse of such technology. Malicious actors could exploit this capability to
fabricate convincing fake identities, posing significant risks in the context
of digital deception and cybercrime.

</details>


### [46] [Can Synthetic Images Conquer Forgetting? Beyond Unexplored Doubts in Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2507.13739)
*Junsu Kim,Yunhoe Ku,Seungryul Baek*

Main category: cs.CV

TL;DR: 本文提出了一种名为Diffusion-FSCIL的新方法，用于解决少样本类增量学习（FSCIL）的问题，采用了一个冻结的文本到图像扩散模型作为骨干，显著地减少了遗忘问题并提升学习效果。


<details>
  <summary>Details</summary>
Motivation: FSCIL挑战在于数据极度稀缺，需要同时避免遗忘和学习新信息。因此，作者的动机是利用大规模预训练的生成模型能力来优化此问题。

Method: 通过冻结一个文本到图像的扩散模型作为骨干，结合多种扩散特征提取和少量特征蒸馏的支持，防止生成偏差和减少训练负担。

Result: 在CUB-200、miniImageNet和CIFAR-100数据集上的实验表明，Diffusion-FSCIL方法在保留已学习类的性能以及适应新类方面均超过了当前最优方法。

Conclusion: Diffusion-FSCIL展示了生成模型在解决FSCIL问题上的潜力，通过高效的框架设计和强大的表示能力在多个基准测试中取得领先表现。

Abstract: Few-shot class-incremental learning (FSCIL) is challenging due to extremely
limited training data; while aiming to reduce catastrophic forgetting and learn
new information. We propose Diffusion-FSCIL, a novel approach that employs a
text-to-image diffusion model as a frozen backbone. Our conjecture is that
FSCIL can be tackled using a large generative model's capabilities benefiting
from 1) generation ability via large-scale pre-training; 2) multi-scale
representation; 3) representational flexibility through the text encoder. To
maximize the representation capability, we propose to extract multiple
complementary diffusion features to play roles as latent replay with slight
support from feature distillation for preventing generative biases. Our
framework realizes efficiency through 1) using a frozen backbone; 2) minimal
trainable components; 3) batch processing of multiple feature extractions.
Extensive experiments on CUB-200, \emph{mini}ImageNet, and CIFAR-100 show that
Diffusion-FSCIL surpasses state-of-the-art methods, preserving performance on
previously learned classes and adapting effectively to new ones.

</details>


### [47] [Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis](https://arxiv.org/abs/2507.13753)
*Tongtong Su,Chengyu Wang,Bingyan Liu,Jun Huang,Dongming Lu*

Main category: cs.CV

TL;DR: 提出了一种称为EVS的无训练视频合成方法，其能在提升视频生成质量的同时提高生成速度。


<details>
  <summary>Details</summary>
Motivation: 解决当前文本到视频生成模型在图像质量和动作表现难以同时兼顾的挑战。

Method: 提出了一种结合T2I和T2V模型的无训练方法：用扩散模型对低质量视频帧进行去噪优化，使用T2V模型确保动作动态一致性，并将T2V的时间先验融入T2I生成过程。

Result: 生成的视频在画质和动作质量方面都有显著提升，并在推理时间方面实现了1.6x-4.5x的速度优化。

Conclusion: 通过结合T2I和T2V模型，EVS在无需重新训练的前提下有效提升了文本到视频生成的视觉保真度和动作平滑性。

Abstract: In recent years, large text-to-video (T2V) synthesis models have garnered
considerable attention for their abilities to generate videos from textual
descriptions. However, achieving both high imaging quality and effective motion
representation remains a significant challenge for these T2V models. Existing
approaches often adapt pre-trained text-to-image (T2I) models to refine video
frames, leading to issues such as flickering and artifacts due to
inconsistencies across frames. In this paper, we introduce EVS, a training-free
Encapsulated Video Synthesizer that composes T2I and T2V models to enhance both
visual fidelity and motion smoothness of generated videos. Our approach
utilizes a well-trained diffusion-based T2I model to refine low-quality video
frames by treating them as out-of-distribution samples, effectively optimizing
them with noising and denoising steps. Meanwhile, we employ T2V backbones to
ensure consistent motion dynamics. By encapsulating the T2V temporal-only prior
into the T2I generation process, EVS successfully leverages the strengths of
both types of models, resulting in videos of improved imaging and motion
quality. Experimental results validate the effectiveness of our approach
compared to previous approaches. Our composition process also leads to a
significant improvement of 1.6x-4.5x speedup in inference time. Source codes:
https://github.com/Tonniia/EVS.

</details>


### [48] [Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction](https://arxiv.org/abs/2507.13769)
*Mingyang Yu,Zhijian Wu,Dingjiang Huang*

Main category: cs.CV

TL;DR: 提出了一种利用光谱扩散先验（SDP）提升高光谱图像重建性能的方法，通过扩散模型学习光谱先验，并引入光谱先验注入模块（SPIM）动态指导模型重建细节，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的高光谱图像重建方法难以准确捕获高频细节。

Method: 提出光谱扩散先验（SDP），利用扩散模型学习光谱领域的隐式先验，同时设计光谱先验注入模块（SPIM）提升模型动态重建细节能力。

Result: 在两种代表性高光谱图像方法MST和BISRNet上实验显示，提出的方法性能优于现有网络约0.5dB。

Conclusion: 通过引入光谱扩散先验和光谱先验注入模块，显著提高了高光谱图像重建的细节还原能力和整体效果。

Abstract: Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its
degraded 2D measurements. Recently great progress has been made in deep
learning-based methods, however, these methods often struggle to accurately
capture high-frequency details of the HSI. To address this issue, this paper
proposes a Spectral Diffusion Prior (SDP) that is implicitly learned from
hyperspectral images using a diffusion model. Leveraging the powerful ability
of the diffusion model to reconstruct details, this learned prior can
significantly improve the performance when injected into the HSI model. To
further improve the effectiveness of the learned prior, we also propose the
Spectral Prior Injector Module (SPIM) to dynamically guide the model to recover
the HSI details. We evaluate our method on two representative HSI methods: MST
and BISRNet. Experimental results show that our method outperforms existing
networks by about 0.5 dB, effectively improving the performance of HSI
reconstruction.

</details>


### [49] [Feature Engineering is Not Dead: Reviving Classical Machine Learning with Entropy, HOG, and LBP Feature Fusion for Image Classification](https://arxiv.org/abs/2507.13772)
*Abhijit Sen,Giridas Maiti,Bikram K. Parida,Bhanu P. Mishra,Mahima Arya,Denys I. Bondar*

Main category: cs.CV

TL;DR: 本文提出了一种基于排列熵（PE）的全新图像分类方法，结合HOG和LBP特征，通过SVM分类器优化实现高效和可解释的分类性能。


<details>
  <summary>Details</summary>
Motivation: 在追求模型可解释性和计算效率的图像分类场景中，需要探索轻量级、非深度学习的替代方法。

Method: 扩展PE到二维图像，结合多尺度、多方向的熵特征提取，同时融合HOG和LBP这两种传统图像特征，使用SVM进行优化和分类。

Result: 在Fashion-MNIST、KMNIST、EMNIST和CIFAR-10等数据集上取得了与深度学习模型相当的分类效果。

Conclusion: 结合PE、HOG、LBP的特征提取提供了一种低算力、高可解释性的图像分类替代方法，展示了熵特征在计算机视觉中的潜力。

Abstract: Feature engineering continues to play a critical role in image
classification, particularly when interpretability and computational efficiency
are prioritized over deep learning models with millions of parameters. In this
study, we revisit classical machine learning based image classification through
a novel approach centered on Permutation Entropy (PE), a robust and
computationally lightweight measure traditionally used in time series analysis
but rarely applied to image data. We extend PE to two-dimensional images and
propose a multiscale, multi-orientation entropy-based feature extraction
approach that characterizes spatial order and complexity along rows, columns,
diagonals, anti-diagonals, and local patches of the image. To enhance the
discriminatory power of the entropy features, we integrate two classic image
descriptors: the Histogram of Oriented Gradients (HOG) to capture shape and
edge structure, and Local Binary Patterns (LBP) to encode micro-texture of an
image. The resulting hand-crafted feature set, comprising of 780 dimensions, is
used to train Support Vector Machine (SVM) classifiers optimized through grid
search. The proposed approach is evaluated on multiple benchmark datasets,
including Fashion-MNIST, KMNIST, EMNIST, and CIFAR-10, where it delivers
competitive classification performance without relying on deep architectures.
Our results demonstrate that the fusion of PE with HOG and LBP provides a
compact, interpretable, and effective alternative to computationally expensive
and limited interpretable deep learning models. This shows a potential of
entropy-based descriptors in image classification and contributes a lightweight
and generalizable solution to interpretable machine learning in image
classification and computer vision.

</details>


### [50] [Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions](https://arxiv.org/abs/2507.13773)
*Pu Jian,Donglei Yu,Wen Yang,Shuo Ren,Jiajun Zhang*

Main category: cs.CV

TL;DR: 提出了 ClearVQA 基准，用于衡量视觉问题答复中的模糊澄清能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言模型中因表达习惯差异导致的问题模糊性，并弥补模型缺少交互澄清能力的不足。

Method: 设计了 ClearVQA 基准，覆盖三大常见模糊类别及多种 VQA 场景，评估模型的交互澄清能力。

Result: ClearVQA 能评估视觉语言模型通过互动解决模糊问题的能力。

Conclusion: ClearVQA 提供了一种新的工具来衡量和改进视觉语言模型处理模糊性问题的交互式性能。

Abstract: In visual question answering (VQA) context, users often pose ambiguous
questions to visual language models (VLMs) due to varying expression habits.
Existing research addresses such ambiguities primarily by rephrasing questions.
These approaches neglect the inherently interactive nature of user interactions
with VLMs, where ambiguities can be clarified through user feedback. However,
research on interactive clarification faces two major challenges: (1)
Benchmarks are absent to assess VLMs' capacity for resolving ambiguities
through interaction; (2) VLMs are trained to prefer answering rather than
asking, preventing them from seeking clarification. To overcome these
challenges, we introduce \textbf{ClearVQA} benchmark, which targets three
common categories of ambiguity in VQA context, and encompasses various VQA
scenarios.

</details>


### [51] [SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering](https://arxiv.org/abs/2507.13779)
*Durgesh Singh,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 本文探索使用显式可微分的聚类模块来改进半监督学习 (SSL) 和无监督领域自适应 (UDA) 的效果，并通过大量实验验证了其在低监督条件下的优势。


<details>
  <summary>Details</summary>
Motivation: 半监督学习和无监督领域自适应需要依赖有限的标注数据和大量未标注数据来提升模型性能，但目前的方法主要通过隐式方式利用聚类假设，需探索更直接的策略。

Method: 提出一种显式引入可微分聚类模块的方法，该模块利用标注数据计算中心点，并采用端到端的训练策略来改进半监督学习和领域自适应，既可作为单独模型，又可用作其他方法的正则器。

Result: 实验结果表明，该方法在低监督场景下具有显著效果，作为独立模型或协助现有方法时均表现良好。

Conclusion: 显式的可微分聚类模块和端到端训练策略显著提高了SSL和UDA的表现，尤其在低监督条件下，显示了其理论意义和实际应用潜力。

Abstract: Semi-Supervised Learning (SSL) and Unsupervised Domain Adaptation (UDA)
enhance the model performance by exploiting information from labeled and
unlabeled data. The clustering assumption has proven advantageous for learning
with limited supervision and states that data points belonging to the same
cluster in a high-dimensional space should be assigned to the same category.
Recent works have utilized different training mechanisms to implicitly enforce
this assumption for the SSL and UDA. In this work, we take a different approach
by explicitly involving a differentiable clustering module which is extended to
leverage the supervised data to compute its centroids. We demonstrate the
effectiveness of our straightforward end-to-end training strategy for SSL and
UDA over extensive experiments and highlight its benefits, especially in low
supervision regimes, both as a standalone model and as a regularizer for
existing approaches.

</details>


### [52] [Localized FNO for Spatiotemporal Hemodynamic Upsampling in Aneurysm MRI](https://arxiv.org/abs/2507.13789)
*Kyriakos Flouris,Moritz Halter,Yolanne Y. R. Lee,Samuel Castonguay,Luuk Jacobs,Pietro Dirix,Jonathan Nestmann,Sebastian Kozerke,Ender Konukoglu*

Main category: cs.CV

TL;DR: 提出了一种名为LoFNO（Localized Fourier Neural Operator）的新颖3D架构，用于提高血流影像数据的时空分辨率和信噪比，能够直接从临床数据中预测壁剪应力（WSS）。


<details>
  <summary>Details</summary>
Motivation: 解决磁共振流量成像中分辨率低和信噪比差的问题，为脑血管病诊断提供更精确的数据支持。

Method: 利用几何先验（拉普拉斯特征向量）结合神经算子框架，以及增强型深度超分辨率网络（EDSR）技术，提高数据的去噪和分辨率。

Result: LoFNO在速度和壁剪应力的预测上，比传统插值方法和其他深度学习方法表现更优。

Conclusion: LoFNO能够在复杂几何下实现更精确的脑血管血流分析，为脑动脉瘤破裂风险评估和治疗提供更好的诊断工具。

Abstract: Hemodynamic analysis is essential for predicting aneurysm rupture and guiding
treatment. While magnetic resonance flow imaging enables time-resolved
volumetric blood velocity measurements, its low spatiotemporal resolution and
signal-to-noise ratio limit its diagnostic utility. To address this, we propose
the Localized Fourier Neural Operator (LoFNO), a novel 3D architecture that
enhances both spatial and temporal resolution with the ability to predict wall
shear stress (WSS) directly from clinical imaging data. LoFNO integrates
Laplacian eigenvectors as geometric priors for improved structural awareness on
irregular, unseen geometries and employs an Enhanced Deep Super-Resolution
Network (EDSR) layer for robust upsampling. By combining geometric priors with
neural operator frameworks, LoFNO de-noises and spatiotemporally upsamples flow
data, achieving superior velocity and WSS predictions compared to interpolation
and alternative deep learning methods, enabling more precise cerebrovascular
diagnostics.

</details>


### [53] [NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining](https://arxiv.org/abs/2507.14119)
*Maksim Kuprashevich,Grigorii Alekseenko,Irina Tolstykh,Georgii Fedorov,Bulat Suleimanov,Vladimir Dokholyan,Aleksandr Gordeev*

Main category: cs.CV

TL;DR: 该论文提出了一种自动化管道，生成高保真图像编辑数据集并开源新数据集NHR-Edit，同时改进模型Bagel以达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成式模型的监督训练需要大量高质量的图像编辑三元组数据，而这些数据集难以大规模构建且缺乏可靠的编辑质量指标。

Method: 提出了一种模块化自动管道，利用Gemini验证器进行任务调优，同时采用逆向和组合自举方法扩展数据规模，无需人工标注。

Result: 生成了包含358k高质量三元组的数据集NHR-Edit，在跨数据集评估中性能超过所有公开替代方案，并改进出开源模型Bagel-NHR-Edit，实验中指标达到最先进水平。

Conclusion: 所提方法显著提升图像编辑数据生成效率，降低了建造高质量数据集的成本，促进了生成式图像编辑模型的研究和应用的发展。

Abstract: Recent advances in generative modeling enable image editing assistants that
follow natural language instructions without additional user input. Their
supervised training requires millions of triplets: original image, instruction,
edited image. Yet mining pixel-accurate examples is hard. Each edit must affect
only prompt-specified regions, preserve stylistic coherence, respect physical
plausibility, and retain visual appeal. The lack of robust automated
edit-quality metrics hinders reliable automation at scale. We present an
automated, modular pipeline that mines high-fidelity triplets across domains,
resolutions, instruction complexities, and styles. Built on public generative
models and running without human intervention, our system uses a task-tuned
Gemini validator to score instruction adherence and aesthetics directly,
removing any need for segmentation or grounding models. Inversion and
compositional bootstrapping enlarge the mined set by approximately 2.2x,
enabling large-scale high-fidelity training data. By automating the most
repetitive annotation steps, the approach allows a new scale of training
without human labeling effort. To democratize research in this
resource-intensive area, we release NHR-Edit: an open dataset of 358k
high-quality triplets. In the largest cross-dataset evaluation, it surpasses
all public alternatives. We also release Bagel-NHR-Edit, an open-source
fine-tuned Bagel model, which achieves state-of-the-art metrics in our
experiments.

</details>


### [54] [DynFaceRestore: Balancing Fidelity and Quality in Diffusion-Guided Blind Face Restoration with Dynamic Blur-Level Mapping and Guidance](https://arxiv.org/abs/2507.13797)
*Huu-Phu Do,Yu-Wei Chen,Yi-Cheng Liao,Chi-Wei Hsiao,Han-Yang Wang,Wei-Chen Chiu,Ching-Chun Huang*

Main category: cs.CV

TL;DR: 提出了DynFaceRestore方法，通过动态时间步选择和局部指导调整解决盲人脸恢复问题，实现了新水平的图像质量和平衡。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在处理待恢复图像时使用固定扩散采样步和全局指导比例引发的问题，提升盲人脸恢复的精度和细节平衡。

Method: 提出一种将盲恢复映射到高斯模糊域的方法，通过动态选择模糊图像的扩散起始时间步并引入局部适应性指导提升结构和细节的恢复质量。

Result: 本方法在定量和定性评估中均达到最先进的性能，展现出了在盲人脸恢复任务中的卓越鲁棒性和效果。

Conclusion: DynFaceRestore通过动态调整策略，成功实现了结构保真与细节平衡的盲人脸恢复，为相关图像处理任务提供了一种有效解决方案。

Abstract: Blind Face Restoration aims to recover high-fidelity, detail-rich facial
images from unknown degraded inputs, presenting significant challenges in
preserving both identity and detail. Pre-trained diffusion models have been
increasingly used as image priors to generate fine details. Still, existing
methods often use fixed diffusion sampling timesteps and a global guidance
scale, assuming uniform degradation. This limitation and potentially imperfect
degradation kernel estimation frequently lead to under- or over-diffusion,
resulting in an imbalance between fidelity and quality. We propose
DynFaceRestore, a novel blind face restoration approach that learns to map any
blindly degraded input to Gaussian blurry images. By leveraging these blurry
images and their respective Gaussian kernels, we dynamically select the
starting timesteps for each blurry image and apply closed-form guidance during
the diffusion sampling process to maintain fidelity. Additionally, we introduce
a dynamic guidance scaling adjuster that modulates the guidance strength across
local regions, enhancing detail generation in complex areas while preserving
structural fidelity in contours. This strategy effectively balances the
trade-off between fidelity and quality. DynFaceRestore achieves
state-of-the-art performance in both quantitative and qualitative evaluations,
demonstrating robustness and effectiveness in blind face restoration.

</details>


### [55] [One Step Closer: Creating the Future to Boost Monocular Semantic Scene Completion](https://arxiv.org/abs/2507.13801)
*Haoang Lu,Yuanqi Su,Xiaoning Zhang,Hao Hu*

Main category: cs.CV

TL;DR: 本论文提出了CF-SSC，一个基于伪未来帧预测的时间性3D语义场景补全集框架，显著提升了单目3D场景补全在遮挡推理和准确性方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的单目3D语义场景补全方法无法有效解决真实交通场景中存在的大量遮挡和摄像机视角局限的问题。

Method: 提出了一个新的时间性3D语义场景补全集框架CF-SSC，通过结合位姿和深度信息，进行几何一致性的过去、现在和未来帧融合；采用3D感知架构，明确建模时空关系，从而克服传统简单特征叠加方法的不足。

Result: 在SemanticKITTI和SSCBench-KITTI-360基准测试中表现出色，达到了当前最优性能，验证了方法在遮挡推理和场景补全准确性方面的改进。

Conclusion: CF-SSC显著提升了单目3D语义场景补全能力，特别是在解决遮挡问题和提高对3D场景的感知精度方面具有重要意义。

Abstract: In recent years, visual 3D Semantic Scene Completion (SSC) has emerged as a
critical perception task for autonomous driving due to its ability to infer
complete 3D scene layouts and semantics from single 2D images. However, in
real-world traffic scenarios, a significant portion of the scene remains
occluded or outside the camera's field of view -- a fundamental challenge that
existing monocular SSC methods fail to address adequately. To overcome these
limitations, we propose Creating the Future SSC (CF-SSC), a novel temporal SSC
framework that leverages pseudo-future frame prediction to expand the model's
effective perceptual range. Our approach combines poses and depths to establish
accurate 3D correspondences, enabling geometrically-consistent fusion of past,
present, and predicted future frames in 3D space. Unlike conventional methods
that rely on simple feature stacking, our 3D-aware architecture achieves more
robust scene completion by explicitly modeling spatial-temporal relationships.
Comprehensive experiments on SemanticKITTI and SSCBench-KITTI-360 benchmarks
demonstrate state-of-the-art performance, validating the effectiveness of our
approach, highlighting our method's ability to improve occlusion reasoning and
3D scene completion accuracy.

</details>


### [56] [GRAM-MAMBA: Holistic Feature Alignment for Wireless Perception with Adaptive Low-Rank Compensation](https://arxiv.org/abs/2507.13803)
*Weiqi Yang,Xu Zhou,Jingfu Guan,Hao Du,Tianyu Bai*

Main category: cs.CV

TL;DR: 提出GRAM-MAMBA框架，通过线性复杂度模型和优化的GRAM矩阵策略，实现高效多模态感知，并在资源受限环境中展现出显著鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现有多模态感知系统因模型复杂度高、模态对齐单向性和缺失数据鲁棒性差等问题，妨碍了物联网实际应用中的效率和鲁棒性。

Method: 基于Mamba模型进行传感器时序数据的高效处理；采用GRAM矩阵策略实现模态间的双向对齐；基于LoRA提出低秩层自适应补偿策略，对缺失模态进行训练后调整。

Result: 在SPAWC2021数据集上，处理缺失模态时性能提升24.5%；在USC-HAD数据集上，F1值达93.55%，整体准确率93.81%，且训练参数量极少。

Conclusion: GRAM-MAMBA在资源受限情况下能实现高效、鲁棒的多模态感知，显著优于现有方法，具有广泛应用潜力。

Abstract: Multi-modal fusion is crucial for Internet of Things (IoT) perception, widely
deployed in smart homes, intelligent transport, industrial automation, and
healthcare. However, existing systems often face challenges: high model
complexity hinders deployment in resource-constrained environments,
unidirectional modal alignment neglects inter-modal relationships, and
robustness suffers when sensor data is missing. These issues impede efficient
and robust multimodal perception in real-world IoT settings. To overcome these
limitations, we propose GRAM-MAMBA. This framework utilizes the
linear-complexity Mamba model for efficient sensor time-series processing,
combined with an optimized GRAM matrix strategy for pairwise alignment among
modalities, addressing the shortcomings of traditional single-modality
alignment. Inspired by Low-Rank Adaptation (LoRA), we introduce an adaptive
low-rank layer compensation strategy to handle missing modalities
post-training. This strategy freezes the pre-trained model core and irrelevant
adaptive layers, fine-tuning only those related to available modalities and the
fusion process. Extensive experiments validate GRAM-MAMBA's effectiveness. On
the SPAWC2021 indoor positioning dataset, the pre-trained model shows lower
error than baselines; adapting to missing modalities yields a 24.5% performance
boost by training less than 0.2% of parameters. On the USC-HAD human activity
recognition dataset, it achieves 93.55% F1 and 93.81% Overall Accuracy (OA),
outperforming prior work; the update strategy increases F1 by 23% while
training less than 0.3% of parameters. These results highlight GRAM-MAMBA's
potential for achieving efficient and robust multimodal perception in
resource-constrained environments.

</details>


### [57] [SkySense V2: A Unified Foundation Model for Multi-modal Remote Sensing](https://arxiv.org/abs/2507.13812)
*Yingying Zhang,Lixiang Ru,Kang Wu,Lei Yu,Lei Liang,Yansheng Li,Jingdong Chen*

Main category: cs.CV

TL;DR: SkySense V2是一个多模态遥感基础模型，使用单一Transformer骨干网络，解决了多模态数据冗余和效率问题，并采用适应遥感图像特点的自监督学习方法，提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要为每种数据模态单独训练网络，效率低下，同时没有充分考虑遥感图像的特殊特点，如单图像内复杂语义分布。

Method: 提出了SkySense V2，一个统一的多模态遥感模型，单一Transformer骨干网络结合自监督学习技术，并引入自适应补丁合并模块和可学习模态提示令牌。为进一步提升性能，添加了专家混合模块（MoE）。

Result: 在16个数据集和7个任务上进行评估，平均超越SkySense 1.8分，展现了出色的泛化能力。

Conclusion: SkySense V2解决了遥感多模态任务的效率和特性适配问题，性能方面显著优于前一版本，对相关领域任务有重要贡献。

Abstract: The multi-modal remote sensing foundation model (MM-RSFM) has significantly
advanced various Earth observation tasks, such as urban planning, environmental
monitoring, and natural disaster management. However, most existing approaches
generally require the training of separate backbone networks for each data
modality, leading to redundancy and inefficient parameter utilization.
Moreover, prevalent pre-training methods typically apply self-supervised
learning (SSL) techniques from natural images without adequately accommodating
the characteristics of remote sensing (RS) images, such as the complicated
semantic distribution within a single RS image. In this work, we present
SkySense V2, a unified MM-RSFM that employs a single transformer backbone to
handle multiple modalities. This backbone is pre-trained with a novel SSL
strategy tailored to the distinct traits of RS data. In particular, SkySense V2
incorporates an innovative adaptive patch merging module and learnable modality
prompt tokens to address challenges related to varying resolutions and limited
feature diversity across modalities. In additional, we incorporate the mixture
of experts (MoE) module to further enhance the performance of the foundation
model. SkySense V2 demonstrates impressive generalization abilities through an
extensive evaluation involving 16 datasets over 7 tasks, outperforming SkySense
by an average of 1.8 points.

</details>


### [58] [Team of One: Cracking Complex Video QA with Model Synergy](https://arxiv.org/abs/2507.13820)
*Jun Xie,Zhaoran Zhao,Xiongjun Guan,Yingjian Zhu,Hongzhu Yi,Xinming Wang,Feng Chen,Zhepeng Wang*

Main category: cs.CV

TL;DR: 本文提出一种新框架，通过增强推理深度和现实世界场景中的鲁棒性改进视频问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频-大规模多模态模型在上下文理解、时间建模和应对复杂查询方面存在局限性，需要方法改进。

Method: 提出了一种“提示与响应集成”机制，协调多个异构的视频语言模型，同时引入外部语言模型作为评估器和整合器。

Result: 实验表明，该方法显著优于现有基线方法，在所有评估指标上均表现出卓越的泛化与鲁棒性。

Conclusion: 该方法提供了一种轻量、可扩展的策略，在无需重新训练模型的情况下推进多模态推理的发展，并为未来视频多模态模型发展奠定了基础。

Abstract: We propose a novel framework for open-ended video question answering that
enhances reasoning depth and robustness in complex real-world scenarios, as
benchmarked on the CVRR-ES dataset. Existing Video-Large Multimodal Models
(Video-LMMs) often exhibit limited contextual understanding, weak temporal
modeling, and poor generalization to ambiguous or compositional queries. To
address these challenges, we introduce a prompting-and-response integration
mechanism that coordinates multiple heterogeneous Video-Language Models (VLMs)
via structured chains of thought, each tailored to distinct reasoning pathways.
An external Large Language Model (LLM) serves as an evaluator and integrator,
selecting and fusing the most reliable responses. Extensive experiments
demonstrate that our method significantly outperforms existing baselines across
all evaluation metrics, showcasing superior generalization and robustness. Our
approach offers a lightweight, extensible strategy for advancing multimodal
reasoning without requiring model retraining, setting a strong foundation for
future Video-LMM development.

</details>


### [59] [A Quantum-assisted Attention U-Net for Building Segmentation over Tunis using Sentinel-1 Data](https://arxiv.org/abs/2507.13852)
*Luigi Russo,Francesco Mauro,Babak Memar,Alessandro Sebastianelli,Silvia Liberata Ullo,Paolo Gamba*

Main category: cs.CV

TL;DR: 本文研究通过Quanvolutional预处理提升Attention U-Net模型的建筑分割能力，利用Tunis的Sentinel-1 SAR影像进行验证，结果表明该方法在保持准确性的同时显著减少了网络参数。


<details>
  <summary>Details</summary>
Motivation: 城市建筑分割对于城市规划、灾害响应和人口映射极为关键，但由于卫星图像的大尺寸和高分辨率，在密集城市区域中精确分割建筑是一项挑战。

Method: 使用Quanvolution提取雷达影像中重要的结构细节特征，并结合Attention U-Net模型进行建筑分割。

Result: 实验表明，与标准Attention U-Net模型相比，该方法在保持较高测试精度的同时，显著减少了网络参数。

Conclusion: Quanvolution与深度学习框架结合在城市环境下的大规模建筑分割任务中具有广阔的应用潜力，既能实现准确性又提升计算效率。

Abstract: Building segmentation in urban areas is essential in fields such as urban
planning, disaster response, and population mapping. Yet accurately segmenting
buildings in dense urban regions presents challenges due to the large size and
high resolution of satellite images. This study investigates the use of a
Quanvolutional pre-processing to enhance the capability of the Attention U-Net
model in the building segmentation. Specifically, this paper focuses on the
urban landscape of Tunis, utilizing Sentinel-1 Synthetic Aperture Radar (SAR)
imagery. In this work, Quanvolution was used to extract more informative
feature maps that capture essential structural details in radar imagery,
proving beneficial for accurate building segmentation. Preliminary results
indicate that proposed methodology achieves comparable test accuracy to the
standard Attention U-Net model while significantly reducing network parameters.
This result aligns with findings from previous works, confirming that
Quanvolution not only maintains model accuracy but also increases computational
efficiency. These promising outcomes highlight the potential of
quantum-assisted Deep Learning frameworks for large-scale building segmentation
in urban environments.

</details>


### [60] [Depth3DLane: Fusing Monocular 3D Lane Detection with Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2507.13857)
*Max van den Hoven,Kishaan Jeeveswaran,Pieter Piscaer,Thijs Wensveen,Elahe Arani,Bahram Zonooz*

Main category: cs.CV

TL;DR: 本文提出Depth3DLane，一种用于单目3D车道检测的自监督方法，无需昂贵传感器或额外深度数据，并且可在无相机校准情况下运行。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D车道检测方法局限于需要昂贵深度传感器或难以大规模收集的地面对齐深度数据，同时还假设相机参数可用，这在众包高清地图等场景中应用受限。

Method: 设计了Depth3DLane框架，结合自监督单目深度估计，利用场景点云表征生成鸟瞰图路径，以提取空间信息，同时通过前视图路径提取语义信息。并引入3D车道锚点以融合这两类特征。同时提出每帧相机参数预测和每段车道的拟合策略增强稳定性。

Result: 实验证明Depth3DLane在OpenLane基准数据集上性能具有竞争力，相机参数学习的结果使其在无法进行相机校准的场景下也可运行。

Conclusion: Depth3DLane通过自监督方法有效检测3D车道，增强实际应用的可能性，尤其在相机参数无法预知的场景中表现优越。

Abstract: Monocular 3D lane detection is essential for autonomous driving, but
challenging due to the inherent lack of explicit spatial information.
Multi-modal approaches rely on expensive depth sensors, while methods
incorporating fully-supervised depth networks rely on ground-truth depth data
that is impractical to collect at scale. Additionally, existing methods assume
that camera parameters are available, limiting their applicability in scenarios
like crowdsourced high-definition (HD) lane mapping. To address these
limitations, we propose Depth3DLane, a novel dual-pathway framework that
integrates self-supervised monocular depth estimation to provide explicit
structural information, without the need for expensive sensors or additional
ground-truth depth data. Leveraging a self-supervised depth network to obtain a
point cloud representation of the scene, our bird's-eye view pathway extracts
explicit spatial information, while our front view pathway simultaneously
extracts rich semantic information. Depth3DLane then uses 3D lane anchors to
sample features from both pathways and infer accurate 3D lane geometry.
Furthermore, we extend the framework to predict camera parameters on a
per-frame basis and introduce a theoretically motivated fitting procedure to
enhance stability on a per-segment basis. Extensive experiments demonstrate
that Depth3DLane achieves competitive performance on the OpenLane benchmark
dataset. Furthermore, experimental results show that using learned parameters
instead of ground-truth parameters allows Depth3DLane to be applied in
scenarios where camera calibration is infeasible, unlike previous methods.

</details>


### [61] [PositionIC: Unified Position and Identity Consistency for Image Customization](https://arxiv.org/abs/2507.13861)
*Junjie Hu,Tianyang Han,Kai Ma,Jialin Gao,Hao Dou,Song Yang,Xianhua He,Jianhui Zhang,Junfeng Luo,Xiaoming Wei,Wenqiang Zhang*

Main category: cs.CV

TL;DR: 本文介绍了一种名为PositionIC的新框架，用于在多主体图像定制任务中实现位置与身份的一致性，并实现了精确的空间控制。


<details>
  <summary>Details</summary>
Motivation: 当前的图像定制在真实感上已经取得了显著进步，但在实现精细的实体级空间控制方面仍存在限制。主要原因是缺乏将身份与具体位置信号绑定的大规模数据集。

Method: 提出了PositionIC框架，通过双向生成范式消除主体漂移并维护语义一致性，同时设计了轻量级的定位调制层来解耦主体之间的空间嵌入，实现独立精准的摆放和视觉保真度。

Result: 实验证明，该方法在保持图像定制任务高一致性的同时，能够实现精确的空间控制。

Conclusion: PositionIC为在开放世界等多实体场景下实现可控的高保真图像定制开辟了新方向，并将公开以促进更多研究。

Abstract: Recent subject-driven image customization has achieved significant
advancements in fidelity, yet fine-grained entity-level spatial control remains
elusive, hindering the broader real-world application. This limitation is
mainly attributed to scalable datasets that bind identity with precise
positional cues are absent. To this end, we introduce PositionIC, a unified
framework that enforces position and identity consistency for multi-subject
customization. We construct a scalable synthesis pipeline that employs a
bidirectional generation paradigm to eliminate subject drift and maintain
semantic coherence. On top of these data, we design a lightweight positional
modulation layer that decouples spatial embeddings among subjects, enabling
independent, accurate placement while preserving visual fidelity. Extensive
experiments demonstrate that our approach can achieve precise spatial control
while maintaining high consistency in image customization task. PositionIC
paves the way for controllable, high-fidelity image customization in
open-world, multi-entity scenarios and will be released to foster further
research.

</details>


### [62] [When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models](https://arxiv.org/abs/2507.13868)
*Francesco Ortu,Zhijing Jin,Diego Doimo,Alberto Cazzaniga*

Main category: cs.CV

TL;DR: 该论文研究了如何解析视觉-语言模型在面对视觉信息和内部知识矛盾时的工作机制，并通过数据集和方法得出结论。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型在处理复杂任务时面临内部知识与外部信息冲突的问题，有时可能导致虚假或不可靠的结果，但这些机制尚未明了。

Method: 提出一个包含多模态反事实查询的数据集，用以故意制造与常识相反的情况，通过logit分析定位控制矛盾的头部节点，并通过修改头部节点控制模型的倾向。同时使用头部的注意力定位图像区域，完成精准的视觉解析。

Result: 精准定位出由内部知识或视觉输入控制的模型头部，证明这些头部的注意力对视觉覆盖区域的定位优于基于梯度的方法。

Conclusion: 通过解析视觉-语言模型的内部机制，提出一种可以更好地理解和调节模型响应的新方法，为理解知识冲突的解析机制提供了有力支持。

Abstract: Vision-language models (VLMs) increasingly leverage diverse knowledge sources
to address complex tasks, often encountering conflicts between their internal
parametric knowledge and external information. Knowledge conflicts can result
in hallucinations and unreliable responses, but the mechanisms governing such
interactions remain unknown. To address this gap, we analyze the mechanisms
that VLMs use to resolve cross-modal conflicts by introducing a dataset of
multimodal counterfactual queries that deliberately contradict internal
commonsense knowledge. We localize with logit inspection a small set of heads
that control the conflict. Moreover, by modifying these heads, we can steer the
model towards its internal knowledge or the visual inputs. Finally, we show
that attention from such heads pinpoints localized image regions driving visual
overrides, outperforming gradient-based attribution in precision.

</details>


### [63] [Real-Time Fusion of Visual and Chart Data for Enhanced Maritime Vision](https://arxiv.org/abs/2507.13880)
*Marten Kreis,Benjamin Kiefer*

Main category: cs.CV

TL;DR: 论文提出了一种通过融合实时视觉数据与海图信息来增强海洋视觉的新方法。


<details>
  <summary>Details</summary>
Motivation: 旨在解决动态和复杂环境中目标定位与匹配准确性的问题。

Method: 引入基于Transformer的端到端神经网络，预测浮标查询的边界框与置信度评分，匹配图像与海图中的目标。

Result: 实验结果表明该方法在真实海事场景数据集上显著提升了目标定位与匹配的准确性。

Conclusion: 本方法在动态复杂的海洋环境中展现出优越的性能，较传统方法具有较大优势。

Abstract: This paper presents a novel approach to enhancing marine vision by fusing
real-time visual data with chart information. Our system overlays nautical
chart data onto live video feeds by accurately matching detected navigational
aids, such as buoys, with their corresponding representations in chart data. To
achieve robust association, we introduce a transformer-based end-to-end neural
network that predicts bounding boxes and confidence scores for buoy queries,
enabling the direct matching of image-domain detections with world-space chart
markers. The proposed method is compared against baseline approaches, including
a ray-casting model that estimates buoy positions via camera projection and a
YOLOv7-based network extended with a distance estimation module. Experimental
results on a dataset of real-world maritime scenes demonstrate that our
approach significantly improves object localization and association accuracy in
dynamic and challenging environments.

</details>


### [64] [PCR-GS: COLMAP-Free 3D Gaussian Splatting via Pose Co-Regularizations](https://arxiv.org/abs/2507.13891)
*Yu Wei,Jiahui Zhang,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: 提出了PCR-GS技术，通过摄像机姿态的共正则化，提供了一种无须COLMAP的高质量3D场景建模方法，应对复杂的摄像机轨迹。


<details>
  <summary>Details</summary>
Motivation: 解决3D-GS在处理存在剧烈旋转和平移的复杂摄像机轨迹时的姿态估计问题。

Method: 通过摄像机姿态的共正则化推进3D场景建模，包括视图稳健特征的重投影正则化和基于小波的频率正则化两个方面。

Result: PCR-GS在多个真实场景中实现了在剧烈摄像机轨迹变化下的高质量无姿态3D建模效果。

Conclusion: PCR-GS技术能够有效提升无姿态3D-GS的性能，特别是在复杂摄像机运动场景中促成更好的3D场景建模和摄像机姿态估计。

Abstract: COLMAP-free 3D Gaussian Splatting (3D-GS) has recently attracted increasing
attention due to its remarkable performance in reconstructing high-quality 3D
scenes from unposed images or videos. However, it often struggles to handle
scenes with complex camera trajectories as featured by drastic rotation and
translation across adjacent camera views, leading to degraded estimation of
camera poses and further local minima in joint optimization of camera poses and
3D-GS. We propose PCR-GS, an innovative COLMAP-free 3DGS technique that
achieves superior 3D scene modeling and camera pose estimation via camera pose
co-regularization. PCR-GS achieves regularization from two perspectives. The
first is feature reprojection regularization which extracts view-robust DINO
features from adjacent camera views and aligns their semantic information for
camera pose regularization. The second is wavelet-based frequency
regularization which exploits discrepancy in high-frequency details to further
optimize the rotation matrix in camera poses. Extensive experiments over
multiple real-world scenes show that the proposed PCR-GS achieves superior
pose-free 3D-GS scene modeling under dramatic changes of camera trajectories.

</details>


### [65] [Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection](https://arxiv.org/abs/2507.13899)
*Yujian Mo,Yan Wu,Junqiao Zhao,Jijun Wang,Yinghao Hu,Jun Yan*

Main category: cs.CV

TL;DR: 这篇论文通过结合DepthAnything的深度先验信息和LiDAR数据，提高了3D目标检测的准确性，尤其是在弱反射率属性问题上有所加强。


<details>
  <summary>Details</summary>
Motivation: 旨在克服原始LiDAR点特征的表达能力限制，特别是反射率的弱区分能力，并提升LiDAR在自动驾驶中的检测性能。

Method: 引入DepthAnything预测的深度先验信息，与LiDAR原始数据融合并丰富点特征，提出点级特征提取模块和双路径RoI特征提取框架，最后通过双向门控RoI特征融合模块进行集成。

Result: 在KITTI基准测试上表现出色，显著提升了检测精度，验证了引入视觉基础模型先验信息的有效性。

Conclusion: 将视觉基础模型的深度先验信息结合到LiDAR点云数据中，可以深层次优化3D目标检测的表现，兼顾了全局语义和局部结构细节。

Abstract: Recent advances in foundation models have opened up new possibilities for
enhancing 3D perception. In particular, DepthAnything offers dense and reliable
geometric priors from monocular RGB images, which can complement sparse LiDAR
data in autonomous driving scenarios. However, such priors remain underutilized
in LiDAR-based 3D object detection. In this paper, we address the limited
expressiveness of raw LiDAR point features, especially the weak discriminative
capability of the reflectance attribute, by introducing depth priors predicted
by DepthAnything. These priors are fused with the original LiDAR attributes to
enrich each point's representation. To leverage the enhanced point features, we
propose a point-wise feature extraction module. Then, a Dual-Path RoI feature
extraction framework is employed, comprising a voxel-based branch for global
semantic context and a point-based branch for fine-grained structural details.
To effectively integrate the complementary RoI features, we introduce a
bidirectional gated RoI feature fusion module that balances global and local
cues. Extensive experiments on the KITTI benchmark show that our method
consistently improves detection accuracy, demonstrating the value of
incorporating visual foundation model priors into LiDAR-based 3D object
detection.

</details>


### [66] [TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views](https://arxiv.org/abs/2507.13929)
*Hsiang-Hui Hung,Huu-Phu Do,Yung-Hui Li,Ching-Chun Huang*

Main category: cs.CV

TL;DR: TimeNeRF 提出了一个能够在任意视角和时间点上生成新视图的通用神经渲染方法，特别适用于仅有少量输入视图的情况，并能实现日夜变化的平滑过渡渲染。


<details>
  <summary>Details</summary>
Motivation: 当前基于 NeRF 的技术虽然在生成新视图方面表现突出，但在时序3D场景建模方面探索较少，缺乏相关数据集，同时传统技术无法高效处理未见场景再优化的问题。

Method: 结合多视角立体、神经辐射场和分解策略，通过隐式内容辐射场建模场景表示，进而在任意时间点上建立神经辐射场并使用体素渲染生成新视图。

Result: 实验表明，TimeNeRF 在少量输入视图情况下，无需针对每个场景进行优化，即可渲染真实感强且具有时间平滑过渡的新视图，特别擅长捕捉复杂的自然场景变化。

Conclusion: TimeNeRF 提供了一种高效、通用且少样本适应的时序3D场景建模和渲染方法，为数字化沉浸式体验（如元宇宙）提供了重要技术支撑。

Abstract: We present TimeNeRF, a generalizable neural rendering approach for rendering
novel views at arbitrary viewpoints and at arbitrary times, even with few input
views. For real-world applications, it is expensive to collect multiple views
and inefficient to re-optimize for unseen scenes. Moreover, as the digital
realm, particularly the metaverse, strives for increasingly immersive
experiences, the ability to model 3D environments that naturally transition
between day and night becomes paramount. While current techniques based on
Neural Radiance Fields (NeRF) have shown remarkable proficiency in synthesizing
novel views, the exploration of NeRF's potential for temporal 3D scene modeling
remains limited, with no dedicated datasets available for this purpose. To this
end, our approach harnesses the strengths of multi-view stereo, neural radiance
fields, and disentanglement strategies across diverse datasets. This equips our
model with the capability for generalizability in a few-shot setting, allows us
to construct an implicit content radiance field for scene representation, and
further enables the building of neural radiance fields at any arbitrary time.
Finally, we synthesize novel views of that time via volume rendering.
Experiments show that TimeNeRF can render novel views in a few-shot setting
without per-scene optimization. Most notably, it excels in creating realistic
novel views that transition smoothly across different times, adeptly capturing
intricate natural scene changes from dawn to dusk.

</details>


### [67] [DiViD: Disentangled Video Diffusion for Static-Dynamic Factorization](https://arxiv.org/abs/2507.13934)
*Marzieh Gheisari,Auguste Genovesio*

Main category: cs.CV

TL;DR: DiViD是一个端到端视频扩散框架，解决了视频静态与动态信息解耦难题，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于VAE或GAN的方法通常面临信息泄露和重建质量模糊的问题，需要更有效的方法实现视频中静态外观和动态运动的解耦。

Method: 提出DiViD视频扩散框架，通过序列编码器提取静态和动态特征，并引入条件DDPM解码器结合共享噪声、时间变化的正则项，以及跨注意力机制以实现精确解耦。

Result: DiViD在真实世界基准下表现优异，在交换准确性和交叉泄露指标上领先，优于现有的序列解耦方法。

Conclusion: DiViD成功通过多种技术创新实现了静态与动态信息的高效解耦，为视频理解任务提供了新方案。

Abstract: Unsupervised disentanglement of static appearance and dynamic motion in video
remains a fundamental challenge, often hindered by information leakage and
blurry reconstructions in existing VAE- and GAN-based approaches. We introduce
DiViD, the first end-to-end video diffusion framework for explicit
static-dynamic factorization. DiViD's sequence encoder extracts a global static
token from the first frame and per-frame dynamic tokens, explicitly removing
static content from the motion code. Its conditional DDPM decoder incorporates
three key inductive biases: a shared-noise schedule for temporal consistency, a
time-varying KL-based bottleneck that tightens at early timesteps (compressing
static information) and relaxes later (enriching dynamics), and cross-attention
that routes the global static token to all frames while keeping dynamic tokens
frame-specific. An orthogonality regularizer further prevents residual
static-dynamic leakage. We evaluate DiViD on real-world benchmarks using
swap-based accuracy and cross-leakage metrics. DiViD outperforms
state-of-the-art sequential disentanglement methods: it achieves the highest
swap-based joint accuracy, preserves static fidelity while improving dynamic
transfer, and reduces average cross-leakage.

</details>


### [68] [Generalist Forecasting with Frozen Video Models via Latent Diffusion](https://arxiv.org/abs/2507.13942)
*Jacob C Walker,Pedro Vélez,Luisa Polania Cabrera,Guangyao Zhou,Rishabh Kabra,Carl Doersch,Maks Ovsjanikov,João Carreira,Shiry Ginosar*

Main category: cs.CV

TL;DR: 研究了一种面向一般性预测的模型框架，利用固定视觉骨干网训练潜在扩散模型进行特征预测，提出了一种一致性评估方法，并验证了视觉模型的感知能力与短期预测性能之间的强相关性。


<details>
  <summary>Details</summary>
Motivation: 探索视觉模型在不同抽象水平下的感知与预测关联，推动通用视频理解中的时间预测性能。

Method: 引入了一种基于冻结视觉骨干网的通用性预测框架，训练潜在扩散模型预测未来特征，并通过轻量化的特定任务读取器解码；提出了适用于不同任务的一致性评估分布指标。

Result: 验证了视觉模型的感知能力与短期预测性能间的强相关性，框架在9种模型和4种任务上进行了测试并取得了优异表现。

Conclusion: 将表示学习与生成建模结合有助于提高时序视频理解的能力。

Abstract: Forecasting what will happen next is a critical skill for general-purpose
systems that plan or act in the world at different levels of abstraction. In
this paper, we identify a strong correlation between a vision model's
perceptual ability and its generalist forecasting performance over short time
horizons. This trend holds across a diverse set of pretrained models-including
those trained generatively-and across multiple levels of abstraction, from raw
pixels to depth, point tracks, and object motion. The result is made possible
by a novel generalist forecasting framework that operates on any frozen vision
backbone: we train latent diffusion models to forecast future features in the
frozen representation space, which are then decoded via lightweight,
task-specific readouts. To enable consistent evaluation across tasks, we
introduce distributional metrics that compare distributional properties
directly in the space of downstream tasks and apply this framework to nine
models and four tasks. Our results highlight the value of bridging
representation learning and generative modeling for temporally grounded video
understanding.

</details>


### [69] [Evaluation of Human Visual Privacy Protection: A Three-Dimensional Framework and Benchmark Dataset](https://arxiv.org/abs/2507.13981)
*Sara Abdulaziz,Giacomo D'Amicantonio,Egor Bondarev*

Main category: cs.CV

TL;DR: 该论文提出了一个用于评估视觉隐私保护方法的框架，并引入了HR-VISPR数据集作为隐私度量训练工具，评估了现有11种方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI监控技术的发展，隐私问题受到关注，因此需要客观评估隐私保护的技术和方法。

Method: 提出了一个包含隐私、实用性和实际性三个维度的综合评估框架，并引入HR-VISPR数据集，用于训练解释性隐私度量，并对11种现有保护方法进行评估。

Result: 评估框架能够区分隐私保护等级，与人类视觉感知一致，同时揭示隐私与实用性、实用性的权衡。

Conclusion: 该框架及数据集为隐私保护评估提供了结构化支持，并适用于多种场景。

Abstract: Recent advances in AI-powered surveillance have intensified concerns over the
collection and processing of sensitive personal data. In response, research has
increasingly focused on privacy-by-design solutions, raising the need for
objective techniques to evaluate privacy protection. This paper presents a
comprehensive framework for evaluating visual privacy-protection methods across
three dimensions: privacy, utility, and practicality. In addition, it
introduces HR-VISPR, a publicly available human-centric dataset with biometric,
soft-biometric, and non-biometric labels to train an interpretable privacy
metric. We evaluate 11 privacy protection methods, ranging from conventional
techniques to advanced deep-learning methods, through the proposed framework.
The framework differentiates privacy levels in alignment with human visual
perception, while highlighting trade-offs between privacy, utility, and
practicality. This study, along with the HR-VISPR dataset, serves as an
insightful tool and offers a structured evaluation framework applicable across
diverse contexts.

</details>


### [70] [CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models](https://arxiv.org/abs/2507.13984)
*Quang-Binh Nguyen,Minh Luu,Quang Nguyen,Anh Tran,Khoi Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一种名为CSD-VAR的新方法，通过视觉自回归模型(VAR)框架实现单图像内容-风格分解（CSD），并证明了其在内容保存和风格化忠实度上的优越性。


<details>
  <summary>Details</summary>
Motivation: 解决单图像内容与风格的有效分离问题，使得视觉合成更加灵活和个性化。

Method: 提出了一种名为CSD-VAR的新方法，包括：（1）尺度感知的交替优化策略，用于增强内容和风格的分离；（2）基于SVD的修正方法，减少内容泄露到风格表示中的问题；（3）增强内容保存的键值存储机制。

Result: CSD-VAR在CSD-100基准数据集上的实验结果表明，其在内容保存和风格化忠实度方面优于现有方法。

Conclusion: 通过CSD-VAR，展示了 VAR 框架在内容-风格分解任务中的潜力，为视觉合成任务提供了新的解决方案，同时引入了高效的分解方法和数据集。

Abstract: Disentangling content and style from a single image, known as content-style
decomposition (CSD), enables recontextualization of extracted content and
stylization of extracted styles, offering greater creative flexibility in
visual synthesis. While recent personalization methods have explored the
decomposition of explicit content style, they remain tailored for diffusion
models. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a
promising alternative with a next-scale prediction paradigm, achieving
performance comparable to that of diffusion models. In this paper, we explore
VAR as a generative framework for CSD, leveraging its scale-wise generation
process for improved disentanglement. To this end, we propose CSD-VAR, a novel
method that introduces three key innovations: (1) a scale-aware alternating
optimization strategy that aligns content and style representation with their
respective scales to enhance separation, (2) an SVD-based rectification method
to mitigate content leakage into style representations, and (3) an Augmented
Key-Value (K-V) memory enhancing content identity preservation. To benchmark
this task, we introduce CSD-100, a dataset specifically designed for
content-style decomposition, featuring diverse subjects rendered in various
artistic styles. Experiments demonstrate that CSD-VAR outperforms prior
approaches, achieving superior content preservation and stylization fidelity.

</details>


### [71] [DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation](https://arxiv.org/abs/2507.13985)
*Haoran Li,Yuli Tian,Kun Lan,Yong Liao,Lin Wang,Pan Hui,Peng Yuan Zhou*

Main category: cs.CV

TL;DR: DreamScene是一种从文本生成高质量且可编辑的3D场景的端到端框架，其在质量、一致性和灵活性上优于现有方法，同时支持细粒度的场景编辑。


<details>
  <summary>Details</summary>
Motivation: 现有方法在自动化、3D一致性和精细控制方面表现不足，因此需要一个新的框架来克服这些局限性。

Method: DreamScene包括场景规划模块、基于图的布局算法、Formation Pattern Sampling (FPS) 多步采样与重建优化生成几何体、渐进式相机采样策略，并支持细粒度场景编辑。

Result: 实验表明，DreamScene的质量、一致性和灵活性优于现有方法，为开放领域的3D内容创建提供了实用的解决方案。

Conclusion: DreamScene成功实现了从自然语言生成高质量且可编辑的3D场景，同时提供了优越的灵活性和一致性，是3D内容创作的一种实用方法。

Abstract: Generating 3D scenes from natural language holds great promise for
applications in gaming, film, and design. However, existing methods struggle
with automation, 3D consistency, and fine-grained control. We present
DreamScene, an end-to-end framework for high-quality and editable 3D scene
generation from text or dialogue. DreamScene begins with a scene planning
module, where a GPT-4 agent infers object semantics and spatial constraints to
construct a hybrid graph. A graph-based placement algorithm then produces a
structured, collision-free layout. Based on this layout, Formation Pattern
Sampling (FPS) generates object geometry using multi-timestep sampling and
reconstructive optimization, enabling fast and realistic synthesis. To ensure
global consistent, DreamScene employs a progressive camera sampling strategy
tailored to both indoor and outdoor settings. Finally, the system supports
fine-grained scene editing, including object movement, appearance changes, and
4D dynamic motion. Experiments demonstrate that DreamScene surpasses prior
methods in quality, consistency, and flexibility, offering a practical solution
for open-domain 3D content creation. Code and demos are available at
https://dreamscene-project.github.io.

</details>


### [72] [Automatic Classification and Segmentation of Tunnel Cracks Based on Deep Learning and Visual Explanations](https://arxiv.org/abs/2507.14010)
*Yong Feng,Xiaolei Zhang,Shijin Feng,Yong Zhao,Yihan Chen*

Main category: cs.CV

TL;DR: 提出了一种两步深度学习方法，用于提高隧道裂缝检测的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 隧道衬砌裂缝是衡量隧道安全状态的核心指标，当前方法的精度和效率亟需提升。

Method: 采用DenseNet-169进行隧道图像分类，随后利用DeepLabV3+进行裂缝分割，并通过分数加权的可视化解释技术评估模型逻辑。

Result: 分类模型的精度为92.23%，每秒帧数为39.80，分割模型的IoU为57.01%，F1分数为67.44%，均优于现有方法。

Conclusion: 两步法结合了分类与分割，提供可视化解释，为隧道健康状态的快速准确评估奠定了基础。

Abstract: Tunnel lining crack is a crucial indicator of tunnels' safety status. Aiming
to classify and segment tunnel cracks with enhanced accuracy and efficiency,
this study proposes a two-step deep learning-based method. An automatic tunnel
image classification model is developed using the DenseNet-169 in the first
step. The proposed crack segmentation model in the second step is based on the
DeepLabV3+, whose internal logic is evaluated via a score-weighted visual
explanation technique. Proposed method combines tunnel image classification and
segmentation together, so that the selected images containing cracks from the
first step are segmented in the second step to improve the detection accuracy
and efficiency. The superior performances of the two-step method are validated
by experiments. The results show that the accuracy and frames per second (FPS)
of the tunnel crack classification model are 92.23% and 39.80, respectively,
which are higher than other convolutional neural networks (CNN) based and
Transformer based models. Also, the intersection over union (IoU) and F1 score
of the tunnel crack segmentation model are 57.01% and 67.44%, respectively,
outperforming other state-of-the-art models. Moreover, the provided visual
explanations in this study are conducive to understanding the "black box" of
deep learning-based models. The developed two-stage deep learning-based method
integrating visual explanations provides a basis for fast and accurate
quantitative assessment of tunnel health status.

</details>


### [73] [Analysis of Plant Nutrient Deficiencies Using Multi-Spectral Imaging and Optimized Segmentation Model](https://arxiv.org/abs/2507.14013)
*Ji-Yan Wu,Zheng Yong Poh,Anoop C. Patil,Bongsoo Park,Giovanni Volpe,Daisuke Urano*

Main category: cs.CV

TL;DR: 该研究提出利用多光谱成像和改进的YOLOv5模型进行植物叶片异常分割，检测营养缺乏的详细症状。


<details>
  <summary>Details</summary>
Motivation: 为改进精准农业的营养缺乏检测，从而实现施肥、病害与应激管理的早期干预。

Method: 提出一种基于深度学习的框架，使用改进的YOLOv5模型，结合变压器注意力头和彩谱成像技术，并引入自注意机制以捕获叶片上细微且分布广的症状。

Result: 实验显示改进模型在Dice分数和IoU上比原有YOLOv5基线模型提升约12%，并特别擅长检测如叶绿素缺失和色素积累等复杂症状。

Conclusion: 多光谱成像结合光谱-空间特征学习在植物表型分析与精准农业领域具有显著潜力。

Abstract: Accurate detection of nutrient deficiency in plant leaves is essential for
precision agriculture, enabling early intervention in fertilization, disease,
and stress management. This study presents a deep learning framework for leaf
anomaly segmentation using multispectral imaging and an enhanced YOLOv5 model
with a transformer-based attention head. The model is tailored for processing
nine-channel multispectral input and uses self-attention mechanisms to better
capture subtle, spatially-distributed symptoms. The plants in the experiments
were grown under controlled nutrient stress conditions for evaluation. We carry
out extensive experiments to benchmark the proposed model against the baseline
YOLOv5. Extensive experiments show that the proposed model significantly
outperforms the baseline YOLOv5, with an average Dice score and IoU
(Intersection over Union) improvement of about 12%. In particular, this model
is effective in detecting challenging symptoms like chlorosis and pigment
accumulation. These results highlight the promise of combining multi-spectral
imaging with spectral-spatial feature learning for advancing plant phenotyping
and precision agriculture.

</details>


### [74] [Moodifier: MLLM-Enhanced Emotion-Driven Image Editing](https://arxiv.org/abs/2507.14024)
*Jiarong Ye,Sharon X. Huang*

Main category: cs.CV

TL;DR: 本文提出了一种结合情感与视觉内容的方法，通过情感驱动的图像编辑来实现精确的情感表现，该解决方案包括情感数据集、视觉语言模型和编辑工具三部分。


<details>
  <summary>Details</summary>
Motivation: 在创意产业中，通过视觉内容表达情感具有吸引力，但由于情感的抽象性和跨场景多样性，精确编辑仍是难题。

Method: 本文提出三部分解决方案：包含丰富情感标注的8M+图片集MoodArchive；从情感转译为具体视觉属性的视觉语言模型MoodifyCLIP；以及用于精确情感编辑的工具Moodifier，结合了MoodifyCLIP和多模态大语言模型。

Result: 实验表明，与现有方法相比，Moodifier能够更优地实现情感准确性和内容保留，在角色表情、时尚设计等领域表现突出。

Conclusion: 通过将抽象情感与具体视觉变化相联系，该方法为情感内容创作提供了全新可能性，其数据集和工具将公开以方便实践。

Abstract: Bridging emotions and visual content for emotion-driven image editing holds
great potential in creative industries, yet precise manipulation remains
challenging due to the abstract nature of emotions and their varied
manifestations across different contexts. We tackle this challenge with an
integrated approach consisting of three complementary components. First, we
introduce MoodArchive, an 8M+ image dataset with detailed hierarchical
emotional annotations generated by LLaVA and partially validated by human
evaluators. Second, we develop MoodifyCLIP, a vision-language model fine-tuned
on MoodArchive to translate abstract emotions into specific visual attributes.
Third, we propose Moodifier, a training-free editing model leveraging
MoodifyCLIP and multimodal large language models (MLLMs) to enable precise
emotional transformations while preserving content integrity. Our system works
across diverse domains such as character expressions, fashion design, jewelry,
and home d\'ecor, enabling creators to quickly visualize emotional variations
while preserving identity and structure. Extensive experimental evaluations
show that Moodifier outperforms existing methods in both emotional accuracy and
content preservation, providing contextually appropriate edits. By linking
abstract emotions to concrete visual changes, our solution unlocks new
possibilities for emotional content creation in real-world applications. We
will release the MoodArchive dataset, MoodifyCLIP model, and make the Moodifier
code and demo publicly available upon acceptance.

</details>


### [75] [QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography](https://arxiv.org/abs/2507.14031)
*Hao Fang,Sihao Teng,Hao Yu,Siyi Yuan,Huaiwu He,Zhe Liu,Yunjie Yang*

Main category: cs.CV

TL;DR: 提出了一种名为QuantEIT的超轻量量子辅助推理框架，用于电阻抗断层成像（EIT）的图像重建。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习方法在EIT图像重建中表现出色，但由于复杂的网络架构和参数数量多，效率与可扩展性受到限制。

Method: 使用量子辅助网络(QA-Net)，结合平行二维量子电路生成隐式非线性先验表示，并通过单层线性层完成电导率重建，无需训练数据和监督学习。

Result: 在模拟与实际2D和3D EIT肺成像数据中表现优异，参数数仅为0.2%的情况下，达到媲美或优于传统方法的重建精度，并表现出更强的抗噪性。

Conclusion: QuantEIT实现了EIT图像重建效率、精度与抗噪性的新突破，是首次将量子电路引入EIT重建的尝试。

Abstract: Electrical Impedance Tomography (EIT) is a non-invasive, low-cost bedside
imaging modality with high temporal resolution, making it suitable for bedside
monitoring. However, its inherently ill-posed inverse problem poses significant
challenges for accurate image reconstruction. Deep learning (DL)-based
approaches have shown promise but often rely on complex network architectures
with a large number of parameters, limiting efficiency and scalability. Here,
we propose an Ultra-Lightweight Quantum-Assisted Inference (QuantEIT) framework
for EIT image reconstruction. QuantEIT leverages a Quantum-Assisted Network
(QA-Net), combining parallel 2-qubit quantum circuits to generate expressive
latent representations that serve as implicit nonlinear priors, followed by a
single linear layer for conductivity reconstruction. This design drastically
reduces model complexity and parameter number. Uniquely, QuantEIT operates in
an unsupervised, training-data-free manner and represents the first integration
of quantum circuits into EIT image reconstruction. Extensive experiments on
simulated and real-world 2D and 3D EIT lung imaging data demonstrate that
QuantEIT outperforms conventional methods, achieving comparable or superior
reconstruction accuracy using only 0.2% of the parameters, with enhanced
robustness to noise.

</details>


### [76] [Training-free Token Reduction for Vision Mamba](https://arxiv.org/abs/2507.14042)
*Qiankun Ma,Ziyao Zhang,Chi Su,Jie Chen,Zhen Song,Hairong Zheng,Wen Gao*

Main category: cs.CV

TL;DR: 论文提出了一种名为MTR的训练无关Mamba Token Reduction框架，用于提高Vision Mamba模型的效率，同时仅带来轻微性能下降。


<details>
  <summary>Details</summary>
Motivation: 探讨Vision Mamba的效率，解决现有ViTs token reduction技术直接应用导致性能下降的问题。

Method: 通过提出Mamba结构感知的重要性分数评估Token重要性，进而设计出MTR框架实现无需训练的Token压缩方法。

Result: MTR框架显著减少计算量，减少约40%的FLOPs，而性能下降仅为1.6%，无需重新训练。

Conclusion: MTR框架能够有效作为插件应用于各种Mamba模型，实现高效Token压缩的同时最大限度保证性能。

Abstract: Vision Mamba has emerged as a strong competitor to Vision Transformers (ViTs)
due to its ability to efficiently capture long-range dependencies with linear
computational complexity. While token reduction, an effective compression
technique in ViTs, has rarely been explored in Vision Mamba. Exploring Vision
Mamba's efficiency is essential for enabling broader applications. However, we
find that directly applying existing token reduction techniques for ViTs to
Vision Mamba leads to significant performance degradation. This is primarily
because Mamba is a sequence model without attention mechanisms, whereas most
token reduction techniques for ViTs rely on attention mechanisms for importance
measurement and overlook the order of compressed tokens. In this paper, we
investigate a Mamba structure-aware importance score to evaluate token
importance in a simple and effective manner. Building on this score, we further
propose MTR, a training-free \textbf{M}amba \textbf{T}oken \textbf{R}eduction
framework. Without the need for training or additional tuning parameters, our
method can be seamlessly integrated as a plug-and-play component across various
Mamba models. Extensive experiments demonstrate that our approach significantly
reduces computational workload while minimizing performance impact across
various tasks and multiple backbones. Notably, MTR reduces FLOPs by
approximately 40\% on the Vim-B backbone, with only a 1.6\% drop in ImageNet
performance without retraining.

</details>


### [77] [Foundation Models as Class-Incremental Learners for Dermatological Image Classification](https://arxiv.org/abs/2507.14050)
*Mohamed Elkhayat,Mohamed Mahmoud,Jamil Fayyad,Nourhan Bayasi*

Main category: cs.CV

TL;DR: 本文研究了在皮肤病分类中的增量学习问题，利用预训练的大规模数据集的基础模型（FM），提出了一种简单有效的增量学习方法，同时实现了高性能和遗忘最小化。


<details>
  <summary>Details</summary>
Motivation: 增量学习面临如何在加入新类别时减少遗忘旧知识的挑战，而基础模型的转移能力提供了新的解决方案，尤其在医学领域的应用尚待探索。

Method: 采用冻结预训练的基础模型作为特征提取器，结合轻量级MLP进行任务增量学习，同时使用原型基的最近均值分类器探索零训练场景的能力。

Result: 提出的方法在皮肤病分类任务中实现了当前最优性能，超越了正则化、重放及基于架构的方法，并通过消融实验验证了基于原型的方法的竞争性表现。

Conclusion: 本文证明了冻结的基础模型在医学增量学习中的潜力，为实际医学应用提供了支持，同时代码和数据集公开以促进进一步研究。

Abstract: Class-Incremental Learning (CIL) aims to learn new classes over time without
forgetting previously acquired knowledge. The emergence of foundation models
(FM) pretrained on large datasets presents new opportunities for CIL by
offering rich, transferable representations. However, their potential for
enabling incremental learning in dermatology remains largely unexplored. In
this paper, we systematically evaluate frozen FMs pretrained on large-scale
skin lesion datasets for CIL in dermatological disease classification. We
propose a simple yet effective approach where the backbone remains frozen, and
a lightweight MLP is trained incrementally for each task. This setup achieves
state-of-the-art performance without forgetting, outperforming regularization,
replay, and architecture based methods. To further explore the capabilities of
frozen FMs, we examine zero training scenarios using nearest mean classifiers
with prototypes derived from their embeddings. Through extensive ablation
studies, we demonstrate that this prototype based variant can also achieve
competitive results. Our findings highlight the strength of frozen FMs for
continual learning in dermatology and support their broader adoption in real
world medical applications. Our code and datasets are available here.

</details>


### [78] [VLA-Mark: A cross modal watermark for large vision-language alignment model](https://arxiv.org/abs/2507.14067)
*Shuliang Liu,Qi Zheng,Jesse Jiaxi Xu,Yibo Yan,He Geng,Aiwei Liu,Peijie Jiang,Jia Liu,Yik-Cheung Tam,Xuming Hu*

Main category: cs.CV

TL;DR: 該論文提出VLA-Mark，一種維持語意和多模態一致性的視覺語言模型水印框架，兼顧語意保真性及辨識準確性。


<details>
  <summary>Details</summary>
Motivation: 當前視覺語言模型缺乏有效的水印方案，現有方法會破壞多模態一致性及語意關鍵概念的完整性。

Method: 設計了VLA-Mark框架，結合多尺度視覺-文本對齊指標（局部片段關聯性、全局語義一致性、上下文注意力模式），並使用動態熵感應機制在水印強度和語意保存之間平衡，無需對模型進行重訓練。

Result: 實驗顯示VLA-Mark方法在PPL指標上降低了7.4%，在BLEU指標上提升了26.6%；水印檢測AUC達到98.8%，並具有96.1%的對抗攻擊抗性。

Conclusion: VLA-Mark不僅能嵌入可檢測水印，還能在不損害語意及多模態一致性的情況下，對抗各類攻擊，為多模態水印樹立了新標準。

Abstract: Vision-language models demand watermarking solutions that protect
intellectual property without compromising multimodal coherence. Existing text
watermarking methods disrupt visual-textual alignment through biased token
selection and static strategies, leaving semantic-critical concepts vulnerable.
We propose VLA-Mark, a vision-aligned framework that embeds detectable
watermarks while preserving semantic fidelity through cross-modal coordination.
Our approach integrates multiscale visual-textual alignment metrics, combining
localized patch affinity, global semantic coherence, and contextual attention
patterns, to guide watermark injection without model retraining. An
entropy-sensitive mechanism dynamically balances watermark strength and
semantic preservation, prioritizing visual grounding during low-uncertainty
generation phases. Experiments show 7.4% lower PPL and 26.6% higher BLEU than
conventional methods, with near-perfect detection (98.8% AUC). The framework
demonstrates 96.1\% attack resilience against attacks such as paraphrasing and
synonym substitution, while maintaining text-visual consistency, establishing
new standards for quality-preserving multimodal watermarking

</details>


### [79] [Unmasking Performance Gaps: A Comparative Study of Human Anonymization and Its Effects on Video Anomaly Detection](https://arxiv.org/abs/2507.14083)
*Sara Abdulaziz,Egor Bondarev*

Main category: cs.CV

TL;DR: 本研究分析了人类匿名化技术对异常检测性能的影响，表明在保留隐私数据的同时异常检测仍可行，但性能因算法设计和学习策略而异。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习在异常检测中的应用日益广泛，隐私问题变得不可忽视。本研究的动机是评估不同匿名化技术对异常检测方法性能的影响，探索隐私保护和检测性能之间的平衡。

Method: 通过对名为UCF-Crime的数据集施加模糊化、遮罩、加密和替换为虚拟形象四种匿名化技术，然后评估MGFN、UR-DMU、BN-WVAD和PEL4VAD四种异常检测方法的性能表现。

Result: 实验结果显示，在一定匿名化模式如加密和遮罩下，有些模型比原始数据还表现出更高的性能（AUC），证明算法组件对噪声模式的敏感性不同。

Conclusion: 算法设计对匿名化技术的敏感性决定性能，同时隐私保护和异常检测效用之间存在权衡。还需考量新兴隐私设计方案与传统方案的差异，本研究为隐私和异常检测效用权衡提供了重要的基准与洞见。

Abstract: Advancements in deep learning have improved anomaly detection in surveillance
videos, yet they raise urgent privacy concerns due to the collection of
sensitive human data. In this paper, we present a comprehensive analysis of
anomaly detection performance under four human anonymization techniques,
including blurring, masking, encryption, and avatar replacement, applied to the
UCF-Crime dataset. We evaluate four anomaly detection methods, MGFN, UR-DMU,
BN-WVAD, and PEL4VAD, on the anonymized UCF-Crime to reveal how each method
responds to different obfuscation techniques. Experimental results demonstrate
that anomaly detection remains viable under anonymized data and is dependent on
the algorithmic design and the learning strategy. For instance, under certain
anonymization patterns, such as encryption and masking, some models
inadvertently achieve higher AUC performance compared to raw data, due to the
strong responsiveness of their algorithmic components to these noise patterns.
These results highlight the algorithm-specific sensitivities to anonymization
and emphasize the trade-off between preserving privacy and maintaining
detection utility. Furthermore, we compare these conventional anonymization
techniques with the emerging privacy-by-design solutions, highlighting an often
overlooked trade-off between robust privacy protection and utility flexibility.
Through comprehensive experiments and analyses, this study provides a
compelling benchmark and insights into balancing human privacy with the demands
of anomaly detection.

</details>


### [80] [Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment](https://arxiv.org/abs/2507.14093)
*Šimon Kubov,Simon Klíčník,Jakub Dandár,Zdeněk Straka,Karolína Kvaková,Daniel Kvak*

Main category: cs.CV

TL;DR: 本研究使用深度学习软件评估脊柱侧弯的Cobb角测量，其结果与专家手工测量高度一致，显示其临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 脊柱侧弯在青少年中具有较高发病率（2%-4%），Cobb角测量是关键的诊断和治疗决策依据，然而手工测量耗时且存在观察者间差异。

Method: 研究使用回顾性、多中心方法，评估自动化深度学习软件（Carebot AI Bones）对103张脊柱正位X光片的表现，与两名肌肉骨骼放射科医生的手工测量结果进行对比分析。

Result: AI软件相较两名放射科医生的平均绝对误差分别为3.89°和3.90°，具有高度的 Pearson 相关性（r=0.906，r=0.880）以及一致性（Cohen kappa=0.51 和0.64）。

Conclusion: 深度学习软件能够在多中心数据中复现专家级Cobb角测量，具有潜在价值以优化脊柱侧弯的临床报告和分诊工作流程。

Abstract: Scoliosis affects roughly 2 to 4 percent of adolescents, and treatment
decisions depend on precise Cobb angle measurement. Manual assessment is time
consuming and subject to inter observer variation. We conducted a
retrospective, multi centre evaluation of a fully automated deep learning
software (Carebot AI Bones, Spine Measurement functionality; Carebot s.r.o.) on
103 standing anteroposterior whole spine radiographs collected from ten
hospitals. Two musculoskeletal radiologists independently measured each study
and served as reference readers. Agreement between the AI and each radiologist
was assessed with Bland Altman analysis, mean absolute error (MAE), root mean
squared error (RMSE), Pearson correlation coefficient, and Cohen kappa for four
grade severity classification. Against Radiologist 1 the AI achieved an MAE of
3.89 degrees (RMSE 4.77 degrees) with a bias of 0.70 degrees and limits of
agreement from minus 8.59 to plus 9.99 degrees. Against Radiologist 2 the AI
achieved an MAE of 3.90 degrees (RMSE 5.68 degrees) with a bias of 2.14 degrees
and limits from minus 8.23 to plus 12.50 degrees. Pearson correlations were r
equals 0.906 and r equals 0.880 (inter reader r equals 0.928), while Cohen
kappa for severity grading reached 0.51 and 0.64 (inter reader kappa 0.59).
These results demonstrate that the proposed software reproduces expert level
Cobb angle measurements and categorical grading across multiple centres,
suggesting its utility for streamlining scoliosis reporting and triage in
clinical workflows.

</details>


### [81] [C-DOG: Training-Free Multi-View Multi-Object Association in Dense Scenes Without Visual Feature via Connected δ-Overlap Graphs](https://arxiv.org/abs/2507.14095)
*Yung-Hong Sun,Ting-Hung Lin,Jiangang Chen,Hongrui Jiang,Yu Hen Hu*

Main category: cs.CV

TL;DR: 提出了一种名为C-DOG的训练无关方法，通过结合delta-overlap图建模与极线几何实现跨多视角检测的鲁棒关联。


<details>
  <summary>Details</summary>
Motivation: 现有多视角多对象关联方法对外观特征或几何约束的依赖不足以应对视觉不可区分的对象或有噪声的观测现象。

Method: 使用连接delta-overlap图（表示节点为2D观测，边权重为极线一致性）并通过IQR过滤与3D回投影误差排除不一致的观测，进行鲁棒的多视角检测关联。

Result: 在合成基准实验中，C-DOG性能优于几何为基础的基线方法，能在高密度对象、无视觉特征及有限视角重叠等条件下保持鲁棒性。

Conclusion: C-DOG方法适用于在复杂实际场景实现可扩展的3D重构。

Abstract: Multi-view multi-object association is a fundamental step in 3D
reconstruction pipelines, enabling consistent grouping of object instances
across multiple camera views. Existing methods often rely on appearance
features or geometric constraints such as epipolar consistency. However, these
approaches can fail when objects are visually indistinguishable or observations
are corrupted by noise. We propose C-DOG, a training-free framework that serves
as an intermediate module bridging object detection (or pose estimation) and 3D
reconstruction, without relying on visual features. It combines connected
delta-overlap graph modeling with epipolar geometry to robustly associate
detections across views. Each 2D observation is represented as a graph node,
with edges weighted by epipolar consistency. A delta-neighbor-overlap
clustering step identifies strongly consistent groups while tolerating noise
and partial connectivity. To further improve robustness, we incorporate
Interquartile Range (IQR)-based filtering and a 3D back-projection error
criterion to eliminate inconsistent observations. Extensive experiments on
synthetic benchmarks demonstrate that C-DOG outperforms geometry-based
baselines and remains robust under challenging conditions, including high
object density, without visual features, and limited camera overlap, making it
well-suited for scalable 3D reconstruction in real-world scenarios.

</details>


### [82] [Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning](https://arxiv.org/abs/2507.14137)
*Shashanka Venkataramanan,Valentinos Pariza,Mohammadreza Salehi,Lukas Knobel,Spyros Gidaris,Elias Ramzi,Andrei Bursuc,Yuki M. Asano*

Main category: cs.CV

TL;DR: 本文介绍了Franca，这是首个完全开源（包括数据、代码和权重）的视觉基础模型，其性能匹敌或超越了当前的专有模型如DINOv2、CLIP等。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在创造一个高性能且完全透明的视觉基础模型，以应对现有专有模型难以复现和验证的问题。

Method: 采用基于Web-SSL的透明训练流程，利用公开数据集（ImageNet-21K和ReLAION-2B子集）；引入多头聚类投影器和位置解耦策略以优化模型性能。

Result: 所提出的模型不仅保持了高性能，还在内存效率上有所提升，并在多个下游基准测试中实现了性能改进。

Conclusion: Franca树立了透明、高性能视觉模型的新标准，为更具可复现性和通用性的基础模型研究打开了新路径。

Abstract: We present Franca (pronounced Fran-ka): free one; the first fully open-source
(data, code, weights) vision foundation model that matches and in many cases
surpasses the performance of state-of-the-art proprietary models, e.g., DINOv2,
CLIP, SigLIPv2, etc. Our approach is grounded in a transparent training
pipeline inspired by Web-SSL and uses publicly available data: ImageNet-21K and
a subset of ReLAION-2B. Beyond model release, we tackle critical limitations in
SSL clustering methods. While modern models rely on assigning image features to
large codebooks via clustering algorithms like Sinkhorn-Knopp, they fail to
account for the inherent ambiguity in clustering semantics. To address this, we
introduce a parameter-efficient, multi-head clustering projector based on
nested Matryoshka representations. This design progressively refines features
into increasingly fine-grained clusters without increasing the model size,
enabling both performance and memory efficiency. Additionally, we propose a
novel positional disentanglement strategy that explicitly removes positional
biases from dense representations, thereby improving the encoding of semantic
content. This leads to consistent gains on several downstream benchmarks,
demonstrating the utility of cleaner feature spaces. Our contributions
establish a new standard for transparent, high-performance vision models and
open a path toward more reproducible and generalizable foundation models for
the broader AI community. The code and model checkpoints are available at
https://github.com/valeoai/Franca.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [83] [Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models](https://arxiv.org/abs/2507.13357)
*Atharva Bhargude,Ishan Gonehal,Chandler Haney,Dave Yoon,Kevin Zhu,Aaron Sandoval,Sean O'Brien,Kaustubh Vinnakota*

Main category: cs.CL

TL;DR: 本研究提出一种名为ALP的少样本自适应语义提示技术，通过结合文本、视觉和URL分析，改进LLM在钓鱼攻击检测中的表现，取得0.93的F1-score。


<details>
  <summary>Details</summary>
Motivation: 现有方法在检测复杂钓鱼攻击方面存在不足，因此需要开发更自适应和准确的检测技术。

Method: 提出了ALP技术，利用LLM的多模态能力，通过分析语言模式、紧迫性提示和操控性用语特征进行语义分解，并结合文本、视觉和URL多重分析实现检测。

Result: 实验结果表明，ALP显著提升了钓鱼检测的准确性，F1-score达0.93，优于传统方法。

Conclusion: ALP技术展示了整合多模态LLM以实现强大、可解释且自适应检测系统的潜力，为钓鱼检测提供了新的基础框架。

Abstract: Phishing attacks represent a significant cybersecurity threat, necessitating
adaptive detection techniques. This study explores few-shot Adaptive Linguistic
Prompting (ALP) in detecting phishing webpages through the multimodal
capabilities of state-of-the-art large language models (LLMs) such as GPT-4o
and Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides
LLMs to analyze textual deception by breaking down linguistic patterns,
detecting urgency cues, and identifying manipulative diction commonly found in
phishing content. By integrating textual, visual, and URL-based analysis, we
propose a unified model capable of identifying sophisticated phishing attempts.
Our experiments demonstrate that ALP significantly enhances phishing detection
accuracy by guiding LLMs through structured reasoning and contextual analysis.
The findings highlight the potential of ALP-integrated multimodal LLMs to
advance phishing detection frameworks, achieving an F1-score of 0.93,
surpassing traditional approaches. These results establish a foundation for
more robust, interpretable, and adaptive linguistic-based phishing detection
systems using LLMs.

</details>


### [84] [Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition](https://arxiv.org/abs/2507.13380)
*Keito Inoshita,Rushia Harada*

Main category: cs.CL

TL;DR: 一种解决情感识别领域高质量情感数据稀缺问题的新方法。


<details>
  <summary>Details</summary>
Motivation: 情感表达具有主观性，受个人性格、社会文化背景和情境因素影响，难以规模化地收集广泛适用的数据。

Method: 提出PersonaGen框架，通过多阶段基于人格特质的条件生成模型，利用大语言模型生成情感丰富的文本数据。

Result: 实验表明，PersonaGen在生成多样性、高一致性和具有辨别性的情感表达方面明显优于基线方法。

Conclusion: PersonaGen可作为增强或替代实际情感数据集的强大工具。

Abstract: In the field of emotion recognition, the development of high-performance
models remains a challenge due to the scarcity of high-quality, diverse
emotional datasets. Emotional expressions are inherently subjective, shaped by
individual personality traits, socio-cultural backgrounds, and contextual
factors, making large-scale, generalizable data collection both ethically and
practically difficult. To address this issue, we introduce PersonaGen, a novel
framework for generating emotionally rich text using a Large Language Model
(LLM) through multi-stage persona-based conditioning. PersonaGen constructs
layered virtual personas by combining demographic attributes, socio-cultural
backgrounds, and detailed situational contexts, which are then used to guide
emotion expression generation. We conduct comprehensive evaluations of the
generated synthetic data, assessing semantic diversity through clustering and
distributional metrics, human-likeness via LLM-based quality scoring, realism
through comparison with real-world emotion corpora, and practical utility in
downstream emotion classification tasks. Experimental results show that
PersonaGen significantly outperforms baseline methods in generating diverse,
coherent, and discriminative emotion expressions, demonstrating its potential
as a robust alternative for augmenting or replacing real-world emotional
datasets.

</details>


### [85] [SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation](https://arxiv.org/abs/2507.13381)
*Rafiq Kamel,Filippo Guerranti,Simon Geisler,Stephan Günnemann*

Main category: cs.CL

TL;DR: 本研究提出了一种名为SAFT的结构感知微调方法，提升了大型语言模型(LLMs)在处理图结构数据（如AMR到文本生成）中的表现，实现了新的性能突破。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理抽象意义表示(AMRs)等图结构输入时要么简单线性化，丢失结构信息，要么使用与现有LLMs不兼容的架构。研究动机是开发一种无需改变模型架构的图结构感知方法。

Method: 提出的SAFT方法通过从变换后的AMRs计算磁拉普拉斯方向敏感位置编码，并将其投影到LLM的嵌入空间中，向LLM注入图的拓扑结构信息。模型以AMR到文本生成作为主要试验基准。

Result: SAFT方法在AMR 3.0数据集上的BLEU分数相比基线提升了3.5分，尤其在图结构复杂性提高的情况下表现更优。

Conclusion: SAFT为连接结构化数据与语言模型提供了一种通用且高效的解决方案，表明结构感知表示在提升LLM性能中的重要性。

Abstract: Large Language Models (LLMs) are increasingly applied to tasks involving
structured inputs such as graphs. Abstract Meaning Representations (AMRs),
which encode rich semantics as directed graphs, offer a rigorous testbed for
evaluating LLMs on text generation from such structures. Yet, current methods
often arbitrarily linearize AMRs, discarding key structural cues, or rely on
architectures incompatible with standard LLMs. We introduce SAFT, a
structure-aware fine-tuning approach that injects graph topology into
pretrained LLMs without architectural changes. We compute direction-sensitive
positional encodings from the magnetic Laplacian of transformed AMRs and
project them into the embedding space of the LLM. While possibly applicable to
any graph-structured inputs, we focus on AMR-to-text generation as a
representative and challenging benchmark. SAFT sets a new state-of-the-art on
AMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph
complexity, highlighting the value of structure-aware representations in
enhancing LLM performance. SAFT offers a general and effective pathway for
bridging structured data and language models.

</details>


### [86] [Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case](https://arxiv.org/abs/2507.13382)
*Chandrashekar Muniyappa,Sirisha Velampalli*

Main category: cs.CL

TL;DR: 研究提出了一种基于图的创新方法来检测假新闻。


<details>
  <summary>Details</summary>
Motivation: 在数字时代，假新闻传播迅速且影响巨大，亟需有效的解决方案。

Method: 利用自然语言处理技术将新闻文章转换为上下文图结构，应用基于最小描述长度（MDL）的图异常检测算法。

Result: 该方法可以发现数据集中普通模式，并识别出偏离这些模式的异常模式。

Conclusion: 基于图的方法能够很好地处理丰富的上下文数据，在假新闻检测领域展示出良好潜力。

Abstract: In today\'s digital world, fake news is spreading with immense speed. Its a
significant concern to address. In this work, we addressed that challenge using
novel graph based approach. We took dataset from Kaggle that contains real and
fake news articles. To test our approach we incorporated recent covid-19
related news articles that contains both genuine and fake news that are
relevant to this problem. This further enhances the dataset as well instead of
relying completely on the original dataset. We propose a contextual graph-based
approach to detect fake news articles. We need to convert news articles into
appropriate schema, so we leverage Natural Language Processing (NLP) techniques
to transform news articles into contextual graph structures. We then apply the
Minimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)
algorithm for graph mining. Graph-based methods are particularly effective for
handling rich contextual data, as they enable the discovery of complex patterns
that traditional query-based or statistical techniques might overlook. Our
proposed approach identifies normative patterns within the dataset and
subsequently uncovers anomalous patterns that deviate from these established
norms.

</details>


### [87] [PARAM-1 BharatGen 2.9B Model](https://arxiv.org/abs/2507.13390)
*Kundeshwar Pundalik,Piyush Sawarkar,Nihar Sahoo,Abhishek Shinde,Prateek Chanda,Vedant Goswami,Ajay Nagpal,Atul Singh,Viraj Thakur,Vijay Dewane,Aamod Thakur,Bhargav Patel,Smita Gautam,Bhagwan Panditi,Shyam Pawar,Madhav Kotcha,Suraj Racha,Saral Sureka,Pankaj Singh,Rishi Bal,Rohit Saluja,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 提出了PARAM-1，一种专注于印度语言多样性的2.9B语言模型，旨在实现公平且代表性的基础模型。


<details>
  <summary>Details</summary>
Motivation: 克服大语言模型在印度语言和文化多样性上的结构性欠代表问题。

Method: 设计并训练了一个只限印度文化和语言的双语数据集（印地语和英语），结合SentencePiece分词器以及文化对齐基准测试，以实现多样性预训练。

Result: PARAM-1展示出作为一般用途模型的能力，同时在印度语境相关应用中表现突出。

Conclusion: 在预训练阶段实现语言和文化多样性嵌入，为公平的语言模型提供了设计驱动的范例。

Abstract: Large Language Models (LLMs) have emerged as powerful general-purpose
reasoning systems, yet their development remains dominated by English-centric
data, architectures, and optimization paradigms. This exclusionary design
results in structural under-representation of linguistically diverse regions
such as India, where over 20 official languages and 100+ dialects coexist
alongside phenomena like code-switching and diglossia. We introduce PARAM-1, a
2.9B parameter decoder-only, text-only language model trained from scratch with
an explicit architectural and linguistic focus on Indian diversity. PARAM-1 is
trained on a bilingual dataset consisting of only Hindi and English,
constructed with a strong focus on fact-rich, high-quality content. It is
guided by three core principles: equitable representation of Indic languages
through a 25% corpus allocation; tokenization fairness via a SentencePiece
tokenizer adapted to Indian morphological structures; and culturally aligned
evaluation benchmarks across IndicQA, code-mixed reasoning, and
socio-linguistic robustness tasks. By embedding diversity at the pretraining
level-rather than deferring it to post-hoc alignment-PARAM-1 offers a
design-first blueprint for equitable foundation modeling. Our results
demonstrate that it serves as both a competent general-purpose model and a
robust baseline for India-centric applications.

</details>


### [88] [TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction](https://arxiv.org/abs/2507.13392)
*Emil Häglund,Johanna Björklund*

Main category: cs.CL

TL;DR: 提出了一种改进的主题建模流程，通过对客户评论中的意见单元（包括文本摘要和相关情感评分）进行操作，提高了主题模型的性能。


<details>
  <summary>Details</summary>
Motivation: 改进现有主题建模方法，提升对顾客评论的洞察提取能力，同时捕获主题相关的情感。

Method: 通过使用大型语言模型提取意见单元，对主题建模流程进行重组，并结合这些单元的情感得分来生成可解释的主题。

Result: 生成的主题更加连贯且易于解释，并且能够根据主题情感与商业指标（如星级评分）的相关性提供分析洞察。

Conclusion: 该系统比传统主题建模具有更大的优势，能够更有效地进行主题预测、星级评分预测并提供实际商业见解。

Abstract: We improve the extraction of insights from customer reviews by restructuring
the topic modelling pipeline to operate on opinion units - distinct statements
that include relevant text excerpts and associated sentiment scores. Prior work
has demonstrated that such units can be reliably extracted using large language
models. The result is a heightened performance of the subsequent topic
modeling, leading to coherent and interpretable topics while also capturing the
sentiment associated with each topic. By correlating the topics and sentiments
with business metrics, such as star ratings, we can gain insights on how
specific customer concerns impact business outcomes. We present our system's
implementation, use cases, and advantages over other topic modeling and
classification solutions. We also evaluate its effectiveness in creating
coherent topics and assess methods for integrating topic and sentiment
modalities for accurate star-rating prediction.

</details>


### [89] [Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only](https://arxiv.org/abs/2507.13395)
*Xuanqi Gao,Weipeng Jiang,Juan Zhai,Shiqing Ma,Siyi Xie,Xinyang Yin,Chao Shen*

Main category: cs.CL

TL;DR: 提出Babel框架，通过单语语料提高NMT系统的风格保真度，无需并行语料。


<details>
  <summary>Details</summary>
Motivation: 目前的NMT系统难以在保留语义的同时，准确传达源文本风格。

Method: Babel框架包含两个主要组件：（1）基于上下文嵌入的风格检测器，用于识别源文本和目标文本之间的风格差异；（2）基于扩散的风格调整器，用于纠正风格不一致的问题，同时保持语义完整性。

Result: Babel框架在五个不同领域的实验中表现出色：识别风格不一致的准确率达到88.21%，风格保留效果提升150%，语义相似度得分为0.92。

Conclusion: Babel框架显著提高了NMT的风格保真度，同时保持翻译结果的流畅性和语义完整性。

Abstract: The advent of neural machine translation (NMT) has revolutionized
cross-lingual communication, yet preserving stylistic nuances remains a
significant challenge. While existing approaches often require parallel corpora
for style preservation, we introduce Babel, a novel framework that enhances
stylistic fidelity in NMT using only monolingual corpora. Babel employs two key
components: (1) a style detector based on contextual embeddings that identifies
stylistic disparities between source and target texts, and (2) a
diffusion-based style applicator that rectifies stylistic inconsistencies while
maintaining semantic integrity. Our framework integrates with existing NMT
systems as a post-processing module, enabling style-aware translation without
requiring architectural modifications or parallel stylistic data. Extensive
experiments on five diverse domains (law, literature, scientific writing,
medicine, and educational content) demonstrate Babel's effectiveness: it
identifies stylistic inconsistencies with 88.21% precision and improves
stylistic preservation by 150% while maintaining a high semantic similarity
score of 0.92. Human evaluation confirms that translations refined by Babel
better preserve source text style while maintaining fluency and adequacy.

</details>


### [90] [Causal Language Control in Multilingual Transformers via Sparse Feature Steering](https://arxiv.org/abs/2507.13410)
*Cheng-Ting Chou,George Liu,Jessica Sun,Cole Blondin,Kevin Zhu,Vasu Sharma,Sean O'Brien*

Main category: cs.CL

TL;DR: 本研究探讨了如何使用稀疏自动编码器模拟器（SAE）特征在LLMs推理过程中控制语言生成，实验中修改了一层中特定特征，实现了精准的语言转换。


<details>
  <summary>Details</summary>
Motivation: 当前多语言大模型在零样本环境下的目标语言控制存在重大挑战，研究意图通过SAE特征来缓解这一问题。

Method: 采用预训练的SAE模型对Gemma-2B与Gemma-9B残差流中的语言特定特征进行改动，专注于中后期Transformer层偏语言敏感的特定注意力头。

Result: 通过在单个Transformer层中修改一个SAE特征，成功实现了目标语言转化，达到了90%的精准率，同时语义一致性基本得以保持。

Conclusion: 稀疏特征控制为多语言生成任务提供了一种轻量且可解释的控制机制，展现出其潜力。

Abstract: Deterministically controlling the target generation language of large
multilingual language models (LLMs) remains a fundamental challenge,
particularly in zero-shot settings where neither explicit language prompts nor
fine-tuning are available. In this work, we investigate whether sparse
autoencoder (SAE) features, previously shown to correlate with interpretable
model behaviors, can be leveraged to steer the generated language of LLMs
during inference. Leveraging pretrained SAEs on the residual streams of
Gemma-2B and Gemma-9B, we identify features whose activations differ most
significantly between English and four target languages: Chinese, Japanese,
Spanish, and French. By modifying just a single SAE feature at one transformer
layer, we achieve controlled language shifts with up to 90\% success, as
measured by FastText language classification, while preserving semantic
fidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding)
similarity. Our analysis reveals that language steering is most effective in
mid-to-late transformer layers and is amplified by specific attention heads
disproportionately associated with language-sensitive SAE features. These
results demonstrate the promise of sparse feature steering as a lightweight and
interpretable mechanism for controllable multilingual generation.

</details>


### [91] [Aligning Knowledge Graphs and Language Models for Factual Accuracy](https://arxiv.org/abs/2507.13411)
*Nur A Zarin Nishat,Andrea Coletta,Luigi Bellomarini,Kossi Amouzouvi,Jens Lehmann,Sahar Vahdati*

Main category: cs.CL

TL;DR: 本文提出ALIGNed-LLM，将知识图谱嵌入整合到语言模型的潜在空间，用于增强模型的事实性和减少幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 应对大模型幻觉问题，结合知识图谱提供结构化和可靠的信息以增强模型性能。

Method: 利用预训练知识图谱嵌入模型和可训练投影层对实体与文本嵌入进行对齐，从而提升大模型内容的事实性。

Result: 在三个问答基准数据集上取得显著改进，并在欧洲某中央银行的实际金融案例中提高了LLM的准确性和精度。

Conclusion: 通过ALIGNed-LLM策略有效地整合知识图谱，强化语言模型的真实性和减少幻觉，显示了其在通用任务和实际场景中的应用潜力。

Abstract: Large language models like GPT-4, Gemini, and Claude have transformed natural
language processing (NLP) tasks such as question answering, dialogue
generation, summarization, and so forth; yet their susceptibility to
hallucination stands as one of the major challenges. Among numerous approaches
to overcome this challenge, integration of Knowledge Graphs (KGs) into language
models has emerged as a promising solution as it provides structured, reliable,
domain-specific, and up-to-date external information to the language models. In
this paper, we introduce ALIGNed-LLM, a simple yet effective approach to
improve language models' factuality via a lean strategy to infuse KGs into the
latent space of language models inspired by LLaVA where visual and textual
information is infused. We use embeddings from a pre-trained Knowledge Graph
Embedding (KGE) model, such as TransE, and a trainable projection layer to
align entity and text embeddings. This alignment enables the language model to
distinguish between similar entities improving factual grounding and reducing
hallucination. We tested our approach on three popular questions-answering
benchmark datasets alongside language models of varying sizes, showing
significant improvement. Furthermore, we applied our approach to a real-world
financial use case from a large central bank in Europe, which demands high
accuracy and precision, demonstrating a substantial improvement of the LLM
answers.

</details>


### [92] [Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers](https://arxiv.org/abs/2507.13474)
*Liang Lin,Zhihao Xu,Xuehai Tang,Shi Liu,Biyu Zhou,Fuqing Zhu,Jizhong Han,Songlin Hu*

Main category: cs.CL

TL;DR: 这篇论文研究了大型语言模型（LLMs）的安全性，提出了一种名为“论文摘要攻击（PSA）”的创新攻击方法，以利用LLMs信任权威来源信息的倾向。实验表明，PSA方法在多个先进模型上取得了高达97%的攻击成功率（ASR）。


<details>
  <summary>Details</summary>
Motivation: 作者发现之前的研究表明，LLMs倾向于信任权威来源的信息，这种性质可能带来新的安全漏洞。作者希望探索和验证这些潜在风险，并设计对应的攻击方法。

Method: 通过从探讨攻击或防御的大型语言模型安全性论文中综合内容，构造对抗性提示模板，并在预定义子部分中嵌入恶意查询作为对抗性载荷，系统测试了不同模型的易受攻击性。

Result: 提出的PSA攻击方法在多个模型上实验有效，例如在Claude3.5-Sonnet模型上达到97%的攻击成功率，在Deepseek-R1模型上甚至达到98%。此外，发现不同型号和版本的LLM在面对不同性质的论文时表现出完全相反的脆弱性偏向。

Conclusion: PSA方法展示了当前LLMs的显著安全漏洞，为对抗技术和LLMs安全对齐研究提供了新的方向和启示。

Abstract: The safety of large language models (LLMs) has garnered significant research
attention. In this paper, we argue that previous empirical studies demonstrate
LLMs exhibit a propensity to trust information from authoritative sources, such
as academic papers, implying new possible vulnerabilities. To verify this
possibility, a preliminary analysis is designed to illustrate our two findings.
Based on this insight, a novel jailbreaking method, Paper Summary Attack
(\llmname{PSA}), is proposed. It systematically synthesizes content from either
attack-focused or defense-focused LLM safety paper to construct an adversarial
prompt template, while strategically infilling harmful query as adversarial
payloads within predefined subsections. Extensive experiments show significant
vulnerabilities not only in base LLMs, but also in state-of-the-art reasoning
model like Deepseek-R1. PSA achieves a 97\% attack success rate (ASR) on
well-aligned models like Claude3.5-Sonnet and an even higher 98\% ASR on
Deepseek-R1. More intriguingly, our work has further revealed diametrically
opposed vulnerability bias across different base models, and even between
different versions of the same model, when exposed to either attack-focused or
defense-focused papers. This phenomenon potentially indicates future research
clues for both adversarial methodologies and safety alignment.Code is available
at https://github.com/233liang/Paper-Summary-Attack

</details>


### [93] [Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?](https://arxiv.org/abs/2507.13490)
*Siqi Shen,Mehar Singh,Lajanugen Logeswaran,Moontae Lee,Honglak Lee,Rada Mihalcea*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLMs）的价值导向评估，发现现有探测方法对输入扰动敏感，且在捕捉上下文信息及实际行为偏好方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs的价值导向对保证电子用户体验的公平性和准确性至关重要，但当前探测方法仍缺乏系统比较及对实际效果的研究。

Method: 研究比较了三种常用的价值探测策略，通过改变提示和选项进行扰动实验，同时设计了检测模型对人口统计学上下文响应性及其价值偏好与实际行为一致性的任务。

Result: 研究发现现有方法对输入扰动表现出很大的波动性。人口统计学背景对生成的自由文本几乎无影响，模型的价值观仅与其实际价值偏好相关性较弱。

Conclusion: 现有LLMs价值导向探测方法在鲁棒性和准确性方面存在显著不足，未来需要更深入的研究来完善相关机制。

Abstract: There has been extensive research on assessing the value orientation of Large
Language Models (LLMs) as it can shape user experiences across demographic
groups. However, several challenges remain. First, while the Multiple Choice
Question (MCQ) setting has been shown to be vulnerable to perturbations, there
is no systematic comparison of probing methods for value probing. Second, it is
unclear to what extent the probed values capture in-context information and
reflect models' preferences for real-world actions. In this paper, we evaluate
the robustness and expressiveness of value representations across three widely
used probing strategies. We use variations in prompts and options, showing that
all methods exhibit large variances under input perturbations. We also
introduce two tasks studying whether the values are responsive to demographic
context, and how well they align with the models' behaviors in value-related
scenarios. We show that the demographic context has little effect on the
free-text generation, and the models' values only weakly correlate with their
preference for value-based actions. Our work highlights the need for a more
careful examination of LLM value probing and awareness of its limitations.

</details>


### [94] [Encoding syntactic objects and Merge operations in function spaces](https://arxiv.org/abs/2507.13501)
*Matilde Marcolli,Robert C. Berwick*

Main category: cs.CL

TL;DR: 研究展示了如何使用数学方法以函数空间中的函数形式表示词汇项和语法对象，并通过第二Renyi熵建立兼容的代数和操作结构，实现语法核心计算结构的神经计算潜力。


<details>
  <summary>Details</summary>
Motivation: 探索是否能够通过函数空间内的函数表征词汇和语法对象，建立一种与神经计算相兼容的语法表示方法。

Method: 在函数空间中将词汇项表示为函数（如小波），通过第二Renyi熵建立交换非结合半环结构。通过将Merge操作映射到回路和Hopf代数上的协乘结构，实现语法结构的合并表述和计算。

Result: 构建了兼容语法计算的代数结构，并展示了可以通过跨频率相位同步实现Merge操作，同时将其与算术继承函数表述联系起来。

Conclusion: 研究表明，语法计算核心结构可以通过函数表示和代数操作在神经网络中实现，揭示了语法与算术继承函数的关系。

Abstract: We provide a mathematical argument showing that, given a representation of
lexical items as functions (wavelets, for instance) in some function space, it
is possible to construct a faithful representation of arbitrary syntactic
objects in the same function space. This space can be endowed with a
commutative non-associative semiring structure built using the second Renyi
entropy. The resulting representation of syntactic objects is compatible with
the magma structure. The resulting set of functions is an algebra over an
operad, where the operations in the operad model circuits that transform the
input wave forms into a combined output that encodes the syntactic structure.
The action of Merge on workspaces is faithfully implemented as action on these
circuits, through a coproduct and a Hopf algebra Markov chain. The results
obtained here provide a constructive argument showing the theoretical
possibility of a neurocomputational realization of the core computational
structure of syntax. We also present a particular case of this general
construction where this type of realization of Merge is implemented as a cross
frequency phase synchronization on sinusoidal waves. This also shows that Merge
can be expressed in terms of the successor function of a semiring, thus
clarifying the well known observation of its similarities with the successor
function of arithmetic.

</details>


### [95] [A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows](https://arxiv.org/abs/2507.13544)
*Mohamed Achref Ben Ammar,Mohamed Taha Bennani*

Main category: cs.CL

TL;DR: 提出了一种用于构建对话图的新框架并通过图简化方法提升理解能力。


<details>
  <summary>Details</summary>
Motivation: 分析对话动态，优化基于对话数据的自动化系统性能。

Method: 提出Filter & Reconnect图简化方法，结合大语言模型以构建语义清晰的对话图。

Result: 语义度量指标提高两倍，保证树状结构的零δ-超曲率，以更清晰地建模对话。

Conclusion: 新方法在大规模对话分析中具有实际意义，可用于监督聊天机器人等系统。

Abstract: The analysis of conversational dynamics has gained increasing importance with
the rise of large language model-based systems, which interact with users
across diverse contexts. In this work, we propose a novel computational
framework for constructing conversational graphs that capture the flow and
structure of loosely organized dialogues, referred to as quasi-patterned
conversations. We introduce the Filter & Reconnect method, a novel graph
simplification technique that minimizes noise while preserving semantic
coherence and structural integrity of conversational graphs. Through
comparative analysis, we demonstrate that the use of large language models
combined with our graph simplification technique has resulted in semantic
metric S increasing by a factor of 2.06 compared to previous approaches while
simultaneously enforcing a tree-like structure with 0 {\delta}-hyperbolicity,
ensuring optimal clarity in conversation modeling. This work provides a
computational method for analyzing large-scale dialogue datasets, with
practical applications related to monitoring automated systems such as
chatbots, dialogue management tools, and user behavior analytics.

</details>


### [96] [Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder](https://arxiv.org/abs/2507.13551)
*Feng Chen,Weizhe Xu,Changye Li,Serguei Pakhomov,Alex Cohen,Simran Bhola,Sandy Yin,Sunny X Tang,Michael Mackinley,Lena Palaniyappan,Dror Ben-Zeev,Trevor Cohen*

Main category: cs.CL

TL;DR: 本文研究了通过自动语音识别（ASR）提取的暂停特征和语义一致性指标结合对正式思维障碍（FTD）严重程度的预测能力，发现结合这两种特征模型表现更好。


<details>
  <summary>Details</summary>
Motivation: 正式思维障碍是精神分裂症的标志性特征，而传统评估手段耗时且难以扩展，因此亟需一种高效、可扩展的自动化评估方法。

Method: 利用自动语音识别提取的暂停特征和语义一致性指标，通过支持向量回归（SVR）在三个语音数据集上预测FTD评分，并比较不同特征组合对模型性能的贡献。

Result: 仅使用暂停特征即可稳定预测FTD严重度，而与语义特征结合后模型预测能力进一步增强，严重病例检测的AUC值可达到83.71%。

Conclusion: 结合语义与时间特征的分析框架能优化语音混乱的评估方式，并推动针对精神病患者的语音分析自动化技术的发展。

Abstract: Formal thought disorder (FTD), a hallmark of schizophrenia spectrum
disorders, manifests as incoherent speech and poses challenges for clinical
assessment. Traditional clinical rating scales, though validated, are
resource-intensive and lack scalability. Automated speech analysis with
automatic speech recognition (ASR) allows for objective quantification of
linguistic and temporal features of speech, offering scalable alternatives. The
use of utterance timestamps in ASR captures pause dynamics, which are thought
to reflect the cognitive processes underlying speech production. However, the
utility of integrating these ASR-derived features for assessing FTD severity
requires further evaluation. This study integrates pause features with semantic
coherence metrics across three datasets: naturalistic self-recorded diaries
(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream
narratives (PsyCL, n = 43). We evaluated pause related features alongside
established coherence measures, using support vector regression (SVR) to
predict clinical FTD scores. Key findings demonstrate that pause features alone
robustly predict the severity of FTD. Integrating pause features with semantic
coherence metrics enhanced predictive performance compared to semantic-only
models, with integration of independent models achieving correlations up to
\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best
\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance
gains from semantic and pause features integration held consistently across all
contexts, though the nature of pause patterns was dataset-dependent. These
findings suggest that frameworks combining temporal and semantic analyses
provide a roadmap for refining the assessment of disorganized speech and
advance automated speech analysis in psychosis.

</details>


### [97] [A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models](https://arxiv.org/abs/2507.13563)
*Kirill Borodin,Nikita Vasiliev,Vasiliy Kudryavtsev,Maxim Maslov,Mikhail Gorodnichev,Oleg Rogov,Grach Mkrtchian*

Main category: cs.CL

TL;DR: 提出了解决俄语语音合成挑战的新数据集Balalaika，并证明其在语音合成任务中优于现有数据集。


<details>
  <summary>Details</summary>
Motivation: 解决俄语语音合成中的困难，如元音弱化、辅音清化和变调等问题。

Method: 构建了包含2000小时高质量俄语语音和相关文本标注的Balalaika数据集，并详细描述了其构建与标注方法。

Result: 实验表明，基于Balalaika训练的模型在语音合成与增强任务上明显优于使用现有数据集训练的模型。

Conclusion: Balalaika数据集能显著提升俄语语音合成性能，为该领域带来了新的突破。

Abstract: Russian speech synthesis presents distinctive challenges, including vowel
reduction, consonant devoicing, variable stress patterns, homograph ambiguity,
and unnatural intonation. This paper introduces Balalaika, a novel dataset
comprising more than 2,000 hours of studio-quality Russian speech with
comprehensive textual annotations, including punctuation and stress markings.
Experimental results show that models trained on Balalaika significantly
outperform those trained on existing datasets in both speech synthesis and
enhancement tasks. We detail the dataset construction pipeline, annotation
methodology, and results of comparative evaluations.

</details>


### [98] [Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models](https://arxiv.org/abs/2507.13614)
*Sergio E. Zanotto,Segun Aroyehun*

Main category: cs.CL

TL;DR: 该研究分析了由大型语言模型和人类撰写的文本，发现机器生成的文本越来越难与人类文本区分。同时，研究基于不同的语言特征来刻画这两类文本的特性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的快速发展，生成的文本与人类写作越来越难以区分，因此有必要通过语言特征来深入理解二者的差异。

Method: 该研究收集跨8个领域、由11种不同LLMs生成和人类撰写的文本数据集，通过分析诸如依赖长度、情感表达等语言特征，结合统计方法和风格嵌入技术，评估文本在语言层面的特性，并比较不同模型的生成效果和变体。

Result: 研究表明，人类文本在句法结构上较为简单，语义内容更有多样性，并且在特性上的表现随领域而变化更大。机器生成文本在样式上趋向同质化，而较新模型的生成文本变异性减少。

Conclusion: 通过语言特征的分析，研究揭示了人类文本与机器文本的差异，对理解和改进机器生成能力具有重要意义，同时也提示了需关注生成文本的同质化问题。

Abstract: The rapid advancements in large language models (LLMs) have significantly
improved their ability to generate natural language, making texts generated by
LLMs increasingly indistinguishable from human-written texts. While recent
research has primarily focused on using LLMs to classify text as either
human-written and machine-generated texts, our study focus on characterizing
these texts using a set of linguistic features across different linguistic
levels such as morphology, syntax, and semantics. We select a dataset of
human-written and machine-generated texts spanning 8 domains and produced by 11
different LLMs. We calculate different linguistic features such as dependency
length and emotionality and we use them for characterizing human-written and
machine-generated texts along with different sampling strategies, repetition
controls and model release date. Our statistical analysis reveals that
human-written texts tend to exhibit simpler syntactic structures and more
diverse semantic content. Furthermore, we calculate the variability of our set
of features across models and domains. Both human and machine texts show
stylistic diversity across domains, with humans displaying greater variation in
our features. Finally, we apply style embeddings to further test variability
among human-written and machine-generated texts. Notably, newer models output
text that is similarly variable, pointing to an homogenization of
machine-generated texts.

</details>


### [99] [Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters](https://arxiv.org/abs/2507.13618)
*Shanbo Cheng,Yu Bao,Qian Cao,Luyang Huang,Liyan Kang,Zhicheng Liu,Yu Lu,Wenhao Zhu,Zhichao Huang,Tao Li,Sitong Liu,Ningxin Peng,Shuaijie She,Lu Xu,Nuo Xu,Sen Yang,Runsheng Yu,Yiming Yu,Liehao Zou,Hang Li,Lu Lu,Yuxuan Wang,Yonghui Wu*

Main category: cs.CL

TL;DR: 本文介绍了一个名为Seed-X的开源大型语言模型家族，专注于多语言翻译任务，表现优于许多封闭和开放源码的更大模型。


<details>
  <summary>Details</summary>
Motivation: 针对大型语言模型在多语言翻译任务中处理复杂语言模式和翻译僵化问题的不足，提出解决方案。

Method: 开发了一个包含28种语言的大规模多语种数据集作为预训练基础，并通过链式推理（CoT）和强化学习（RL）对模型进行微调提升泛化能力。

Result: Seed-X在自动指标和人工评估的表现中均优于许多更大的开放源码模型，并可与领先的闭源模型媲美。

Conclusion: Seed-X不仅在多语言翻译中表现出色，还通过公开参数和优化实践推动翻译研究和应用的发展。

Abstract: Multilingual translation stands as a challenging task for large language
models (LLMs) to handle intricate language patterns and stilted translations
that arise in automated translations. In this paper, we introduce Seed-X, a
family of open-source LLMs comprising instruct and reasoning models, pushing
the limits of translation capability with 7B parameter size. The base model is
pre-trained on a diverse, high-quality dataset encompassing both monolingual
and bilingual content across 28 languages, harnessing the full potential of
multilingual data. The instruct model is then finetuned to translate by
Chain-of-Thought (CoT) reasoning and further enhanced through reinforcement
learning (RL) to achieve better generalization across diverse language pairs.
Seed-X achieves performance comparable to leading closed-source models,
including Gemini-2.5 and GPT-4o, across 28 languages, and significantly
outperforms larger open-source models in both automatic metrics and human
evaluations. We share the best practices through our optimization process, and
make the parameter public available for advancing translation research and
applications.

</details>


### [100] [CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer](https://arxiv.org/abs/2507.13655)
*Teerapong Panboonyuen*

Main category: cs.CL

TL;DR: 本文提出CU-ICU方法，利用T5架构，通过少量更新模型参数，在ICU数据集上实现语言模型的高效领域适应，并提高准确性和解释性。


<details>
  <summary>Details</summary>
Motivation: 在医疗保健领域集成大规模语言模型面临领域适应与标注数据稀缺等挑战，因此需要低监督、高效适应的方法。

Method: 采用基于Text-to-Text Transfer Transformer (T5)架构的稀疏微调方法，结合少样本提示与选择性参数更新实现模型的高效适应。

Result: CU-ICU在早期败血症检测、死亡率预测以及临床笔记生成任务上表现优异，其中败血症检测准确率提升达15%，临床解释能力提升达20%。

Conclusion: CU-ICU提供了一种高效、可扩展、低成本的解决方案，为重症监护环境中的临床决策支持提供了高准确性与高解释性。

Abstract: Integrating large language models into specialized domains like healthcare
presents unique challenges, including domain adaptation and limited labeled
data. We introduce CU-ICU, a method for customizing unsupervised
instruction-finetuned language models for ICU datasets by leveraging the
Text-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse
fine-tuning approach that combines few-shot prompting with selective parameter
updates, enabling efficient adaptation with minimal supervision. Our evaluation
across critical ICU tasks--early sepsis detection, mortality prediction, and
clinical note generation--demonstrates that CU-ICU consistently improves
predictive accuracy and interpretability over standard fine-tuning methods.
Notably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and
a 20% enhancement in generating clinically relevant explanations while updating
fewer than 1% of model parameters in its most efficient configuration. These
results establish CU-ICU as a scalable, low-overhead solution for delivering
accurate and interpretable clinical decision support in real-world ICU
environments.

</details>


### [101] [KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs](https://arxiv.org/abs/2507.13666)
*Woo-Chan Kim,Ji-Hoon Park,Seong-Whan Lee*

Main category: cs.CL

TL;DR: 提出了Keyword-inspired Cascade（KiC），一个针对自由生成文本的成本效益优化框架，通过智能调整模型使用，接近GPT-4性能同时显著降低API成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型使用成本高昂，而现有级联方法在自由文本生成任务上的表现有限，因此需要一种新的方法优化成本与性能的平衡。

Method: 提出KiC框架，通过识别最具代表性的答案，评估对其语义对齐程度，根据对齐程度决定是否切换到更强模型。

Result: 在三个自由文本生成基准测试中，KiC达到GPT-4准确率的97.53%，同时平均降低API成本28.81%，在某些基准测试中甚至超越了GPT-4。

Conclusion: KiC显著提升了自由文本生成任务中成本和性能的效率，是一种在平衡性能与成本方面的有效方法。

Abstract: Large language models (LLMs) have demonstrated state-of-the-art performance
across a wide range of natural language processing tasks. However,
high-performing models are typically accessible only via APIs, incurring
substantial inference costs. Cascade methods address this by initially
employing a cheaper model and escalating to a stronger one only when necessary.
Nevertheless, existing cascade approaches struggle to select a reliable
representative response and assess the overall reliability of free-form
outputs, as they rely on exact text matching. To overcome these limitations, we
propose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient
free-form text generation. KiC identifies the most representative answer among
multiple outputs from a weaker model and evaluates the semantic alignment of
other responses with it. Based on the degree of alignment, KiC determines
whether to accept the weaker model's output or escalate to a stronger model.
Experiments on three free-form text generation benchmarks show that KiC
achieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81
percent on average, and even outperforms GPT-4 in a specific benchmark.

</details>


### [102] [LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues](https://arxiv.org/abs/2507.13681)
*Haoyang Li,Zhanchao Xu,Yiming Li,Xuejia Chen,Darian Li,Anxin Tian,Qingfa Xiao,Cheng Deng,Jun Wang,Qing Li,Lei Chen,Mingxuan Yuan*

Main category: cs.CL

TL;DR: LoopServe通过动态筛选注意力矩阵的关键部分和自适应维护高效缓存两种创新，显著提升了多轮对话中大模型的推理效率。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在多轮对话中的计算和内存挑战，提升高效性和响应能力。

Method: 提出LoopServe框架，包含在线稀疏化和渐进式键值压缩两种核心机制，并设计了一个适合多轮对话任务的新基准。

Result: LoopServe在多个多轮对话数据集上的实验效果优于现有方法，并显著加速了推理过程。

Conclusion: LoopServe为多轮对话任务中的大型语言模型推理提供了一套高效且动态适应的解决方案。

Abstract: Multi-turn dialogues are essential in many real-world applications of large
language models, such as chatbots and virtual assistants. As conversation
histories become longer, existing large language models face increasing
computational and memory challenges, which hinder their ability to provide
efficient and responsive interactions. Most current acceleration methods either
compress the context or optimize key value caching, but they often rely on
fixed or position-based heuristics that do not adapt well to the dynamic and
unpredictable patterns found in actual multi-turn conversations. In this paper,
we present LoopServe, an adaptive dual-phase inference acceleration framework
for large language models in multi-turn dialogues. LoopServe introduces two
main innovations. First, it performs online sparsification during the
prefilling phase by dynamically selecting the most important parts of the
attention matrix for each new input. Second, it uses progressive key value
compression during decoding by adaptively maintaining a relevant and efficient
cache based on the most recently generated output tokens. We also propose a
\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new
benchmark} with eleven multi-turn datasets that reflect realistic query
positions and conversational dependencies. Extensive experiments demonstrate
that LoopServe consistently achieves superior effectiveness compared to
existing baselines and significantly accelerates LLM inference across a wide
range of long-context dialogue tasks.

</details>


### [103] [Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations](https://arxiv.org/abs/2507.13705)
*Cedric Waterschoot,Nava Tintarev,Francesco Barile*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型（LLMs）作为组推荐系统（GRS）中的决策生成和解释工具的表现，发现其推荐与加性效用（ADD）聚合策略类似，但解释存在不一致和模糊性问题。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于评估LLMs在组推荐系统中的有效性以及其提供的解释与传统社会选择策略相比的表现，关注透明度和解释性。

Method: 通过比较LLMs生成的推荐与社会选择方法中的加性效用（ADD）聚合表现，同时分析推荐解释中的额外标准及对组结构的影响。

Result: LLMs生成的推荐通常与ADD聚合结果相似，但其解释中包含不一致的额外标准，比如用户之间的相似性或项目多样性。此外，组结构并未显著影响推荐结果。

Conclusion: LLMs可能在组推荐系统中作为一种有效工具，但其解释的不一致性和模糊性可能削弱透明度与可解释性，提示需要优化解释生成或调整标准聚合方法的效率。

Abstract: Large Language Models (LLMs) are increasingly being implemented as joint
decision-makers and explanation generators for Group Recommender Systems (GRS).
In this paper, we evaluate these recommendations and explanations by comparing
them to social choice-based aggregation strategies. Our results indicate that
LLM-generated recommendations often resembled those produced by Additive
Utilitarian (ADD) aggregation. However, the explanations typically referred to
averaging ratings (resembling but not identical to ADD aggregation). Group
structure, uniform or divergent, did not impact the recommendations.
Furthermore, LLMs regularly claimed additional criteria such as user or item
similarity, diversity, or used undefined popularity metrics or thresholds. Our
findings have important implications for LLMs in the GRS pipeline as well as
standard aggregation strategies. Additional criteria in explanations were
dependent on the number of ratings in the group scenario, indicating potential
inefficiency of standard aggregation methods at larger item set sizes.
Additionally, inconsistent and ambiguous explanations undermine transparency
and explainability, which are key motivations behind the use of LLMs for GRS.

</details>


### [104] [The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction](https://arxiv.org/abs/2507.13732)
*Guillaume Zambrano*

Main category: cs.CL

TL;DR: 本研究通过机器学习预测法国上诉法院中儿童监护权判决，探讨法官个人决策模式对案件结果的影响。


<details>
  <summary>Details</summary>
Motivation: 挑战法官仅以法律统一应用为中立变量的假设，探讨法官个人决策模式在法律判决中的作用。

Method: 使用18,937个判决和10,306个案例，采用大语言模型进行特征提取，并结合RF、XGB、SVC模型进行结果预测，对比基于个别法官判决历史的模型和对判决整体数据的通用模型。

Result: 基于法官历史的模型预测精度更高，F1分数最高达92.85%，优于通用模型的82.63%，且展现个别法官稳定的行为模式不具泛化性。

Conclusion: 法官身份对法律裁决结果具有显著影响，支持法律现实主义观点，数据和代码将公开。

Abstract: This study examines the role of human judges in legal decision-making by
using machine learning to predict child physical custody outcomes in French
appellate courts. Building on the legal realism-formalism debate, we test
whether individual judges' decision-making patterns significantly influence
case outcomes, challenging the assumption that judges are neutral variables
that apply the law uniformly. To ensure compliance with French privacy laws, we
implement a strict pseudonymization process. Our analysis uses 18,937 living
arrangements rulings extracted from 10,306 cases. We compare models trained on
individual judges' past rulings (specialist models) with a judge-agnostic model
trained on aggregated data (generalist models). The prediction pipeline is a
hybrid approach combining large language models (LLMs) for structured feature
extraction and ML models for outcome prediction (RF, XGB and SVC). Our results
show that specialist models consistently achieve higher predictive accuracy
than the general model, with top-performing models reaching F1 scores as high
as 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x
more samples. Specialist models capture stable individual patterns that are not
transferable to other judges. In-Domain and Cross-Domain validity tests provide
empirical support for legal realism, demonstrating that judicial identity plays
a measurable role in legal outcomes. All data and code used will be made
available.

</details>


### [105] [PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs](https://arxiv.org/abs/2507.13743)
*Maluna Menke,Thilo Hagendorff*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型（LLMs）中性别及性别认同偏见问题，并通过低秩适配（LoRA）和软提示调优两种参数高效微调技术进行偏见缓解评估。


<details>
  <summary>Details</summary>
Motivation: LLMs 存在复制训练语料库中性别及性少数偏见的问题，导致对 LGBTQIA+ 用户的边缘化，需要减少此类偏见以实现更公平的模型表现。

Method: 结合 WinoQueer 基准，使用 LoRA 和软提示调优针对性地对模型进行微调，同时采用 QueerNews 语料库进行 LoRA 微调。

Result: LoRA 可以将偏见评分从最高98（100分制，50为中立）降低至最多50分，并提升中立性比例至36%；而软提示调优改进效果有限。

Conclusion: LoRA 作为低计算代价的微调方式能显著提升模型公平性，但需结合更大的语料库及多元化的评估体系，同时持续审查以确保包含性。

Abstract: Large Language Models (LLMs) frequently reproduce the gender- and
sexual-identity prejudices embedded in their training corpora, leading to
outputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of
great importance. To achieve this, we evaluate two parameter-efficient
fine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt
tuning - as lightweight alternatives to full-model fine-tuning for mitigating
such biases. Using the WinoQueer benchmark, we quantify bias in three
open-source LLMs and observe baseline bias scores reaching up to 98 (out of
100) across a range of queer identities defined by gender and/or sexual
orientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%
additional parameters) on a curated QueerNews corpus reduces those scores by up
to 50 points and raises neutrality from virtually 0% to as much as 36%.
Soft-prompt tuning (10 virtual tokens) delivers only marginal improvements.
These findings show that LoRA can deliver meaningful fairness gains with
minimal computation. We advocate broader adoption of community-informed PEFT,
the creation of larger queer-authored corpora, and richer evaluation suites
beyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.

</details>


### [106] [Innocence in the Crossfire: Roles of Skip Connections in Jailbreaking Visual Language Models](https://arxiv.org/abs/2507.13761)
*Palash Nandi,Maithili Joshi,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 研究探讨了视觉语言模型（VLMs）如何因提示词设计而生成不适当内容的可能性，并提出一种增加破解成功率的框架。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型对输入提示的敏感性，特别是其在多模态情境下的脆弱性，以揭示潜在的滥用风险。

Method: 分析提示设计中的三大影响因素（视觉信息、对抗性例子、正面开头短语）对生成不适当内容的影响，并提出利用VLM内部层的跳跃连接框架提升破解率。

Result: VLM在单独文本或图像时表现良好，但多模态情况下能力显著下降；三个因素均单独可触发破解，少量例子即可导致生成不适当内容；提出框架能显著提高破解率并揭示表面无害内容的隐患。

Conclusion: 视觉语言模型对多模态输入存在显著脆弱性，提示设计需审慎；框架及观察结果对模型安全性研究具有重要意义。

Abstract: Language models are highly sensitive to prompt formulations - small changes
in input can drastically alter their output. This raises a critical question:
To what extent can prompt sensitivity be exploited to generate inapt content?
In this paper, we investigate how discrete components of prompt design
influence the generation of inappropriate content in Visual Language Models
(VLMs). Specifically, we analyze the impact of three key factors on successful
jailbreaks: (a) the inclusion of detailed visual information, (b) the presence
of adversarial examples, and (c) the use of positively framed beginning
phrases. Our findings reveal that while a VLM can reliably distinguish between
benign and harmful inputs in unimodal settings (text-only or image-only), this
ability significantly degrades in multimodal contexts. Each of the three
factors is independently capable of triggering a jailbreak, and we show that
even a small number of in-context examples (as few as three) can push the model
toward generating inappropriate outputs. Furthermore, we propose a framework
that utilizes a skip-connection between two internal layers of the VLM, which
substantially increases jailbreak success rates, even when using benign images.
Finally, we demonstrate that memes, often perceived as humorous or harmless,
can be as effective as toxic visuals in eliciting harmful content, underscoring
the subtle and complex vulnerabilities of VLMs.

</details>


### [107] [An Enhanced Model-based Approach for Short Text Clustering](https://arxiv.org/abs/2507.13793)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Xuemeng Song,Tian Gan,Liqiang Nie*

Main category: cs.CL

TL;DR: 提出了一种改进的短文本聚类算法GSDMM+，通过减小初始化噪声、自适应调整词权重和策略性聚类合并优化聚类效果。


<details>
  <summary>Details</summary>
Motivation: 短文本数据具有稀疏性、高维性和大规模性，现有的主题模型和深度学习方法难以平衡效果和计算效率。

Method: 设计了GSDMM+，改进了GSDMM算法，引入基于信息熵的自适应词权重调整和策略性聚类合并，以实现更精细的聚类。

Result: 实验表明，GSDMM+在效率和效果上优于传统方法和最新方法。

Conclusion: GSDMM+能够有效应对短文本的稀疏和高维特性，同时揭示更相关的主题信息，表现出卓越的聚类性能。

Abstract: Short text clustering has become increasingly important with the popularity
of social media like Twitter, Google+, and Facebook. Existing methods can be
broadly categorized into two paradigms: topic model-based approaches and deep
representation learning-based approaches. This task is inherently challenging
due to the sparse, large-scale, and high-dimensional characteristics of the
short text data. Furthermore, the computational intensity required by
representation learning significantly increases the running time. To address
these issues, we propose a collapsed Gibbs Sampling algorithm for the Dirichlet
Multinomial Mixture model (GSDMM), which effectively handles the sparsity and
high dimensionality of short texts while identifying representative words for
each cluster. Based on several aspects of GSDMM that warrant further
refinement, we propose an improved approach, GSDMM+, designed to further
optimize its performance. GSDMM+ reduces initialization noise and adaptively
adjusts word weights based on entropy, achieving fine-grained clustering that
reveals more topic-related information. Additionally, strategic cluster merging
is employed to refine clustering granularity, better aligning the predicted
distribution with the true category distribution. We conduct extensive
experiments, comparing our methods with both classical and state-of-the-art
approaches. The experimental results demonstrate the efficiency and
effectiveness of our methods. The source code for our model is publicly
available at https://github.com/chehaoa/VEMC.

</details>


### [108] [Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models](https://arxiv.org/abs/2507.13827)
*Hosein Azarbonyad,Zi Long Zhu,Georgios Cheirmpos,Zubair Afzal,Vikrant Yadav,Georgios Tsatsaronis*

Main category: cs.CL

TL;DR: 该研究旨在通过生成问答对的方式从科学文章中提取主要概念与贡献。


<details>
  <summary>Details</summary>
Motivation: 为了帮助学者快速理解和辨别科学文章的关键内容与创新性。

Method: 提出两种生成问答对的方法：一是基于LLM从文章内容生成问题并回答；二是基于知识图谱，通过实体关系抽取模型构建图谱，再根据文章与文献中的中心性提取三元组生成问答。

Result: 基于知识图谱的方法能有效捕获文章主旨，而对实体关系抽取模型的微调显著提升了抽取高质量三元组的能力。

Conclusion: 知识图谱驱动方法在提取科学文章的核心内容方面表现出色，并强调了针对科学语料库进行模型微调的重要性。

Abstract: When deciding to read an article or incorporate it into their research,
scholars often seek to quickly identify and understand its main ideas. In this
paper, we aim to extract these key concepts and contributions from scientific
articles in the form of Question and Answer (QA) pairs. We propose two distinct
approaches for generating QAs. The first approach involves selecting salient
paragraphs, using a Large Language Model (LLM) to generate questions, ranking
these questions by the likelihood of obtaining meaningful answers, and
subsequently generating answers. This method relies exclusively on the content
of the articles. However, assessing an article's novelty typically requires
comparison with the existing literature. Therefore, our second approach
leverages a Knowledge Graph (KG) for QA generation. We construct a KG by
fine-tuning an Entity Relationship (ER) extraction model on scientific articles
and using it to build the graph. We then employ a salient triplet extraction
method to select the most pertinent ERs per article, utilizing metrics such as
the centrality of entities based on a triplet TF-IDF-like measure. This measure
assesses the saliency of a triplet based on its importance within the article
compared to its prevalence in the literature. For evaluation, we generate QAs
using both approaches and have them assessed by Subject Matter Experts (SMEs)
through a set of predefined metrics to evaluate the quality of both questions
and answers. Our evaluations demonstrate that the KG-based approach effectively
captures the main ideas discussed in the articles. Furthermore, our findings
indicate that fine-tuning the ER extraction model on our scientific corpus is
crucial for extracting high-quality triplets from such documents.

</details>


### [109] [The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words](https://arxiv.org/abs/2507.13839)
*Lizhi Ma,Tong Zhao,Shuai Zhang,Nirui Song,Hongliang He,Anqi Li,Ran Feng,Huachuan Qiu,Jingsong Ma,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 研究了汉语心理咨询中语言表达与抑郁、焦虑心理状态的关系，发现负面情感词的频率与心理状态严重性正相关，而第一人称单数代词的使用频率并无显著变化。


<details>
  <summary>Details</summary>
Motivation: 探讨心理健康交流中语言使用的文化与对话情境影响，寻找中国语境下的心理语言学标志。

Method: 利用从735次网上心理咨询中获取的语料库，采用普通线性混合效应模型和LIWC分析语言模式。

Result: 发现负面情感词频率与抑郁和焦虑状态显著正相关，但第一人称单数代词的使用频率未随心理状态显著变化。

Conclusion: 文化背景和心理咨询互动对语言使用有重要影响，为中文心理咨询实践提供了新见解。

Abstract: This study explores the relationship between linguistic expressions and
psychological states of depression and anxiety within Chinese psycho-counseling
interactions, focusing specifically on the usage of first-person singular
pronouns and negative emotional words. Utilizing a corpus derived from 735
online counseling sessions, the analysis employed a general linear mixed-effect
model to assess linguistic patterns quantified by the Linguistic Inquiry and
Word Count (LIWC) software. Results indicate a significant positive correlation
between the frequency of negative emotional words and the severity of both
depressive and anxious states among clients. However, contrary to prior
findings predominantly derived from English-language contexts, the usage
frequency of first-person singular pronouns did not vary significantly with the
clients' psychological conditions. These outcomes are discussed within the
framework of cultural distinctions between collectivist Chinese contexts and
individualistic Western settings, as well as the interactive dynamics unique to
psycho-counseling conversations. The findings highlight the nuanced influence
of cultural and conversational contexts on language use in mental health
communications, providing insights into psycholinguistic markers relevant to
therapeutic practices in Chinese-speaking populations.

</details>


### [110] [Modeling Fair Play in Detective Stories with Language Models](https://arxiv.org/abs/2507.13841)
*Eitan Wagner,Renana Keydar,Omri Abend*

Main category: cs.CL

TL;DR: 提出了一个关于侦探小说的概率框架，并通过LLM生成的侦探故事验证了其有效性，发现LLM生成的故事缺乏“公平游戏”和“惊奇感”的平衡性。


<details>
  <summary>Details</summary>
Motivation: 想要通过框架形式分析和定义侦探小说中重要的写作品质如公平游戏（fair play）和惊奇感之间的平衡，并进一步评估LLM在生成侦探故事中的表现。

Method: 构建了一个概率框架，用于分析故事的连贯性（coherence）和惊奇性（surprise），同时正式定义了公平游戏，并设计了相应的指标。将该框架应用到LLM生成的侦探故事中进行验证。

Result: 发现LLM生成的故事虽具有一定的不可预测性，但在平衡惊奇感和公平游戏之间表现较差，这也是LLM生成故事质量较低的主要原因。

Conclusion: LLM生成侦探故事未能有效平衡惊奇感和连贯性的矛盾，表明未来需要改进生成机制以提升故事质量。

Abstract: Effective storytelling relies on a delicate balance between meeting the
reader's prior expectations and introducing unexpected developments. In the
domain of detective fiction, this tension is known as fair play, which includes
the implicit agreement between the writer and the reader as to the range of
possible resolutions the mystery story may have. In this work, we present a
probabilistic framework for detective fiction that allows us to define desired
qualities. Using this framework, we formally define fair play and design
appropriate metrics for it. Stemming from these definitions is an inherent
tension between the coherence of the story, which measures how much it ``makes
sense'', and the surprise it induces. We validate the framework by applying it
to LLM-generated detective stories. This domain is appealing since we have an
abundance of data, we can sample from the distribution generating the story,
and the story-writing capabilities of LLMs are interesting in their own right.
Results show that while LLM-generated stories may be unpredictable, they
generally fail to balance the trade-off between surprise and fair play, which
greatly contributes to their poor quality.

</details>


### [111] [InTraVisTo: Inside Transformer Visualisation Tool](https://arxiv.org/abs/2507.13858)
*Nicolò Brunello,Davide Rigamonti,Andrea Sassella,Vincenzo Scotti,Mark James Carman*

Main category: cs.CL

TL;DR: 介绍了一种新工具InTraVisTo，通过可视化变压器模型的内部状态和信息流，帮助研究人员理解LLMs的计算过程。


<details>
  <summary>Details</summary>
Motivation: 由于LLMs的不可预测性和实际输出与期望行为之间的差异，在生产中使用LLMs存在挑战，因此需要工具来探索LLMs的行为。

Method: 通过InTraVisTo，研究人员可以可视化变压器模型的内部状态（解码每层的词嵌入）以及模型不同层之间的信息流（使用桑基图）。

Result: 提供了一种能够揭示LLMs内部计算过程和推理模式的工具，从而帮助研究人员更好地理解这些模型的行为。

Conclusion: InTraVisTo为分析Transformer模型的内部机制提供了一个新途径，为提高对LLMs的理解和改进生产应用铺平了道路。

Abstract: The reasoning capabilities of Large Language Models (LLMs) have increased
greatly over the last few years, as have their size and complexity.
Nonetheless, the use of LLMs in production remains challenging due to their
unpredictable nature and discrepancies that can exist between their desired
behavior and their actual model output. In this paper, we introduce a new tool,
InTraVisTo (Inside Transformer Visualisation Tool), designed to enable
researchers to investigate and trace the computational process that generates
each token in a Transformer-based LLM. InTraVisTo provides a visualization of
both the internal state of the Transformer model (by decoding token embeddings
at each layer of the model) and the information flow between the various
components across the different layers of the model (using a Sankey diagram).
With InTraVisTo, we aim to help researchers and practitioners better understand
the computations being performed within the Transformer model and thus to shed
some light on internal patterns and reasoning processes employed by LLMs.

</details>


### [112] [Label Unification for Cross-Dataset Generalization in Cybersecurity NER](https://arxiv.org/abs/2507.13870)
*Maciej Jalocha,Johan Hausted Schmidt,William Michelseen*

Main category: cs.CL

TL;DR: 研究安全领域NER标签统一性问题，通过跨数据集评估以及提出新模型，探讨其对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 当前网络安全NER领域缺乏标准化标签，难以整合数据集，限制了数据资源的使用。

Method: 在四个网络安全数据集间执行粗粒度标签统一，并使用BiLSTM模型进行交叉数据集评估；同时提出多头模型和基于图的迁移模型以改善统一程度的局限性。

Result: 训练于统一数据集的模型在跨数据集上的泛化能力较差，多头模型的改进有限，而基于BERT-base-NER的图模型未显示显著性能提升。

Conclusion: 数据集统一虽然增加了可用性，但其局限性对泛化性能的提升有限。

Abstract: The field of cybersecurity NER lacks standardized labels, making it
challenging to combine datasets. We investigate label unification across four
cybersecurity datasets to increase data resource usability. We perform a
coarse-grained label unification and conduct pairwise cross-dataset evaluations
using BiLSTM models. Qualitative analysis of predictions reveals errors,
limitations, and dataset differences. To address unification limitations, we
propose alternative architectures including a multihead model and a graph-based
transfer model. Results show that models trained on unified datasets generalize
poorly across datasets. The multihead model with weight sharing provides only
marginal improvements over unified training, while our graph-based transfer
model built on BERT-base-NER shows no significant performance gains compared
BERT-base-NER.

</details>


### [113] [Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies](https://arxiv.org/abs/2507.13875)
*Carlos Mena,Pol Serra,Jacobo Romero,Abir Messaoudi,Jose Giraldo,Carme Armentano-Oller,Rodolfo Zevallos,Ivan Meza,Javier Hernando*

Main category: cs.CL

TL;DR: 探讨了通过综合数据生成和语言标记策略来提高加泰罗尼亚语-西班牙语代码切换语音识别的性能。


<details>
  <summary>Details</summary>
Motivation: 加泰罗尼亚语和西班牙语的代码切换因缺乏专用数据集导致自动语音识别性能受限，亟需改进适用于多语言社会代码切换场景的识别技术。

Method: 提出并比较了三种方法：生成合成代码切换数据、单语音频拼接以及结合语言标记的真实代码切换数据，针对Whisper模型进行了微调实验。

Result: 实验表明，结合适量的合成代码切换数据与主要语言标记可达最佳转录性能。

Conclusion: 利用合成数据和语言标记是改进代码切换语音识别性能的有效方法，成果已公开以供社区使用。

Abstract: Code-switching (CS), the alternating use of two or more languages, challenges
automatic speech recognition (ASR) due to scarce training data and linguistic
similarities. The lack of dedicated CS datasets limits ASR performance, as most
models rely on monolingual or mixed-language corpora that fail to reflect
real-world CS patterns. This issue is critical in multilingual societies where
CS occurs in informal and formal settings. A key example is Catalan-Spanish CS,
widely used in media and parliamentary speeches. In this work, we improve ASR
for Catalan-Spanish CS by exploring three strategies: (1) generating synthetic
CS data, (2) concatenating monolingual audio, and (3) leveraging real CS data
with language tokens. We extract CS data from Catalan speech corpora and
fine-tune OpenAI's Whisper models, making them available on Hugging Face.
Results show that combining a modest amount of synthetic CS data with the
dominant language token yields the best transcription performance.

</details>


### [114] [Using LLMs to identify features of personal and professional skills in an open-response situational judgment test](https://arxiv.org/abs/2507.13881)
*Cole Walsh,Rodica Ivan,Muhammad Zafar Iqbal,Colleen Robb*

Main category: cs.CL

TL;DR: 研究探讨通过大型语言模型（LLMs）提取情景判断测试(SJT)的构造相关特征，并展示其在Casper SJT中的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着对个人和职业技能需求的增长，学术项目需要可扩展的系统来评估和开发这些技能。

Method: 通过使用LLMs从SJT响应中提取构造相关特征，作为自动评分系统的新方法。

Result: 成功展示了在Casper SJT中使用LLMs提取构造相关特征的有效性。

Conclusion: 此研究为通过自动评分评估个人和职业技能奠定了基础。

Abstract: Academic programs are increasingly recognizing the importance of personal and
professional skills and their critical role alongside technical expertise in
preparing students for future success in diverse career paths. With this
growing demand comes the need for scalable systems to measure, evaluate, and
develop these skills. Situational Judgment Tests (SJTs) offer one potential
avenue for measuring these skills in a standardized and reliable way, but
open-response SJTs have traditionally relied on trained human raters for
evaluation, presenting operational challenges to delivering SJTs at scale. Past
attempts at developing NLP-based scoring systems for SJTs have fallen short due
to issues with construct validity of these systems. In this article, we explore
a novel approach to extracting construct-relevant features from SJT responses
using large language models (LLMs). We use the Casper SJT to demonstrate the
efficacy of this approach. This study sets the foundation for future
developments in automated scoring for personal and professional skills.

</details>


### [115] [Political Leaning and Politicalness Classification of Texts](https://arxiv.org/abs/2507.13913)
*Matous Volf,Jakub Simko*

Main category: cs.CL

TL;DR: 本文利用变压器模型进行政治倾向和政治性文本分类，提出了多数据集整合与新模型方法以提升跨分布文本的表现。


<details>
  <summary>Details</summary>
Motivation: 目前的文本分类方法在处理超出分布文本时表现较差，需要一种更通用和高效的方法来分类政治文本。

Method: 通过整合12个政治倾向分类数据集并扩展18个数据集生成新的政治性数据集，结合保留一个/剔除一个方法进行广泛基准测试，训练具备更强泛化能力的新模型。

Result: 提出的数据集和训练的新模型显著提升了在政治文本分类中的表现，尤其是处理分布外文本的能力。

Conclusion: 通过增强数据集整合与高性能模型开发，提升文本分类的普适性和泛用性，在政治文本分析领域迈出了重要一步。

Abstract: This paper addresses the challenge of automatically classifying text
according to political leaning and politicalness using transformer models. We
compose a comprehensive overview of existing datasets and models for these
tasks, finding that current approaches create siloed solutions that perform
poorly on out-of-distribution texts. To address this limitation, we compile a
diverse dataset by combining 12 datasets for political leaning classification
and creating a new dataset for politicalness by extending 18 existing datasets
with the appropriate label. Through extensive benchmarking with leave-one-in
and leave-one-out methodologies, we evaluate the performance of existing models
and train new ones with enhanced generalization capabilities.

</details>


### [116] [The Levers of Political Persuasion with Conversational AI](https://arxiv.org/abs/2507.13919)
*Kobi Hackenburg,Ben M. Tappin,Luke Hewitt,Ed Saunders,Sid Black,Hause Lin,Catherine Fist,Helen Margetts,David G. Rand,Christopher Summerfield*

Main category: cs.CL

TL;DR: 该研究通过三个大规模实验研究了19个大语言模型（LLMs）的说服力，发现其说服能力主要取决于后期训练和提示方法，而不是个性化或模型规模的增加。


<details>
  <summary>Details</summary>
Motivation: 当前对于对话式人工智能影响人类信念的担忧日益增长，研究旨在评估其在政治问题上的说服力及准确性。

Method: 通过三个大规模实验，涉及19个LLMs，并分析了707个政治问题和466,769条模型生成的声明，同时评估后期训练和提示方法对说服力的影响。

Result: 后期训练使说服力提高了51%，提示方法提高27%，但同时也降低了生成声明的事实准确性。

Conclusion: 当前和近期AI的说服力主要来源于后期训练和提示，而非模型规模的提升，但伴随的事实准确性下降引发新的问题。

Abstract: There are widespread fears that conversational AI could soon exert
unprecedented influence over human beliefs. Here, in three large-scale
experiments (N=76,977), we deployed 19 LLMs-including some post-trained
explicitly for persuasion-to evaluate their persuasiveness on 707 political
issues. We then checked the factual accuracy of 466,769 resulting LLM claims.
Contrary to popular concerns, we show that the persuasive power of current and
near-future AI is likely to stem more from post-training and prompting
methods-which boosted persuasiveness by as much as 51% and 27%
respectively-than from personalization or increasing model scale. We further
show that these methods increased persuasion by exploiting LLMs' unique ability
to rapidly access and strategically deploy information and that, strikingly,
where they increased AI persuasiveness they also systematically decreased
factual accuracy.

</details>


### [117] [Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support](https://arxiv.org/abs/2507.13937)
*Jan Trienes,Anastasiia Derzhanskaia,Roland Schwarzkopf,Markus Mühling,Jörg Schlötterer,Christin Seifert*

Main category: cs.CL

TL;DR: 本文介绍了一种轻量级的开源会话代理Marcel，用于回答入学相关问题，并减轻大学员工的工作负担。


<details>
  <summary>Details</summary>
Motivation: 希望开发一个能快速提供个性化及验证信息的工具，解决学生入学问题咨询过程中的资源占用问题。

Method: 利用增强检索生成技术从大学资源中提取答案，同时开发了FAQ检索器来提高检索质量，可以根据用户问题匹配知识库条目。

Result: 系统架构设计简单，能够适合资源有限的学术环境，并经过实际部署提供了技术评价和洞察。

Conclusion: 系统提高了响应效率，减轻了大学工作人员的工作量，且适合资源受限的使用场景。

Abstract: We present Marcel, a lightweight and open-source conversational agent
designed to support prospective students with admission-related inquiries. The
system aims to provide fast and personalized responses, while reducing workload
of university staff. We employ retrieval-augmented generation to ground answers
in university resources and to provide users with verifiable, contextually
relevant information. To improve retrieval quality, we introduce an FAQ
retriever that maps user questions to knowledge-base entries, allowing
administrators to steer retrieval, and improving over standard dense/hybrid
retrieval strategies. The system is engineered for easy deployment in
resource-constrained academic settings. We detail the system architecture,
provide a technical evaluation of its components, and report insights from a
real-world deployment.

</details>


### [118] [Exploiting Primacy Effect To Improve Large Language Models](https://arxiv.org/abs/2507.13949)
*Bianca Raimondi,Maurizio Gabbrielli*

Main category: cs.CL

TL;DR: 本研究探讨了语言模型在多选题问答中的初始项偏差，并提出通过基于查询的语义相似性重新排序选项来改善模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是了解并利用语言模型中的位置偏差，如初始项效应，优化自然语言处理任务的结果。

Method: 提出了一种基于选项的语义相似性重新排序策略，无需知道正确答案，即可缓解初始项偏差并提升性能。

Result: 实验结果表明，通过语义相似性调整选项顺序能够显著提高多选题问答的表现。

Conclusion: 偏差既是挑战也是机会。研究结果为设计更加偏差感知的模型提供了有益的见解，有助于改进自然语言处理中的应用。

Abstract: Large Language Models (LLMs) have become essential in many Natural Language
Processing (NLP) tasks, leveraging extensive pre-training and fine-tuning to
achieve high accuracy. However, like humans, LLMs exhibit biases, particularly
positional biases such as primacy and recency effects, which can influence the
accuracy of the answers. The primacy effect-where items presented first are
more likely to be remembered or selected-plays a key role in Multiple Choice
Question Answering (MCQA), where the order of answer options can affect
prediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We
first show that fine-tuning amplifies this bias, probably due to exposure to
human-like patterns. Hence, we strategically leverage this effect by reordering
response options based on semantic similarity to the query, without requiring
knowledge of the correct answer. Our experimental results show that this
approach significantly improves performance in MCQA. More generally, our
findings underscore the dual nature of biases as both challenges and
opportunities, offering insights for bias-aware model design and NLP
applications.

</details>


### [119] [Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need](https://arxiv.org/abs/2507.13966)
*Bhishma Dedhia,Yuval Kansal,Niraj K. Jha*

Main category: cs.CL

TL;DR: 该研究通过利用知识图谱(KG)生成跨领域任务，训练语言模型提高特定领域的推理能力，并在医学领域验证了方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型在多领域泛化上效果有限，本文旨在通过自底向上的知识获取提升深层领域专 expertise。

Method: 构建基于知识图谱的任务生成管道，通过组合简单领域概念生成复杂概念，基于此制定KG驱动的训练课程并微调语言模型。

Result: 开发了QwQ-Med-3模型，并通过新的医学基准ICD-Bench评估其在15个医学领域的推理能力，显著优势于当前最先进模型。

Conclusion: 研究表明，利用知识图谱生成细化课程可显著提升语言模型在领域特定推理任务上的表现，展望通过高效领域智能体的交互实现通用人工智能发展。

Abstract: Language models traditionally used for cross-domain generalization have
recently demonstrated task-specific reasoning. However, their top-down training
approach on general corpora is insufficient for acquiring abstractions needed
for deep domain expertise. This may require a bottom-up approach that acquires
expertise by learning to compose simple domain concepts into more complex ones.
A knowledge graph (KG) provides this compositional structure, where domain
primitives are represented as head-relation-tail edges and their paths encode
higher-level concepts. We present a task generation pipeline that synthesizes
tasks directly from KG primitives, enabling models to acquire and compose them
for reasoning. We fine-tune language models on the resultant KG-grounded
curriculum to demonstrate domain-specific superintelligence. While broadly
applicable, we validate our approach in medicine, where reliable KGs exist.
Using a medical KG, we curate 24,000 reasoning tasks paired with thinking
traces derived from diverse medical primitives. We fine-tune the QwQ-32B model
on this curriculum to obtain QwQ-Med-3 that takes a step towards medical
superintelligence. We also introduce ICD-Bench, an evaluation suite to quantify
reasoning abilities across 15 medical domains. Our experiments demonstrate that
QwQ-Med-3 significantly outperforms state-of-the-art reasoning models on
ICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired
primitives to widen the performance gap on the hardest tasks of ICD-Bench.
Finally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3
transfers acquired expertise to enhance the base model's performance. While the
industry's approach to artificial general intelligence (AGI) emphasizes broad
expertise, we envision a future in which AGI emerges from the composable
interaction of efficient domain-specific superintelligent agents.

</details>


### [120] [Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic](https://arxiv.org/abs/2507.13977)
*Lilit Grigoryan,Nikolay Karpov,Enas Albasiri,Vitaly Lavrukhin,Boris Ginsburg*

Main category: cs.CL

TL;DR: 本文提出了一种面向阿拉伯语语音和文本处理的通用方法论，并基于该方法训练了两个创新型的FastConformer模型，分别针对现代标准阿拉伯语（MSA）和包括经典阿拉伯语（CA）在内的统一阿拉伯语。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语复杂性导致自动语音识别系统发展困难，现有公共模型有限，特别是对阿拉伯语多样性变化的普及性研究较少。

Method: 提出基于FastConformer架构的通用方法学，并训练了两个模型：一个专注于现代标准阿拉伯语（MSA），另一个统一覆盖MSA和经典阿拉伯语（CA）的模型。

Result: MSA模型在相关数据集上达到了最新的业界基准（SOTA），而统一模型在CA的音标准确性上实现了SOTA，同时保持对MSA的强大表现。

Conclusion: 本文通过对模型和训练方法的开源，促进了可重复性研究，展示了基于通用方法学解决阿拉伯语复杂问题的潜力。

Abstract: Despite Arabic being one of the most widely spoken languages, the development
of Arabic Automatic Speech Recognition (ASR) systems faces significant
challenges due to the language's complexity, and only a limited number of
public Arabic ASR models exist. While much of the focus has been on Modern
Standard Arabic (MSA), there is considerably less attention given to the
variations within the language. This paper introduces a universal methodology
for Arabic speech and text processing designed to address unique challenges of
the language. Using this methodology, we train two novel models based on the
FastConformer architecture: one designed specifically for MSA and the other,
the first unified public model for both MSA and Classical Arabic (CA). The MSA
model sets a new benchmark with state-of-the-art (SOTA) performance on related
datasets, while the unified model achieves SOTA accuracy with diacritics for CA
while maintaining strong performance for MSA. To promote reproducibility, we
open-source the models and their training recipes.

</details>


### [121] [Efficient Temporal Tokenization for Mobility Prediction with Large Language Models](https://arxiv.org/abs/2507.14017)
*Haoyu He,Haozheng Luo,Yan Chen,Qi R. Wang*

Main category: cs.CL

TL;DR: 提出RHYTHM，一个结合LLMs作为时空预测器和轨迹推理器的框架，显著提升了性能和计算效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决人类移动轨迹预测中长序列建模和计算效率的挑战。

Method: 将轨迹划分为每日片段，同时引入分层注意力和冻结的LLM进行编码和推理，减少序列长度并增强依赖关系建模。

Result: 在三个真实数据集上，准确率提升2.4%，周末提升5.0%，训练时间减少24.6%。

Conclusion: RHYTHM通过高效的时空建模和推理提高了预测性能并降低计算开销。

Abstract: We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for
Human Mobility), a framework that leverages large language models (LLMs) as
spatio-temporal predictors and trajectory reasoners. RHYTHM partitions
trajectories into daily segments encoded as discrete tokens with hierarchical
attention, capturing both daily and weekly dependencies while substantially
reducing the sequence length. Token representations are enriched with
pre-computed prompt embeddings via a frozen LLM, enhancing the model's ability
to capture interdependencies without extensive computational overhead. By
freezing the LLM backbone, RHYTHM achieves significant computational
efficiency. Evaluation on three real-world datasets demonstrates a 2.4%
improvement in accuracy, 5.0% increase on weekends, and 24.6% reduction in
training time compared to state-of-the-art methods.

</details>


### [122] [CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis](https://arxiv.org/abs/2507.14022)
*Jianfei Li,Kevin Kam Fung Yuen*

Main category: cs.CL

TL;DR: 提出了一种用于文档级情感分析的CPC-CMS框架，通过专家知识判断计算评价标准的权重，选择最佳分类模型。


<details>
  <summary>Details</summary>
Motivation: 解决多分类模型在选择过程中的复杂性问题，并提高分类模型的选择效率和准确性。

Method: 利用CPC方法基于多个评价指标计算模型权重，结合加权决策矩阵选择最优模型；使用基准模型进行比较实验并验证框架的可行性。

Result: 在不考虑时间因素时，ALBERT在三个数据集上表现最佳；包含耗时因素时，无单一模型始终表现最好。

Conclusion: CPC-CMS框架可用于情感分析及其他领域的分类模型选择，具有通用性及实用价值。

Abstract: This study proposes the Cognitive Pairwise Comparison Classification Model
Selection (CPC-CMS) framework for document-level sentiment analysis. The CPC,
based on expert knowledge judgment, is used to calculate the weights of
evaluation criteria, including accuracy, precision, recall, F1-score,
specificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and
efficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random
Forest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long
Short-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from
Transformers (ALBERT) are chosen as classification baseline models. A weighted
decision matrix consisting of classification evaluation scores with respect to
criteria weights, is formed to select the best classification model for a
classification problem. Three open datasets of social media are used to
demonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,
for evaluation results excluding the time factor, ALBERT is the best for the
three datasets; if time consumption is included, no single model always
performs better than the other models. The CPC-CMS can be applied to the other
classification applications in different areas.

</details>


### [123] [Evaluating the Effectiveness of Cost-Efficient Large Language Models in Benchmark Biomedical Tasks](https://arxiv.org/abs/2507.14045)
*Israt Jahan,Md Tahmid Rahman Laskar,Chun Peng,Jimmy Huang*

Main category: cs.CL

TL;DR: 本文评估了各种适用于生物医学任务的成本效益大型语言模型。这些任务涵盖文本和图像处理，结果显示没有单一模型在所有任务中领先，而是各有所长。


<details>
  <summary>Details</summary>
Motivation: 探索和比较封闭源与开源大型语言模型在生物医学领域的性能，寻找最适合特定任务的高效解决方案。

Method: 评估封闭源和开源模型在包括文本分类、生成、问答、多模态图像处理等不同生物医学任务中的表现，并进行对比分析。

Result: 不同模型在不同任务中表现优异，例如某些封闭源模型在特定任务上表现出色，而开源模型则在推理速度、隐私和一些性能上拥有优势。

Conclusion: 开源模型表现出色且具有独特优势，可用于生物医学领域特定任务的高效模型选择提供了重要参考。

Abstract: This paper presents a comprehensive evaluation of cost-efficient Large
Language Models (LLMs) for diverse biomedical tasks spanning both text and
image modalities. We evaluated a range of closed-source and open-source LLMs on
tasks such as biomedical text classification and generation, question
answering, and multimodal image processing. Our experimental findings indicate
that there is no single LLM that can consistently outperform others across all
tasks. Instead, different LLMs excel in different tasks. While some
closed-source LLMs demonstrate strong performance on specific tasks, their
open-source counterparts achieve comparable results (sometimes even better),
with additional benefits like faster inference and enhanced privacy. Our
experimental results offer valuable insights for selecting models that are
optimally suited for specific biomedical applications.

</details>


### [124] [Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog](https://arxiv.org/abs/2507.14063)
*Lautaro Estienne,Gabriel Ben Zenou,Nona Naderi,Jackie Cheung,Pablo Piantanida*

Main category: cs.CL

TL;DR: 本文提出了一种名为Collaborative Rational Speech Act (CRSA)的新方法，通过信息论的方式扩展RSA模型，用于多轮对话场景并提升协作表现。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在协作应用中的广泛使用，它们需要不仅能够生成流畅的语言，还需要理解和推理共同的目标和信念。而现有的RSA扩展在处理多轮协作场景时存在局限性。

Method: 提出了Collaborative Rational Speech Act (CRSA)，一种基于信息论的扩展模型，通过优化从速率-失真理论中改编的增益函数来建模多轮对话，同时考虑对话中双方拥有的私有信息和生成的语言表述。

Result: 在指称游戏和医疗领域的模板化医生-患者对话中，实验结果显示CRSA模型的表现优于现有基准，展现出更一致、可解释和具有协作性的行为。

Conclusion: CRSA方法为创建更加务实且具有社会意识的语言代理提供了依据，使得其在多轮协作场景中具有更强的适应性和表现。

Abstract: As AI systems take on collaborative roles, they must reason about shared
goals and beliefs-not just generate fluent language. The Rational Speech Act
(RSA) framework offers a principled approach to pragmatic reasoning, but
existing extensions face challenges in scaling to multi-turn, collaborative
scenarios. In this paper, we introduce Collaborative Rational Speech Act
(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn
dialog by optimizing a gain function adapted from rate-distortion theory. This
gain is an extension of the gain model that is maximized in the original RSA
model but takes into account the scenario in which both agents in a
conversation have private information and produce utterances conditioned on the
dialog. We demonstrate the effectiveness of CRSA on referential games and
template-based doctor-patient dialogs in the medical domain. Empirical results
show that CRSA yields more consistent, interpretable, and collaborative
behavior than existing baselines-paving the way for more pragmatic and socially
aware language agents.

</details>


### [125] [DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits](https://arxiv.org/abs/2507.14079)
*Garapati Keerthana,Manik Gupta*

Main category: cs.CL

TL;DR: 提出了一个名为DENSE的系统，通过整合分散在不同类型医嘱的证据，生成具有时间连续性的患者进展记录。


<details>
  <summary>Details</summary>
Motivation: 在EHR数据中，进展记录的信息严重不足，影响了患者纵向病史叙述的完整性，而这些记录对于观察患者病情变化及临床决策至关重要。

Method: DENSE系统通过细粒度分类和时间对齐机制，将不同类型的医疗记录整理为结构化的、按时间顺序排列的输入，并结合检索策略和大型语言模型生成进展记录。

Result: 在包含多个诊次和完整进展记录的患者数据集上，生成的记录在纵向一致性方面明显优于原始记录，具有更高的时间对齐比。

Conclusion: DENSE系统能够有效提升医疗记录的叙述连贯性，对临床任务如总结、预测建模和决策支持提供帮助，为实际医疗场景下的记录生成提供了可扩展的解决方案。

Abstract: Progress notes are among the most clinically meaningful artifacts in an
Electronic Health Record (EHR), offering temporally grounded insights into a
patient's evolving condition, treatments, and care decisions. Despite their
importance, they are severely underrepresented in large-scale EHR datasets. For
instance, in the widely used Medical Information Mart for Intensive Care III
(MIMIC-III) dataset, only about $8.56\%$ of hospital visits include progress
notes, leaving gaps in longitudinal patient narratives. In contrast, the
dataset contains a diverse array of other note types, each capturing different
aspects of care.
  We present DENSE (Documenting Evolving Progress Notes from Scattered
Evidence), a system designed to align with clinical documentation workflows by
simulating how physicians reference past encounters while drafting progress
notes. The system introduces a fine-grained note categorization and a temporal
alignment mechanism that organizes heterogeneous notes across visits into
structured, chronological inputs. At its core, DENSE leverages a clinically
informed retrieval strategy to identify temporally and semantically relevant
content from both current and prior visits. This retrieved evidence is used to
prompt a large language model (LLM) to generate clinically coherent and
temporally aware progress notes.
  We evaluate DENSE on a curated cohort of patients with multiple visits and
complete progress note documentation. The generated notes demonstrate strong
longitudinal fidelity, achieving a temporal alignment ratio of $1.089$,
surpassing the continuity observed in original notes. By restoring narrative
coherence across fragmented documentation, our system supports improved
downstream tasks such as summarization, predictive modeling, and clinical
decision support, offering a scalable solution for LLM-driven note synthesis in
real-world healthcare settings.

</details>


### [126] [Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track](https://arxiv.org/abs/2507.14096)
*Brian Ondov,William Xia,Kush Attal,Ishita Unde,Jerry He,Hoa Dang,Ian Soboroff,Dina Demner-Fushman*

Main category: cs.CL

TL;DR: 研究探讨了使用大语言模型将专业医学文献转化为简明语言的潜力，通过2023和2024年的PLABA研究轨道进行了评估，结果展示了模型的优点与不足。


<details>
  <summary>Details</summary>
Motivation: 探索如何使用语言模型将医学文献转化为患者和护理者易懂的语言，同时确保准确性和无害性。

Method: 在2023和2024年文本检索会议上举办PLABA轨道，包含摘要句子级别重写和困难术语识别与替换两项任务，并引入专业参考标准和人工评估机制。

Result: 共有来自十二个国家的十二支团队参与。顶尖模型在准确性与完整性上接近人工水平，但在简单性和简洁性上表现不足。参考对比的自动评估和人工评判相关性较低，LLM在术语替换上的人工评估成绩优异，但仍需改进。

Conclusion: 研究显示大语言模型在医学文献简明化及公共传播中的潜力，同时暴露其在评估工具和任务表现上的不足。

Abstract: Objective: Recent advances in language models have shown potential to adapt
professional-facing biomedical literature to plain language, making it
accessible to patients and caregivers. However, their unpredictability,
combined with the high potential for harm in this domain, means rigorous
evaluation is necessary. Our goals with this track were to stimulate research
and to provide high-quality evaluation of the most promising systems.
  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts
(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included
complete, sentence-level, rewriting of abstracts (Task 1) as well as
identifying and replacing difficult terms (Task 2). For automatic evaluation of
Task 1, we developed a four-fold set of professionally-written references.
Submissions for both Tasks 1 and 2 were provided extensive manual evaluation
from biomedical experts.
  Results: Twelve teams spanning twelve countries participated in the track,
with models from multilayer perceptrons to large pretrained transformers. In
manual judgments of Task 1, top-performing models rivaled human levels of
factual accuracy and completeness, but not simplicity or brevity. Automatic,
reference-based metrics generally did not correlate well with manual judgments.
In Task 2, systems struggled with identifying difficult terms and classifying
how to replace them. When generating replacements, however, LLM-based systems
did well in manually judged accuracy, completeness, and simplicity, though not
in brevity.
  Conclusion: The PLABA track showed promise for using Large Language Models to
adapt biomedical literature for the general public, while also highlighting
their deficiencies and the need for improved automatic benchmarking tools.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [127] [GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination](https://arxiv.org/abs/2507.13511)
*Nabil Abdelaziz Ferhat Taleb,Abdolazim Rezaei,Raj Atulkumar Patel,Mehdi Sookhak*

Main category: cs.AI

TL;DR: GraphTrafficGPT是一种新型图形架构，优化了LLM在交通管理中的任务执行效率，相较于TrafficGPT，其降低了50.2%的代币消耗，平均响应延迟减少19.0%。


<details>
  <summary>Details</summary>
Motivation: 现有基于链的系统如TrafficGPT在复杂交通场景中表现出任务顺序执行、代币使用过高和扩展性差的问题，需要更高效的系统来支持智能交通管理。

Method: 提出GraphTrafficGPT，使用图形架构将任务及其依赖表示为有向图节点和边，引入Brain Agent分解用户查询，优化依赖图，并协调多种专用Agent完成数据检索、分析、可视化和模拟。

Result: GraphTrafficGPT在任务并行执行和动态资源分配方面表现出色，与TrafficGPT相比，代币消耗减少50.2%，平均响应延迟缩短19.0%，并支持多查询同时处理，效率提高23.0%。

Conclusion: GraphTrafficGPT显著改进了智能交通管理场景中的任务执行效率和资源利用，为复杂现实场景中LLM应用提供了高效的解决方案。

Abstract: Large Language Models (LLMs) offer significant promise for intelligent
traffic management; however, current chain-based systems like TrafficGPT are
hindered by sequential task execution, high token usage, and poor scalability,
making them inefficient for complex, real-world scenarios. To address these
limitations, we propose GraphTrafficGPT, a novel graph-based architecture,
which fundamentally redesigns the task coordination process for LLM-driven
traffic applications. GraphTrafficGPT represents tasks and their dependencies
as nodes and edges in a directed graph, enabling efficient parallel execution
and dynamic resource allocation. The main idea behind the proposed model is a
Brain Agent that decomposes user queries, constructs optimized dependency
graphs, and coordinates a network of specialized agents for data retrieval,
analysis, visualization, and simulation. By introducing advanced context-aware
token management and supporting concurrent multi-query processing, the proposed
architecture handles interdependent tasks typical of modern urban mobility
environments. Experimental results demonstrate that GraphTrafficGPT reduces
token consumption by 50.2% and average response latency by 19.0% compared to
TrafficGPT, while supporting simultaneous multi-query execution with up to
23.0% improvement in efficiency.

</details>


### [128] [PrefPalette: Personalized Preference Modeling with Latent Attributes](https://arxiv.org/abs/2507.13541)
*Shuyue Stella Li,Melanie Sclar,Hunter Lang,Ansong Ni,Jacqueline He,Puxin Xu,Andrew Cohen,Chan Young Park,Yulia Tsvetkov,Asli Celikyilmaz*

Main category: cs.AI

TL;DR: PrefPalette框架将用户偏好分解为属性维度，并依据不同社群价值进行人类可解释的偏好预测，在Reddit上的测试显著超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前偏好模型将人类判断视为黑箱，缺乏对偏好背后原因的理解，研究旨在提供更透明和值得信赖的个性化AI系统。

Method: 提议PrefPalette框架，基于多属性决策认知科学原理。方法包括（1）生成合成训练数据以分离属性效应；（2）基于注意力的偏好建模，学习社群如何动态加权属性。

Result: 在Reddit的45个社群测试中，PrefPalette相比GPT-4的预测准确率提升46.6%。模型还揭示了社群间的独特偏好模式。

Conclusion: PrefPalette不仅增强了偏好建模性能，还提供了透明且可解释的见解，是实现信赖和值得关注的个性化应用的第一步。

Abstract: Personalizing AI systems requires understanding not just what users prefer,
but the reasons that underlie those preferences - yet current preference models
typically treat human judgment as a black box. We introduce PrefPalette, a
framework that decomposes preferences into attribute dimensions and tailors its
preference prediction to distinct social community values in a
human-interpretable manner. PrefPalette operationalizes a cognitive science
principle known as multi-attribute decision making in two ways: (1) a scalable
counterfactual attribute synthesis step that involves generating synthetic
training data to isolate for individual attribute effects (e.g., formality,
humor, cultural values), and (2) attention-based preference modeling that
learns how different social communities dynamically weight these attributes.
This approach moves beyond aggregate preference modeling to capture the diverse
evaluation frameworks that drive human judgment. When evaluated on 45 social
communities from the online platform Reddit, PrefPalette outperforms GPT-4o by
46.6% in average prediction accuracy. Beyond raw predictive improvements,
PrefPalette also shed light on intuitive, community-specific profiles:
scholarly communities prioritize verbosity and stimulation, conflict-oriented
communities value sarcasm and directness, and support-based communities
emphasize empathy. By modeling the attribute-mediated structure of human
judgment, PrefPalette delivers both superior preference modeling and
transparent, interpretable insights, and serves as a first step toward more
trustworthy, value-aware personalized applications.

</details>


### [129] [GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models](https://arxiv.org/abs/2507.13550)
*Eduardo C. Garrido-Merchán,Cristina Puente*

Main category: cs.AI

TL;DR: 引入了一种利用大型语言模型（LLMs）开发专家系统的新方法，强调可控性和透明性。


<details>
  <summary>Details</summary>
Motivation: 目前LLMs在生成知识方面表现突出，但存在如幻觉生成或不准确信息等缺点，需要新的方法提升其可靠性和可信度。

Method: 通过限定领域，结合基于提示的结构化提取法生成Prolog符号知识表示，并由人类专家进行验证和校正。

Result: 对Claude Sonnet 3.7和GPT-4.1进行实验，生成的知识库表现出较强的事实一致性和语义连贯性。

Conclusion: 提出了一种结合LLMs回忆能力和符号系统精准性的透明混合解决方案，为敏感领域的可靠AI应用提供了基础。

Abstract: The development of large language models (LLMs) has successfully transformed
knowledge-based systems such as open domain question nswering, which can
automatically produce vast amounts of seemingly coherent information. Yet,
those models have several disadvantages like hallucinations or confident
generation of incorrect or unverifiable facts. In this paper, we introduce a
new approach to the development of expert systems using LLMs in a controlled
and transparent way. By limiting the domain and employing a well-structured
prompt-based extraction approach, we produce a symbolic representation of
knowledge in Prolog, which can be validated and corrected by human experts.
This approach also guarantees interpretability, scalability and reliability of
the developed expert systems. Via quantitative and qualitative experiments with
Claude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic
coherence on our generated knowledge bases. We present a transparent hybrid
solution that combines the recall capacity of LLMs with the precision of
symbolic systems, thereby laying the foundation for dependable AI applications
in sensitive domains.

</details>


### [130] [Why Isn't Relational Learning Taking Over the World?](https://arxiv.org/abs/2507.13558)
*David Poole*

Main category: cs.AI

TL;DR: 本文探讨了当前AI主要集中于建模像素、文字和音素，而忽略了现实中由实体及其属性和关系组成的本质。同时也探讨了为何关系学习尚未成为主流，并提出提高其受重视程度的方法。


<details>
  <summary>Details</summary>
Motivation: 目前AI模型大多着眼于像素、文字和音素的处理，但真实世界是由实体、事件及它们之间的关系组成的。论文旨在强调应将研究重点从感知和描述转向对这些实体和关系的建模。

Method: 分析现有AI系统和关系学习的现状，讨论为何关系学习未取得大范围应用，并提出相关改进措施。

Result: 提出了对关系学习领域进行改进的建议，为其在AI发展中的更广泛运用奠定基础。

Conclusion: 尽管当前AI发展多集中于感知和文本数据处理，但关系学习应得到更多关注，因为其更贴合现实世界的数据特点。未来应加强对关系学习的研究与推广，以实现更全面的AI应用。

Abstract: AI seems to be taking over the world with systems that model pixels, words,
and phonemes. The world is arguably made up, not of pixels, words, and phonemes
but of entities (objects, things, including events) with properties and
relations among them. Surely we should model these, not the perception or
description of them. You might suspect that concentrating on modeling words and
pixels is because all of the (valuable) data in the world is in terms of text
and images. If you look into almost any company you will find their most
valuable data is in spreadsheets, databases and other relational formats. These
are not the form that are studied in introductory machine learning, but are
full of product numbers, student numbers, transaction numbers and other
identifiers that can't be interpreted naively as numbers. The field that
studies this sort of data has various names including relational learning,
statistical relational AI, and many others. This paper explains why relational
learning is not taking over the world -- except in a few cases with restricted
relations -- and what needs to be done to bring it to it's rightful prominence.

</details>


### [131] [BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety](https://arxiv.org/abs/2507.13625)
*Yuxin Zhang,Xi Wang,Mo Hu,Zhenyu Zhang*

Main category: cs.AI

TL;DR: 本研究提出了BifrostRAG，一种双图谱检索增强生成系统，用于解决安全法规的信息检索及问答中的多跳推理问题，显著优于当前方法。


<details>
  <summary>Details</summary>
Motivation: 由于安全法规文本的语言和结构复杂性，许多合规性问题需要跨多条相互关联的条款进行信息整合，这对传统检索增强生成（RAG）系统构成了挑战。

Method: 提出了BifrostRAG，结合实体网络图和文档导航图的双图架构，通过混合检索机制（图遍历与向量语义搜索结合）支持大型语言模型理解文本意义与结构。

Result: 在多跳问题数据集上获得92.8%的精确率、85.5%的召回率及87.3%的F1值，明显优于仅基于向量和仅基于图的方法。

Conclusion: BifrostRAG证明其为一种强大的LLM驱动合规性检查引擎，其双图混合检索机制为在复杂技术文档中导航提供了可迁移的蓝图。

Abstract: Information retrieval and question answering from safety regulations are
essential for automated construction compliance checking but are hindered by
the linguistic and structural complexity of regulatory text. Many
compliance-related queries are multi-hop, requiring synthesis of information
across interlinked clauses. This poses a challenge for traditional
retrieval-augmented generation (RAG) systems. To overcome this, we introduce
BifrostRAG: a dual-graph RAG-integrated system that explicitly models both
linguistic relationships (via an Entity Network Graph) and document structure
(via a Document Navigator Graph). This architecture powers a hybrid retrieval
mechanism that combines graph traversal with vector-based semantic search,
enabling large language models to reason over both the meaning and the
structure of the text. Evaluation on a multi-hop question dataset shows that
BifrostRAG achieves 92.8 percent precision, 85.5 percent recall, and an F1
score of 87.3 percent. These results significantly outperform vector-only and
graph-only RAG baselines that represent current leading approaches. Error
analysis further highlights the comparative advantages of our hybrid method
over single-modality RAGs. These findings establish BifrostRAG as a robust
knowledge engine for LLM-driven compliance checking. Its dual-graph, hybrid
retrieval mechanism offers a transferable blueprint for navigating complex
technical documents across knowledge-intensive engineering domains.

</details>


### [132] [Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks](https://arxiv.org/abs/2507.13651)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 研究一种基于最终答案的自动错误诊断方法，用于解决学生在多步骤合并情况下的错误评估困难。


<details>
  <summary>Details</summary>
Motivation: 解决当学生合并多个步骤导致可能路径过多而引发的错误诊断困难问题。

Method: 通过最终答案评估，结合任务解决策略自动诊断中间输入，从而减少路径组合引发的复杂性。

Result: 实验验证表明，该方法能诊断出29.4%的无法通过传统规则服务诊断的步骤，与教师诊断对比一致率达到97%。

Conclusion: 基于最终答案的错误诊断方法证明有效，为进一步探索此方法奠定了基础。

Abstract: Many intelligent tutoring systems can support a student in solving a stepwise
task. When a student combines several steps in one step, the number of possible
paths connecting consecutive inputs may be very large. This combinatorial
explosion makes error diagnosis hard. Using a final answer to diagnose a
combination of steps can mitigate the combinatorial explosion, because there
are generally fewer possible (erroneous) final answers than (erroneous)
solution paths. An intermediate input for a task can be diagnosed by
automatically completing it according to the task solution strategy and
diagnosing this solution. This study explores the potential of automated error
diagnosis based on a final answer. We investigate the design of a service that
provides a buggy rule diagnosis when a student combines several steps. To
validate the approach, we apply the service to an existing dataset (n=1939) of
unique student steps when solving quadratic equations, which could not be
diagnosed by a buggy rule service that tries to connect consecutive inputs with
a single rule. Results show that final answer evaluation can diagnose 29,4% of
these steps. Moreover, a comparison of the generated diagnoses with teacher
diagnoses on a subset (n=115) shows that the diagnoses align in 97% of the
cases. These results can be considered a basis for further exploration of the
approach.

</details>


### [133] [Combining model tracing and constraint-based modeling for multistep strategy diagnoses](https://arxiv.org/abs/2507.13652)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 提出了一个结合模型追踪和约束建模的新方法，用于诊断学生在逐步任务中的输入。通过在解二次方程问题的数据集上进行验证，证明方法的诊断结果与教师编码结果一致。


<details>
  <summary>Details</summary>
Motivation: 解决单独使用模型追踪或约束建模在诊断学生多步骤策略中的局限性，提出一种更全面的诊断方法。

Method: 定义约束为学生输入与策略步骤的共同属性，结合模型追踪和约束建模，根据现有数据集验证多步骤诊断系统的表现，并与教师编码结果进行比较。

Result: 诊断系统所生成的结果在140个学生步骤上与教师的编码结果完全一致，证明了该方法的有效性。

Conclusion: 结合两种方法的新诊断系统能有效处理学生多步骤策略的偏差，为教育技术领域提供新工具。

Abstract: Model tracing and constraint-based modeling are two approaches to diagnose
student input in stepwise tasks. Model tracing supports identifying consecutive
problem-solving steps taken by a student, whereas constraint-based modeling
supports student input diagnosis even when several steps are combined into one
step. We propose an approach that merges both paradigms. By defining
constraints as properties that a student input has in common with a step of a
strategy, it is possible to provide a diagnosis when a student deviates from a
strategy even when the student combines several steps. In this study we explore
the design of a system for multistep strategy diagnoses, and evaluate these
diagnoses. As a proof of concept, we generate diagnoses for an existing dataset
containing steps students take when solving quadratic equations (n=2136). To
compare with human diagnoses, two teachers coded a random sample of deviations
(n=70) and applications of the strategy (n=70). Results show that that the
system diagnosis aligned with the teacher coding in all of the 140 student
steps.

</details>


### [134] [DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs](https://arxiv.org/abs/2507.13737)
*Ye Tian,Xiaoyuan Ren,Zihao Wang,Onat Gungor,Xiaofan Yu,Tajana Rosing*

Main category: cs.AI

TL;DR: DailyLLM提出了一种结合语境信息的活动日志生成和总结系统，应用于智能手机和智能手表。


<details>
  <summary>Details</summary>
Motivation: 现有活动日志生成方法在准确性、高效性和语义丰富性上存在局限。

Method: DailyLLM应用轻量级大语言模型框架，通过结构化提示和高效特征提取，综合了位置、运动、环境和生理四个维度的信息。

Result: 实验表明，DailyLLM在日志生成质量和效率上优于现有方法，使用1.5B参数的模型可达成较70B参数模型更高的精度和更快的推理速度。

Conclusion: DailyLLM实现了高质量、高效率的活动日志生成，是一种创新且实用的技术方案。

Abstract: Rich and context-aware activity logs facilitate user behavior analysis and
health monitoring, making them a key research focus in ubiquitous computing.
The remarkable semantic understanding and generation capabilities of Large
Language Models (LLMs) have recently created new opportunities for activity log
generation. However, existing methods continue to exhibit notable limitations
in terms of accuracy, efficiency, and semantic richness. To address these
challenges, we propose DailyLLM. To the best of our knowledge, this is the
first log generation and summarization system that comprehensively integrates
contextual activity information across four dimensions: location, motion,
environment, and physiology, using only sensors commonly available on
smartphones and smartwatches. To achieve this, DailyLLM introduces a
lightweight LLM-based framework that integrates structured prompting with
efficient feature extraction to enable high-level activity understanding.
Extensive experiments demonstrate that DailyLLM outperforms state-of-the-art
(SOTA) log generation methods and can be efficiently deployed on personal
computers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM
achieves a 17% improvement in log generation BERTScore precision compared to
the 70B-parameter SOTA baseline, while delivering nearly 10x faster inference
speed.

</details>


### [135] [OntView: What you See is What you Meant](https://arxiv.org/abs/2507.13759)
*Carlos Bobed,Carlota Quintana,Eduardo Mena,Jorge Bobed,Fernando Bobillo*

Main category: cs.AI

TL;DR: 本文讨论了知识管理和计算机科学中本体可视化的挑战，并提出了一款名为OntView的本体可视化工具，旨在提供直观的界面和更好的本体结构表示。


<details>
  <summary>Details</summary>
Motivation: 目前大多数本体编辑和查看工具无法以非压迫性且有意义的方式显示本体结构，这限制了用户理解大型本体框架中依赖关系和属性的能力。

Method: 提出并开发了OntView工具，借助DL推理进行‘所见即所得’的推理知识展示及展现一般概念包含（GCI），提供多个功能实现动态语义可视化。

Result: OntView实现了直观的本体概念及定义显示，并具备如创建本体摘要、焦点视图及动态隐藏等功能，解决了信息过载问题。

Conclusion: OntView通过开源形式发布于社区中，填补了本体可视化领域中的空白，并优化了用户体验。

Abstract: In the field of knowledge management and computer science, ontologies provide
a structured framework for modeling domain-specific knowledge by defining
concepts and their relationships. However, the lack of tools that provide
effective visualization is still a significant challenge. While numerous
ontology editors and viewers exist, most of them fail to graphically represent
ontology structures in a meaningful and non-overwhelming way, limiting users'
ability to comprehend dependencies and properties within large ontological
frameworks.
  In this paper, we present OntView, an ontology viewer that is designed to
provide users with an intuitive visual representation of ontology concepts and
their formal definitions through a user-friendly interface. Building on the use
of a DL reasoner, OntView follows a "What you see is what you meant" paradigm,
showing the actual inferred knowledge. One key aspect for this is its ability
to visualize General Concept Inclusions (GCI), a feature absent in existing
visualization tools. Moreover, to avoid a possible information overload,
OntView also offers different ways to show a simplified view of the ontology
by: 1) creating ontology summaries by assessing the importance of the concepts
(according to different available algorithms), 2) focusing the visualization on
the existing TBox elements between two given classes and 3) allowing to
hide/show different branches in a dynamic way without losing the semantics.
OntView has been released with an open-source license for the whole community.

</details>


### [136] [From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning](https://arxiv.org/abs/2507.13768)
*Renato Ghisellini,Remo Pareschi,Marco Pedroni,Giovanni Battista Raggi*

Main category: cs.AI

TL;DR: 本文提出一种混合架构，用于增强战略推理，融合启发式提取、语义激活和构成综合。


<details>
  <summary>Details</summary>
Motivation: 目前的决策引擎多选择单一规则，而复杂情境需要能够融合冲突性启发式规则的方法。

Method: 通过结合经典军事理论到现代企业战略，系统通过量子认知的语义相互依赖启发来激活和组合多种启发式规则。

Result: 框架通过Meta与FTC案例研究进行了展示，并通过语义指标初步验证其效果。

Conclusion: 提出了在战略推理中通过语义交互建模和修辞框架来生成情境敏感性叙述的创新方法，同时讨论了局限性和可能的扩展。

Abstract: We present a hybrid architecture for agent-augmented strategic reasoning,
combining heuristic extraction, semantic activation, and compositional
synthesis. Drawing on sources ranging from classical military theory to
contemporary corporate strategy, our model activates and composes multiple
heuristics through a process of semantic interdependence inspired by research
in quantum cognition. Unlike traditional decision engines that select the best
rule, our system fuses conflicting heuristics into coherent and
context-sensitive narratives, guided by semantic interaction modeling and
rhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,
with preliminary validation through semantic metrics. Limitations and
extensions (e.g., dynamic interference tuning) are discussed.

</details>


### [137] [When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction](https://arxiv.org/abs/2507.13825)
*Haoyang Li,Yuming Xu,Yiming Li,Hanmo Liu,Darian Li,Chen Jason Zhang,Lei Chen,Qing Li*

Main category: cs.AI

TL;DR: EAGLE是一种轻量级框架，用于动态图的时间链接预测，通过结合短期时间邻近性与长期全局结构模式，显著提高了效率和效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有T-GNNs在复杂时间和结构依赖建模中面临的可扩展性和效率挑战。

Method: 提出EAGLE框架，包括时间感知模块和结构感知模块，结合自适应权重机制平衡短期和长期信息，同时避免复杂的多跳信息传递或高内存机制。

Result: 在七个真实动态图上的实验表明，EAGLE性能稳定优越，效果和效率均超过当前最先进的T-GNNs，并在效率上达到50倍以上的提升。

Conclusion: EAGLE有效兼顾了效率和效果，在动态图时间链接预测任务中表现卓越，具有重要应用潜力。

Abstract: Temporal link prediction in dynamic graphs is a critical task with
applications in diverse domains such as social networks, recommendation
systems, and e-commerce platforms. While existing Temporal Graph Neural
Networks (T-GNNs) have achieved notable success by leveraging complex
architectures to model temporal and structural dependencies, they often suffer
from scalability and efficiency challenges due to high computational overhead.
In this paper, we propose EAGLE, a lightweight framework that integrates
short-term temporal recency and long-term global structural patterns. EAGLE
consists of a time-aware module that aggregates information from a node's most
recent neighbors to reflect its immediate preferences, and a structure-aware
module that leverages temporal personalized PageRank to capture the influence
of globally important nodes. To balance these attributes, EAGLE employs an
adaptive weighting mechanism to dynamically adjust their contributions based on
data characteristics. Also, EAGLE eliminates the need for complex multi-hop
message passing or memory-intensive mechanisms, enabling significant
improvements in efficiency. Extensive experiments on seven real-world temporal
graphs demonstrate that EAGLE consistently achieves superior performance
against state-of-the-art T-GNNs in both effectiveness and efficiency,
delivering more than a 50x speedup over effective transformer-based T-GNNs.

</details>


### [138] [Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments](https://arxiv.org/abs/2507.13846)
*Kathrin Korte,Christian Medeiros Adriano,Sona Ghahremani,Holger Giese*

Main category: cs.AI

TL;DR: 提出了一种因果知识转移框架，通过紧凑的因果路径表示实现了非固定环境下代理间的知识共享和适应性学习，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 针对多智能体强化学习(MARL)中传统知识转移方法难以在非固定环境中泛化的问题，提出解决方法。

Method: 设计了一种因果知识转移框架，通过模式的零样本查询，将从其他代理学习的因果干预(恢复动作序列)转移并应用。

Result: 研究结果表明：(1)代理在适应新环境时，能够缩减从随机探索到完全重新训练的策略差距的约50%；(2)因果知识转移的效果受环境复杂性和代理目标异质性的影响。

Conclusion: 该方法在非固定目标和环境变化的设定下，实现了高效的知识共享和无重新训练的适应性行为，显示出潜在的广泛应用前景。

Abstract: [Context] Multi-agent reinforcement learning (MARL) has achieved notable
success in environments where agents must learn coordinated behaviors. However,
transferring knowledge across agents remains challenging in non-stationary
environments with changing goals. [Problem] Traditional knowledge transfer
methods in MARL struggle to generalize, and agents often require costly
retraining to adapt. [Approach] This paper introduces a causal knowledge
transfer framework that enables RL agents to learn and share compact causal
representations of paths within a non-stationary environment. As the
environment changes (new obstacles), agents' collisions require adaptive
recovery strategies. We model each collision as a causal intervention
instantiated as a sequence of recovery actions (a macro) whose effect
corresponds to a causal knowledge of how to circumvent the obstacle while
increasing the chances of achieving the agent's goal (maximizing cumulative
reward). This recovery action macro is transferred online from a second agent
and is applied in a zero-shot fashion, i.e., without retraining, just by
querying a lookup model with local context information (collisions). [Results]
Our findings reveal two key insights: (1) agents with heterogeneous goals were
able to bridge about half of the gap between random exploration and a fully
retrained policy when adapting to new environments, and (2) the impact of
causal knowledge transfer depends on the interplay between environment
complexity and agents' heterogeneous goals.

</details>


### [139] [Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery](https://arxiv.org/abs/2507.13874)
*Mateusz Bystroński,Mikołaj Hołysz,Grzegorz Piotrowski,Nitesh V. Chawla,Tomasz Kajdanowicz*

Main category: cs.AI

TL;DR: 本文提出了一种模型无关的潜在空间创意生成框架，旨在通过导航嵌入空间实现可控且具有扩展性的创造力。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在创意生成中存在局限，容易复制训练中的模式，难以产生新颖且相关的输出。

Method: 利用潜在空间中的连续嵌入，通过无需手工规则的框架实现跨域适用的创意生成。

Result: 初步原型展示了该方法在协助人机协作创意中的潜力。

Conclusion: 该框架可为广泛场景下的创意生成提供通用协助，提出了突破现有方法局限的新路径。

Abstract: Innovative idea generation remains a core challenge in AI, as large language
models (LLMs) often struggle to produce outputs that are both novel and
relevant. Despite their fluency, LLMs tend to replicate patterns seen during
training, limiting their ability to diverge creatively without extensive prompt
engineering. Prior work has addressed this through domain-specific heuristics
and structured prompting pipelines, but such solutions are brittle and
difficult to generalize. In this paper, we propose a model-agnostic
latent-space ideation framework that enables controlled, scalable creativity by
navigating the continuous embedding space of ideas. Unlike prior methods, our
framework requires no handcrafted rules and adapts easily to different domains,
input formats, and creative tasks. This paper introduces an early-stage
prototype of our method, outlining the conceptual framework and preliminary
results highlighting its potential as a general-purpose co-ideator for human-AI
collaboration.

</details>


### [140] [Cross-modal Causal Intervention for Alzheimer's Disease Prediction](https://arxiv.org/abs/2507.13956)
*Yutao Jin,Haowen Xiao,Jielei Chu,Fengmao Lv,Yuxiao Li,Tianrui Li*

Main category: cs.AI

TL;DR: 该论文提出了一种新颖的视觉语言因果干预框架（ADPC），用于早期预测阿尔茨海默病（AD），通过整合MRI、fMRI及大语言模型生成的文本数据进行分类。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的早期诊断面临数据选择偏差和变量关系复杂性的问题，该研究旨在解决这些挑战。

Method: 提出了名为ADPC的视觉语言因果干预框架，结合大语言模型生成的结构化文本和MRI等多模态数据，通过因果干预消除混杂因素。

Result: 实验结果表明，该方法在区分认知正常（CN）、轻度认知障碍（MCI）和阿尔茨海默病（AD）患者方面表现出色，超过了大多数评估指标的最先进水平。

Conclusion: 该研究证明，结合因果推理与多模态学习在神经疾病诊断中的潜力。

Abstract: Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's
Disease (AD), where early identification and intervention can effectively slow
the progression to dementia. However, diagnosing AD remains a significant
challenge in neurology due to the confounders caused mainly by the selection
bias of multimodal data and the complex relationships between variables. To
address these issues, we propose a novel visual-language causal intervention
framework named Alzheimer's Disease Prediction with Cross-modal Causal
Intervention (ADPC) for diagnostic assistance. Our ADPC employs large language
model (LLM) to summarize clinical data under strict templates, maintaining
structured text outputs even with incomplete or unevenly distributed datasets.
The ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)
images and textual data generated by LLM to classify participants into
Cognitively Normal (CN), MCI, and AD categories. Because of the presence of
confounders, such as neuroimaging artifacts and age-related biomarkers,
non-causal models are likely to capture spurious input-output correlations,
generating less reliable results. Our framework implicitly eliminates
confounders through causal intervention. Experimental results demonstrate the
outstanding performance of our method in distinguishing CN/MCI/AD cases,
achieving state-of-the-art (SOTA) metrics across most evaluation metrics. The
study showcases the potential of integrating causal reasoning with multi-modal
learning for neurological disease diagnosis.

</details>


### [141] [Towards Constraint Temporal Answer Set Programming](https://arxiv.org/abs/2507.13958)
*Pedro Cabalar,Martín Diéguez,François Olivier,Torsten Schaub,Igor Stéphan*

Main category: cs.AI

TL;DR: 本研究通过结合时间逻辑和约束扩展，提出了一种适用于ASP的非单调时序约束推理框架。


<details>
  <summary>Details</summary>
Motivation: 逻辑方法，如ASP，在处理细粒度时序和数值分辨率的动态系统时面临挑战。

Method: 结合Here-and-There逻辑的线性时间扩展与约束逻辑，创建一个能直接处理数值约束的非单调逻辑框架。

Result: 首次开发出针对ASP的非单调时序推理及约束整合的方法。

Conclusion: 为在ASP中高分辨率解决复杂动态系统问题奠定了基础逻辑框架。

Abstract: Reasoning about dynamic systems with a fine-grained temporal and numeric
resolution presents significant challenges for logic-based approaches like
Answer Set Programming (ASP). To address this, we introduce and elaborate upon
a novel temporal and constraint-based extension of the logic of Here-and-There
and its nonmonotonic equilibrium extension, representing, to the best of our
knowledge, the first approach to nonmonotonic temporal reasoning with
constraints specifically tailored for ASP. This expressive system is achieved
by a synergistic combination of two foundational ASP extensions: the
linear-time logic of Here-and-There, providing robust nonmonotonic temporal
reasoning capabilities, and the logic of Here-and-There with constraints,
enabling the direct integration and manipulation of numeric constraints, among
others. This work establishes the foundational logical framework for tackling
complex dynamic systems with high resolution within the ASP paradigm.

</details>


### [142] [KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models](https://arxiv.org/abs/2507.14032)
*Lam Nguyen,Erika Barcelos,Roger French,Yinghui Wu*

Main category: cs.AI

TL;DR: KROMA利用大型语言模型（LLMs）和检索增强生成（RAG）优化语义互操作的本体匹配任务，比现有方法表现更优，且通信开销较低。


<details>
  <summary>Details</summary>
Motivation: 现有的本体匹配系统常依赖固定规则或专门模型，适应性有限，需探索更灵活高效的解决方案。

Method: 提出KROMA框架，结合检索增强生成（RAG）和LLMs，在匹配中加入结构、词汇及定义上下文。同时利用双相匹配方法与轻量本体精炼以优化效率和性能。

Result: KROMA在多项基准数据集上表现优异，超过经典和最新的LLM方法，同时保持低通信开销。

Conclusion: 通过知识检索、提示增强和本体精炼等技术，KROMA证明了大规模高效本体匹配的可行性和优势。

Abstract: Ontology Matching (OM) is a cornerstone task of semantic interoperability,
yet existing systems often rely on handcrafted rules or specialized models with
limited adaptability. We present KROMA, a novel OM framework that harnesses
Large Language Models (LLMs) within a Retrieval-Augmented Generation (RAG)
pipeline to dynamically enrich the semantic context of OM tasks with
structural, lexical, and definitional knowledge. To optimize both performance
and efficiency, KROMA integrates a bisimilarity-based concept matching and a
lightweight ontology refinement step, which prune candidate concepts and
substantially reduce the communication overhead from invoking LLMs. Through
experiments on multiple benchmark datasets, we show that integrating knowledge
retrieval with context-augmented LLMs significantly enhances ontology matching,
outperforming both classic OM systems and cutting-edge LLM-based approaches
while keeping communication overhead comparable. Our study highlights the
feasibility and benefit of the proposed optimization techniques (targeted
knowledge retrieval, prompt enrichment, and ontology refinement) for ontology
matching at scale.

</details>


### [143] [Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions](https://arxiv.org/abs/2507.14077)
*Temiloluwa Prioleau,Baiying Lu,Yanjun Cui*

Main category: cs.AI

TL;DR: 本文介绍了Glucose-ML，一个包含10个公共糖尿病数据集的集合，提供超过38百万的血糖监测数据，用于支持AI算法开发和健康领域的研究。


<details>
  <summary>Details</summary>
Motivation: 由于大规模高质量数据集的缺乏，一直制约了可靠AI解决方案在糖尿病管理中的开发。本研究旨在加速透明、可复现及稳健的AI解决方案的发展。

Method: 论文开发并介绍了一个名为Glucose-ML的数据集集合，并对其中的10个数据集进行分析和比较，同时以血糖预测为案例给出基准表现及指导建议。

Result: 通过案例分析，发现不同数据集对算法表现有显著影响，并提供了数据选择指南及算法开发的建议。

Conclusion: Glucose-ML的数据集集合及辅助资源对支持AI开发、提升糖尿病管理和健康领域研究价值意义重大，作者公开了数据链接及代码。

Abstract: Artificial intelligence (AI) algorithms are a critical part of
state-of-the-art digital health technology for diabetes management. Yet, access
to large high-quality datasets is creating barriers that impede development of
robust AI solutions. To accelerate development of transparent, reproducible,
and robust AI solutions, we present Glucose-ML, a collection of 10 publicly
available diabetes datasets, released within the last 7 years (i.e., 2018 -
2025). The Glucose-ML collection comprises over 300,000 days of continuous
glucose monitor (CGM) data with a total of 38 million glucose samples collected
from 2500+ people across 4 countries. Participants include persons living with
type 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support
researchers and innovators with using this rich collection of diabetes
datasets, we present a comparative analysis to guide algorithm developers with
data selection. Additionally, we conduct a case study for the task of blood
glucose prediction - one of the most common AI tasks within the field. Through
this case study, we provide a benchmark for short-term blood glucose prediction
across all 10 publicly available diabetes datasets within the Glucose-ML
collection. We show that the same algorithm can have significantly different
prediction results when developed/evaluated with different datasets. Findings
from this study are then used to inform recommendations for developing robust
AI solutions within the diabetes or broader health domain. We provide direct
links to each longitudinal diabetes dataset in the Glucose-ML collection and
openly provide our code.

</details>


### [144] [Generative AI-Driven High-Fidelity Human Motion Simulation](https://arxiv.org/abs/2507.14097)
*Hari Iyer,Neel Macwan,Atharva Jitendra Hude,Heejin Jeong,Shenghan Guo*

Main category: cs.AI

TL;DR: 提出了一种名为G-AI-HMS的新方法，将任务描述转化为运动，并通过计算机视觉验证模拟结果的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在人类运动仿真中存在低运动保真度问题，需要改进以提升工业任务的劳动力行为评估。

Method: 结合文本到文本及文本到运动的生成式AI模型，将任务描述转化为与运动相关的语言，使用计算机视觉评估AI生成的运动与真实人类运动的匹配度。

Result: 在多个案例任务中，AI增强运动在空间精度、姿势准确性和时间相似性方面优于人类描述，显著降低关节误差和时间失真(p < 0.0001)。

Conclusion: G-AI-HMS方法显著提高了运动仿真的质量，为工业任务中的劳动力评估提供了有效工具。

Abstract: Human motion simulation (HMS) supports cost-effective evaluation of worker
behavior, safety, and productivity in industrial tasks. However, existing
methods often suffer from low motion fidelity. This study introduces
Generative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and
text-to-motion models to enhance simulation quality for physical tasks.
G-AI-HMS tackles two key challenges: (1) translating task descriptions into
motion-aware language using Large Language Models aligned with MotionGPT's
training vocabulary, and (2) validating AI-enhanced motions against real human
movements using computer vision. Posture estimation algorithms are applied to
real-time videos to extract joint landmarks, and motion similarity metrics are
used to compare them with AI-enhanced sequences. In a case study involving
eight tasks, the AI-enhanced motions showed lower error than human created
descriptions in most scenarios, performing better in six tasks based on spatial
accuracy, four tasks based on alignment after pose normalization, and seven
tasks based on overall temporal similarity. Statistical analysis showed that
AI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and
temporal misalignment while retaining comparable posture accuracy.

</details>


### [145] [Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment](https://arxiv.org/abs/2507.14107)
*Viraj Nishesh Darji,Callie C. Liao,Duoduo Liao*

Main category: cs.AI

TL;DR: 本研究探讨了大型语言模型（LLMs）在桥梁检测中解读非破坏性检测（NDE）数据的潜力，发现其能提高分析效率并保证准确性。


<details>
  <summary>Details</summary>
Motivation: 桥梁维护和安全需要高效解读NDE数据，传统方法耗时且需要专门知识，希望通过LLMs改进此过程并加速决策。

Method: 通过设计特定提示词，测试多个LLMs解读NDE等高桥状况映射数据，并根据模型的描述细致度、缺陷识别、建议实用性等进行评估。

Result: 研究表明，九种LLMs中有四种在图像描述方面表现优异，其中ChatGPT-4和Claude 3.5 Sonnet生成的总结更有效，实验还整合五种LLMs的输出形成桥梁综合评估报告。

Conclusion: LLMs有助于加速桥梁维护决策，提高效率和准确性，并为未来桥梁检测工作流的优化提供了框架。

Abstract: Bridge maintenance and safety are essential for transportation authorities,
and Non-Destructive Evaluation (NDE) techniques are critical to assessing
structural integrity. However, interpreting NDE data can be time-consuming and
requires expertise, potentially delaying decision-making. Recent advancements
in Large Language Models (LLMs) offer new ways to automate and improve this
analysis. This pilot study introduces a holistic assessment of LLM capabilities
for interpreting NDE contour maps and demonstrates the effectiveness of LLMs in
providing detailed bridge condition analyses. It establishes a framework for
integrating LLMs into bridge inspection workflows, indicating that LLM-assisted
analysis can enhance efficiency without compromising accuracy. In this study,
several LLMs are explored with prompts specifically designed to enhance the
quality of image descriptions, which are applied to interpret five different
NDE contour maps obtained through technologies for assessing bridge conditions.
Each LLM model is evaluated based on its ability to produce detailed
descriptions, identify defects, provide actionable recommendations, and
demonstrate overall accuracy. The research indicates that four of the nine
models provide better image descriptions, effectively covering a wide range of
topics related to the bridge's condition. The outputs from these four models
are summarized using five different LLMs to form a comprehensive overview of
the bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more
effective summaries. The findings suggest that LLMs have the potential to
significantly improve efficiency and accuracy. This pilot study presents an
innovative approach that leverages LLMs for image captioning in parallel and
summarization, enabling faster decision-making in bridge maintenance and
enhancing infrastructure management and safety assessments.

</details>


### [146] [CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.14111)
*Xiaoya Li,Xiaofei Sun,Albert Wang,Jiwei Li,Chris Shum*

Main category: cs.AI

TL;DR: CUDA-L1是一个旨在优化CUDA编程的强化学习框架，实现了大幅度的性能提升，并且在多种GPU架构上具有出色的可移植性。


<details>
  <summary>Details</summary>
Motivation: 当前针对CUDA优化的需求迫切，但现有的语言模型在提升CUDA性能方面成功率较低，本文提出了一种能够在CUDA代码优化上实现显著速度提升的新方法。

Method: 提出了一种名为CUDA-L1的强化学习框架，利用基于速度提升的奖励信号，在无需人为专业知识的情况下对CUDA代码进行自动优化。

Result: 实验表明，在NVIDIA A100上，CUDA-L1平均加速了17.7倍，并在KernelBench基准测试中达到了最高449倍的加速。此外，该模型在其他GPU架构上也表现出色，例如在H100、RTX 3090等不同设备上均有显著的性能提升。

Conclusion: CUDA-L1展示了强化学习在CUDA优化中的潜力，通过强化学习方法不仅提高了GPU计算效率，还为未来实现CUDA操作自动化优化提供了新途径。

Abstract: The exponential growth in demand for GPU computing resources, driven by the
rapid advancement of Large Language Models, has created an urgent need for
automated CUDA optimization strategies. While recent advances in LLMs show
promise for code generation, current SOTA models (e.g. R1, o1) achieve low
success rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an
automated reinforcement learning framework for CUDA optimization.
  CUDA-L1 achieves performance improvements on the CUDA optimization task:
trained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250
CUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the
model also demonstrates excellent portability across GPU architectures,
achieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,
x14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.
Beyond these benchmark results, CUDA-L1 demonstrates several remarkable
properties: 1) Discovers a variety of CUDA optimization techniques and learns
to combine them strategically to achieve optimal performance; 2) Uncovers
fundamental principles of CUDA optimization; 3) Identifies non-obvious
performance bottlenecks and rejects seemingly beneficial optimizations that
harm performance.
  The capabilities of CUDA-L1 demonstrate that reinforcement learning can
transform an initially poor-performing LLM into an effective CUDA optimizer
through speedup-based reward signals alone, without human expertise or domain
knowledge. More importantly, the trained RL model extend the acquired reasoning
abilities to new kernels. This paradigm opens possibilities for automated
optimization of CUDA operations, and holds promise to substantially promote GPU
efficiency and alleviate the rising pressure on GPU computing resources.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [147] [Physical models realizing the transformer architecture of large language models](https://arxiv.org/abs/2507.13354)
*Zeqian Chen*

Main category: cs.LG

TL;DR: 本文以物理学视角，将基于Transformer架构的大型语言模型视为开放量子系统，并建立对应的物理模型。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer架构为何有效，并从物理角度弥补理论理解的不足。

Method: 以现代计算芯片为出发点，将Transformer架构语言模型建模为Fock空间上的开放量子系统。

Result: 构建了支撑Transformer架构的物理模型。

Conclusion: 论文从物理学角度提供对Transformer架构的新理解并拓展理论基础。

Abstract: The introduction of the transformer architecture in 2017 (cf.\cite{VSP2017})
marked the most striking advancement in natural language processing. The
transformer is a model architecture relying entirely on an attention mechanism
to draw global dependencies between input and output. However, we believe there
is a gap in our theoretical understanding of what the transformer is, and why
it works physically. In this paper, from a physical perspective on modern
chips, we construct physical models in the Fock space over the Hilbert space of
tokens realizing large language models based on a transformer architecture as
open quantum systems. Our physical models underlie the transformer architecture
for large language models.

</details>


### [148] [Whose View of Safety? A Deep DIVE Dataset for Pluralistic Alignment of Text-to-Image Models](https://arxiv.org/abs/2507.13383)
*Charvi Rastogi,Tian Huey Teh,Pushkar Mishra,Roma Patel,Ding Wang,Mark Díaz,Alicia Parrish,Aida Mostafazadeh Davani,Zoe Ashwood,Michela Paganini,Vinodkumar Prabhakaran,Verena Rieser,Lora Aroyo*

Main category: cs.LG

TL;DR: 本文研究了文本生成图像(T2I)模型的多元对齐问题，并提出了DIVE数据集，确认了人口统计学对多样化视角的影响，讨论了模型对齐的方法及其意义。


<details>
  <summary>Details</summary>
Motivation: 当前T2I模型未能涵盖多样化的价值观和人类经验，导致对齐问题。此研究旨在推动系统理解并偏向多样且互相冲突的人类价值观，提升系统的公平性和责任性。

Method: 1. 创建DIVE数据集，包含1000条多模态提示，通过多元化、交叉人口统计学来源的评价者提供的反馈，捕捉多样化的安全评估。2. 从实验角度验证人口统计学作为多样化观点的代理，揭示不同人口背景下的损害感知差异。3. 探讨高效数据采集、LLM判断能力及引导模型进行多视角对齐的方法。

Result: 验证了人口统计对视角多样化的有效代理作用，生成了一套可以支撑更公平及对齐的T2I基础工具。

Conclusion: 研究奠定了更公平和对齐的T2I系统开发基础，提供了探索和实现多元对齐的工具和方法。

Abstract: Current text-to-image (T2I) models often fail to account for diverse human
experiences, leading to misaligned systems. We advocate for pluralistic
alignment, where an AI understands and is steerable towards diverse, and often
conflicting, human values. Our work provides three core contributions to
achieve this in T2I models. First, we introduce a novel dataset for Diverse
Intersectional Visual Evaluation (DIVE) -- the first multimodal dataset for
pluralistic alignment. It enable deep alignment to diverse safety perspectives
through a large pool of demographically intersectional human raters who
provided extensive feedback across 1000 prompts, with high replication,
capturing nuanced safety perceptions. Second, we empirically confirm
demographics as a crucial proxy for diverse viewpoints in this domain,
revealing significant, context-dependent differences in harm perception that
diverge from conventional evaluations. Finally, we discuss implications for
building aligned T2I models, including efficient data collection strategies,
LLM judgment capabilities, and model steerability towards diverse perspectives.
This research offers foundational tools for more equitable and aligned T2I
systems. Content Warning: The paper includes sensitive content that may be
harmful.

</details>


### [149] [Improving KAN with CDF normalization to quantiles](https://arxiv.org/abs/2507.13393)
*Jakub Strawa,Jarek Duda*

Main category: cs.LG

TL;DR: 本文探讨了在机器学习中使用CDF归一化替代传统标准化或重缩放方法的潜力，特别是在Kolmogorov-Arnold网络（KANs）中。


<details>
  <summary>Details</summary>
Motivation: 旨在引入金融领域常用的基于分布函数的归一化方法到机器学习，并展示其在减少过拟合和提升预测性能上的潜力。

Method: 通过将数据从传统的减均值和除以标准差的归一化方法转换为基于累计分布函数（CDF）的方式，对KANs模型进行验证。

Result: 在Kolmogorov-Arnold Networks中，使用CDF归一化可以改进使用传统Legendre-KAN的预测性能。

Conclusion: CDF归一化提高了模型的预测能力，同时还能帮助表征和传播概率分布，为机器学习模型引入新的解释和应用可能性。

Abstract: Data normalization is crucial in machine learning, usually performed by
subtracting the mean and dividing by standard deviation, or by rescaling to a
fixed range. In copula theory, popular in finance, there is used normalization
to approximately quantiles by transforming x to CDF(x) with estimated CDF
(cumulative distribution function) to nearly uniform distribution in [0,1],
allowing for simpler representations which are less likely to overfit. It seems
nearly unknown in machine learning, therefore, we would like to present some
its advantages on example of recently popular Kolmogorov-Arnold Networks
(KANs), improving predictions from Legendre-KAN by just switching rescaling to
CDF normalization. Additionally, in HCR interpretation, weights of such neurons
are mixed moments providing local joint distribution models, allow to propagate
also probability distributions, and change propagation direction.

</details>


### [150] [Selective Embedding for Deep Learning](https://arxiv.org/abs/2507.13399)
*Mert Sehri,Zehui Hua,Francisco de Assis Boldt,Patrick Dumond*

Main category: cs.LG

TL;DR: 提出了一种新颖的数据加载策略“选择性嵌入”，改进了现有深度学习方法在非平稳和跨领域时间序列数据上的表现，并验证了其在多个实际领域中的有效性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在数据输入敏感性高，在非平稳条件或不同领域尤其是时间域数据时表现差强人意，传统数据加载方式不能很好解决泛化与效率问题。

Method: 提出了一种模仿人类信息处理的选择性嵌入数据加载策略，采用多源数据短片段交替嵌入单一输入通道，提高模型泛化能力与计算效率。

Result: 在使用六个时间域数据集进行验证中，选择性嵌入方法提高了分类准确率，减少了训练时间，并在多种深度学习架构中表现优越。

Conclusion: 此方法适用于多源复杂系统，特别是在需要高鲁棒性和适应性的医疗、重型机械、海洋、铁路和农业等实际领域中具备可扩展性和资源效率。

Abstract: Deep learning has revolutionized many industries by enabling models to
automatically learn complex patterns from raw data, reducing dependence on
manual feature engineering. However, deep learning algorithms are sensitive to
input data, and performance often deteriorates under nonstationary conditions
and across dissimilar domains, especially when using time-domain data.
Conventional single-channel or parallel multi-source data loading strategies
either limit generalization or increase computational costs. This study
introduces selective embedding, a novel data loading strategy, which alternates
short segments of data from multiple sources within a single input channel.
Drawing inspiration from cognitive psychology, selective embedding mimics
human-like information processing to reduce model overfitting, enhance
generalization, and improve computational efficiency. Validation is conducted
using six time-domain datasets, demonstrating that the proposed method
consistently achieves high classification accuracy across various deep learning
architectures while significantly reducing training times. The approach proves
particularly effective for complex systems with multiple data sources, offering
a scalable and resource-efficient solution for real-world applications in
healthcare, heavy machinery, marine, railway, and agriculture, where robustness
and adaptability are critical.

</details>


### [151] [LightAutoDS-Tab: Multi-AutoML Agentic System for Tabular Data](https://arxiv.org/abs/2507.13413)
*Aleksey Lapin,Igor Hromov,Stanislav Chumakov,Mile Mitrovic,Dmitry Simakov,Nikolay O. Nikitin,Andrey V. Savchenko*

Main category: cs.LG

TL;DR: 本文提出LightAutoDS-Tab，一种多自动化机器学习（AutoML）代理系统，基于LLM代码生成与多种AutoML工具结合的设计，超越现有开源解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前的AutoML系统在处理复杂任务时效率受到对特定底层工具依赖的限制。作者希望设计一种更灵活、鲁棒的系统。

Method: 开发基于LLM代码生成的多AutoML工具集成系统LightAutoDS-Tab，用于表格数据任务，并通过Pipeline设计优化性能。

Result: 在多个Kaggle数据科学任务中，LightAutoDS-Tab的表现优于最先进的开源解决方案。

Conclusion: 本研究展示了通过整合LLM技术和多个AutoML工具，开发更灵活、强大的数据科学解决方案的潜力。

Abstract: AutoML has advanced in handling complex tasks using the integration of LLMs,
yet its efficiency remains limited by dependence on specific underlying tools.
In this paper, we introduce LightAutoDS-Tab, a multi-AutoML agentic system for
tasks with tabular data, which combines an LLM-based code generation with
several AutoML tools. Our approach improves the flexibility and robustness of
pipeline design, outperforming state-of-the-art open-source solutions on
several data science tasks from Kaggle. The code of LightAutoDS-Tab is
available in the open repository https://github.com/sb-ai-lab/LADS

</details>


### [152] [Gauge Flow Models](https://arxiv.org/abs/2507.13414)
*Alexander Strunk,Roland Assam*

Main category: cs.LG

TL;DR: 提出了新型生成流模型——规范流模型，这些模型在流体常微分方程中引入一个可学习的规范场。


<details>
  <summary>Details</summary>
Motivation: 现有生成流模型存在性能瓶颈，研究旨在改善其表达能力和任务适应性。

Method: 在流模型中融入可学习的规范场，并构建了详细的数学框架，通过“流匹配”对高斯混合模型进行实验验证。

Result: 相比传统流模型，即使模型规模更小，规范流模型也表现出显著更好的性能。

Conclusion: 该方法展示了在更广泛生成任务中表现提升的潜力，可能推动生成模型领域的进步。

Abstract: This paper introduces Gauge Flow Models, a novel class of Generative Flow
Models. These models incorporate a learnable Gauge Field within the Flow
Ordinary Differential Equation (ODE). A comprehensive mathematical framework
for these models, detailing their construction and properties, is provided.
Experiments using Flow Matching on Gaussian Mixture Models demonstrate that
Gauge Flow Models yields significantly better performance than traditional Flow
Models of comparable or even larger size. Additionally, unpublished research
indicates a potential for enhanced performance across a broader range of
generative tasks.

</details>


### [153] [Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement: application to data-driven constitutive modeling](https://arxiv.org/abs/2507.13416)
*Jiaxiang Yi,Bernardo P. Ferreira,Miguel A. Bessa*

Main category: cs.LG

TL;DR: 本文提出了一种历史相关的多保真数据驱动学习方法，可以区分和量化模型的不确定性（认知不确定性和数据噪声）。


<details>
  <summary>Details</summary>
Motivation: 为了在科学与工程领域中，在不确定性条件下进行更加精确的数据驱动建模和预测。

Method: 提出了一种多保真方差估计的贝叶斯递归神经网络，同时适用于最简单的单保真模型到复杂多保真模型场景。

Result: 在不同的多保真数据驱动模型情境中，方法成功预测响应、量化模型错误并揭示了噪声分布。

Conclusion: 此方法显著提升了在不确定条件下建模和预测的能力，为科学和工程领域的实际应用开辟了广阔前景。

Abstract: Data-driven learning is generalized to consider history-dependent
multi-fidelity data, while quantifying epistemic uncertainty and disentangling
it from data noise (aleatoric uncertainty). This generalization is hierarchical
and adapts to different learning scenarios: from training the simplest
single-fidelity deterministic neural networks up to the proposed multi-fidelity
variance estimation Bayesian recurrent neural networks. The versatility and
generality of the proposed methodology are demonstrated by applying it to
different data-driven constitutive modeling scenarios that include multiple
fidelities with and without aleatoric uncertainty (noise). The method
accurately predicts the response and quantifies model error while also
discovering the noise distribution (when present). This opens opportunities for
future real-world applications in diverse scientific and engineering domains;
especially, the most challenging cases involving design and analysis under
uncertainty.

</details>


### [154] [Soft-ECM: An extension of Evidential C-Means for complex data](https://arxiv.org/abs/2507.13417)
*Armel Soubeiga,Thomas Guyet,Violaine Antoine*

Main category: cs.LG

TL;DR: 提出了软证据C均值（Soft-ECM）方法，扩展了传统的ECM算法，使其可应用于混合数据和非表格数据。


<details>
  <summary>Details</summary>
Motivation: 解决现有ECM算法无法处理混合数据和非表格数据的问题，提高对复杂数据的聚类能力。

Method: 通过重新构造ECM问题，引入Soft-ECM算法，该算法利用半度量属性来定义不精确聚类中心点。

Result: Soft-ECM对数值数据的效果与传统模糊聚类方法相当，同时展示了其对混合数据和时间序列数据的处理能力。

Conclusion: Soft-ECM扩展了ECM的适用范围，在复杂数据聚类方面具有显著优势。

Abstract: Clustering based on belief functions has been gaining increasing attention in
the machine learning community due to its ability to effectively represent
uncertainty and/or imprecision. However, none of the existing algorithms can be
applied to complex data, such as mixed data (numerical and categorical) or
non-tabular data like time series. Indeed, these types of data are, in general,
not represented in a Euclidean space and the aforementioned algorithms make use
of the properties of such spaces, in particular for the construction of
barycenters. In this paper, we reformulate the Evidential C-Means (ECM) problem
for clustering complex data. We propose a new algorithm, Soft-ECM, which
consistently positions the centroids of imprecise clusters requiring only a
semi-metric. Our experiments show that Soft-ECM present results comparable to
conventional fuzzy clustering approaches on numerical data, and we demonstrate
its ability to handle mixed data and its benefits when combining fuzzy
clustering with semi-metrics such as DTW for time series data.

</details>


### [155] [Air Traffic Controller Task Demand via Graph Neural Networks: An Interpretable Approach to Airspace Complexity](https://arxiv.org/abs/2507.13423)
*Edward Henderson,Dewi Gould,Richard Everson,George De Ath,Nick Pepper*

Main category: cs.LG

TL;DR: 本文提出一种可解释的基于图神经网络（GNN）的框架，用于预测空中交通控制员任务需求，通过对飞机交互的分析，实现更准确的复杂性评估。


<details>
  <summary>Details</summary>
Motivation: 现有的复杂性指标无法有效捕捉超越单纯飞机数量的操作驱动因素，因此需要更先进的评估方法来支持日益拥挤的空域管理。

Method: 采用基于注意力机制的图神经网络模型，预测空中交通控制员在静态交通场景中的任务指令，通过系统性的剔除分析提供单机层面的任务需求得分。

Result: 框架在准确性上远优于基于经验的启发式方法和传统的基准方法，并能够提供对任务需求来源的准确定性分析。

Conclusion: 该工具可用于分析和理解任务复杂性的驱动因素，在交通控制员培训和空域重新设计方面具有重要应用价值。

Abstract: Real-time assessment of near-term Air Traffic Controller (ATCO) task demand
is a critical challenge in an increasingly crowded airspace, as existing
complexity metrics often fail to capture nuanced operational drivers beyond
simple aircraft counts. This work introduces an interpretable Graph Neural
Network (GNN) framework to address this gap. Our attention-based model predicts
the number of upcoming clearances, the instructions issued to aircraft by
ATCOs, from interactions within static traffic scenarios. Crucially, we derive
an interpretable, per-aircraft task demand score by systematically ablating
aircraft and measuring the impact on the model's predictions. Our framework
significantly outperforms an ATCO-inspired heuristic and is a more reliable
estimator of scenario complexity than established baselines. The resulting tool
can attribute task demand to specific aircraft, offering a new way to analyse
and understand the drivers of complexity for applications in controller
training and airspace redesign.

</details>


### [156] [Improving Out-of-distribution Human Activity Recognition via IMU-Video Cross-modal Representation Learning](https://arxiv.org/abs/2507.13482)
*Seyyed Saeid Cheshmi,Buyao Lyu,Thomas Lisko,Rajesh Rajamani,Robert A. McGovern,Yogatheesan Varatharajah*

Main category: cs.LG

TL;DR: 提出一种基于大规模未标记IMU视频数据的跨模态自监督预训练方法，用于提升人体运动识别在分布外数据上的泛化性，特别是在患帕金森病患者的数据集上表现突出。


<details>
  <summary>Details</summary>
Motivation: 针对现有基于自动化运动辨识的机器学习方法依赖特定应用标签，缺乏在不同环境或人群中推广能力的问题，提出提升HAR在分布外数据有效性的新方法。

Method: 提出了基于IMU与视频数据的跨模态自监督预训练方法，利用大规模未标记IMU视频数据训练模型，并与现有方法进行对比实验。

Result: 验证了这种预训练方法在分布外IMU数据集上的优越性，尤其是在零样本和小样本情况下超越了现有技术水平。

Conclusion: 跨模态自监督预训练在高动态数据（如IMU信号）中表现出潜力，是提升数据表征学习泛化性的有效工具。

Abstract: Human Activity Recognition (HAR) based on wearable inertial sensors plays a
critical role in remote health monitoring. In patients with movement disorders,
the ability to detect abnormal patient movements in their home environments can
enable continuous optimization of treatments and help alert caretakers as
needed. Machine learning approaches have been proposed for HAR tasks using
Inertial Measurement Unit (IMU) data; however, most rely on
application-specific labels and lack generalizability to data collected in
different environments or populations. To address this limitation, we propose a
new cross-modal self-supervised pretraining approach to learn representations
from large-sale unlabeled IMU-video data and demonstrate improved
generalizability in HAR tasks on out of distribution (OOD) IMU datasets,
including a dataset collected from patients with Parkinson's disease.
Specifically, our results indicate that the proposed cross-modal pretraining
approach outperforms the current state-of-the-art IMU-video pretraining
approach and IMU-only pretraining under zero-shot and few-shot evaluations.
Broadly, our study provides evidence that in highly dynamic data modalities,
such as IMU signals, cross-modal pretraining may be a useful tool to learn
generalizable data representations. Our software is available at
https://github.com/scheshmi/IMU-Video-OOD-HAR.

</details>


### [157] [Model-free Reinforcement Learning for Model-based Control: Towards Safe, Interpretable and Sample-efficient Agents](https://arxiv.org/abs/2507.13491)
*Thomas Banker,Ali Mesbah*

Main category: cs.LG

TL;DR: 本文探讨了通过结合模型驱动和无模型强化学习，来开发高效、安全且可解释的自主决策代理的可能性。


<details>
  <summary>Details</summary>
Motivation: 无模型强化学习在现代自主系统中应用广泛，但其样本效率低、不安全性高且可解释性较差的问题阻碍了进一步发展。

Method: 提出利用模型驱动代理作为控制策略的逼近方法，通过系统的动态、成本和约束模型进行安全的策略学习，同时结合无模型强化学习的优势以解决模型失配问题。

Result: 详细分析了模型驱动代理的优点与基于模型的主要学习方法，包括贝叶斯优化、策略搜索和离线策略的强项及挑战。

Conclusion: 结合模型驱动与无模型的学习方法有潜力实现样本高效、安全且可解释的自主决策代理。

Abstract: Training sophisticated agents for optimal decision-making under uncertainty
has been key to the rapid development of modern autonomous systems across
fields. Notably, model-free reinforcement learning (RL) has enabled
decision-making agents to improve their performance directly through system
interactions, with minimal prior knowledge about the system. Yet, model-free RL
has generally relied on agents equipped with deep neural network function
approximators, appealing to the networks' expressivity to capture the agent's
policy and value function for complex systems. However, neural networks amplify
the issues of sample inefficiency, unsafe learning, and limited
interpretability in model-free RL. To this end, this work introduces
model-based agents as a compelling alternative for control policy
approximation, leveraging adaptable models of system dynamics, cost, and
constraints for safe policy learning. These models can encode prior system
knowledge to inform, constrain, and aid in explaining the agent's decisions,
while deficiencies due to model mismatch can be remedied with model-free RL. We
outline the benefits and challenges of learning model-based agents --
exemplified by model predictive control -- and detail the primary learning
approaches: Bayesian optimization, policy search RL, and offline strategies,
along with their respective strengths. While model-free RL has long been
established, its interplay with model-based agents remains largely unexplored,
motivating our perspective on their combined potentials for sample-efficient
learning of safe and interpretable decision-making agents.

</details>


### [158] [Fake or Real: The Impostor Hunt in Texts for Space Operations](https://arxiv.org/abs/2507.13508)
*Agata Kaczmarek,Dawid Płudowski,Piotr Wilczyński,Przemysław Biecek,Krzysztof Kotowski,Ramez Shendy,Jakub Nalepa,Artur Janicki,Evridiki Ntagiou*

Main category: cs.LG

TL;DR: 本论文提出了一项关于使用人工智能区分真实与伪造输出的竞赛。


<details>
  <summary>Details</summary>
Motivation: 通过大赛探讨LLMs的潜在安全威胁问题，如数据中毒和过度依赖问题。

Method: 要求参赛者开发新的技术或调整现有方法以区分LLM的正常输出和恶意修改的输出。

Result: 竞赛方案详情未给出具体结果描述。

Conclusion: 这是LLM安全性相关领域的一次创新尝试，旨在推动相关技术的研究与应用探索。

Abstract: The "Fake or Real" competition hosted on Kaggle
(\href{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt}{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt})
is the second part of a series of follow-up competitions and hackathons related
to the "Assurance for Space Domain AI Applications" project funded by the
European Space Agency
(\href{https://assurance-ai.space-codev.org/}{https://assurance-ai.space-codev.org/}).
The competition idea is based on two real-life AI security threats identified
within the project -- data poisoning and overreliance in Large Language Models.
The task is to distinguish between the proper output from LLM and the output
generated under malicious modification of the LLM. As this problem was not
extensively researched, participants are required to develop new techniques to
address this issue or adjust already existing ones to this problem's statement.

</details>


### [159] [Provable Low-Frequency Bias of In-Context Learning of Representations](https://arxiv.org/abs/2507.13540)
*Yongyi Yang,Hidenori Tanaka,Wei Hu*

Main category: cs.LG

TL;DR: 该论文对大语言模型（LLMs）在上下文学习（ICL）中的能力提出了一种解释，表明其通过“双重收敛”过程来实现隐式偏向低频表示，并对许多实证现象进行了理论解释和验证。


<details>
  <summary>Details</summary>
Motivation: 当前尚未清楚大语言模型在上下文学习中如何通过提示的数据生成过程内部化结构，超越预训练阶段所学内容，本文试图解决这一问题。

Method: 引入统一的“双重收敛”框架，解释隐藏表示在上下文和层之间如何收敛，并分析其隐式诱导的平滑低频表示偏好，同时通过理论和实证验证提出的理论。

Result: 验证了双重收敛框架的预测能力，解释了隐藏表示的几何结构特性和能量衰减特性，并证实了其对高频噪声的内在鲁棒性。

Conclusion: 文章提供了对上下文学习机制的新见解，并建立了理论基础，这些发现或可推广到更一般的数据分布和设置中。

Abstract: In-context learning (ICL) enables large language models (LLMs) to acquire new
behaviors from the input sequence alone without any parameter updates. Recent
studies have shown that ICL can surpass the original meaning learned in
pretraining stage through internalizing the structure the data-generating
process (DGP) of the prompt into the hidden representations. However, the
mechanisms by which LLMs achieve this ability is left open. In this paper, we
present the first rigorous explanation of such phenomena by introducing a
unified framework of double convergence, where hidden representations converge
both over context and across layers. This double convergence process leads to
an implicit bias towards smooth (low-frequency) representations, which we prove
analytically and verify empirically. Our theory explains several open empirical
observations, including why learned representations exhibit globally structured
but locally distorted geometry, and why their total energy decays without
vanishing. Moreover, our theory predicts that ICL has an intrinsic robustness
towards high-frequency noise, which we empirically confirm. These results
provide new insights into the underlying mechanisms of ICL, and a theoretical
foundation to study it that hopefully extends to more general data
distributions and settings.

</details>


### [160] [Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk Stratification Using Echocardiography](https://arxiv.org/abs/2507.13542)
*Beka Begiashvili,Carlos J. Fernandez-Candel,Matías Pérez Paredes*

Main category: cs.LG

TL;DR: 本研究提出了一种新型AI参数“声学指数”，用于早期检测心脏功能障碍，结合Koopman算子理论和混合神经网络，在大规模临床数据中表现出高效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的心脏超声参数如射血分数(EF)和全球纵向应变(GLS)在检测早期心脏功能障碍上存在局限性，研究意在开发一种可重复且无需人为干预的参数以捕捉心脏功能的全局变化。

Method: 引入了基于Koopman算子理论的扩展动态模态分解(EDMD)结合混合神经网络的模型，从超声图像序列中提取时空动态，用注意力机制权重运动模式，并与临床数据融合，生成0到1连续评分。

Result: 在736名患者的队列实验中，“声学指数”在独立测试集中实现了AUC 0.89，五折交叉验证显示灵敏度和特异性均超过0.8。

Conclusion: “声学指数”作为一种基于物理模型的AI生物标志物，展示了在早期检测、筛查及纵向监测心脏功能上的应用潜力，但需进一步验证和疾病特异性优化。

Abstract: Traditional echocardiographic parameters such as ejection fraction (EF) and
global longitudinal strain (GLS) have limitations in the early detection of
cardiac dysfunction. EF often remains normal despite underlying pathology, and
GLS is influenced by load conditions and vendor variability. There is a growing
need for reproducible, interpretable, and operator-independent parameters that
capture subtle and global cardiac functional alterations.
  We introduce the Acoustic Index, a novel AI-derived echocardiographic
parameter designed to quantify cardiac dysfunction from standard ultrasound
views. The model combines Extended Dynamic Mode Decomposition (EDMD) based on
Koopman operator theory with a hybrid neural network that incorporates clinical
metadata. Spatiotemporal dynamics are extracted from echocardiographic
sequences to identify coherent motion patterns. These are weighted via
attention mechanisms and fused with clinical data using manifold learning,
resulting in a continuous score from 0 (low risk) to 1 (high risk).
  In a prospective cohort of 736 patients, encompassing various cardiac
pathologies and normal controls, the Acoustic Index achieved an area under the
curve (AUC) of 0.89 in an independent test set. Cross-validation across five
folds confirmed the robustness of the model, showing that both sensitivity and
specificity exceeded 0.8 when evaluated on independent data. Threshold-based
analysis demonstrated stable trade-offs between sensitivity and specificity,
with optimal discrimination near this threshold.
  The Acoustic Index represents a physics-informed, interpretable AI biomarker
for cardiac function. It shows promise as a scalable, vendor-independent tool
for early detection, triage, and longitudinal monitoring. Future directions
include external validation, longitudinal studies, and adaptation to
disease-specific classifiers.

</details>


### [161] [Time Series Forecastability Measures](https://arxiv.org/abs/2507.13556)
*Rui Wang,Steven Klee,Alexis Roos*

Main category: cs.LG

TL;DR: 本文提出了两种指标：光谱可预测性评分和最大Lyapunov指数，用于在开发预测模型前量化时间序列的可预测性。


<details>
  <summary>Details</summary>
Motivation: 传统模型评估指标不能在预测尝试前预先评估数据的固有可预测性特征，因此需要新的方法。

Method: 提出了光谱可预测性评分（评估频率成分的强度和规律性）和最大Lyapunov指数（量化生成系统的混沌和稳定性），并在合成数据与M5预测竞赛数据集上验证其有效性。

Result: 实验表明这两种指标能够正确反映时间序列的固有可预测性，并与各类模型的实际预测性能具有较强相关性。

Conclusion: 通过提前了解时间序列的固有可预测性，实践者可集中精力于更具预测性的产品及供应链层级，同时为可预测性有限的产品设定合理期望或寻找替代策略。

Abstract: This paper proposes using two metrics to quantify the forecastability of time
series prior to model development: the spectral predictability score and the
largest Lyapunov exponent. Unlike traditional model evaluation metrics, these
measures assess the inherent forecastability characteristics of the data before
any forecast attempts. The spectral predictability score evaluates the strength
and regularity of frequency components in the time series, whereas the Lyapunov
exponents quantify the chaos and stability of the system generating the data.
We evaluated the effectiveness of these metrics on both synthetic and
real-world time series from the M5 forecast competition dataset. Our results
demonstrate that these two metrics can correctly reflect the inherent
forecastability of a time series and have a strong correlation with the actual
forecast performance of various models. By understanding the inherent
forecastability of time series before model training, practitioners can focus
their planning efforts on products and supply chain levels that are more
forecastable, while setting appropriate expectations or seeking alternative
strategies for products with limited forecastability.

</details>


### [162] [Change of Thought: Adaptive Test-Time Computation](https://arxiv.org/abs/2507.13569)
*Mrinal Mathur,Mike Doan,Barak Pearlmutter,Sergey Plis*

Main category: cs.LG

TL;DR: 提出了一种名为SELF-Transformer的新型编码器Transformer，能够通过迭代优化注意力权重来提高模型表现。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer因单次固定深度的处理限制了其表达能力，需要通过自回归或链式思维来提升，该方法需要外部反馈回路，这与人类无需外部化中间状态进行推理的方式不同。

Method: 引入SELF-Transformer，编码过程中通过内部迭代优化注意力权重，达到一种固定点，从而提升模型的表达能力和适应性，而非依赖单次处理或自回归。

Result: 在不增加参数数量的情况下，在编码器类型基准测试中提升了高达20%的准确率，同时节省了额外计算资源。

Conclusion: SELF-Transformer可以在不增加复杂性的情况下恢复迭代推理的表达能力，同时保留简洁的编码器架构。

Abstract: Transformers evaluated in a single, fixed-depth pass are provably limited in
expressive power to the constant-depth circuit class TC0. Running a Transformer
autoregressively removes that ceiling -- first in next-token prediction and,
more recently, in chain-of-thought reasoning. Both regimes rely on feedback
loops that decode internal states into tokens only to re-encode them in
subsequent steps. While this "thinking aloud" mirrors human reasoning,
biological brains iterate without externalising intermediate states as
language. To boost the expressive power of encoder Transformers without
resorting to token-level autoregression, we introduce the SELF-Transformer: an
encoder layer that iteratively refines its own attention weights to a fixed
point. Instead of producing -- in one pass -- the alignment matrix that remixes
the input sequence, the SELF-Transformer iteratively updates that matrix
internally, scaling test-time computation with input difficulty. This
adaptivity yields up to 20\% accuracy gains on encoder-style benchmarks without
increasing parameter count, demonstrating that input-adaptive alignment at test
time offers substantial benefits for only a modest extra compute budget.
Self-Transformers thus recover much of the expressive power of iterative
reasoning while preserving the simplicity of pure encoder architectures.

</details>


### [163] [Apple Intelligence Foundation Language Models: Tech Report 2025](https://arxiv.org/abs/2507.13575)
*Hanzhi Zhou,Erik Hornberger,Pengsheng Guo,Xiyou Zhou,Saiwen Wang,Xin Wang,Yifei He,Xuankai Chang,Rene Rauch,Louis D'hauwe,John Peebles,Alec Doane,Kohen Chia,Jenna Thibodeau,Zi-Yi Dou,Yuanyang Zhang,Ruoming Pang,Reed Li,Zhifeng Chen,Jeremy Warner,Zhaoyang Xu,Sophy Lee,David Mizrahi,Ramsey Tantawi,Chris Chaney,Kelsey Peterson,Jun Qin,Alex Dombrowski,Mira Chiang,Aiswarya Raghavan,Gerard Casamayor,Qibin Chen,Aonan Zhang,Nathalie Tran,Jianyu Wang,Hang Su,Thomas Voice,Alessandro Pappalardo,Brycen Wershing,Prasanth Yadla,Rui Li,Priyal Chhatrapati,Ismael Fernandez,Yusuf Goren,Xin Zheng,Forrest Huang,Tao Lei,Eray Yildiz,Alper Kokmen,Gokul Santhanam,Areeba Kamal,Kaan Elgin,Dian Ang Yap,Jeremy Liu,Peter Gray,Howard Xing,Kieran Liu,Matteo Ronchi,Moritz Schwarzer-Becker,Yun Zhu,Mandana Saebi,Jeremy Snow,David Griffiths,Guillaume Tartavel,Erin Feldman,Simon Lehnerer,Fernando Bermúdez-Medina,Hans Han,Joe Zhou,Xiaoyi Ren,Sujeeth Reddy,Zirui Wang,Tom Gunter,Albert Antony,Yuanzhi Li,John Dennison,Tony Sun,Yena Han,Yi Qin,Sam Davarnia,Jeffrey Bigham,Wayne Shan,Hannah Gillis Coleman,Guillaume Klein,Peng Liu,Muyang Yu,Jack Cackler,Yuan Gao,Crystal Xiao,Binazir Karimzadeh,Zhengdong Zhang,Felix Bai,Albin Madappally Jose,Feng Nan,Nazir Kamaldin,Dong Yin,Hans Hao,Yanchao Sun,Yi Hua,Charles Maalouf,Alex Guillen Garcia,Guoli Yin,Lezhi Li,Mohana Prasad Sathya Moorthy,Hongbin Gao,Jay Tang,Joanna Arreaza-Taylor,Faye Lao,Carina Peng,Josh Shaffer,Dan Masi,Sushma Rao,Tommi Vehvilainen,Senyu Tong,Dongcai Shen,Yang Zhao,Chris Bartels,Peter Fu,Qingqing Cao,Christopher Neubauer,Ethan Li,Mingfei Gao,Rebecca Callahan,Richard Wei,Patrick Dong,Alex Braunstein,Sachin Ravi,Adolfo Lopez Mendez,Kaiwei Huang,Kun Duan,Haoshuo Huang,Rui Qian,Stefano Ligas,Jordan Huffaker,Dongxu Li,Bailin Wang,Nanzhu Wang,Anuva Agarwal,Tait Madsen,Josh Newnham,Abhishek Sharma,Zhile Ren,Deepak Gopinath,Erik Daxberger,Saptarshi Guha,Oron Levy,Jing Lu,Nan Dun,Marc Kirchner,Yinfei Yang,Manjot Bilkhu,Dave Nelson,Anthony Spalvieri-Kruse,Juan Lao Tebar,Yang Xu,Phani Mutyala,Gabriel Jacoby-Cooper,Yingbo Wang,Karla Vega,Vishaal Mahtani,Darren Botten,Eric Wang,Hanli Li,Matthias Paulik,Haoran Yan,Navid Shiee,Yihao Qian,Bugu Wu,Qi Zhu,Ob Adaranijo,Bhuwan Dhingra,Zhe Gan,Nicholas Seidl,Grace Duanmu,Rong Situ,Yiping Ma,Yin Xia,David Riazati,Vasileios Saveris,Anh Nguyen,Michael,Lee,Patrick Sonnenberg,Chinguun Erdenebileg,Yanghao Li,Vivian Ma,James Chou,Isha Garg,Mark Lee,Keen You,Yuhong Li,Ransen Niu,Nandhitha Raghuram,Pulkit Agrawal,Henry Mason,Sumeet Singh,Keyu He,Hong-You Chen,Lucas Guibert,Shiyu Li,Varsha Paidi,Narendran Raghavan,Mingze Xu,Yuli Yang,Sergiu Sima,Irina Belousova,Sprite Chu,Afshin Dehghan,Philipp Dufter,David Haldimann,Zhen Yang,Margit Bowler,Chang Liu,Ying-Chang Cheng,Vivek Rathod,Syd Evans,Wilson Tsao,Dustin Withers,Haitian Sun,Biyao Wang,Peter Grasch,Walker Cheng,Yihao Feng,Vivek Kumar,Frank Chu,Victoria MönchJuan Haladjian,Doug Kang,Jiarui Lu,Ciro Sannino,Max Lam,Floris Weers,Bowen Pan,Kenneth Jung,Dhaval Doshi,Fangping Shi,Olli Saarikivi,Alp Aygar,Josh Elman,Cheng Leong,Eshan Verma,Matthew Lei,Jeff Nichols,Jiulong Shan,Donald Zhang,Lawrence Zhou,Stephen Murphy,Xianzhi Du,Chang Lan,Ankur Jain,Elmira Amirloo,Marcin Eichner,Naomy Sabo,Anupama Mann Anupama,David Qiu,Zhao Meng,Michael FitzMaurice,Peng Zhang,Simon Yeung,Chen Chen,Marco Zuliani,Andrew Hansen,Yang Lu,Brent Ramerth,Ziyi Zhong,Parsa Mazaheri,Matthew Hopkins,Mengyu Li,Simon Wang,David Chen,Farzin Rasteh,Chong Wang,Josh Gardner,Asaf Liberman,Haoxuan You,Andrew Walkingshaw,Xingyu Zhou,Jinhao Lei,Yan Meng,Quentin Keunebroek,Sam Wiseman,Anders Boesen Lindbo Larsen,Yi Zhang,Zaid Ahmed,Haiming Gang,Aaron Franklin,Kelvin Zou,Guillaume Seguin,Jonathan Janke,Rachel Burger,Co Giang,Cheng Shen,Jen Liu,Sanskruti Shah,Xiang Kong,Yiran Fei,TJ Collins,Chen Zhang,Zhiyun Lu,Michael Booker,Qin Ba,Yasutaka Tanaka,Andres Romero Mier Y Teran,Federico Scozzafava,Regan Poston,Jane Li,Eduardo Jimenez,Bas Straathof,Karanjeet Singh,Lindsay Hislop,Rajat Arora,Deepa Seshadri,Boyue Li,Colorado Reed,Zhen Li,TJ Lu,Yi Wang,Kaelen Haag,Nicholas Lusskin,Raunak Sinha,Rahul Nair,Eldon Schoop,Mary Beth Kery,Mehrdad Farajtbar,Brenda Yang,George Horrell,Shiwen Zhao,Dhruti Shah,Cha Chen,Bowen Zhang,Chang Gao,Devi Krishna,Jennifer Mallalieu,Javier Movellan,Di Feng,Emily Zhang,Sam Xu,Junting Pan,Dominik Moritz,Suma Jayaram,Kevin Smith,Dongseong Hwang,Daniel Parilla,Jiaming Hu,You-Cyuan Jhang,Emad Soroush,Fred Hohman,Nan Du,Emma Wang,Sam Dodge,Pragnya Sridhar,Joris Pelemans,Wei Fang,Nina Wenzel,Joseph Yitan Cheng,Hadas Kotek,Chung-Cheng Chiu,Meng Cao,Haijing Fu,Ruixuan Hou,Ke Ye,Diane Zhu,Nikhil Bhendawade,Joseph Astrauskas,Jian Liu,Sai Aitharaju,Wentao Wu,Artsiom Peshko,Hyunjik Kim,Nilesh Shahdadpuri,Andy De Wang,Qi Shan,Piotr Maj,Raul Rea Menacho,Justin Lazarow,Eric Liang Yang,Arsalan Farooq,Donghan Yu,David Güera,Minsik Cho,Kavya Nerella,Yongqiang Wang,Tao Jia,John Park,Jeff Lai,Haotian Zhang,Futang Peng,Daniele Molinari,Aparna Rajamani,Tyler Johnson,Lauren Gardiner,Chao Jia,Violet Yao,Wojciech Kryscinski,Xiujun Li,Shang-Chen Wu*

Main category: cs.LG

TL;DR: 苹果推出两种多语言、多模态基础语言模型：一款为3B参数的设备端模型，另一款为具有PT-MoE架构的服务器端模型。


<details>
  <summary>Details</summary>
Motivation: 提升苹果设备与服务的智能特性，为多语言和多模态提供支持，同时保障用户隐私与AI内容的责任性。

Method: 设备端模型通过KV缓存共享和2位量化感知训练进行优化；服务器端通过PT-MoE变换器结合轨道并行、稀疏计算和全局-局部注意力；大规模多语言和多模态数据集训练，结合强化学习与监督微调。

Result: 两种模型在公共基准测试和人类评估中表现优异且超越同类开源模型；Swift框架支持相关开发集成。

Conclusion: 新模型显著提高了多语言和多模态处理能力，以责任AI和隐私保护为核心，推动开发者更多应用场景。

Abstract: We introduce two multilingual, multimodal foundation language models that
power Apple Intelligence features across Apple devices and services: i a
3B-parameter on-device model optimized for Apple silicon through architectural
innovations such as KV-cache sharing and 2-bit quantization-aware training; and
ii a scalable server model built on a novel Parallel-Track Mixture-of-Experts
PT-MoE transformer that combines track parallelism, mixture-of-experts sparse
computation, and interleaved global-local attention to deliver high quality
with competitive cost on Apple's Private Cloud Compute platform. Both models
are trained on large-scale multilingual and multimodal datasets sourced via
responsible web crawling, licensed corpora, and high-quality synthetic data,
then further refined with supervised fine-tuning and reinforcement learning on
a new asynchronous platform. The resulting models support several additional
languages while understanding images and executing tool calls. In public
benchmarks and human evaluations, both the server model and the on-device model
match or surpass comparably sized open baselines.
  A new Swift-centric Foundation Models framework exposes guided generation,
constrained tool calling, and LoRA adapter fine-tuning, allowing developers to
integrate these capabilities with a few lines of code. The latest advancements
in Apple Intelligence models are grounded in our Responsible AI approach with
safeguards like content filtering and locale-specific evaluation, as well as
our commitment to protecting our users' privacy with innovations like Private
Cloud Compute.

</details>


### [164] [Learning Pluralistic User Preferences through Reinforcement Learning Fine-tuned Summaries](https://arxiv.org/abs/2507.13579)
*Hyunji Nam,Yanming Wan,Mickel Liu,Jianxun Lian,Natasha Jaques*

Main category: cs.LG

TL;DR: 该论文提出了大语言模型LLM个性化响应的新框架，通过总结用户偏好资料实现个性化预测，优化当前的RLHF方法。


<details>
  <summary>Details</summary>
Motivation: 当前的RLHF模型无法考虑用户之间的偏好和需求差异，个性化是LLM应用的重要需求。

Method: 提出一种名为PLUS的新框架，通过学习用户偏好和特征的文本摘要来条件化奖励模型，并使用强化学习同时更新用户摘要模型与奖励模型。

Result: 验证了这种方法对新用户和不同对话主题的鲁棒性，并证明生成的用户摘要适合迁移到强大的模型如GPT-4进行零样本个性化。

Conclusion: 用户摘要不仅便于解释和修改，还增加了系统透明性和用户对LLM调整的控制能力，提升了个性化能力。

Abstract: As everyday use cases of large language model (LLM) AI assistants have
expanded, it is becoming increasingly important to personalize responses to
align to different users' preferences and goals. While reinforcement learning
from human feedback (RLHF) is effective at improving LLMs to be generally more
helpful and fluent, it does not account for variability across users, as it
models the entire user population with a single reward model. We present a
novel framework, Preference Learning Using Summarization (PLUS), that learns
text-based summaries of each user's preferences, characteristics, and past
conversations. These summaries condition the reward model, enabling it to make
personalized predictions about the types of responses valued by each user. We
train the user-summarization model with reinforcement learning, and update the
reward model simultaneously, creating an online co-adaptation loop. We show
that in contrast with prior personalized RLHF techniques or with in-context
learning of user information, summaries produced by PLUS capture meaningful
aspects of a user's preferences. Across different pluralistic user datasets, we
show that our method is robust to new users and diverse conversation topics.
Additionally, we demonstrate that the textual summaries generated about users
can be transferred for zero-shot personalization of stronger, proprietary
models like GPT-4. The resulting user summaries are not only concise and
portable, they are easy for users to interpret and modify, allowing for more
transparency and user control in LLM alignment.

</details>


### [165] [Off-Policy Evaluation and Learning for Matching Markets](https://arxiv.org/abs/2507.13608)
*Yudai Hayashi,Shuhei Goda,Yuta Saito*

Main category: cs.LG

TL;DR: 本文提出了两种新型的OPE估计方法，特别为匹配市场设计，以解决传统方法在离线评估的偏差和方差问题，使推荐策略实现更好效果。


<details>
  <summary>Details</summary>
Motivation: 匹配市场中的推荐系统需要可靠的离线评估方法，但传统OPE方法存在方差过大和奖励稀疏问题，这影响了其实用性。

Method: 提出了DiPS和DPR两种方法，结合了直接方法、逆倾向得分和双重鲁棒估计，同时引入中间标注（如初始交互信号）以优化偏差-方差控制。

Result: 理论分析了新方法的偏差和方差，实验证明其在合成数据和真实求职平台A/B测试日志中优于现有方法。

Conclusion: 新提出的DiPS和DPR估计器显著改进了匹配市场中的离线评估及学习能力，有潜力提升推荐策略下的匹配效果。

Abstract: Matching users based on mutual preferences is a fundamental aspect of
services driven by reciprocal recommendations, such as job search and dating
applications. Although A/B tests remain the gold standard for evaluating new
policies in recommender systems for matching markets, it is costly and
impractical for frequent policy updates. Off-Policy Evaluation (OPE) thus plays
a crucial role by enabling the evaluation of recommendation policies using only
offline logged data naturally collected on the platform. However, unlike
conventional recommendation settings, the large scale and bidirectional nature
of user interactions in matching platforms introduce variance issues and
exacerbate reward sparsity, making standard OPE methods unreliable. To address
these challenges and facilitate effective offline evaluation, we propose novel
OPE estimators, \textit{DiPS} and \textit{DPR}, specifically designed for
matching markets. Our methods combine elements of the Direct Method (DM),
Inverse Propensity Score (IPS), and Doubly Robust (DR) estimators while
incorporating intermediate labels, such as initial engagement signals, to
achieve better bias-variance control in matching markets. Theoretically, we
derive the bias and variance of the proposed estimators and demonstrate their
advantages over conventional methods. Furthermore, we show that these
estimators can be seamlessly extended to offline policy learning methods for
improving recommendation policies for making more matches. We empirically
evaluate our methods through experiments on both synthetic data and A/B testing
logs from a real job-matching platform. The empirical results highlight the
superiority of our approach over existing methods in off-policy evaluation and
learning tasks for a variety of configurations.

</details>


### [166] [Tri-Learn Graph Fusion Network for Attributed Graph Clustering](https://arxiv.org/abs/2507.13620)
*Binxiong Li,Yuefei Wang,Xu Xiang,Xue Li,Binyu Zhao,Heyang Gao,Qinyu Zhao,Xi Yu*

Main category: cs.LG

TL;DR: 提出了一种新的深度聚类框架Tri-GFN，通过三通道增强模块和特征融合策略，显著提高了图聚类性能，在多个数据集上超过了最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有GCN模型存在过平滑和过压缩问题，而Graph Transformer在处理异质图数据时表现受限，需要更强大的图聚类方法。

Method: 提出一种名为Tri-GFN的框架，融合了GCN、AE和Graph Transformer模块，通过三学习机制和特征融合策略提升全局和局部信息的表现力。

Result: Tri-GFN在ACM、Reuters和USPS数据集上分别提高了0.87%、14.14%和7.58%的性能，尤其在Reuters数据集上表现突出。

Conclusion: Tri-GFN在处理复杂图数据的聚类任务上表现显著优越，具有潜在的实际应用价值，如新闻分类和主题检索。

Abstract: In recent years, models based on Graph Convolutional Networks (GCN) have made
significant strides in the field of graph data analysis. However, challenges
such as over-smoothing and over-compression remain when handling large-scale
and complex graph datasets, leading to a decline in clustering quality.
Although the Graph Transformer architecture has mitigated some of these issues,
its performance is still limited when processing heterogeneous graph data. To
address these challenges, this study proposes a novel deep clustering framework
that comprising GCN, Autoencoder (AE), and Graph Transformer, termed the
Tri-Learn Graph Fusion Network (Tri-GFN). This framework enhances the
differentiation and consistency of global and local information through a
unique tri-learning mechanism and feature fusion enhancement strategy. The
framework integrates GCN, AE, and Graph Transformer modules. These components
are meticulously fused by a triple-channel enhancement module, which maximizes
the use of both node attributes and topological structures, ensuring robust
clustering representation. The tri-learning mechanism allows mutual learning
among these modules, while the feature fusion strategy enables the model to
capture complex relationships, yielding highly discriminative representations
for graph clustering. It surpasses many state-of-the-art methods, achieving an
accuracy improvement of approximately 0.87% on the ACM dataset, 14.14 % on the
Reuters dataset, and 7.58 % on the USPS dataset. Due to its outstanding
performance on the Reuters dataset, Tri-GFN can be applied to automatic news
classification, topic retrieval, and related fields.

</details>


### [167] [Generalist Bimanual Manipulation via Foundation Video Diffusion Models](https://arxiv.org/abs/2507.12898)
*Yao Feng,Hengkai Tan,Xinyi Mao,Guodong Liu,Shuhe Huang,Chendong Xiang,Hang Su,Jun Zhu*

Main category: cs.LG

TL;DR: 引入VIDAR框架，通过视频扩散模型和新的掩码逆动力学模型实现机器人双臂操作，显著减少数据需求并提高任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决机器人双臂操作中的数据不足和异构性问题，以推动机器人操作的扩展和应用。

Method: 提出VIDAR框架，分为两阶段：首先以扩散式视频预训练模型学习场景和任务上下文；其次通过掩码逆动力学模型进行动作预测，无需像素级标签。

Result: 实现了仅需20分钟的人类示范即可在新机器人平台上完成任务，超越现有技术，具备强泛化能力。

Conclusion: 视频基础模型和掩码动作预测结合的框架有效推动了机器人操作在复杂场景中的随规模扩展和普适性应用的潜力。

Abstract: Bimanual robotic manipulation, which involves the coordinated control of two
robotic arms, is foundational for solving challenging tasks. Despite recent
progress in general-purpose manipulation, data scarcity and embodiment
heterogeneity remain serious obstacles to further scaling up in bimanual
settings. In this paper, we introduce VIdeo Diffusion for Action Reasoning
(VIDAR), a two-stage framework that leverages large-scale, diffusion-based
video pre-training and a novel masked inverse dynamics model for action
prediction. We pre-train the video diffusion model on 750K multi-view videos
from three real-world bimanual robot platforms, utilizing a unified observation
space that encodes robot, camera, task, and scene contexts. Our masked inverse
dynamics model learns masks to extract action-relevant information from
generated trajectories without requiring pixel-level labels, and the masks can
effectively generalize to unseen backgrounds. Our experiments demonstrate that
with only 20 minutes of human demonstrations on an unseen robot platform (only
1% of typical data requirements), VIDAR generalizes to unseen tasks and
backgrounds with strong semantic understanding, surpassing state-of-the-art
methods. Our findings highlight the potential of video foundation models,
coupled with masked action prediction, to enable scalable and generalizable
robotic manipulation in diverse real-world settings.

</details>


### [168] [FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning](https://arxiv.org/abs/2507.13624)
*Daniel Commey,Kamel Abbad,Garth V. Crosby,Lyes Khoukhi*

Main category: cs.LG

TL;DR: FedSkipTwin 利用轻量级数字孪生客户端跳过机制，减少联邦学习通信开销的同时提升模型精度。


<details>
  <summary>Details</summary>
Motivation: 解决在带宽受限的移动及物联网设备中，联邦学习通信开销过高的问题。

Method: 提出 FedSkipTwin 算法，构建基于简单 LSTM 模型的数字孪生，预测客户端的梯度更新趋势和不确定性，并在特定条件下跳过通信。

Result: 在 UCI-HAR 和 MNIST 数据集上，FedSkipTwin 能在 20 轮中减少 12-15.5% 的总通信量，同时模型精度最高提升 0.5 个百分点。

Conclusion: FedSkipTwin 证明了在带宽受限的边缘环境中，预测驱动的跳过策略是一种实用且有效的联邦学习方法。

Abstract: Communication overhead remains a primary bottleneck in federated learning
(FL), particularly for applications involving mobile and IoT devices with
constrained bandwidth. This work introduces FedSkipTwin, a novel
client-skipping algorithm driven by lightweight, server-side digital twins.
Each twin, implemented as a simple LSTM, observes a client's historical
sequence of gradient norms to forecast both the magnitude and the epistemic
uncertainty of its next update. The server leverages these predictions,
requesting communication only when either value exceeds a predefined threshold;
otherwise, it instructs the client to skip the round, thereby saving bandwidth.
Experiments are conducted on the UCI-HAR and MNIST datasets with 10 clients
under a non-IID data distribution. The results demonstrate that FedSkipTwin
reduces total communication by 12-15.5% across 20 rounds while simultaneously
improving final model accuracy by up to 0.5 percentage points compared to the
standard FedAvg algorithm. These findings establish that prediction-guided
skipping is a practical and effective strategy for resource-aware FL in
bandwidth-constrained edge environments.

</details>


### [169] [A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design](https://arxiv.org/abs/2507.13646)
*Nimisha Ghosh,Daniele Santoni,Debaleena Nawn,Eleonora Ottaviani,Giovanni Felici*

Main category: cs.LG

TL;DR: 本文回顾了Transformer模型在蛋白质序列分析与设计中的应用，涵盖了多种研究方向并指出未来可能的研究方向。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在NLP的成功激发其在生物信息学领域中的应用，特别是在蛋白质序列分析与设计中的研究热情。

Method: 回顾并分析了大量关于Transformer在蛋白质分析应用的相关工作，包括功能与结构识别、新型蛋白生成、蛋白结合等方向。

Result: 总结了当前研究的长处与不足，并指出现有研究的短板与未来的可能改进空间。

Conclusion: 该综述为研究者提供了对当前领域现状的全面理解，帮助指导未来的研究方向。

Abstract: The impact of Transformer-based language models has been unprecedented in
Natural Language Processing (NLP). The success of such models has also led to
their adoption in other fields including bioinformatics. Taking this into
account, this paper discusses recent advances in Transformer-based models for
protein sequence analysis and design. In this review, we have discussed and
analysed a significant number of works pertaining to such applications. These
applications encompass gene ontology, functional and structural protein
identification, generation of de novo proteins and binding of proteins. We
attempt to shed light on the strength and weaknesses of the discussed works to
provide a comprehensive insight to readers. Finally, we highlight shortcomings
in existing research and explore potential avenues for future developments. We
believe that this review will help researchers working in this field to have an
overall idea of the state of the art in this field, and to orient their future
studies.

</details>


### [170] [Kolmogorov-Arnold Networks-based GRU and LSTM for Loan Default Early Prediction](https://arxiv.org/abs/2507.13685)
*Yue Yang,Zihan Su,Ying Zhang,Chang Chuan Goh,Yuxiang Lin,Anthony Graham Bellotti,Boon Giin Lee*

Main category: cs.LG

TL;DR: 本文提出将Kolmogorov-Arnold网络（KAN）与GRU和LSTM结合的GRU-KAN和LSTM-KAN架构，用于提升金融贷款违约的早期预测能力，尤其适用于时间跨度较大的预测场景。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测方法在早期预测方面准确性不足，并局限于特定年份和时间框架，无法有效处理跨时间数据。这限制了其实际应用，尤其在金融风险管理中的应用。

Method: 提出GRU-KAN和LSTM-KAN模型，将Kolmogorov-Arnold网络与GRU和LSTM结合，并通过多种指标（准确率、精确率、召回率等）对模型在预测窗口长度、样本量、早期预测时间上的性能进行了评估。

Result: 在提前三个月预测中，模型准确率超过92%；在提前八个月预测中，准确率超过88%，表现显著优于基线模型（LSTM、GRU、LSTM-Attention等）。

Conclusion: 通过引入创新的混合架构，GRU-KAN和LSTM-KAN在早期预测贷款违约方面展现了极高的准确性，为金融机构的风险预防措施提供了强有力的支持。

Abstract: This study addresses a critical challenge in time series anomaly detection:
enhancing the predictive capability of loan default models more than three
months in advance to enable early identification of default events, helping
financial institutions implement preventive measures before risk events
materialize. Existing methods have significant drawbacks, such as their lack of
accuracy in early predictions and their dependence on training and testing
within the same year and specific time frames. These issues limit their
practical use, particularly with out-of-time data. To address these, the study
introduces two innovative architectures, GRU-KAN and LSTM-KAN, which merge
Kolmogorov-Arnold Networks (KAN) with Gated Recurrent Units (GRU) and Long
Short-Term Memory (LSTM) networks. The proposed models were evaluated against
the baseline models (LSTM, GRU, LSTM-Attention, and LSTM-Transformer) in terms
of accuracy, precision, recall, F1 and AUC in different lengths of feature
window, sample sizes, and early prediction intervals. The results demonstrate
that the proposed model achieves a prediction accuracy of over 92% three months
in advance and over 88% eight months in advance, significantly outperforming
existing baselines.

</details>


### [171] [Binarizing Physics-Inspired GNNs for Combinatorial Optimization](https://arxiv.org/abs/2507.13703)
*Martin Krutský,Gustav Šír,Vyacheslav Kungurtsev,Georgios Korpas*

Main category: cs.LG

TL;DR: 本文探讨了物理启发的图神经网络（PI-GNNs）在组合优化问题上的性能，并提出方法改进其对密集图问题的适应性。


<details>
  <summary>Details</summary>
Motivation: 虽然PI-GNNs在许多组合优化问题上表现优秀，但对于更高密度的组合问题，其性能会显著下降。这种现象激发了研究者寻找解决方案来提升其训练效果。

Method: 通过分析PI-GNNs的训练动态，并参考模糊逻辑和二值化神经网络的原理，提出了一系列改进策略以替代现有的简单方法。

Result: 实验表明，新提出的方法显著提高了PI-GNNs在高密度场景下的表现。

Conclusion: 改进的策略可以缓解PI-GNNs在处理密集图时出现的性能退化问题，为处理复杂的组合优化问题提供了更广阔的前景。

Abstract: Physics-inspired graph neural networks (PI-GNNs) have been utilized as an
efficient unsupervised framework for relaxing combinatorial optimization
problems encoded through a specific graph structure and loss, reflecting
dependencies between the problem's variables. While the framework has yielded
promising results in various combinatorial problems, we show that the
performance of PI-GNNs systematically plummets with an increasing density of
the combinatorial problem graphs. Our analysis reveals an interesting phase
transition in the PI-GNNs' training dynamics, associated with degenerate
solutions for the denser problems, highlighting a discrepancy between the
relaxed, real-valued model outputs and the binary-valued problem solutions. To
address the discrepancy, we propose principled alternatives to the naive
strategy used in PI-GNNs by building on insights from fuzzy logic and binarized
neural networks. Our experiments demonstrate that the portfolio of proposed
methods significantly improves the performance of PI-GNNs in increasingly dense
settings.

</details>


### [172] [Bayesian Optimization for Molecules Should Be Pareto-Aware](https://arxiv.org/abs/2507.13704)
*Anabel Yong,Austin Tripp,Layla Hosseini-Gerami,Brooks Paige*

Main category: cs.LG

TL;DR: 研究比较了多目标贝叶斯优化（MOBO）与标量化替代策略在分子设计中的表现，发现Pareto-aware的MOBO策略在多个关键指标上有明显优势。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索多目标贝叶斯优化（MOBO）策略相比标量化替代方法在实证上的优势，特别是在分子设计任务中的表现。

Method: 通过对比简单的Pareto-based MOBO策略（EHVI）和固定权重标量化基准（EI）的方法，在相同的高斯过程模型和分子表示下，进行性能评估。

Result: EHVI在Pareto前沿覆盖率、收敛速度和化学多样性方面均明显优于标量化EI，尤其是在数据量较少、评估预算有限且权衡非平凡的情境中表现出色。

Conclusion: 研究证明了在新型分子优化问题中，与标量化方法相比，基于Pareto-aware的多目标贝叶斯优化具备显著的实际优势，特别是在资源有限的情况下。

Abstract: Multi-objective Bayesian optimization (MOBO) provides a principled framework
for navigating trade-offs in molecular design. However, its empirical
advantages over scalarized alternatives remain underexplored. We benchmark a
simple Pareto-based MOBO strategy -- Expected Hypervolume Improvement (EHVI) --
against a simple fixed-weight scalarized baseline using Expected Improvement
(EI), under a tightly controlled setup with identical Gaussian Process
surrogates and molecular representations. Across three molecular optimization
tasks, EHVI consistently outperforms scalarized EI in terms of Pareto front
coverage, convergence speed, and chemical diversity. While scalarization
encompasses flexible variants -- including random or adaptive schemes -- our
results show that even strong deterministic instantiations can underperform in
low-data regimes. These findings offer concrete evidence for the practical
advantages of Pareto-aware acquisition in de novo molecular optimization,
especially when evaluation budgets are limited and trade-offs are nontrivial.

</details>


### [173] [Learning Deformable Body Interactions With Adaptive Spatial Tokenization](https://arxiv.org/abs/2507.13707)
*Hao Wang,Yu Liu,Daniel Biggs,Haoru Wang,Jiandong Yu,Ping Huang*

Main category: cs.LG

TL;DR: 本文提出了一个基于自适应空间分块（AST）的方法，通过将非结构化网格映射到结构化网格，从而在物理模拟中有效表示物理状态，并利用注意力机制实现可扩展的仿真。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图神经网络的方法虽然在解决复杂物理系统方面表现出色，但在大规模可变形体交互建模中存在计算效率和可扩展性问题。

Method: 提出了一个自适应空间分块（AST）方法，将仿真空间划分为网格单元，将非结构化网格数据映射到此网格，然后通过交叉注意力模块将稀疏单元映射为紧凑的定长嵌入，利用自注意力模块在潜在空间中预测下一状态。

Result: 方法在大规模仿真、特别是包含超过10万个网格节点的可变形体交互建模中显著优于现有方法，同时提出了一个新的大规模数据集用于支持未来研究。

Conclusion: 该方法通过结合tokenization和注意力机制的优势，实现了精确且高效的大规模可变形体交互仿真。

Abstract: Simulating interactions between deformable bodies is vital in fields like
material science, mechanical design, and robotics. While learning-based methods
with Graph Neural Networks (GNNs) are effective at solving complex physical
systems, they encounter scalability issues when modeling deformable body
interactions. To model interactions between objects, pairwise global edges have
to be created dynamically, which is computationally intensive and impractical
for large-scale meshes. To overcome these challenges, drawing on insights from
geometric representations, we propose an Adaptive Spatial Tokenization (AST)
method for efficient representation of physical states. By dividing the
simulation space into a grid of cells and mapping unstructured meshes onto this
structured grid, our approach naturally groups adjacent mesh nodes. We then
apply a cross-attention module to map the sparse cells into a compact,
fixed-length embedding, serving as tokens for the entire physical state.
Self-attention modules are employed to predict the next state over these tokens
in latent space. This framework leverages the efficiency of tokenization and
the expressive power of attention mechanisms to achieve accurate and scalable
simulation results. Extensive experiments demonstrate that our method
significantly outperforms state-of-the-art approaches in modeling deformable
body interactions. Notably, it remains effective on large-scale simulations
with meshes exceeding 100,000 nodes, where existing methods are hindered by
computational limitations. Additionally, we contribute a novel large-scale
dataset encompassing a wide range of deformable body interactions to support
future research in this area.

</details>


### [174] [Benchmarking of EEG Analysis Techniques for Parkinson's Disease Diagnosis: A Comparison between Traditional ML Methods and Foundation DL Methods](https://arxiv.org/abs/2507.13716)
*Danilo Avola,Andrea Bernardini,Giancarlo Crocetti,Andrea Ladogana,Mario Lezoche,Maurizio Mancini,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 本研究评估了基于EEG的PD诊断中传统机器学习和深度学习模型的表现，揭示了CNN-LSTM模型的优越性，同时指出XGBoost等传统分类器的潜力。


<details>
  <summary>Details</summary>
Motivation: 针对Parkinson’s Disease，早期诊断非常重要。本研究希望通过系统性比较，找出最适合的模型，以改善基于EEG的自动诊断。

Method: 利用公开的oddball任务数据集，实施了统一的七步预处理流程，并采用一致的被试交叉验证与评估标准，比较传统机器学习和深度学习模型表现。

Result: 深度学习模型，尤其是CNN-LSTM表现最佳，但XGBoost等传统ML分类器也展现了较强的预测准确性和决策边界。

Conclusion: 研究为未来开发更复杂的EEG诊断模型奠定了基准，确保新方法改进有对照性，从而促进科学严谨性与可重复性。

Abstract: Parkinson's Disease PD is a progressive neurodegenerative disorder that
affects motor and cognitive functions with early diagnosis being critical for
effective clinical intervention Electroencephalography EEG offers a noninvasive
and costeffective means of detecting PDrelated neural alterations yet the
development of reliable automated diagnostic models remains a challenge In this
study we conduct a systematic benchmark of traditional machine learning ML and
deep learning DL models for classifying PD using a publicly available oddball
task dataset Our aim is to lay the groundwork for developing an effective
learning system and to determine which approach produces the best results We
implement a unified sevenstep preprocessing pipeline and apply consistent
subjectwise crossvalidation and evaluation criteria to ensure comparability
across models Our results demonstrate that while baseline deep learning
architectures particularly CNNLSTM models achieve the best performance compared
to other deep learning architectures underlining the importance of capturing
longrange temporal dependencies several traditional classifiers such as XGBoost
also offer strong predictive accuracy and calibrated decision boundaries By
rigorously comparing these baselines our work provides a solid reference
framework for future studies aiming to develop and evaluate more complex or
specialized architectures Establishing a reliable set of baseline results is
essential to contextualize improvements introduced by novel methods ensuring
scientific rigor and reproducibility in the evolving field of EEGbased
neurodiagnostics

</details>


### [175] [Bi-GRU Based Deception Detection using EEG Signals](https://arxiv.org/abs/2507.13718)
*Danilo Avola,Muhammad Yasir Bilal,Emad Emam,Cristina Lakasz,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 该研究利用EEG信号和Bi-GRU深度学习模型检测欺骗行为，达到97%准确率。


<details>
  <summary>Details</summary>
Motivation: 解决安全、心理学和法证学中欺骗行为检测的挑战。

Method: 使用来自Bag-of-Lies数据集的EEG信号，采用双向门控循环单元（Bi-GRU）模型进行二分类。

Result: 模型测试准确率达到97%，并在精度、召回率和F1评分方面表现优异。

Conclusion: Bi-GRU模型有效性验证，为基于EEG的即时欺骗检测及未来神经架构研究开拓了潜力。

Abstract: Deception detection is a significant challenge in fields such as security,
psychology, and forensics. This study presents a deep learning approach for
classifying deceptive and truthful behavior using ElectroEncephaloGram (EEG)
signals from the Bag-of-Lies dataset, a multimodal corpus designed for
naturalistic, casual deception scenarios. A Bidirectional Gated Recurrent Unit
(Bi-GRU) neural network was trained to perform binary classification of EEG
samples. The model achieved a test accuracy of 97\%, along with high precision,
recall, and F1-scores across both classes. These results demonstrate the
effectiveness of using bidirectional temporal modeling for EEG-based deception
detection and suggest potential for real-time applications and future
exploration of advanced neural architectures.

</details>


### [176] [Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion](https://arxiv.org/abs/2507.13721)
*Zizhao Zhang,Tianxiang Zhao,Yu Sun,Liping Sun,Jichuan Kang*

Main category: cs.LG

TL;DR: 该论文提出了一种混合特征融合框架，用于构建失效模式的图结构化数据集，并通过改进的布谷鸟搜索算法显著提高了文献检索效率，构建的系统在数据集和模型验证中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为解决自主货船部件失效引发的级联反应和紧急决策中不确定性问题，提出新的数据构建和分析方法。

Method: 使用改进的布谷鸟搜索算法提高检索效率，结合Word2Vec、BERT-KPCA处理特征，并通过GATE-GNN模型分类验证。

Result: 构建了包含12个系统、1262个失效模式和6150条传播路径的数据集。验证显示，GATE-GNN模型分类准确率为0.735，某些系统的F1得分达0.93。

Conclusion: 该研究为自主货船的失效分析、故障诊断和智能决策系统提供了可靠支持。

Abstract: To address the challenges posed by cascading reactions caused by component
failures in autonomous cargo ships (ACS) and the uncertainties in emergency
decision-making, this paper proposes a novel hybrid feature fusion framework
for constructing a graph-structured dataset of failure modes. By employing an
improved cuckoo search algorithm (HN-CSA), the literature retrieval efficiency
is significantly enhanced, achieving improvements of 7.1% and 3.4% compared to
the NSGA-II and CSA search algorithms, respectively. A hierarchical feature
fusion framework is constructed, using Word2Vec encoding to encode
subsystem/component features, BERT-KPCA to process failure modes/reasons, and
Sentence-BERT to quantify the semantic association between failure impact and
emergency decision-making. The dataset covers 12 systems, 1,262 failure modes,
and 6,150 propagation paths. Validation results show that the GATE-GNN model
achieves a classification accuracy of 0.735, comparable to existing benchmarks.
Additionally, a silhouette coefficient of 0.641 indicates that the features are
highly distinguishable. In the label prediction results, the Shore-based
Meteorological Service System achieved an F1 score of 0.93, demonstrating high
prediction accuracy. This paper not only provides a solid foundation for
failure analysis in autonomous cargo ships but also offers reliable support for
fault diagnosis, risk assessment, and intelligent decision-making systems. The
link to the dataset is
https://github.com/wojiufukele/Graph-Structured-about-CSA.

</details>


### [177] [Adversarial Training Improves Generalization Under Distribution Shifts in Bioacoustics](https://arxiv.org/abs/2507.13727)
*René Heinrich,Lukas Rauch,Bernhard Sick,Christoph Scholz*

Main category: cs.LG

TL;DR: 本文研究了对抗训练在音频分类中提升模型鲁棒性和泛化能力的潜力，尤其是在显著数据分布偏移下的情境。实验表明，对抗训练（尤其基于输出空间攻击的方法）显著加强了模型性能和对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探索对抗训练如何在音频分类面临显著数据分布偏移时，提升模型的泛化性能和对抗鲁棒性。

Method: 采用两种对抗训练策略：1) 基于输出空间攻击，最大化分类损失；2) 基于嵌入空间攻击，最大化嵌入差异。同时，在测试中进行对抗鲁棒性评估，并分析AudioProtoPNet原型的稳定性。

Result: 对抗训练（特别是输出空间攻击方法）在干净测试数据上平均提升10.5%的相对性能，同时增强了模型的对抗鲁棒性。

Conclusion: 尽管研究基于鸟声音域，结果表明对抗训练可在音频分类中应对分布偏移和对抗攻击，从而提升模型的鲁棒性。

Abstract: Adversarial training is a promising strategy for enhancing model robustness
against adversarial attacks. However, its impact on generalization under
substantial data distribution shifts in audio classification remains largely
unexplored. To address this gap, this work investigates how different
adversarial training strategies improve generalization performance and
adversarial robustness in audio classification. The study focuses on two model
architectures: a conventional convolutional neural network (ConvNeXt) and an
inherently interpretable prototype-based model (AudioProtoPNet). The approach
is evaluated using a challenging bird sound classification benchmark. This
benchmark is characterized by pronounced distribution shifts between training
and test data due to varying environmental conditions and recording methods, a
common real-world challenge. The investigation explores two adversarial
training strategies: one based on output-space attacks that maximize the
classification loss function, and another based on embedding-space attacks
designed to maximize embedding dissimilarity. These attack types are also used
for robustness evaluation. Additionally, for AudioProtoPNet, the study assesses
the stability of its learned prototypes under targeted embedding-space attacks.
Results show that adversarial training, particularly using output-space
attacks, improves clean test data performance by an average of 10.5% relative
and simultaneously strengthens the adversarial robustness of the models. These
findings, although derived from the bird sound domain, suggest that adversarial
training holds potential to enhance robustness against both strong distribution
shifts and adversarial attacks in challenging audio classification settings.

</details>


### [178] [An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC](https://arxiv.org/abs/2507.13736)
*Matthias Jobst,Tim Langer,Chen Liu,Mehmet Alici,Hector A. Gonzalez,Christian Mayr*

Main category: cs.LG

TL;DR: 这篇论文提出一个多层DNN调度框架，用于在SpiNNaker2芯片上高效执行大规模DNN推理任务。


<details>
  <summary>Details</summary>
Motivation: 目前需要高效地在边缘设备上执行复杂的深度神经网络，尤其是变压器规模的模型。

Method: 在OctopuScheduler的基础上扩展，结合量化和降维技术，形成完整的端到端工作流，从PyTorch模型映射到SpiNNaker2平台的执行。

Result: 使SpiNNaker2能够高效运行复杂DNN模型，大幅拓展其适用场景至包括变压器模型在内的大规模任务。

Conclusion: 提出的框架证明了SpiNNaker2在处理复杂DNN中的潜力，展示了边缘计算领域的最新进展。

Abstract: This work presents a multi-layer DNN scheduling framework as an extension of
OctopuScheduler, providing an end-to-end flow from PyTorch models to inference
on a single SpiNNaker2 chip. Together with a front-end comprised of
quantization and lowering steps, the proposed framework enables the edge-based
execution of large and complex DNNs up to transformer scale using the
neuromorphic platform SpiNNaker2.

</details>


### [179] [SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification](https://arxiv.org/abs/2507.13741)
*Shangyou Wang,Zezhong Ding,Xike Xie*

Main category: cs.LG

TL;DR: 提出SamGoG框架，通过采样和图上图机制解决图分类中的类别和图规模不平衡问题，支持高效嵌入和训练。


<details>
  <summary>Details</summary>
Motivation: 解决实际图数据中，类别不平衡和图大小不平衡对GNN性能的影响问题。

Method: 提出基于采样的Graph-of-Graphs (GoG)学习框架SamGoG，使用重要性采样机制生成多个GoG，并通过可学习的相似性和自适应GoG节点度数增强边同质性。

Result: 在基准数据集上的实验表明，SamGoG性能达到最先进水平，准确率提高达15.66%，且训练加速达6.7倍。

Conclusion: SamGoG框架适应性强，可与多种GNN集成，在解决实用问题的同时显著提升图分类的精度和效率。

Abstract: Graph Neural Networks (GNNs) have shown remarkable success in graph
classification tasks by capturing both structural and feature-based
representations. However, real-world graphs often exhibit two critical forms of
imbalance: class imbalance and graph size imbalance. These imbalances can bias
the learning process and degrade model performance. Existing methods typically
address only one type of imbalance or incur high computational costs. In this
work, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learning
framework that effectively mitigates both class and graph size imbalance.
SamGoG constructs multiple GoGs through an efficient importance-based sampling
mechanism and trains on them sequentially. This sampling mechanism incorporates
the learnable pairwise similarity and adaptive GoG node degree to enhance edge
homophily, thus improving downstream model quality. SamGoG can seamlessly
integrate with various downstream GNNs, enabling their efficient adaptation for
graph classification tasks. Extensive experiments on benchmark datasets
demonstrate that SamGoG achieves state-of-the-art performance with up to a
15.66% accuracy improvement with 6.7$\times$ training acceleration.

</details>


### [180] [Search-Optimized Quantization in Biomedical Ontology Alignment](https://arxiv.org/abs/2507.13742)
*Oussama Bouaggad,Natalia Grabar*

Main category: cs.LG

TL;DR: 本文提出一种基于监督式变压器模型的高效模型优化方法，通过与UMLS Metathesaurus的语义相似性进行本体对齐，使用ONYX与Intel优化工具实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决AI模型在资源受限环境中的部署难题，如能耗高、内存需求大和延迟问题。

Method: 通过结合微软Olive和ONYX Runtime，采用动态量化与Intel Neural Compressor和IPEX完成模型优化。

Result: 在DEFT 2020评测任务中创下新SOTA，推理速度提升20倍，内存使用减少约70%。

Conclusion: 优化技术不仅保持高性能，还大幅提升能效与效率，为资源受限环境中AI模型部署提供可能性。

Abstract: In the fast-moving world of AI, as organizations and researchers develop more
advanced models, they face challenges due to their sheer size and computational
demands. Deploying such models on edge devices or in resource-constrained
environments adds further challenges related to energy consumption, memory
usage and latency. To address these challenges, emerging trends are shaping the
future of efficient model optimization techniques. From this premise, by
employing supervised state-of-the-art transformer-based models, this research
introduces a systematic method for ontology alignment, grounded in cosine-based
semantic similarity between a biomedical layman vocabulary and the Unified
Medical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to
search for target optimizations among different Execution Providers (EPs) using
the ONNX Runtime backend, followed by an assembled process of dynamic
quantization employing Intel Neural Compressor and IPEX (Intel Extension for
PyTorch). Through our optimization process, we conduct extensive assessments on
the two tasks from the DEFT 2020 Evaluation Campaign, achieving a new
state-of-the-art in both. We retain performance metrics intact, while attaining
an average inference speed-up of 20x and reducing memory usage by approximately
70%.

</details>


### [181] [MolPIF: A Parameter Interpolation Flow Model for Molecule Generation](https://arxiv.org/abs/2507.13762)
*Yaowei Jin,Junjie Wang,Wenkai Xiang,Duanhua Cao,Dan Teng,Zhehuan Fan,Jiacheng Xiong,Xia Sheng,Chuanlong Zeng,Mingyue Zheng,Qian Shi*

Main category: cs.LG

TL;DR: 提出了一种参数插值流（Parameter Interpolation Flow, PIF）模型，并应用于基于结构的药物设计，实现了优越性能。


<details>
  <summary>Details</summary>
Motivation: 目前基于贝叶斯流网络（BFN）的分子生成方法虽在化学任务中表现出色，但缺乏灵活性且难以适应不同数据分布与任务需求。此外，探索更简单、高效的参数空间建模方法的潜力尚未开发。

Method: 提出了一种新的参数插值流（PIF）模型，配备详细的理论基础、训练与推理流程，并开发出MolPIF用于基于结构的药物设计。

Result: 所提模型在多种评估指标上优于基线方法，显示出在多样化任务中的优势性能。

Conclusion: 验证了基于参数空间的生成建模方法在分子生成中的有效性，并为模型设计提供了新视角。

Abstract: Advances in deep learning for molecular generation show promise in
accelerating drug discovery. Bayesian Flow Networks (BFNs) have recently shown
impressive performance across diverse chemical tasks, with their success often
ascribed to the paradigm of modeling in a low-variance parameter space.
However, the Bayesian inference-based strategy imposes limitations on designing
more flexible distribution transformation pathways, making it challenging to
adapt to diverse data distributions and varied task requirements. Furthermore,
the potential for simpler, more efficient parameter-space-based models is
unexplored. To address this, we propose a novel Parameter Interpolation Flow
model (named PIF) with detailed theoretical foundation, training, and inference
procedures. We then develop MolPIF for structure-based drug design,
demonstrating its superior performance across diverse metrics compared to
baselines. This work validates the effectiveness of parameter-space-based
generative modeling paradigm for molecules and offers new perspectives for
model design.

</details>


### [182] [Dual-Center Graph Clustering with Neighbor Distribution](https://arxiv.org/abs/2507.13765)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Li Jin,Liqiang Nie*

Main category: cs.LG

TL;DR: 本文提出了一种新的双中心图聚类方法 (DCGC)，通过邻居分布特性进行表示学习和优化，并取得了优异的实验结果。


<details>
  <summary>Details</summary>
Motivation: 图聚类因其无监督特性具有很大挑战，现有目标导向方法多依赖伪标签且指导性不足。

Method: 引入邻居分布作为监督信号，提高对比学习中表示学习的效果，同时结合特征中心与邻居分布中心进行双目标优化。

Result: 通过大量实验验证，新方法的性能优于现有方法。

Conclusion: DCGC方法提供了一种新颖且有效的图聚类框架，利用邻居分布与双中心优化显著提升了聚类效果。

Abstract: Graph clustering is crucial for unraveling intricate data structures, yet it
presents significant challenges due to its unsupervised nature. Recently,
goal-directed clustering techniques have yielded impressive results, with
contrastive learning methods leveraging pseudo-label garnering considerable
attention. Nonetheless, pseudo-label as a supervision signal is unreliable and
existing goal-directed approaches utilize only features to construct a
single-target distribution for single-center optimization, which lead to
incomplete and less dependable guidance. In our work, we propose a novel
Dual-Center Graph Clustering (DCGC) approach based on neighbor distribution
properties, which includes representation learning with neighbor distribution
and dual-center optimization. Specifically, we utilize neighbor distribution as
a supervision signal to mine hard negative samples in contrastive learning,
which is reliable and enhances the effectiveness of representation learning.
Furthermore, neighbor distribution center is introduced alongside feature
center to jointly construct a dual-target distribution for dual-center
optimization. Extensive experiments and analysis demonstrate superior
performance and effectiveness of our proposed method.

</details>


### [183] [On-the-Fly Fine-Tuning of Foundational Neural Network Potentials: A Bayesian Neural Network Approach](https://arxiv.org/abs/2507.13805)
*Tim Rensmeyer,Denis Kramer,Oliver Niggemann*

Main category: cs.LG

TL;DR: 本文探讨了如何通过贝叶斯神经网络方法完善基础模型微调的流程，从而自动化采样并提高处理稀有事件的效率。


<details>
  <summary>Details</summary>
Motivation: 由于计算原子间力的复杂性，研究者尝试通过机器学习力场来降低计算成本，但生成高质量训练数据集本身依然计算昂贵。微调在大规模数据库上预训练的基础模型有助于减少训练数据需求，但生成适用的训练数据仍然具挑战性。

Method: 提出利用贝叶斯神经网络评估模型不确定性，并结合飞行中学习的工作流，在模拟运行中判断是否需要重新计算结构，从而自动化地更新和微调模型。

Result: 实现了一种工作流自动优化模型，使其在保持准确性的同时以更高频率采样稀有事件如过渡态。

Conclusion: 文中方法提高了基础模型微调的效率，并通过不确定性评估适应了稀有事件的样本采集需求，相较传统方法具有显著提升。

Abstract: Due to the computational complexity of evaluating interatomic forces from
first principles, the creation of interatomic machine learning force fields has
become a highly active field of research. However, the generation of training
datasets of sufficient size and sample diversity itself comes with a
computational burden that can make this approach impractical for modeling rare
events or systems with a large configuration space. Fine-tuning foundation
models that have been pre-trained on large-scale material or molecular
databases offers a promising opportunity to reduce the amount of training data
necessary to reach a desired level of accuracy. However, even if this approach
requires less training data overall, creating a suitable training dataset can
still be a very challenging problem, especially for systems with rare events
and for end-users who don't have an extensive background in machine learning.
In on-the-fly learning, the creation of a training dataset can be largely
automated by using model uncertainty during the simulation to decide if the
model is accurate enough or if a structure should be recalculated with
classical methods and used to update the model. A key challenge for applying
this form of active learning to the fine-tuning of foundation models is how to
assess the uncertainty of those models during the fine-tuning process, even
though most foundation models lack any form of uncertainty quantification. In
this paper, we overcome this challenge by introducing a fine-tuning approach
based on Bayesian neural network methods and a subsequent on-the-fly workflow
that automatically fine-tunes the model while maintaining a pre-specified
accuracy and can detect rare events such as transition states and sample them
at an increased rate relative to their occurrence.

</details>


### [184] [Scalable Submodular Policy Optimization via Pruned Submodularity Graph](https://arxiv.org/abs/2507.13834)
*Aditi Anand,Suman Banerjee,Dildar Ali*

Main category: cs.LG

TL;DR: 本文研究强化学习中奖励函数服从次模性时的优化问题，提出了一种基于剪枝次模性图的近似解算法，并验证了其优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习假设奖励函数具有可加性，但现实中很多问题的奖励函数表现出次模性，例如路径规划和覆盖控制等问题。

Method: 提出了一种基于剪枝次模性图的方法，提供可计算时间内的近似解，并分析了算法的时间与空间复杂度及性能保证。

Result: 实验表明，所提出的方法在类似研究中使用的基准环境中获得的奖励优于基线方法。

Conclusion: 基于剪枝次模性图的方法在解决奖励函数次模性强化学习优化任务中表现出色，并具有可行的计算与应用价值。

Abstract: In Reinforcement Learning (abbreviated as RL), an agent interacts with the
environment via a set of possible actions, and a reward is generated from some
unknown distribution. The task here is to find an optimal set of actions such
that the reward after a certain time step gets maximized. In a traditional
setup, the reward function in an RL Problem is considered additive. However, in
reality, there exist many problems, including path planning, coverage control,
etc., the reward function follows the diminishing return, which can be modeled
as a submodular function. In this paper, we study a variant of the RL Problem
where the reward function is submodular, and our objective is to find an
optimal policy such that this reward function gets maximized. We have proposed
a pruned submodularity graph-based approach that provides a provably
approximate solution in a feasible computation time. The proposed approach has
been analyzed to understand its time and space requirements as well as a
performance guarantee. We have experimented with a benchmark agent-environment
setup, which has been used for similar previous studies, and the results are
reported. From the results, we observe that the policy obtained by our proposed
approach leads to more reward than the baseline methods.

</details>


### [185] [Self-supervised learning on gene expression data](https://arxiv.org/abs/2507.13912)
*Kevin Dradjat,Massinissa Hamidi,Pierre Bartet,Blaise Hanczar*

Main category: cs.LG

TL;DR: 研究探讨了自监督学习方法在基因表达数据中的应用，展示其在表型预测中的潜力与优势，尤其是在降低对标注数据依赖方面的表现优异。


<details>
  <summary>Details</summary>
Motivation: 基因表达数据对表型预测在疾病机制、药物反应和个性化医疗研究中很重要，而传统方法依赖大量标注数据，获取成本高。需要新的技术方法突破这一局限。

Method: 选择三种基于不同方法的自监督学习技术，在公开基因表达数据集上测试其能力，评估生成的特征表示，用于下游预测任务并进行性能对比。

Result: 研究显示这些自监督学习方法能够捕获数据中的复杂信息，在减少标注数据依赖的同时提升表型预测的准确性，并优于传统的有监督模型。

Conclusion: 自监督学习在基因表达数据分析中展现出显著潜力，研究提供了不同算法优势与适用场景的分析，并提出未来发展方向。

Abstract: Predicting phenotypes from gene expression data is a crucial task in
biomedical research, enabling insights into disease mechanisms, drug responses,
and personalized medicine. Traditional machine learning and deep learning rely
on supervised learning, which requires large quantities of labeled data that
are costly and time-consuming to obtain in the case of gene expression data.
Self-supervised learning has recently emerged as a promising approach to
overcome these limitations by extracting information directly from the
structure of unlabeled data. In this study, we investigate the application of
state-of-the-art self-supervised learning methods to bulk gene expression data
for phenotype prediction. We selected three self-supervised methods, based on
different approaches, to assess their ability to exploit the inherent structure
of the data and to generate qualitative representations which can be used for
downstream predictive tasks. By using several publicly available gene
expression datasets, we demonstrate how the selected methods can effectively
capture complex information and improve phenotype prediction accuracy. The
results obtained show that self-supervised learning methods can outperform
traditional supervised models besides offering significant advantage by
reducing the dependency on annotated data. We provide a comprehensive analysis
of the performance of each method by highlighting their strengths and
limitations. We also provide recommendations for using these methods depending
on the case under study. Finally, we outline future research directions to
enhance the application of self-supervised learning in the field of gene
expression data analysis. This study is the first work that deals with bulk
RNA-Seq data and self-supervised learning.

</details>


### [186] [Reframing attention as a reinforcement learning problem for causal discovery](https://arxiv.org/abs/2507.13920)
*Turan Orujlu,Christian Gumbsch,Martin V. Butz,Charley M Wu*

Main category: cs.LG

TL;DR: 提出了一种基于动态因果结构的新框架，采用强化学习和Transformer注意力机制，构建动态因果过程模型，在视觉观测中推断因果关系，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有因果关系研究主要基于静态因果图，与强化学习领域结合较少，且缺乏对动态因果交互的建模能力。作者希望通过新的理论框架填补这一空白。

Method: 提出Causal Process框架及其实现方案Causal Process Model，将Transformer的注意力机制引入强化学习环境中，用于从视觉数据中学习因果关系。因果推理被嵌套到强化学习任务中，通过强化学习代理生成因果图假设。

Result: 证明了在强化学习环境中，该方法在因果表征学习和代理性能方面均优于当前其它方法，且能够独特地恢复动态因果过程的图示。

Conclusion: 该研究提出了一个新颖的动态因果过程框架，展示了其在因果表征学习中的有效性和独特性，为因果推理在强化学习中的应用提供了新的视角。

Abstract: Formal frameworks of causality have operated largely parallel to modern
trends in deep reinforcement learning (RL). However, there has been a revival
of interest in formally grounding the representations learned by neural
networks in causal concepts. Yet, most attempts at neural models of causality
assume static causal graphs and ignore the dynamic nature of causal
interactions. In this work, we introduce Causal Process framework as a novel
theory for representing dynamic hypotheses about causal structure. Furthermore,
we present Causal Process Model as an implementation of this framework. This
allows us to reformulate the attention mechanism popularized by Transformer
networks within an RL setting with the goal to infer interpretable causal
processes from visual observations. Here, causal inference corresponds to
constructing a causal graph hypothesis which itself becomes an RL task nested
within the original RL problem. To create an instance of such hypothesis, we
employ RL agents. These agents establish links between units similar to the
original Transformer attention mechanism. We demonstrate the effectiveness of
our approach in an RL environment where we outperform current alternatives in
causal representation learning and agent performance, and uniquely recover
graphs of dynamic causal processes.

</details>


### [187] [MoDyGAN: Combining Molecular Dynamics With GANs to Investigate Protein Conformational Space](https://arxiv.org/abs/2507.13950)
*Jingbo Liang,Bruna Jacobson*

Main category: cs.LG

TL;DR: MoDyGAN利用分子动力学模拟和生成对抗网络，显著提升蛋白结构构象生成及探索效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于物理动态的模拟方法在探索蛋白构象空间时计算成本过高，存在效率瓶颈。

Method: 提出MoDyGAN框架，将蛋白质3D结构转化为2D矩阵形式，通过GAN生成新的构象，同时结合双判别器模块和集合学习以提升结构合理性。

Result: 使用三种蛋白和deca-alanine验证了模型生成的构象是合理的，并展示潜在空间内插与分子模拟轨迹一致。

Conclusion: MoDyGAN实现了高效的蛋白质构象采样，并展现了将生物分子模拟与深度学习技术结合的潜力，适合扩展到其他复杂结构模型。

Abstract: Extensively exploring protein conformational landscapes remains a major
challenge in computational biology due to the high computational cost involved
in dynamic physics-based simulations. In this work, we propose a novel
pipeline, MoDyGAN, that leverages molecular dynamics (MD) simulations and
generative adversarial networks (GANs) to explore protein conformational
spaces. MoDyGAN contains a generator that maps Gaussian distributions into
MD-derived protein trajectories, and a refinement module that combines ensemble
learning with a dual-discriminator to further improve the plausibility of
generated conformations. Central to our approach is an innovative
representation technique that reversibly transforms 3D protein structures into
2D matrices, enabling the use of advanced image-based GAN architectures. We use
three rigid proteins to demonstrate that MoDyGAN can generate plausible new
conformations. We also use deca-alanine as a case study to show that
interpolations within the latent space closely align with trajectories obtained
from steered molecular dynamics (SMD) simulations. Our results suggest that
representing proteins as image-like data unlocks new possibilities for applying
advanced deep learning techniques to biomolecular simulation, leading to an
efficient sampling of conformational states. Additionally, the proposed
framework holds strong potential for extension to other complex 3D structures.

</details>


### [188] [Robust Anomaly Detection with Graph Neural Networks using Controllability](https://arxiv.org/abs/2507.13954)
*Yifan Wei,Anwar Said,Waseem Abbas,Xenofon Koutsoukos*

Main category: cs.LG

TL;DR: 本文探讨了通过结合平均可控性来提升基于图的机器学习模型在异常检测中的表现。


<details>
  <summary>Details</summary>
Motivation: 处理异常检测时需要应对标签数据稀缺和异常与正常样本不平衡的难题。用图学习模型将属性与关系数据结合提供潜在解决方案，但异常数据稀缺性依旧存在困难。

Method: 将平均可控性融入图模型，包括（1）作为边权重使用；（2）作为独热边属性向量编码。

Result: 通过在真实与合成网络上的评估，这种方法在识别异常上表现出对比六个前沿方法的显著改进。

Conclusion: 整合平均可控性可以作为图机器学习模型的补充指标，有望解决数据稀疏与不平衡下的异常检测问题。

Abstract: Anomaly detection in complex domains poses significant challenges due to the
need for extensive labeled data and the inherently imbalanced nature of
anomalous versus benign samples. Graph-based machine learning models have
emerged as a promising solution that combines attribute and relational data to
uncover intricate patterns. However, the scarcity of anomalous data exacerbates
the challenge, which requires innovative strategies to enhance model learning
with limited information. In this paper, we hypothesize that the incorporation
of the influence of the nodes, quantified through average controllability, can
significantly improve the performance of anomaly detection. We propose two
novel approaches to integrate average controllability into graph-based
frameworks: (1) using average controllability as an edge weight and (2)
encoding it as a one-hot edge attribute vector. Through rigorous evaluation on
real-world and synthetic networks with six state-of-the-art baselines, our
proposed methods demonstrate improved performance in identifying anomalies,
highlighting the critical role of controllability measures in enhancing the
performance of graph machine learning models. This work underscores the
potential of integrating average controllability as additional metrics to
address the challenges of anomaly detection in sparse and imbalanced datasets.

</details>


### [189] [Signs of the Past, Patterns of the Present: On the Automatic Classification of Old Babylonian Cuneiform Signs](https://arxiv.org/abs/2507.13959)
*Eli Verwimp,Gustav Ryberg Smidt,Hendrik Hameeuw,Katrien De Graef*

Main category: cs.LG

TL;DR: 该论文探讨了机器学习技术在楔形文字标志分类中的应用，特别关注数据集之间的表现差异对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 楔形文字标志存在由于来源、书写者以及数字化过程造成的显著变异性，研究旨在探索机器学习模型在处理这些数据集间差异时的性能表现，为未来制定更好的数据采集标准并提高分类任务的效率。

Method: 使用ResNet50模型对手写的古巴比伦文本进行训练和测试，这些文本来自尼普尔、杜尔-阿比苏赫和希帕尔三个城市的泥板文书。模型分类基于具有至少20个实例的标志。

Result: ResNet50模型在标志分类任务中取得了顶级-1准确度87.1%和顶级-5准确度96.5%的成绩。

Conclusion: 这是首次在古巴比伦楔形文字文本上的自动分类研究，成果为该领域的进一步发展奠定了基础。

Abstract: The work in this paper describes the training and evaluation of machine
learning (ML) techniques for the classification of cuneiform signs. There is a
lot of variability in cuneiform signs, depending on where they come from, for
what and by whom they were written, but also how they were digitized. This
variability makes it unlikely that an ML model trained on one dataset will
perform successfully on another dataset. This contribution studies how such
differences impact that performance. Based on our results and insights, we aim
to influence future data acquisition standards and provide a solid foundation
for future cuneiform sign classification tasks. The ML model has been trained
and tested on handwritten Old Babylonian (c. 2000-1600 B.C.E.) documentary
texts inscribed on clay tablets originating from three Mesopotamian cities
(Nippur, D\=ur-Abie\v{s}uh and Sippar). The presented and analysed model is
ResNet50, which achieves a top-1 score of 87.1% and a top-5 score of 96.5% for
signs with at least 20 instances. As these automatic classification results are
the first on Old Babylonian texts, there are currently no comparable results.

</details>


### [190] [Structural Connectome Harmonization Using Deep Learning: The Strength of Graph Neural Networks](https://arxiv.org/abs/2507.13992)
*Jagruti Patel,Thomas A. W. Bolton,Mikkel Schöttner,Anjali Tarun,Sebastien Tourbier,Yasser Alemàn-Gòmez,Jonas Richiardi,Patric Hagmann*

Main category: cs.LG

TL;DR: 小样本体量阻碍了脑影像，尤其是结构性连接组学的生物标记研究发展。本研究提出了无需元数据或旅行样本的深度学习框架以和谐化多站点数据，验证了图卷积自编码器在保持图形拓扑结构和个体差异上的性能优势。


<details>
  <summary>Details</summary>
Motivation: 应对小样本量和仪器异质性导致的统计学和可推广性问题，提升结构性连接组学研究中的数据一致性和可靠性。

Method: 提出一个基于站点条件的深度和谐化框架，测试三种深度自编码器（AE、卷积AE、图卷积AE）的表现，并与线性回归基准模型比较。

Result: 非图形模型在边权重预测和边存在性检测中的表现突出，而图卷积自编码器更能优异保持拓扑结构和个体差异。

Conclusion: 图形方法在多站点结构性连接组学研究中的结构感知和领域泛化能力上表现出色，可提供可靠的和谐化效果。

Abstract: Small sample sizes in neuroimaging in general, and in structural connectome
(SC) studies in particular limit the development of reliable biomarkers for
neurological and psychiatric disorders - such as Alzheimer's disease and
schizophrenia - by reducing statistical power, reliability, and
generalizability. Large-scale multi-site studies have exist, but they have
acquisition-related biases due to scanner heterogeneity, compromising imaging
consistency and downstream analyses. While existing SC harmonization methods -
such as linear regression (LR), ComBat, and deep learning techniques - mitigate
these biases, they often rely on detailed metadata, traveling subjects (TS), or
overlook the graph-topology of SCs. To address these limitations, we propose a
site-conditioned deep harmonization framework that harmonizes SCs across
diverse acquisition sites without requiring metadata or TS that we test in a
simulated scenario based on the Human Connectome Dataset. Within this
framework, we benchmark three deep architectures - a fully connected
autoencoder (AE), a convolutional AE, and a graph convolutional AE - against a
top-performing LR baseline. While non-graph models excel in edge-weight
prediction and edge existence detection, the graph AE demonstrates superior
preservation of topological structure and subject-level individuality, as
reflected by graph metrics and fingerprinting accuracy, respectively. Although
the LR baseline achieves the highest numerical performance by explicitly
modeling acquisition parameters, it lacks applicability to real-world
multi-site use cases as detailed acquisition metadata is often unavailable. Our
results highlight the critical role of model architecture in SC harmonization
performance and demonstrate that graph-based approaches are particularly
well-suited for structure-aware, domain-generalizable SC harmonization in
large-scale multi-site SC studies.

</details>


### [191] [ParallelTime: Dynamically Weighting the Balance of Short- and Long-Term Temporal Dependencies](https://arxiv.org/abs/2507.13998)
*Itay Katav,Aryeh Kontorovich*

Main category: cs.LG

TL;DR: 提出了ParallelTime Weighter动态加权机制，结合ParallelTime架构，优化了时序预测任务的性能。


<details>
  <summary>Details</summary>
Motivation: 目前的时序预测方法中，对长短期依赖赋予相等权重的方式效果并不理想。

Method: 提出动态权重机制ParallelTime Weighter，根据输入和模型知识为长短期依赖动态赋权；设计ParallelTime架构结合该机制。

Result: 新方法在多种基准数据集上表现出色，性能领先现有方法，同时降低了FLOPs和参数量，具备更长预测范围的可扩展性。

Conclusion: ParallelTime Weighter机制和ParallelTime架构提供了一种高效且性能优越的新方法，为时间序列预测领域的未来发展指明了方向。

Abstract: Modern multivariate time series forecasting primarily relies on two
architectures: the Transformer with attention mechanism and Mamba. In natural
language processing, an approach has been used that combines local window
attention for capturing short-term dependencies and Mamba for capturing
long-term dependencies, with their outputs averaged to assign equal weight to
both. We find that for time-series forecasting tasks, assigning equal weight to
long-term and short-term dependencies is not optimal. To mitigate this, we
propose a dynamic weighting mechanism, ParallelTime Weighter, which calculates
interdependent weights for long-term and short-term dependencies for each token
based on the input and the model's knowledge. Furthermore, we introduce the
ParallelTime architecture, which incorporates the ParallelTime Weighter
mechanism to deliver state-of-the-art performance across diverse benchmarks.
Our architecture demonstrates robustness, achieves lower FLOPs, requires fewer
parameters, scales effectively to longer prediction horizons, and significantly
outperforms existing methods. These advances highlight a promising path for
future developments of parallel Attention-Mamba in time series forecasting. The
implementation is readily available at:
\href{https://github.com/itay1551/ParallelTime}{ParallelTime GitHub

</details>


### [192] [On the Fundamental Limitations of Dual Static CVaR Decompositions in Markov Decision Processes](https://arxiv.org/abs/2507.14005)
*Mathieu Godbout,Audrey Durand*

Main category: cs.LG

TL;DR: 本文分析了在MDP中使用基于对偶形式的动态规划方法计算CVaR（条件在风险）的政策时可能失败的根源，并提出了与风险分配一致性相关的新研究视角与发现。


<details>
  <summary>Details</summary>
Motivation: 解决用对偶形式动态规划方法求解CVaR最优政策失败的根源问题，并扩展对政策评估问题的研究。

Method: 用两个最小化问题框架描述CVaR的静态政策评估，并引入“风险分配一致性约束”作为解决间隙的关键条件。通过分析和验证，将政策优化失败归因于CVaR评估间隙。

Result: 证明了基于对偶CVaR分解寻找统一最优政策的基本局限性，并发现了MDP中的一个特殊情形，表明不可能对所有初始风险水平找到单一政策。

Conclusion: 研究重新定义了CVaR政策评估的关键概念，解释了传统方法导致错误的原因，并揭示了基于风险分配一致性的新分析潜力。

Abstract: Recent work has shown that dynamic programming (DP) methods for finding
static CVaR-optimal policies in Markov Decision Processes (MDPs) can fail when
based on the dual formulation, yet the root cause for the failure has remained
unclear. We expand on these findings by shifting focus from policy optimization
to the seemingly simpler task of policy evaluation. We show that evaluating the
static CVaR of a given policy can be framed as two distinct minimization
problems. For their solutions to match, a set of ``risk-assignment consistency
constraints'' must be satisfied, and we demonstrate that the intersection of
the constraints being empty is the source of previously observed evaluation
errors. Quantifying the evaluation error as the CVaR evaluation gap, we then
demonstrate that the issues observed when optimizing over the dual-based CVaR
DP are explained by the returned policy having a non-zero CVaR evaluation gap.
We then leverage our proposed risk-assignment perspective to prove that the
search for a single, uniformly optimal policy via on the dual CVaR
decomposition is fundamentally limited, identifying an MDP where no single
policy can be optimal across all initial risk levels.

</details>


### [193] [Byzantine-resilient federated online learning for Gaussian process regression](https://arxiv.org/abs/2507.14021)
*Xu Zhang,Zhenyuan Yuan,Minghui Zhu*

Main category: cs.LG

TL;DR: 该论文提出了一种针对高斯过程回归的拜占庭鲁棒联邦在线学习算法，能够在存在拜占庭节点的情况下协同学习潜在函数。


<details>
  <summary>Details</summary>
Motivation: 研究如何在拜占庭故障和潜在存在恶意行为的联邦环境中，提升高斯过程回归模型的学习性能。

Method: 提出了一种“拜占庭鲁棒专家产品聚合规则”，结合云端全局模型和代理节点的本地预测进行模型优化，并定量分析了本地和全局模型融合的效果提升。

Result: 通过在玩具示例和两个中型真实数据集上的实验，验证了算法的性能提升。

Conclusion: 提出的算法在存在拜占庭故障的条件下，能够实现有效的协同学习并提升模型整体性能。

Abstract: In this paper, we study Byzantine-resilient federated online learning for
Gaussian process regression (GPR). We develop a Byzantine-resilient federated
GPR algorithm that allows a cloud and a group of agents to collaboratively
learn a latent function and improve the learning performances where some agents
exhibit Byzantine failures, i.e., arbitrary and potentially adversarial
behavior. Each agent-based local GPR sends potentially compromised local
predictions to the cloud, and the cloud-based aggregated GPR computes a global
model by a Byzantine-resilient product of experts aggregation rule. Then the
cloud broadcasts the current global model to all the agents. Agent-based fused
GPR refines local predictions by fusing the received global model with that of
the agent-based local GPR. Moreover, we quantify the learning accuracy
improvements of the agent-based fused GPR over the agent-based local GPR.
Experiments on a toy example and two medium-scale real-world datasets are
conducted to demonstrate the performances of the proposed algorithm.

</details>


### [194] [DONUT: Physics-aware Machine Learning for Real-time X-ray Nanodiffraction Analysis](https://arxiv.org/abs/2507.14038)
*Aileen Luo,Tao Zhou,Ming Du,Martin V. Holt,Andrej Singer,Mathew J. Cherukara*

Main category: cs.LG

TL;DR: DONUT是一种物理感知的神经网络，用于快速自动分析纳米束衍射数据，无需标签数据集或预训练，速度比传统方法快200倍。


<details>
  <summary>Details</summary>
Motivation: 目前实时分析相干X射线散射数据受到伪影和计算需求的限制，尤其在扫描X射线纳米衍射显微技术中，逐点分析成为瓶颈。

Method: 提出了DONUT，一个将可微几何衍射模型与神经网络架构相结合的工具，用于实时预测晶格应变和取向，无需标签或预训练。

Result: 实验表明，DONUT能够在不依赖传统拟合方法的情况下，以超过200倍的效率准确提取数据中的特征。

Conclusion: DONUT克服了X射线科学中监督学习的主要限制，极大提高了数据分析效率，为纳米级结构分析提供了强有力的工具。

Abstract: Coherent X-ray scattering techniques are critical for investigating the
fundamental structural properties of materials at the nanoscale. While
advancements have made these experiments more accessible, real-time analysis
remains a significant bottleneck, often hindered by artifacts and computational
demands. In scanning X-ray nanodiffraction microscopy, which is widely used to
spatially resolve structural heterogeneities, this challenge is compounded by
the convolution of the divergent beam with the sample's local structure. To
address this, we introduce DONUT (Diffraction with Optics for Nanobeam by
Unsupervised Training), a physics-aware neural network designed for the rapid
and automated analysis of nanobeam diffraction data. By incorporating a
differentiable geometric diffraction model directly into its architecture,
DONUT learns to predict crystal lattice strain and orientation in real-time.
Crucially, this is achieved without reliance on labeled datasets or
pre-training, overcoming a fundamental limitation for supervised machine
learning in X-ray science. We demonstrate experimentally that DONUT accurately
extracts all features within the data over 200 times more efficiently than
conventional fitting methods.

</details>


### [195] [Noradrenergic-inspired gain modulation attenuates the stability gap in joint training](https://arxiv.org/abs/2507.14056)
*Alejandro Rodriguez-Garcia,Anindya Ghosh,Srikanth Ramaswamy*

Main category: cs.LG

TL;DR: 研究探讨了持续学习中存在的"稳定性差距"问题，并提出了一种受生物神经调节机制启发的不确定性调节增益动态方法，有效减缓了此问题。


<details>
  <summary>Details</summary>
Motivation: 当前持续学习仍面临稳定性差距问题，即在学习新任务时，已掌握任务的性能会暂时下降；该研究旨在解决如何在快速适应与长期保留之间找到平衡，以提高持续学习的鲁棒性。

Method: 研究受生物神经中蓝斑系统的去甲肾上腺素调节机制启发，提出了一种不确定性调节的增益动态方法，用以模拟两时间尺度优化器，平衡知识的整合与减少已掌握信息的干扰。

Result: 实验在MNIST和CIFAR的领域增量和类别增量任务中进行，显示不确定性调节增益动态减小了稳定性差距，提升了持续学习的性能。

Conclusion: 该方法有效改善了稳定性差距问题，并为人造网络如何借鉴生物系统的多时间尺度动态提供了新见解，对持续学习领域有重要意义。

Abstract: Recent studies in continual learning have identified a transient drop in
performance on mastered tasks when assimilating new ones, known as the
stability gap. Such dynamics contradict the objectives of continual learning,
revealing a lack of robustness in mitigating forgetting, and notably,
persisting even under an ideal joint-loss regime. Examining this gap within
this idealized joint training context is critical to isolate it from other
sources of forgetting. We argue that it reflects an imbalance between rapid
adaptation and robust retention at task boundaries, underscoring the need to
investigate mechanisms that reconcile plasticity and stability within continual
learning frameworks. Biological brains navigate a similar dilemma by operating
concurrently on multiple timescales, leveraging neuromodulatory signals to
modulate synaptic plasticity. However, artificial networks lack native
multitimescale dynamics, and although optimizers like momentum-SGD and Adam
introduce implicit timescale regularization, they still exhibit stability gaps.
Inspired by locus coeruleus mediated noradrenergic bursts, which transiently
enhance neuronal gain under uncertainty to facilitate sensory assimilation, we
propose uncertainty-modulated gain dynamics - an adaptive mechanism that
approximates a two-timescale optimizer and dynamically balances integration of
knowledge with minimal interference on previously consolidated information. We
evaluate our mechanism on domain-incremental and class-incremental variants of
the MNIST and CIFAR benchmarks under joint training, demonstrating that
uncertainty-modulated gain dynamics effectively attenuate the stability gap.
Finally, our analysis elucidates how gain modulation replicates noradrenergic
functions in cortical circuits, offering mechanistic insights into reducing
stability gaps and enhance performance in continual learning tasks.

</details>


### [196] [Preference-based Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2507.14066)
*Ni Mu,Yao Luan,Qing-Shan Jia*

Main category: cs.LG

TL;DR: 提出了一种基于偏好的多目标强化学习（Pb-MORL）方法，通过理论证明和实验验证其在多目标任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 通过偏好代替预定义的奖励函数，以克服设计复杂性并更好平衡冲突目标。

Method: 提出了Pb-MORL方法，通过偏好构建多目标奖励模型，并理论证明这种方法能够有效训练Pareto最优策略。

Result: 在多种基准任务、能源管理和自动驾驶应用中展现了强大的性能表现，优于使用真实奖励函数的基准方法。

Conclusion: Pb-MORL方法不仅提供了一种理论支持的框架，还在实际复杂问题中展示了其高效性和实际应用潜力。

Abstract: Multi-objective reinforcement learning (MORL) is a structured approach for
optimizing tasks with multiple objectives. However, it often relies on
pre-defined reward functions, which can be hard to design for balancing
conflicting goals and may lead to oversimplification. Preferences can serve as
more flexible and intuitive decision-making guidance, eliminating the need for
complicated reward design. This paper introduces preference-based MORL
(Pb-MORL), which formalizes the integration of preferences into the MORL
framework. We theoretically prove that preferences can derive policies across
the entire Pareto frontier. To guide policy optimization using preferences, our
method constructs a multi-objective reward model that aligns with the given
preferences. We further provide theoretical proof to show that optimizing this
reward model is equivalent to training the Pareto optimal policy. Extensive
experiments in benchmark multi-objective tasks, a multi-energy management task,
and an autonomous driving task on a multi-line highway show that our method
performs competitively, surpassing the oracle method, which uses the ground
truth reward function. This highlights its potential for practical applications
in complex real-world systems.

</details>


### [197] [DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration](https://arxiv.org/abs/2507.14088)
*Xiyun Li,Yining Ding,Yuhua Jiang,Yunlong Zhao,Runpeng Xie,Shuang Xu,Yuanhua Ni,Yiqin Yang,Bo Xu*

Main category: cs.LG

TL;DR: 本文提出了一个名为DPMT的框架，基于双重过程理论和多尺度的心智理论，用于增强实时人机协作。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在处理复杂人类心理特征建模方面存在不足，特别是在缺乏直接交流情况下准确捕捉领域意图的能力欠佳。

Method: 提出了一个基于认知科学双重过程理论的DPMT框架，引入多尺度心智理论模块，通过推断人类心理特征实现更稳健的合作建模。

Result: 实验结果表明，DPMT框架显著提高了人机协作能力，消融实验也验证了多尺度心智理论在系统中的重要角色。

Conclusion: DPMT框架有效克服了现有模型的局限性，在实时人机协作中表现出更强的适应性和准确性。

Abstract: Real-time human-artificial intelligence (AI) collaboration is crucial yet
challenging, especially when AI agents must adapt to diverse and unseen human
behaviors in dynamic scenarios. Existing large language model (LLM) agents
often fail to accurately model the complex human mental characteristics such as
domain intentions, especially in the absence of direct communication. To
address this limitation, we propose a novel dual process multi-scale theory of
mind (DPMT) framework, drawing inspiration from cognitive science dual process
theory. Our DPMT framework incorporates a multi-scale theory of mind (ToM)
module to facilitate robust human partner modeling through mental
characteristic reasoning. Experimental results demonstrate that DPMT
significantly enhances human-AI collaboration, and ablation studies further
validate the contributions of our multi-scale ToM in the slow system.

</details>


### [198] [Kolmogorov Arnold Networks (KANs) for Imbalanced Data -- An Empirical Perspective](https://arxiv.org/abs/2507.14121)
*Pankaj Yadav,Vivek Vijay*

Main category: cs.LG

TL;DR: 本文对Kolmogorov Arnold Networks (KANs)在类别不平衡分类中的应用进行了实证评估，发现其在原始不平衡数据上表现优于MLPs，但计算成本过高且与传统的不平衡处理策略不兼容。


<details>
  <summary>Details</summary>
Motivation: 探讨正在发展的KAN架构在类别不平衡分类问题中的性能，验证其是否对比传统神经网络有优势。

Method: 通过使用十个基准数据集，直接评估KANs与传统MLPs在不平衡分类中的表现，并测试其与数据重采样及焦点损失等不平衡处理策略的相容性。

Result: KANs在处理原始不平衡数据方面优于MLPs，但传统的不平衡策略会显著降低KANs性能，同时KANs的计算代价过高，导致性能资源比不理想。

Conclusion: KANs目前仅适用于资源丰富的原始不平衡数据场景，其实用性受计算效率和与数据增强方法的不兼容性限制，需改进架构及优化资源利用以扩大应用前景。

Abstract: Kolmogorov Arnold Networks (KANs) are recent architectural advancement in
neural computation that offer a mathematically grounded alternative to standard
neural networks. This study presents an empirical evaluation of KANs in context
of class imbalanced classification, using ten benchmark datasets. We observe
that KANs can inherently perform well on raw imbalanced data more effectively
than Multi-Layer Perceptrons (MLPs) without any resampling strategy. However,
conventional imbalance strategies fundamentally conflict with KANs mathematical
structure as resampling and focal loss implementations significantly degrade
KANs performance, while marginally benefiting MLPs. Crucially, KANs suffer from
prohibitive computational costs without proportional performance gains.
Statistical validation confirms that MLPs with imbalance techniques achieve
equivalence with KANs (|d| < 0.08 across metrics) at minimal resource costs.
These findings reveal that KANs represent a specialized solution for raw
imbalanced data where resources permit. But their severe performance-resource
tradeoffs and incompatibility with standard resampling techniques currently
limits practical deployment. We identify critical research priorities as
developing KAN specific architectural modifications for imbalance learning,
optimizing computational efficiency, and theoretical reconciling their conflict
with data augmentation. This work establishes foundational insights for next
generation KAN architectures in imbalanced classification scenarios.

</details>


### [199] [Toward Temporal Causal Representation Learning with Tensor Decomposition](https://arxiv.org/abs/2507.14126)
*Jianhong Chen,Meng Zhao,Mostafa Reisi Gahrooei,Xubo Yue*

Main category: cs.LG

TL;DR: 该研究提出了CaRTeD框架，将时间因果表示学习与不规则张量分解相结合，用于高维、不规则数据的因果信息提取，实验在模拟和实际EHR数据中表现优越。


<details>
  <summary>Details</summary>
Motivation: 动机在于现有方法难以对高维、不规则数据进行关联建模和因果分析，作者旨在弥合不规则张量分解的理论和应用之间的差距。

Method: 提出了一种新的因果推理表述和CaRTeD框架，将时间因果表示学习与不规则张量分解联合，实现对潜在因果结构的建模和因果信息提取。

Result: 理论证明了算法的收敛性，通过合成数据和真实EHR数据集（如MIMIC-III）上的实验验证了框架在表型分析和网络恢复中的性能优越。

Conclusion: CaRTeD框架不仅在性能上超越了现有最优方法，还增强了因果表示的可解释性，并推动了对不规则张量分解的理论研究。

Abstract: Temporal causal representation learning is a powerful tool for uncovering
complex patterns in observational studies, which are often represented as
low-dimensional time series. However, in many real-world applications, data are
high-dimensional with varying input lengths and naturally take the form of
irregular tensors. To analyze such data, irregular tensor decomposition is
critical for extracting meaningful clusters that capture essential information.
In this paper, we focus on modeling causal representation learning based on the
transformed information. First, we present a novel causal formulation for a set
of latent clusters. We then propose CaRTeD, a joint learning framework that
integrates temporal causal representation learning with irregular tensor
decomposition. Notably, our framework provides a blueprint for downstream tasks
using the learned tensor factors, such as modeling latent structures and
extracting causal information, and offers a more flexible regularization design
to enhance tensor decomposition. Theoretically, we show that our algorithm
converges to a stationary point. More importantly, our results fill the gap in
theoretical guarantees for the convergence of state-of-the-art irregular tensor
decomposition. Experimental results on synthetic and real-world electronic
health record (EHR) datasets (MIMIC-III), with extensive benchmarks from both
phenotyping and network recovery perspectives, demonstrate that our proposed
method outperforms state-of-the-art techniques and enhances the explainability
of causal representations.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [200] [Neural Architecture Search with Mixed Bio-inspired Learning Rules](https://arxiv.org/abs/2507.13485)
*Imane Hamzaoui,Riyadh Baghdadi*

Main category: cs.NE

TL;DR: 本文通过神经网络架构搜索 (NAS) 在每层独立使用不同的类脑启发学习规则，提高了类脑启发网络的准确性和扩展性。


<details>
  <summary>Details</summary>
Motivation: 类脑启发网络在支持抗对抗性、节能以及接近皮层生理学方面有优势，但其准确性和扩展能力低于基于BP的模型，存在研究改进空间。

Method: 本文利用神经网络架构搜索 (NAS)，扩展搜索空间以包括类脑启发学习规则，并在每层寻找最佳架构和学习规则组合。

Result: 采用多样化类脑学习规则的网络在多个数据集上取得最佳记录，例如CIFAR-10 (95.16%)、CIFAR-100 (76.48%)、ImageNet16-120 (43.42%) 和ImageNet top-1 (60.51%)。某些情况下超越BP模型，并保留其鲁棒性。

Conclusion: 每层采用不同学习规则可以提高类脑启发网络的扩展性和准确性，鼓励未来研究混合多种类脑学习规则。

Abstract: Bio-inspired neural networks are attractive for their adversarial robustness,
energy frugality, and closer alignment with cortical physiology, yet they often
lag behind back-propagation (BP) based models in accuracy and ability to scale.
We show that allowing the use of different bio-inspired learning rules in
different layers, discovered automatically by a tailored
neural-architecture-search (NAS) procedure, bridges this gap. Starting from
standard NAS baselines, we enlarge the search space to include bio-inspired
learning rules and use NAS to find the best architecture and learning rule to
use in each layer. We show that neural networks that use different bio-inspired
learning rules for different layers have better accuracy than those that use a
single rule across all the layers. The resulting NN that uses a mix of
bio-inspired learning rules sets new records for bio-inspired models: 95.16% on
CIFAR-10, 76.48% on CIFAR-100, 43.42% on ImageNet16-120, and 60.51% top-1 on
ImageNet. In some regimes, they even surpass comparable BP-based networks while
retaining their robustness advantages. Our results suggest that layer-wise
diversity in learning rules allows better scalability and accuracy, and
motivates further research on mixing multiple bio-inspired learning rules in
the same network.

</details>


### [201] [Evolving Neural Controllers for Xpilot-AI Racing Using Neuroevolution of Augmenting Topologies](https://arxiv.org/abs/2507.13549)
*Jim O'Connor,Nicholas Lorentzen,Gary B. Parker,Derin Gezgin*

Main category: cs.NE

TL;DR: 本文研究了使用NEAT算法开发高性能赛车控制器，以应对Xpilot-AI平台中的新赛车模式。


<details>
  <summary>Details</summary>
Motivation: 探索如何在复杂物理模拟环境下发展自适应控制器，以提升赛车性能。

Method: 通过NEAT算法演化神经网络的结构与权重，develop自适应控制器，并设计可灵活调整的赛道与并行评估机制。

Result: 实验表明，控制器的单圈时间改进了32%，并学会了类似人类的高效赛车策略。

Conclusion: NEAT算法能够在游戏环境中生成稳健的控制策略，而Xpilot-AI是一个优质的AI控制器进化测试平台。

Abstract: This paper investigates the development of high-performance racing
controllers for a newly implemented racing mode within the Xpilot-AI platform,
utilizing the Neuro Evolution of Augmenting Topologies (NEAT) algorithm. By
leveraging NEAT's capability to evolve both the structure and weights of neural
networks, we develop adaptive controllers that can navigate complex circuits
under the challenging space simulation physics of Xpilot-AI, which includes
elements such as inertia, friction, and gravity. The racing mode we introduce
supports flexible circuit designs and allows for the evaluation of multiple
agents in parallel, enabling efficient controller optimization across
generations. Experimental results demonstrate that our evolved controllers
achieve up to 32% improvement in lap time compared to the controller's initial
performance and develop effective racing strategies, such as optimal cornering
and speed modulation, comparable to human-like techniques. This work
illustrates NEAT's effectiveness in producing robust control strategies within
demanding game environments and highlights Xpilot-AI's potential as a rigorous
testbed for competitive AI controller evolution.

</details>


### [202] [MorphoNAS: Embryogenic Neural Architecture Search Through Morphogen-Guided Development](https://arxiv.org/abs/2507.13785)
*Mykola Glybovets,Sergii Medvid*

Main category: cs.NE

TL;DR: 提出了一种可以自动生长神经网络的系统MorphoNAS，灵感来自生物学的自由能原理、反应-扩散系统和基因调控网络，通过简单发育规则构建复杂神经网络。


<details>
  <summary>Details</summary>
Motivation: 旨在减少人工干预，通过模拟生物神经网络的发育过程来实现自动神经网络架构搜索。

Method: 提出MorphoNAS系统，利用基因简单编码和细胞化学交互规则，模仿生物细胞自组织生成复杂神经网络。

Result: 在结构模拟任务中，成功生成目标随机图；在功能任务CartPole中，发现低复杂度（6-7神经元）解决方案，并在质量与效率间取得平衡。

Conclusion: MorphoNAS能够通过简单发育规则有效生成复杂神经架构，为自适应高效的神经网络搜索提供了生物学启示。

Abstract: While biological neural networks develop from compact genomes using
relatively simple rules, modern artificial neural architecture search methods
mostly involve explicit and routine manual work. In this paper, we introduce
MorphoNAS (Morphogenetic Neural Architecture Search), a system able to
deterministically grow neural networks through morphogenetic self-organization
inspired by the Free Energy Principle, reaction-diffusion systems, and gene
regulatory networks. In MorphoNAS, simple genomes encode just morphogens
dynamics and threshold-based rules of cellular development. Nevertheless, this
leads to self-organization of a single progenitor cell into complex neural
networks, while the entire process is built on local chemical interactions. Our
evolutionary experiments focused on two different domains: structural
targeting, in which MorphoNAS system was able to find fully successful genomes
able to generate predefined random graph configurations (8-31 nodes); and
functional performance on the CartPole control task achieving low complexity
6-7 neuron solutions when target network size minimization evolutionary
pressure was applied. The evolutionary process successfully balanced between
quality of of the final solutions and neural architecture search effectiveness.
Overall, our findings suggest that the proposed MorphoNAS method is able to
grow complex specific neural architectures, using simple developmental rules,
which suggests a feasible biological route to adaptive and efficient neural
architecture search.

</details>


### [203] [Conceptual and Design Principles for a Self-Referential Algorithm Mimicking Neuronal Assembly Functions](https://arxiv.org/abs/2507.14011)
*Paolo Totaro,Alberto Mangiante*

Main category: cs.NE

TL;DR: 提出了一种基于经验的认知过程模型形式化方法，通过一个称为环境生成操作符(EGO)的算法架构和一种自指语言(E-language)来模拟神经元组合层面的认知过程。


<details>
  <summary>Details</summary>
Motivation: 基于系统自我维持需求的角度，而非外部观察者视角，探讨如何形式化描述认知的运作机制。

Method: 利用环境生成操作符(EGO)算法和一种为该目的开发的自指语言(E-language)，模拟与赫布理论相符的神经元组合认知操作。

Result: 成功实现并测试了一个EGO的原型 (EGO-P)。

Conclusion: EGO及其实现原型EGO-P为认知过程建模提供了一种新的算法框架及工具，潜在助力更深刻理解神经元层面的认知运作。

Abstract: This article proposes a method to formalise models of cognitive processes
grounded in experience, considering experience from the perspective of a living
system and not from that of an observer of the living system. The perspective
of a living system is defined by the need of the system to preserve the vital
equilibria. The method is based on an algorithmic schema that we call
Environment Generative Operator (EGO) and uses a self-referential language
developed for this purpose which we call E-language. EGO simulates cognitive
processes as operations on neuron assemblies as understood by Hebb. In this
article we present an EGO prototype (EGO-P) which has already been implemented
and tested.

</details>
